[{"id":"11227809","href":"https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array","title":"Why is processing a sorted array faster than processing an unsorted array?","description":"\n                \nHere is a piece of C++ code that shows some very peculiar behavior. For some strange reason, sorting the data (before the timed region) miraculously makes the loop almost six times faster.\n#include <algorithm>\n#include <ctime>\n#include <iostream>\n\nint main()\n{\n    // Generate data\n    const unsigned arraySize = 32768;\n    int data[arraySize];\n\n    for (unsigned c = 0; c < arraySize; ++c)\n        data[c] = std::rand() % 256;\n\n    // !!! With this, the next loop runs faster.\n    std::sort(data, data + arraySize);\n\n    // Test\n    clock_t start = clock();\n    long long sum = 0;\n    for (unsigned i = 0; i < 100000; ++i)\n    {\n        for (unsigned c = 0; c < arraySize; ++c)\n        {   // Primary loop\n            if (data[c] >= 128)\n                sum += data[c];\n        }\n    }\n\n    double elapsedTime = static_cast<double>(clock()-start) / CLOCKS_PER_SEC;\n\n    std::cout << elapsedTime << '\\n';\n    std::cout << \"sum = \" << sum << '\\n';\n}\n\n\nWithout std::sort(data, data + arraySize);, the code runs in 11.54 seconds.\nWith the sorted data, the code runs in 1.93 seconds.\n\n(Sorting itself takes more time than than this one pass over the array, so it's not actually worth doing if we needed to calculate this for an unknown array.)\n\nInitially, I thought this might be just a language or compiler anomaly, so I tried Java:\nimport java.util.Arrays;\nimport java.util.Random;\n\npublic class Main\n{\n    public static void main(String[] args)\n    {\n        // Generate data\n        int arraySize = 32768;\n        int data[] = new int[arraySize];\n\n        Random rnd = new Random(0);\n        for (int c = 0; c < arraySize; ++c)\n            data[c] = rnd.nextInt() % 256;\n\n        // !!! With this, the next loop runs faster\n        Arrays.sort(data);\n\n        // Test\n        long start = System.nanoTime();\n        long sum = 0;\n        for (int i = 0; i < 100000; ++i)\n        {\n            for (int c = 0; c < arraySize; ++c)\n            {   // Primary loop\n                if (data[c] >= 128)\n                    sum += data[c];\n            }\n        }\n\n        System.out.println((System.nanoTime() - start) / 1000000000.0);\n        System.out.println(\"sum = \" + sum);\n    }\n}\n\nWith a similar but less extreme result.\n\nMy first thought was that sorting brings the data into the cache, but then I thought how silly that was because the array was just generated.\n\nWhat is going on?\nWhy is processing a sorted array faster than processing an unsorted array?\n\nThe code is summing up some independent terms, so the order should not matter.\n\nRelated / followup Q&As about the same effect with different / later compilers and options:\n\nWhy is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang?\ngcc optimization flag -O3 makes code slower than -O2\n\n    ","questionComments":["For the record, your data need not be sorted, only partitioned which is a much faster operation.","Another observation is that you don't need to sort the array, but you just need to partition it with the value 128. Sorting is n*log(n), whereas partitioning is just linear. Basically it is just one run of the quick sort partitioning step with the pivot chosen to be 128. Unfortunately in C++ there is just nth_element function, which partition by position, not by value.","@screwnut here's an experiment which would show that partitioning is sufficient: create an unsorted but partitioned array with otherwise random contents. Measure time. Sort it. Measure time again. The two measurements should be basically indistinguishable. (Experiment 2: create a random array. Measure time. Partition it. Measure time again. You should see the same speed-up as sorting. You could roll the two experiments into one.)","Btw. on Apple M1 the code runs in 17 sec unsorted, and in 7 sec sorted, so the branch prediction penalty isn't that bad on risc architecture.","@RomanYavorskyi: It depends on the compiler. If they make branchless asm for this specific test (e.g. as part of vectorizing with SIMD like in Why is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang?, or just with scalar cmov (gcc optimization flag -O3 makes code slower than -O2), then sorted or not doesn't matter. But unpredictable branches are still a very real thing when it's not as simple as counting, so it would be insane to delete this question."],"answers":[{"answer":"You are a victim of branch prediction fail.\n\nWhat is Branch Prediction?\n\nConsider a railroad junction:\n\n Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license.\n\nNow for the sake of argument, suppose this is back in the 1800s - before long-distance or radio communication.\n\nYou are the operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want. And then you set the switch appropriately.\n\nTrains are heavy and have a lot of inertia, so they take forever to start up and slow down.\n\nIs there a better way? You guess which direction the train will go!\n\nIf you guessed right, it continues on.\nIf you guessed wrong, the captain will stop, back up, and yell at you to flip the switch. Then it can restart down the other path.\n\nIf you guess right every time, the train will never have to stop.\nIf you guess wrong too often, the train will spend a lot of time stopping, backing up, and restarting.\n\nConsider an if-statement: At the processor level, it is a branch instruction:\n\nYou are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path.\n\nModern processors are complicated and have long pipelines. This means they take forever to \"warm up\" and \"slow down\".\n\nIs there a better way? You guess which direction the branch will go!\n\nIf you guessed right, you continue executing.\nIf you guessed wrong, you need to flush the pipeline and roll back to the branch. Then you can restart down the other path.\n\nIf you guess right every time, the execution will never have to stop.\nIf you guess wrong too often, you spend a lot of time stalling, rolling back, and restarting.\n\nThis is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment.\n\nHow would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every three times, you guess the same...\n\nIn other words, you try to identify a pattern and follow it. This is more or less how branch predictors work.\n\nMost applications have well-behaved branches. Therefore, modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless.\n\nFurther reading: \"Branch predictor\" article on Wikipedia.\n\nAs hinted from above, the culprit is this if-statement:\nif (data[c] >= 128)\n    sum += data[c];\n\n\nNotice that the data is evenly distributed between 0 and 255. When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement.\n\nThis is very friendly to the branch predictor since the branch consecutively goes the same direction many times. Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction.\n\nQuick visualization:\n\nT = branch taken\nN = branch not taken\n\ndata[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...\nbranch = N  N  N  N  N  ...   N    N    T    T    T  ...   T    T    T  ...\n\n       = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT  (easy to predict)\n\n\nHowever, when the data is completely random, the branch predictor is rendered useless, because it can't predict random data. Thus there will probably be around 50% misprediction (no better than random guessing).\n\ndata[] = 226, 185, 125, 158, 198, 144, 217, 79, 202, 118,  14, 150, 177, 182, ...\nbranch =   T,   T,   N,   T,   T,   T,   T,  N,   T,   N,   N,   T,   T,   T  ...\n\n       = TTNTTTTNTNNTTT ...   (completely random - impossible to predict)\n\n\nWhat can be done?\n\nIf the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance.\n\nReplace:\n\nif (data[c] >= 128)\n    sum += data[c];\n\n\nwith:\n\nint t = (data[c] - 128) >> 31;\nsum += ~t & data[c];\n\n\nThis eliminates the branch and replaces it with some bitwise operations.\n\n(Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of data[].)\n\nBenchmarks: Core i7 920 @ 3.5 GHz\n\nC++ - Visual Studio 2010 - x64 Release\n\nScenario\tTime (seconds)\nBranching - Random data\t11.777\nBranching - Sorted data\t2.352\nBranchless - Random data\t2.564\nBranchless - Sorted data\t2.587\n\nJava - NetBeans 7.1.1 JDK 7 - x64\n\nScenario\tTime (seconds)\nBranching - Random data\t10.93293813\nBranching - Sorted data\t5.643797077\nBranchless - Random data\t3.113581453\nBranchless - Sorted data\t3.186068823\n\nObservations:\n\nWith the Branch: There is a huge difference between the sorted and unsorted data.\nWith the Hack: There is no difference between sorted and unsorted data.\nIn the C++ case, the hack is actually a tad slower than with the branch when the data is sorted.\n\nA general rule of thumb is to avoid data-dependent branching in critical loops (such as in this example).\n\nUpdate:\n\nGCC 4.6.1 with -O3 or -ftree-vectorize on x64 is able to generate a conditional move, so there is no difference between the sorted and unsorted data - both are fast.\n\n(Or somewhat fast: for the already-sorted case, cmov can be slower especially if GCC puts it on the critical path instead of just add, especially on Intel before Broadwell where cmov has 2 cycle latency: gcc optimization flag -O3 makes code slower than -O2)\n\nVC++ 2010 is unable to generate conditional moves for this branch even under /Ox.\n\nIntel C++ Compiler (ICC) 11 does something miraculous. It interchanges the two loops, thereby hoisting the unpredictable branch to the outer loop. Not only is it immune to the mispredictions, it's also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark...\n\nIf you give the Intel compiler the branchless code, it just outright vectorizes it... and is just as fast as with the branch (with the loop interchange).\n\nThis goes to show that even mature modern compilers can vary wildly in their ability to optimize code...\n\nShare\nImprove this answer\nFollow\nedited Jul 25 at 22:06\nZoe\n23.9k16\n16 gold badges\n101\n101 silver badges\n139\n139 bronze badges\nanswered Jun 27 '12 at 13:56\nMysticial\n442k44\n44 gold badges\n324\n324 silver badges\n323\n323 bronze badges","comments":["this is all C++?","@HannaMcquaig I'd guess that part where it says \"Java\" isn't C++, but I may be wrong.","wait a second, doesnt shifting negative values to the right yield implementation-defined values? int t = (data[c] - 128) >> 31; sum += ~t & data[c];","Incidently branch prediction failure can also be exploited by a program to obtain crypto keys being used by another program on the same CPU core.","@Mycotina, I'm no expert, but what I understand is: the processor needs multiple steps to execute a single instruction (fetching, decoding, etc) -- this is called \"instruction pipelining\" -- so, as an optimization, it will fetch multiple instructions at once and \"warm up\" the next instructions while executing the current one. If the wrong branch is chosen, the instructions being \"warmed up\" in the pipeline must be discarded, so that the instructions on the right branch can be put into the pipeline instead."]},{"answer":"Branch prediction.\n\nWith a sorted array, the condition data[c] >= 128 is first false for a streak of values, then becomes true for all later values. That's easy to predict. With an unsorted array, you pay for the branching cost.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jun 27 '12 at 13:54\nDaniel Fischer\n176k16\n16 gold badges\n294\n294 silver badges\n422\n422 bronze badges","comments":["Does branch prediction work better on sorted arrays vs. arrays with different patterns? For example, for the array --> { 10, 5, 20, 10, 40, 20, ... } the next element in the array from the pattern is 80. Would this kind of array be sped up by branch prediction in which the next element is 80 here if the pattern is followed? Or does it usually only help with sorted arrays?","So basically everything I conventionally learned about big-O is out of the window? Better to incur a sorting cost than a branching cost?","@AgrimPathak That depends. For not too large input, an algorithm with higher complexity is faster than an algorithm with lower complexity when the constants are smaller for the algorithm with higher complexity. Where the break-even point is can be hard to predict. Also, compare this, locality is important. Big-O is important, but it is not the sole criterion for performance.","When does branch prediction takes place? When does language will know that array is sorted? I'm thinking of situation of array that looks like: [1,2,3,4,5,...998,999,1000, 3, 10001, 10002] ? will this obscure 3 increase running time? Will it be as long as unsorted array?","@FilipBartuzi Branch prediction takes place in the processor, below the language level (but the language may offer ways to tell the compiler what's likely, so the compiler can emit code suited to that). In your example, the out-of-order 3 will lead to a branch-misprediction (for appropriate conditions, where 3 gives a different result than 1000), and thus processing that array will likely take a couple dozen or hundred nanoseconds longer than a sorted array would, hardly ever noticeable. What costs time is i high rate of mispredictions, one misprediction per 1000 isn't much."]},{"answer":"The reason why performance improves drastically when the data is sorted is that the branch prediction penalty is removed, as explained beautifully in Mysticial's answer.\n\nNow, if we look at the code\n\nif (data[c] >= 128)\n    sum += data[c];\n\n\nwe can find that the meaning of this particular if... else... branch is to add something when a condition is satisfied. This type of branch can be easily transformed into a conditional move statement, which would be compiled into a conditional move instruction: cmovl, in an x86 system. The branch and thus the potential branch prediction penalty is removed.\n\nIn C, thus C++, the statement, which would compile directly (without any optimization) into the conditional move instruction in x86, is the ternary operator ... ? ... : .... So we rewrite the above statement into an equivalent one:\n\nsum += data[c] >=128 ? data[c] : 0;\n\n\nWhile maintaining readability, we can check the speedup factor.\n\nOn an Intel Core i7-2600K @ 3.4 GHz and Visual Studio 2010 Release Mode, the benchmark is:\n\nx86\n\nScenario\tTime (seconds)\nBranching - Random data\t8.885\nBranching - Sorted data\t1.528\nBranchless - Random data\t3.716\nBranchless - Sorted data\t3.71\n\nx64\n\nScenario\tTime (seconds)\nBranching - Random data\t11.302\nBranching - Sorted data\t1.830\nBranchless - Random data\t2.736\nBranchless - Sorted data\t2.737\n\nThe result is robust in multiple tests. We get a great speedup when the branch result is unpredictable, but we suffer a little bit when it is predictable. In fact, when using a conditional move, the performance is the same regardless of the data pattern.\n\nNow let's look more closely by investigating the x86 assembly they generate. For simplicity, we use two functions max1 and max2.\n\nmax1 uses the conditional branch if... else ...:\n\nint max1(int a, int b) {\n    if (a > b)\n        return a;\n    else\n        return b;\n}\n\n\nmax2 uses the ternary operator ... ? ... : ...:\n\nint max2(int a, int b) {\n    return a > b ? a : b;\n}\n\n\nOn a x86-64 machine, GCC -S generates the assembly below.\n\n:max1\n    movl    %edi, -4(%rbp)\n    movl    %esi, -8(%rbp)\n    movl    -4(%rbp), %eax\n    cmpl    -8(%rbp), %eax\n    jle     .L2\n    movl    -4(%rbp), %eax\n    movl    %eax, -12(%rbp)\n    jmp     .L4\n.L2:\n    movl    -8(%rbp), %eax\n    movl    %eax, -12(%rbp)\n.L4:\n    movl    -12(%rbp), %eax\n    leave\n    ret\n\n:max2\n    movl    %edi, -4(%rbp)\n    movl    %esi, -8(%rbp)\n    movl    -4(%rbp), %eax\n    cmpl    %eax, -8(%rbp)\n    cmovge  -8(%rbp), %eax\n    leave\n    ret\n\n\nmax2 uses much less code due to the usage of instruction cmovge. But the real gain is that max2 does not involve branch jumps, jmp, which would have a significant performance penalty if the predicted result is not right.\n\nSo why does a conditional move perform better?\n\nIn a typical x86 processor, the execution of an instruction is divided into several stages. Roughly, we have different hardware to deal with different stages. So we do not have to wait for one instruction to finish to start a new one. This is called pipelining.\n\nIn a branch case, the following instruction is determined by the preceding one, so we cannot do pipelining. We have to either wait or predict.\n\nIn a conditional move case, the execution conditional move instruction is divided into several stages, but the earlier stages like Fetch and Decode do not depend on the result of the previous instruction; only latter stages need the result. Thus, we wait a fraction of one instruction's execution time. This is why the conditional move version is slower than the branch when the prediction is easy.\n\nThe book Computer Systems: A Programmer's Perspective, second edition explains this in detail. You can check Section 3.6.6 for Conditional Move Instructions, entire Chapter 4 for Processor Architecture, and Section 5.11.2 for special treatment for Branch Prediction and Misprediction Penalties.\n\nSometimes, some modern compilers can optimize our code to assembly with better performance, sometimes some compilers can't (the code in question is using Visual Studio's native compiler). Knowing the performance difference between a branch and a conditional move when unpredictable can help us write code with better performance when the scenario gets so complex that the compiler can not optimize them automatically.\n\nShare\nImprove this answer\nFollow\nedited Jan 10 at 17:22\nDeduplicator\n42.3k6\n6 gold badges\n61\n61 silver badges\n105\n105 bronze badges\nanswered Jun 28 '12 at 2:14\nWiSaGaN\n42.9k8\n8 gold badges\n52\n52 silver badges\n81\n81 bronze badges","comments":["This doesn't work for Java.","stackoverflow.com/questions/9745389/…"]},{"answer":"If you are curious about even more optimizations that can be done to this code, consider this:\n\nStarting with the original loop:\n\nfor (unsigned i = 0; i < 100000; ++i)\n{\n    for (unsigned j = 0; j < arraySize; ++j)\n    {\n        if (data[j] >= 128)\n            sum += data[j];\n    }\n}\n\n\nWith loop interchange, we can safely change this loop to:\n\nfor (unsigned j = 0; j < arraySize; ++j)\n{\n    for (unsigned i = 0; i < 100000; ++i)\n    {\n        if (data[j] >= 128)\n            sum += data[j];\n    }\n}\n\n\nThen, you can see that the if conditional is constant throughout the execution of the i loop, so you can hoist the if out:\n\nfor (unsigned j = 0; j < arraySize; ++j)\n{\n    if (data[j] >= 128)\n    {\n        for (unsigned i = 0; i < 100000; ++i)\n        {\n            sum += data[j];\n        }\n    }\n}\n\n\nThen, you see that the inner loop can be collapsed into one single expression, assuming the floating point model allows it (/fp:fast is thrown, for example)\n\nfor (unsigned j = 0; j < arraySize; ++j)\n{\n    if (data[j] >= 128)\n    {\n        sum += data[j] * 100000;\n    }\n}\n\n\nThat one is 100,000 times faster than before.\n\nShare\nImprove this answer\nFollow\nedited May 27 '19 at 12:51\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 3 '12 at 2:25\nvulcan raven\n30k9\n9 gold badges\n52\n52 silver badges\n90\n90 bronze badges","comments":[]},{"answer":"No doubt some of us would be interested in ways of identifying code that is problematic for the CPU's branch-predictor. The Valgrind tool cachegrind has a branch-predictor simulator, enabled by using the --branch-sim=yes flag. Running it over the examples in this question, with the number of outer loops reduced to 10000 and compiled with g++, gives these results:\n\nSorted:\n\n==32551== Branches:        656,645,130  (  656,609,208 cond +    35,922 ind)\n==32551== Mispredicts:         169,556  (      169,095 cond +       461 ind)\n==32551== Mispred rate:            0.0% (          0.0%     +       1.2%   )\n\n\nUnsorted:\n\n==32555== Branches:        655,996,082  (  655,960,160 cond +  35,922 ind)\n==32555== Mispredicts:     164,073,152  (  164,072,692 cond +     460 ind)\n==32555== Mispred rate:           25.0% (         25.0%     +     1.2%   )\n\n\nDrilling down into the line-by-line output produced by cg_annotate we see for the loop in question:\n\nSorted:\n\n          Bc    Bcm Bi Bim\n      10,001      4  0   0      for (unsigned i = 0; i < 10000; ++i)\n           .      .  .   .      {\n           .      .  .   .          // primary loop\n 327,690,000 10,016  0   0          for (unsigned c = 0; c < arraySize; ++c)\n           .      .  .   .          {\n 327,680,000 10,006  0   0              if (data[c] >= 128)\n           0      0  0   0                  sum += data[c];\n           .      .  .   .          }\n           .      .  .   .      }\n\n\nUnsorted:\n\n          Bc         Bcm Bi Bim\n      10,001           4  0   0      for (unsigned i = 0; i < 10000; ++i)\n           .           .  .   .      {\n           .           .  .   .          // primary loop\n 327,690,000      10,038  0   0          for (unsigned c = 0; c < arraySize; ++c)\n           .           .  .   .          {\n 327,680,000 164,050,007  0   0              if (data[c] >= 128)\n           0           0  0   0                  sum += data[c];\n           .           .  .   .          }\n           .           .  .   .      }\n\n\nThis lets you easily identify the problematic line - in the unsorted version the if (data[c] >= 128) line is causing 164,050,007 mispredicted conditional branches (Bcm) under cachegrind's branch-predictor model, whereas it's only causing 10,006 in the sorted version.\n\nAlternatively, on Linux you can use the performance counters subsystem to accomplish the same task, but with native performance using CPU counters.\n\nperf stat ./sumtest_sorted\n\n\nSorted:\n\n Performance counter stats for './sumtest_sorted':\n\n  11808.095776 task-clock                #    0.998 CPUs utilized          \n         1,062 context-switches          #    0.090 K/sec                  \n            14 CPU-migrations            #    0.001 K/sec                  \n           337 page-faults               #    0.029 K/sec                  \n26,487,882,764 cycles                    #    2.243 GHz                    \n41,025,654,322 instructions              #    1.55  insns per cycle        \n 6,558,871,379 branches                  #  555.455 M/sec                  \n       567,204 branch-misses             #    0.01% of all branches        \n\n  11.827228330 seconds time elapsed\n\n\nUnsorted:\n\n Performance counter stats for './sumtest_unsorted':\n\n  28877.954344 task-clock                #    0.998 CPUs utilized          \n         2,584 context-switches          #    0.089 K/sec                  \n            18 CPU-migrations            #    0.001 K/sec                  \n           335 page-faults               #    0.012 K/sec                  \n65,076,127,595 cycles                    #    2.253 GHz                    \n41,032,528,741 instructions              #    0.63  insns per cycle        \n 6,560,579,013 branches                  #  227.183 M/sec                  \n 1,646,394,749 branch-misses             #   25.10% of all branches        \n\n  28.935500947 seconds time elapsed\n\n\nIt can also do source code annotation with dissassembly.\n\nperf record -e branch-misses ./sumtest_unsorted\nperf annotate -d sumtest_unsorted\n\n Percent |      Source code & Disassembly of sumtest_unsorted\n------------------------------------------------\n...\n         :                      sum += data[c];\n    0.00 :        400a1a:       mov    -0x14(%rbp),%eax\n   39.97 :        400a1d:       mov    %eax,%eax\n    5.31 :        400a1f:       mov    -0x20040(%rbp,%rax,4),%eax\n    4.60 :        400a26:       cltq   \n    0.00 :        400a28:       add    %rax,-0x30(%rbp)\n...\n\n\nSee the performance tutorial for more details.\n\nShare\nImprove this answer\nFollow\nedited Oct 18 '12 at 19:20\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 12 '12 at 5:53\ncaf\n219k34\n34 gold badges\n290\n290 silver badges\n437\n437 bronze badges","comments":["This is scary, in the unsorted list, there should be 50% chance of hitting the add. Somehow the branch prediction only has a 25% miss rate, how can it do better than 50% miss?","@tall.b.lo: The 25% is of all branches - there are two branches in the loop, one for data[c] >= 128 (which has a 50% miss rate as you suggest) and one for the loop condition c < arraySize which has ~0% miss rate."]},{"answer":"I just read up on this question and its answers, and I feel an answer is missing.\n\nA common way to eliminate branch prediction that I've found to work particularly good in managed languages is a table lookup instead of using a branch (although I haven't tested it in this case).\n\nThis approach works in general if:\n\nit's a small table and is likely to be cached in the processor, and\nyou are running things in a quite tight loop and/or the processor can preload the data.\n\nBackground and why\n\nFrom a processor perspective, your memory is slow. To compensate for the difference in speed, a couple of caches are built into your processor (L1/L2 cache). So imagine that you're doing your nice calculations and figure out that you need a piece of memory. The processor will get its 'load' operation and loads the piece of memory into cache -- and then uses the cache to do the rest of the calculations. Because memory is relatively slow, this 'load' will slow down your program.\n\nLike branch prediction, this was optimized in the Pentium processors: the processor predicts that it needs to load a piece of data and attempts to load that into the cache before the operation actually hits the cache. As we've already seen, branch prediction sometimes goes horribly wrong -- in the worst case scenario you need to go back and actually wait for a memory load, which will take forever (in other words: failing branch prediction is bad, a memory load after a branch prediction fail is just horrible!).\n\nFortunately for us, if the memory access pattern is predictable, the processor will load it in its fast cache and all is well.\n\nThe first thing we need to know is what is small? While smaller is generally better, a rule of thumb is to stick to lookup tables that are <= 4096 bytes in size. As an upper limit: if your lookup table is larger than 64K it's probably worth reconsidering.\n\nConstructing a table\n\nSo we've figured out that we can create a small table. Next thing to do is get a lookup function in place. Lookup functions are usually small functions that use a couple of basic integer operations (and, or, xor, shift, add, remove and perhaps multiply). You want to have your input translated by the lookup function to some kind of 'unique key' in your table, which then simply gives you the answer of all the work you wanted it to do.\n\nIn this case: >= 128 means we can keep the value, < 128 means we get rid of it. The easiest way to do that is by using an 'AND': if we keep it, we AND it with 7FFFFFFF; if we want to get rid of it, we AND it with 0. Notice also that 128 is a power of 2 -- so we can go ahead and make a table of 32768/128 integers and fill it with one zero and a lot of 7FFFFFFFF's.\n\nManaged languages\n\nYou might wonder why this works well in managed languages. After all, managed languages check the boundaries of the arrays with a branch to ensure you don't mess up...\n\nWell, not exactly... :-)\n\nThere has been quite some work on eliminating this branch for managed languages. For example:\n\nfor (int i = 0; i < array.Length; ++i)\n{\n   // Use array[i]\n}\n\n\nIn this case, it's obvious to the compiler that the boundary condition will never be hit. At least the Microsoft JIT compiler (but I expect Java does similar things) will notice this and remove the check altogether. WOW, that means no branch. Similarly, it will deal with other obvious cases.\n\nIf you run into trouble with lookups in managed languages -- the key is to add a & 0x[something]FFF to your lookup function to make the boundary check predictable -- and watch it going faster.\n\nThe result of this case\n\n// Generate data\nint arraySize = 32768;\nint[] data = new int[arraySize];\n\nRandom random = new Random(0);\nfor (int c = 0; c < arraySize; ++c)\n{\n    data[c] = random.Next(256);\n}\n\n/*To keep the spirit of the code intact, I'll make a separate lookup table\n(I assume we cannot modify 'data' or the number of loops)*/\n\nint[] lookup = new int[256];\n\nfor (int c = 0; c < 256; ++c)\n{\n    lookup[c] = (c >= 128) ? c : 0;\n}\n\n// Test\nDateTime startTime = System.DateTime.Now;\nlong sum = 0;\n\nfor (int i = 0; i < 100000; ++i)\n{\n    // Primary loop\n    for (int j = 0; j < arraySize; ++j)\n    {\n        /* Here you basically want to use simple operations - so no\n        random branches, but things like &, |, *, -, +, etc. are fine. */\n        sum += lookup[data[j]];\n    }\n}\n\nDateTime endTime = System.DateTime.Now;\nConsole.WriteLine(endTime - startTime);\nConsole.WriteLine(\"sum = \" + sum);\nConsole.ReadLine();\n\nShare\nImprove this answer\nFollow\nedited Jan 16 '19 at 4:47\nPalec\n10.6k7\n7 gold badges\n53\n53 silver badges\n116\n116 bronze badges\nanswered Apr 24 '13 at 6:26\natlaste\n28.1k3\n3 gold badges\n52\n52 silver badges\n76\n76 bronze badges","comments":[]},{"answer":"As data is distributed between 0 and 255 when the array is sorted, around the first half of the iterations will not enter the if-statement (the if statement is shared below).\n\nif (data[c] >= 128)\n    sum += data[c];\n\n\nThe question is: What makes the above statement not execute in certain cases as in case of sorted data? Here comes the \"branch predictor\". A branch predictor is a digital circuit that tries to guess which way a branch (e.g. an if-then-else structure) will go before this is known for sure. The purpose of the branch predictor is to improve the flow in the instruction pipeline. Branch predictors play a critical role in achieving high effective performance!\n\nLet's do some bench marking to understand it better\n\nThe performance of an if-statement depends on whether its condition has a predictable pattern. If the condition is always true or always false, the branch prediction logic in the processor will pick up the pattern. On the other hand, if the pattern is unpredictable, the if-statement will be much more expensive.\n\nLet’s measure the performance of this loop with different conditions:\n\nfor (int i = 0; i < max; i++)\n    if (condition)\n        sum++;\n\n\nHere are the timings of the loop with different true-false patterns:\n\nCondition                Pattern             Time (ms)\n-------------------------------------------------------\n(i & 0×80000000) == 0    T repeated          322\n\n(i & 0xffffffff) == 0    F repeated          276\n\n(i & 1) == 0             TF alternating      760\n\n(i & 3) == 0             TFFFTFFF…           513\n\n(i & 2) == 0             TTFFTTFF…           1675\n\n(i & 4) == 0             TTTTFFFFTTTTFFFF…   1275\n\n(i & 8) == 0             8T 8F 8T 8F …       752\n\n(i & 16) == 0            16T 16F 16T 16F …   490\n\n\nA “bad” true-false pattern can make an if-statement up to six times slower than a “good” pattern! Of course, which pattern is good and which is bad depends on the exact instructions generated by the compiler and on the specific processor.\n\nSo there is no doubt about the impact of branch prediction on performance!\n\nShare\nImprove this answer\nFollow\nedited Feb 27 '19 at 10:58\nNeuron\n3,8373\n3 gold badges\n24\n24 silver badges\n44\n44 bronze badges\nanswered Feb 15 '13 at 7:24\nSaqlain\n16.2k4\n4 gold badges\n25\n25 silver badges\n33\n33 bronze badges","comments":["@MooingDuck 'Cause it won't make a difference - that value can be anything, but it still will be in the bounds of these thresholds. So why show a random value when you already know the limits? Although I agree that you could show one for the sake of completeness, and 'just for the heck of it'.","@cst1992: Right now his slowest timing is TTFFTTFFTTFF, which seems, to my human eye, quite predictable. Random is inherently unpredictable, so it's entirely possible it would be slower still, and thus outside the limits shown here. OTOH, it could be that TTFFTTFF perfectly hits the pathological case. Can't tell, since he didn't show the timings for random.","@MooingDuck To a human eye, \"TTFFTTFFTTFF\" is a predictable sequence, but what we are talking about here is the behavior of the branch predictor built into a CPU. The branch predictor is not AI-level pattern recognition; it's very simple. When you just alternate branches it doesn't predict well. In most code, branches go the same way almost all the time; consider a loop that executes a thousand times. The branch at the end of the loop goes back to the start of the loop 999 times, and then the thousandth time does something different. A very simple branch predictor works well, usually.","@steveha: I think you're making assumptions about how the CPU branch predictor works, and I disagree with that methodology. I don't know how advanced that branch predictor is, but I seem to think it's far more advanced than you do. You're probably right, but measurements would definitely be good.","@steveha: The Two-level adaptive predictor could lock onto the TTFFTTFF pattern with no issue whatsoever. \"Variants of this prediction method are used in most modern microprocessors\". Local branch prediction and Global branch prediction are based on a two level adaptive predictor, they can as well. \"Global branch prediction is used in AMD processors, and in Intel Pentium M, Core, Core 2, and Silvermont-based Atom processors\" Also add Agree predictor, Hybrid predictor, Prediction of indirect jumps, to that list. Loop predictor wont lock on, but hits 75%. That leaves only 2 that can't lock on"]},{"answer":"One way to avoid branch prediction errors is to build a lookup table, and index it using the data. Stefan de Bruijn discussed that in his answer.\n\nBut in this case, we know values are in the range [0, 255] and we only care about values >= 128. That means we can easily extract a single bit that will tell us whether we want a value or not: by shifting the data to the right 7 bits, we are left with a 0 bit or a 1 bit, and we only want to add the value when we have a 1 bit. Let's call this bit the \"decision bit\".\n\nBy using the 0/1 value of the decision bit as an index into an array, we can make code that will be equally fast whether the data is sorted or not sorted. Our code will always add a value, but when the decision bit is 0, we will add the value somewhere we don't care about. Here's the code:\n\n// Test\nclock_t start = clock();\nlong long a[] = {0, 0};\nlong long sum;\n\nfor (unsigned i = 0; i < 100000; ++i)\n{\n    // Primary loop\n    for (unsigned c = 0; c < arraySize; ++c)\n    {\n        int j = (data[c] >> 7);\n        a[j] += data[c];\n    }\n}\n\ndouble elapsedTime = static_cast<double>(clock() - start) / CLOCKS_PER_SEC;\nsum = a[1];\n\n\nThis code wastes half of the adds but never has a branch prediction failure. It's tremendously faster on random data than the version with an actual if statement.\n\nBut in my testing, an explicit lookup table was slightly faster than this, probably because indexing into a lookup table was slightly faster than bit shifting. This shows how my code sets up and uses the lookup table (unimaginatively called lut for \"LookUp Table\" in the code). Here's the C++ code:\n\n// Declare and then fill in the lookup table\nint lut[256];\nfor (unsigned c = 0; c < 256; ++c)\n    lut[c] = (c >= 128) ? c : 0;\n\n// Use the lookup table after it is built\nfor (unsigned i = 0; i < 100000; ++i)\n{\n    // Primary loop\n    for (unsigned c = 0; c < arraySize; ++c)\n    {\n        sum += lut[data[c]];\n    }\n}\n\n\nIn this case, the lookup table was only 256 bytes, so it fits nicely in a cache and all was fast. This technique wouldn't work well if the data was 24-bit values and we only wanted half of them... the lookup table would be far too big to be practical. On the other hand, we can combine the two techniques shown above: first shift the bits over, then index a lookup table. For a 24-bit value that we only want the top half value, we could potentially shift the data right by 12 bits, and be left with a 12-bit value for a table index. A 12-bit table index implies a table of 4096 values, which might be practical.\n\nThe technique of indexing into an array, instead of using an if statement, can be used for deciding which pointer to use. I saw a library that implemented binary trees, and instead of having two named pointers (pLeft and pRight or whatever) had a length-2 array of pointers and used the \"decision bit\" technique to decide which one to follow. For example, instead of:\n\nif (x < node->value)\n    node = node->pLeft;\nelse\n    node = node->pRight;\n\n\nthis library would do something like:\n\ni = (x < node->value);\nnode = node->link[i];\n\n\nHere's a link to this code: Red Black Trees, Eternally Confuzzled\n\nShare\nImprove this answer\nFollow\nedited Jan 27 at 10:03\njakubde\n231\n1 silver badge\n4\n4 bronze badges\nanswered Jul 22 '13 at 8:29\nsteveha\n68.3k18\n18 gold badges\n87\n87 silver badges\n112\n112 bronze badges","comments":["Right, you can also just use the bit directly and multiply (data[c]>>7 - which is discussed somewhere here as well); I intentionally left this solution out, but of course you are correct. Just a small note: The rule of thumb for lookup tables is that if it fits in 4KB (because of caching), it'll work - preferably make the table as small as possible. For managed languages I'd push that to 64KB, for low-level languages like C++ and C, I'd probably reconsider (that's just my experience). Since typeof(int) = 4, I'd try to stick to max 10 bits.","I think indexing with the 0/1 value will probably be faster than an integer multiply, but I guess if performance is really critical you should profile it. I agree that small lookup tables are essential to avoid cache pressure, but clearly if you have a bigger cache you can get away with a bigger lookup table, so 4KB is more a rule of thumb than a hard rule. I think you meant sizeof(int) == 4? That would be true for 32-bit. My two-year-old cell phone has a 32KB L1 cache, so even a 4K lookup table might work, especially if the lookup values were a byte instead of an int.","Possibly I'm missing something but in your j equals 0 or 1 method why don't you just multiply your value by j before adding it rather than using the array indexing (possibly should be multiplied by 1-j rather than j)","@steveha Multiplication should be faster, I tried looking it up in the Intel books, but couldn't find it... either way, benchmarking also gives me that result here.","@steveha P.S.: another possible answer would be int c = data[j]; sum += c & -(c >> 7); which requires no multiplications at all."]},{"answer":"In the sorted case, you can do better than relying on successful branch prediction or any branchless comparison trick: completely remove the branch.\n\nIndeed, the array is partitioned in a contiguous zone with data < 128 and another with data >= 128. So you should find the partition point with a dichotomic search (using Lg(arraySize) = 15 comparisons), then do a straight accumulation from that point.\n\nSomething like (unchecked)\n\nint i= 0, j, k= arraySize;\nwhile (i < k)\n{\n  j= (i + k) >> 1;\n  if (data[j] >= 128)\n    k= j;\n  else\n    i= j;\n}\nsum= 0;\nfor (; i < arraySize; i++)\n  sum+= data[i];\n\n\nor, slightly more obfuscated\n\nint i, k, j= (i + k) >> 1;\nfor (i= 0, k= arraySize; i < k; (data[j] >= 128 ? k : i)= j)\n  j= (i + k) >> 1;\nfor (sum= 0; i < arraySize; i++)\n  sum+= data[i];\n\n\nA yet faster approach, that gives an approximate solution for both sorted or unsorted is: sum= 3137536; (assuming a truly uniform distribution, 16384 samples with expected value 191.5) :-)\n\nShare\nImprove this answer\nFollow\nedited May 11 '19 at 11:31\nKonard\n1,14713\n13 silver badges\n17\n17 bronze badges\nanswered Jul 24 '13 at 7:57\nYves Daoust\n49.7k8\n8 gold badges\n39\n39 silver badges\n86\n86 bronze badges","comments":["sum= 3137536 - clever. That's kinda obviously not the point of the question. The question is clearly about explaining surprising performance characteristics. I'm inclined to say that the addition of doing std::partition instead of std::sort is valuable. Though the actual question extends to more than just the synthetic benchmark given.","@DeadMG: this is indeed not the standard dichotomic search for a given key, but a search for the partitioning index; it requires a single compare per iteration. But don't rely on this code, I have not checked it. If you are interested in a guaranteed correct implementation, let me know."]},{"answer":"The above behavior is happening because of Branch prediction.\n\nTo understand branch prediction one must first understand Instruction Pipeline:\n\nAny instruction is broken into a sequence of steps so that different steps can be executed concurrently in parallel. This technique is known as instruction pipeline and this is used to increase throughput in modern processors. To understand this better please see this example on Wikipedia.\n\nGenerally, modern processors have quite long pipelines, but for ease let's consider these 4 steps only.\n\nIF -- Fetch the instruction from memory\nID -- Decode the instruction\nEX -- Execute the instruction\nWB -- Write back to CPU register\n\n4-stage pipeline in general for 2 instructions. \n\nMoving back to the above question let's consider the following instructions:\n\n                        A) if (data[c] >= 128)\n                                /\\\n                               /  \\\n                              /    \\\n                        true /      \\ false\n                            /        \\\n                           /          \\\n                          /            \\\n                         /              \\\n              B) sum += data[c];          C) for loop or print().\n\n\nWithout branch prediction, the following would occur:\n\nTo execute instruction B or instruction C the processor will have to wait till the instruction A doesn't reach till EX stage in the pipeline, as the decision to go to instruction B or instruction C depends on the result of instruction A. So the pipeline will look like this.\n\nwhen if condition returns true: \n\nWhen if condition returns false: \n\nAs a result of waiting for the result of instruction A, the total CPU cycles spent in the above case (without branch prediction; for both true and false) is 7.\n\nSo what is branch prediction?\n\nBranch predictor will try to guess which way a branch (an if-then-else structure) will go before this is known for sure. It will not wait for the instruction A to reach the EX stage of the pipeline, but it will guess the decision and go to that instruction (B or C in case of our example).\n\nIn case of a correct guess, the pipeline looks something like this: \n\nIf it is later detected that the guess was wrong then the partially executed instructions are discarded and the pipeline starts over with the correct branch, incurring a delay. The time that is wasted in case of a branch misprediction is equal to the number of stages in the pipeline from the fetch stage to the execute stage. Modern microprocessors tend to have quite long pipelines so that the misprediction delay is between 10 and 20 clock cycles. The longer the pipeline the greater the need for a good branch predictor.\n\nIn the OP's code, the first time when the conditional, the branch predictor does not have any information to base up prediction, so the first time it will randomly choose the next instruction. Later in the for loop, it can base the prediction on the history. For an array sorted in ascending order, there are three possibilities:\n\nAll the elements are less than 128\nAll the elements are greater than 128\nSome starting new elements are less than 128 and later it become greater than 128\n\nLet us assume that the predictor will always assume the true branch on the first run.\n\nSo in the first case, it will always take the true branch since historically all its predictions are correct. In the 2nd case, initially it will predict wrong, but after a few iterations, it will predict correctly. In the 3rd case, it will initially predict correctly till the elements are less than 128. After which it will fail for some time and the correct itself when it sees branch prediction failure in history.\n\nIn all these cases the failure will be too less in number and as a result, only a few times it will need to discard the partially executed instructions and start over with the correct branch, resulting in fewer CPU cycles.\n\nBut in case of a random unsorted array, the prediction will need to discard the partially executed instructions and start over with the correct branch most of the time and result in more CPU cycles compared to the sorted array.\n\nShare\nImprove this answer\nFollow\nedited Apr 10 '18 at 20:13\nSaheb\n1,2002\n2 gold badges\n13\n13 silver badges\n28\n28 bronze badges\nanswered Jul 3 '15 at 15:35\nHarsh Sharma\n9,8042\n2 gold badges\n13\n13 silver badges\n25\n25 bronze badges","comments":["how are two instructions executed together? is this done with separate cpu cores or is pipeline instruction is integrated in single cpu core?","@M.kazemAkhgary It's all inside one logical core. If you're interested, this is nicely described for example in Intel Software Developer Manual"]},{"answer":"An official answer would be from\n\nIntel - Avoiding the Cost of Branch Misprediction\nIntel - Branch and Loop Reorganization to Prevent Mispredicts\nScientific papers - branch prediction computer architecture\nBooks: J.L. Hennessy, D.A. Patterson: Computer architecture: a quantitative approach\nArticles in scientific publications: T.Y. Yeh, Y.N. Patt made a lot of these on branch predictions.\n\nYou can also see from this lovely diagram why the branch predictor gets confused.\n\nEach element in the original code is a random value\n\ndata[c] = std::rand() % 256;\n\n\nso the predictor will change sides as the std::rand() blow.\n\nOn the other hand, once it's sorted, the predictor will first move into a state of strongly not taken and when the values change to the high value the predictor will in three runs through change all the way from strongly not taken to strongly taken.\n\nShare\nImprove this answer\nFollow\nedited Jan 31 '17 at 11:39\ngreatwolf\n19k13\n13 gold badges\n64\n64 silver badges\n102\n102 bronze badges\nanswered Oct 11 '15 at 21:05\nSurt\n14.3k3\n3 gold badges\n22\n22 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"In the same line (I think this was not highlighted by any answer) it's good to mention that sometimes (specially in software where the performance matters—like in the Linux kernel) you can find some if statements like the following:\n\nif (likely( everything_is_ok ))\n{\n    /* Do something */\n}\n\n\nor similarly:\n\nif (unlikely(very_improbable_condition))\n{\n    /* Do something */    \n}\n\n\nBoth likely() and unlikely() are in fact macros that are defined by using something like the GCC's __builtin_expect to help the compiler insert prediction code to favour the condition taking into account the information provided by the user. GCC supports other builtins that could change the behavior of the running program or emit low level instructions like clearing the cache, etc. See this documentation that goes through the available GCC's builtins.\n\nNormally this kind of optimizations are mainly found in hard-real time applications or embedded systems where execution time matters and it's critical. For example, if you are checking for some error condition that only happens 1/10000000 times, then why not inform the compiler about this? This way, by default, the branch prediction would assume that the condition is false.\n\nShare\nImprove this answer\nFollow\nedited Oct 28 '16 at 10:28\nStacked\n5,8466\n6 gold badges\n53\n53 silver badges\n69\n69 bronze badges\nanswered Sep 23 '15 at 14:57\nrkachach\n14.2k5\n5 gold badges\n35\n35 silver badges\n58\n58 bronze badges","comments":[]},{"answer":"Frequently used Boolean operations in C++ produce many branches in the compiled program. If these branches are inside loops and are hard to predict they can slow down execution significantly. Boolean variables are stored as 8-bit integers with the value 0 for false and 1 for true.\n\nBoolean variables are overdetermined in the sense that all operators that have Boolean variables as input check if the inputs have any other value than 0 or 1, but operators that have Booleans as output can produce no other value than 0 or 1. This makes operations with Boolean variables as input less efficient than necessary. Consider example:\n\nbool a, b, c, d;\nc = a && b;\nd = a || b;\n\n\nThis is typically implemented by the compiler in the following way:\n\nbool a, b, c, d;\nif (a != 0) {\n    if (b != 0) {\n        c = 1;\n    }\n    else {\n        goto CFALSE;\n    }\n}\nelse {\n    CFALSE:\n    c = 0;\n}\nif (a == 0) {\n    if (b == 0) {\n        d = 0;\n    }\n    else {\n        goto DTRUE;\n    }\n}\nelse {\n    DTRUE:\n    d = 1;\n}\n\n\nThis code is far from optimal. The branches may take a long time in case of mispredictions. The Boolean operations can be made much more efficient if it is known with certainty that the operands have no other values than 0 and 1. The reason why the compiler does not make such an assumption is that the variables might have other values if they are uninitialized or come from unknown sources. The above code can be optimized if a and b has been initialized to valid values or if they come from operators that produce Boolean output. The optimized code looks like this:\n\nchar a = 0, b = 1, c, d;\nc = a & b;\nd = a | b;\n\n\nchar is used instead of bool in order to make it possible to use the bitwise operators (& and |) instead of the Boolean operators (&& and ||). The bitwise operators are single instructions that take only one clock cycle. The OR operator (|) works even if a and b have other values than 0 or 1. The AND operator (&) and the EXCLUSIVE OR operator (^) may give inconsistent results if the operands have other values than 0 and 1.\n\n~ can not be used for NOT. Instead, you can make a Boolean NOT on a variable which is known to be 0 or 1 by XOR'ing it with 1:\n\nbool a, b;\nb = !a;\n\n\ncan be optimized to:\n\nchar a = 0, b;\nb = a ^ 1;\n\n\na && b cannot be replaced with a & b if b is an expression that should not be evaluated if a is false ( && will not evaluate b, & will). Likewise, a || b can not be replaced with a | b if b is an expression that should not be evaluated if a is true.\n\nUsing bitwise operators is more advantageous if the operands are variables than if the operands are comparisons:\n\nbool a; double x, y, z;\na = x > y && z < 5.0;\n\n\nis optimal in most cases (unless you expect the && expression to generate many branch mispredictions).\n\nShare\nImprove this answer\nFollow\nedited May 30 '19 at 16:34\nSujal Patel\n2,2671\n1 gold badge\n19\n19 silver badges\n34\n34 bronze badges\nanswered Oct 10 '15 at 0:30\nMaciej\n8,5852\n2 gold badges\n13\n13 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"That's for sure!...\n\nBranch prediction makes the logic run slower, because of the switching which happens in your code! It's like you are going a straight street or a street with a lot of turnings, for sure the straight one is going to be done quicker!...\n\nIf the array is sorted, your condition is false at the first step: data[c] >= 128, then becomes a true value for the whole way to the end of the street. That's how you get to the end of the logic faster. On the other hand, using an unsorted array, you need a lot of turning and processing which make your code run slower for sure...\n\nLook at the image I created for you below. Which street is going to be finished faster?\n\nSo programmatically, branch prediction causes the process to be slower...\n\nAlso at the end, it's good to know we have two kinds of branch predictions that each is going to affect your code differently:\n\n1. Static\n\n2. Dynamic\n\nStatic branch prediction is used by the microprocessor the first time a conditional branch is encountered, and dynamic branch prediction is used for succeeding executions of the conditional branch code.\n\nIn order to effectively write your code to take advantage of these rules, when writing if-else or switch statements, check the most common cases first and work progressively down to the least common. Loops do not necessarily require any special ordering of code for static branch prediction, as only the condition of the loop iterator is normally used.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jun 18 '17 at 11:40\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"This question has already been answered excellently many times over. Still I'd like to draw the group's attention to yet another interesting analysis.\n\nRecently this example (modified very slightly) was also used as a way to demonstrate how a piece of code can be profiled within the program itself on Windows. Along the way, the author also shows how to use the results to determine where the code is spending most of its time in both the sorted & unsorted case. Finally the piece also shows how to use a little known feature of the HAL (Hardware Abstraction Layer) to determine just how much branch misprediction is happening in the unsorted case.\n\nThe link is here: A Demonstration of Self-Profiling\n\nShare\nImprove this answer\nFollow\nedited Jan 10 at 15:50\nDeduplicator\n42.3k6\n6 gold badges\n61\n61 silver badges\n105\n105 bronze badges\nanswered Jan 12 '17 at 1:50\nForeverLearning\n5,4863\n3 gold badges\n23\n23 silver badges\n33\n33 bronze badges","comments":["That is a very interesting article (in fact, I have just read all of it), but how does it answer the question?","@PeterMortensen I am a bit flummoxed by your question. For example here is one relevant line from that piece: When the input is unsorted, all the rest of the loop takes substantial time. But with sorted input, the processor is somehow able to spend not just less time in the body of the loop, meaning the buckets at offsets 0x18 and 0x1C, but vanishingly little time on the mechanism of looping. Author is trying to discuss profiling in the context of code posted here and in the process trying to explain why the sorted case is so much more faster."]},{"answer":"As what has already been mentioned by others, what behind the mystery is Branch Predictor.\n\nI'm not trying to add something but explaining the concept in another way. There is a concise introduction on the wiki which contains text and diagram. I do like the explanation below which uses a diagram to elaborate the Branch Predictor intuitively.\n\nIn computer architecture, a branch predictor is a digital circuit that tries to guess which way a branch (e.g. an if-then-else structure) will go before this is known for sure. The purpose of the branch predictor is to improve the flow in the instruction pipeline. Branch predictors play a critical role in achieving high effective performance in many modern pipelined microprocessor architectures such as x86.\n\nTwo-way branching is usually implemented with a conditional jump instruction. A conditional jump can either be \"not taken\" and continue execution with the first branch of code which follows immediately after the conditional jump, or it can be \"taken\" and jump to a different place in program memory where the second branch of code is stored. It is not known for certain whether a conditional jump will be taken or not taken until the condition has been calculated and the conditional jump has passed the execution stage in the instruction pipeline (see fig. 1).\n\nBased on the described scenario, I have written an animation demo to show how instructions are executed in a pipeline in different situations.\n\nWithout the Branch Predictor.\n\nWithout branch prediction, the processor would have to wait until the conditional jump instruction has passed the execute stage before the next instruction can enter the fetch stage in the pipeline.\n\nThe example contains three instructions and the first one is a conditional jump instruction. The latter two instructions can go into the pipeline until the conditional jump instruction is executed.\n\nIt will take 9 clock cycles for 3 instructions to be completed.\n\nUse Branch Predictor and don't take a conditional jump. Let's assume that the predict is not taking the conditional jump.\n\nIt will take 7 clock cycles for 3 instructions to be completed.\n\nUse Branch Predictor and take a conditional jump. Let's assume that the predict is not taking the conditional jump.\n\nIt will take 9 clock cycles for 3 instructions to be completed.\n\nThe time that is wasted in case of a branch misprediction is equal to the number of stages in the pipeline from the fetch stage to the execute stage. Modern microprocessors tend to have quite long pipelines so that the misprediction delay is between 10 and 20 clock cycles. As a result, making a pipeline longer increases the need for a more advanced branch predictor.\n\nAs you can see, it seems we don't have a reason not to use Branch Predictor.\n\nIt's quite a simple demo that clarifies the very basic part of Branch Predictor. If those gifs are annoying, please feel free to remove them from the answer and visitors can also get the live demo source code from BranchPredictorDemo\n\nShare\nImprove this answer\nFollow\nedited Feb 10 '20 at 2:05\nanswered Nov 6 '17 at 16:15\nEugene\n8,8173\n3 gold badges\n36\n36 silver badges\n57\n57 bronze badges","comments":["Almost as good as the Intel marketing animations, and they were obsessed not just with branch prediction but out of order execution, both strategies being \"speculative\". Reading ahead in memory and storage (sequential pre-fetch to buffer) is also speculative. It all adds up.","@mckenzm: out-of-order speculative exec makes branch prediction even more valuable; as well as hiding fetch/decode bubbles, branch prediction + speculative exec removes control dependencies from critical path latency. Code inside or after an if() block can execute before the branch condition is known. Or for a search loop like strlen or memchr, interations can overlap. If you had to wait for the match-or-not result to be known before running any of the next iteration, you'd bottleneck on cache load + ALU latency instead of throughput.","Did you make the example app in JavaFX?","@HannaMcquaig No, it's made by Swing. The code is available at github.com/Eugene-Mark/branch-predictor-demo."]},{"answer":"Branch-prediction gain!\n\nIt is important to understand that branch misprediction doesn't slow down programs. The cost of a missed prediction is just as if branch prediction didn't exist and you waited for the evaluation of the expression to decide what code to run (further explanation in the next paragraph).\n\nif (expression)\n{\n    // Run 1\n} else {\n    // Run 2\n}\n\n\nWhenever there's an if-else \\ switch statement, the expression has to be evaluated to determine which block should be executed. In the assembly code generated by the compiler, conditional branch instructions are inserted.\n\nA branch instruction can cause a computer to begin executing a different instruction sequence and thus deviate from its default behavior of executing instructions in order (i.e. if the expression is false, the program skips the code of the if block) depending on some condition, which is the expression evaluation in our case.\n\nThat being said, the compiler tries to predict the outcome prior to it being actually evaluated. It will fetch instructions from the if block, and if the expression turns out to be true, then wonderful! We gained the time it took to evaluate it and made progress in the code; if not then we are running the wrong code, the pipeline is flushed, and the correct block is run.\n\nVisualization:\n\nLet's say you need to pick route 1 or route 2. Waiting for your partner to check the map, you have stopped at ## and waited, or you could just pick route1 and if you were lucky (route 1 is the correct route), then great you didn't have to wait for your partner to check the map (you saved the time it would have taken him to check the map), otherwise you will just turn back.\n\nWhile flushing pipelines is super fast, nowadays taking this gamble is worth it. Predicting sorted data or a data that changes slowly is always easier and better than predicting fast changes.\n\n O      Route 1  /-------------------------------\n/|\\             /\n |  ---------##/\n/ \\            \\\n                \\\n        Route 2  \\--------------------------------\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Aug 4 '17 at 10:07\nTony Tannous\n12.3k7\n7 gold badges\n42\n42 silver badges\n76\n76 bronze badges","comments":["While flushing pipelines is super fast Not really. It's fast compared to a cache miss all the way to DRAM, but on a modern high-performance x86 (like Intel Sandybridge-family) it's about a dozen cycles. Although fast recovery does allow it to avoid waiting for all older independent instructions to reach retirement before starting recovery, you still lose a lot of front-end cycles on a mispredict. What exactly happens when a skylake CPU mispredicts a branch?. (And each cycle can be about 4 instructions of work.) Bad for high-throughput code."]},{"answer":"On ARM, there is no branch needed, because every instruction has a 4-bit condition field, which tests (at zero cost) any of 16 different different conditions that may arise in the Processor Status Register, and if the condition on an instruction is false, the instruction is skipped. This eliminates the need for short branches, and there would be no branch prediction hit for this algorithm. Therefore, the sorted version of this algorithm would run slower than the unsorted version on ARM, because of the extra overhead of sorting.\n\nThe inner loop for this algorithm would look something like the following in ARM assembly language:\n\nMOV R0, #0   // R0 = sum = 0\nMOV R1, #0   // R1 = c = 0\nADR R2, data // R2 = addr of data array (put this instruction outside outer loop)\n.inner_loop  // Inner loop branch label\n    LDRB R3, [R2, R1]   // R3 = data[c]\n    CMP R3, #128        // compare R3 to 128\n    ADDGE R0, R0, R3    // if R3 >= 128, then sum += data[c] -- no branch needed!\n    ADD R1, R1, #1      // c++\n    CMP R1, #arraySize  // compare c to arraySize\n    BLT inner_loop      // Branch to inner_loop if c < arraySize\n\n\nBut this is actually part of a bigger picture:\n\nCMP opcodes always update the status bits in the Processor Status Register (PSR), because that is their purpose, but most other instructions do not touch the PSR unless you add an optional S suffix to the instruction, specifying that the PSR should be updated based on the result of the instruction. Just like the 4-bit condition suffix, being able to execute instructions without affecting the PSR is a mechanism that reduces the need for branches on ARM, and also facilitates out of order dispatch at the hardware level, because after performing some operation X that updates the status bits, subsequently (or in parallel) you can do a bunch of other work that explicitly should not affect (or be affected by) the status bits, then you can test the state of the status bits set earlier by X.\n\nThe condition testing field and the optional \"set status bit\" field can be combined, for example:\n\nADD R1, R2, R3 performs R1 = R2 + R3 without updating any status bits.\nADDGE R1, R2, R3 performs the same operation only if a previous instruction that affected the status bits resulted in a Greater than or Equal condition.\nADDS R1, R2, R3 performs the addition and then updates the N, Z, C and V flags in the Processor Status Register based on whether the result was Negative, Zero, Carried (for unsigned addition), or oVerflowed (for signed addition).\nADDSGE R1, R2, R3 performs the addition only if the GE test is true, and then subsequently updates the status bits based on the result of the addition.\n\nMost processor architectures do not have this ability to specify whether or not the status bits should be updated for a given operation, which can necessitate writing additional code to save and later restore status bits, or may require additional branches, or may limit the processor's out of order execution efficiency: one of the side effects of most CPU instruction set architectures forcibly updating status bits after most instructions is that it is much harder to tease apart which instructions can be run in parallel without interfering with each other. Updating status bits has side effects, therefore has a linearizing effect on code. ARM's ability to mix and match branch-free condition testing on any instruction with the option to either update or not update the status bits after any instruction is extremely powerful, for both assembly language programmers and compilers, and produces very efficient code.\n\nWhen you don't have to branch, you can avoid the time cost of flushing the pipeline for what would otherwise be short branches, and you can avoid the design complexity of many forms of speculative evalution. The performance impact of the initial naive imlementations of the mitigations for many recently discovered processor vulnerabilities (Spectre etc.) shows you just how much the performance of modern processors depends upon complex speculative evaluation logic. With a short pipeline and the dramatically reduced need for branching, ARM just doesn't need to rely on speculative evaluation as much as CISC processors. (Of course high-end ARM implementations do include speculative evaluation, but it's a smaller part of the performance story.)\n\nIf you have ever wondered why ARM has been so phenomenally successful, the brilliant effectiveness and interplay of these two mechanisms (combined with another mechanism that lets you \"barrel shift\" left or right one of the two arguments of any arithmetic operator or offset memory access operator at zero additional cost) are a big part of the story, because they are some of the greatest sources of the ARM architecture's efficiency. The brilliance of the original designers of the ARM ISA back in 1983, Steve Furber and Roger (now Sophie) Wilson, cannot be overstated.\n\nShare\nImprove this answer\nFollow\nedited Oct 20 '20 at 22:33\nanswered Dec 22 '17 at 13:13\nLuke Hutchison\n6,3592\n2 gold badges\n32\n32 silver badges\n27\n27 bronze badges","comments":["The other innovation in ARM is the addition of the S instruction suffix, also optional on (almost) all instructions, which if absent, prevents instructions from changing status bits (with the exception of the CMP instruction, whose job is to set status bits, so it doesn't need the S suffix). This allows you to avoid CMP instructions in many cases, as long as the comparison is with zero or similar (eg. SUBS R0, R0, #1 will set the Z (Zero) bit when R0 reaches zero). Conditionals and the S suffix incur zero overhead. It's quite a beautiful ISA.","Not adding the S suffix allows you to have several conditional instructions in a row without worrying that one of them might change the status bits, which might otherwise have the side effect of skipping the rest of the conditional instructions.","Note that the OP is not including the time to sort in their measurement. It's probably an overall loss to sort first before running a branch x86 loop, too, even though the non-sorted case makes the loop run a lot slower. But sorting a big array requires a lot of work.","BTW, you could save an instruction in the loop by indexing relative to the end of the array. Before the loop, set up R2 = data + arraySize, then start with R1 = -arraySize. The bottom of the loop becomes adds r1, r1, #1 / bnz inner_loop. Compilers don't use this optimization for some reason :/ But anyway, predicated execution of the add is not fundamentally different in this case from what you can do with branchless code on other ISAs, like x86 cmov. Although it's not as nice: gcc optimization flag -O3 makes code slower than -O2","(ARM predicated execution truly NOPs the instruction, so you can even use it on loads or stores that would fault, unlike x86 cmov with a memory source operand. Most ISAs, including AArch64, only have ALU select operations. So ARM predication can be powerful, and usable more efficiently than branchless code on most ISAs.)"]},{"answer":"It's about branch prediction. What is it?\n\nA branch predictor is one of the ancient performance-improving techniques which still finds relevance in modern architectures. While the simple prediction techniques provide fast lookup and power efficiency they suffer from a high misprediction rate.\n\nOn the other hand, complex branch predictions –either neural-based or variants of two-level branch prediction –provide better prediction accuracy, but they consume more power and complexity increases exponentially.\n\nIn addition to this, in complex prediction techniques, the time taken to predict the branches is itself very high –ranging from 2 to 5 cycles –which is comparable to the execution time of actual branches.\n\nBranch prediction is essentially an optimization (minimization) problem where the emphasis is on to achieve lowest possible miss rate, low power consumption, and low complexity with minimum resources.\n\nThere really are three different kinds of branches:\n\nForward conditional branches - based on a run-time condition, the PC (program counter) is changed to point to an address forward in the instruction stream.\n\nBackward conditional branches - the PC is changed to point backward in the instruction stream. The branch is based on some condition, such as branching backwards to the beginning of a program loop when a test at the end of the loop states the loop should be executed again.\n\nUnconditional branches - this includes jumps, procedure calls, and returns that have no specific condition. For example, an unconditional jump instruction might be coded in assembly language as simply \"jmp\", and the instruction stream must immediately be directed to the target location pointed to by the jump instruction, whereas a conditional jump that might be coded as \"jmpne\" would redirect the instruction stream only if the result of a comparison of two values in a previous \"compare\" instructions shows the values to not be equal. (The segmented addressing scheme used by the x86 architecture adds extra complexity since jumps can be either \"near\" (within a segment) or \"far\" (outside the segment). Each type has different effects on branch prediction algorithms.)\n\nStatic/dynamic Branch Prediction: Static branch prediction is used by the microprocessor the first time a conditional branch is encountered, and dynamic branch prediction is used for succeeding executions of the conditional branch code.\n\nReferences:\n\nBranch predictor\n\nA Demonstration of Self-Profiling\n\nBranch Prediction Review\n\nBranch Prediction (Using wayback machine)\n\nShare\nImprove this answer\nFollow\nedited Jul 16 at 18:58\nPeter Cordes\n255k36\n36 gold badges\n440\n440 silver badges\n635\n635 bronze badges\nanswered Oct 3 '17 at 9:47\nFarhad\n5,7788\n8 gold badges\n37\n37 silver badges\n61\n61 bronze badges","comments":[]},{"answer":"Besides the fact that the branch prediction may slow you down, a sorted array has another advantage:\n\nYou can have a stop condition instead of just checking the value, this way you only loop over the relevant data, and ignore the rest.\nThe branch prediction will miss only once.\n\n // sort backwards (higher values first), may be in some other part of the code\n std::sort(data, data + arraySize, std::greater<int>());\n\n for (unsigned c = 0; c < arraySize; ++c) {\n       if (data[c] < 128) {\n              break;\n       }\n       sum += data[c];               \n }\n\nShare\nImprove this answer\nFollow\nedited Mar 5 '19 at 9:58\nanswered Nov 23 '17 at 14:28\nYochai Timmer\n45.2k21\n21 gold badges\n136\n136 silver badges\n180\n180 bronze badges","comments":["Right, but the setup cost of sorting the array is O(N log N), so breaking early doesn't help you if the only reason you are sorting the array is to be able to break early. If, however, you have other reasons to pre-sort the array, then yes, this is valuable.","Depends how many times you sort the data compared to how many times you loop on it. The sort in this example is just an example, it doesn't have to be just before the loop","Yes, that's exactly the point I made in my first comment :-) You say \"The branch prediction will miss only once.\" But you are not counting the O(N log N) branch prediction misses inside the sort algorithm, which is actually greater than the O(N) branch prediction misses in the unsorted case. So you would need to use the entirety of the sorted data O(log N) times to break even (probably actually closer to O(10 log N), depending on the sort algorithm, e.g. for quicksort, due to cache misses -- mergesort is more cache-coherent, so you would need closer to O(2 log N) usages to break even.)","One significant optimization though would be to do only \"half a quicksort\", sorting only items less than the target pivot value of 127 (assuming everything less than or equal to the pivot is sorted after the pivot). Once you reach the pivot, sum the elements before the pivot. This would run in O(N) startup time rather than O(N log N), although there will still be a lot of branch prediction misses, probably of the order of O(5 N) based on the numbers I gave before, since it's half a quicksort."]},{"answer":"Sorted arrays are processed faster than an unsorted array, due to a phenomena called branch prediction.\n\nThe branch predictor is a digital circuit (in computer architecture) trying to predict which way a branch will go, improving the flow in the instruction pipeline. The circuit/computer predicts the next step and executes it.\n\nMaking a wrong prediction leads to going back to the previous step, and executing with another prediction. Assuming the prediction is correct, the code will continue to the next step. A wrong prediction results in repeating the same step, until a correct prediction occurs.\n\nThe answer to your question is very simple.\n\nIn an unsorted array, the computer makes multiple predictions, leading to an increased chance of errors. Whereas, in a sorted array, the computer makes fewer predictions, reducing the chance of errors. Making more predictions requires more time.\n\nSorted Array: Straight Road\n\n____________________________________________________________________________________\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT\n\n\nUnsorted Array: Curved Road\n\n______   ________\n|     |__|\n\n\nBranch prediction: Guessing/predicting which road is straight and following it without checking\n\n___________________________________________ Straight road\n |_________________________________________|Longer road\n\n\nAlthough both the roads reach the same destination, the straight road is shorter, and the other is longer. If then you choose the other by mistake, there is no turning back, and so you will waste some extra time if you choose the longer road. This is similar to what happens in the computer, and I hope this helped you understand better.\n\nAlso I want to cite @Simon_Weaver from the comments:\n\nIt doesn’t make fewer predictions - it makes fewer incorrect predictions. It still has to predict for each time through the loop...\n\nShare\nImprove this answer\nFollow\nedited Jan 10 at 15:59\nDeduplicator\n42.3k6\n6 gold badges\n61\n61 silver badges\n105\n105 bronze badges\nanswered Dec 7 '17 at 17:28\nomkaartg\n2,3581\n1 gold badge\n7\n7 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"I tried the same code with MATLAB 2011b with my MacBook Pro (Intel i7, 64 bit, 2.4 GHz) for the following MATLAB code:\n\n% Processing time with Sorted data vs unsorted data\n%==========================================================================\n% Generate data\narraySize = 32768\nsum = 0;\n% Generate random integer data from range 0 to 255\ndata = randi(256, arraySize, 1);\n\n\n%Sort the data\ndata1= sort(data); % data1= data  when no sorting done\n\n\n%Start a stopwatch timer to measure the execution time\ntic;\n\nfor i=1:100000\n\n    for j=1:arraySize\n\n        if data1(j)>=128\n            sum=sum + data1(j);\n        end\n    end\nend\n\ntoc;\n\nExeTimeWithSorting = toc - tic;\n\n\nThe results for the above MATLAB code are as follows:\n\n  a: Elapsed time (without sorting) = 3479.880861 seconds.\n  b: Elapsed time (with sorting ) = 2377.873098 seconds.\n\n\nThe results of the C code as in @GManNickG I get:\n\n  a: Elapsed time (without sorting) = 19.8761 sec.\n  b: Elapsed time (with sorting ) = 7.37778 sec.\n\n\nBased on this, it looks MATLAB is almost 175 times slower than the C implementation without sorting and 350 times slower with sorting. In other words, the effect (of branch prediction) is 1.46x for MATLAB implementation and 2.7x for the C implementation.\n\nShare\nImprove this answer\nFollow\nedited Mar 16 '18 at 12:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 30 '12 at 16:16\nShan\n4,62610\n10 gold badges\n41\n41 silver badges\n57\n57 bronze badges","comments":["Just for the sake of completeness, this is probably not how you'd implement that in Matlab. I bet it'd be much faster if done after vectorizing the problem.","Matlab does automatic parallelization / vectorization in many situations but the issue here is to check the effect of branch prediction. Matlab is not immune in anyway!","Does matlab use native numbers or a mat lab specific implementation (infinite amount of digits or so?)"]},{"answer":"The assumption by other answers that one needs to sort the data is not correct.\n\nThe following code does not sort the entire array, but only 200-element segments of it, and thereby runs the fastest.\n\nSorting only k-element sections completes the pre-processing in linear time, O(n), rather than the O(n.log(n)) time needed to sort the entire array.\n\n#include <algorithm>\n#include <ctime>\n#include <iostream>\n\nint main() {\n    int data[32768]; const int l = sizeof data / sizeof data[0];\n\n    for (unsigned c = 0; c < l; ++c)\n        data[c] = std::rand() % 256;\n\n    // sort 200-element segments, not the whole array\n    for (unsigned c = 0; c + 200 <= l; c += 200)\n        std::sort(&data[c], &data[c + 200]);\n\n    clock_t start = clock();\n    long long sum = 0;\n\n    for (unsigned i = 0; i < 100000; ++i) {\n        for (unsigned c = 0; c < sizeof data / sizeof(int); ++c) {\n            if (data[c] >= 128)\n                sum += data[c];\n        }\n    }\n\n    std::cout << static_cast<double>(clock() - start) / CLOCKS_PER_SEC << std::endl;\n    std::cout << \"sum = \" << sum << std::endl;\n}\n\n\nThis also \"proves\" that it has nothing to do with any algorithmic issue such as sort order, and it is indeed branch prediction.\n\nShare\nImprove this answer\nFollow\nedited Jul 2 '19 at 4:08\nanswered Dec 9 '18 at 6:18\nuser2297550\n2,3531\n1 gold badge\n19\n19 silver badges\n29\n29 bronze badges","comments":["I don't really see how this proves anything? The only thing you have shown is that \"not doing all the work of sorting the whole array takes less time than sorting the whole array\". Your claim that this \"also runs fastest\" is very architecture-dependent. See my answer about how this works on ARM. PS you could make your code faster on non-ARM architectures by putting the summation inside the 200-element block loop, sorting in reverse, and then using Yochai Timmer's suggestion of breaking once you get an out-of range value. That way each 200-element block summation can be terminated early.","If you just want to implement the algorithm efficiently over unsorted data, you would do that operation branchlessly (and with SIMD, e.g. with x86 pcmpgtb to find elements with their high bit set, then AND to zero smaller elements). Spending any time actually sorting chunks would be slower. A branchless version would have data-independent performance, also proving that the cost came from branch misprediction. Or just use performance counters to observe that directly, like Skylake int_misc.clear_resteer_cycles or int_misc.recovery_cycles to count front-end idle cycles from mispredicts","Both comments above seem to ignore the general algorithmic issues and complexity, in favor of advocating specialized hardware with special machine instructions. I find the first one particularly petty in that it blithely dismisses the important general insights in this answer in blind favor of specialized machine instructions.","Also note that specialized hardware instructions do not help if the computation within the if is more complicated than an simple addition, which is quite likely in the general case. Therefore, this answer is unique in offering a general solution that is still O(n)"]},{"answer":"Bjarne Stroustrup's Answer to this question:\n\nThat sounds like an interview question. Is it true? How would you know? It is a bad idea to answer questions about efficiency without first doing some measurements, so it is important to know how to measure.\n\nSo, I tried with a vector of a million integers and got:\n\nAlready sorted    32995 milliseconds\nShuffled          125944 milliseconds\n\nAlready sorted    18610 milliseconds\nShuffled          133304 milliseconds\n\nAlready sorted    17942 milliseconds\nShuffled          107858 milliseconds\n\n\nI ran that a few times to be sure. Yes, the phenomenon is real. My key code was:\n\nvoid run(vector<int>& v, const string& label)\n{\n    auto t0 = system_clock::now();\n    sort(v.begin(), v.end());\n    auto t1 = system_clock::now();\n    cout << label\n         << duration_cast<microseconds>(t1 — t0).count()\n         << \" milliseconds\\n\";\n}\n\nvoid tst()\n{\n    vector<int> v(1'000'000);\n    iota(v.begin(), v.end(), 0);\n    run(v, \"already sorted \");\n    std::shuffle(v.begin(), v.end(), std::mt19937{ std::random_device{}() });\n    run(v, \"shuffled    \");\n}\n\n\nAt least the phenomenon is real with this compiler, standard library, and optimizer settings. Different implementations can and do give different answers. In fact, someone did do a more systematic study (a quick web search will find it) and most implementations show that effect.\n\nOne reason is branch prediction: the key operation in the sort algorithm is “if(v[i] < pivot]) …” or equivalent. For a sorted sequence that test is always true whereas, for a random sequence, the branch chosen varies randomly.\n\nAnother reason is that when the vector is already sorted, we never need to move elements to their correct position. The effect of these little details is the factor of five or six that we saw.\n\nQuicksort (and sorting in general) is a complex study that has attracted some of the greatest minds of computer science. A good sort function is a result of both choosing a good algorithm and paying attention to hardware performance in its implementation.\n\nIf you want to write efficient code, you need to know a bit about machine architecture.\n\nShare\nImprove this answer\nFollow\nedited Jan 10 at 16:02\ncommunity wiki\n\n\n2 revs, 2 users 75%\nSelcuk","comments":["This seems to be missing the point of the question, and is answering whether sorting itself is faster with already-sorted arrays. This is less surprising because as this answer points out, there's less work to be done (with most sort algorithms other than merge-sort), on top of the branch-prediction effect. The actual question factors out this effect and is only timing a conditional increment."]},{"answer":"This question is rooted in branch prediction models on CPUs. I'd recommend reading this paper:\n\nIncreasing the Instruction Fetch Rate via Multiple Branch Prediction and a Branch Address Cache\n\nWhen you have sorted elements, the IR can not be bothered to fetch all CPU instructions, again and again. It fetches them from the cache.\n\nShare\nImprove this answer\nFollow\nedited Jan 13 at 21:23\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 23 '19 at 21:35\nhatirlatici\n1,3551\n1 gold badge\n11\n11 silver badges\n20\n20 bronze badges","comments":["The instructions stay hot in the CPU's L1 instruction cache regardless of mispredicts. The problem is fetching them into the pipeline in the right order, before the immediately-previous instructions have decoded and finished executing."]},{"answer":"BRANCH PREDICTION\n\nThis is called branch prediction. Without branch prediction, the processor would have to wait until the conditional jump instruction has passed the execute stage before the next instruction can enter the fetch stage in the pipeline. The branch predictor attempts to avoid this waste of time by trying to guess whether the conditional jump is most likely to be taken or not taken. The branch that is guessed to be the most likely is then fetched and speculatively executed. If it is later detected that the guess was wrong, then the speculatively executed, incurring a delay.\n\ndata[c] >= 128\n\n\nTake more help from this link: Multiple Branch Prediction for Wide-Issue Superscalar\n\nShare\nImprove this answer\nFollow\nedited Apr 14 at 10:51\nanswered Apr 14 at 8:08\nNuman Gillani\n5715\n5 silver badges\n18\n18 bronze badges","comments":["The CPU's instruction and data caches are separate from branch prediction. (The BPU itself can be considered a cache of branch directions, but if that's what you mean you should be more specific.) All the code will stay hot in the L1i cache regardless of branch mispredict; it's the pipeline itself that's the problem. The CPU (or the code) isn't \"search\"ing for anything, so I'm not sure what point you're trying to make when you talk about \"search time\".","Without branch prediction, the processor would have to wait until the conditional jump instruction has passed the execute stage before the next instruction can enter the fetch stage in the pipeline. The branch predictor attempts to avoid this waste of time by trying to guess whether the conditional jump is most likely to be taken or not taken. The branch that is guessed to be the most likely is then fetched and speculatively executed. If it is later detected that the guess was wrong, then the speculatively executed, incurring a delay.","Yes, that's correct. If you replaced your current answer with that comment, I'd change my downvote! But that's not how your answer explains it. Instead your answer says \"next time the cache memory will be used for searching\" which doesn't even make sense, and certainly isn't an accurate description of the relevant part of CPU internals.","Also, an unsorted array only \"comes with branching cost\" if your asm has branches in the first place. A branchless count (like Why is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang?) doesn't care about patterns in the data.","yes agreed with you, answer updated."]},{"answer":"Maybe you should not sort the data, since the output value range is limited. Its much faster to calculate how many times each value is happening.\n\ne.g. you have 20 data between 0..3 then you could reserve 3 counters. In the end you may have : { 0: 10x , 1: 8x, 2: 2x }\n\nTo convert this array back to a linear array is easy, just print 10x 0, 8x 1, 2x 2.\n\nWhen the values are not 0..2 but still limited, you could still consider this method. Sorting is always slow! Other advantage: This is little code, easy to read and test, has less bugs.\n\nShare\nImprove this answer\nFollow\nanswered Jun 27 at 13:49\nBart Mensfort\n76410\n10 silver badges\n17\n17 bronze badges","comments":["That wasn't the question. The question was, if the data happens to already be sorted, why does that specific conditional-increment loop run faster. But yeah if you want to answer the question of \"how to optimize this query against the array\": Histogramming indeed would put your data into a form that could answer queries with an arbitrary threshold much faster. But if you just want to answer one query for a given threshold with that data, it's not faster to pre-process the data. (At least if you can convince the compiler to do a branchless sum of boolean 0/1 compare results.)"]}]},{"id":"927358","href":"https://stackoverflow.com/questions/927358/how-do-i-undo-the-most-recent-local-commits-in-git","title":"How do I undo the most recent local commits in Git?","description":"\n                \nI accidentally committed the wrong files to Git, but didn't push the commit to the server yet.\nHow can I undo those commits from the local repository?\nThe only way seems to be to copy the edits in some kind of GUI text editor, then wipe the whole local clone, then re-clone the repository, then re-applying the edits. However,\n\nThis can cause data loss.\nIt's very hard to do this when only an accidental git commit was run.\n\nIs there a better way?\n    ","questionComments":["You know what git needs? git undo, that's it. Then the reputation git has for handling mistakes made by us mere mortals disappears. Implement by pushing the current state on a git stack before executing any git command. It would affect performance, so it would be best to add a config flag as to whether to enable it.","@YiminRong That can be done with Git's alias feature: git-scm.com/book/en/v2/Git-Basics-Git-Aliases","For VsCode users , just type ctrl +shift +G and then click on three dot ,ie , more options and then click on undo Last Commit","@YiminRong Not buying it. People would still fumble and undo things not to be undone. But more importantly, git reflog is already close to what you describe, but gives the user more control on what's to be (un)done. But please, no, \"undo\" does not work the same everywhere, and people would expect many different things for the feature to achieve. Undo last commit? Undo last action? If last action was a push, undo how exactly, (reset and push) or (revert and push)?","See this diagram from Git. It shows all the possible ways to mess up code and its solutions."],"answers":[{"answer":"Undo a commit & redo\n$ git commit -m \"Something terribly misguided\" # (0: Your Accident)\n$ git reset HEAD~                              # (1)\n[ edit files as necessary ]                    # (2)\n$ git add .                                    # (3)\n$ git commit -c ORIG_HEAD                      # (4)\n\n\nThis command is responsible for the undo. It will undo your last commit while leaving your working tree (the state of your files on disk) untouched. You'll need to add them again before you can commit them again).\n\nMake corrections to working tree files.\n\ngit add anything that you want to include in your new commit.\n\nCommit the changes, reusing the old commit message. reset copied the old head to .git/ORIG_HEAD; commit with -c ORIG_HEAD will open an editor, which initially contains the log message from the old commit and allows you to edit it. If you do not need to edit the message, you could use the -C option.\n\nAlternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.\n\nTo remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin master --force is necessary.\n\nFurther Reading\n\nHow can I move HEAD back to a previous location? (Detached head) & Undo commits\n\nThe above answer will show you git reflog, which you can use to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.\n\nHEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits.\n\nShare\nImprove this answer\nFollow\nedited Dec 21 '20 at 16:53\ncommunity wiki\n\n\n47 revs, 39 users 15%\nMark Amery","comments":["And if the commit was to the wrong branch, you may git checkout theRightBranch with all the changes stages. As I just had to do.","If you're working in DOS, instead of git reset --soft HEAD^ you'll need to use git reset --soft HEAD~1. The ^ is a continuation character in DOS so it won't work properly. Also, --soft is the default, so you can omit it if you like and just say git reset HEAD~1.","zsh users might get: zsh: no matches found: HEAD^ - you need to escape ^ i.e. git reset --soft HEAD\\^","The answer is not correct if, say by accident, git commit -a was issued when the -a should have been left out. In which case, it's better no leave out the --soft (which will result in --mixed which is the default) and then you can restage the changes you meant to commit.","In more recent versions of git HEAD~ can be replaced with @~."]},{"answer":"Undoing a commit is a little scary if you don't know how it works. But it's actually amazingly easy if you do understand. I'll show you the 4 different ways you can undo a commit.\n\noption 1: git reset --hard\n\nSay you have this, where C is your HEAD and (F) is the state of your files.\n\n   (F)\nA-B-C\n    ↑\n  master\n\n\nYou want to nuke commit C and never see it again and lose all the changes in locally modified files. You do this:\n\ngit reset --hard HEAD~1\n\n\nThe result is:\n\n (F)\nA-B\n  ↑\nmaster\n\n\nNow B is the HEAD. Because you used --hard, your files are reset to their state at commit B.\n\noption 2: git reset\n\nAh, but suppose commit C wasn't a disaster, but just a bit off. You want to undo the commit but keep your changes for a bit of editing before you do a better commit. Starting again from here, with C as your HEAD:\n\n   (F)\nA-B-C\n    ↑\n  master\n\n\nYou can do this, leaving off the --hard:\n\ngit reset HEAD~1\n\n\nIn this case the result is:\n\n   (F)\nA-B-C\n  ↑\nmaster\n\n\nIn both cases, HEAD is just a pointer to the latest commit. When you do a git reset HEAD~1, you tell Git to move the HEAD pointer back one commit. But (unless you use --hard) you leave your files as they were. So now git status shows the changes you had checked into C. You haven't lost a thing!\n\noption 3: git reset --soft\n\nFor the lightest touch, you can even undo your commit but leave your files and your index:\n\ngit reset --soft HEAD~1\n\n\nThis not only leaves your files alone, it even leaves your index alone. When you do git status, you'll see that the same files are in the index as before. In fact, right after this command, you could do git commit and you'd be redoing the same commit you just had.\n\noption 4: you did git reset --hard and need to get that code back\n\nOne more thing: Suppose you destroy a commit as in the first example, but then discover you needed it after all? Tough luck, right?\n\nNope, there's still a way to get it back. Type git reflog and you'll see a list of (partial) commit shas (that is, hashes) that you've moved around in. Find the commit you destroyed, and do this:\n\ngit checkout -b someNewBranchName shaYouDestroyed\n\n\nYou've now resurrected that commit. Commits don't actually get destroyed in Git for some 90 days, so you can usually go back and rescue one you didn't mean to get rid of.\n\nShare\nImprove this answer\nFollow\nedited Jul 24 at 5:20\nanswered Jul 28 '11 at 22:22\nRyan Lundy\n189k36\n36 gold badges\n174\n174 silver badges\n206\n206 bronze badges","comments":["BEWARE! This might not do what you expect if your erroneous commit was a (fast-forward) merge! If your head is on a merge commit (ex: merged branch feature into master), git reset --hard~1 will point the master branch to the last commit inside the feature branch. In this case the specific commit ID should be used instead of the relative command.","Consider noting that the number in HEAD~1 can be substituted to any positive integer, e.g. HEAD~3. It may seem obvious, but beginners (like me) are very careful when running git commands, so they may not want to risk messing something up by testing this stuff themselves.","Missing a crucial point: If the said commit was previously 'pushed' to the remote, any 'undo' operation, no matter how simple, will cause enormous pain and suffering to the rest of the users who have this commit in their local copy, when they do a 'git pull' in the future. So, if the commit was already 'pushed', do this instead: git revert <bad-commit-sha1-id> git push origin :","@FractalSpace, it won't cause \"enormous pain and suffering.\" I've done a few force pushes when using Git with a team. All it takes is communication.","@Kyralessa In my workplace, messing up entire team's workflow and then telling them how to fix sh*t is not called 'communication'. git history re-write is a destructive operation that results in trashing of parts of the repo. Insisting on its use, while clear and safe alternatives are available is simply irresponsible."]},{"answer":"There are two ways to \"undo\" your last commit, depending on whether or not you have already made your commit public (pushed to your remote repository):\n\nHow to undo a local commit\n\nLet's say I committed locally, but now I want to remove that commit.\n\ngit log\n    commit 101: bad commit    # Latest commit. This would be called 'HEAD'.\n    commit 100: good commit   # Second to last commit. This is the one we want.\n\n\nTo restore everything back to the way it was prior to the last commit, we need to reset to the commit before HEAD:\n\ngit reset --soft HEAD^     # Use --soft if you want to keep your changes\ngit reset --hard HEAD^     # Use --hard if you don't care about keeping the changes you made\n\n\nNow git log will show that our last commit has been removed.\n\nHow to undo a public commit\n\nIf you have already made your commits public, you will want to create a new commit which will \"revert\" the changes you made in your previous commit (current HEAD).\n\ngit revert HEAD\n\n\nYour changes will now be reverted and ready for you to commit:\n\ngit commit -m 'restoring the file I removed by accident'\ngit log\n    commit 102: restoring the file I removed by accident\n    commit 101: removing a file we don't need\n    commit 100: adding a file that we need\n\n\nFor more information, check out Git Basics - Undoing Things.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jun 16 '11 at 17:27\nAndrew\n201k185\n185 gold badges\n491\n491 silver badges\n679\n679 bronze badges","comments":["I found this answer the clearest. git revert HEAD^ is not the previous, is the previous of the previous. I did : git revert HEAD and then push again and it worked :)","If Git asks you \"More?\" when you try these commands, use the alternate syntax on this answer: stackoverflow.com/a/14204318/823470","revert deleted some files I add added to my repo. Use it with caution!"]},{"answer":"Add/remove files to get things the way you want:\n\ngit rm classdir\ngit add sourcedir\n\n\nThen amend the commit:\n\ngit commit --amend\n\n\nThe previous, erroneous commit will be edited to reflect the new index state - in other words, it'll be like you never made the mistake in the first place.\n\nNote that you should only do this if you haven't pushed yet. If you have pushed, then you'll just have to commit a fix normally.\n\nShare\nImprove this answer\nFollow\nedited Oct 12 '16 at 6:45\nVikrant\n5,00016\n16 gold badges\n47\n47 silver badges\n68\n68 bronze badges\nanswered May 29 '09 at 18:16\nbdonlan\n207k28\n28 gold badges\n245\n245 silver badges\n317\n317 bronze badges","comments":["FYI: This removes all my files and I lost changes.","UPD: However, I've restored it using reflog. But the receipt did not work for the initial commit.","Use git rm --cached to keep the files in the filesystem and only delete them from the git index!"]},{"answer":"git rm yourfiles/*.class\ngit commit -a -m \"deleted all class files in folder 'yourfiles'\"\n\n\nor\n\ngit reset --hard HEAD~1\n\n\nWarning: The above command will permanently remove the modifications to the .java files (and any other files) that you wanted to commit.\n\nThe hard reset to HEAD-1 will set your working copy to the state of the commit before your wrong commit.\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '17 at 22:03\ndippas\n50k15\n15 gold badges\n95\n95 silver badges\n108\n108 bronze badges\nanswered May 29 '09 at 18:13\nLennart Koopmann\n17.9k4\n4 gold badges\n24\n24 silver badges\n32\n32 bronze badges","comments":["git commit -a -m \"\" or git commit -am \"\" naturally! :]","Another 'shortcut' use of stash; if you want to unstage everything (undo git add), just git stash, then git stash pop"]},{"answer":"To change the last commit\n\nReplace the files in the index:\n\ngit rm --cached *.class\ngit add *.java\n\n\nThen, if it's a private branch, amend the commit:\n\ngit commit --amend\n\n\nOr, if it's a shared branch, make a new commit:\n\ngit commit -m 'Replace .class files with .java files'\n\n\n\n\n(To change a previous commit, use the awesome interactive rebase.)\n\nProTip™: Add *.class to a gitignore to stop this happening again.\n\nTo revert a commit\n\nAmending a commit is the ideal solution if you need to change the last commit, but a more general solution is reset.\n\nYou can reset Git to any commit with:\n\ngit reset @~N\n\n\nWhere N is the number of commits before HEAD, and @~ resets to the previous commit.\n\nInstead of amending the commit, you could use:\n\ngit reset @~\ngit add *.java\ngit commit -m \"Add .java files\"\n\n\nCheck out git help reset, specifically the sections on --soft --mixed and --hard, for a better understanding of what this does.\n\nReflog\n\nIf you mess up, you can always use the reflog to find dropped commits:\n\n$ git reset @~\n$ git reflog\nc4f708b HEAD@{0}: reset: moving to @~\n2c52489 HEAD@{1}: commit: added some .class files\n$ git reset 2c52489\n... and you're back where you started\n\n\n\nShare\nImprove this answer\nFollow\nedited Jul 23 at 20:52\nZoe\n23.9k16\n16 gold badges\n101\n101 silver badges\n139\n139 bronze badges\nanswered Jul 31 '10 at 9:39\nZaz\n40.4k10\n10 gold badges\n71\n71 silver badges\n93\n93 bronze badges","comments":["For those reading in future - please note that git revert is a separate command - which basically 'resets' a single commimt."]},{"answer":"Use git revert <commit-id>.\n\nTo get the commit ID, just use git log.\n\nShare\nImprove this answer\nFollow\nedited Nov 21 '19 at 13:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 25 '12 at 16:04\nJaco Pretorius\n24.1k10\n10 gold badges\n57\n57 silver badges\n92\n92 bronze badges","comments":["What does that mean, cherry pick the commit? In my case, I was on the wrong branch when I edited a file. I committed it then realized I was in the wrong branch. Using \"git reset --soft HEAD~1\" got me back to just before the commit, but now if I checkout the correct branch, how do I undo the changes to the file in wrong branch but instead make them (in the same named file) in the correct branch?","I just utilized git revert commit-id worked like a charm. Of course then you will need to push your changes.","I believe that would be git cherry-pick <<erroneous-commit-sha>> @astronomerdave. From, Mr. Almost-2-Years-Late-to-the-Party.","@Kris: Instead of cherry-pick use rebase. Because it is advanced cherry-picking","I'd use revert only if I've already pushed my commit. Otherwise, reset is a better option. Don't forget that revert creates a new commit, and usually this is not the goal."]},{"answer":"If you are planning to undo a local commit entirely, whatever you change you did on the commit, and if you don't worry anything about that, just do the following command.\n\ngit reset --hard HEAD^1\n\n\n(This command will ignore your entire commit and your changes will be lost completely from your local working tree). If you want to undo your commit, but you want your changes in the staging area (before commit just like after git add) then do the following command.\n\ngit reset --soft HEAD^1\n\n\nNow your committed files come into the staging area. Suppose if you want to upstage the files, because you need to edit some wrong content, then do the following command\n\ngit reset HEAD\n\n\nNow committed files to come from the staged area into the unstaged area. Now files are ready to edit, so whatever you change, you want to go edit and added it and make a fresh/new commit.\n\nMore (link broken) (Archived version)\n\nShare\nImprove this answer\nFollow\nedited Nov 21 '20 at 14:11\nriQQ\n4,7014\n4 gold badges\n22\n22 silver badges\n36\n36 bronze badges\nanswered Jan 31 '13 at 7:06\nMadhan Ayyasamy\n13.7k3\n3 gold badges\n16\n16 silver badges\n18\n18 bronze badges","comments":["@SMR, In your example, all are pointing into current HEAD only. HEAD^ = HEAD^1. As well as HEAD^1 = HEAD~1. When you use HEAD~2, there is a difference between ~ and ^ symbols. If you use ~2 means “the first parent of the first parent,” or “the grandparent”.","git reset --hard HEAD^1 gives me this error \"fatal: ambiguous argument 'HEAD1': unknown revision or path not in the working tree.\"","What about deleting some files from the commit and keeping others?"]},{"answer":"If you have Git Extras installed, you can run git undo to undo the latest commit. git undo 3 will undo the last three commits.\n\nShare\nImprove this answer\nFollow\nedited Nov 21 '19 at 13:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 13 '11 at 10:18\nnickf\n504k196\n196 gold badges\n617\n617 silver badges\n709\n709 bronze badges","comments":[]},{"answer":"I wanted to undo the latest five commits in our shared repository. I looked up the revision id that I wanted to rollback to. Then I typed in the following.\n\nprompt> git reset --hard 5a7404742c85\nHEAD is now at 5a74047 Added one more page to catalogue\nprompt> git push origin master --force\nTotal 0 (delta 0), reused 0 (delta 0)\nremote: bb/acl: neoneye is allowed. accepted payload.\nTo git@bitbucket.org:thecompany/prometheus.git\n + 09a6480...5a74047 master -> master (forced update)\nprompt>\n\nShare\nImprove this answer\nFollow\nedited Nov 21 '19 at 13:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 6 '12 at 13:58\nneoneye\n45.1k23\n23 gold badges\n156\n156 silver badges\n145\n145 bronze badges","comments":["Rewriting history on a shared repository is generally a very bad idea. I assume you know what you're doing, I just hope future readers do too.","Yes rollback is dangerous. Make sure that your working copy is in the desired state before you push. When pushing then the unwanted commits gets deleted permanently.","\"Just like in the real world, if you want to rewrite history, you need a conspiracy: everybody has to be 'in' on the conspiracy (at least everybody who knows about the history, i.e. everybody who has ever pulled from the branch).\" Source: stackoverflow.com/a/2046748/334451"]},{"answer":"I prefer to use git rebase -i for this job, because a nice list pops up where I can choose the commits to get rid of. It might not be as direct as some other answers here, but it just feels right.\n\nChoose how many commits you want to list, then invoke like this (to enlist last three)\n\ngit rebase -i HEAD~3\n\n\nSample list\n\npick aa28ba7 Sanity check for RtmpSrv port\npick c26c541 RtmpSrv version option\npick 58d6909 Better URL decoding support\n\n\nThen Git will remove commits for any line that you remove.\n\nShare\nImprove this answer\nFollow\nedited Dec 6 '18 at 21:59\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 25 '12 at 3:41\nSteven Penny\n1","comments":["I find this really useful for undoing merges/cherry-picks from e.g. an unstable feature branch"]},{"answer":"How to fix the previous local commit\n\nUse git-gui (or similar) to perform a git commit --amend. From the GUI you can add or remove individual files from the commit. You can also modify the commit message.\n\nHow to undo the previous local commit\n\nJust reset your branch to the previous location (for example, using gitk or git rebase). Then reapply your changes from a saved copy. After garbage collection in your local repository, it will be like the unwanted commit never happened. To do all of that in a single command, use git reset HEAD~1.\n\nWord of warning: Careless use of git reset is a good way to get your working copy into a confusing state. I recommend that Git novices avoid this if they can.\n\nHow to undo a public commit\n\nPerform a reverse cherry pick (git-revert) to undo the changes.\n\nIf you haven't yet pulled other changes onto your branch, you can simply do...\n\ngit revert --no-edit HEAD\n\n\nThen push your updated branch to the shared repository.\n\nThe commit history will show both commits, separately.\n\nAdvanced: Correction of the private branch in public repository\nThis can be dangerous -- be sure you have a local copy of the branch to repush.\n\nAlso note: You don't want to do this if someone else may be working on the branch.\n\ngit push --delete (branch_name) ## remove public version of branch\n\n\nClean up your branch locally then repush...\n\ngit push origin (branch_name)\n\n\nIn the normal case, you probably needn't worry about your private-branch commit history being pristine. Just push a followup commit (see 'How to undo a public commit' above), and later, do a squash-merge to hide the history.\n\nShare\nImprove this answer\nFollow\nedited Dec 7 '18 at 5:57\ncommunity wiki\n\n\n12 revs, 4 users 76%\nnobar","comments":["gitk --all $(git reflog | cut -c1-7)& may be helpful for finding the previous revision if you want to undo an '--amend' commit.","It should be noted that if you're attempting to remove secret information before pushing to a shared repository, doing a revert won't help you, because the information will still be in the history in the previous commit. If you want to ensure the change is never visible to others you need to use git reset","I think 'private'/'public' would more correctly be 'local'/'remote'.","Correcting a private branch in remote repository can also be done by simply git push origin (branch_name) --force"]},{"answer":"If you want to permanently undo it and you have cloned some repository.\n\nThe commit id can be seen by:\n\ngit log \n\n\nThen you can do like:\n\ngit reset --hard <commit_id>\n\ngit push origin <branch_name> -f\n\nShare\nImprove this answer\nFollow\nedited Apr 10 at 9:04\ncommunity wiki\n\n\n3 revs, 3 users 85%\npoorva","comments":["What if you do not use \"<commit_id>\" and simply use \"git reset --hard\"? I typically just want to get rid of my latest updates that I have not committed yet and got back to the latest commit I made, and I always use \"git reset --hard\".","@JaimeMontoya To undo latest changes you can use git reset --hard , but if you have to hard remove last \"n\" commits you specify a SHA"]},{"answer":"If you have committed junk but not pushed,\n\ngit reset --soft HEAD~1\n\n\nHEAD~1 is a shorthand for the commit before head. Alternatively you can refer to the SHA-1 of the hash if you want to reset to. --soft option will delete the commit but it will leave all your changed files \"Changes to be committed\", as git status would put it.\n\nIf you want to get rid of any changes to tracked files in the working tree since the commit before head use \"--hard\" instead.\n\nOR\n\nIf you already pushed and someone pulled which is usually my case, you can't use git reset. You can however do a git revert,\n\ngit revert HEAD\n\n\nThis will create a new commit that reverses everything introduced by the accidental commit.\n\nShare\nImprove this answer\nFollow\nedited Sep 25 '14 at 7:58\ncommunity wiki\n\n\n2 revs, 2 users 87%\nsantos_mgr","comments":["I'm in the 2nd case, but when I do \"git revert HEAD\" it says \"error: Commit [ID] is a merge but no -m option was given. fatal: revert failed\". Any suggestions?","Probably worth mentioning that instead of HEAD~1 you could use the actual hash as displayed by git log --stat or by git reflog - useful when you need to 'undo' more than one commit."]},{"answer":"On SourceTree (GUI for GitHub), you may right-click the commit and do a 'Reverse Commit'. This should undo your changes.\n\nOn the terminal:\n\nYou may alternatively use:\n\ngit revert\n\n\nOr:\n\ngit reset --soft HEAD^ # Use --soft if you want to keep your changes.\ngit reset --hard HEAD^ # Use --hard if you don't care about keeping your changes.\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '15 at 9:34\ncommunity wiki\n\n\n5 revs, 5 users 56%\nVarun Parakh","comments":[]},{"answer":"A single command:\n\ngit reset --soft 'HEAD^' \n\n\nIt works great to undo the last local commit!\n\nShare\nImprove this answer\nFollow\nedited Jul 21 '14 at 20:13\ncommunity wiki\n\n\n3 revs, 3 users 67%\nManish Shrivastava","comments":["I needed to write git reset --soft \"HEAD^\" with double quotes, because I write it from Windows command prompt."]},{"answer":"Just reset it doing the command below using git:\n\ngit reset --soft HEAD~1\n\n\nExplain: what git reset does, it's basically reset to any commit you'd like to go back to, then if you combine it with --soft key, it will go back, but keep the changes in your file(s), so you get back to the stage which the file was just added, HEAD is the head of the branch and if you combine with ~1 (in this case you also use HEAD^), it will go back only one commit which what you want...\n\nI create the steps in the image below in more details for you, including all steps that may happens in real situations and committing the code:\n\nShare\nImprove this answer\nFollow\nedited Oct 27 '17 at 12:46\ncommunity wiki\n\n\n17 revs\nAlireza","comments":[]},{"answer":"How to undo the last Git commit?\n\nTo restore everything back to the way it was prior to the last commit, we need to reset to the commit before HEAD.\n\nIf you don't want to keep your changes that you made:\n\ngit reset --hard HEAD^\n\n\nIf you want to keep your changes:\n\ngit reset --soft HEAD^\n\n\nNow check your git log. It will show that our last commit has been removed.\n\nShare\nImprove this answer\nFollow\nedited Mar 25 '17 at 8:14\ncommunity wiki\n\n\n3 revs, 3 users 74%\nRanjithkumar Ravi","comments":[]},{"answer":"\"Reset the working tree to the last commit\"\n\ngit reset --hard HEAD^ \n\n\n\"Clean unknown files from the working tree\"\n\ngit clean    \n\n\nsee - Git Quick Reference\n\nNOTE: This command will delete your previous commit, so use with caution! git reset --hard is safer.\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '19 at 16:39\ncommunity wiki\n\n\n6 revs, 5 users 77%\nRavi_Parmar","comments":[]},{"answer":"Use reflog to find a correct state\n\ngit reflog\n\n\n REFLOG BEFORE RESET\n\nSelect the correct reflog (f3cb6e2 in my case) and type\n\ngit reset --hard f3cb6e2\n\n\nAfter that the repo HEAD will be reset to that HEADid  LOG AFTER RESET\n\nFinally the reflog looks like the picture below\n\n REFLOG FINAL\n\nShare\nImprove this answer\nFollow\nanswered Jan 6 '14 at 22:34\ncommunity wiki\n\n\nShubham Chaudhary","comments":[]},{"answer":"First run:\n\ngit reflog\n\n\nIt will show you all the possible actions you have performed on your repository, for example, commit, merge, pull, etc.\n\nThen do:\n\ngit reset --hard ActionIdFromRefLog\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '15 at 9:33\ncommunity wiki\n\n\n4 revs, 4 users 70%\nU. Ali","comments":[]},{"answer":"Undo last commit:\n\ngit reset --soft HEAD^ or git reset --soft HEAD~\n\nThis will undo the last commit.\n\nHere --soft means reset into staging.\n\nHEAD~ or HEAD^ means to move to commit before HEAD.\n\nReplace last commit to new commit:\ngit commit --amend -m \"message\"\n\n\nIt will replace the last commit with the new commit.\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '17 at 22:05\ncommunity wiki\n\n\n4 revs, 3 users 81%\nakshay_rahar","comments":[]},{"answer":"Another way:\n\nCheckout the branch you want to revert, then reset your local working copy back to the commit that you want to be the latest one on the remote server (everything after it will go bye-bye). To do this, in SourceTree I right-clicked on the and selected \"Reset BRANCHNAME to this commit\".\n\nThen navigate to your repository's local directory and run this command:\n\ngit -c diff.mnemonicprefix=false -c core.quotepath=false push -v -f --tags REPOSITORY_NAME BRANCHNAME:BRANCHNAME\n\n\nThis will erase all commits after the current one in your local repository but only for that one branch.\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '15 at 9:34\ncommunity wiki\n\n\n3 revs, 3 users 90%\nCommaToast","comments":[]},{"answer":"Type git log and find the last commit hash code and then enter:\n\ngit reset <the previous co>\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '15 at 9:34\ncommunity wiki\n\n\n3 revs, 3 users 56%\nPeter Mortensen","comments":[]},{"answer":"In my case I accidentally committed some files I did not want to. So I did the following and it worked:\n\ngit reset --soft HEAD^\ngit rm --cached [files you do not need]\ngit add [files you need]\ngit commit -c ORIG_HEAD\n\n\nVerify the results with gitk or git log --stat\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '15 at 9:34\ncommunity wiki\n\n\n2 revs, 2 users 93%\negridasov","comments":[]},{"answer":"Simple, run this in your command line:\n\ngit reset --soft HEAD~ \n\nShare\nImprove this answer\nFollow\nedited Jan 18 '16 at 21:58\ncommunity wiki\n\n\n2 revs, 2 users 80%\nihue","comments":[]},{"answer":"There are two main scenarios\n\nYou haven't pushed the commit yet\n\nIf the problem was extra files you commited (and you don't want those on repository), you can remove them using git rm and then commiting with --amend\n\ngit rm <pathToFile>\n\n\nYou can also remove entire directories with -r, or even combine with other Bash commands\n\ngit rm -r <pathToDirectory>\ngit rm $(find -name '*.class')\n\n\nAfter removing the files, you can commit, with --amend option\n\ngit commit --amend -C HEAD # the -C option is to use the same commit message\n\n\nThis will rewrite your recent local commit removing the extra files, so, these files will never be sent on push and also will be removed from your local .git repository by GC.\n\nYou already pushed the commit\n\nYou can apply the same solution of the other scenario and then doing git push with the -f option, but it is not recommended since it overwrites the remote history with a divergent change (it can mess your repository).\n\nInstead, you have to do the commit without --amend (remember this about -amend`: That option rewrites the history on the last commit).\n\nShare\nImprove this answer\nFollow\nedited Jan 11 '16 at 23:50\ncommunity wiki\n\n\n3 revs, 3 users 86%\ndseminara","comments":[]},{"answer":"For a local commit\ngit reset --soft HEAD~1\n\n\nor if you do not remember exactly in which commit it is, you might use\n\ngit rm --cached <file>\n\nFor a pushed commit\n\nThe proper way of removing files from the repository history is using git filter-branch. That is,\n\ngit filter-branch --index-filter 'git rm --cached <file>' HEAD\n\n\nBut I recomnend you use this command with care. Read more at git-filter-branch(1) Manual Page.\n\nShare\nImprove this answer\nFollow\nedited Jul 21 '14 at 20:15\ncommunity wiki\n\n\n3 revs, 3 users 64%\ngeoom","comments":[]},{"answer":"To reset to the previous revision, permanently deleting all uncommitted changes:\n\ngit reset --hard HEAD~1\n\nShare\nImprove this answer\nFollow\nedited Sep 16 '16 at 7:25\ncommunity wiki\n\n\n2 revs, 2 users 80%\nthestar","comments":["Maybe you could at a note/warning that his command will throw away the commit and the changes in the working directory without asking any further.","If you happen to do this by accident, not all is lost, though. See stackoverflow.com/questions/10099258/…, stackoverflow.com/questions/15479501/… and stackoverflow.com/questions/7374069/undo-git-reset-hard/7376959.","Use --soft to keep your changes as uncommitted changes, --hard to nuke the commit completely and revert back by one. Remember to do such operations only on changes, that are not pushed yet.","@Zaz: You are right; maybe I should have clarified that. Only files/changes that have been either added to index (/staged) or have been committed can possibly be recovered. Uncommitted, unstaged changes are, as you said, completely thrown away by git reset --hard.","As a sidenote: Everytime a file is staged, git stores its contents in its object database. The stored contents are only removed when garbage collection is executed. It is therefore possible to recover the last staged version of a file that was not currently staged when git reset --hard was executed (see the posts linked above for more information)."]},{"answer":"There are many ways to do it:\n\nGit command to undo the last commit/ previous commits:\n\nWarning: Do Not use --hard if you do not know what you are doing. --hard is too dangerous, and it might delete your files.\n\nBasic command to revert the commit in Git is:\n\n$ git reset --hard <COMMIT -ID>\n\n\nor\n\n$ git reset --hard HEAD~<n>\n\n\nCOMMIT-ID: ID for the commit\n\nn: is number of last commits you want to revert\n\nYou can get the commit id as shown below:\n\n$ **git log --oneline**\n\nd81d3f1 function to subtract two numbers\n\nbe20eb8 function to add two numbers\n\nbedgfgg function to mulitply two numbers\n\n\nwhere d81d3f1 and be20eb8 are commit id.\n\nNow let's see some cases:\n\nSuppose you want to revert the last commit 'd81d3f1'. Here are two options:\n\n$ git reset --hard d81d3f1\n\n\nor\n\n$ git reset --hard HEAD~1\n\n\nSuppose you want to revert the commit 'be20eb8':\n\n$ git reset --hard be20eb8\n\n\nFor more detailed information you can refer and try out some other commands too for resetting head to a specified state:\n\n$ git reset --help\n\nShare\nImprove this answer\nFollow\nedited Aug 19 '18 at 14:00\ncommunity wiki\n\n\n5 revs, 5 users 86%\nuser3799762","comments":["git reset --hard HEAD~1 is too dangerous! This will not just 'cancel last commit', but will revert repo completely back to the previous commit. So you will LOOSE all changes committed in the last commit!","You right, to undo this you can use git push -f <remote> HEAD@{1}:<branch>","Unfortunately, I use --hard, and my files are deleted! I did not check the comment first because it is collapsed. Do not use --hard if you do not know what you are doing!"]}]},{"id":"2003505","href":"https://stackoverflow.com/questions/2003505/how-do-i-delete-a-git-branch-locally-and-remotely","title":"How do I delete a Git branch locally and remotely?","description":"\n                \nI want to delete a branch both locally and remotely.\nFailed Attempts to Delete a Remote Branch\n$ git branch -d remotes/origin/bugfix\nerror: branch 'remotes/origin/bugfix' not found.\n\n$ git branch -d origin/bugfix\nerror: branch 'origin/bugfix' not found.\n\n$ git branch -rd origin/bugfix\nDeleted remote branch origin/bugfix (was 2a14ef7).\n\n$ git push\nEverything up-to-date\n\n$ git pull\nFrom github.com:gituser/gitproject\n\n* [new branch] bugfix -> origin/bugfix\nAlready up-to-date.\n\nWhat should I do differently to successfully delete the remotes/origin/bugfix branch both locally and remotely?\n    ","questionComments":["Moderator note: If you intend to answer this question, do note that there are already 40 answers posted. Will your new answer add any substantial value?","Note: for Git 2.5+ (Q2 2015), the exact message will be \"deleted remote-tracking branch\": see github.com/git/git/commit/…","Skip the first few answers and just jump down to the best one: stackoverflow.com/a/23961231/4561887. To delete a git branch, there are actually 3 different branches to delete! This answer makes that fact clear.","@GabrielStaples Without context, your comment is confusing. Are the \"best\" rated answers wrong somehow?","@Nathan, no, they're not wrong, but they don't teach what you don't know you don't know, whereas the one I link to makes this critical unknown unknown become a known unknown and then a known known. I didn't know you had a 1) local branch, 2) locally-stored remote-tracking branch, and 3) remote branch until I read that answer. Prior to that I thought there was only a local branch and remote branch. The locally-stored remote-tracking branch was an unknown unknown. Making it go from that to a known known is what makes that answer the best."],"answers":[{"answer":"Executive Summary\n$ git push -d <remote_name> <branch_name>\n$ git branch -d <branch_name>\n\n\nNote that in most cases the remote name is origin. In such a case you'll have to use the command like so.\n\n$ git push -d origin <branch_name>\n\nDelete Local Branch\n\nTo delete the local branch use one of the following:\n\n$ git branch -d branch_name\n$ git branch -D branch_name\n\n\nNote: The -d option is an alias for --delete, which only deletes the branch if it has already been fully merged in its upstream branch. You could also use -D, which is an alias for --delete --force, which deletes the branch \"irrespective of its merged status.\" [Source: man git-branch]\nAlso note that git branch -d branch_name will fail if you are currently in the branch you want to remove. The message starts with error: Cannot delete the branch 'branch_name'. If so, first switch to some other branch, for example: git checkout main.\n\nDelete Remote Branch [Updated on 8-Sep-2017]\n\nAs of Git v1.7.0, you can delete a remote branch using\n\n$ git push <remote_name> --delete <branch_name>\n\n\nwhich might be easier to remember than\n\n$ git push <remote_name> :<branch_name>\n\n\nwhich was added in Git v1.5.0 \"to delete a remote branch or a tag.\"\n\nStarting on Git v2.8.0 you can also use git push with the -d option as an alias for --delete.\n\nTherefore, the version of Git you have installed will dictate whether you need to use the easier or harder syntax.\n\nDelete Remote Branch [Original Answer from 5-Jan-2010]\n\nFrom Chapter 3 of Pro Git by Scott Chacon:\n\nDeleting Remote Branches\n\nSuppose you’re done with a remote branch — say, you and your collaborators are finished with a feature and have merged it into your remote’s main branch (or whatever branch your stable code-line is in). You can delete a remote branch using the rather obtuse syntax git push [remotename] :[branch]. If you want to delete your server-fix branch from the server, you run the following:\n\n$ git push origin :serverfix\nTo git@github.com:schacon/simplegit.git\n - [deleted]         serverfix\n\n\nBoom. No more branches on your server. You may want to dog-ear this page, because you’ll need that command, and you’ll likely forget the syntax. A way to remember this command is by recalling the git push [remotename] [localbranch]:[remotebranch] syntax that we went over a bit earlier. If you leave off the [localbranch] portion, then you’re basically saying, “Take nothing on my side and make it be [remotebranch].”\n\nI issued git push origin: bugfix and it worked beautifully. Scott Chacon was right—I will want to dog ear that page (or virtually dog ear by answering this on Stack Overflow).\n\nThen you should execute this on other machines\n\n# Fetch changes from all remotes and locally delete \n# remote deleted branches/tags etc\n# --prune will do the job :-;\ngit fetch --all --prune\n\n\nto propagate changes.\n\nShare\nImprove this answer\nFollow\nedited May 6 at 8:38\nJunaid\n3,4921\n1 gold badge\n24\n24 silver badges\n31\n31 bronze badges\nanswered Jan 5 '10 at 1:13\nMatthew Rankin\n407k38\n38 gold badges\n116\n116 silver badges\n157\n157 bronze badges","comments":["Don't forget to do a git fetch --all --prune on other machines after deleting the remote branch on the server. ||| After deleting the local branch with git branch -d and deleting the remote branch with git push origin --delete other machines may still have \"obsolete tracking branches\" (to see them do git branch -a). To get rid of these do git fetch --all --prune.","in addition to @TrevorBoydSmith's git branch -a to view all branches, you can also use git branch -r to view remote branches only. see also git remote show origin - source: gitready.com/intermediate/2009/02/13/list-remote-branches.html","I had to run git branch -D Branch_Name to get rid of the local branch","@KolobCanyon You only have to use -D if the branch has not been merged into another branch.","The question was \"What do I need to do differently to successfully delete the remotes/origin/bugfix branch both locally and on GitHub?\" After running the commands in your updated answer, the local branch is still present. It would be nice if the accepted answer was a complete answer. Its absolutely amazing at how difficult Git makes simple tasks..."]},{"answer":"Matthew's answer is great for removing remote branches and I also appreciate the explanation, but to make a simple distinction between the two commands:\n\nTo remove a local branch from your machine:\n\ngit branch -d {the_local_branch} (use -D instead to force deleting the branch without checking merged status)\n\nTo remove a remote branch from the server:\n\ngit push origin --delete {the_remote_branch}\n\nReference: Git: Delete a branch (local or remote)\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:08\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 12 '12 at 14:51\nEric Brotto\n49.7k29\n29 gold badges\n124\n124 silver badges\n171\n171 bronze badges","comments":["@megido well -D force deletes, -d gives you a warning if it's not already merged in.","If your local branch is not merge with master and ran 'git branch -d your_branch then you will error like error: The branch 'your_branch' is not fully merged. If you are sure you want to delete it, run 'git branch -D your_branch'.","I would suggest using -d instead of -D because it is safer. If -d fails due to unmerged commits then you need to assess that and if it is definitely OK to remove then use -D.","Others with repository clones where remote branches have been removed should run git remote prune <name> (e.g. git remote prune origin) in order to locally remove stale branches that no longer exist in the remote.","I would like to add that -d gives a warning if it isn't merged in with the current HEAD. If you need clarity I recommend this command git branch -a --merged origin/master It will list any branches, both local and remote; that have been merged into master. Additional information here"]},{"answer":"The short answers\n\nIf you want more detailed explanations of the following commands, then see the long answers in the next section.\n\nDeleting a remote branch\ngit push origin --delete <branch>  # Git version 1.7.0 or newer\ngit push origin -d <branch>        # Shorter version (Git 1.7.0 or newer)\ngit push origin :<branch>          # Git versions older than 1.7.0\n\nDeleting a local branch\ngit branch --delete <branch>\ngit branch -d <branch> # Shorter version\ngit branch -D <branch> # Force-delete un-merged branches\n\nDeleting a local remote-tracking branch\ngit branch --delete --remotes <remote>/<branch>\ngit branch -dr <remote>/<branch> # Shorter\n\ngit fetch <remote> --prune # Delete multiple obsolete remote-tracking branches\ngit fetch <remote> -p      # Shorter\n\nThe long answer: there are three different branches to delete!\n\nWhen you're dealing with deleting branches both locally and remotely, keep in mind that there are three different branches involved:\n\nThe local branch X.\nThe remote origin branch X.\nThe local remote-tracking branch origin/X that tracks the remote branch X.\n\nThe original poster used:\n\ngit branch -rd origin/bugfix\n\n\nWhich only deleted his local remote-tracking branch origin/bugfix, and not the actual remote branch bugfix on origin.\n\nTo delete that actual remote branch, you need\n\ngit push origin --delete bugfix\n\n\nAdditional details\n\nThe following sections describe additional details to consider when deleting your remote and remote-tracking branches.\n\nPushing to delete remote branches also removes remote-tracking branches\n\nNote that deleting the remote branch X from the command line using a git push will also remove the local remote-tracking branch origin/X, so it is not necessary to prune the obsolete remote-tracking branch with git fetch --prune or git fetch -p. However, it wouldn't hurt if you did it anyway.\n\nYou can verify that the remote-tracking branch origin/X was also deleted by running the following:\n\n# View just remote-tracking branches\ngit branch --remotes\ngit branch -r\n\n# View both strictly local as well as remote-tracking branches\ngit branch --all\ngit branch -a\n\nPruning the obsolete local remote-tracking branch origin/X\n\nIf you didn't delete your remote branch X from the command line (like above), then your local repository will still contain (a now obsolete) remote-tracking branch origin/X. This can happen if you deleted a remote branch directly through GitHub's web interface, for example.\n\nA typical way to remove these obsolete remote-tracking branches (since Git version 1.6.6) is to simply run git fetch with the --prune or shorter -p. Note that this removes all obsolete local remote-tracking branches for any remote branches that no longer exist on the remote:\n\ngit fetch origin --prune\ngit fetch origin -p # Shorter\n\n\nHere is the relevant quote from the 1.6.6 release notes (emphasis mine):\n\n\"git fetch\" learned --all and --multipleoptions, to run fetch from many repositories, and --prune option to remove remote tracking branches that went stale. These make \"git remote update\" and \"git remote prune\" less necessary (there is no plan to remove \"remote update\" nor \"remote prune\", though).\n\nAlternative to above automatic pruning for obsolete remote-tracking branches\n\nAlternatively, instead of pruning your obsolete local remote-tracking branches through git fetch -p, you can avoid making the extra network operation by just manually removing the branch(es) with the --remote or -r flags:\n\ngit branch --delete --remotes origin/X\ngit branch -dr origin/X # Shorter\n\nSee Also\ngit-branch(1) Manual Page.\ngit-fetch(1) Manual Page.\nPro Git § 3.5 Git Branching - Remote Branches.\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 30 '14 at 18:32\nuser456814","comments":["From your illustration, I can see there are local clone repo and remote origin repo. So there are at least two physical branches. Where is the third branch to delete? Is the third branch only a pointer pointing to a commit in the local clone repo?","@huggie that's pretty much correct. Branches in Git are just bookmarks attached to commits. So in my graphs above, there are X and origin/X bookmarks in the local clone (2 branches), and then there is X on the remote (making 3 branches).","+1 for the remote tracking branch. This branch is what causes issues when you clone someone else's branch. It keeps on tracking your commits and asking you if you want to push to that person's branch.","For the sake of future readers: What @Kermit_ice_tea is talking about above is a local branch (as described in this answer), not a remote-tracking branch. When a local branch has an \"upstream branch\" configured for it, it will by default pull from and push to that remote branch. A local branch that has an \"upstream branch\" set on it is referred to as a \"tracking branch\", so it's easy to confuse with remote-tracking branches due to the similar terminology.","I've read all the answers down to here and this is for sure the best answer I've read so far!--(and probably the best one on this page, period). This is especially true because it's the only answer which states this REALLY IMPORTANT fact that I never knew before: \"there are 3 different branches to delete!\" I had no idea! This all makes so much more sense now, and it sheds so much light on all the other answers here now too. Thanks!"]},{"answer":"Steps for deleting a branch:\n\nFor deleting the remote branch:\n\ngit push origin --delete <your_branch>\n\n\nFor deleting the local branch, you have three ways:\n\n1: git branch -D <branch_name>\n\n2: git branch --delete --force <branch_name>  # Same as -D\n\n3: git branch --delete  <branch_name>         # Error on unmerge\n\n\nExplain: OK, just explain what's going on here!\n\nSimply do git push origin --delete to delete your remote branch only, add the name of the branch at the end and this will delete and push it to remote at the same time...\n\nAlso, git branch -D, which simply delete the local branch only!...\n\n-D stands for --delete --force which will delete the branch even it's not merged (force delete), but you can also use -d which stands for --delete which throw an error respective of the branch merge status...\n\nI also create the image below to show the steps:\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:59\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 27 '17 at 13:13\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":["git branch -a will display local and remote branches.It will be help for you diagram introduce.","note that if you are setting on the branch you want to delete, you need to checkout a branch other than the one you need to delete (eg: master) before deleting the local branch.","When branches get deleted on origin, your local repository won't take notice of that. You'll still have your locally cached versions of those branches (which is actually good) but git branch -a will still list them as remote branches. You can clean up that information locally like this: git remote prune origin Your local copies of deleted branches are not removed by this. The same effect is achieved by using git fetch --prune","The image is distracting and very large and adds nothing to the answer. I hope this does not become a trend on SO."]},{"answer":"You can also use the following to delete the remote branch\n\ngit push --delete origin serverfix\n\n\nWhich does the same thing as\n\ngit push origin :serverfix\n\n\nbut it may be easier to remember.\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '18 at 4:44\nAnant Kumar Singh\n66.8k10\n10 gold badges\n46\n46 silver badges\n86\n86 bronze badges\nanswered Oct 27 '11 at 22:22\npagetribe\n14.2k3\n3 gold badges\n22\n22 silver badges\n18\n18 bronze badges","comments":["...and safer to use :O","You forgot the part about deleting the local branch which can be done by: git branch -d <local_branch> or git branch -D <local_branch> for force deleting"]},{"answer":"Tip: When you delete branches using\n\ngit branch -d <branchname> # Deletes local branch\n\n\nor\n\ngit push origin :<branchname> # Deletes remote branch\n\n\nonly the references are deleted. Even though the branch is actually removed on the remote, the references to it still exists in the local repositories of your team members. This means that for other team members the deleted branches are still visible when they do a git branch -a.\n\nTo solve this, your team members can prune the deleted branches with\n\ngit remote prune <repository>\n\n\nThis is typically git remote prune origin.\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 7 '12 at 13:02\npfrenssen\n5,1601\n1 gold badge\n19\n19 silver badges\n15\n15 bronze badges","comments":["You should clarify that the above git push operation deletes the local branch and the remote branch.","Note that git remote prune is a somewhat obsolete way to remove obsolete remote-tracking branches, the newer way to do it is to use git fetch --prune or git fetch -p.","@RRMadhav, indeed you won't see the deleted branch after deleting it since the reference to the remote branch will be removed for you locally. Anyone else on your team that has checked out that branch will still have that reference and will still see it unless they prune the branch."]},{"answer":"It's very simple:\n\nTo delete the remote branch\n\ngit push -d origin <branch-name>\n\n\nOr\n\ngit push origin :<branch-name>\n\n\n-- You can also delete tags with this syntax\n\nTo forcefully delete local branch\n\ngit branch -D <branch-name>\n\n\nNote: do a git fetch --all --prune on other machines after deleting remote branch, to remove obsolete tracking branches.\n\nExample\n\nto remove local branch\n\ngit branch -D my-local-branch\n\n\nto remove remote branch\n\ngit push origin :my-remote-branch\n\n\nHappy Coding :)\n\nShare\nImprove this answer\nFollow\nedited Jul 5 at 4:26\nanswered Dec 7 '17 at 13:29\nVivek Maru\n5,1651\n1 gold badge\n16\n16 silver badges\n27\n27 bronze badges","comments":["I needed to use --delete instead of -d to delete remote branch.","-d option is an alias for --delete and if --delete work then -d should also work, if you forcefully want to delete a branch you can use -D instead of -d or --delete."]},{"answer":"If you want to delete a branch, first checkout to the branch other than the branch to be deleted.\n\ngit checkout other_than_branch_to_be_deleted\n\n\nDeleting the local branch:\n\ngit branch -D branch_to_be_deleted\n\n\nDeleting the remote branch:\n\ngit push origin --delete branch_to_be_deleted\n\nShare\nImprove this answer\nFollow\nedited Jun 9 '15 at 2:04\nWillem Van Onsem\n339k27\n27 gold badges\n310\n310 silver badges\n423\n423 bronze badges\nanswered Oct 7 '14 at 13:52\nPraveen Hiremath\n4,0392\n2 gold badges\n15\n15 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"git branch -D <name-of-branch>\ngit branch -D -r origin/<name-of-branch>\ngit push origin :<name-of-branch>\n\nShare\nImprove this answer\nFollow\nedited Aug 8 '14 at 20:04\nanswered Oct 24 '13 at 17:36\nFelipe\n15.7k9\n9 gold badges\n63\n63 silver badges\n87\n87 bronze badges","comments":["Note that -D forces the deletion. It's always better to use -d, which will remind if you need to do something dangerous.","ahahah :) it's up to you: use -d if you want to see git crying or -D if you want to cry."]},{"answer":"This is simple: Just run the following command:\n\nTo delete a Git branch both locally and remotely, first delete the local branch using this command:\n\ngit branch -d example\n\n\n(Here example is the branch name.)\n\nAnd after that, delete the remote branch using this command:\n\ngit push origin :example\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 15 '15 at 15:20\nSyeful Islam\n3,4731\n1 gold badge\n17\n17 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"Another approach is:\n\ngit push --prune origin\n\n\nWARNING: This will delete all remote branches that do not exist locally. Or more comprehensively,\n\ngit push --mirror\n\n\nwill effectively make the remote repository look like the local copy of the repository (local heads, remotes and tags are mirrored on remote).\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 18 '12 at 6:11\nimanuelcostigan\n3,1393\n3 gold badges\n15\n15 silver badges\n18\n18 bronze badges","comments":["git push --prune origin didn't do anything for me on gitlab: git clone git://repo.git; git branch -d -r origin/some-branches; git push --prune origin; yields: Everything up-to-date; git fetch; brings locally deleted branches back; git push --mirror; now they are really gone!"]},{"answer":"I use the following in my Bash settings:\n\nalias git-shoot=\"git push origin --delete\"\n\n\nThen you can call:\n\ngit-shoot branchname\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '18 at 4:43\nAnant Kumar Singh\n66.8k10\n10 gold badges\n46\n46 silver badges\n86\n86 bronze badges\nanswered Apr 2 '13 at 22:11\ncrizCraig\n7,2894\n4 gold badges\n47\n47 silver badges\n51\n51 bronze badges","comments":["I ended up just add the alias \"shoot\" into my .gitconfig shoot = push origin --delete","If your origin is a Atlassian Stash and the branch is set as the default, you will get an error \"By default, deleting the current branch is denied...\". I had to change the default branch in Stash to point to another branch before I could delete.","This is perfectly simple as you've done it, but fyi git also lets you make custom commands. Put git push origin --delete $1 in a file on your path called git-shoot and git shoot branchname will work too.","this is a good solution"]},{"answer":"Delete locally:\n\nTo delete a local branch, you can use:\n\ngit branch -d <branch_name>\n\n\nTo delete a branch forcibly, use -D instead of -d.\n\ngit branch -D <branch_name>\n\n\nDelete remotely:\n\nThere are two options:\n\ngit push origin :branchname\n\ngit push origin --delete branchname\n\n\nI would suggest you use the second way as it is more intuitive.\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 23 '15 at 8:56\nRahul Gupta\n40.6k10\n10 gold badges\n93\n93 silver badges\n110\n110 bronze badges","comments":[]},{"answer":"If you want to complete both these steps with a single command, you can make an alias for it by adding the below to your ~/.gitconfig:\n\n[alias]\n    rmbranch = \"!f(){ git branch -d ${1} && git push origin --delete ${1}; };f\"\n\n\nAlternatively, you can add this to your global configuration from the command line using\n\ngit config --global alias.rmbranch \\\n'!f(){ git branch -d ${1} && git push origin --delete ${1}; };f'\n\n\nNOTE: If using -d (lowercase d), the branch will only be deleted if it has been merged. To force the delete to happen, you will need to use -D (uppercase D).\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 15 '13 at 19:05\nRyan Kohn\n12k10\n10 gold badges\n51\n51 silver badges\n80\n80 bronze badges","comments":["This is what I was looking for. My own shell function alias didn't work (Unexpected EOF) and I couldn't figure out why, but this works great! The only change I made was replacing && with ; so that even if the first command fails the second will still execute (sometimes only local or only remote exists)."]},{"answer":"Since January 2013, GitHub included a Delete branch button next to each branch in your \"Branches\" page.\n\nRelevant blog post: Create and delete branches\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '18 at 4:42\nAnant Kumar Singh\n66.8k10\n10 gold badges\n46\n46 silver badges\n86\n86 bronze badges\nanswered Apr 29 '13 at 10:39\nNacho Coloma\n6,1052\n2 gold badges\n36\n36 silver badges\n42\n42 bronze badges","comments":["I only started using Github this year, so I was wondering why this was such a highly rated question, and why none of the top answers were suggesting to just delete it from the Github web interface! Interesting that it's only a recent addition.","I was going to point this one out. Note that the button won't delete your local branch... see this answer for how to do that: stackoverflow.com/a/10999165/901641"]},{"answer":"To delete your branch locally and remotely\n\nCheckout to master branch - git checkout master\n\nDelete your remote branch - git push origin --delete <branch-name>\n\nDelete your local branch - git branch --delete <branch-name>\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '17 at 22:10\ndippas\n50k15\n15 gold badges\n95\n95 silver badges\n108\n108 bronze badges\nanswered Jan 3 '16 at 21:08\nmfathy00\n1,5311\n1 gold badge\n11\n11 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"You can also do this using git remote prune origin\n\n$ git remote prune origin\nPruning origin\nURL: git@example.com/yourrepo.git\n * [pruned] origin/some-branchs\n\n\nIt prunes and deletes remote-tracking branches from a git branch -r listing.\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '18 at 4:43\nAnant Kumar Singh\n66.8k10\n10 gold badges\n46\n46 silver badges\n86\n86 bronze badges\nanswered Mar 12 '13 at 14:57\nnickleefly\n3,5731\n1 gold badge\n24\n24 silver badges\n31\n31 bronze badges","comments":[]},{"answer":"In addition to the other answers, I often use the git_remote_branch tool. It's an extra install, but it gets you a convenient way to interact with remote branches. In this case, to delete:\n\ngrb delete branch\n\n\nI find that I also use the publish and track commands quite often.\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:07\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 24 '12 at 2:21\nu2622\n2,9013\n3 gold badges\n22\n22 silver badges\n26\n26 bronze badges","comments":["this is a good solution"]},{"answer":"A one-liner command to delete both local, and remote:\n\nD=branch-name; git branch -D $D; git push origin :$D\n\n\nOr add the alias below to your ~/.gitconfig. Usage: git kill branch-name\n\n[alias]\n    kill = \"!f(){ git branch -D \\\"$1\\\";  git push origin --delete \\\"$1\\\"; };f\"\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 17 '16 at 1:03\nVinnie James\n4,9575\n5 gold badges\n36\n36 silver badges\n47\n47 bronze badges","comments":["⚠️ Use git branch -D carefully in a script, since it force-deletes a branch without checking it has been merged. Use -d to be safe."]},{"answer":"Deleting Branches\n\nLet's assume our work on branch \"contact-form\" is done and we've already integrated it into \"master\". Since we don't need it anymore, we can delete it (locally):\n\n$ git branch -d contact-form\n\n\nAnd for deleting the remote branch:\n\ngit push origin --delete contact-form\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Oct 30 '15 at 12:39\nUlysses Alves\n1,9901\n1 gold badge\n19\n19 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"Delete remote branch\n\ngit push origin :<branchname>\n\nDelete local branch\n\ngit branch -D <branchname>\n\nDelete local branch steps:\n\ncheckout to another branch\ndelete local branch\nShare\nImprove this answer\nFollow\nedited Feb 19 '16 at 18:05\nanswered Dec 31 '15 at 9:22\njayxhj\n2,17417\n17 silver badges\n22\n22 bronze badges","comments":["Does the remote branch deletion requires \"git push\" afterwards ?","@SamithaChathuranga no, git push origin :<branchname> already pushes an 'empty` branch to the remote (hence deletes the remote branch)"]},{"answer":"Simply say:\n\ngit branch -d <branch-name>\ngit push origin :<branch-name>\n\nShare\nImprove this answer\nFollow\nedited Jun 25 '16 at 12:52\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 23 '15 at 18:06\npiyushmandovra\n3,7232\n2 gold badges\n17\n17 silver badges\n29\n29 bronze badges","comments":["This works if its your own branch. But if you are pruning all unneeded branches in the repo (some of which aren't yours) it wouldn't suffice"]},{"answer":"To delete locally - (normal)\n\ngit branch -d my_branch\n\n\nIf your branch is in a rebasing/merging progress and that was not done properly, it means you will get an error, Rebase/Merge in progress, so in that case, you won't be able to delete your branch.\n\nSo either you need to solve the rebasing/merging. Otherwise, you can do force delete by using,\n\ngit branch -D my_branch\n\n\nTo delete in remote:\n\ngit push --delete origin my_branch\n\n\nYou can do the same using:\n\ngit push origin :my_branch   # Easy to remember both will do the same.\n\n\nGraphical representation:\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:58\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 23 '17 at 6:42\nMohideen bin Mohammed\n14.9k7\n7 gold badges\n87\n87 silver badges\n101\n101 bronze badges","comments":[]},{"answer":"git push origin --delete <branch Name>\n\n\nis easier to remember than\n\ngit push origin :branchName\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '18 at 4:44\nAnant Kumar Singh\n66.8k10\n10 gold badges\n46\n46 silver badges\n86\n86 bronze badges\nanswered May 2 '15 at 10:59\nSmila\n1,0828\n8 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"Now you can do it with the GitHub Desktop application.\n\nAfter launching the application\n\nClick on the project containing the branch\n\nSwitch to the branch you would like to delete\n\nFrom the \"Branch\" menu, select, \"Unpublish...\", to have the branch deleted from the GitHub servers.\n\nFrom the \"Branch\" menu, select, 'Delete \"branch_name\"...', to have the branch deleted off of your local machine (AKA the machine you are currently working on)\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:28\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 22 '15 at 7:38\nEric\n6,3765\n5 gold badges\n38\n38 silver badges\n61\n61 bronze badges","comments":["I didn't downvote, but my thinking is that it isn't substantively helping. The question is obviously asking for a more commandline type answer without having to use an external program, if people were clicking into here, they likely won't be looking for a github for desktop ways.","@Daemedeor , I dissagree. In 2010 when the OP asked the question, the UI way of doing it didn't exist and the only option was command line. To indicate that you want a command line only option it should be stated in the question or with the tag, command-line-interface, which in this case is no present.","The git command for deleting a remote branch sucks and I tend to forget it (both new and old). Luckily there are GUI tools that have the option. Git Gui, TortoiseGit and GitHub Desktop have it - I wish Git Extensions had this functionality too. Anyway, what I remember is to start Git Gui from within Git Extensions when I need to delete a remote branch."]},{"answer":"This won't work if you have a tag with the same name as the branch on the remote:\n\n$ git push origin :branch-or-tag-name\nerror: dst refspec branch-or-tag-name matches more than one.\nerror: failed to push some refs to 'git@github.com:SomeName/some-repo.git'\n\n\nIn that case you need to specify that you want to delete the branch, not the tag:\n\ngit push origin :refs/heads/branch-or-tag-name\n\n\nSimilarly, to delete the tag instead of the branch you would use:\n\ngit push origin :refs/tags/branch-or-tag-name\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '18 at 4:43\nAnant Kumar Singh\n66.8k10\n10 gold badges\n46\n46 silver badges\n86\n86 bronze badges\nanswered Jul 29 '14 at 9:02\nGreg\n7,7044\n4 gold badges\n33\n33 silver badges\n51\n51 bronze badges","comments":["This is fine, but people really shouldn't be naming their branches and tags with the same name and same naming scheme in the first place.","Well, my scenario was that I was converting a branch to a tag and it made sense for the tag to have the same name as the branch. By converting I mean merging branch B to A and tagging the last commit in branch B with tag B so that after deleting branch B it can still be easily restored by simply checking out tag B.","More on the : and why it deletes","I get still the same error error: failed to push some refs to 'https://github.com/tik9/tik9.github.io' when git push origin :refs/heads/main. Probably github is the culprit."]},{"answer":"Many of the other answers will lead to errors/warnings. This approach is relatively fool proof although you may still need git branch -D branch_to_delete if it's not fully merged into some_other_branch, for example.\n\ngit checkout some_other_branch\ngit push origin :branch_to_delete\ngit branch -d branch_to_delete\n\n\nRemote pruning isn't needed if you deleted the remote branch. It's only used to get the most up-to-date remotes available on a repository you're tracking. I've observed git fetch will add remotes, not remove them. Here's an example of when git remote prune origin will actually do something:\n\nUser A does the steps above. User B would run the following commands to see the most up-to-date remote branches:\n\ngit fetch\ngit remote prune origin\ngit branch -r\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 27 '13 at 3:04\nBrandon Cook\n1,29211\n11 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"I got sick of googling for this answer, so I took a similar approach to the answer that crizCraig posted earlier.\n\nI added the following to my Bash profile:\n\nfunction gitdelete(){\n    git push origin --delete $1\n    git branch -D $1\n}\n\n\nThen every time I'm done with a branch (merged into master, for example) I run the following in my terminal:\n\ngitdelete my-branch-name\n\n\n...which then deletes my-branch-name from origin as as well as locally.\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:32\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 10 '16 at 19:47\narthurakay\n5,2917\n7 gold badges\n37\n37 silver badges\n57\n57 bronze badges","comments":["expanding on this, --delete \"$@\" and -D \"$@\" instead of $1 will handle it for multiple branches.","I suggest running git branch -d (with lowercase 'd') first to ensure changes have been merged, and then push if successful (put && in between commands)"]},{"answer":"Before executing\n\ngit branch --delete <branch>\n\n\nmake sure you determine first what the exact name of the remote branch is by executing:\n\ngit ls-remote\n\n\nThis will tell you what to enter exactly for <branch> value. (branch is case sensitive!)\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:37\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 20 '16 at 21:42\njbooker\n4,3972\n2 gold badges\n30\n30 silver badges\n43\n43 bronze badges","comments":[]},{"answer":"Use:\n\ngit push origin :bugfix  # Deletes remote branch\ngit branch -d bugfix     # Must delete local branch manually\n\n\nIf you are sure you want to delete it, run\n\ngit branch -D bugfix\n\n\nNow to clean up deleted remote branches run\n\ngit remote prune origin\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '20 at 11:32\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 21 '16 at 16:49\nuser\n6991\n1 gold badge\n7\n7 silver badges\n21\n21 bronze badges","comments":[]}]},{"id":"292357","href":"https://stackoverflow.com/questions/292357/what-is-the-difference-between-git-pull-and-git-fetch","title":"What is the difference between 'git pull' and 'git fetch'?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        Want to improve this post? Provide detailed answers to this question, including citations and an explanation of why your answer is correct. Answers without enough detail may be edited or deleted.\n                        \n                    \n                \n            \n        \n\n\n    \n\nWhat are the differences between git pull and git fetch?\n    ","questionComments":["I found this well written article about git fetch and git pull it's worth the reading: longair.net/blog/2009/04/16/git-fetch-and-merge","Our alternative approach has become git fetch; git reset --hard origin/master as part of our workflow. It blows away local changes, keeps you up to date with master BUT makes sure you don't just pull in new changes on top on current changes and make a mess. We've used it for a while and it basically feels a lot safer in practice. Just be sure to add/commit/stash any work-in-progress first !","Make sure you know how to use git stash correctly. If you're asking about 'pull' and 'fetch' then maybe 'stash' will also need explaining...","Lots of folks coming from Mercurial keep using \"git pull\", thinking it's an equivalent for \"hg pull\". Which it's not. Git's equivalent of \"hg pull\" is \"git fetch\"."],"answers":[{"answer":"In the simplest terms, git pull does a git fetch followed by a git merge.\n\nYou can do a git fetch at any time to update your remote-tracking branches under refs/remotes/<remote>/. This operation never changes any of your own local branches under refs/heads, and is safe to do without changing your working copy. I have even heard of people running git fetch periodically in a cron job in the background (although I wouldn't recommend doing this).\n\nA git pull is what you would do to bring a local branch up-to-date with its remote version, while also updating your other remote-tracking branches.\n\nFrom the Git documentation for git pull:\n\nIn its default mode, git pull is shorthand for git fetch followed by git merge FETCH_HEAD.\n\nShare\nImprove this answer\nFollow\nedited May 14 at 11:26\nMateen Ulhaq\n18.9k13\n13 gold badges\n77\n77 silver badges\n113\n113 bronze badges\nanswered Nov 15 '08 at 9:52\nGreg Hewgill\n843k170\n170 gold badges\n1107\n1107 silver badges\n1243\n1243 bronze badges","comments":["\"A \"git pull\" is what you would do to bring your repository up to date\" <- isn't the repository update already done by fetch? don't you mean it brings your local branches up-to-date with the remote branches? To the merge: It merges the remote branches with your local copies of those branches, or what exactly does it merge here?","@Albert: Yeah, it's weirdly worded. git pull will always merge into the current branch. So you select which branch you want to pull from, and it pulls it into the current branch. The from branch can be local or remote; it can even be a remote branch that's not a registered git remote (meaning you pass a URL on the git pull command line).","@espertus: No. Pushing never automatically does a merge. The user is expected to pull, resolving any merge conflicts locally, then push back to the remote.","If I am at /home/alice/ and do git fetch /home/bob, what parameters should I pass to the subsequent git merge ?","Note to people learning Git: pull can't actually be emulated by a fetch plus a merge. I just fetched a change where only a remote branch pointer changes, and merge refuses to do anything. pull, on the other hand, fast-forwards my tracking branch."]},{"answer":"When you use pull, Git tries to automatically merge. It is context sensitive, so Git will merge any pulled commits into the branch you are currently working on. pull automatically merges the commits without letting you review them first. If you don’t carefully manage your branches, you may run into frequent conflicts.\n\nWhen you fetch, Git gathers any commits from the target branch that do not exist in your current branch and stores them in your local repository. However, it does not merge them with your current branch. This is particularly useful if you need to keep your repository up to date, but are working on something that might break if you update your files. To integrate the commits into your current branch, you must use merge afterwards.\n\nShare\nImprove this answer\nFollow\nedited May 14 at 11:35\nMateen Ulhaq\n18.9k13\n13 gold badges\n77\n77 silver badges\n113\n113 bronze badges\nanswered Aug 18 '11 at 8:53\nMouna Cheikhna\n35.6k10\n10 gold badges\n46\n46 silver badges\n68\n68 bronze badges","comments":["Agreed, great comment. Which is why I hate git pull. When would it ever make sense to let a revision tool make code edits for you? And isn't that what merging two files is doing? What if those two edits are physically separated in the file, but LOGICALLY at odds?","I'm not sure if I understand this correctly. Let me know if I'm right: Lets say I have two branches, master and test. test is a branch that I'm working on to experiment something. If I do git fetch, it updates master with the target branch. If I do git pull, it tries to update test with the target branch. Is this right? If not, I think I don't understand what 'local repository' means - I assumed it means my local master.","@elexhobby short put, git fetch only updates your .git/ directory (AKA: local repository) and nothing outside .git/ (AKA: working tree). It does not change your local branches, and it does not touch master either. It touches remotes/origin/master though (see git branch -avv). If you have more remotes, try git remote update. This is a git fetch for all remotes in one command.","@Tino yours is really the most important point. People may not know that \"remote\" branches are actually stored as a bunch of hashes in .git/refs/remotes/origin/.","So, fetch command is something like a \"commit from the remote to local\". Right?"]},{"answer":"It is important to contrast the design philosophy of git with the philosophy of a more traditional source control tool like SVN.\n\nSubversion was designed and built with a client/server model. There is a single repository that is the server, and several clients can fetch code from the server, work on it, then commit it back to the server. The assumption is that the client can always contact the server when it needs to perform an operation.\n\nGit was designed to support a more distributed model with no need for a central repository (though you can certainly use one if you like). Also git was designed so that the client and the \"server\" don't need to be online at the same time. Git was designed so that people on an unreliable link could exchange code via email, even. It is possible to work completely disconnected and burn a CD to exchange code via git.\n\nIn order to support this model git maintains a local repository with your code and also an additional local repository that mirrors the state of the remote repository. By keeping a copy of the remote repository locally, git can figure out the changes needed even when the remote repository is not reachable. Later when you need to send the changes to someone else, git can transfer them as a set of changes from a point in time known to the remote repository.\n\ngit fetch is the command that says \"bring my local copy of the remote repository up to date.\"\n\ngit pull says \"bring the changes in the remote repository to where I keep my own code.\"\n\nNormally git pull does this by doing a git fetch to bring the local copy of the remote repository up to date, and then merging the changes into your own code repository and possibly your working copy.\n\nThe take away is to keep in mind that there are often at least three copies of a project on your workstation. One copy is your own repository with your own commit history. The second copy is your working copy where you are editing and building. The third copy is your local \"cached\" copy of a remote repository.\n\nShare\nImprove this answer\nFollow\nedited Aug 24 '18 at 20:01\nIan Ringrose\n49.7k50\n50 gold badges\n203\n203 silver badges\n305\n305 bronze badges\nanswered Mar 31 '13 at 18:43\nMikeD\n13.4k1\n1 gold badge\n17\n17 silver badges\n9\n9 bronze badges","comments":["Technically, the local and remote repositories are really one and the same. In Git, a repository is a DAG of commits pointing to their parents. Branches are, technically, nothing more than meaningful names of commits. The only difference between local and remote branches is that remote ones are prefixed with remoteName/ Git from the ground up is a very good read. Once you get an understanding of how Git works - and it's beautifully simple, really - everything just makes sense."]},{"answer":"Here is Oliver Steele's image of how all it all fits together:\n\nIf there is sufficient interest, I suppose I could update the image to add git clone and git merge...\n\nShare\nImprove this answer\nFollow\nedited Mar 19 '18 at 19:21\nnmichaels\n46k12\n12 gold badges\n98\n98 silver badges\n128\n128 bronze badges\nanswered Jun 9 '15 at 13:30\nContango\n66.5k53\n53 gold badges\n231\n231 silver badges\n279\n279 bronze badges","comments":["An updated image with git clone and git merge would be very helpful!","Yes, please add git merge - it should clearly show that merge called separately is NOT the same as calling pull because pull is merging from remote only and ignores your local commits in your local branch which is tracking the remote branch being pulled from.","A picture is worth a thousand words! Is the updated image with clone and merge data flow ready somewhere? Any other data flow besides what's already in the diagram?"]},{"answer":"One use case of git fetch is that the following will tell you any changes in the remote branch since your last pull... so you can check before doing an actual pull, which could change files in your current branch and working copy.\n\ngit fetch\ngit diff ...origin\n\n\nSee: https://git-scm.com/docs/git-diff regarding double- and triple-dot syntax in the diff command\n\nShare\nImprove this answer\nFollow\nedited Jul 16 '19 at 19:49\nrkedge\n3882\n2 silver badges\n12\n12 bronze badges\nanswered May 7 '10 at 19:23\nmepster\n5,2331\n1 gold badge\n13\n13 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"It cost me a little bit to understand what was the difference, but this is a simple explanation. master in your localhost is a branch.\n\nWhen you clone a repository you fetch the entire repository to you local host. This means that at that time you have an origin/master pointer to HEAD and master pointing to the same HEAD.\n\nwhen you start working and do commits you advance the master pointer to HEAD + your commits. But the origin/master pointer is still pointing to what it was when you cloned.\n\nSo the difference will be:\n\nIf you do a git fetch it will just fetch all the changes in the remote repository (GitHub) and move the origin/master pointer to HEAD. Meanwhile your local branch master will keep pointing to where it has.\nIf you do a git pull, it will do basically fetch (as explained previously) and merge any new changes to your master branch and move the pointer to HEAD.\nShare\nImprove this answer\nFollow\nedited Jan 2 '16 at 4:52\nstites\n4,0435\n5 gold badges\n29\n29 silver badges\n43\n43 bronze badges\nanswered May 11 '12 at 18:37\nGerardo\n6,5413\n3 gold badges\n19\n19 silver badges\n15\n15 bronze badges","comments":["origin/master is a local branch that is a COPY of master on origin. When you fetch, you update local:/origin/master. Once you really grok that everything in git is a branch, this makes a lot of sense and is a very powerful way to maintain different changesets, make quick local branches, merge and rebase, and generally get a lot of value out of the cheap branching model."]},{"answer":"Briefly\n\ngit fetch is similar to pull but doesn't merge. i.e. it fetches remote updates (refs and objects) but your local stays the same (i.e. origin/master gets updated but master stays the same) .\n\ngit pull pulls down from a remote and instantly merges.\n\nMore\n\ngit clone clones a repo.\n\ngit rebase saves stuff from your current branch that isn't in the upstream branch to a temporary area. Your branch is now the same as before you started your changes. So, git pull -rebase will pull down the remote changes, rewind your local branch, replay your changes over the top of your current branch one by one until you're up-to-date.\n\nAlso, git branch -a will show you exactly what’s going on with all your branches - local and remote.\n\nThis blog post was useful:\n\nThe difference between git pull, git fetch and git clone (and git rebase) - Mike Pearce\n\nand covers git pull, git fetch, git clone and git rebase.\n\nUPDATE\n\nI thought I'd update this to show how you'd actually use this in practice.\n\nUpdate your local repo from the remote (but don't merge):\n\n git fetch \n\n\nAfter downloading the updates, let's see the differences:\n\n git diff master origin/master \n\n\nIf you're happy with those updates, then merge:\n\n git pull\n\n\nNotes:\n\nOn step 2: For more on diffs between local and remotes, see: How to compare a local git branch with its remote branch?\n\nOn step 3: It's probably more accurate (e.g. on a fast changing repo) to do a git rebase origin here. See @Justin Ohms comment in another answer.\n\nSee also: http://longair.net/blog/2009/04/16/git-fetch-and-merge/\n\nShare\nImprove this answer\nFollow\nedited Jan 26 at 21:26\njakubde\n231\n1 silver badge\n4\n4 bronze badges\nanswered Apr 13 '13 at 17:31\nSnowcrash\n68.3k64\n64 gold badges\n213\n213 silver badges\n329\n329 bronze badges","comments":[]},{"answer":"Sometimes a visual representation helps.\n\nShare\nImprove this answer\nFollow\nanswered Jan 25 '16 at 17:28\nthedarkpassenger\n6,1602\n2 gold badges\n33\n33 silver badges\n54\n54 bronze badges","comments":["I think the picture got to show that it affects the local repo too. That's is, Git pull is a combination of affecting the local repo and working copy. Right now it seems it just affect the working copy."]},{"answer":"git-pull - Fetch from and merge with another repository or a local branch\nSYNOPSIS\n\ngit pull   …\nDESCRIPTION\n\nRuns git-fetch with the given parameters, and calls git-merge to merge the \nretrieved head(s) into the current branch. With --rebase, calls git-rebase \ninstead of git-merge.\n\nNote that you can use . (current directory) as the <repository> to pull \nfrom the local repository — this is useful when merging local branches \ninto the current branch.\n\nAlso note that options meant for git-pull itself and underlying git-merge \nmust be given before the options meant for git-fetch.\n\n\nYou would pull if you want the histories merged, you'd fetch if you just 'want the codez' as some person has been tagging some articles around here.\n\nShare\nImprove this answer\nFollow\nanswered Nov 15 '08 at 9:52\nVinko Vrsalovic♦\n246k51\n51 gold badges\n319\n319 silver badges\n362\n362 bronze badges","comments":[]},{"answer":"You can fetch from a remote repository, see the differences and then pull or merge.\n\nThis is an example for a remote repository called origin and a branch called master tracking the remote branch origin/master:\n\ngit checkout master                                                  \ngit fetch                                        \ngit diff origin/master\ngit rebase origin master\n\nShare\nImprove this answer\nFollow\nedited Mar 15 '15 at 22:20\nOlli\n1,20815\n15 silver badges\n31\n31 bronze badges\nanswered Mar 21 '11 at 11:07\nAntonio Bardazzi\n2,6271\n1 gold badge\n16\n16 silver badges\n19\n19 bronze badges","comments":["You probably want to skip the pull and just do a \"git rebase origin\" as the last step since you already fetched the changes. The reason is that someone could have pushed changes in the time since you did the fetch and these would not have been in fetch that you did the diff review on."]},{"answer":"The short and easy answer is that git pull is simply git fetch followed by git merge.\n\nIt is very important to note that git pull will automatically merge whether you like it or not. This could, of course, result in merge conflicts. Let's say your remote is origin and your branch is master. If you git diff origin/master before pulling, you should have some idea of potential merge conflicts and could prepare your local branch accordingly.\n\nIn addition to pulling and pushing, some workflows involve git rebase, such as this one, which I paraphrase from the linked article:\n\ngit pull origin master\ngit checkout foo-branch\ngit rebase master\ngit push origin foo-branch\n\n\nIf you find yourself in such a situation, you may be tempted to git pull --rebase. Unless you really, really know what you are doing, I would advise against that. This warning is from the man page for git-pull, version 2.3.5:\n\nThis is a potentially dangerous mode of operation. It rewrites history, which does not bode well when you published that history already. Do not use this option unless you have read git-rebase(1) carefully.\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '18 at 15:28\nanswered May 15 '11 at 20:53\njfmercer\n3,3413\n3 gold badges\n26\n26 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"OK, here is some information about git pull and git fetch, so you can understand the actual differences... in few simple words, fetch gets the latest data, but not the code changes and not going to mess with your current local branch code, but pull get the code changes and merge it your local branch, read on to get more details about each:\n\ngit fetch\n\nIt will download all refs and objects and any new branches to your local Repository...\n\nFetch branches and/or tags (collectively, \"refs\") from one or more other repositories, along with the objects necessary to complete their histories. Remote-tracking branches are updated (see the description of below for ways to control this behavior).\n\nBy default, any tag that points into the histories being fetched is also fetched; the effect is to fetch tags that point at branches that you are interested in. This default behavior can be changed by using the --tags or --no-tags options or by configuring remote..tagOpt. By using a refspec that fetches tags explicitly, you can fetch tags that do not point into branches you are interested in as well.\n\ngit fetch can fetch from either a single named repository or URL or from several repositories at once if is given and there is a remotes. entry in the configuration file. (See git-config1).\n\nWhen no remote is specified, by default the origin remote will be used, unless there’s an upstream branch configured for the current branch.\n\nThe names of refs that are fetched, together with the object names they point at, are written to .git/FETCH_HEAD. This information may be used by scripts or other git commands, such as git-pull.\n\ngit pull\n\nIt will apply the changes from remote to the current branch in local...\n\nIncorporates changes from a remote repository into the current branch. In its default mode, git pull is shorthand for git fetch followed by git merge FETCH_HEAD.\n\nMore precisely, git pull runs git fetch with the given parameters and calls git merge to merge the retrieved branch heads into the current branch. With --rebase, it runs git rebase instead of git merge.\n\nshould be the name of a remote repository as passed to git-fetch1. can name an arbitrary remote ref (for example, the name of a tag) or even a collection of refs with corresponding remote-tracking branches (e.g., refs/heads/:refs/remotes/origin/), but usually it is the name of a branch in the remote repository.\n\nDefault values for and are read from the \"remote\" and \"merge\" configuration for the current branch as set by git-branch --track.\n\nI also create the visual below to show you how git fetch and git pull working together...\n\nShare\nImprove this answer\nFollow\nedited Dec 24 '20 at 18:17\nNoor A Shuvo\n2,25118\n18 silver badges\n36\n36 bronze badges\nanswered Jun 21 '17 at 9:48\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"This interactive graphical representation is very helpful in understanging git: http://ndpsoftware.com/git-cheatsheet.html\n\ngit fetch just \"downloads\" the changes from the remote to your local repository. git pull downloads the changes and merges them into your current branch. \"In its default mode, git pull is shorthand for git fetch followed by git merge FETCH_HEAD.\"\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '16 at 10:02\nanswered Feb 6 '15 at 11:48\nth3sly\n1,7311\n1 gold badge\n15\n15 silver badges\n19\n19 bronze badges","comments":["People, click on the link to interact with the different columns. This cheatsheet is the best resource I've seen to fully understand the differences between each command."]},{"answer":"Bonus:\n\nIn speaking of pull & fetch in the above answers, I would like to share an interesting trick,\n\ngit pull --rebase\n\nThis above command is the most useful command in my git life which saved a lots of time.\n\nBefore pushing your new commits to server, try this command and it will automatically sync latest server changes (with a fetch + merge) and will place your commit at the top in git log. No need to worry about manual pull/merge.\n\nFind details at: http://gitolite.com/git-pull--rebase\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Dec 23 '15 at 15:31\nSazzad Hissain Khan\n30.5k21\n21 gold badges\n138\n138 silver badges\n201\n201 bronze badges","comments":[]},{"answer":"I like to have some visual representation of the situation to grasp these things. Maybe other developers would like to see it too, so here's my addition. I'm not totally sure that it all is correct, so please comment if you find any mistakes.\n\n                                         LOCAL SYSTEM\n                  . =====================================================    \n================= . =================  ===================  =============\nREMOTE REPOSITORY . REMOTE REPOSITORY  LOCAL REPOSITORY     WORKING COPY\n(ORIGIN)          . (CACHED)           \nfor example,      . mirror of the      \na github repo.    . remote repo\nCan also be       .\nmultiple repo's   .\n                  .\n                  .\nFETCH  *------------------>*\nYour local cache of the remote is updated with the origin (or multiple\nexternal sources, that is git's distributed nature)\n                  .\nPULL   *-------------------------------------------------------->*\nchanges are merged directly into your local copy. when conflicts occur, \nyou are asked for decisions.\n                  .\nCOMMIT            .                             *<---------------*\nWhen coming from, for example, subversion, you might think that a commit\nwill update the origin. In git, a commit is only done to your local repo.\n                  .\nPUSH   *<---------------------------------------*\nSynchronizes your changes back into the origin.\n\n\nSome major advantages for having a fetched mirror of the remote are:\n\nPerformance (scroll through all commits and messages without trying to squeeze it through the network)\nFeedback about the state of your local repo (for example, I use Atlassian's SourceTree, which will give me a bulb indicating if I'm commits ahead or behind compared to the origin. This information can be updated with a GIT FETCH).\nShare\nImprove this answer\nFollow\nedited Jul 25 '14 at 7:01\nanswered Feb 19 '14 at 21:18\nJustus Romijn\n14.1k4\n4 gold badges\n47\n47 silver badges\n59\n59 bronze badges","comments":[]},{"answer":"The Difference between GIT Fetch and GIT Pull can be explained with the following scenario: (Keeping in mind that pictures speak louder than words!, I have provided pictorial representation)\n\nLet's take an example that you are working on a project with your team members. So there will be one main Branch of the project and all the contributors must fork it to their own local repository and then work on this local branch to modify/Add modules then push back to the main branch.\n\nSo, Initial State of the two Branches when you forked the main project on your local repository will be like this- (A, B and C are Modules already completed of the project)\n\nNow, you have started working on the new module (suppose D) and when you have completed the D module you want to push it to the main branch, But meanwhile what happens is that one of your teammates has developed new Module E, F and modified C.\nSo now what has happened is that your local repository is lacking behind the original progress of the project and thus pushing of your changes to the main branch can lead to conflict and may cause your Module D to malfunction.\n\nTo avoid such issues and to work parallel with the original progress of the project there are Two ways:\n\n1. Git Fetch- This will Download all the changes that have been made to the origin/main branch project which are not present in your local branch. And will wait for the Git Merge command to apply the changes that have been fetched to your Repository or branch.\n\nSo now You can carefully monitor the files before merging it to your repository. And you can also modify D if required because of Modified C.\n\n2. Git Pull- This will update your local branch with the origin/main branch i.e. actually what it does is a combination of Git Fetch and Git merge one after another. But this may Cause Conflicts to occur, so it’s recommended to use Git Pull with a clean copy.\n\nShare\nImprove this answer\nFollow\nedited Jul 14 '20 at 20:45\nAnupama Karunarathna\n1071\n1 silver badge\n12\n12 bronze badges\nanswered Feb 7 '17 at 14:15\nAman Tiwari\n1,2651\n1 gold badge\n8\n8 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"I have struggled with this as well. In fact I got here with a google search of exactly the same question. Reading all these answers finally painted a picture in my head and I decided to try to get this down looking at the state of the 2 repositories and 1 sandbox and actions performed over time while watching the version of them. So here is what I came up with. Please correct me if I messed up anywhere.\n\nThe three repos with a fetch:\n\n---------------------     -----------------------     -----------------------\n- Remote Repo       -     - Remote Repo         -     - Remote Repo         -\n-                   -     - gets pushed         -     -                     -\n- @ R01             -     - @ R02               -     - @ R02               -\n---------------------     -----------------------     -----------------------\n\n---------------------     -----------------------     -----------------------\n- Local Repo        -     - Local Repo          -     - Local Repo          -\n- pull              -     -                     -     - fetch               -\n- @ R01             -     - @ R01               -     - @ R02               -\n---------------------     -----------------------     -----------------------\n\n---------------------     -----------------------     -----------------------\n- Local Sandbox     -     - Local Sandbox       -     - Local Sandbox       -\n- Checkout          -     - new work done       -     -                     -\n- @ R01             -     - @ R01+              -     - @R01+               -\n---------------------     -----------------------     -----------------------\n\n\nThe three repos with a pull\n\n---------------------     -----------------------     -----------------------\n- Remote Repo       -     - Remote Repo         -     - Remote Repo         -\n-                   -     - gets pushed         -     -                     -\n- @ R01             -     - @ R02               -     - @ R02               -\n---------------------     -----------------------     -----------------------\n\n---------------------     -----------------------     -----------------------\n- Local Repo        -     - Local Repo          -     - Local Repo          -\n- pull              -     -                     -     - pull                -\n- @ R01             -     - @ R01               -     - @ R02               -\n---------------------     -----------------------     -----------------------\n\n---------------------     -----------------------     -----------------------\n- Local Sandbox     -     - Local Sandbox       -     - Local Sandbox       -\n- Checkout          -     - new work done       -     - merged with R02     -\n- @ R01             -     - @ R01+              -     - @R02+               -\n---------------------     -----------------------     -----------------------\n\n\nThis helped me understand why a fetch is pretty important.\n\nShare\nImprove this answer\nFollow\nedited May 31 '17 at 19:41\nJohnAllen\n6,4959\n9 gold badges\n38\n38 silver badges\n61\n61 bronze badges\nanswered Jul 17 '12 at 16:43\npn1 dude\n3,8985\n5 gold badges\n26\n26 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"We simply say:\n\ngit pull == git fetch + git merge\n\n\nIf you run git pull, you do not need to merge the data to local. If you run git fetch, it means you must run git merge for getting the latest code to your local machine. Otherwise, the local machine code would not be changed without merge.\n\nSo in the Git Gui, when you do fetch, you have to merge the data. Fetch itself won't make the code changes at your local. You can check that when you update the code by fetching once fetch and see; the code it won't change. Then you merge... You will see the changed code.\n\nShare\nImprove this answer\nFollow\nedited Jul 17 '13 at 13:35\nanswered Feb 21 '13 at 13:25\nSelvamani\n6,6703\n3 gold badges\n28\n28 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"git fetch pulls down the code from the remote server to your tracking branches in your local repository. If your remote is named origin (the default) then these branches will be within origin/, for example origin/master, origin/mybranch-123, etc. These are not your current branches, they are local copies of those branches from the server.\n\ngit pull does a git fetch but then also merges the code from the tracking branch into your current local version of that branch. If you're not ready for that changes yet, just git fetch first.\n\nShare\nImprove this answer\nFollow\nedited Jun 1 '16 at 0:59\nanswered Sep 19 '13 at 20:01\nMichael Durrant\n85.6k84\n84 gold badges\n288\n288 silver badges\n437\n437 bronze badges","comments":[]},{"answer":"git fetch will retrieve remote branches so that you can git diff or git merge them with the current branch. git pull will run fetch on the remote brach tracked by the current branch and then merge the result. You can use git fetch to see if there are any updates to the remote branch without necessary merging them with your local branch.\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '13 at 20:31\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 26 '12 at 21:58\nntanase\n1,0498\n8 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"In simple terms, if you were about to hop onto a plane without any Internet connection...before departing you could just do git fetch origin <branch>. It would fetch all the changes into your computer, but keep it separate from your local development/workspace.\n\nOn the plane, you could make changes to your local workspace and then merge it with what you've previously fetched and then resolve potential merge conflicts all without a connection to the Internet. And unless someone had made new changes to the remote repository then once you arrive at the destination you would do git push origin <branch> and go get your coffee.\n\nFrom this awesome Atlassian tutorial:\n\nThe git fetch command downloads commits, files, and refs from a remote repository into your local repository.\n\nFetching is what you do when you want to see what everybody else has been working on. It’s similar to SVN update in that it lets you see how the central history has progressed, but it doesn’t force you to actually merge the changes into your repository. Git isolates fetched content as a from existing local content, it has absolutely no effect on your local development work. Fetched content has to be explicitly checked out using the git checkout command. This makes fetching a safe way to review commits before integrating them with your local repository.\n\nWhen downloading content from a remote repository, git pull and git fetch commands are available to accomplish the task. You can consider git fetch the 'safe' version of the two commands. It will download the remote content, but not update your local repository's working state, leaving your current work intact. git pull is the more aggressive alternative, it will download the remote content for the active local branch and immediately execute git merge to create a merge commit for the new remote content. If you have pending changes in progress this will cause conflicts and kickoff the merge conflict resolution flow.\n\nWith git pull:\n\nYou don't get any isolation.\nIt doesn't need to be explicitly checked out. Because it implicitly does a git merge.\nThe merging step will affect your local development and may cause conflicts\nIt's basically NOT safe. It's aggressive.\nUnlike git fetch where it only affects your .git/refs/remotes, git pull will affect both your .git/refs/remotes and .git/refs/heads/\n\nHmmm...so if I'm not updating the working copy with git fetch, then where am I making changes? Where does Git fetch store the new commits?\n\nGreat question. First and foremost, the heads or remotes don't store the new commits. They just have pointers to commits. So with git fetch you download the latest git objects (blob, tree, commits. To fully understand the objects watch this video on git internals), but only update your remotes pointer to point to the latest commit of that branch. It's still isolated from your working copy, because your branch's pointer in the heads directory hasn't updated. It will only update upon a merge/pull. But again where? Let's find out.\n\nIn your project directory (i.e., where you do your git commands) do:\n\nls. This will show the files & directories. Nothing cool, I know.\n\nNow do ls -a. This will show dot files, i.e., files beginning with . You will then be able to see a directory named: .git.\n\nDo cd .git. This will obviously change your directory.\n\nNow comes the fun part; do ls. You will see a list of directories. We're looking for refs. Do cd refs.\n\nIt's interesting to see what's inside all directories, but let's focus on two of them. heads and remotes. Use cd to check inside them too.\n\nAny git fetch that you do will update the pointer in the /.git/refs/remotes directory. It won't update anything in the /.git/refs/heads directory.\n\nAny git pull will first do the git fetch, update items in the /.git/refs/remotes directory, then merge with your local and then change the head inside the /.git/refs/heads directory.\n\nA very good related answer can also be found in Where does 'git fetch' place itself?.\n\nAlso, look for \"Slash notation\" from the Git branch naming conventions post. It helps you better understand how Git places things in different directories.\n\nTo see the actual difference\n\nJust do:\n\ngit fetch origin master\ngit checkout master\n\n\nIf the remote master was updated you'll get a message like this:\n\nYour branch is behind 'origin/master' by 2 commits, and can be fast-forwarded.\n  (use \"git pull\" to update your local branch)\n\n\nIf you didn't fetch and just did git checkout master then your local git wouldn't know that there are 2 commits added. And it would just say:\n\nAlready on 'master'\nYour branch is up to date with 'origin/master'.\n\n\nBut that's outdated and incorrect. It's because git will give you feedback solely based on what it knows. It's oblivious to new commits that it hasn't pulled down yet...\n\nIs there any way to see the new changes made in remote while working on the branch locally?\n\nSome IDEs (e.g. Xcode) are super smart and use the result of a git fetch and can annotate the lines of code that have been changed in remote branch of your current working branch. If that line has been changed by both local changes and remote branch, then that line gets annotated with red. This isn't a merge conflict. It's a potential merge conflict. It's a headsup that you can use to resolve the future merge conflict before doing git pull from the remote branch.\n\nFun tip:\n\nIf you fetched a remote branch e.g. did:\n\ngit fetch origin feature/123\n\n\nThen this would go into your remotes directory. It's still not available to your local directory. However, it simplifies your checkout to that remote branch by DWIM (Do what I mean):\n\ngit checkout feature/123\n\n\nyou no longer need to do:\n\ngit checkout -b feature/123 origin/feature/123\n\n\nFor more on that read here\n\nShare\nImprove this answer\nFollow\nedited Mar 28 at 12:13\nanswered Feb 12 '19 at 19:25\nHoney\n25.2k14\n14 gold badges\n126\n126 silver badges\n224\n224 bronze badges","comments":[]},{"answer":"Git Fetch\n\nYou download changes to your local branch from origin through fetch. Fetch asks the remote repo for all commits that others have made but you don't have on your local repo. Fetch downloads these commits and adds them to the local repository.\n\nGit Merge\n\nYou can apply changes downloaded through fetch using the merge command. Merge will take the commits retrieved from fetch and try to add them to your local branch. The merge will keep the commit history of your local changes so that when you share your branch with push, Git will know how others can merge your changes.\n\nGit Pull\n\nFetch and merge run together often enough that a command that combines the two, pull, was created. Pull does a fetch and then a merge to add the downloaded commits into your local branch.\n\nShare\nImprove this answer\nFollow\nedited Jun 16 '17 at 18:15\nanswered Jul 13 '16 at 21:23\nPinkesh Sharma\n2,16816\n16 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"The only difference between git pull and git fetch is that :\n\ngit pull pulls from a remote branch and merges it.\n\ngit fetch only fetches from the remote branch but it does not merge\n\ni.e. git pull = git fetch + git merge ...\n\nShare\nImprove this answer\nFollow\nedited Jun 5 '13 at 15:47\nbcr\n1,66622\n22 silver badges\n25\n25 bronze badges\nanswered Jun 4 '13 at 14:08\nRohitashv Singhal\n4,29113\n13 gold badges\n49\n49 silver badges\n100\n100 bronze badges","comments":[]},{"answer":"Git allows chronologically older commits to be applied after newer commits. Because of this, the act of transferring commits between repositories is split into two steps:\n\nCopying new commits from remote branch to copy of this remote branch inside local repo.\n\n(repo to repo operation) master@remote >> remote/origin/master@local\n\nIntegrating new commits to local branch\n\n(inside-repo operation) remote/origin/master@local >> master@local\n\nThere are two ways of doing step 2. You can:\n\nFork local branch after last common ancestor and add new commits parallel to commits which are unique to local repository, finalized by merging commit, closing the fork.\nInsert new commits after last common ancestor and reapply commits unique to local repository.\n\nIn git terminology, step 1 is git fetch, step 2 is git merge or git rebase\n\ngit pull is git fetch and git merge\n\nShare\nImprove this answer\nFollow\nanswered Nov 28 '13 at 17:03\nPawel Furmaniak\n4,0643\n3 gold badges\n27\n27 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"Git obtains the branch of the latest version from the remote to the local using two commands:\n\ngit fetch: Git is going to get the latest version from remote to local, but it do not automatically merge.      git fetch origin master git log -p master..origin/master git merge origin/master\n\n     The commands above mean that download latest version of the main branch from origin from the remote to origin master branch. And then compares the local master branch and origin master branch. Finally, merge.\n\ngit pull: Git is going to get the latest version from the remote and merge into the local.\n\n    git pull origin master\n\n     The command above is the equivalent to git fetch and git merge. In practice, git fetch maybe more secure because before the merge we can see the changes and decide whether to merge.\n\nShare\nImprove this answer\nFollow\nanswered Aug 12 '14 at 4:00\nMarcus Thornton\n5,0735\n5 gold badges\n41\n41 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"What is the difference between git pull and git fetch?\n\nTo understand this, you first need to understand that your local git maintains not only your local repository, but it also maintains a local copy of the remote repository.\n\ngit fetch brings your local copy of the remote repository up to date. For example, if your remote repository is GitHub - you may want to fetch any changes made in the remote repository to your local copy of it the remote repository. This will allow you to perform operations such as compare or merge.\n\ngit pull on the other hand will bring down the changes in the remote repository to where you keep your own code. Typically, git pull will do a git fetch first to bring the local copy of the remote repository up to date, and then it will merge the changes into your own code repository and possibly your working copy.\n\nShare\nImprove this answer\nFollow\nedited Jul 11 '15 at 10:22\nanswered May 19 '15 at 11:57\nDonal\n26.4k9\n9 gold badges\n60\n60 silver badges\n70\n70 bronze badges","comments":[]},{"answer":"git pull == ( git fetch + git merge)\n\ngit fetch does not changes to local branches.\n\nIf you already have a local repository with a remote set up for the desired project, you can grab all branches and tags for the existing remote using git fetch . ... Fetch does not make any changes to local branches, so you will need to merge a remote branch with a paired local branch to incorporate newly fetch changes. from github\n\nShare\nImprove this answer\nFollow\nanswered Sep 19 '13 at 22:41\nIggy\n7,7433\n3 gold badges\n29\n29 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"Trying to be clear and simple.\n\nThe git pull command is actually a shortcut for git fetch followed by the git merge or the git rebase command depending on your configuration. You can configure your Git repository so that git pull is a fetch followed by a rebase.\n\nShare\nImprove this answer\nFollow\nanswered Jul 29 '15 at 18:38\nMontells\n5,6213\n3 gold badges\n43\n43 silver badges\n48\n48 bronze badges","comments":[]},{"answer":"A simple Graphical Representation for Beginners,\n\nhere,\n\ngit pull  \n\n\nwill fetch code from repository and rebase with your local... in git pull there is possibility of new commits getting created.\n\nbut in ,\n\ngit fetch\n\nwill fetch code from repository and we need to rebase it manually by using git rebase\n\neg: i am going to fetch from server master and rebase it in my local master.\n\n1) git pull ( rebase will done automatically):\n\ngit pull origin master\n\n\nhere origin is your remote repo master is your branch\n\n2) git fetch (need to rebase manually):\n\ngit fetch origin master\n\n\nit will fetch server changes from origin. and it will be in your local until you rebase it on your own. we need to fix conflicts manually by checking codes.\n\ngit rebase origin/master\n\n\nthis will rebase code into local. before that ensure you're in right branch.\n\nShare\nImprove this answer\nFollow\nanswered Jul 12 '17 at 6:23\nMohideen bin Mohammed\n14.9k7\n7 gold badges\n87\n87 silver badges\n101\n101 bronze badges","comments":[]},{"answer":"Actually Git maintains a copy of your own code and the remote repository.\n\nThe command git fetch makes your local copy up to date by getting data from remote repository. The reason we need this is because somebody else might have made some changes to the code and you want to keep yourself updated.\n\nThe command git pull brings the changes in the remote repository to where you keep your own code. Normally, git pull does this by doing a ‘git fetch’ first to bring the local copy of the remote repository up to date, and then it merges the changes into your own code repository and possibly your working copy.\n\nShare\nImprove this answer\nFollow\nedited Aug 17 '17 at 20:51\n5377037\n9,49412\n12 gold badges\n43\n43 silver badges\n74\n74 bronze badges\nanswered Sep 13 '15 at 18:48\nPokemon\n4315\n5 silver badges\n8\n8 bronze badges","comments":[]}]},{"id":"231767","href":"https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do","title":"What does the “yield” keyword do?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        Want to improve this post? Provide detailed answers to this question, including citations and an explanation of why your answer is correct. Answers without enough detail may be edited or deleted.\n                        \n                    \n                \n            \n        \n\n\n    \n\nWhat is the use of the yield keyword in Python? What does it do?\nFor example, I'm trying to understand this code1:\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n    if self._leftchild and distance - max_dist < self._median:\n        yield self._leftchild\n    if self._rightchild and distance + max_dist >= self._median:\n        yield self._rightchild  \n\nAnd this is the caller:\nresult, candidates = [], [self]\nwhile candidates:\n    node = candidates.pop()\n    distance = node._get_dist(obj)\n    if distance <= max_dist and distance >= min_dist:\n        result.extend(node._values)\n    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))\nreturn result\n\nWhat happens when the method _get_child_candidates is called?\nIs a list returned? A single element? Is it called again? When will subsequent calls stop?\n\n\n1. This piece of code was written by Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: [Module mspace][1].\n    ","questionComments":["yield is not magical as top answer suggests. Great comment by @mattias-fripp: When you call a function that has a yield statement, you get a generator object, but no code runs. Then each time you extract an object from the generator, Python executes the function until it reaches a yield statement, then pauses and delivers the object. When you extract another object, Python resumes just after the yield and continues until it reaches another yield (often the same one, but one iteration later). This continues until the function runs off the end, at which point the generator is deemed exhausted."],"answers":[{"answer":"To understand what yield does, you must understand what generators are. And before you can understand generators, you must understand iterables.\n\nIterables\n\nWhen you create a list, you can read its items one by one. Reading its items one by one is called iteration:\n\n>>> mylist = [1, 2, 3]\n>>> for i in mylist:\n...    print(i)\n1\n2\n3\n\n\nmylist is an iterable. When you use a list comprehension, you create a list, and so an iterable:\n\n>>> mylist = [x*x for x in range(3)]\n>>> for i in mylist:\n...    print(i)\n0\n1\n4\n\n\nEverything you can use \"for... in...\" on is an iterable; lists, strings, files...\n\nThese iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.\n\nGenerators\n\nGenerators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly:\n\n>>> mygenerator = (x*x for x in range(3))\n>>> for i in mygenerator:\n...    print(i)\n0\n1\n4\n\n\nIt is just the same except you used () instead of []. BUT, you cannot perform for i in mygenerator a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one.\n\nYield\n\nyield is a keyword that is used like return, except the function will return a generator.\n\n>>> def create_generator():\n...    mylist = range(3)\n...    for i in mylist:\n...        yield i*i\n...\n>>> mygenerator = create_generator() # create a generator\n>>> print(mygenerator) # mygenerator is an object!\n<generator object create_generator at 0xb7555c34>\n>>> for i in mygenerator:\n...     print(i)\n0\n1\n4\n\n\nHere it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.\n\nTo master yield, you must understand that when you call the function, the code you have written in the function body does not run. The function only returns the generator object, this is a bit tricky.\n\nThen, your code will continue from where it left off each time for uses the generator.\n\nNow the hard part:\n\nThe first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting yield. That can be because the loop has come to an end, or because you no longer satisfy an \"if/else\".\n\nYour code explained\n\nGenerator:\n\n# Here you create the method of the node object that will return the generator\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n\n    # Here is the code that will be called each time you use the generator object:\n\n    # If there is still a child of the node object on its left\n    # AND if the distance is ok, return the next child\n    if self._leftchild and distance - max_dist < self._median:\n        yield self._leftchild\n\n    # If there is still a child of the node object on its right\n    # AND if the distance is ok, return the next child\n    if self._rightchild and distance + max_dist >= self._median:\n        yield self._rightchild\n\n    # If the function arrives here, the generator will be considered empty\n    # there is no more than two values: the left and the right children\n\n\nCaller:\n\n# Create an empty list and a list with the current object reference\nresult, candidates = list(), [self]\n\n# Loop on candidates (they contain only one element at the beginning)\nwhile candidates:\n\n    # Get the last candidate and remove it from the list\n    node = candidates.pop()\n\n    # Get the distance between obj and the candidate\n    distance = node._get_dist(obj)\n\n    # If distance is ok, then you can fill the result\n    if distance <= max_dist and distance >= min_dist:\n        result.extend(node._values)\n\n    # Add the children of the candidate in the candidate's list\n    # so the loop will keep running until it will have looked\n    # at all the children of the children of the children, etc. of the candidate\n    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))\n\nreturn result\n\n\nThis code contains several smart parts:\n\nThe loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) exhaust all the values of the generator, but while keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.\n\nThe extend() method is a list object method that expects an iterable and adds its values to the list.\n\nUsually we pass a list to it:\n\n>>> a = [1, 2]\n>>> b = [3, 4]\n>>> a.extend(b)\n>>> print(a)\n[1, 2, 3, 4]\n\n\nBut in your code, it gets a generator, which is good because:\n\nYou don't need to read the values twice.\nYou may have a lot of children and you don't want them all stored in memory.\n\nAnd it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...\n\nYou can stop here, or read a little bit to see an advanced use of a generator:\n\nControlling a generator exhaustion\n>>> class Bank(): # Let's create a bank, building ATMs\n...    crisis = False\n...    def create_atm(self):\n...        while not self.crisis:\n...            yield \"$100\"\n>>> hsbc = Bank() # When everything's ok the ATM gives you as much as you want\n>>> corner_street_atm = hsbc.create_atm()\n>>> print(corner_street_atm.next())\n$100\n>>> print(corner_street_atm.next())\n$100\n>>> print([corner_street_atm.next() for cash in range(5)])\n['$100', '$100', '$100', '$100', '$100']\n>>> hsbc.crisis = True # Crisis is coming, no more money!\n>>> print(corner_street_atm.next())\n<type 'exceptions.StopIteration'>\n>>> wall_street_atm = hsbc.create_atm() # It's even true for new ATMs\n>>> print(wall_street_atm.next())\n<type 'exceptions.StopIteration'>\n>>> hsbc.crisis = False # The trouble is, even post-crisis the ATM remains empty\n>>> print(corner_street_atm.next())\n<type 'exceptions.StopIteration'>\n>>> brand_new_atm = hsbc.create_atm() # Build a new one to get back in business\n>>> for cash in brand_new_atm:\n...    print cash\n$100\n$100\n$100\n$100\n$100\n$100\n$100\n$100\n$100\n...\n\n\nNote: For Python 3, useprint(corner_street_atm.__next__()) or print(next(corner_street_atm))\n\nIt can be useful for various things like controlling access to a resource.\n\nItertools, your best friend\n\nThe itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator? Chain two generators? Group values in a nested list with a one-liner? Map / Zip without creating another list?\n\nThen just import itertools.\n\nAn example? Let's see the possible orders of arrival for a four-horse race:\n\n>>> horses = [1, 2, 3, 4]\n>>> races = itertools.permutations(horses)\n>>> print(races)\n<itertools.permutations object at 0xb754f1dc>\n>>> print(list(itertools.permutations(horses)))\n[(1, 2, 3, 4),\n (1, 2, 4, 3),\n (1, 3, 2, 4),\n (1, 3, 4, 2),\n (1, 4, 2, 3),\n (1, 4, 3, 2),\n (2, 1, 3, 4),\n (2, 1, 4, 3),\n (2, 3, 1, 4),\n (2, 3, 4, 1),\n (2, 4, 1, 3),\n (2, 4, 3, 1),\n (3, 1, 2, 4),\n (3, 1, 4, 2),\n (3, 2, 1, 4),\n (3, 2, 4, 1),\n (3, 4, 1, 2),\n (3, 4, 2, 1),\n (4, 1, 2, 3),\n (4, 1, 3, 2),\n (4, 2, 1, 3),\n (4, 2, 3, 1),\n (4, 3, 1, 2),\n (4, 3, 2, 1)]\n\nUnderstanding the inner mechanisms of iteration\n\nIteration is a process implying iterables (implementing the __iter__() method) and iterators (implementing the __next__() method). Iterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.\n\nThere is more about it in this article about how for loops work.\n\nShare\nImprove this answer\nFollow\nedited Mar 7 at 12:59\nNeuron\n3,8373\n3 gold badges\n24\n24 silver badges\n44\n44 bronze badges\nanswered Oct 23 '08 at 22:48\ne-satis\n525k103\n103 gold badges\n284\n284 silver badges\n322\n322 bronze badges","comments":["yield is not as magical this answer suggests. When you call a function that contains a yield statement anywhere, you get a generator object, but no code runs. Then each time you extract an object from the generator, Python executes code in the function until it comes to a yield statement, then pauses and delivers the object. When you extract another object, Python resumes just after the yield and continues until it reaches another yield (often the same one, but one iteration later). This continues until the function runs off the end, at which point the generator is deemed exhausted.","\"These iterables are handy... but you store all the values in memory and this is not always what you want\", is either wrong or confusing. An iterable returns an iterator upon calling the iter() on the iterable, and an iterator doesn't always have to store its values in memory, depending on the implementation of the iter method, it can also generate values in the sequence on demand.","It would be nice to add to this great answer why It is just the same except you used () instead of [], specifically what () is (there may be confusion with a tuple).","@MatthiasFripp \"This continues until the function runs off the end\" -- or it encounters a return statement. (return is permitted in a function containing yield, provided that it does not specify a return value.)","The yield statement suspends function’s execution and sends a value back to the caller, but retains enough state to enable function to resume where it is left off. When resumed, the function continues execution immediately after the last yield run. This allows its code to produce a series of values over time, rather than computing them at once and sending them back like a list."]},{"answer":"Shortcut to understanding yield\n\nWhen you see a function with yield statements, apply this easy trick to understand what will happen:\n\nInsert a line result = [] at the start of the function.\nReplace each yield expr with result.append(expr).\nInsert a line return result at the bottom of the function.\nYay - no more yield statements! Read and figure out code.\nCompare function to the original definition.\n\nThis trick may give you an idea of the logic behind the function, but what actually happens with yield is significantly different than what happens in the list based approach. In many cases, the yield approach will be a lot more memory efficient and faster too. In other cases, this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more...\n\nDon't confuse your Iterables, Iterators, and Generators\n\nFirst, the iterator protocol - when you write\n\nfor x in mylist:\n    ...loop body...\n\n\nPython performs the following two steps:\n\nGets an iterator for mylist:\n\nCall iter(mylist) -> this returns an object with a next() method (or __next__() in Python 3).\n\n[This is the step most people forget to tell you about]\n\nUses the iterator to loop over items:\n\nKeep calling the next() method on the iterator returned from step 1. The return value from next() is assigned to x and the loop body is executed. If an exception StopIteration is raised from within next(), it means there are no more values in the iterator and the loop is exited.\n\nThe truth is Python performs the above two steps anytime it wants to loop over the contents of an object - so it could be a for loop, but it could also be code like otherlist.extend(mylist) (where otherlist is a Python list).\n\nHere mylist is an iterable because it implements the iterator protocol. In a user-defined class, you can implement the __iter__() method to make instances of your class iterable. This method should return an iterator. An iterator is an object with a next() method. It is possible to implement both __iter__() and next() on the same class, and have __iter__() return self. This will work for simple cases, but not when you want two iterators looping over the same object at the same time.\n\nSo that's the iterator protocol, many objects implement this protocol:\n\nBuilt-in lists, dictionaries, tuples, sets, files.\nUser-defined classes that implement __iter__().\nGenerators.\n\nNote that a for loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls next(). Built-in lists return their items one by one, dictionaries return the keys one by one, files return the lines one by one, etc. And generators return... well that's where yield comes in:\n\ndef f123():\n    yield 1\n    yield 2\n    yield 3\n\nfor item in f123():\n    print item\n\n\nInstead of yield statements, if you had three return statements in f123() only the first would get executed, and the function would exit. But f123() is no ordinary function. When f123() is called, it does not return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the for loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the yield it previously returned from, executes the next line of code, in this case, a yield statement, and returns that as the next item. This happens until the function exits, at which point the generator raises StopIteration, and the loop exits.\n\nSo the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing __iter__() and next() methods to keep the for loop happy. At the other end, however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode.\n\nWhy Use Generators?\n\nUsually, you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class SomethingIter that keeps the state in instance members and performs the next logical step in it's next() (or __next__() in Python 3) method. Depending on the logic, the code inside the next() method may end up looking very complex and be prone to bugs. Here generators provide a clean and easy solution.\n\nShare\nImprove this answer\nFollow\nedited May 13 '20 at 12:29\nnzz\n51\n1 silver badge\n2\n2 bronze badges\nanswered Oct 25 '08 at 21:22\nuser28409\n34.2k2\n2 gold badges\n15\n15 silver badges\n5\n5 bronze badges","comments":["\"When you see a function with yield statements, apply this easy trick to understand what will happen\" Doesn't this completely ignore the fact that you can send into a generator, which is a huge part of the point of generators?","\"it could be a for loop, but it could also be code like otherlist.extend(mylist)\" -> This is incorrect. extend() modifies the list in-place and does not return an iterable. Trying to loop over otherlist.extend(mylist) will fail with a TypeError because extend() implicitly returns None, and you can't loop over None.","@pedro You have misunderstood that sentence. It means that python performs the two mentioned steps on mylist (not on otherlist) when executing otherlist.extend(mylist)."]},{"answer":"Think of it this way:\n\nAn iterator is just a fancy sounding term for an object that has a next() method. So a yield-ed function ends up being something like this:\n\nOriginal version:\n\ndef some_function():\n    for i in xrange(4):\n        yield i\n\nfor i in some_function():\n    print i\n\n\nThis is basically what the Python interpreter does with the above code:\n\nclass it:\n    def __init__(self):\n        # Start at -1 so that we get 0 when we add 1 below.\n        self.count = -1\n\n    # The __iter__ method will be called once by the 'for' loop.\n    # The rest of the magic happens on the object returned by this method.\n    # In this case it is the object itself.\n    def __iter__(self):\n        return self\n\n    # The next method will be called repeatedly by the 'for' loop\n    # until it raises StopIteration.\n    def next(self):\n        self.count += 1\n        if self.count < 4:\n            return self.count\n        else:\n            # A StopIteration exception is raised\n            # to signal that the iterator is done.\n            # This is caught implicitly by the 'for' loop.\n            raise StopIteration\n\ndef some_func():\n    return it()\n\nfor i in some_func():\n    print i\n\n\nFor more insight as to what's happening behind the scenes, the for loop can be rewritten to this:\n\niterator = some_func()\ntry:\n    while 1:\n        print iterator.next()\nexcept StopIteration:\n    pass\n\n\nDoes that make more sense or just confuse you more? :)\n\nI should note that this is an oversimplification for illustrative purposes. :)\n\nShare\nImprove this answer\nFollow\nedited May 7 '19 at 13:28\nGeorgy\n6,8417\n7 gold badges\n49\n49 silver badges\n59\n59 bronze badges\nanswered Oct 23 '08 at 22:28\nJason Baker\n174k123\n123 gold badges\n355\n355 silver badges\n502\n502 bronze badges","comments":["__getitem__ could be defined instead of __iter__. For example: class it: pass; it.__getitem__ = lambda self, i: i*10 if i < 10 else [][0]; for i in it(): print(i), It will print: 0, 10, 20, ..., 90","I tried this example in Python 3.6 and if I create iterator = some_function(), the variable iterator does not have a function called next() anymore, but only a __next__() function. Thought I'd mention it.","Where does the for loop implementation you wrote call the __iter__ method of iterator, the instantiated instance of it?","Unfortunately this answer is not true at all. This is not what python interpreter does with generators. It is not creating a class starting from the generator function and implement __iter__ and __next__. What it is acutally doing under the hood is explained in this post stackoverflow.com/questions/45723893/…. To cite @Raymond Hettinger \"generators are not implemented internally as shown in your pure python class. Instead, they share most of the same logic as regular functions\""]},{"answer":"The yield keyword is reduced to two simple facts:\n\nIf the compiler detects the yield keyword anywhere inside a function, that function no longer returns via the return statement. Instead, it immediately returns a lazy \"pending list\" object called a generator\nA generator is iterable. What is an iterable? It's anything like a list or set or range or dict-view, with a built-in protocol for visiting each element in a certain order.\n\nIn a nutshell: a generator is a lazy, incrementally-pending list, and yield statements allow you to use function notation to program the list values the generator should incrementally spit out.\n\ngenerator = myYieldingFunction(...)\nx = list(generator)\n\n   generator\n       v\n[x[0], ..., ???]\n\n         generator\n             v\n[x[0], x[1], ..., ???]\n\n               generator\n                   v\n[x[0], x[1], x[2], ..., ???]\n\n                       StopIteration exception\n[x[0], x[1], x[2]]     done\n\nlist==[x[0], x[1], x[2]]\n\nExample\n\nLet's define a function makeRange that's just like Python's range. Calling makeRange(n) RETURNS A GENERATOR:\n\ndef makeRange(n):\n    # return 0,1,2,...,n-1\n    i = 0\n    while i < n:\n        yield i\n        i += 1\n\n>>> makeRange(5)\n<generator object makeRange at 0x19e4aa0>\n\n\nTo force the generator to immediately return its pending values, you can pass it into list() (just like you could any iterable):\n\n>>> list(makeRange(5))\n[0, 1, 2, 3, 4]\n\nComparing example to \"just returning a list\"\n\nThe above example can be thought of as merely creating a list which you append to and return:\n\n# list-version                   #  # generator-version\ndef makeRange(n):                #  def makeRange(n):\n    \"\"\"return [0,1,2,...,n-1]\"\"\" #~     \"\"\"return 0,1,2,...,n-1\"\"\"\n    TO_RETURN = []               #>\n    i = 0                        #      i = 0\n    while i < n:                 #      while i < n:\n        TO_RETURN += [i]         #~         yield i\n        i += 1                   #          i += 1  ## indented\n    return TO_RETURN             #>\n\n>>> makeRange(5)\n[0, 1, 2, 3, 4]\n\n\nThere is one major difference, though; see the last section.\n\nHow you might use generators\n\nAn iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so:\n\n#                   _ITERABLE_\n>>> [x+10 for x in makeRange(5)]\n[10, 11, 12, 13, 14]\n\n\nTo get a better feel for generators, you can play around with the itertools module (be sure to use chain.from_iterable rather than chain when warranted). For example, you might even use generators to implement infinitely-long lazy lists like itertools.count(). You could implement your own def enumerate(iterable): zip(count(), iterable), or alternatively do so with the yield keyword in a while-loop.\n\nPlease note: generators can actually be used for many more things, such as implementing coroutines or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find.\n\nBehind the scenes\n\nThis is how the \"Python iteration protocol\" works. That is, what is going on when you do list(makeRange(5)). This is what I describe earlier as a \"lazy, incremental list\".\n\n>>> x=iter(range(5))\n>>> next(x)\n0\n>>> next(x)\n1\n>>> next(x)\n2\n>>> next(x)\n3\n>>> next(x)\n4\n>>> next(x)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nStopIteration\n\n\nThe built-in function next() just calls the objects .next() function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the next() function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that...\n\nMinutiae\n\nNormally, most people would not care about the following distinctions and probably want to stop reading here.\n\nIn Python-speak, an iterable is any object which \"understands the concept of a for-loop\" like a list [1,2,3], and an iterator is a specific instance of the requested for-loop like [1,2,3].__iter__(). A generator is exactly the same as any iterator, except for the way it was written (with function syntax).\n\nWhen you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself.\n\nThus, in the unlikely event that you are failing to do something like this...\n\n> x = myRange(5)\n> list(x)\n[0, 1, 2, 3, 4]\n> list(x)\n[]\n\n\n... then remember that a generator is an iterator; that is, it is one-time-use. If you want to reuse it, you should call myRange(...) again. If you need to use the result twice, convert the result to a list and store it in a variable x = list(myRange(5)). Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use itertools.tee if absolutely necessary, since the copyable iterator Python PEP standards proposal has been deferred.\n\nShare\nImprove this answer\nFollow\nedited Mar 19 '17 at 8:07\nWansen\n239\n9 bronze badges\nanswered Jun 19 '11 at 6:33\nninjagecko\n78.9k22\n22 gold badges\n131\n131 silver badges\n140\n140 bronze badges","comments":[]},{"answer":"What does the yield keyword do in Python?\n\nAnswer Outline/Summary\nA function with yield, when called, returns a Generator.\nGenerators are iterators because they implement the iterator protocol, so you can iterate over them.\nA generator can also be sent information, making it conceptually a coroutine.\nIn Python 3, you can delegate from one generator to another in both directions with yield from.\n(Appendix critiques a couple of answers, including the top one, and discusses the use of return in a generator.)\nGenerators:\n\nyield is only legal inside of a function definition, and the inclusion of yield in a function definition makes it return a generator.\n\nThe idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is frozen at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield.\n\nyield provides an easy way of implementing the iterator protocol, defined by the following two methods: __iter__ and next (Python 2) or __next__ (Python 3). Both of those methods make an object an iterator that you could type-check with the Iterator Abstract Base Class from the collections module.\n\n>>> def func():\n...     yield 'I am'\n...     yield 'a generator!'\n... \n>>> type(func)                 # A function with yield is still a function\n<type 'function'>\n>>> gen = func()\n>>> type(gen)                  # but it returns a generator\n<type 'generator'>\n>>> hasattr(gen, '__iter__')   # that's an iterable\nTrue\n>>> hasattr(gen, 'next')       # and with .next (.__next__ in Python 3)\nTrue                           # implements the iterator protocol.\n\n\nThe generator type is a sub-type of iterator:\n\n>>> import collections, types\n>>> issubclass(types.GeneratorType, collections.Iterator)\nTrue\n\n\nAnd if necessary, we can type-check like this:\n\n>>> isinstance(gen, types.GeneratorType)\nTrue\n>>> isinstance(gen, collections.Iterator)\nTrue\n\n\nA feature of an Iterator is that once exhausted, you can't reuse or reset it:\n\n>>> list(gen)\n['I am', 'a generator!']\n>>> list(gen)\n[]\n\n\nYou'll have to make another if you want to use its functionality again (see footnote 2):\n\n>>> list(func())\n['I am', 'a generator!']\n\n\nOne can yield data programmatically, for example:\n\ndef func(an_iterable):\n    for item in an_iterable:\n        yield item\n\n\nThe above simple generator is also equivalent to the below - as of Python 3.3 (and not available in Python 2), you can use yield from:\n\ndef func(an_iterable):\n    yield from an_iterable\n\n\nHowever, yield from also allows for delegation to subgenerators, which will be explained in the following section on cooperative delegation with sub-coroutines.\n\nCoroutines:\n\nyield forms an expression that allows data to be sent into the generator (see footnote 3)\n\nHere is an example, take note of the received variable, which will point to the data that is sent to the generator:\n\ndef bank_account(deposited, interest_rate):\n    while True:\n        calculated_interest = interest_rate * deposited \n        received = yield calculated_interest\n        if received:\n            deposited += received\n\n\n>>> my_account = bank_account(1000, .05)\n\n\nFirst, we must queue up the generator with the builtin function, next. It will call the appropriate next or __next__ method, depending on the version of Python you are using:\n\n>>> first_year_interest = next(my_account)\n>>> first_year_interest\n50.0\n\n\nAnd now we can send data into the generator. (Sending None is the same as calling next.) :\n\n>>> next_year_interest = my_account.send(first_year_interest + 1000)\n>>> next_year_interest\n102.5\n\nCooperative Delegation to Sub-Coroutine with yield from\n\nNow, recall that yield from is available in Python 3. This allows us to delegate coroutines to a subcoroutine:\n\n\ndef money_manager(expected_rate):\n    # must receive deposited value from .send():\n    under_management = yield                   # yield None to start.\n    while True:\n        try:\n            additional_investment = yield expected_rate * under_management \n            if additional_investment:\n                under_management += additional_investment\n        except GeneratorExit:\n            '''TODO: write function to send unclaimed funds to state'''\n            raise\n        finally:\n            '''TODO: write function to mail tax info to client'''\n        \n\ndef investment_account(deposited, manager):\n    '''very simple model of an investment account that delegates to a manager'''\n    # must queue up manager:\n    next(manager)      # <- same as manager.send(None)\n    # This is where we send the initial deposit to the manager:\n    manager.send(deposited)\n    try:\n        yield from manager\n    except GeneratorExit:\n        return manager.close()  # delegate?\n\n\nAnd now we can delegate functionality to a sub-generator and it can be used by a generator just as above:\n\nmy_manager = money_manager(.06)\nmy_account = investment_account(1000, my_manager)\nfirst_year_return = next(my_account) # -> 60.0\n\n\nNow simulate adding another 1,000 to the account plus the return on the account (60.0):\n\nnext_year_return = my_account.send(first_year_return + 1000)\nnext_year_return # 123.6\n\n\nYou can read more about the precise semantics of yield from in PEP 380.\n\nOther Methods: close and throw\n\nThe close method raises GeneratorExit at the point the function execution was frozen. This will also be called by __del__ so you can put any cleanup code where you handle the GeneratorExit:\n\nmy_account.close()\n\n\nYou can also throw an exception which can be handled in the generator or propagated back to the user:\n\nimport sys\ntry:\n    raise ValueError\nexcept:\n    my_manager.throw(*sys.exc_info())\n\n\nRaises:\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 4, in <module>\n  File \"<stdin>\", line 6, in money_manager\n  File \"<stdin>\", line 2, in <module>\nValueError\n\nConclusion\n\nI believe I have covered all aspects of the following question:\n\nWhat does the yield keyword do in Python?\n\nIt turns out that yield does a lot. I'm sure I could add even more thorough examples to this. If you want more or have some constructive criticism, let me know by commenting below.\n\nAppendix:\nCritique of the Top/Accepted Answer**\nIt is confused on what makes an iterable, just using a list as an example. See my references above, but in summary: an iterable has an __iter__ method returning an iterator. An iterator provides a .next (Python 2 or .__next__ (Python 3) method, which is implicitly called by for loops until it raises StopIteration, and once it does, it will continue to do so.\nIt then uses a generator expression to describe what a generator is. Since a generator is simply a convenient way to create an iterator, it only confuses the matter, and we still have not yet gotten to the yield part.\nIn Controlling a generator exhaustion he calls the .next method, when instead he should use the builtin function, next. It would be an appropriate layer of indirection, because his code does not work in Python 3.\nItertools? This was not relevant to what yield does at all.\nNo discussion of the methods that yield provides along with the new functionality yield from in Python 3. The top/accepted answer is a very incomplete answer.\nCritique of answer suggesting yield in a generator expression or comprehension.\n\nThe grammar currently allows any expression in a list comprehension.\n\nexpr_stmt: testlist_star_expr (annassign | augassign (yield_expr|testlist) |\n                     ('=' (yield_expr|testlist_star_expr))*)\n...\nyield_expr: 'yield' [yield_arg]\nyield_arg: 'from' test | testlist\n\n\nSince yield is an expression, it has been touted by some as interesting to use it in comprehensions or generator expression - in spite of citing no particularly good use-case.\n\nThe CPython core developers are discussing deprecating its allowance. Here's a relevant post from the mailing list:\n\nOn 30 January 2017 at 19:05, Brett Cannon wrote:\n\nOn Sun, 29 Jan 2017 at 16:39 Craig Rodrigues wrote:\n\nI'm OK with either approach. Leaving things the way they are in Python 3 is no good, IMHO.\n\nMy vote is it be a SyntaxError since you're not getting what you expect from the syntax.\n\nI'd agree that's a sensible place for us to end up, as any code relying on the current behaviour is really too clever to be maintainable.\n\nIn terms of getting there, we'll likely want:\n\nSyntaxWarning or DeprecationWarning in 3.7\nPy3k warning in 2.7.x\nSyntaxError in 3.8\n\nCheers, Nick.\n\n-- Nick Coghlan | ncoghlan at gmail.com | Brisbane, Australia\n\nFurther, there is an outstanding issue (10544) which seems to be pointing in the direction of this never being a good idea (PyPy, a Python implementation written in Python, is already raising syntax warnings.)\n\nBottom line, until the developers of CPython tell us otherwise: Don't put yield in a generator expression or comprehension.\n\nThe return statement in a generator\n\nIn Python 2:\n\nIn a generator function, the return statement is not allowed to include an expression_list. In that context, a bare return indicates that the generator is done and will cause StopIteration to be raised.\n\nAn expression_list is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with return, but you can't return a value.\n\nIn Python 3:\n\nIn a generator function, the return statement indicates that the generator is done and will cause StopIteration to be raised. The returned value (if any) is used as an argument to construct StopIteration and becomes the StopIteration.value attribute.\n\nFootnotes\n\nThe languages CLU, Sather, and Icon were referenced in the proposal to introduce the concept of generators to Python. The general idea is that a function can maintain internal state and yield intermediate data points on demand by the user. This promised to be superior in performance to other approaches, including Python threading, which isn't even available on some systems.\n\nThis means, for example, that range objects aren't Iterators, even though they are iterable, because they can be reused. Like lists, their __iter__ methods return iterator objects.\n\nyield was originally introduced as a statement, meaning that it could only appear at the beginning of a line in a code block. Now yield creates a yield expression. https://docs.python.org/2/reference/simple_stmts.html#grammar-token-yield_stmt This change was proposed to allow a user to send data into the generator just as one might receive it. To send data, one must be able to assign it to something, and for that, a statement just won't work.\n\nShare\nImprove this answer\nFollow\nedited Jan 24 at 4:44\nanswered Jun 25 '15 at 6:11\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":[]},{"answer":"yield is just like return - it returns whatever you tell it to (as a generator). The difference is that the next time you call the generator, execution starts from the last call to the yield statement. Unlike return, the stack frame is not cleaned up when a yield occurs, however control is transferred back to the caller, so its state will resume the next time the function is called.\n\nIn the case of your code, the function get_child_candidates is acting like an iterator so that when you extend your list, it adds one element at a time to the new list.\n\nlist.extend calls an iterator until it's exhausted. In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list.\n\nShare\nImprove this answer\nFollow\nedited Jan 24 '19 at 9:39\nFang\n1,7692\n2 gold badges\n19\n19 silver badges\n37\n37 bronze badges\nanswered Oct 23 '08 at 22:24\nDouglas Mayle\n18.5k7\n7 gold badges\n40\n40 silver badges\n57\n57 bronze badges","comments":["This is close, but not correct. Every time you call a function with a yield statement in it, it returns a brand new generator object. It's only when you call that generator's .next() method that execution resumes after the last yield."]},{"answer":"There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this:\n\ndef fib():\n    last, cur = 0, 1\n    while True: \n        yield cur\n        last, cur = cur, last + cur\n\n\nThen I can use it in other code like this:\n\nfor f in fib():\n    if some_condition: break\n    coolfuncs(f);\n\n\nIt really helps simplify some problems, and makes some things easier to work with.\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '13 at 15:42\nanswered Oct 24 '08 at 8:44\nClaudiu\n209k155\n155 gold badges\n451\n451 silver badges\n657\n657 bronze badges","comments":[]},{"answer":"For those who prefer a minimal working example, meditate on this interactive Python session:\n\n>>> def f():\n...   yield 1\n...   yield 2\n...   yield 3\n... \n>>> g = f()\n>>> for i in g:\n...   print(i)\n... \n1\n2\n3\n>>> for i in g:\n...   print(i)\n... \n>>> # Note that this time nothing was printed\n\nShare\nImprove this answer\nFollow\nedited Feb 2 '20 at 22:09\nOren\n2,6313\n3 gold badges\n25\n25 silver badges\n50\n50 bronze badges\nanswered Jan 18 '13 at 17:25\nDaniel\n2,9261\n1 gold badge\n11\n11 silver badges\n3\n3 bronze badges","comments":[]},{"answer":"TL;DR\n\nInstead of this:\ndef square_list(n):\n    the_list = []                         # Replace\n    for x in range(n):\n        y = x * x\n        the_list.append(y)                # these\n    return the_list                       # lines\n\ndo this:\ndef square_yield(n):\n    for x in range(n):\n        y = x * x\n        yield y                           # with this one.\n\n\nWhenever you find yourself building a list from scratch, yield each piece instead.\n\nThis was my first \"aha\" moment with yield.\n\nyield is a sugary way to say\n\nbuild a series of stuff\n\nSame behavior:\n\n>>> for square in square_list(4):\n...     print(square)\n...\n0\n1\n4\n9\n>>> for square in square_yield(4):\n...     print(square)\n...\n0\n1\n4\n9\n\n\nDifferent behavior:\n\nYield is single-pass: you can only iterate through once. When a function has a yield in it we call it a generator function. And an iterator is what it returns. Those terms are revealing. We lose the convenience of a container, but gain the power of a series that's computed as needed, and arbitrarily long.\n\nYield is lazy, it puts off computation. A function with a yield in it doesn't actually execute at all when you call it. It returns an iterator object that remembers where it left off. Each time you call next() on the iterator (this happens in a for-loop) execution inches forward to the next yield. return raises StopIteration and ends the series (this is the natural end of a for-loop).\n\nYield is versatile. Data doesn't have to be stored all together, it can be made available one at a time. It can be infinite.\n\n>>> def squares_all_of_them():\n...     x = 0\n...     while True:\n...         yield x * x\n...         x += 1\n...\n>>> squares = squares_all_of_them()\n>>> for _ in range(4):\n...     print(next(squares))\n...\n0\n1\n4\n9\n\n\nIf you need multiple passes and the series isn't too long, just call list() on it:\n\n>>> list(square_yield(4))\n[0, 1, 4, 9]\n\n\nBrilliant choice of the word yield because both meanings apply:\n\nyield — produce or provide (as in agriculture)\n\n...provide the next data in the series.\n\nyield — give way or relinquish (as in political power)\n\n...relinquish CPU execution until the iterator advances.\n\nShare\nImprove this answer\nFollow\nedited Jan 4 '19 at 15:30\nanswered Mar 25 '16 at 13:21\nBob Stein\n13.1k8\n8 gold badges\n74\n74 silver badges\n92\n92 bronze badges","comments":[]},{"answer":"Yield gives you a generator.\n\ndef get_odd_numbers(i):\n    return range(1, i, 2)\ndef yield_odd_numbers(i):\n    for x in range(1, i, 2):\n       yield x\nfoo = get_odd_numbers(10)\nbar = yield_odd_numbers(10)\nfoo\n[1, 3, 5, 7, 9]\nbar\n<generator object yield_odd_numbers at 0x1029c6f50>\nbar.next()\n1\nbar.next()\n3\nbar.next()\n5\n\n\nAs you can see, in the first case foo holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called.\n\nIn the second case, bar just gives you a generator. A generator is an iterable--which means you can use it in a for loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through.\n\nAgain, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :)\n\nThis is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things.\n\nShare\nImprove this answer\nFollow\nedited Mar 13 '19 at 6:04\nAndreas\n2,30010\n10 gold badges\n19\n19 silver badges\n23\n23 bronze badges\nanswered Jan 16 '13 at 6:42\nRBansal\n2,1791\n1 gold badge\n10\n10 silver badges\n3\n3 bronze badges","comments":["Just a note - in Python 3, range also returns a generator instead of a list, so you'd also see a similar idea, except that __repr__/__str__ are overridden to show a nicer result, in this case range(1, 10, 2)."]},{"answer":"It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as C#'s iterator blocks if you're familiar with those.\n\nThe key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values - as if the generator method was paused. Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself.\n\nShare\nImprove this answer\nFollow\nedited Oct 31 '18 at 8:42\nanswered Oct 23 '08 at 22:26\nJon Skeet\n1.3m800\n800 gold badges\n8772\n8772 silver badges\n8958\n8958 bronze badges","comments":[]},{"answer":"There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators. Here is the programming language theory answer:\n\nThe yield statement in Python returns a generator. A generator in Python is a function that returns continuations (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on).\n\nContinuations in programming languages theory are a much more fundamental kind of computation, but they are not often used, because they are extremely hard to reason about and also very difficult to implement. But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state, the current values of variables, the operations that have yet to be performed, and so on, are saved. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out.\n\nContinuations, in this more general form, can be implemented in two ways. In the call/cc way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored.\n\nIn continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows:\n\ndef save_file(filename):\n  def write_file_continuation():\n    write_stuff_to_file(filename)\n\n  check_if_file_exists_and_user_wants_to_overwrite(write_file_continuation)\n\n\nIn this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger.)\n\nThe rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read.\n\n\n\n\nNow let's talk about generators in Python. Generators are a specific subtype of continuation. Whereas continuations are able in general to save the state of a computation (i.e., the program's call stack), generators are only able to save the state of iteration over an iterator. Although, this definition is slightly misleading for certain use cases of generators. For instance:\n\ndef f():\n  while True:\n    yield 4\n\n\nThis is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e., for x in collection: do_something(x)). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration.\n\nTo reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand this page about continuations and call/cc).\n\nBut you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style:\n\nWhenever yield is called, it tells the function to return a continuation. When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode (i.e., not pseudocode, but not code) the generator's next method is basically as follows:\n\nclass Generator():\n  def __init__(self,iterable,generatorfun):\n    self.next_continuation = lambda:generatorfun(iterable)\n\n  def next(self):\n    value, next_continuation = self.next_continuation()\n    self.next_continuation = next_continuation\n    return value\n\n\nwhere the yield keyword is actually syntactic sugar for the real generator function, basically something like:\n\ndef generatorfun(iterable):\n  if len(iterable) == 0:\n    raise StopIteration\n  else:\n    return (iterable[0], lambda:generatorfun(iterable[1:]))\n\n\nRemember that this is just pseudocode and the actual implementation of generators in Python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the yield keyword.\n\nShare\nImprove this answer\nFollow\nedited May 20 '18 at 10:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 4 '13 at 14:56\naestrivex\n4,7201\n1 gold badge\n23\n23 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"Here is an example in plain language. I will provide a correspondence between high-level human concepts to low-level Python concepts.\n\nI want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following:\n\nI call you and tell you that I want a sequence of numbers which is produced in a specific way, and I let you know what the algorithm is.\nThis step corresponds to defining the generator function, i.e. the function containing a yield.\nSometime later, I tell you, \"OK, get ready to tell me the sequence of numbers\".\nThis step corresponds to calling the generator function which returns a generator object. Note that you don't tell me any numbers yet; you just grab your paper and pencil.\nI ask you, \"tell me the next number\", and you tell me the first number; after that, you wait for me to ask you for the next number. It's your job to remember where you were, what numbers you have already said, and what is the next number. I don't care about the details.\nThis step corresponds to calling .next() on the generator object.\n… repeat previous step, until…\neventually, you might come to an end. You don't tell me a number; you just shout, \"hold your horses! I'm done! No more numbers!\"\nThis step corresponds to the generator object ending its job, and raising a StopIteration exception The generator function does not need to raise the exception. It's raised automatically when the function ends or issues a return.\n\nThis is what a generator does (a function that contains a yield); it starts executing, pauses whenever it does a yield, and when asked for a .next() value it continues from the point it was last. It fits perfectly by design with the iterator protocol of Python, which describes how to sequentially request values.\n\nThe most famous user of the iterator protocol is the for command in Python. So, whenever you do a:\n\nfor item in sequence:\n\n\nit doesn't matter if sequence is a list, a string, a dictionary or a generator object like described above; the result is the same: you read items off a sequence one by one.\n\nNote that defining a function which contains a yield keyword is not the only way to create a generator; it's just the easiest way to create one.\n\nFor more accurate information, read about iterator types, the yield statement and generators in the Python documentation.\n\nShare\nImprove this answer\nFollow\nedited May 20 '18 at 10:06\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 24 '08 at 0:36\ntzot\n82.6k26\n26 gold badges\n131\n131 silver badges\n197\n197 bronze badges","comments":[]},{"answer":"While a lot of answers show why you'd use a yield to create a generator, there are more uses for yield. It's quite easy to make a coroutine, which enables the passing of information between two blocks of code. I won't repeat any of the fine examples that have already been given about using yield to create a generator.\n\nTo help understand what a yield does in the following code, you can use your finger to trace the cycle through any code that has a yield. Every time your finger hits the yield, you have to wait for a next or a send to be entered. When a next is called, you trace through the code until you hit the yield… the code on the right of the yield is evaluated and returned to the caller… then you wait. When next is called again, you perform another loop through the code. However, you'll note that in a coroutine, yield can also be used with a send… which will send a value from the caller into the yielding function. If a send is given, then yield receives the value sent, and spits it out the left hand side… then the trace through the code progresses until you hit the yield again (returning the value at the end, as if next was called).\n\nFor example:\n\n>>> def coroutine():\n...     i = -1\n...     while True:\n...         i += 1\n...         val = (yield i)\n...         print(\"Received %s\" % val)\n...\n>>> sequence = coroutine()\n>>> sequence.next()\n0\n>>> sequence.next()\nReceived None\n1\n>>> sequence.send('hello')\nReceived hello\n2\n>>> sequence.close()\n\nShare\nImprove this answer\nFollow\nanswered Feb 4 '14 at 2:27\nMike McKerns\n28.1k7\n7 gold badges\n105\n105 silver badges\n127\n127 bronze badges","comments":["Cute! A trampoline (in the Lisp sense). Not often one sees those!"]},{"answer":"There is another yield use and meaning (since Python 3.3):\n\nyield from <expr>\n\n\nFrom PEP 380 -- Syntax for Delegating to a Subgenerator:\n\nA syntax is proposed for a generator to delegate part of its operations to another generator. This allows a section of code containing 'yield' to be factored out and placed in another generator. Additionally, the subgenerator is allowed to return with a value, and the value is made available to the delegating generator.\n\nThe new syntax also opens up some opportunities for optimisation when one generator re-yields values produced by another.\n\nMoreover this will introduce (since Python 3.5):\n\nasync def new_coroutine(data):\n   ...\n   await blocking_action()\n\n\nto avoid coroutines being confused with a regular generator (today yield is used in both).\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jul 24 '14 at 21:15\nSławomir Lenart\n5,3772\n2 gold badges\n33\n33 silver badges\n47\n47 bronze badges","comments":[]},{"answer":"All great answers, however a bit difficult for newbies.\n\nI assume you have learned the return statement.\n\nAs an analogy, return and yield are twins. return means 'return and stop' whereas 'yield` means 'return, but continue'\n\nTry to get a num_list with return.\ndef num_list(n):\n    for i in range(n):\n        return i\n\n\nRun it:\n\nIn [5]: num_list(3)\nOut[5]: 0\n\n\nSee, you get only a single number rather than a list of them. return never allows you prevail happily, just implements once and quit.\n\nThere comes yield\n\nReplace return with yield:\n\nIn [10]: def num_list(n):\n    ...:     for i in range(n):\n    ...:         yield i\n    ...:\n\nIn [11]: num_list(3)\nOut[11]: <generator object num_list at 0x10327c990>\n\nIn [12]: list(num_list(3))\nOut[12]: [0, 1, 2]\n\n\nNow, you win to get all the numbers.\n\nComparing to return which runs once and stops, yield runs times you planed. You can interpret return as return one of them, and yield as return all of them. This is called iterable.\n\nOne more step we can rewrite yield statement with return\nIn [15]: def num_list(n):\n    ...:     result = []\n    ...:     for i in range(n):\n    ...:         result.append(i)\n    ...:     return result\n\nIn [16]: num_list(3)\nOut[16]: [0, 1, 2]\n\n\nIt's the core about yield.\n\nThe difference between a list return outputs and the object yield output is:\n\nYou will always get [0, 1, 2] from a list object but only could retrieve them from 'the object yield output' once. So, it has a new name generator object as displayed in Out[11]: <generator object num_list at 0x10327c990>.\n\nIn conclusion, as a metaphor to grok it:\n\nreturn and yield are twins\nlist and generator are twins\nShare\nImprove this answer\nFollow\nedited May 28 '18 at 9:06\nanswered Nov 14 '17 at 12:02\nAbstProcDo\n15k14\n14 gold badges\n54\n54 silver badges\n99\n99 bronze badges","comments":["This is understandable, but one major difference is that you can have multiple yields in a function/method. The analogy totally breaks down at that point. Yield remembers its place in a function, so the next time you call next(), your function continues on to the next yield. This is important, I think, and should be expressed."]},{"answer":"From a programming viewpoint, the iterators are implemented as thunks.\n\nTo implement iterators, generators, and thread pools for concurrent execution, etc. as thunks, one uses messages sent to a closure object, which has a dispatcher, and the dispatcher answers to \"messages\".\n\n\"next\" is a message sent to a closure, created by the \"iter\" call.\n\nThere are lots of ways to implement this computation. I used mutation, but it is possible to do this kind of computation without mutation, by returning the current value and the next yielder (making it referential transparent). Racket uses a sequence of transformations of the initial program in some intermediary languages, one of such rewriting making the yield operator to be transformed in some language with simpler operators.\n\nHere is a demonstration of how yield could be rewritten, which uses the structure of R6RS, but the semantics is identical to Python's. It's the same model of computation, and only a change in syntax is required to rewrite it using yield of Python.\n\nWelcome to Racket v6.5.0.3.\n\n-> (define gen\n     (lambda (l)\n       (define yield\n         (lambda ()\n           (if (null? l)\n               'END\n               (let ((v (car l)))\n                 (set! l (cdr l))\n                 v))))\n       (lambda(m)\n         (case m\n           ('yield (yield))\n           ('init  (lambda (data)\n                     (set! l data)\n                     'OK))))))\n-> (define stream (gen '(1 2 3)))\n-> (stream 'yield)\n1\n-> (stream 'yield)\n2\n-> (stream 'yield)\n3\n-> (stream 'yield)\n'END\n-> ((stream 'init) '(a b))\n'OK\n-> (stream 'yield)\n'a\n-> (stream 'yield)\n'b\n-> (stream 'yield)\n'END\n-> (stream 'yield)\n'END\n->\n\nShare\nImprove this answer\nFollow\nedited Jul 2 '20 at 7:36\nanswered Aug 21 '13 at 19:01\nalinsoar\n13.3k4\n4 gold badges\n47\n47 silver badges\n63\n63 bronze badges","comments":[]},{"answer":"Here are some Python examples of how to actually implement generators as if Python did not provide syntactic sugar for them:\n\nAs a Python generator:\n\nfrom itertools import islice\n\ndef fib_gen():\n    a, b = 1, 1\n    while True:\n        yield a\n        a, b = b, a + b\n\nassert [1, 1, 2, 3, 5] == list(islice(fib_gen(), 5))\n\n\nUsing lexical closures instead of generators\n\ndef ftake(fnext, last):\n    return [fnext() for _ in xrange(last)]\n\ndef fib_gen2():\n    #funky scope due to python2.x workaround\n    #for python 3.x use nonlocal\n    def _():\n        _.a, _.b = _.b, _.a + _.b\n        return _.a\n    _.a, _.b = 0, 1\n    return _\n\nassert [1,1,2,3,5] == ftake(fib_gen2(), 5)\n\n\nUsing object closures instead of generators (because ClosuresAndObjectsAreEquivalent)\n\nclass fib_gen3:\n    def __init__(self):\n        self.a, self.b = 1, 1\n\n    def __call__(self):\n        r = self.a\n        self.a, self.b = self.b, self.a + self.b\n        return r\n\nassert [1,1,2,3,5] == ftake(fib_gen3(), 5)\n\nShare\nImprove this answer\nFollow\nedited Oct 24 '17 at 10:46\nanswered Oct 3 '12 at 20:38\nDustin Getz\n20.1k13\n13 gold badges\n77\n77 silver badges\n127\n127 bronze badges","comments":[]},{"answer":"I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already.\n\nAlso, note that yield can be used in coroutines as the dual of their use in generator functions. Although it isn't the same use as your code snippet, (yield) can be used as an expression in a function. When a caller sends a value to the method using the send() method, then the coroutine will execute until the next (yield) statement is encountered.\n\nGenerators and coroutines are a cool way to set up data-flow type applications. I thought it would be worthwhile knowing about the other use of the yield statement in functions.\n\nShare\nImprove this answer\nFollow\nanswered Jan 28 '13 at 1:37\njohnzachary\n2,2952\n2 gold badges\n17\n17 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"Here is a simple example:\n\ndef isPrimeNumber(n):\n    print \"isPrimeNumber({}) call\".format(n)\n    if n==1:\n        return False\n    for x in range(2,n):\n        if n % x == 0:\n            return False\n    return True\n\ndef primes (n=1):\n    while(True):\n        print \"loop step ---------------- {}\".format(n)\n        if isPrimeNumber(n): yield n\n        n += 1\n\nfor n in primes():\n    if n> 10:break\n    print \"wiriting result {}\".format(n)\n\n\nOutput:\n\nloop step ---------------- 1\nisPrimeNumber(1) call\nloop step ---------------- 2\nisPrimeNumber(2) call\nloop step ---------------- 3\nisPrimeNumber(3) call\nwiriting result 3\nloop step ---------------- 4\nisPrimeNumber(4) call\nloop step ---------------- 5\nisPrimeNumber(5) call\nwiriting result 5\nloop step ---------------- 6\nisPrimeNumber(6) call\nloop step ---------------- 7\nisPrimeNumber(7) call\nwiriting result 7\nloop step ---------------- 8\nisPrimeNumber(8) call\nloop step ---------------- 9\nisPrimeNumber(9) call\nloop step ---------------- 10\nisPrimeNumber(10) call\nloop step ---------------- 11\nisPrimeNumber(11) call\n\n\nI am not a Python developer, but it looks to me yield holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work.\n\nIt seems to be an interesting and nice ability :D\n\nShare\nImprove this answer\nFollow\nedited May 20 '18 at 10:31\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 20 '13 at 13:07\nEngin OZTURK\n1,9251\n1 gold badge\n20\n20 silver badges\n12\n12 bronze badges","comments":["You are correct. But what is the effect on flow which is to see the behaviour of \"yield\" ? I can change the algorithm in the name of mathmatics. Will it help to get different assessment of \"yield\" ?"]},{"answer":"Here is a mental image of what yield does.\n\nI like to think of a thread as having a stack (even when it's not implemented that way).\n\nWhen a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again.\n\nWith a yield function, when its code begins to run (i.e. after the function is called, returning a generator object, whose next() method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the yield statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular yield statement).\n\nSo it's a kind of a frozen function that the generator is hanging onto.\n\nWhen next() is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage.\n\nCompare the following examples:\n\ndef normalFunction():\n    return\n    if False:\n        pass\n\ndef yielderFunction():\n    return\n    if False:\n        yield 12\n\n\nWhen we call the second function, it behaves very differently to the first. The yield statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with.\n\n>>> yielderFunction()\n<generator object yielderFunction at 0x07742D28>\n\n\nCalling yielderFunction() doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the yielder prefix for readability.)\n\n>>> gen = yielderFunction()\n>>> dir(gen)\n['__class__',\n ...\n '__iter__',    #Returns gen itself, to make it work uniformly with containers\n ...            #when given to a for loop. (Containers return an iterator instead.)\n 'close',\n 'gi_code',\n 'gi_frame',\n 'gi_running',\n 'next',        #The method that runs the function's body.\n 'send',\n 'throw']\n\n\nThe gi_code and gi_frame fields are where the frozen state is stored. Exploring them with dir(..), we can confirm that our mental model above is credible.\n\nShare\nImprove this answer\nFollow\nedited Mar 1 '17 at 13:36\nanswered Jun 14 '13 at 16:36\nEvgeni Sergeev\n19.1k15\n15 gold badges\n94\n94 silver badges\n115\n115 bronze badges","comments":[]},{"answer":"An easy example to understand what it is: yield\n\ndef f123():\n    for _ in range(4):\n        yield 1\n        yield 2\n\n\nfor i in f123():\n    print (i)\n\n\nThe output is:\n\n1 2 1 2 1 2 1 2\n\nShare\nImprove this answer\nFollow\nedited Feb 2 '20 at 18:21\nZF007\n3,3498\n8 gold badges\n27\n27 silver badges\n39\n39 bronze badges\nanswered Jan 2 '17 at 12:09\nGavriel Cohen\n3,51427\n27 silver badges\n36\n36 bronze badges","comments":["are you sure about that output? wouldnt that only be printed on a single line if you ran that print statement using print(i, end=' ')? Otherwise, i believe the default behavior would put each number on a new line","@user9074332, You're right, but it is written on one line to facilitate understanding"]},{"answer":"Like every answer suggests, yield is used for creating a sequence generator. It's used for generating some sequence dynamically. For example, while reading a file line by line on a network, you can use the yield function as follows:\n\ndef getNextLines():\n   while con.isOpen():\n       yield con.read()\n\n\nYou can use it in your code as follows:\n\nfor line in getNextLines():\n    doSomeThing(line)\n\n\nExecution Control Transfer gotcha\n\nThe execution control will be transferred from getNextLines() to the for loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time.\n\nThus in short, a function with the following code\n\ndef simpleYield():\n    yield \"first time\"\n    yield \"second time\"\n    yield \"third time\"\n    yield \"Now some useful value {}\".format(12)\n\nfor i in simpleYield():\n    print i\n\n\nwill print\n\n\"first time\"\n\"second time\"\n\"third time\"\n\"Now some useful value 12\"\n\nShare\nImprove this answer\nFollow\nedited May 20 '18 at 10:42\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 29 '15 at 6:11\nMangu Singh Rajpurohit\n9,1343\n3 gold badges\n52\n52 silver badges\n79\n79 bronze badges","comments":[]},{"answer":"(My below answer only speaks from the perspective of using Python generator, not the underlying implementation of generator mechanism, which involves some tricks of stack and heap manipulation.)\n\nWhen yield is used instead of a return in a python function, that function is turned into something special called generator function. That function will return an object of generator type. The yield keyword is a flag to notify the python compiler to treat such function specially. Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function can be thought of as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a StopIteration exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about generator but this one from the functional programming perspective is the most digestable.\n\n(Now I want to talk about the rationale behind generator, and the iterator based on my own understanding. I hope this can help you grasp the essential motivation of iterator and generator. Such concept shows up in other languages as well such as C#.)\n\nAs I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this naive approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand. So instead of storing the data itself directly, why not store some kind of metadata indirectly, i.e. the logic how the data is computed.\n\nThere are 2 approaches to wrap such metadata.\n\nThe OO approach, we wrap the metadata as a class. This is the so-called iterator who implements the iterator protocol (i.e. the __next__(), and __iter__() methods). This is also the commonly seen iterator design pattern.\nThe functional approach, we wrap the metadata as a function. This is the so-called generator function. But under the hood, the returned generator object still IS-A iterator because it also implements the iterator protocol.\n\nEither way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you.\n\nShare\nImprove this answer\nFollow\nedited Nov 23 '18 at 1:38\nanswered Mar 25 '16 at 5:40\nsmwikipedia\n53.9k80\n80 gold badges\n270\n270 silver badges\n438\n438 bronze badges","comments":[]},{"answer":"In summary, the yield statement transforms your function into a factory that produces a special object called a generator which wraps around the body of your original function. When the generator is iterated, it executes your function until it reaches the next yield then suspends execution and evaluates to the value passed to yield. It repeats this process on each iteration until the path of execution exits the function. For instance,\n\ndef simple_generator():\n    yield 'one'\n    yield 'two'\n    yield 'three'\n\nfor i in simple_generator():\n    print i\n\n\nsimply outputs\n\none\ntwo\nthree\n\n\nThe power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculations\n\nSay you wanted to create a your own range function that produces an iterable range of numbers, you could do it like so,\n\ndef myRangeNaive(i):\n    n = 0\n    range = []\n    while n < i:\n        range.append(n)\n        n = n + 1\n    return range\n\n\nand use it like this;\n\nfor i in myRangeNaive(10):\n    print i\n\n\nBut this is inefficient because\n\nYou create an array that you only use once (this wastes memory)\nThis code actually loops over that array twice! :(\n\nLuckily Guido and his team were generous enough to develop generators so we could just do this;\n\ndef myRangeSmart(i):\n    n = 0\n    while n < i:\n       yield n\n       n = n + 1\n    return\n\nfor i in myRangeSmart(10):\n    print i\n\n\nNow upon each iteration a function on the generator called next() executes the function until it either reaches a 'yield' statement in which it stops and 'yields' the value or reaches the end of the function. In this case on the first call, next() executes up to the yield statement and yield 'n', on the next call it will execute the increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function.\n\nShare\nImprove this answer\nFollow\nedited May 20 '18 at 11:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 13 '16 at 13:43\nredbandit\n1,90314\n14 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"Yield is an object\n\nA return in a function will return a single value.\n\nIf you want a function to return a huge set of values, use yield.\n\nMore importantly, yield is a barrier.\n\nlike barrier in the CUDA language, it will not transfer control until it gets completed.\n\nThat is, it will run the code in your function from the beginning until it hits yield. Then, it’ll return the first value of the loop.\n\nThen, every other call will run the loop you have written in the function one more time, returning the next value until there isn't any value to return.\n\nShare\nImprove this answer\nFollow\nedited May 20 '18 at 10:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 1 '15 at 12:42\nKaleem Ullah\n5,7182\n2 gold badges\n37\n37 silver badges\n44\n44 bronze badges","comments":[]},{"answer":"Many people use return rather than yield, but in some cases yield can be more efficient and easier to work with.\n\nHere is an example which yield is definitely best for:\n\nreturn (in function)\n\nimport random\n\ndef return_dates():\n    dates = [] # With 'return' you need to create a list then return it\n    for i in range(5):\n        date = random.choice([\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"])\n        dates.append(date)\n    return dates\n\n\nyield (in function)\n\ndef yield_dates():\n    for i in range(5):\n        date = random.choice([\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"])\n        yield date # 'yield' makes a generator automatically which works\n                   # in a similar way. This is much more efficient.\n\n\nCalling functions\n\ndates_list = return_dates()\nprint(dates_list)\nfor i in dates_list:\n    print(i)\n\ndates_generator = yield_dates()\nprint(dates_generator)\nfor i in dates_generator:\n    print(i)\n\n\nBoth functions do the same thing, but yield uses three lines instead of five and has one less variable to worry about.\n\nThis is the result from the code:\n\nAs you can see both functions do the same thing. The only difference is return_dates() gives a list and yield_dates() gives a generator.\n\nA real life example would be something like reading a file line by line or if you just want to make a generator.\n\nShare\nImprove this answer\nFollow\nedited May 20 '18 at 11:02\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 10 '16 at 11:37\nTom Fuller\n4,6986\n6 gold badges\n31\n31 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"yield is like a return element for a function. The difference is, that the yield element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling list(generator()).\n\nShare\nImprove this answer\nFollow\nanswered May 20 '15 at 6:19\nWill Dereham\n8769\n9 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"The yield keyword simply collects returning results. Think of yield like return +=\n\nShare\nImprove this answer\nFollow\nedited Apr 23 '16 at 3:16\nPhillip\n2,0191\n1 gold badge\n22\n22 silver badges\n38\n38 bronze badges\nanswered Nov 18 '15 at 19:37\nBahtiyar Özdere\n1,56813\n13 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"Yet another TL;DR\n\nIterator on list: next() returns the next element of the list\n\nIterator generator: next() will compute the next element on the fly (execute code)\n\nYou can see the yield/generator as a way to manually run the control flow from outside (like continue loop one step), by calling next, however complex the flow.\n\nNote: The generator is NOT a normal function. It remembers the previous state like local variables (stack). See other answers or articles for detailed explanation. The generator can only be iterated on once. You could do without yield, but it would not be as nice, so it can be considered 'very nice' language sugar.\n\nShare\nImprove this answer\nFollow\nedited May 20 '18 at 10:58\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 22 '16 at 9:40\nChristophe Roussy\n14.1k2\n2 gold badges\n77\n77 silver badges\n75\n75 bronze badges","comments":[]}]},{"id":"477816","href":"https://stackoverflow.com/questions/477816/what-is-the-correct-json-content-type","title":"What is the correct JSON content type?","description":"\n                \nI've been messing around with JSON for some time, just pushing it out as text and it hasn't hurt anybody (that I know of), but I'd like to start doing things properly.\n\nI have seen so many purported \"standards\" for the JSON content type:\n\napplication/json\napplication/x-javascript\ntext/javascript\ntext/x-javascript\ntext/x-json\n\n\nBut which one is correct, or best? I gather that there are security and browser support issues varying between them.\n\nI know there's a similar question, What MIME type if JSON is being returned by a REST API?, but I'd like a slightly more targeted answer.\n    ","questionComments":[],"answers":[{"answer":"For JSON text:\n\napplication/json\n\n\nThe MIME media type for JSON text is application/json. The default encoding is UTF-8. (Source: RFC 4627)\n\nFor JSONP (runnable JavaScript) with callback:\n\napplication/javascript\n\n\nHere are some blog posts that were mentioned in the relevant comments:\n\nWhy you shouldn't use text/html for JSON\nInternet Explorer sometimes has issues with application/json\nA rather complete list of Mimetypes and what to use them for\nThe official mime type list at IANA from @gnrfan's answer below\nShare\nImprove this answer\nFollow\nedited May 22 at 6:32\nRoshana Pitigala\n7,3138\n8 gold badges\n39\n39 silver badges\n67\n67 bronze badges\nanswered Jan 25 '09 at 15:27\nGumbo\n601k102\n102 gold badges\n743\n743 silver badges\n818\n818 bronze badges","comments":["Complete list of MIME types","does it really matter what mime type it has? it's text that gets parsed into an object. wouldn't it be more natural to pass it as text/plain if you want it to be openable in browser without force download, and application/octet-stream if you want it to be automatically downloaded(useful if you're generating it on a webpage intended to be saved locally). Is there really that many people that will need to know the mime type so the downloader can view it with a special json viewer? What am I missing that warrants it a special mime type?","Internet Explorer sometimes has issues with application/json - blog is offline","Imagine I have a document written by somebody which contains plain text. Now that plain text just happens to be valid JSON as well. Would I then be wrong to use text/plain as its mime-type? JSON is a SUB-TYPE of text. So I think both should be allowed. The question is which works better in practice. According to comment by codetoshare IE has problems with application/json. But no browser should have problems with text/plain. If text/plain is unsafe then how can I serve text-files from my web-site?","@EugenMihailescu The title of that page is \"Incomplete list of MIME types\""]},{"answer":"IANA has registered the official MIME Type for JSON as application/json.\n\nWhen asked about why not text/json, Crockford seems to have said JSON is not really JavaScript nor text and also IANA was more likely to hand out application/* than text/*.\n\nMore resources:\n\nMedia Types\nRequest for Comments 4627\nbluesmoon: JSON has a type\nShare\nImprove this answer\nFollow\nedited Jan 17 '17 at 20:53\nGowtham Subramaniam\n2,8902\n2 gold badges\n15\n15 silver badges\n29\n29 bronze badges\nanswered Apr 7 '10 at 4:32\ngnrfan\n18k1\n1 gold badge\n19\n19 silver badges\n12\n12 bronze badges","comments":["A lot of stuff got put into the text/* section in the early days that would probably be put into the application/* section these days.","@Rohmer - You \"can\" open anything in a text editor, but a binary format like JPEG or a Windows .exe or a .zip will contain non-printable characters which can actually break many text editors or cause undesired behavior. Try running cat file.jpg for example. Whereas any xml or json file is 100% printable. So I think Stijn de Witt's point is a valid one, despite the fact that yes, it's too late to change now.","@XP84 You can open any binary with a text editor in HEX form. And all the different characters (the 16 of them) are 100% printable. So, by that logic... are all binaries text? Json is not text. Json is (warning: informal loose definition ahead) a text representation of an object (or array of objects)","There is no meaning to the phrase \"a text editor in HEX form\". A Hex editor shows each byte as its hexadecimal value, for example, the byte 1111000 as \"78\". While there may be some text editors which also happen to have a hex editing mode, this is neither common nor useful for anything but the most technical users doing the most technical tasks. Text, by comparison, means ASCII or Unicode, and in text, the byte 1111000 means lower-case x character. Not 78. JSON is text in exactly the same way as HTML (text/html). It contains only readable text characters, with structured meaning in them.","I tend to agree with Stijn de Witt. JSON is meant to be viewed and edited with a text-editor."]},{"answer":"For JSON:\n\nContent-Type: application/json\n\n\nFor JSON-P:\n\nContent-Type: application/javascript\n\nShare\nImprove this answer\nFollow\nedited May 27 '14 at 2:35\nAmal Murali\n71.2k17\n17 gold badges\n121\n121 silver badges\n140\n140 bronze badges\nanswered Jun 20 '12 at 3:10\nAlix Axel\n143k85\n85 gold badges\n379\n379 silver badges\n486\n486 bronze badges","comments":["JSONP is not really JSON though, it's a technique for passing a JavaScript object literal"]},{"answer":"Of course, the correct MIME media type for JSON is application/json, but it's necessary to realize what type of data is expected in your application.\n\nFor example, I use Ext GWT and the server response must go as text/html but contains JSON data.\n\nClient side, Ext GWT form listener\n\nuploadForm.getForm().addListener(new FormListenerAdapter()\n{\n    @Override\n    public void onActionFailed(Form form, int httpStatus, String responseText) \n    {\n        MessageBox.alert(\"Error\");\n    }\n\n    @Override\n    public void onActionComplete(Form form, int httpStatus, String responseText) \n    {\n        MessageBox.alert(\"Success\");\n    }\n});\n\n\nIn case of using application/json response type, the browser suggests me to save the file.\n\nServer side source code snippet using Spring MVC\n\nreturn new AbstractUrlBasedView() \n{\n    @SuppressWarnings(\"unchecked\")\n    @Override\n    protected void renderMergedOutputModel(Map model, HttpServletRequest request,\n                                           HttpServletResponse response) throws Exception \n    {\n        response.setContentType(\"text/html\");\n        response.getWriter().write(json);\n    }\n};\n\nShare\nImprove this answer\nFollow\nedited May 4 '15 at 22:37\nJohn Odom\n1,0982\n2 gold badges\n19\n19 silver badges\n35\n35 bronze badges\nanswered Oct 7 '09 at 14:35\nMikhail.Mamaev\n7,5495\n5 gold badges\n22\n22 silver badges\n28\n28 bronze badges","comments":["server response must go as text/html. This is true for the ExtJS variant as well."]},{"answer":"JSON:\n\nResponse is dynamically generated data, according to the query parameters passed in the URL.\n\nExample:\n\n{ \"Name\": \"Foo\", \"Id\": 1234, \"Rank\": 7 }\n\n\nContent-Type: application/json\n\nJSON-P:\n\nJSON with padding. Response is JSON data, with a function call wrapped around it.\n\nExample:\n\nfunctionCall({\"Name\": \"Foo\", \"Id\": 1234, \"Rank\": 7});\n\n\nContent-Type: application/javascript\n\nShare\nImprove this answer\nFollow\nedited Aug 1 '14 at 13:09\nUser 1531343\n8,12212\n12 gold badges\n87\n87 silver badges\n158\n158 bronze badges\nanswered Mar 28 '13 at 7:54\nBhavin\n26.8k11\n11 gold badges\n53\n53 silver badges\n91\n91 bronze badges","comments":["The definition of JSON is wrong. It does not need to be dynamically generated or respect query parameters. You can serve a static JSON file. Also, the most upvoted answer has a link to the RFC.","Also JSONP can be json data assigned to a var."]},{"answer":"If you are using Ubuntu or Debian and you serve .json files through Apache, you might want to serve the files with the correct content type. I am doing this primarily because I want to use the Firefox extension JSONView\n\nThe Apache module mod_mime will help to do this easily. However, with Ubuntu you need to edit the file /etc/mime.types and add the line\n\napplication/json json\n\n\nThen restart Apache:\n\nsudo service apache2 restart\n\nShare\nImprove this answer\nFollow\nedited Jun 30 '14 at 16:56\nUmpa\n32910\n10 silver badges\n15\n15 bronze badges\nanswered Nov 16 '10 at 22:58\nGourneau\n11.8k8\n8 gold badges\n41\n41 silver badges\n41\n41 bronze badges","comments":["usually a reload is enough (faster than restart). Also, note that you can now do \"sudo service apache2 reload\".","Ubuntu 12.04 has this by default"]},{"answer":"If you're calling ASP.NET Web Services from the client-side you have to use application/json for it to work. I believe this is the same for the jQuery and Ext frameworks.\n\nShare\nImprove this answer\nFollow\nedited May 27 '14 at 2:38\nAmal Murali\n71.2k17\n17 gold badges\n121\n121 silver badges\n140\n140 bronze badges\nanswered Jan 25 '09 at 15:31\nMark Clancy\n7,4838\n8 gold badges\n41\n41 silver badges\n47\n47 bronze badges","comments":["jQuery seems to work with at least 'application/json' and 'text/plain'... I haven't tried all the others though.","jQuery is capable of working with content-Type: text/plain, content-Type: application/json, content-Type: application/json; charset=UTF-8, contentType: \"application/x-www-form-urlencoded; charset=UTF-8\""]},{"answer":"The right content type for JSON is application/json UNLESS you're using JSONP, also known as JSON with Padding, which is actually JavaScript and so the right content type would be application/javascript.\n\nShare\nImprove this answer\nFollow\nedited May 27 '14 at 2:39\nAmal Murali\n71.2k17\n17 gold badges\n121\n121 silver badges\n140\n140 bronze badges\nanswered Apr 12 '12 at 4:00\nResist Design\n4,1832\n2 gold badges\n20\n20 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"There is no doubt that application/json is the best MIME type for a JSON response.\n\nBut I had some experience where I had to use application/x-javascript because of some compression issues. My hosting environment is shared hosting with GoDaddy. They do not allow me to change server configurations. I had added the following code to my web.config file for compressing responses.\n\n<httpCompression>\n    <scheme name=\"gzip\" dll=\"%Windir%\\system32\\inetsrv\\gzip.dll\"/>\n    <dynamicTypes>\n        <add mimeType=\"text/*\" enabled=\"true\"/>\n        <add mimeType=\"message/*\" enabled=\"true\"/>\n        <add mimeType=\"application/javascript\" enabled=\"true\"/>\n        <add mimeType=\"*/*\" enabled=\"false\"/>\n    </dynamicTypes>\n    <staticTypes>\n        <add mimeType=\"text/*\" enabled=\"true\"/>\n        <add mimeType=\"message/*\" enabled=\"true\"/>\n        <add mimeType=\"application/javascript\" enabled=\"true\"/>\n        <add mimeType=\"*/*\" enabled=\"false\"/>\n    </staticTypes>\n</httpCompression>\n<urlCompression doStaticCompression=\"true\" doDynamicCompression=\"true\"/>\n\n\nBy using this, the .aspx pages was compressed with g-zip but JSON responses were not. I added\n\n<add mimeType=\"application/json\" enabled=\"true\"/>\n\n\nin the static and dynamic types sections. But this does not compress JSON responses at all.\n\nAfter that I removed this newly added type and added\n\n<add mimeType=\"application/x-javascript\" enabled=\"true\"/>\n\n\nin both the static and dynamic types sections, and changed the response type in\n\n.ashx (asynchronous handler) to\n\napplication/x-javascript\n\n\nAnd now I found that my JSON responses were compressed with g-zip. So I personally recommend to use\n\napplication/x-javascript\n\n\nonly if you want to compress your JSON responses on a shared hosting environment. Because in shared hosting, they do not allow you to change IIS configurations.\n\nShare\nImprove this answer\nFollow\nedited Nov 9 '17 at 8:31\nA J A Y\n5061\n1 gold badge\n5\n5 silver badges\n19\n19 bronze badges\nanswered Apr 18 '12 at 8:22\nshashwat\n7,1457\n7 gold badges\n54\n54 silver badges\n86\n86 bronze badges","comments":["\"So I personally recommending to use application/x-javascript\" is where this answer becomes misleading. GoDaddy does allow compression of application/json, I leverage it on my shared hosting and I wouldn't suggest using a different content type to enable compression anyway, it's simply wrong. It can be done, but it will still be wrong. Using different content types for browser support is one thing, using different content types for server-side compression is another."]},{"answer":"Only when using application/json as the MIME type I have the following (as of November 2011 with the most recent versions of Chrome, Firefox with Firebug):\n\nNo more warnings from Chrome when the JSON is loaded from the server.\nFirebug will add a tab to the response showing you the JSON data formatted. If the MIME type is different, it will just show up as 'Response content'.\nShare\nImprove this answer\nFollow\nedited Jul 25 '13 at 15:52\nMichael Berkowski\n255k41\n41 gold badges\n422\n422 silver badges\n372\n372 bronze badges\nanswered Nov 30 '11 at 6:42\nIvo Limmen\n2,9951\n1 gold badge\n23\n23 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"Not everything works for content type application/json.\n\nIf you are using Ext JS form submit to upload file, be aware that the server response is parsed by the browser to create the document for the <iframe>.\n\nIf the server is using JSON to send the return object, then the Content-Type header must be set to text/html in order to tell the browser to insert the text unchanged into the document body.\n\nSee the Ext JS 3.4.0 API documentation.\n\nShare\nImprove this answer\nFollow\nedited Aug 2 '13 at 15:53\nHolger Just\n46.6k14\n14 gold badges\n100\n100 silver badges\n116\n116 bronze badges\nanswered Sep 7 '11 at 2:41\nConan\n2,9041\n1 gold badge\n19\n19 silver badges\n23\n23 bronze badges","comments":["Tools that don't adhere to standards should be avoided whenever possible; use application/json per spec.","@one.beat.consumer while that is true, it's not specific to ExtJs per se. It's a browser limitation (or rather, perhaps, a \"security measure\").","Surely it would be better to use text/plain so it doesn't apply any HTML semantics to non-HTML content? Or don't browsers let you extract a frame's content if it's got no DOM?","To add further confusion: I'm just debugging a similar case on Samsung Galaxy Beam (Android 2.3) with default browser, and the iframe seems to fire load event for application/javascript, application/x-javascript, text/javascript, text/plain, but NOT firing it for application/json nor text/html. As of today, Android <=2.3 is About 50% of the Android market share."]},{"answer":"JSON is a domain-specific language (DSL) and a data format independent of JavaScript, and as such has its own MIME type, application/json. Respect for MIME types is of course client driven, so text/plain may do for transfer of bytes, but then you would be pushing up interpretation to the vendor application domain unnecessarily - application/json. Would you transfer XML via text/plain?\n\nBut honestly, your choice of MIME type is advice to the client as to how to interpret the data- text/plain or text/HTML (when it's not HTML) is like type erasure- it's as uninformative as making all your objects of type Object in a typed language.\n\nNo browser runtime I know of will take a JSON document and automatically make it available to the runtime as a JavaScript accessible object without intervention, but if you are working with a crippled client, that's an entirely different matter. But that's not the whole story- RESTful JSON services often don't have JavaScript runtimes, but it doesn't stop them using JSON as a viable data interchange format. If clients are that crippled... then I would consider perhaps HTML injection via an Ajax templating service instead.\n\nApplication/JSON!\n\nShare\nImprove this answer\nFollow\nedited Dec 11 '14 at 16:48\ndjv\n11.7k7\n7 gold badges\n44\n44 silver badges\n62\n62 bronze badges\nanswered May 14 '12 at 22:19\nVLostBoy\n3,8042\n2 gold badges\n21\n21 silver badges\n30\n30 bronze badges","comments":[]},{"answer":"If you're in a client-side environment, investigating about the cross-browser support is mandatory for a well supported web application.\n\nThe right HTTP Content-Type would be application/json, as others already highlighted too, but some clients do not handle it very well, that's why jQuery recommends the default text/html.\n\nShare\nImprove this answer\nFollow\nedited Feb 23 '13 at 15:37\nanswered Apr 27 '12 at 16:27\nyodabar\n4,3211\n1 gold badge\n29\n29 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"The correct answer is:\n\nContent-Type: application/json\n\nShare\nImprove this answer\nFollow\nedited Nov 22 '14 at 11:11\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 31 '12 at 6:29\nIrfan DANISH\n7,58711\n11 gold badges\n35\n35 silver badges\n64\n64 bronze badges","comments":[]},{"answer":"As many others have mentioned, application/json is the correct answer.\n\nBut what haven't been explained yet is what the other options you proposed mean.\n\napplication/x-javascript: Experimental MIME type for JavaScript before application/javascript was made standard.\n\ntext/javascript: Now obsolete. You should use application/javascript when using javascript.\n\ntext/x-javascript: Experimental MIME type for the above situation.\n\ntext/x-json: Experimental MIME type for JSON before application/json got officially registered.\n\nAll in all, whenever you have any doubts about content types, you should check this link\n\nShare\nImprove this answer\nFollow\nedited Aug 17 '15 at 20:05\nuser1596138\nanswered Apr 2 '13 at 11:10\nfcm\n5,6775\n5 gold badges\n22\n22 silver badges\n36\n36 bronze badges","comments":["When did text/javascript become obsolete? I'm still filling up HTML documents with <script type=\"text/javascript\" ... tags.","It makes no difference for browsers, really. It's just obsolete for RFC standards: rfc-editor.org/rfc/rfc4329.txt","@Oli you can safely drop type=\"text/javascript\" and just do <script>...</script> at least according to HTML5."]},{"answer":"In JSP, you can use this in page directive:\n\n<%@ page language=\"java\" contentType=\"application/json; charset=UTF-8\"\n    pageEncoding=\"UTF-8\"%>\n\n\nThe correct MIME media type for JSON is application/json. JSP will use it for sending a response to the client.\n\nShare\nImprove this answer\nFollow\nedited Aug 5 '14 at 7:08\nanswered Jan 19 '13 at 8:22\nraja\n2,2932\n2 gold badges\n20\n20 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"“application/json” is the correct JSON content type.\n\ndef ajaxFindSystems = {\n  def result = Systems.list()\n  render(contentType:'application/json') {\n    results {\n      result.each{sys->\n        system(id:sys.id, name:sys.name)\n      }\n    }\n    resultset (rows:result.size())\n  }\n}\n\nShare\nImprove this answer\nFollow\nedited Feb 25 '14 at 17:59\nGeorge Stocker\n55.4k29\n29 gold badges\n169\n169 silver badges\n231\n231 bronze badges\nanswered Feb 26 '13 at 11:55\nSukane\n2,4623\n3 gold badges\n15\n15 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"The IANA registration for application/json says\n\nApplications that use this media type: JSON has been used to exchange data between applications written in all of these programming languages: ActionScript, C, C#, Clojure, ColdFusion, Common Lisp, E, Erlang, Go, Java, JavaScript, Lua, Objective CAML, Perl, PHP, Python, Rebol, Ruby, Scala, and Scheme.\n\nYou'll notice that IANA.org doesn't list any of these other media types, in fact even application/javascript is now obsolete. So application/json is really the only possible correct answer.\n\nBrowser support is another thing.\n\nThe most widely supported non-standard media types are text/json or text/javascript. But some big names even use text/plain.\n\nEven more strange is the Content-Type header sent by Flickr, who returns JSON as text/xml. Google uses text/javascript for some of it's ajax apis.\n\nExamples:\n\ncurl -I \"https://ajax.googleapis.com/ajax/services/search/video?v=1.0&q=jsonexample\"\n\n\nOutput: Content-Type: text/javascript\n\ncurl -I \"https://www.flickr.com/services/rest/?method=flickr.test.echo&format=json&api_key=f82254c1491d894f1204d8408f645a93\"\n\n\nOutput: Content-Type: text/xml\n\nShare\nImprove this answer\nFollow\nedited Apr 12 '18 at 15:49\nanswered Feb 12 '14 at 16:12\nuser1596138","comments":[]},{"answer":"The right MIME type is application/json\n\nBUT\n\nI experienced many situations where the browser type or the framework user needed:\n\ntext/html\n\napplication/javascript\n\nShare\nImprove this answer\nFollow\nedited Feb 25 '14 at 17:59\nGeorge Stocker\n55.4k29\n29 gold badges\n169\n169 silver badges\n231\n231 bronze badges\nanswered May 3 '13 at 16:00\nLombaX\n17k5\n5 gold badges\n49\n49 silver badges\n73\n73 bronze badges","comments":["Example of such a situation?"]},{"answer":"I use the below\n\ncontentType: 'application/json',\ndata: JSON.stringify(SendData),\n\nShare\nImprove this answer\nFollow\nedited May 17 '13 at 9:52\nDD_\n7,00111\n11 gold badges\n36\n36 silver badges\n60\n60 bronze badges\nanswered May 16 '13 at 12:43\nAndro\n8756\n6 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"The Content-Type header should be set to 'application/json' when posting. Server listening for the request should include \"Accept=application/json\". In Spring MVC you can do it like this:\n\n@RequestMapping(value=\"location\", method = RequestMethod.POST, headers = \"Accept=application/json\")\n\n\nAdd headers to the response:\n\nHttpHeaders headers = new HttpHeaders();\nheaders.add(\"Content-Type\", \"application/json\");\n\nShare\nImprove this answer\nFollow\nanswered Aug 9 '13 at 10:49\nAlexander Burakevych\n2,2581\n1 gold badge\n21\n21 silver badges\n24\n24 bronze badges","comments":["stackoverflow.com/a/65430096/4307338"]},{"answer":"The application/json works great in PHP to store an array or object data.\n\nI use this code to put data in JSON on Google Cloud Storage (GCS) which is set publically viewable:\n\n$context = stream_context_create([\n    'gs' => [\n        'acl'=>'public-read', \n        'Content-Type' => 'application/json',\n    ]\n]);\n\nfile_put_contents(\n    \"gs://BUCKETNAME/FILENAME.json\", \n    json_encode((object) $array), \n    false, \n    $context\n);\n\n\nTo get back the data is straight forward:\n\n$data = json_decode(file_get_contents(\"gs://BUCKETNAME/FILENAME.json\"));\n\nShare\nImprove this answer\nFollow\nedited Jan 17 '18 at 2:33\nNubok\n3,1936\n6 gold badges\n24\n24 silver badges\n45\n45 bronze badges\nanswered Apr 1 '15 at 16:13\nChetabahana\n8,0743\n3 gold badges\n53\n53 silver badges\n71\n71 bronze badges","comments":[]},{"answer":"In Spring you have a defined type: MediaType.APPLICATION_JSON_VALUE which is equivalent to application/json.\n\nShare\nImprove this answer\nFollow\nedited Jul 10 '13 at 22:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 29 '13 at 8:34\nChand Priyankara\n6,5351\n1 gold badge\n38\n38 silver badges\n59\n59 bronze badges","comments":["That's Java EE too :: javax.ws.rs.core.MediaType"]},{"answer":"For JSON, I am using:\n\n Content-Type: application/json\n\n\nThis is described in the IETF's JSON Data Interchange Format 7158 proposal, Section 1.2: Specifications of JSON.\n\nShare\nImprove this answer\nFollow\nedited Jan 2 '16 at 4:03\nRohit Gupta\n2,40911\n11 gold badges\n21\n21 silver badges\n36\n36 bronze badges\nanswered Feb 6 '15 at 12:01\nMehmet_\n5544\n4 silver badges\n8\n8 bronze badges","comments":[]},{"answer":"If the JSON is with padding then it will be application/jsonp. If the JSON is without padding then it will be application/json.\n\nTo deal with both, it is a good practice to use: 'application/javascript' without bothering whether it is with padding or without padding.\n\nShare\nImprove this answer\nFollow\nedited Jul 10 '13 at 22:16\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 21 '13 at 15:22\nAnkit Zalani\n2,9405\n5 gold badges\n24\n24 silver badges\n46\n46 bronze badges","comments":["The first part of your answer is wrong. \"application/jsonp\" is not a valid MIME type. The response body of a JSONP is just JavaScript, so one of the MIME-types for JavaScript has to be used."]},{"answer":"PHP developers use this:\n\n<?php\n    header(\"Content-type: application/json\");\n\n    // Do something here...\n?>\n\nShare\nImprove this answer\nFollow\nedited Jul 19 '14 at 21:49\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 29 '14 at 5:43\nuser3087089","comments":[]},{"answer":"Extending the accepted responses, when you are using JSON in a REST context...\n\nThere is a strong argument about using application/x-resource+json and application/x-collection+json when you are representing REST resources and collections.\n\nAnd if you decide to follow the jsonapi specification, you should use of application/vnd.api+json, as it is documented.\n\nAltough there is not an universal standard, it is clear that the added semantic to the resources being transfered justify a more explicit Content-Type than just application/json.\n\nFollowing this reasoning, other contexts could justify a more specific Content-Type.\n\nShare\nImprove this answer\nFollow\nedited Jul 27 '16 at 0:57\ncommunity wiki\n\n\n3 revs, 2 users 96%\njgomo3","comments":["application/vnd.api+json seems to be specifically for apis using json:api, a very narrow specification with its own expectations and format, I don't understand it to be for any API that returns json. Please correct me if I'm wrong"]},{"answer":"If you get data from REST API in JSON so you have to use content-type\n\nFor JSON data: Content-Type:application/json\nFor HTML data: Content-Type:text/html,\nFor XHTML data: Content-Type:application/xhtml+xml,\nFor XML data: Content-Type:text/xml, application/xml\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '16 at 8:44\nMeTitus\n3,2221\n1 gold badge\n19\n19 silver badges\n46\n46 bronze badges\nanswered Apr 11 '16 at 9:15\nKrishna\n7931\n1 gold badge\n9\n9 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"JSON (JavaScript Object Notation) and JSONP (\"JSON with padding\") formats seems to be very similar and therefore it might be very confusing which MIME type they should be using. Even though the formats are similar, there are some subtle differences between them.\n\nSo whenever in any doubts, I have a very simple approach (which works perfectly fine in most cases), namely, go and check corresponding RFC document.\n\nJSON RFC 4627 (The application/json Media Type for JavaScript Object Notation (JSON)) is a specifications of JSON format. It says in section 6, that the MIME media type for JSON text is\n\napplication/json.\n\n\nJSONP JSONP (\"JSON with padding\") is handled different way than JSON, in a browser. JSONP is treated as a regular JavaScript script and therefore it should use application/javascript, the current official MIME type for JavaScript. In many cases, however, text/javascript MIME type will work fine too.\n\nNote that text/javascript has been marked as obsolete by RFC 4329 (Scripting Media Types) document and it is recommended to use application/javascript type instead. However, due to legacy reasons, text/javascript is still widely used and it has cross-browser support (which is not always a case with application/javascript MIME type, especially with older browsers).\n\nShare\nImprove this answer\nFollow\nedited Mar 13 '19 at 6:03\nPrajwal Dhatwalia\n2091\n1 gold badge\n4\n4 silver badges\n14\n14 bronze badges\nanswered Feb 15 '16 at 3:20\nIresha Rubasinghe\n8231\n1 gold badge\n10\n10 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"Content-Type: application/json - json\nContent-Type: application/javascript - json-P\nContent-Type: application/x-javascript - javascript\nContent-Type: text/javascript - javascript BUT obsolete, older IE versions used to use as html attribute.\nContent-Type: text/x-javascript - JavaScript Media Types BUT obsolete\nContent-Type: text/x-json - json before application/json got officially registered.\n\nShare\nImprove this answer\nFollow\nedited Jan 25 '19 at 14:57\nAxifive\n1,1092\n2 gold badges\n19\n19 silver badges\n27\n27 bronze badges\nanswered Aug 8 '17 at 3:49\nKashif Solangi\n4915\n5 silver badges\n9\n9 bronze badges","comments":["For JSON text: application/json Content-Type: application/json"]}]},{"id":"348170","href":"https://stackoverflow.com/questions/348170/how-do-i-undo-git-add-before-commit","title":"How do I undo 'git add' before commit?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        Want to improve this post? Provide detailed answers to this question, including citations and an explanation of why your answer is correct. Answers without enough detail may be edited or deleted.\n                        \n                    \n                \n            \n        \n\n\n    \n\nI mistakenly added files to Git using the command:\n\ngit add myfile.txt\n\n\nI have not yet run git commit. Is there a way to undo this, so these files won't be included in the commit?\n    ","questionComments":["Starting with Git v1.8.4, all the answers below that use HEAD or head can now use @ in place of HEAD instead. See this answer (last section) to learn why you can do that.","I made a little summery which shows all ways to unstage a file: stackoverflow.com/questions/6919121/…","@ErikReppen git checkout does not remove staged changes from the commit index. It only reverts un-staged changes to the last committed revision - which by the way is not what I want either, I want those changes, I just want them in a later commit.","If you use Eclipse, it is as simple as unchecking the files in the commit dialogue box","This is a great resource straight from Github: How to undo (almost) anything with Git"],"answers":[{"answer":"You can undo git add before commit with\n\ngit reset <file>\n\n\nwhich will remove it from the current index (the \"about to be committed\" list) without changing anything else.\n\nYou can use\n\ngit reset\n\n\nwithout any file name to unstage all due changes. This can come in handy when there are too many files to be listed one by one in a reasonable amount of time.\n\nIn old versions of Git, the above commands are equivalent to git reset HEAD <file> and git reset HEAD respectively, and will fail if HEAD is undefined (because you haven't yet made any commits in your repository) or ambiguous (because you created a branch called HEAD, which is a stupid thing that you shouldn't do). This was changed in Git 1.8.2, though, so in modern versions of Git you can use the commands above even prior to making your first commit:\n\n\"git reset\" (without options or parameters) used to error out when you do not have any commits in your history, but it now gives you an empty index (to match non-existent commit you are not even on).\n\nDocumentation: git reset\n\nShare\nImprove this answer\nFollow\nedited Jun 25 '20 at 12:10\nManu Sharma\n5045\n5 silver badges\n15\n15 bronze badges\nanswered Dec 7 '08 at 22:30\ngenehack\n121k1\n1 gold badge\n20\n20 silver badges\n24\n24 bronze badges","comments":["Of course, this is not a true undo, because if the wrong git add overwrote a previous staged uncommited version, we can't recover it. I tried to clarify this in my answer below.","git reset HEAD *.ext where ext is the files of the given extension you want to unadd. For me it was *.bmp & *.zip","@Jonny, the index (aka staging area) contains all the files, not just changed files. It \"starts life\" (when you check out a commit or clone a repo) as a copy of all the files in the commit pointed to by HEAD. So if you remove a file from the index (git rm --cached) it means you are preparing to make a commit that deletes that file. git reset HEAD <filename> on the other hand will copy the file from HEAD to the index, so that the next commit won't show any changes being made to that file.","I just discovered that there is a git reset -p just like git add -p. This is awesome!","You actually can recover overwriten previously staged but uncommited changes but not in a userfriendly way and not 100% secure (at least none I had found): goto .git/objects, search for files created at the time of git add you want to recover (61/3AF3... -> object id 613AF3...), then git cat-file -p <object-id> (might be worth it to recover several hours of work but also a lesson to commit more often...)"]},{"answer":"You want:\n\ngit rm --cached <added_file_to_undo>\n\n\nReasoning:\n\nWhen I was new to this, I first tried\n\ngit reset .\n\n\n(to undo my entire initial add), only to get this (not so) helpful message:\n\nfatal: Failed to resolve 'HEAD' as a valid ref.\n\n\nIt turns out that this is because the HEAD ref (branch?) doesn't exist until after the first commit. That is, you'll run into the same beginner's problem as me if your workflow, like mine, was something like:\n\ncd to my great new project directory to try out Git, the new hotness\ngit init\ngit add .\n\ngit status\n\n... lots of crap scrolls by ...\n\n=> Damn, I didn't want to add all of that.\n\ngoogle \"undo git add\"\n\n=> find Stack Overflow - yay\n\ngit reset .\n\n=> fatal: Failed to resolve 'HEAD' as a valid ref.\n\nIt further turns out that there's a bug logged against the unhelpfulness of this in the mailing list.\n\nAnd that the correct solution was right there in the Git status output (which, yes, I glossed over as 'crap)\n\n...\n# Changes to be committed:\n#   (use \"git rm --cached <file>...\" to unstage)\n...\n\n\nAnd the solution indeed is to use git rm --cached FILE.\n\nNote the warnings elsewhere here - git rm deletes your local working copy of the file, but not if you use --cached. Here's the result of git help rm:\n\n--cached Use this option to unstage and remove paths only from the index. Working tree files, whether modified or not, will be left.\n\nI proceed to use\n\ngit rm --cached .\n\n\nto remove everything and start again. Didn't work though, because while add . is recursive, turns out rm needs -r to recurse. Sigh.\n\ngit rm -r --cached .\n\n\nOkay, now I'm back to where I started. Next time I'm going to use -n to do a dry run and see what will be added:\n\ngit add -n .\n\n\nI zipped up everything to a safe place before trusting git help rm about the --cached not destroying anything (and what if I misspelled it).\n\nShare\nImprove this answer\nFollow\nedited Sep 13 '18 at 0:05\ncodeforester\n29.9k12\n12 gold badges\n82\n82 silver badges\n109\n109 bronze badges\nanswered Mar 25 '09 at 16:20\nRhubarb\n32.2k2\n2 gold badges\n43\n43 silver badges\n33\n33 bronze badges","comments":["Hah. I followed this same process. Except I gave up and said rm -rf .git, git init because I didn't trust git rm --cached to keep my working copy. It says a little for how git is still overly complex in some places. git unstage should just be a stock standard command, I don't care if I can add it as an alias.","For me git says git reset HEAD <File>...","git rm --cached <file> is actually the correct answer, if it is the initial import of <file> into the repository. If you're trying to unstage a change to the file, git reset is the correct answer. People saying that this answer is wrong are thinking of a different question.","This will actually work, but only on the first commit, where the file didn't exist before, or where the git add command added new files, but not changes to existing files.","just goes to show how unintuitive and convoluted git is. instead of having parallel \"undo\" commands, you have to find out how to undo them. Like trying to free your leg in quick sand, and then getting your arm stuck, then getting your other arm stuck... every command should be done through GUI, with dropdown menus items for the options... Think of all the UI, productivity gains we've had, but we have this mess of a retro command line interface. It's not like the git GUI programs make this any more intuitive."]},{"answer":"If you type:\n\ngit status\n\n\nGit will tell you what is staged, etc., including instructions on how to unstage:\n\nuse \"git reset HEAD <file>...\" to unstage\n\n\nI find Git does a pretty good job of nudging me to do the right thing in situations like this.\n\nNote: Recent Git versions (1.8.4.x) have changed this message:\n\n(use \"git rm --cached <file>...\" to unstage)\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:08\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 7 '08 at 23:22\nPaul Beckingham\n13.6k5\n5 gold badges\n31\n31 silver badges\n67\n67 bronze badges","comments":["The message will be different depending on whether the added file was already being tracked (the add only saved a new version to the cache - here it will show your message). Elsewhere, if the file was not previously staged, it will display use \"git rm --cached <file>...\" to unstage","Great! The git reset HEAD <file> one is the only one that will work in case you want to unstage a file delete","My git version 2.14.3 says git reset HEAD to unstage.","Since Git v2.23 the message has changed yet again. It now says git restore --staged <file>. See my answer below for an update."]},{"answer":"To clarify: git add moves changes from the current working directory to the staging area (index).\n\nThis process is called staging. So the most natural command to stage the changes (changed files) is the obvious one:\n\ngit stage\n\n\ngit add is just an easier-to-type alias for git stage\n\nPity there is no git unstage nor git unadd commands. The relevant one is harder to guess or remember, but it is pretty obvious:\n\ngit reset HEAD --\n\n\nWe can easily create an alias for this:\n\ngit config --global alias.unadd 'reset HEAD --'\ngit config --global alias.unstage 'reset HEAD --'\n\n\nAnd finally, we have new commands:\n\ngit add file1\ngit stage file2\ngit unadd file2\ngit unstage file1\n\n\nPersonally I use even shorter aliases:\n\ngit a # For staging\ngit u # For unstaging\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:15\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 10 '10 at 20:28\ntakeshin\n45.1k30\n30 gold badges\n113\n113 silver badges\n161\n161 bronze badges","comments":["\"moves\"? This would indicate it has gone from the working directory. That's not the case.","Why is it obvious?","Actually, git stage is the alias for git add, which is the historic command, both on Git and other SCM. It has been added in december 2008 with commit 11920d28da in the \"Git's git repository\", if I can say.","This might be unrelated, but I've found validating the file before even adding to be a useful idea, something like check-command filename && git add filename, I replaced git with a shorter g in my machine, and so far it has worked ok for me: github.com/dataf3l/g , I don't know if this will be useful to somebody, but I'll put it here in the hopes it saves some people's time."]},{"answer":"An addition to the accepted answer, if your mistakenly-added file was huge, you'll probably notice that, even after removing it from the index with 'git reset', it still seems to occupy space in the .git directory.\n\nThis is nothing to be worried about; the file is indeed still in the repository, but only as a \"loose object\". It will not be copied to other repositories (via clone, push), and the space will be eventually reclaimed - though perhaps not very soon. If you are anxious, you can run:\n\ngit gc --prune=now\n\n\nUpdate (what follows is my attempt to clear some confusion that can arise from the most upvoted answers):\n\nSo, which is the real undo of git add?\n\ngit reset HEAD <file> ?\n\nor\n\ngit rm --cached <file>?\n\nStrictly speaking, and if I'm not mistaken: none.\n\ngit add cannot be undone - safely, in general.\n\nLet's recall first what git add <file> actually does:\n\nIf <file> was not previously tracked, git add adds it to the cache, with its current content.\n\nIf <file> was already tracked, git add saves the current content (snapshot, version) to the cache. In Git, this action is still called add, (not mere update it), because two different versions (snapshots) of a file are regarded as two different items: hence, we are indeed adding a new item to the cache, to be eventually committed later.\n\nIn light of this, the question is slightly ambiguous:\n\nI mistakenly added files using the command...\n\nThe OP's scenario seems to be the first one (untracked file), we want the \"undo\" to remove the file (not just the current contents) from the tracked items. If this is the case, then it's ok to run git rm --cached <file>.\n\nAnd we could also run git reset HEAD <file>. This is in general preferable, because it works in both scenarios: it also does the undo when we wrongly added a version of an already tracked item.\n\nBut there are two caveats.\n\nFirst: There is (as pointed out in the answer) only one scenario in which git reset HEAD doesn't work, but git rm --cached does: a new repository (no commits). But, really, this a practically irrelevant case.\n\nSecond: Be aware that git reset HEAD can't magically recover the previously cached file contents, it just resynchronises it from the HEAD. If our misguided git add overwrote a previous staged uncommitted version, we can't recover it. That's why, strictly speaking, we cannot undo [*].\n\nExample:\n\n$ git init\n$ echo \"version 1\" > file.txt\n$ git add file.txt   # First add of file.txt\n$ git commit -m 'first commit'\n$ echo \"version 2\" > file.txt\n$ git add  file.txt   # Stage (don't commit) \"version 2\" of file.txt\n$ git diff --cached file.txt\n-version 1\n+version 2\n$ echo \"version 3\" > file.txt\n$ git diff  file.txt\n-version 2\n+version 3\n$ git add  file.txt    # Oops we didn't mean this\n$ git reset HEAD file.txt  # Undo?\n$ git diff --cached file.txt  # No dif, of course. stage == HEAD\n$ git diff file.txt   # We have irrevocably lost \"version 2\"\n-version 1\n+version 3\n\n\nOf course, this is not very critical if we just follow the usual lazy workflow of doing 'git add' only for adding new files (case 1), and we update new contents via the commit, git commit -a command.\n\n* (Edit: the above is practically correct, but still there can be some slightly hackish/convoluted ways for recovering changes that were staged, but not committed and then overwritten - see the comments by Johannes Matokic and iolsmit)\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:21\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 18 '11 at 18:05\nleonbloy\n66.1k19\n19 gold badges\n130\n130 silver badges\n180\n180 bronze badges","comments":["Strictly speaking there is a way to recover an already staged file that was replaced with git add. As you mention git add creates an git object for that file that will become a loose object not only when removing the file completely but also when being overwritten with new content. But there is no command to automatically recover it. Instead the file has to be identified and extracted manually or with tools written only for this case (libgit2 will allow this). But this will only pay out if the file is very important and big and could not be rebuild by editing the previous version.","To correct myself: Once the loose object file is found (use meta-data like creation date/time) git cat-file could be used to recover its content.","Another way to recover changes that were staged but not committed and then overwritten by e.g. another git add is via git fsck --unreachable that will list all unreachable obj, which you can then inspect by git show SHA-1_ID or git fsck --lost-found that will >Write dangling objects into .git/lost-found/commit/ or .git/lost-found/other/, depending on type. See also git fsck --help"]},{"answer":"Undo a file which has already been added is quite easy using Git. For resetting myfile.txt, which have already been added, use:\n\ngit reset HEAD myfile.txt\n\n\nExplanation:\n\nAfter you staged unwanted file(s), to undo, you can do git reset. Head is head of your file in the local and the last parameter is the name of your file.\n\nI have created the steps in the image below in more details for you, including all steps which may happen in these cases:\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:50\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 28 '17 at 10:43\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":["Image: \"The command add...\" → \"The command adds...\" (present simple tense, third person)","Image: wanna → want to (there is no need to use slang here)"]},{"answer":"git rm --cached . -r\n\n\nwill \"un-add\" everything you've added from your current directory recursively\n\nShare\nImprove this answer\nFollow\nedited May 28 '13 at 15:18\nfedorqui 'SO stop harming'\n234k82\n82 gold badges\n477\n477 silver badges\n531\n531 bronze badges\nanswered Dec 9 '09 at 21:19\nbraitsch\n12.9k5\n5 gold badges\n39\n39 silver badges\n33\n33 bronze badges","comments":["I wasn't looking to un-add everything, just ONE specific file.","Also helpful if you don't have any previous commits. In absence of previous commit, git reset HEAD <file> would say fatal: Failed to resolve 'HEAD' as a valid ref.","No, this adds a deletion of everything in your current directory. Very different to just unstaging changes."]},{"answer":"Git has commands for every action imaginable, but it needs extensive knowledge to get things right and because of that it is counter-intuitive at best...\n\nWhat you did before:\n\nChanged a file and used git add ., or git add <file>.\n\nWhat you want:\n\nRemove the file from the index, but keep it versioned and left with uncommitted changes in working copy:\n\n git reset HEAD <file>\n\n\nReset the file to the last state from HEAD, undoing changes and removing them from the index:\n\n # Think `svn revert <file>` IIRC.\n git reset HEAD <file>\n git checkout <file>\n\n # If you have a `<branch>` named like `<file>`, use:\n git checkout -- <file>\n\n\nThis is needed since git reset --hard HEAD won't work with single files.\n\nRemove <file> from index and versioning, keeping the un-versioned file with changes in working copy:\n\n git rm --cached <file>\n\n\nRemove <file> from working copy and versioning completely:\n\n git rm <file>\n\nShare\nImprove this answer\nFollow\nedited Nov 27 '20 at 14:10\nanswered Mar 29 '13 at 11:14\nsjas\n15.8k11\n11 gold badges\n76\n76 silver badges\n81\n81 bronze badges","comments":["I can't under stand the difference of 'git reset head <file>' and 'git rm --cached <file>. Could you explain it?","@jeswang files are either 'known' to git (changes in them are being tracked.), or they are not 'versioned'. reset head undoes your current changes, but the file is still being monitored by git. rm --cached takes the file out of versioning, so git no longer checks it for changes (and also removes eventually indexed present changes, told to git by the prior add), but the changed file will be kept in your working copy, that is in you file folder on the HDD.","The difference is git reset HEAD <file> is temporary - the command will be applied to the next commit only, but git rm --cached <file> will unstage untill it gets added again with git add <file>. Also, git rm --cached <file> means if you push that branch to the remote, anyone pulling the branch will get the file ACTUALLY deleted from their folder.","just what i searched git checkout -- <file> thanx !"]},{"answer":"Run\n\ngit gui\n\n\nand remove all the files manually or by selecting all of them and clicking on the unstage from commit button.\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '13 at 11:21\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 12 '11 at 1:12\nKhaja Minhajuddin\n6,2566\n6 gold badges\n43\n43 silver badges\n44\n44 bronze badges","comments":["Yes I understand that. I only wanted to implicitly suggest that your indicate that on your answer like \"You can use git-gui....\" :)","It says, \"git-gui: command not found\". I'm not sure if this works.","Wow, this is much simple then doing command lines which you don't understood. This is definitely recommended for a beginner like me. Thanks for writing this up!","Thanks. Didn't want to risk it so had to use GUI."]},{"answer":"The question is not clearly posed. The reason is that git add has two meanings:\n\nadding a new file to the staging area, then undo with git rm --cached file.\nadding a modified file to the staging area, then undo with git reset HEAD file.\n\nIf in doubt, use\n\ngit reset HEAD file\n\n\nBecause it does the expected thing in both cases.\n\nWarning: if you do git rm --cached file on a file that was modified (a file that existed before in the repository), then the file will be removed on git commit! It will still exist in your file system, but if anybody else pulls your commit, the file will be deleted from their work tree.\n\ngit status will tell you if the file was a new file or modified:\n\nOn branch master\nChanges to be committed:\n  (use \"git reset HEAD <file>...\" to unstage)\n\n    new file:   my_new_file.txt\n    modified:   my_modified_file.txt\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:33\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 16 '14 at 19:54\nMichael_Scharf\n29.5k16\n16 gold badges\n62\n62 silver badges\n88\n88 bronze badges","comments":["+1. An extraordinary number of highly-upvoted answers and comments on this page are just flat-out wrong about the behaviour of git rm --cached somefile. I hope this answer makes its way up the page to a prominent position where it can protect newbies from being misled by all the false claims.","one of the best answers on here, sadly it is quite low on the list"]},{"answer":"As per many of the other answers, you can use git reset\n\nBUT:\n\nI found this great little post that actually adds the Git command (well, an alias) for git unadd: see git unadd for details or..\n\nSimply,\n\ngit config --global alias.unadd \"reset HEAD\"\n\n\nNow you can\n\ngit unadd foo.txt bar.txt\n\n\nAlternatively / directly:\n\ngit reset HEAD foo.txt bar.txt\n\nShare\nImprove this answer\nFollow\nedited Feb 26 at 22:47\nmatinict\n2,2022\n2 gold badges\n24\n24 silver badges\n34\n34 bronze badges\nanswered Oct 1 '10 at 14:54\nelectblake\n1,74716\n16 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"If you're on your initial commit and you can't use git reset, just declare \"Git bankruptcy\" and delete the .git folder and start over\n\nShare\nImprove this answer\nFollow\nedited Feb 17 '19 at 12:01\njoppiesaus\n4,9273\n3 gold badges\n22\n22 silver badges\n35\n35 bronze badges\nanswered Nov 19 '09 at 16:39\nAna Betts\n71.5k16\n16 gold badges\n136\n136 silver badges\n202\n202 bronze badges","comments":["One tip is to copy your .git/config file if you have added remote origin, before deleting the folder.","@ChrisJohnsen comment is spot on. Sometimes, you want to commit all files except one: git add -A && git rm --cached EXCLUDEFILE && git commit -m 'awesome commit' (This also works when there's no previous commits, re Failed to resolve 'HEAD' problem)"]},{"answer":"Use git add -i to remove just-added files from your upcoming commit. Example:\n\nAdding the file you didn't want:\n\n$ git add foo\n$ git status\n# On branch master\n# Changes to be committed:\n#   (use \"git reset HEAD <file>...\" to unstage)\n#\n#       new file:   foo\n#\n# Untracked files:\n#   (use \"git add <file>...\" to include in what will be committed)\n# [...]#\n\n\nGoing into interactive add to undo your add (the commands typed at git here are \"r\" (revert), \"1\" (first entry in the list revert shows), 'return' to drop out of revert mode, and \"q\" (quit):\n\n$ git add -i\n           staged     unstaged path\n  1:        +1/-0      nothing foo\n\n*** Commands ***\n  1: [s]tatus     2: [u]pdate     3: [r]evert     4: [a]dd untracked\n  5: [p]atch      6: [d]iff       7: [q]uit       8: [h]elp\nWhat now> r\n           staged     unstaged path\n  1:        +1/-0      nothing [f]oo\nRevert>> 1\n           staged     unstaged path\n* 1:        +1/-0      nothing [f]oo\nRevert>> \nnote: foo is untracked now.\nreverted one path\n\n*** Commands ***\n  1: [s]tatus     2: [u]pdate     3: [r]evert     4: [a]dd untracked\n  5: [p]atch      6: [d]iff       7: [q]uit       8: [h]elp\nWhat now> q\nBye.\n$\n\n\nThat's it! Here's your proof, showing that \"foo\" is back on the untracked list:\n\n$ git status\n# On branch master\n# Untracked files:\n#   (use \"git add <file>...\" to include in what will be committed)\n# [...]\n#       foo\nnothing added to commit but untracked files present (use \"git add\" to track)\n$\n\nShare\nImprove this answer\nFollow\nedited Dec 21 '12 at 22:14\nthe Tin Man\n152k39\n39 gold badges\n199\n199 silver badges\n279\n279 bronze badges\nanswered Apr 18 '12 at 12:53\nAlex North-Keys\n3,9111\n1 gold badge\n18\n18 silver badges\n22\n22 bronze badges","comments":[]},{"answer":"git remove or git rm can be used for this, with the --cached flag. Try:\n\ngit help rm\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '13 at 11:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 7 '08 at 22:00\ngnud\n73.8k5\n5 gold badges\n57\n57 silver badges\n76\n76 bronze badges","comments":["Isn't this going to remove the file altogether?","git rm --cached ... will remove files from a git repo. They'll still exist on your computer, but this is VERY different from unstaging changes to a file. For anyone stumbling upon this, it isn't a valid answer to the question."]},{"answer":"Here's a way to avoid this vexing problem when you start a new project:\n\nCreate the main directory for your new project.\nRun git init.\nNow create a .gitignore file (even if it's empty).\nCommit your .gitignore file.\n\nGit makes it really hard to do git reset if you don't have any commits. If you create a tiny initial commit just for the sake of having one, after that you can git add -A and git reset as many times as you want in order to get everything right.\n\nAnother advantage of this method is that if you run into line-ending troubles later and need to refresh all your files, it's easy:\n\nCheck out that initial commit. This will remove all your files.\nThen check out your most recent commit again. This will retrieve fresh copies of your files, using your current line-ending settings.\nShare\nImprove this answer\nFollow\nedited May 10 '12 at 18:59\nanswered Sep 24 '11 at 23:34\nRyan Lundy\n189k36\n36 gold badges\n174\n174 silver badges\n206\n206 bronze badges","comments":["Confirmed! Tried a git reset after a git add . and git was complaining about corrupt HEAD. Following your advice, I could git add & reset back and forth with no problems :)","The second part works, but it is a bit clumsy. How line endings are handled, depends on autocrlf value... This won't work in every project, depending the settings.","This answer was reasonable at the time it was posted, but is now obsolete; git reset somefile and git reset both work prior to making the first commit, now. This has been the case since several Git releases back.","@MarkAmery, you may be right (it'd be cool if you posted a source for your assertion), but there's still value in starting your repo with a clean commit or two."]},{"answer":"Note that if you fail to specify a revision then you have to include a separator. Example from my console:\n\ngit reset <path_to_file>\nfatal: ambiguous argument '<path_to_file>': unknown revision or path not in the working tree.\nUse '--' to separate paths from revisions\n\ngit reset -- <path_to_file>\nUnstaged changes after reset:\nM    <path_to_file>\n\n\n(Git version 1.7.5.4)\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:23\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 23 '12 at 16:57\npowlo\n2,2162\n2 gold badges\n25\n25 silver badges\n35\n35 bronze badges","comments":["I tried git reset <path> and it works just fine without a separator. I'm also using git 1.9.0. Maybe it doesn't work in older versions?"]},{"answer":"Maybe Git has evolved since you posted your question.\n\n$> git --version\ngit version 1.6.2.1\n\n\nNow, you can try:\n\ngit reset HEAD .\n\n\nThis should be what you are looking for.\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '13 at 11:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 19 '09 at 16:38\nKokotte23\n3973\n3 silver badges\n2\n2 bronze badges","comments":["Sure, but then you have the followup question of how one should unadd one of two (or more) files added. The \"git reset\" manual does mention that \"git reset <paths>\" is the opposite of \"git add <paths>\", however."]},{"answer":"To remove new files from the staging area (and only in case of a new file), as suggested above:\n\ngit rm --cached FILE\n\n\nUse rm --cached only for new files accidentally added.\n\nShare\nImprove this answer\nFollow\nedited Jun 22 '09 at 19:46\nanswered Jun 22 '09 at 11:58\nRan\n7,12312\n12 gold badges\n56\n56 silver badges\n72\n72 bronze badges","comments":["Mind that the --cached is a really important part here.","-1; no, this doesn't un-stage the file, it stages a deletion of the file (without actually deleting it from your work tree)."]},{"answer":"To reset every file in a particular folder (and its subfolders), you can use the following command:\n\ngit reset *\n\nShare\nImprove this answer\nFollow\nanswered Jul 26 '12 at 7:50\nZorayr\n20.7k5\n5 gold badges\n112\n112 silver badges\n103\n103 bronze badges","comments":["Actually, this does not reset every file because * uses shell expansion and it ignores dotfiles (and dot-directories).","You can run git status to see anything remaining and reset it manually i.e. git reset file."]},{"answer":"Use the * command to handle multiple files at a time:\n\ngit reset HEAD *.prj\ngit reset HEAD *.bmp\ngit reset HEAD *gdb*\n\n\netc.\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:31\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 27 '13 at 21:15\nboulder_ruby\n33.5k8\n8 gold badges\n67\n67 silver badges\n93\n93 bronze badges","comments":["Mind that * will usually not include dotfiles or 'dot-directories' unless you explicitly specify .* or .*.prj"]},{"answer":"Just type git reset it will revert back and it is like you never typed git add . since your last commit. Make sure you have committed before.\n\nShare\nImprove this answer\nFollow\nedited Apr 22 '15 at 10:57\nPiyush\n3,7577\n7 gold badges\n32\n32 silver badges\n64\n64 bronze badges\nanswered May 19 '10 at 3:49\nDonovan\n3053\n3 silver badges\n3\n3 bronze badges","comments":["As it happens, there was a last commit... but I was specifically asking about removing a single file from the commit, not every file from the commit."]},{"answer":"Suppose I create a new file, newFile.txt:\n\nSuppose I add the file accidentally, git add newFile.txt:\n\nNow I want to undo this add, before commit, git reset newFile.txt:\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 4 '16 at 11:02\nVidura Mudalige\n7602\n2 gold badges\n14\n14 silver badges\n26\n26 bronze badges","comments":["Suppose I am at 1st pic meaning meaning I have not even did \"git.add\". Also, I not at all want all this change. I mean when I do git status, it should not show any red files. I mean it should be in sync as if there was not a single file altered since the last git push. how to achieve that.","SO suppose you are just at step first. And you want to get rid of all the changes you have done which is making \"newFile.txt\" to come up as red.","When I do git status. I should not see any change at all. All the red files should get reverted.","Hi, I think your question is how to remove untracked files from the current tree. For that, you can use \"git clean -f -d\". This will remove untracked directories as well.","If you don't want to delete the untracked files, just ignore \"-f\" flag."]},{"answer":"2019 update\n\nAs pointed out by others in related questions (see here, here, here, here, here, here, and here), you can now unstage a single file with:\n\ngit restore --staged <file>\n\n\nand unstage all files (from the root of the repo) with:\n\ngit restore --staged .\n\nNotes\n\ngit restore was introduced in July 2019 and released in version 2.23.\nWith the --staged flag, it restores the content of the index (what is asked here).\n\nWhen running git status with staged uncommitted file(s), this is now what Git suggests to use to unstage file(s) (instead of git reset HEAD <file> as it used to prior to v2.23).\n\nShare\nImprove this answer\nFollow\nedited Feb 18 at 21:30\nanswered Jun 25 '20 at 6:23\nprosoitos\n5,0215\n5 gold badges\n20\n20 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"For a specific file:\n\ngit reset my_file.txt\ngit checkout my_file.txt\n\nFor all added files:\n\ngit reset .\ngit checkout .\n\nNote: checkout changes the code in the files and moves to the last updated (committed) state. reset doesn't change the codes; it just resets the header.\n\nShare\nImprove this answer\nFollow\nedited Sep 28 '18 at 18:11\nJonathan Leffler\n674k127\n127 gold badges\n821\n821 silver badges\n1193\n1193 bronze badges\nanswered Oct 28 '17 at 6:03\nHasib Kamal\n2,04520\n20 silver badges\n26\n26 bronze badges","comments":["Please explain the difference between git reset <file> and git checkout <file>.","reset doesn't change the file, just put it away from the stage (=index, where it was put by git add)","checkout change the codes in file and move to the last updated state. reset doesn't change the codes it just reset the header. As example, reset use for added or committed files resetting before push and checkout use for back to the last updated/committed stage before git add.","reset = remove the file from stage however changes will still be there. checkout = gets the updated file from the repository and will overrides the current file"]},{"answer":"To undo git add, use:\n\ngit reset filename\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:43\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 2 '16 at 15:54\nAnirudh Sood\n1,39011\n11 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"There is also interactive mode:\n\ngit add -i\n\n\nChoose option 3 to un add files. In my case I often want to add more than one file, and with interactive mode you can use numbers like this to add files. This will take all but 4: 1, 2, 3, and 5\n\nTo choose a sequence, just type 1-5 to take all from 1 to 5.\n\nGit staging files\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 22 '15 at 13:03\nJonathan\n2793\n3 silver badges\n9\n9 bronze badges","comments":["\"I'm surprised that no one mention interactive mode\" - they did: stackoverflow.com/a/10209776/1709587"]},{"answer":"This command will unstash your changes:\n\ngit reset HEAD filename.txt\n\n\nYou can also use\n\ngit add -p \n\n\nto add parts of files.\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '13 at 11:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 31 '13 at 15:43\nwallerjake\n3,8593\n3 gold badges\n24\n24 silver badges\n31\n31 bronze badges","comments":[]},{"answer":"git add myfile.txt # This will add your file into the to-be-committed list\n\nQuite opposite to this command is,\n\ngit reset HEAD myfile.txt  # This will undo it.\n\n\nso, you will be in the previous state. Specified will be again in untracked list (previous state).\n\nIt will reset your head with that specified file. so, if your head doesn't have it means, it will simply reset it.\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '19 at 13:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 27 '17 at 13:58\nMohideen bin Mohammed\n14.9k7\n7 gold badges\n87\n87 silver badges\n101\n101 bronze badges","comments":[]},{"answer":"git reset filename.txt\n\n\nWill remove a file named filename.txt from the current index, the \"about to be committed\" area, without changing anything else.\n\nShare\nImprove this answer\nFollow\nanswered Jul 11 '16 at 18:40\nRahul Sinha\n1,1019\n9 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"git reset filename.txt  \n\n\nWill remove a file named filename.txt from the current index, the \"about to be committed\" area, without changing anything else.\n\nShare\nImprove this answer\nFollow\nanswered Oct 26 '17 at 18:15\nJoseph Mathew\n1,04912\n12 silver badges\n17\n17 bronze badges","comments":["git reset [file name] ex : git reset src/main/java/com/dao/ImportCsvDataDaoImpl.java"]}]},{"id":"5767325","href":"https://stackoverflow.com/questions/5767325/how-can-i-remove-a-specific-item-from-an-array","title":"How can I remove a specific item from an array?","description":"\n                \nI have an array of numbers and I'm using the .push() method to add elements to it.\n\nIs there a simple way to remove a specific element from an array?\n\nI'm looking for the equivalent of something like:\n\narray.remove(number);\n\n\nI have to use core JavaScript. Frameworks are not allowed.\n    ","questionComments":["array.remove(index) or array.pull(index) would make a lot of sense. splice is very useful, but a remove() or pull() method would be welcome... Search the internet, you will find a lot of \"What is the opposite of push() in JavaScript?\" questions. Would be great if the answare could be as simples as plain english: Pull!","For those who don't want indexOf() + splice(): developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/… developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/…","Opposite of push is pop","const array = [2, 5, 9]; console.log(array); const index = array.indexOf(5); if (index > -1) { array.splice(index, 1); } // array = [2, 9] console.log(array);"],"answers":[{"answer":"Find the index of the array element you want to remove using indexOf, and then remove that index with splice.\n\nThe splice() method changes the contents of an array by removing existing elements and/or adding new elements.\n\nconst array = [2, 5, 9];\n\nconsole.log(array);\n\nconst index = array.indexOf(5);\nif (index > -1) {\n  array.splice(index, 1);\n}\n\n// array = [2, 9]\nconsole.log(array); \n Run code snippetExpand snippet\n\nThe second parameter of splice is the number of elements to remove. Note that splice modifies the array in place and returns a new array containing the elements that have been removed.\n\nFor the reason of completeness, here are functions. The first function removes only a single occurrence (i.e. removing the first match of 5 from [2,5,9,1,5,8,5]), while the second function removes all occurrences:\n\nfunction removeItemOnce(arr, value) {\n  var index = arr.indexOf(value);\n  if (index > -1) {\n    arr.splice(index, 1);\n  }\n  return arr;\n}\n\nfunction removeItemAll(arr, value) {\n  var i = 0;\n  while (i < arr.length) {\n    if (arr[i] === value) {\n      arr.splice(i, 1);\n    } else {\n      ++i;\n    }\n  }\n  return arr;\n}\n// Usage\nconsole.log(removeItemOnce([2,5,9,1,5,8,5], 5))\nconsole.log(removeItemAll([2,5,9,1,5,8,5], 5))\n Run code snippetExpand snippet\n\nIn TypeScript, these functions can stay type-safe with a type parameter:\n\nfunction removeItem<T>(arr: Array<T>, value: T): Array<T> { \n  const index = arr.indexOf(value);\n  if (index > -1) {\n    arr.splice(index, 1);\n  }\n  return arr;\n}\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 4:05\ncommunity wiki\n\n\n30 revs, 25 users 13%\nJustin Liu","comments":["Serious question: why doesn't JavaScript allow the simple and intuitive method of removing an element at an index? A simple, elegant, myArray.remove(index); seems to be the best solution and is implemented in many other languages (a lot of them older than JavaScript.)","@Andrew sets and arrays are two completely different collection types.","You can simplify this solution by counting down instead of up: for ( var i = ary.length - 1; i >= 0; i-- ) { if ( ary[i] === value ) { ary.remove(i)} }","function remove(item,array) { var new_array = [] new_ array = array.filter((ar)=> ar != item) return new_array }","I'm a bit late to the party, but here's my two cents: @a2br: Array.unshift() is basically what pull() would be if it existed! @Bob: Personally, I think it's good that nothing similar to Array.remove() exists. We don't want JavaScript to end up like PHP, now do we? xD"]},{"answer":"Edited on 2016 October\n\nDo it simple, intuitive and explicit (Occam's razor)\nDo it immutable (original array stay unchanged)\nDo it with standard JavaScript functions, if your browser doesn't support them - use polyfill\n\nIn this code example I use \"array.filter(...)\" function to remove unwanted items from an array. This function doesn't change the original array and creates a new one. If your browser doesn't support this function (e.g. Internet Explorer before version 9, or Firefox before version 1.5), consider using the filter polyfill from Mozilla.\n\nRemoving item (ECMA-262 Edition 5 code aka oldstyle JavaScript)\nvar value = 3\n\nvar arr = [1, 2, 3, 4, 5, 3]\n\narr = arr.filter(function(item) {\n    return item !== value\n})\n\nconsole.log(arr)\n// [ 1, 2, 4, 5 ]\n\nRemoving item (ECMAScript 6 code)\nlet value = 3\n\nlet arr = [1, 2, 3, 4, 5, 3]\n\narr = arr.filter(item => item !== value)\n\nconsole.log(arr)\n// [ 1, 2, 4, 5 ]\n\n\nIMPORTANT ECMAScript 6 \"() => {}\" arrow function syntax is not supported in Internet Explorer at all, Chrome before 45 version, Firefox before 22 version, and Safari before 10 version. To use ECMAScript 6 syntax in old browsers you can use BabelJS.\n\nRemoving multiple items (ECMAScript 7 code)\n\nAn additional advantage of this method is that you can remove multiple items\n\nlet forDeletion = [2, 3, 5]\n\nlet arr = [1, 2, 3, 4, 5, 3]\n\narr = arr.filter(item => !forDeletion.includes(item))\n// !!! Read below about array.includes(...) support !!!\n\nconsole.log(arr)\n// [ 1, 4 ]\n\n\nIMPORTANT \"array.includes(...)\" function is not supported in Internet Explorer at all, Chrome before 47 version, Firefox before 43 version, Safari before 9 version, and Edge before 14 version so here is polyfill from Mozilla.\n\nRemoving multiple items (in the future, maybe)\n\nIf the \"This-Binding Syntax\" proposal is ever accepted, you'll be able to do this:\n\n// array-lib.js\n\nexport function remove(...forDeletion) {\n    return this.filter(item => !forDeletion.includes(item))\n}\n\n// main.js\n\nimport { remove } from './array-lib.js'\n\nlet arr = [1, 2, 3, 4, 5, 3]\n\n// :: This-Binding Syntax Proposal\n// using \"remove\" function as \"virtual method\"\n// without extending Array.prototype\narr = arr::remove(2, 3, 5)\n\nconsole.log(arr)\n// [ 1, 4 ]\n\n\nTry it yourself in BabelJS :)\n\nReference\n\nArray.prototype.includes\nFunctional composition\nShare\nImprove this answer\nFollow\nedited Jan 18 at 22:58\nashleedawg\n17.6k5\n5 gold badges\n60\n60 silver badges\n83\n83 bronze badges\nanswered Dec 19 '13 at 19:54\nujeenator\n19.4k2\n2 gold badges\n20\n20 silver badges\n27\n27 bronze badges","comments":["what if content of array are objects and nested objects"]},{"answer":"I don't know how you are expecting array.remove(int) to behave. There are three possibilities I can think of that you might want.\n\nTo remove an element of an array at an index i:\n\narray.splice(i, 1);\n\n\nIf you want to remove every element with value number from the array:\n\nfor (var i = array.length - 1; i >= 0; i--) {\n if (array[i] === number) {\n  array.splice(i, 1);\n }\n}\n\n\nIf you just want to make the element at index i no longer exist, but you don't want the indexes of the other elements to change:\n\ndelete array[i];\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '20 at 14:33\nLioness100\n7,4225\n5 gold badges\n11\n11 silver badges\n45\n45 bronze badges\nanswered Apr 23 '11 at 22:20\nPeter Olson\n124k47\n47 gold badges\n190\n190 silver badges\n235\n235 bronze badges","comments":[]},{"answer":"It depends on whether you want to keep an empty spot or not.\n\nIf you do want an empty slot:\n\narray[index] = undefined;\n\n\nIf you don't want an empty slot:\n\n//To keep the original:\n//oldArray = [...array];\n\n//This modifies the array.\narray.splice(index, 1);\n\n\nAnd if you need the value of that item, you can just store the returned array's element:\n\nvar value = array.splice(index, 1)[0];\n\n\nIf you want to remove at either end of the array, you can use array.pop() for the last one or array.shift() for the first one (both return the value of the item as well).\n\nIf you don't know the index of the item, you can use array.indexOf(item) to get it (in a if() to get one item or in a while() to get all of them). array.indexOf(item) returns either the index or -1 if not found. \n\nShare\nImprove this answer\nFollow\nedited Jun 16 '20 at 4:51\nAndrew\n3,7271\n1 gold badge\n38\n38 silver badges\n55\n55 bronze badges\nanswered Apr 23 '11 at 22:32\nxavierm02\n7,2811\n1 gold badge\n17\n17 silver badges\n24\n24 bronze badges","comments":["It's kinda funny that splice returns another array built out of the removed elements. I wrote something which assumed splice would return the newly modified list (like what immutable collections would do, for example). So, in this particular case of only one item in the list, and that item being removed, the returned list is exactly identical to the original one after splicing that one item. So, my app went into an infinite loop."]},{"answer":"A friend was having issues in Internet Explorer 8 and showed me what he did. I told him it was wrong, and he told me he got the answer here. The current top answer will not work in all browsers (Internet Explorer 8 for example), and it will only remove the first occurrence of the item.\n\nRemove ALL instances from an array\nfunction removeAllInstances(arr, item) {\n   for (var i = arr.length; i--;) {\n     if (arr[i] === item) arr.splice(i, 1);\n   }\n}\n\n\nIt loops through the array backwards (since indices and length will change as items are removed) and removes the item if it's found. It works in all browsers.\n\nShare\nImprove this answer\nFollow\nedited Apr 8 at 17:35\nanswered Aug 10 '13 at 19:21\nBen Lesh\n106k47\n47 gold badges\n244\n244 silver badges\n231\n231 bronze badges","comments":[]},{"answer":"There are two major approaches:\n\nsplice(): anArray.splice(index, 1);\n\ndelete: delete anArray[index];\n\nBe careful when you use the delete for an array. It is good for deleting attributes of objects, but not so good for arrays. It is better to use splice for arrays.\n\nKeep in mind that when you use delete for an array you could get wrong results for anArray.length. In other words, delete would remove the element, but it wouldn't update the value of the length property.\n\nYou can also expect to have holes in index numbers after using delete, e.g. you could end up with having indexes 1, 3, 4, 8, 9, and 11 and length as it was before using delete. In that case, all indexed for loops would crash, since indexes are no longer sequential.\n\nIf you are forced to use delete for some reason, then you should use for each loops when you need to loop through arrays. As the matter of fact, always avoid using indexed for loops, if possible. That way the code would be more robust and less prone to problems with indexes.\n\nShare\nImprove this answer\nFollow\nedited Apr 26 at 8:12\nanswered Dec 21 '12 at 11:32\nSaša\n3,3181\n1 gold badge\n21\n21 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"Array.prototype.remove_by_value = function(val) {\n for (var i = 0; i < this.length; i++) {\n  if (this[i] === val) {\n   this.splice(i, 1);\n   i--;\n  }\n }\n return this;\n}[\n // call like\n (1, 2, 3, 4)\n].remove_by_value(3);\n\n\nArray.prototype.remove_by_value = function(val) {\n  for (var i = 0; i < this.length; i++) {\n    if (this[i] === val) {\n      this.splice(i, 1);\n      i--;\n    }\n  }\n  return this;\n}\n\nvar rooms = ['hello', 'something']\n\nrooms = rooms.remove_by_value('hello')\n\nconsole.log(rooms)\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '20 at 14:35\nLioness100\n7,4225\n5 gold badges\n11\n11 silver badges\n45\n45 bronze badges\nanswered Apr 23 '11 at 22:20\nZirak\n35.8k12\n12 gold badges\n76\n76 silver badges\n89\n89 bronze badges","comments":["Many frown on modifying prototypes that don't belong to you."]},{"answer":"There is no need to use indexOf or splice. However, it performs better if you only want to remove one occurrence of an element.\n\nFind and move (move):\n\nfunction move(arr, val) {\n  var j = 0;\n  for (var i = 0, l = arr.length; i < l; i++) {\n    if (arr[i] !== val) {\n      arr[j++] = arr[i];\n    }\n  }\n  arr.length = j;\n}\n\n\nUse indexOf and splice (indexof):\n\nfunction indexof(arr, val) {\n  var i;\n  while ((i = arr.indexOf(val)) != -1) {\n    arr.splice(i, 1);\n  }\n}\n\n\nUse only splice (splice):\n\nfunction splice(arr, val) {\n  for (var i = arr.length; i--;) {\n    if (arr[i] === val) {\n      arr.splice(i, 1);\n    }\n  }\n}\n\n\nRun-times on nodejs for array with 1000 elements (average over 10000 runs):\n\nindexof is approximately 10x slower than move. Even if improved by removing the call to indexOf in splice it performs much worse than move.\n\nRemove all occurrences:\n    move 0.0048 ms\n    indexof 0.0463 ms\n    splice 0.0359 ms\n\nRemove first occurrence:\n    move_one 0.0041 ms\n    indexof_one 0.0021 ms\n\nShare\nImprove this answer\nFollow\nedited Sep 11 '15 at 12:47\nanswered Sep 19 '13 at 1:53\nslosd\n2,6142\n2 gold badges\n18\n18 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"This provides a predicate instead of a value.\n\nNOTE: it will update the given array, and return the affected rows.\n\nUsage\nvar removed = helper.remove(arr, row => row.id === 5 );\n\nvar removed = helper.removeAll(arr, row => row.name.startsWith('BMW'));\n\nDefinition\nvar helper = {\n // Remove and return the first occurrence\n\n remove: function(array, predicate) {\n  for (var i = 0; i < array.length; i++) {\n   if (predicate(array[i])) {\n    return array.splice(i, 1);\n   }\n  }\n },\n\n // Remove and return all occurrences\n\n removeAll: function(array, predicate) {\n  var removed = [];\n\n  for (var i = 0; i < array.length; ) {\n   if (predicate(array[i])) {\n    removed.push(array.splice(i, 1));\n    continue;\n   }\n   i++;\n  }\n  return removed;\n },\n};\n\nShare\nImprove this answer\nFollow\nedited Aug 1 at 8:39\nanswered May 2 '14 at 12:00\namd\n18.3k6\n6 gold badges\n45\n45 silver badges\n64\n64 bronze badges","comments":["put your code in code snippet so other users could see the result"]},{"answer":"You can do it easily with the filter method:\n\nfunction remove(arrOriginal, elementToRemove){\n    return arrOriginal.filter(function(el){return el !== elementToRemove});\n}\nconsole.log(remove([1, 2, 1, 0, 3, 1, 4], 1));\n Run code snippetExpand snippet\n\nThis removes all elements from the array and also works faster than a combination of slice and indexOf.\n\nShare\nImprove this answer\nFollow\nedited Jan 31 at 11:47\nMasoud Aghaei\n4723\n3 silver badges\n14\n14 bronze badges\nanswered Feb 10 '14 at 22:06\nSalvador Dali\n187k132\n132 gold badges\n649\n649 silver badges\n715\n715 bronze badges","comments":[]},{"answer":"John Resig posted a good implementation:\n\n// Array Remove - By John Resig (MIT Licensed)\nArray.prototype.remove = function(from, to) {\n  var rest = this.slice((to || from) + 1 || this.length);\n  this.length = from < 0 ? this.length + from : from;\n  return this.push.apply(this, rest);\n};\n\n\nIf you don’t want to extend a global object, you can do something like the following, instead:\n\n// Array Remove - By John Resig (MIT Licensed)\nArray.remove = function(array, from, to) {\n    var rest = array.slice((to || from) + 1 || array.length);\n    array.length = from < 0 ? array.length + from : from;\n    return array.push.apply(array, rest);\n};\n\n\nBut the main reason I am posting this is to warn users against the alternative implementation suggested in the comments on that page (Dec 14, 2007):\n\nArray.prototype.remove = function(from, to){\n  this.splice(from, (to=[0,from||1,++to-from][arguments.length])<0?this.length+to:to);\n  return this.length;\n};\n\n\nIt seems to work well at first, but through a painful process I discovered it fails when trying to remove the second to last element in an array. For example, if you have a 10-element array and you try to remove the 9th element with this:\n\nmyArray.remove(8);\n\n\nYou end up with an 8-element array. Don't know why but I confirmed John's original implementation doesn't have this problem.\n\nShare\nImprove this answer\nFollow\nedited Feb 16 '15 at 12:51\nmagiccrafter\n4,2591\n1 gold badge\n46\n46 silver badges\n41\n41 bronze badges\nanswered Aug 30 '13 at 19:07\nRoger\n1,70417\n17 silver badges\n22\n22 bronze badges","comments":[]},{"answer":"You can use ES6. For example to delete the value '3' in this case:\n\nvar array=['1','2','3','4','5','6']\nvar newArray = array.filter((value)=>value!='3');\nconsole.log(newArray);\n\n\nOutput :\n\n[\"1\", \"2\", \"4\", \"5\", \"6\"]\n\nShare\nImprove this answer\nFollow\nedited Oct 1 '19 at 22:13\ndarmis\n1,7091\n1 gold badge\n15\n15 silver badges\n19\n19 bronze badges\nanswered Oct 4 '16 at 8:07\nrajat44\n4,1815\n5 gold badges\n26\n26 silver badges\n35\n35 bronze badges","comments":["This answer is nice because it creates a copy of the original array, instead of modifying the original directly.","Note: Array.prototype.filter is ECMAScript 5.1 (No IE8). for more specific solutions: stackoverflow.com/a/54390552/8958729"]},{"answer":"Underscore.js can be used to solve issues with multiple browsers. It uses in-build browser methods if present. If they are absent like in the case of older Internet Explorer versions it uses its own custom methods.\n\nA simple example to remove elements from array (from the website):\n\n_.without([1, 2, 1, 0, 3, 1, 4], 0, 1); // => [2, 3, 4]\n\nShare\nImprove this answer\nFollow\nedited May 21 '17 at 11:29\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 30 '14 at 9:57\nvatsal\n3,4171\n1 gold badge\n17\n17 silver badges\n19\n19 bronze badges","comments":["though elegant and concise, OP clearly mentioned core JS only"]},{"answer":"If you want a new array with the deleted positions removed, you can always delete the specific element and filter out the array. It might need an extension of the array object for browsers that don't implement the filter method, but in the long term it's easier since all you do is this:\n\nvar my_array = [1, 2, 3, 4, 5, 6];\ndelete my_array[4];\nconsole.log(my_array.filter(function(a){return typeof a !== 'undefined';}));\n\n\nIt should display [1, 2, 3, 4, 6].\n\nShare\nImprove this answer\nFollow\nedited Sep 1 '19 at 20:30\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 18 '12 at 10:13\nLoupax\n4,1344\n4 gold badges\n36\n36 silver badges\n64\n64 bronze badges","comments":[]},{"answer":"Here are a few ways to remove an item from an array using JavaScript.\n\nAll the method described do not mutate the original array, and instead create a new one.\n\nIf you know the index of an item\n\nSuppose you have an array, and you want to remove an item in position i.\n\nOne method is to use slice():\n\nconst items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst i = 3\nconst filteredItems = items.slice(0, i).concat(items.slice(i+1, items.length))\n\nconsole.log(filteredItems)\n Run code snippetExpand snippet\n\nslice() creates a new array with the indexes it receives. We simply create a new array, from start to the index we want to remove, and concatenate another array from the first position following the one we removed to the end of the array.\n\nIf you know the value\n\nIn this case, one good option is to use filter(), which offers a more declarative approach:\n\nconst items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valueToRemove = 'c'\nconst filteredItems = items.filter(item => item !== valueToRemove)\n\nconsole.log(filteredItems)\n Run code snippetExpand snippet\n\nThis uses the ES6 arrow functions. You can use the traditional functions to support older browsers:\n\nconst items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valueToRemove = 'c'\nconst filteredItems = items.filter(function(item) {\n  return item !== valueToRemove\n})\n\nconsole.log(filteredItems)\n Run code snippetExpand snippet\n\nor you can use Babel and transpile the ES6 code back to ES5 to make it more digestible to old browsers, yet write modern JavaScript in your code.\n\nRemoving multiple items\n\nWhat if instead of a single item, you want to remove many items?\n\nLet's find the simplest solution.\n\nBy index\n\nYou can just create a function and remove items in series:\n\nconst items = ['a', 'b', 'c', 'd', 'e', 'f']\n\nconst removeItem = (items, i) =>\n  items.slice(0, i-1).concat(items.slice(i, items.length))\n\nlet filteredItems = removeItem(items, 3)\nfilteredItems = removeItem(filteredItems, 5)\n//[\"a\", \"b\", \"c\", \"d\"]\n\nconsole.log(filteredItems)\n Run code snippetExpand snippet\n\nBy value\n\nYou can search for inclusion inside the callback function:\n\nconst items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valuesToRemove = ['c', 'd']\nconst filteredItems = items.filter(item => !valuesToRemove.includes(item))\n// [\"a\", \"b\", \"e\", \"f\"]\n\nconsole.log(filteredItems)\n Run code snippetExpand snippet\n\nAvoid mutating the original array\n\nsplice() (not to be confused with slice()) mutates the original array, and should be avoided.\n\n(originally posted on my site https://flaviocopes.com/how-to-remove-item-from-array/)\n\nShare\nImprove this answer\nFollow\nedited Jul 26 '20 at 9:45\nBhargav Rao♦\n42.1k27\n27 gold badges\n113\n113 silver badges\n129\n129 bronze badges\nanswered May 4 '18 at 5:17\nFlavio Copes\n3,6023\n3 gold badges\n24\n24 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"Check out this code. It works in every major browser.\n\nremove_item = function(arr, value) {\n var b = '';\n for (b in arr) {\n  if (arr[b] === value) {\n   arr.splice(b, 1);\n   break;\n  }\n }\n return arr;\n};\n\nvar array = [1,3,5,6,5,9,5,3,55]\nvar res = remove_item(array,5);\nconsole.log(res)\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Feb 2 at 23:45\nMasoud Aghaei\n4723\n3 silver badges\n14\n14 bronze badges\nanswered Apr 2 '13 at 10:56\nEkramul Hoque\n4,5013\n3 gold badges\n28\n28 silver badges\n31\n31 bronze badges","comments":["@RolandIllig Except the use of a for in-loop and the fact that the script could stopped earlier, by returning the result from the loop directly. The upvotes are reasonable ;)","I should also reiterate yckart's comment that for( i = 0; i < arr.length; i++ ) would be a better approach since it preserves the exact indices versus whatever order the browser decides to store the items (with for in). Doing so also lets you get the array index of a value if you need it."]},{"answer":"ES6 & without mutation: (October 2016)\n\nconst removeByIndex = (list, index) =>\n      [\n        ...list.slice(0, index),\n        ...list.slice(index + 1)\n      ];\n         \noutput = removeByIndex([33,22,11,44],1) //=> [33,11,44]\n      \nconsole.log(output)\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Feb 10 '20 at 7:37\ndipenparmar12\n1,6431\n1 gold badge\n18\n18 silver badges\n28\n28 bronze badges\nanswered Oct 7 '16 at 19:42\nAbdennour TOUMI\n67.7k29\n29 gold badges\n206\n206 silver badges\n212\n212 bronze badges","comments":["Why not just use filter then? array.filter((_, index) => index !== removedIndex);.","@user4642212 you are right! also, I liked the underscore of Golang style"]},{"answer":"You can use lodash _.pull (mutate array), _.pullAt (mutate array) or _.without (does't mutate array),\n\nvar array1 = ['a', 'b', 'c', 'd']\n_.pull(array1, 'c')\nconsole.log(array1) // ['a', 'b', 'd']\n\nvar array2 = ['e', 'f', 'g', 'h']\n_.pullAt(array2, 0)\nconsole.log(array2) // ['f', 'g', 'h']\n\nvar array3 = ['i', 'j', 'k', 'l']\nvar newArray = _.without(array3, 'i') // ['j', 'k', 'l']\nconsole.log(array3) // ['i', 'j', 'k', 'l']\n\nShare\nImprove this answer\nFollow\nedited Aug 25 '15 at 21:19\nanswered Aug 25 '15 at 19:34\nChun Yang\n2,08520\n20 silver badges\n16\n16 bronze badges","comments":["That's not core JS as the OP requested, is it?","@some-non-descript-user You are right. But a lot of users like me come here looking for a general answer not just for the OP only.","@ChunYang You are absolutely right. I am already using lodash, why not just use it if it saves time."]},{"answer":"Removing a particular element/string from an array can be done in a one-liner:\n\ntheArray.splice(theArray.indexOf(\"stringToRemoveFromArray\"), 1);\n\n\nwhere:\n\ntheArray: the array you want to remove something particular from\n\nstringToRemoveFromArray: the string you want to be removed and 1 is the number of elements you want to remove.\n\nNOTE: If \"stringToRemoveFromArray\" is not located in the array, this will remove the last element of the array.\n\nIt's always good practice to check if the element exists in your array first, before removing it.\n\nif (theArray.indexOf(\"stringToRemoveFromArray\") >= 0){\n   theArray.splice(theArray.indexOf(\"stringToRemoveFromArray\"), 1);\n}\n\n\nDepending if you have newer or older version of Ecmascript running on your client's computers:\n\nvar array=['1','2','3','4','5','6']\nvar newArray = array.filter((value)=>value!='3');\n\n\nOR\n\nvar array = ['1','2','3','4','5','6'];\nvar newArray = array.filter(function(item){ return item !== '3' });\n\n\nWhere '3' is the value you want to be removed from the array. The array would then become : ['1','2','4','5','6']\n\nShare\nImprove this answer\nFollow\nedited Jan 29 at 21:55\nanswered Jan 8 '19 at 14:34\nMax Alexander Hanna\n2,53922\n22 silver badges\n28\n28 bronze badges","comments":["This is the answer that worked for me when trying to update an array based on radio button toggling.","Beware, if \"stringToRemoveFromArray\" is not located your in array, this will remove last element of array."]},{"answer":"Performance\n\nToday (2019-12-09) I conduct performance tests on macOS v10.13.6 (High Sierra) for chosen solutions. I show delete (A), but I do not use it in comparison with other methods, because it left empty space in the array.\n\nThe conclusions\n\nthe fastest solution is array.splice (C) (except Safari for small arrays where it has the second time)\nfor big arrays, array.slice+splice (H) is the fastest immutable solution for Firefox and Safari; Array.from (B) is fastest in Chrome\nmutable solutions are usually 1.5x-6x faster than immutable\nfor small tables on Safari, surprisingly the mutable solution (C) is slower than the immutable solution (G)\nDetails\n\nIn tests, I remove the middle element from the array in different ways. The A, C solutions are in-place. The B, D, E, F, G, H solutions are immutable.\n\nResults for an array with 10 elements\n\nIn Chrome the array.splice (C) is the fastest in-place solution. The array.filter (D) is the fastest immutable solution. The slowest is array.slice (F). You can perform the test on your machine here.\n\nResults for an array with 1.000.000 elements\n\nIn Chrome the array.splice (C) is the fastest in-place solution (the delete (C) is similar fast - but it left an empty slot in the array (so it does not perform a 'full remove')). The array.slice-splice (H) is the fastest immutable solution. The slowest is array.filter (D and E). You can perform the test on your machine here.\n\nShow code snippet\n\nComparison for browsers: Chrome v78.0.0, Safari v13.0.4, and Firefox v71.0.0\n\nShare\nImprove this answer\nFollow\nedited Jan 26 at 9:12\nAmmar\n556\n6 bronze badges\nanswered Dec 9 '19 at 16:04\nKamil Kiełczewski\n57.6k22\n22 gold badges\n275\n275 silver badges\n253\n253 bronze badges","comments":[]},{"answer":"OK, for example you have the array below:\n\nvar num = [1, 2, 3, 4, 5];\n\n\nAnd we want to delete number 4. You can simply use the below code:\n\nnum.splice(num.indexOf(4), 1); // num will be [1, 2, 3, 5];\n\n\nIf you are reusing this function, you write a reusable function which will be attached to the native array function like below:\n\nArray.prototype.remove = Array.prototype.remove || function(x) {\n  const i = this.indexOf(x);\n  if(i===-1)\n      return;\n  this.splice(i, 1); // num.remove(5) === [1, 2, 3];\n}\n\n\nBut how about if you have the below array instead with a few [5]s in the array?\n\nvar num = [5, 6, 5, 4, 5, 1, 5];\n\n\nWe need a loop to check them all, but an easier and more efficient way is using built-in JavaScript functions, so we write a function which use a filter like below instead:\n\nconst _removeValue = (arr, x) => arr.filter(n => n!==x);\n//_removeValue([1, 2, 3, 4, 5, 5, 6, 5], 5) // Return [1, 2, 3, 4, 6]\n\n\nAlso there are third-party libraries which do help you to do this, like Lodash or Underscore. For more information, look at lodash _.pull, _.pullAt or _.without.\n\nShare\nImprove this answer\nFollow\nedited Sep 1 '19 at 22:33\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 10 '17 at 9:39\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"I'm pretty new to JavaScript and needed this functionality. I merely wrote this:\n\nfunction removeFromArray(array, item, index) {\n  while((index = array.indexOf(item)) > -1) {\n    array.splice(index, 1);\n  }\n}\n\n\nThen when I want to use it:\n\n//Set-up some dummy data\nvar dummyObj = {name:\"meow\"};\nvar dummyArray = [dummyObj, \"item1\", \"item1\", \"item2\"];\n\n//Remove the dummy data\nremoveFromArray(dummyArray, dummyObj);\nremoveFromArray(dummyArray, \"item2\");\n\n\nOutput - As expected. [\"item1\", \"item1\"]\n\nYou may have different needs than I, so you can easily modify it to suit them. I hope this helps someone.\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '14 at 16:17\nyckart\n28.7k7\n7 gold badges\n112\n112 silver badges\n122\n122 bronze badges\nanswered Jan 16 '14 at 11:27\nsofiax\n4494\n4 silver badges\n3\n3 bronze badges","comments":["This is going to have terrible behavior if your array is really long and there are several instances of the element in it. The indexOf method of array will start at the beginning every time, so your cost is going to be O(n^2).","@Zag: It has a name: Shlemiel the Painter's Algorithm"]},{"answer":"If you have complex objects in the array you can use filters? In situations where $.inArray or array.splice is not as easy to use. Especially if the objects are perhaps shallow in the array.\n\nE.g. if you have an object with an Id field and you want the object removed from an array:\n\nthis.array = this.array.filter(function(element, i) {\n    return element.id !== idToRemove;\n});\n\nShare\nImprove this answer\nFollow\nedited Nov 10 '15 at 4:20\nAnik Islam Abhi\n24.5k8\n8 gold badges\n52\n52 silver badges\n76\n76 bronze badges\nanswered Apr 9 '15 at 10:00\nflurdy\n3,39227\n27 silver badges\n30\n30 bronze badges","comments":["This is how I like to do it. Using an arrow function it can be a one-liner. I'm curious about performance. Also worth nothing that this replaces the array. Any code with a reference to the old array will not notice the change."]},{"answer":"I want to answer based on ECMAScript 6. Assume, you have an array like below:\n\nlet arr = [1,2,3,4];\n\n\nIf you want to delete at a special index like 2, write the below code:\n\narr.splice(2, 1); //=> arr became [1,2,4]\n\n\nBut if you want to delete a special item like 3 and you don't know its index, do like below:\n\narr = arr.filter(e => e !== 3); //=> arr became [1,2,4]\n\n\nHint: please use an arrow function for filter callback unless you will get an empty array.\n\nShare\nImprove this answer\nFollow\nedited Sep 1 '19 at 22:59\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 30 '18 at 17:37\nAmerllicA\n17.3k12\n12 gold badges\n82\n82 silver badges\n109\n109 bronze badges","comments":[]},{"answer":"ES10 Update\n\nThis post summarizes common approaches to element removal from an array as of ECMAScript 2019 (ES10).\n\n1. General cases\n1.1. Removing Array element by value using .splice()\n\n| In-place: Yes |\n| Removes duplicates: Yes(loop), No(indexOf) |\n| By value / index: By index |\n\nIf you know the value you want to remove from an array you can use the splice method. First, you must identify the index of the target item. You then use the index as the start element and remove just one element.\n\n// With a 'for' loop\nconst arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0];\nfor( let i = 0; i < arr.length; i++){\n  if ( arr[i] === 5) {\n    arr.splice(i, 1);\n  }\n} // => [1, 2, 3, 4, 6, 7, 8, 9, 0]\n\n// With the .indexOf() method\nconst arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0];\nconst i = arr.indexOf(5);\narr.splice(i, 1); // => [1, 2, 3, 4, 6, 7, 8, 9, 0]\n\n1.2. Removing Array element using the .filter() method\n\n| In-place: No |\n| Removes duplicates: Yes |\n| By value / index: By value |\n\n\nThe specific element can be filtered out from the array, by providing a filtering function. Such function is then called for every element in the array.\n\nconst value = 3\nlet arr = [1, 2, 3, 4, 5, 3]\narr = arr.filter(item => item !== value)\nconsole.log(arr)\n// [ 1, 2, 4, 5 ]\n\n1.3. Removing Array element by extending Array.prototype\n\n| In-place: Yes/No (Depends on implementation) |\n| Removes duplicates: Yes/No (Depends on implementation) |\n| By value / index: By index / By value (Depends on implementation) |\n\nThe prototype of Array can be extended with additional methods. Such methods will be then available to use on created arrays.\n\nNote: Extending prototypes of objects from the standard library of JavaScript (like Array) is considered by some as an antipattern.\n\n// In-place, removes all, by value implementation\nArray.prototype.remove = function(item) {\n    for (let i = 0; i < this.length; i++) {\n        if (this[i] === item) {\n            this.splice(i, 1);\n        }\n    }\n}\nconst arr1 = [1,2,3,1];\narr1.remove(1) // arr1 equals [2,3]\n\n// Non-stationary, removes first, by value implementation\nArray.prototype.remove = function(item) {\n    const arr = this.slice();\n    for (let i = 0; i < this.length; i++) {\n        if (arr[i] === item) {\n            arr.splice(i, 1);\n            return arr;\n        }\n    }\n    return arr;\n}\nlet arr2 = [1,2,3,1];\narr2 = arr2.remove(1) // arr2 equals [2,3,1]\n\n1.4. Removing Array element using the delete operator\n\n| In-place: Yes |\n| Removes duplicates: No |\n| By value / index: By index |\n\nUsing the delete operator does not affect the length property. Nor does it affect the indexes of subsequent elements. The array becomes sparse, which is a fancy way of saying the deleted item is not removed but becomes undefined.\n\nconst arr = [1, 2, 3, 4, 5, 6];\ndelete arr[4]; // Delete element with index 4\nconsole.log( arr ); // [1, 2, 3, 4, undefined, 6]\n\n\nThe delete operator is designed to remove properties from JavaScript objects, which arrays are objects.\n\n1.5. Removing Array element using Object utilities (>= ES10)\n\n| In-place: No |\n| Removes duplicates: Yes |\n| By value / index: By value |\n\nES10 introduced Object.fromEntries, which can be used to create the desired Array from any Array-like object and filter unwanted elements during the process.\n\nconst object = [1,2,3,4];\nconst valueToRemove = 3;\nconst arr = Object.values(Object.fromEntries(\n  Object.entries(object)\n  .filter(([ key, val ]) => val !== valueToRemove)\n));\nconsole.log(arr); // [1,2,4]\n\n2. Special cases\n2.1 Removing element if it's at the end of the Array\n2.1.1. Changing Array length\n\n| In-place: Yes |\n| Removes duplicates: No |\n| By value / index: N/A |\n\nJavaScript Array elements can be removed from the end of an array by setting the length property to a value less than the current value. Any element whose index is greater than or equal to the new length will be removed.\n\nconst arr = [1, 2, 3, 4, 5, 6];\narr.length = 5; // Set length to remove element\nconsole.log( arr ); // [1, 2, 3, 4, 5]\n\n2.1.2. Using .pop() method\n\n| In-place: Yes |\n| Removes duplicates: No |\n| By value / index: N/A |\n\nThe pop method removes the last element of the array, returns that element, and updates the length property. The pop method modifies the array on which it is invoked, This means unlike using delete the last element is removed completely and the array length reduced.\n\nconst arr = [1, 2, 3, 4, 5, 6];\narr.pop(); // returns 6\nconsole.log( arr ); // [1, 2, 3, 4, 5]\n\n2.2. Removing element if it's at the beginning of the Array\n\n| In-place: Yes |\n| Removes duplicates: No |\n| By value / index: N/A |\n\nThe .shift() method works much like the pop method except it removes the first element of a JavaScript array instead of the last. When the element is removed the remaining elements are shifted down.\n\nconst arr = [1, 2, 3, 4];\narr.shift(); // returns 1\nconsole.log( arr ); // [2, 3, 4]\n\n2.3. Removing element if it's the only element in the Array\n\n| In-place: Yes |\n| Removes duplicates: N/A |\n| By value / index: N/A |\n\nThe fastest technique is to set an array variable to an empty array.\n\nlet arr = [1];\narr = []; //empty array\n\n\nAlternatively technique from 2.1.1 can be used by setting length to 0.\n\nShare\nImprove this answer\nFollow\nedited Jan 26 at 7:17\nAmmar\n556\n6 bronze badges\nanswered Apr 2 '20 at 10:15\nM. Twarog\n1,5723\n3 gold badges\n17\n17 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"Update: This method is recommended only if you cannot use ECMAScript 2015 (formerly known as ES6). If you can use it, other answers here provide much neater implementations.\n\nThis gist here will solve your problem, and also deletes all occurrences of the argument instead of just 1 (or a specified value).\n\nArray.prototype.destroy = function(obj){\n    // Return null if no objects were found and removed\n    var destroyed = null;\n\n    for(var i = 0; i < this.length; i++){\n\n        // Use while-loop to find adjacent equal objects\n        while(this[i] === obj){\n\n            // Remove this[i] and store it within destroyed\n            destroyed = this.splice(i, 1)[0];\n        }\n    }\n\n    return destroyed;\n}\n\n\nUsage:\n\nvar x = [1, 2, 3, 3, true, false, undefined, false];\n\nx.destroy(3);         // => 3\nx.destroy(false);     // => false\nx;                    // => [1, 2, true, undefined]\n\nx.destroy(true);      // => true\nx.destroy(undefined); // => undefined\nx;                    // => [1, 2]\n\nx.destroy(3);         // => null\nx;                    // => [1, 2]\n\nShare\nImprove this answer\nFollow\nedited Sep 1 '17 at 22:41\nanswered Mar 13 '13 at 9:28\nzykadelic\n9539\n9 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"You should never mutate your array. As this is against the functional programming pattern. You can create a new array without referencing the array you want to change data of using the ECMAScript 6 method filter;\n\nvar myArray = [1, 2, 3, 4, 5, 6];\n\n\nSuppose you want to remove 5 from the array, you can simply do it like this:\n\nmyArray = myArray.filter(value => value !== 5);\n\n\nThis will give you a new array without the value you wanted to remove. So the result will be:\n\n [1, 2, 3, 4, 6]; // 5 has been removed from this array\n\n\nFor further understanding you can read the MDN documentation on Array.filter.\n\nShare\nImprove this answer\nFollow\nedited Sep 1 '19 at 22:41\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 26 '17 at 19:32\nAdeel Imran\n9,4016\n6 gold badges\n47\n47 silver badges\n72\n72 bronze badges","comments":[]},{"answer":"You can do a backward loop to make sure not to screw up the indexes, if there are multiple instances of the element.\n\nvar myElement = \"chocolate\";\nvar myArray = ['chocolate', 'poptart', 'poptart', 'poptart', 'chocolate', 'poptart', 'poptart', 'chocolate'];\n\n/* Important code */\nfor (var i = myArray.length - 1; i >= 0; i--) {\n  if (myArray[i] == myElement) myArray.splice(i, 1);\n}\nconsole.log(myArray);\n Run code snippetExpand snippet\n\nLive Demo\n\nShare\nImprove this answer\nFollow\nedited Jul 10 '20 at 12:53\nEdric\n19.1k11\n11 gold badges\n68\n68 silver badges\n81\n81 bronze badges\nanswered Aug 12 '13 at 17:56\nJeff Noel\n7,0723\n3 gold badges\n37\n37 silver badges\n63\n63 bronze badges","comments":[]},{"answer":"A more modern, ECMAScript 2015 (formerly known as Harmony or ES 6) approach. Given:\n\nconst items = [1, 2, 3, 4];\nconst index = 2;\n\n\nThen:\n\nitems.filter((x, i) => i !== index);\n\n\nYielding:\n\n[1, 2, 4]\n\n\nYou can use Babel and a polyfill service to ensure this is well supported across browsers.\n\nShare\nImprove this answer\nFollow\nedited Jun 25 '16 at 13:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 25 '16 at 10:21\nbjfletcher\n10.1k3\n3 gold badges\n45\n45 silver badges\n65\n65 bronze badges","comments":["Note that .filter returns a new array, which is not exactly the same as removing the element from the same array. The benefit of this approach is that you can chain array methods together. eg: [1,2,3].filter(n => n%2).map(n => n*n) === [ 1, 9 ]","Great, if I have 600k elements in array and want to remove first 50k, can you imagine that slowness? This is not solution, there's need for function which just remove elements and returns nothing.","@Seraph For that, you'd probably want to use splice or slice.","@bjfletcher Thats even better, in process of removal, just allocate 50K elements and throw them somewhere. (with slice 550K elements, but without throwing them from the window).","I'd prefer bjfletcher's answer, which could be as short as items= items.filter(x=>x!=3). Besides, the OP didn't state any requirement for large data set."]},{"answer":"You have 1 to 9 in the array, and you want remove 5. Use the below code:\n\nvar numberArray = [1, 2, 3, 4, 5, 6, 7, 8, 9];\n\nvar newNumberArray = numberArray.filter(m => {\n  return m !== 5;\n});\n\nconsole.log(\"new Array, 5 removed\", newNumberArray);\n Run code snippetExpand snippet\n\nIf you want to multiple values. Example:- 1,7,8\n\nvar numberArray = [1, 2, 3, 4, 5, 6, 7, 8, 9];\n\nvar newNumberArray = numberArray.filter(m => {\n  return (m !== 1) && (m !== 7) && (m !== 8);\n});\n\nconsole.log(\"new Array, 1,7 and 8 removed\", newNumberArray);\n Run code snippetExpand snippet\n\nIf you want to remove an array value in an array. Example: [3,4,5]\n\nvar numberArray = [1, 2, 3, 4, 5, 6, 7, 8, 9];\nvar removebleArray = [3,4,5];\n\nvar newNumberArray = numberArray.filter(m => {\n    return !removebleArray.includes(m);\n});\n\nconsole.log(\"new Array, [3,4,5] removed\", newNumberArray);\n Run code snippetExpand snippet\n\nIncludes supported browser is link.\n\nShare\nImprove this answer\nFollow\nedited Sep 2 '19 at 4:01\nanswered Aug 7 '18 at 9:37\nThilina Sampath\n2,9705\n5 gold badges\n34\n34 silver badges\n61\n61 bronze badges","comments":[]}]},{"id":"6591213","href":"https://stackoverflow.com/questions/6591213/how-do-i-rename-a-local-git-branch","title":"How do I rename a local Git branch?","description":"\n                \nI don't want to rename a remote branch, as described in Rename master branch for both local and remote Git repositories.\nHow can I rename a local branch which hasn't been pushed to a remote repository?\nIn case you need to rename a remote branch as well:\nHow do I rename both a Git local and remote branch name?\n    ","questionComments":[],"answers":[{"answer":"If you want to rename a branch while pointed to any branch, do:\n\ngit branch -m <oldname> <newname>\n\n\nIf you want to rename the current branch, you can do:\n\ngit branch -m <newname>\n\n\nIf you want to push the local branch and reset the upstream branch:\n\ngit push origin -u <newname>\n\n\nAnd finally if you want to Delete the remote branch:\n\ngit push origin --delete <oldname>\n\n\nA way to remember this is -m is for \"move\" (or mv), which is how you rename files. Adding an alias could also help. To do so, run the following:\n\ngit config --global alias.rename 'branch -m'\n\n\nIf you are on Windows or another case-insensitive filesystem, and there are only capitalization changes in the name, you need to use -M, otherwise, git will throw branch already exists error:\n\ngit branch -M <newname>\n\nShare\nImprove this answer\nFollow\nedited May 17 at 2:41\nNuman Gillani\n5715\n5 silver badges\n18\n18 bronze badges\nanswered Jul 6 '11 at 3:21\nsiride\n170k4\n4 gold badges\n35\n35 silver badges\n56\n56 bronze badges","comments":["What I really wanted to know was whether this will necessarily effect the remote branch when/if you push","@PandaWood: it will add the new branch when you push, but won't delete the old branch. If you use git push -f --mirror, then it will rename the branch on the remote, but you should only use this method if the remote is simply to be a copy of your current repository. See also this question: stackoverflow.com/questions/1526794/git-rename-remote-branch","@PandaWood, it depends on how push.default is configured. By default (matching) it will push to a remote whose name matches. You would have to do git push origin <newname>:<oldname> or you will create a new remote branch. However, if push.default is set to upstream, then you can push origin head and things will go to the oldname on the remote.","@NightOwl888: the -m probably is short for \"move\", following the Unix convention of using the mv to rename files. The reason for this is that moving and renaming, in a directory-based inode file system, are entirely equivalent.","The long name of the -m option is --move, e.g., git branch --move master renames the current branch to be called \"master\"."]},{"answer":"git branch -m old_branch_name new_branch_name\n\n\nThe above command will change your branch name, but you have to be very careful using the renamed branch, because it will still refer to the old upstream branch associated with it, if any.\n\nIf you want to push some changes into master after your local branch is renamed into new_branch_name (example name):\n\ngit push origin new_branch_name:master (now changes will go to master branch but your local branch name is new_branch_name)\n\nFor more details, see \"How to rename your local branch name in Git.\"\n\nShare\nImprove this answer\nFollow\nedited May 14 '16 at 20:18\nNick Matteo\n4,05620\n20 silver badges\n30\n30 bronze badges\nanswered Jan 21 '13 at 9:49\nMadhan Ayyasamy\n13.7k3\n3 gold badges\n16\n16 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"To rename your current branch:\n\ngit branch -m <newname>\n\nShare\nImprove this answer\nFollow\nanswered Jun 20 '13 at 15:05\nJonathan\n18.9k6\n6 gold badges\n62\n62 silver badges\n66\n66 bronze badges","comments":["You will need to use -M to rename if you are only changing capitalization, as git will tell you that branch already exists.","and afterwards git push origin HEAD:<oldname>"]},{"answer":"Here are the steps to rename the branch:\n\nSwitch to the branch which needs to be renamed\ngit branch -m <new_name>\ngit push origin :<old_name>\ngit push origin <new_name>:refs/heads/<new_name>\n\nEDIT (12/01/2017): Make sure you run command git status and check that the newly created branch is pointing to its own ref and not the older one. If you find the reference to the older branch, you need to unset the upstream using:\n\ngit branch --unset-upstream\n\nShare\nImprove this answer\nFollow\nedited Mar 23 '19 at 11:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 15 '15 at 12:50\nMilind Anantwar\n78.2k22\n22 gold badges\n90\n90 silver badges\n116\n116 bronze badges","comments":["In which step would one unset the upstream? Before step 4?","This is the best answer here as it describes the full process to correctly complete a rename","To explain the steps: 1 = switch to branch locally, 2 = 'move' i.e. 'rename' branch locally (-m), 3 = push 'nothing' to the old branch destination on the remote (i.e. delete the reference to the branch on the remote) - left side of a colon is 'source', right side is 'destination', 4 = push a reference (pointer) to the new branch, to the remote","@Milind Anantwar, what does it mean to \"check that the new branch is pointing to it's own ref\"? And could you please explain how git branch --unset-upstream resolves the unsynchronised condition(s) to which you're referring?","I also used this git push origin HEAD Its working fine"]},{"answer":"Rename the branch will be useful once your branch is finished. Then new stuff is coming, and you want to develop in the same branch instead of deleting it and create the new one.\n\nFrom my experience, to rename a local and remote branch in Git you should do the following steps.\n\nQuoting from Multiple States - Rename a local and remote branch in git\n\n1. Rename your local branch\n\nIf you are on the branch you want to rename:\n\ngit branch -m new-name\n\n\nIf you are on a different branch:\n\ngit branch -m old-name new-name\n\n2. Delete the old-name remote branch and push the new-name local branch\ngit push origin :old-name new-name\n\n3. Reset the upstream branch for the new-name local branch\ngit push origin -u new-name\n\nShare\nImprove this answer\nFollow\nedited Mar 4 '17 at 22:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 14 '16 at 3:22\ntrungk18\n18.4k6\n6 gold badges\n41\n41 silver badges\n73\n73 bronze badges","comments":["This one worked better for me. Here the 2 steps gave me the following errors: error: dst ref refs/heads/<old-name> receives from more than one src.; error: failed to push some refs to 'git@uri:foo/bar.git'","You got the problem when running the command git push origin :old-name new-name right?","Yep exactly (sorry I meant \"2nd step\", not \"2 steps\" -- tired)"]},{"answer":"The answers so far have been correct, but here is some additional information:\n\nOne can safely rename a branch with '-m' (move), but one has to be careful with '-M', because it forces the rename, even if there is an existing branch with the same name already. Here is the excerpt from the 'git-branch' man page:\n\nWith a -m or -M option, <oldbranch> will be renamed to <newbranch>. If <oldbranch> had a corresponding reflog, it is renamed to match <newbranch>, and a reflog entry is created to remember the branch renaming. If <newbranch> exists, -M must be used to force the rename to happen.\n\nShare\nImprove this answer\nFollow\nedited Oct 4 '19 at 18:16\nmskfisher\n3,0273\n3 gold badges\n31\n31 silver badges\n47\n47 bronze badges\nanswered Sep 24 '13 at 13:21\nVanchev\n1,4841\n1 gold badge\n9\n9 silver badges\n7\n7 bronze badges","comments":["What happens to the overwritten branch?","It is overwritten by the new name/branch. For example if you have the following branches in git: master b1 <-- current branch b2 after you do 'git branch -M b2' you will only have: master b2 <-- current branch b1 will be gone and if you wish to recover it you should check it out by its hash. You can see it by typing 'git reflog'. Cheers.","The -M flag is also useful to force a rename if you are just correcting the case of the branch name, e.g. changing myBranch to MyBranch. (With -m, git returns fatal: A branch named 'MyBranch' already exists.)"]},{"answer":"1. Rename\n\nIf it is your current branch, just do\n\ngit branch -m new_name\n\n\nIf it is another branch you want to rename\n\ngit branch -m old_name new_name\n\n2. Track a new remote branch\n\n- If your branch was pushed, then after renaming you need to delete it from the remote Git repository and ask your new local to track a new remote branch:\n\ngit push origin :old_name\ngit push --set-upstream origin new_name\n\nShare\nImprove this answer\nFollow\nedited Apr 5 '18 at 23:15\npkamb\n27.5k21\n21 gold badges\n128\n128 silver badges\n159\n159 bronze badges\nanswered Dec 17 '15 at 13:45\nOss\n4,0722\n2 gold badges\n18\n18 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"I foolishly named a branch starting with a hyphen, and then checked out master. I didn't want to delete my branch, I had work in it.\n\nNeither of these worked:\n\ngit checkout -dumb-name\n\ngit checkout -- -dumb-name\n\n\"s, 's and \\s didn't help either. git branch -m doesn't work.\n\nHere's how I finally fixed it. Go into your working copy's .git/refs/heads, find the filename \"-dumb-name\", get the hash of the branch. Then this will check it out, make a new branch with a sane name, and delete the old one.\n\ngit checkout {hash}\ngit checkout -b brilliant-name\ngit branch -d -- -dumb-name\n\nShare\nImprove this answer\nFollow\nanswered Nov 9 '13 at 7:31\nSamuel Meacham\n9,8757\n7 gold badges\n42\n42 silver badges\n50\n50 bronze badges","comments":["Couldn't you just have renamed the file in refs/heads?","Ditto. If you have to dig into the directory structure to do this magic, go all the way and do a 'mv -- -dumb-name brilliant-name' Do a 'git branch -av' and you'll see an directory structure of .git/refs. Or maybe 'grep -R ^ .git/refs' to see the hashes directly.","You could probably have used reflog","Honestly, if that's the route you wanted to take, I'd avoid the (IMO confusing and potentially dangerous if you don't know what you're doing) jaunt through .git directory in the first place, and just do it with some normal commands with some \"git log\" parsing (using appropriate flags to show branches, and to figure out which shasum you want to checkout a new branch from), and then do it. Then, remove the wonky-named branch. I despise that git insists that you need to understand all of its inner workings to do some things, but greatly appreciate that you can do those things.","It's harder to create a branch with a bad name in 2.10.1+. If you do somehow do it, you can use git branch -v to get the short hash version of your branches(add -r for remote). You can then use git rev-parse <shorthash> to get the full hash if you need it."]},{"answer":"Just three steps to replicate change in name on remote as well as on GitHub:\n\nStep 1 git branch -m old_branchname new_branchname\n\nStep 2 git push origin :old_branchname new_branchname\n\nStep 3 git push --set-upstream origin new_branchname\n\nShare\nImprove this answer\nFollow\nedited Mar 8 '20 at 3:54\nanswered Mar 22 '19 at 1:03\nHarry_pb\n5,2221\n1 gold badge\n33\n33 silver badges\n46\n46 bronze badges","comments":["I had also to do one addtional thing: git push --set-upstream origin new_branchname which is mentioned in @Nomade answer","Step 3 not needed. Everything was up-to-date after Step 2.","@Dev not in all the cases Dev, I had to update recently since using bitbucket and codecommit, step 3 is necessary"]},{"answer":"To rename a branch locally:\n\ngit branch -m [old-branch] [new-branch]\n\n\nNow you'll have to propagate these changes on your remote server as well.\n\nTo push changes of the deleted old branch:\n\ngit push origin :[old-branch]\n\n\nTo push changes of creation of new branch:\n\ngit push origin [new-branch]\n\nShare\nImprove this answer\nFollow\nanswered Aug 20 '15 at 6:39\naliasav\n2,6752\n2 gold badges\n22\n22 silver badges\n30\n30 bronze badges","comments":[]},{"answer":"Rename the branch using this command:\n\ngit branch -m [old_branch_name] [new_branch_name]\n\n\n-m: It renames/moves the branch. If there is already a branch, you will get an error.\n\nIf there is already a branch and you want to rename with that branch, use:\n\n git rename -M [old_branch_name] [new_branch_name]\n\n\nFor more information about help, use this command in the terminal:\n\ngit branch --help\n\n\nor\n\nman git branch\n\nShare\nImprove this answer\nFollow\nedited Mar 4 '17 at 22:07\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 11 '15 at 6:19\nHafiz Shehbaz Ali\n2,34621\n21 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"Advanced Git users can rename manually using:\n\nRename the old branch under .git/refs/heads to the new name\n\nRename the old branch under .git/logs/refs/heads to the new name\n\nUpdate the .git/HEAD to point to yout new branch name\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '19 at 12:19\nTito Amoo\n2932\n2 silver badges\n14\n14 bronze badges\nanswered Aug 5 '15 at 9:04\nJethik\n1,7441\n1 gold badge\n21\n21 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"Rename your local branch.\n\nIf you are on the branch you want to rename:\n\ngit branch -m new-name\n\n\nIf you are on a different branch:\n\ngit branch -m old-name new-name\n\nDelete the old-name remote branch and push the new-name local branch.\n\ngit push origin :old-name new-name\n\nReset the upstream branch for the new-name local branch. Switch to the branch and then:\n\ngit push origin -u new-name\n\nOr for a fast way to do that, you can use these 3 steps:\n\n# Rename branch locally\n\ngit branch -m old_branch new_branch  \n\n\n# Delete the old remote branch\n\ngit push origin :old_branch  \n\n\n# Push the new branch, set local branch to track the new remote\n\ngit push --set-upstream origin new_branch   \n\n\nReferance: https://www.w3docs.com/snippets/git/how-to-rename-git-local-and-remote-branches.html\n\nShare\nImprove this answer\nFollow\nedited Sep 14 '18 at 20:05\nMajor\n5165\n5 silver badges\n18\n18 bronze badges\nanswered Apr 8 '18 at 5:49\nbadarshahzad\n1,10714\n14 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"Here are three steps: A command that you can call inside your terminal and change branch name.\n\ngit branch -m old_branch new_branch         # Rename branch locally\ngit push origin :old_branch                 # Delete the old branch\ngit push --set-upstream origin new_branch   # Push the new branch, set local branch to track the new remote\n\n\nIf you need more: step-by-step, How To Change Git Branch Name is a good article about that.\n\nShare\nImprove this answer\nFollow\nedited Mar 4 '17 at 22:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 10 '16 at 18:04\nHazarapet Tunanyan\n2,56124\n24 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"Probably as mentioned by others, this will be a case mismatch in branch naming.\n\nIf you have such a situation, I can guess that you're on Windows which will also lead you to:\n\n$ git branch -m CaseSensitive casesensitive\nfatal: A branch named 'casesensitive' already exists.\n\n\nThen you have to do an intermediate step:\n\n$ git branch -m temporary\n$ git branch -m casesensitive\n\n\nNothing more.\n\nShare\nImprove this answer\nFollow\nedited Mar 4 '17 at 22:08\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 25 '15 at 11:52\nP4C\n4775\n5 silver badges\n10\n10 bronze badges","comments":["Note that this situation might also arise on a Mac, which is also (exceptionally annoyingly) case insensitive in its file system.","Alternatively, you can use -M instead of -m to do this kind of \"casing fix\" rename in a single step."]},{"answer":"Trying to answer specifically the question (at least the title).\n\nYou can also rename the local branch, but keep tracking the old name on the remote.\n\ngit branch -m old_branch new_branch\ngit push --set-upstream origin new_branch:old_branch\n\n\nNow, when you run git push, the remote old_branch ref is updated with your local new_branch.\n\nYou have to know and remember this configuration. But it can be useful if you don't have the choice for the remote branch name, but you don't like it (oh, I mean, you've got a very good reason not to like it !) and prefer a clearer name for your local branch.\n\nPlaying with the fetch configuration, you can even rename the local remote-reference. i.e, having a refs/remote/origin/new_branch ref pointer to the branch, that is in fact the old_branch on origin. However, I highly discourage this, for the safety of your mind.\n\nShare\nImprove this answer\nFollow\nedited Jul 16 at 16:56\nauspicious99\n2,7471\n1 gold badge\n32\n32 silver badges\n43\n43 bronze badges\nanswered May 19 '16 at 10:39\nPierre-Olivier Vares\n1,13911\n11 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"Changing the branch locally is quite easy...\n\nIf you are on the branch you want to change the name for, simply do this:\n\ngit branch -m my_new_branch\n\n\nOtherwise, if you are on master or any other branch other than the one you'd like to change the name, simply do:\n\ngit branch -m my_old_branch my_new_branch\n\n\nAlso, I create the image below to show this in action on a command line. In this case, you are on master branch, for example:\n\nShare\nImprove this answer\nFollow\nedited Mar 23 '19 at 11:15\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 4 '17 at 14:01\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"To rename the current branch (except for detached HEAD state) you can also use this alias:\n\n[alias]\n    mvh = !sh -c 'git branch -m `git rev-parse --abbrev-ref HEAD` $1'\n\nShare\nImprove this answer\nFollow\nedited Mar 23 '19 at 11:07\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 2 '14 at 17:25\ndentuzhik\n7027\n7 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"If you are willing to use SourceTree (which I strongly recommend), you can right click your branch and chose 'Rename'.\n\nShare\nImprove this answer\nFollow\nedited Sep 6 '18 at 7:03\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered May 26 '17 at 11:14\nMarcin Szymczak\n9,8554\n4 gold badges\n49\n49 silver badges\n60\n60 bronze badges","comments":[]},{"answer":"Another option is not to use the command line at all. Git GUI clients such as SourceTree take away much of the syntactical learning curve / pain that causes questions such as this one to be amongst the most viewed on Stack Overflow.\n\nIn SourceTree, right click on any local branch in the \"Branches\" pane on the left and select \"Rename ...\".\n\nShare\nImprove this answer\nFollow\nedited Mar 4 '17 at 22:06\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 8 '15 at 16:13\nSteve Chambers\n32.4k15\n15 gold badges\n131\n131 silver badges\n175\n175 bronze badges","comments":["I wouldn't call it pain. The git command is very easy to use, once you've seen this answer, you'll probably never come back again. The problem is more that, so it seems, the documentation of the git command-line isn't intuitive enough.","True but with SourceTree I hardly ever need to worry about checking documentation. Everything is generally intuitive - just right click and see what the options are. (BTW I'm not affiliated with them in any way - just like the tool!)"]},{"answer":"A simple way to do it:\n\ngit branch -m old_branch new_branch         # Rename branch locally\ngit push origin :old_branch                 # Delete the old branch\ngit push --set-upstream origin new_branch   # Push the new branch, set local branch to track the new remote\n\n\nFor more, see this.\n\nShare\nImprove this answer\nFollow\nedited Mar 23 '19 at 11:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 27 '18 at 16:00\nNomade\n1,6822\n2 gold badges\n18\n18 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"Since you do not want to push the branch to a remote server, this example will be useful:\n\nLet's say you have an existing branch called \"my-hot-feature,\" and you want to rename it to \"feature-15.\"\n\nFirst, you want to change your local branch. This couldn't be easier:\n\ngit branch -m my-hot-feature feature-15\n\n\nFor more information, you can visit Locally and Remotely Renaming a Branch in Git.\n\nShare\nImprove this answer\nFollow\nedited Mar 4 '17 at 22:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 27 '15 at 10:17\nTanah\n3492\n2 silver badges\n8\n8 bronze badges","comments":[]},{"answer":"Git version 2.9.2\n\nIf you want to change the name of the local branch you are on:\n\ngit branch -m new_name\n\n\nIf you want to change the name of a different branch:\n\ngit branch -m old_name new_name\n\n\nIf you want to change the name of a different branch to a name that already exists:\n\ngit branch -M old_name new_name_that_already_exists\n\n\nNote: The last command is destructive and will rename your branch, but you will lose the old branch with that name and those commits because branch names must be unique.\n\nShare\nImprove this answer\nFollow\nedited Mar 23 '19 at 11:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 22 '16 at 0:03\nnikkypx\n1,62016\n16 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"If you want to change the name of the current branch, run:\n\ngit branch -m [old_branch] [new_branch]\n\n\nIf you want to delete the old remote branch, run:\n\ngit push origin :[old_branch]\n\n\nIf you want to delete the old remote branch and create a new remote branch, run:\n\ngit push origin :old_branch new_branch\n\nShare\nImprove this answer\nFollow\nedited Feb 8 '17 at 6:23\n2Toad\n13.9k7\n7 gold badges\n38\n38 silver badges\n38\n38 bronze badges\nanswered Jan 31 '17 at 15:53\nArif\n1711\n1 silver badge\n7\n7 bronze badges","comments":[]},{"answer":"Actually you have three steps because the local branch has a duplicate on the server so we have one step for local on two steps on the server:\n\nRename local: just use the following command to rename your current branch, even you checked it out:\ngit branch -m <old-branch-name> <new-branch-name>\n\nDelete the server one: use the following command to delete the old name branch on the server:\ngit push <remote-name[origin by default]> :<old-branch-name>\n\nPush the new one: now it's time to push the new branch named on the server:\ngit push -u <new-branch-name>\n\nShare\nImprove this answer\nFollow\nanswered Aug 5 '20 at 8:24\nAmerllicA\n17.3k12\n12 gold badges\n82\n82 silver badges\n109\n109 bronze badges","comments":["in my case 3rd command is taking care to rename remote branch, without executing above 2 nd command. Is it necessary to delete before renaming remote branch?","@SP007, The 2nd command is not essential, but I'm a little worry about clarity on git server. so I don't keep useless branches.","when I execute 3rd command it renamed existing remote branch.","@SP007, I will test it, maybe the 2nd command is not needed."]},{"answer":"Git branch rename can be done by using:\n\ngit branch -m oldBranch newBranch\n\ngit branch -M oldBranch ExistingBranch\n\nThe difference between -m and -M:\n\n-m: if you're trying to rename your branch with an existing branch name using -m. It will raise an error saying that the branch already exists. You need to give unique name.\n\nBut,\n\n-M: this will help you to force rename with a given name, even it is exists. So an existing branch will overwrite entirely with it...\n\nHere is a Git terminal example,\n\nmohideen@dev:~/project/myapp/sunithamakeup$ git branch\n  master\n  master0\n  new_master\n  test\n* test1\nmohideen@dev:~/project/myapp/sunithamakeup$ git branch -m test1 test\nfatal: A branch named 'test' already exists.\nmohideen@dev:~/project/myapp/sunithamakeup$ git branch -M test1 test\nmohideen@dev:~/project/myapp/sunithamakeup$ git branch\n  master\n  master0\n  new_master\n* test\nmohideen@dev:~/project/myapp/sunithamakeup$\n\nShare\nImprove this answer\nFollow\nedited Mar 23 '19 at 11:23\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 1 '17 at 6:59\nMohideen bin Mohammed\n14.9k7\n7 gold badges\n87\n87 silver badges\n101\n101 bronze badges","comments":[]},{"answer":"Before we begin, make sure you’ve selected the branch you want to rename:\n\ngit checkout old-name\n\n\nIf you want to see all of your local branches, use the following command:\n\ngit branch --list\n\n\nWhen you’re all clear, follow these steps:\n\nUsing the Git rename branch command will require you to add an -m option to your command:\n\ngit branch -m new-name\n\n\nYou can also rename a local branch from another branch by using the following two commands:\n\ngit checkout master\n\ngit branch -m old-name new-name\n\n\nLastly, this command will list all — both local and remote — branches to verify that it has been renamed:\n\ngit branch -a\n\n\nAlthough it isn’t possible to rename a remote branch directly, the process of renaming one involves these three easy steps:\n\nTo start, you will need to rename a local branch by following the previous steps. 2.Then delete the old branch and push the new one. You can do this easily with the following commands:\n\n git push origin --delete old-name\n git push origin :old-name new-name\n\n\nReset the upstream branch for your new local branch and you will be all set:\n\ngit push origin -u new-name\n\nShare\nImprove this answer\nFollow\nedited Nov 14 '20 at 5:31\nanswered Sep 28 '20 at 13:01\nS. Hesam\n2,0022\n2 gold badges\n13\n13 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"For Git GUI users it couldn't be much simpler. In Git GUI, choose the branch name from the drop down list in the \"Rename Branch\" dialog box created from the menu item Branch:Rename, type a New Name, and click \"Rename\". I have highlighted where to find the drop down list.\n\nShare\nImprove this answer\nFollow\nanswered Sep 3 '18 at 15:58\nIvan\n3,64328\n28 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"All of the previous answers are talking about git branch -m. Of course, it's easy to operate, but for me, it may be a little hard to remember another Git command. So I tried to get the work done by the command I was familiar with. Yeah, you may guessed it.\n\nI use git branch -b <new_branch_name>. And if you don't want to save the old branch now you can execute git branch -D <old_branch_name> to remove it.\n\nI know it may be a little tedious, but it's easier to understand and remember. I hope it‘s helpful for you.\n\nShare\nImprove this answer\nFollow\nedited Mar 28 '19 at 6:53\nanswered Aug 29 '17 at 2:16\nDai Kaixian\n8872\n2 gold badges\n12\n12 silver badges\n21\n21 bronze badges","comments":["If you're having trouble remembering commands, you can set up shell or git aliases for yourself."]},{"answer":"If you want to:\n\nRename the Git repository, run: git branch -m <oldname> <newname>\nDelete the old branch by: git push origin: old-name new-name\nCommit it using: git commit <newname>\nand then push using: git push origin new_branch_name:master\nIf you want to check the status then use: git status\nIf you want to check out then use: git checkout\nShare\nImprove this answer\nFollow\nedited Mar 23 '19 at 11:16\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 26 '17 at 14:18\nVineet Jain\n1,3484\n4 gold badges\n16\n16 silver badges\n31\n31 bronze badges","comments":[]}]},{"id":"1642028","href":"https://stackoverflow.com/questions/1642028/what-is-the-operator-in-c-c","title":"What is the “-->” operator in C/C++?","description":"\n                \nAfter reading Hidden Features and Dark Corners of C++/STL on comp.lang.c++.moderated, I was completely surprised that the following snippet compiled and worked in both Visual Studio 2008 and G++ 4.4.\nHere's the code:\n#include <stdio.h>\nint main()\n{\n    int x = 10;\n    while (x --> 0) // x goes to 0\n    {\n        printf(\"%d \", x);\n    }\n}\n\nOutput:\n9 8 7 6 5 4 3 2 1 0\n\nI'd assume this is C, since it works in GCC as well. Where is this defined in the standard, and where has it come from?\n    ","questionComments":["if you use it in a for loop it requires an obligatory wink: for (int x = 10; x --> 0 ;) ..."],"answers":[{"answer":"--> is not an operator. It is in fact two separate operators, -- and >.\n\nThe conditional's code decrements x, while returning x's original (not decremented) value, and then compares the original value with 0 using the > operator.\n\nTo better understand, the statement could be written as follows:\n\nwhile( (x--) > 0 )\n\nShare\nImprove this answer\nFollow\nedited Jun 15 at 8:09\ncommunity wiki\n\n\n13 revs, 12 users 16%\nBradley Mackey","comments":["I've seen it jokingly referred to as the \"downto\" operator (codegolf.stackexchange.com/questions/16226/…)","I think you wouldn't really need the parentheses around x-- though it does further enforce the separation. It would probably be enough just to associate tokens more clearly with something like while (x-- > 0)."]},{"answer":"Or for something completely different... x slides to 0.\n\nwhile (x --\\\n            \\\n             \\\n              \\\n               > 0)\n     printf(\"%d \", x);\n\n\nNot so mathematical, but... every picture paints a thousand words...\n\nShare\nImprove this answer\nFollow\nedited Jan 8 '20 at 22:51\ncommunity wiki\n\n\n8 revs, 8 users 60%\nunsynchronized","comments":["So, in this use case, would the slope of the line, eg: each line being \\_ instead of \\, determine how fast it drops to zero? :-)"]},{"answer":"That's a very complicated operator, so even ISO/IEC JTC1 (Joint Technical Committee 1) placed its description in two different parts of the C++ Standard.\n\nJoking aside, they are two different operators: -- and > described respectively in §5.2.6/2 and §5.9 of the C++03 Standard.\n\nShare\nImprove this answer\nFollow\nedited Oct 2 '19 at 8:08\ncommunity wiki\n\n\n12 revs, 9 users 31%\nKirill V. Lyadvinsky","comments":[]},{"answer":"x can go to zero even faster in the opposite direction:\n\nint x = 10;\n\nwhile( 0 <---- x )\n{\n   printf(\"%d \", x);\n}\n\n\n8 6 4 2\n\nYou can control speed with an arrow!\n\nint x = 100;\n\nwhile( 0 <-------------------- x )\n{\n   printf(\"%d \", x);\n}\n\n\n90 80 70 60 50 40 30 20 10\n\n;)\n\nShare\nImprove this answer\nFollow\nedited Oct 11 '17 at 2:51\ncommunity wiki\n\n\n3 revs, 3 users 93%\ndoc","comments":["\"You can control speed with an arrow!\". Thanks, I hate it.","An apt answer to the question."]},{"answer":"It's equivalent to\n\nwhile (x-- > 0)\n\n\nx-- (post decrement) is equivalent to x = x-1 so, the code transforms to:\n\nwhile(x > 0) {\n    x = x-1;\n    // logic\n}\nx--;   // The post decrement done when x <= 0\n\nShare\nImprove this answer\nFollow\nedited Apr 25 '20 at 10:16\ncommunity wiki\n\n\n6 revs, 6 users 47%\nShubham","comments":[]},{"answer":"It's\n\n#include <stdio.h>\n\nint main(void) {\n  int x = 10;\n  while (x-- > 0) { // x goes to 0\n    printf(\"%d \", x);\n  }\n  return 0;\n}\n\n\nJust the space makes the things look funny, -- decrements and > compares.\n\nShare\nImprove this answer\nFollow\nedited Oct 20 '20 at 3:43\ncommunity wiki\n\n\n7 revs, 7 users 51%\nRageZ","comments":[]},{"answer":"The usage of --> has historical relevance. Decrementing was (and still is in some cases), faster than incrementing on the x86 architecture. Using --> suggests that x is going to 0, and appeals to those with mathematical backgrounds.\n\nShare\nImprove this answer\nFollow\nanswered Nov 18 '09 at 12:47\ncommunity wiki\n\n\nMatt Joiner","comments":["Not exactly true. Decrementing and Incrementing take the same amount of time, the benefit of this is that comparison to zero is very fast compared to comparison versus a variable. This is true for many architectures, not just x86. Anything with a JZ instruction (jump if zero). Poking around you can find many \"for\" loops that are written backwards to save cycles on the compare. This is particularly fast on x86 as the act of decrementing the variable set the zero flag appropriately, so you could then branch without having to explicitly compare the variable.","Well, decrementing toward zero means you only have to compare against 0 per loop iteration, while iterating toward n means comparing with n each iteration. The former tends to be easier (and on some architectures, is automatically tested after every data register operation).","This would be better as a footnote in another answer or a comment - it clearly doesn't explain what --> means, which is what was asked.","In x86 ASM, the LOOP <address> decreases the ECX register, then jumps to <address> unless the decrementing of ECX resulted in zero. Decrementing the loop counter towards zero allows the compiler to generate a single LOOP instruction, whereas incrementing or counting to other values requires separate INC/DEC/ADD/SUB, compare, and conditional jump instructions. Modern compilers can often convert other loops to a counter --> 0 loop if the value of counter isn't used in the loop.","Continuing my previous comment: MOV ECX, value, @start:, <code>, LOOP @start is an x86 ASM equivalent for counter = value - 1; while (counter --> 0) { <code>; }. Note that it will barf if value is initially zero, so an extra check is needed pre-loop."]},{"answer":"Utterly geek, but I will be using this:\n\n#define as ;while\n\nint main(int argc, char* argv[])\n{\n    int n = atoi(argv[1]);\n    do printf(\"n is %d\\n\", n) as ( n --> 0);\n    return 0;\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 3 '11 at 2:33\ncommunity wiki\n\n\n3 revs, 2 users 76%\nArrieta","comments":["I know it looks way cool, but I fear it's deceptive. The reason you're writing C++ instead of Machine Language is b/c you want to convey your intent to the next guy reading your code. This construct violates the principle of least surprise. It is a mental \"trip hazard.\"","\"as n approaches zero\" is kinda cool, in a geeky, calculus, sort of way :-)"]},{"answer":"while( x-- > 0 )\n\n\nis how that's parsed.\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '09 at 19:46\ncommunity wiki\n\n\n2 revs, 2 users 86%\nGrumdrig","comments":[]},{"answer":"One book I read (I don't remember correctly which book) stated: Compilers try to parse expressions to the biggest token by using the left right rule.\n\nIn this case, the expression:\n\nx-->0\n\n\nParses to biggest tokens:\n\ntoken 1: x\ntoken 2: --\ntoken 3: >\ntoken 4: 0\nconclude: x-- > 0\n\n\nThe same rule applies to this expression:\n\na-----b\n\n\nAfter parse:\n\ntoken 1: a\ntoken 2: --\ntoken 3: --\ntoken 4: -\ntoken 5: b\nconclude: (a--)-- - b\n\n\nI hope this helps to understand the complicated expression ^^\n\nShare\nImprove this answer\nFollow\nedited Apr 23 '15 at 9:02\ncommunity wiki\n\n\n4 revs, 4 users 69%\nNguyenDat","comments":[]},{"answer":"This is exactly the same as\n\nwhile (x--)\n\nShare\nImprove this answer\nFollow\nedited Mar 12 at 12:03\ncommunity wiki\n\n\n4 revs, 3 users 55%\nGood Person","comments":["Shouldn't this be for(--x++;--x;++x--)?","@DoctorT that's what unsigned is for","while (x --> 0) is not the same as while (x--) if x has a signed type, the first loop does not execute at all if x has a negative value but the second iterates many times until it hits undefined behavior when x reaches INT_MIN."]},{"answer":"Anyway, we have a \"goes to\" operator now. \"-->\" is easy to be remembered as a direction, and \"while x goes to zero\" is meaning-straight.\n\nFurthermore, it is a little more efficient than \"for (x = 10; x > 0; x --)\" on some platforms.\n\nShare\nImprove this answer\nFollow\nedited Feb 28 '13 at 17:28\ncommunity wiki\n\n\n4 revs, 3 users 56%\nTest","comments":["Goes to cant be true always especially when value of x is negative.","The other version does not do the same thing - with for (size_t x=10; x-->0; ) the body of the loop is executed with 9,8,..,0 whereas the other version has 10,9,..,1. It's quite tricky to exit a loop down to zero with an unsigned variable otherwise.","I think this is a little bit misleading... We don't have a literally \"goes to\" operator, since we need another ++> to do the incremental work.","@Josh: actually, overflow gives undefined behavior for int, so it could just as easily eat your dog as take x to zero if it starts out negative.","This is a very important idiom to me for the reason given in the comnmet by @PeteKirkham, as I often need to do decreasing loops over unsigned quantities all the way to 0. (For comparison, the idiom of omitting tests for zero, such as writing while (n--) instead for unsigned n, buys you nothing and for me greatly hampers readability.) It also has the pleasant property that you specify one more than the initial index, which is usually what you want (e.g., for a loop over an array you specify its size). I also like --> without space, as this makes the idiom easy to recognise."]},{"answer":"This code first compares x and 0 and then decrements x. (Also said in the first answer: You're post-decrementing x and then comparing x and 0 with the > operator.) See the output of this code:\n\n9 8 7 6 5 4 3 2 1 0\n\n\nWe now first compare and then decrement by seeing 0 in the output.\n\nIf we want to first decrement and then compare, use this code:\n\n#include <stdio.h>\nint main(void)\n{\n    int x = 10;\n\n    while( --x> 0 ) // x goes to 0\n    {\n        printf(\"%d \", x);\n    }\n    return 0;\n}\n\n\nThat output is:\n\n9 8 7 6 5 4 3 2 1\n\nShare\nImprove this answer\nFollow\nedited Jan 3 '16 at 17:48\ncommunity wiki\n\n\n5 revs, 4 users 70%\nSjB","comments":["--x> 0 Is that x in a spaceship going towards 0 (the moon)?"]},{"answer":"My compiler will print out 9876543210 when I run this code.\n\n#include <iostream>\nint main()\n{\n    int x = 10;\n\n    while( x --> 0 ) // x goes to 0\n    {\n        std::cout << x;\n    }\n}\n\n\nAs expected. The while( x-- > 0 ) actually means while( x > 0). The x-- post decrements x.\n\nwhile( x > 0 ) \n{\n    x--;\n    std::cout << x;\n}\n\n\nis a different way of writing the same thing.\n\nIt is nice that the original looks like \"while x goes to 0\" though.\n\nShare\nImprove this answer\nFollow\nedited Apr 30 '15 at 22:49\ncommunity wiki\n\n\n5 revs, 4 users 82%\ncool_me5000","comments":["The result is only undefined when you're incrementing/decrementing the same variable more than once in the same statement. It doesn't apply to this situation.","while( x-- > 0 ) actually means while( x > 0) - I'm not sure what you were trying to say there, but the way you phrased it implies the -- has no meaning whatsoever, which is obviously very wrong.","To drive the point home from @Dukeling, this answer is not the same as the original post. In the original post, x will be -1 after it leaves the loop, while in this answer, x will be 0."]},{"answer":"There is a space missing between -- and >. x is post decremented, that is, decremented after checking the condition x>0 ?.\n\nShare\nImprove this answer\nFollow\nedited Nov 22 '10 at 19:02\ncommunity wiki\n\n\n2 revs, 2 users 50%\nMr. X","comments":["The space is not missing - C(++) ignores whitespace.","@H2CO3 This isn't true in general. There are places where white space must be used to separate tokens, e.g. in #define foo() versus #define foo ().","@Jens How about: \"The space is not missing - C(++) ignores unnecessary white space.\"?"]},{"answer":"-- is the decrement operator and > is the greater-than operator.\n\nThe two operators are applied as a single one like -->.\n\nShare\nImprove this answer\nFollow\nedited Oct 29 '11 at 21:42\ncommunity wiki\n\n\n4 revs, 4 users 38%\nmuntoo","comments":["They're applied as the 2 separate operators they are. They're only written misleadingly to look like \"a single one\"."]},{"answer":"It's a combination of two operators. First -- is for decrementing the value, and > is for checking whether the value is greater than the right-hand operand.\n\n#include<stdio.h>\n\nint main()\n{\n    int x = 10;\n\n    while (x-- > 0)\n        printf(\"%d \",x);\n\n    return 0;\n}\n\n\nThe output will be:\n\n9 8 7 6 5 4 3 2 1 0            \n\nShare\nImprove this answer\nFollow\nedited Apr 30 '15 at 22:50\ncommunity wiki\n\n\n4 revs, 4 users 56%\nRajeev Das","comments":[]},{"answer":"Actually, x is post-decrementing and with that condition is being checked. It's not -->, it's (x--) > 0\n\nNote: value of x is changed after the condition is checked, because it post-decrementing. Some similar cases can also occur, for example:\n\n-->    x-->0\n++>    x++>0\n-->=   x-->=0\n++>=   x++>=0\n\nShare\nImprove this answer\nFollow\nedited Apr 12 '14 at 9:52\ncommunity wiki\n\n\n3 revs, 3 users 70%\nAndroidLearner","comments":["Except that ++> can hardly be used in a while(). A \"goes up to...\" operator would be ++<, which doesn't look anywhere as nice. The operator --> is a happy coincidence.","@BenLeggiero That could 'work' in the sense of generating code that does something (while infuriating readers who don't like faux-clever code), but the semantics are different, as its use of predecrement means it will execute one fewer iteration. As a contrived example, it would never execute the loop body if x started at 1, but while ( (x--) > 0 ) would. {edit} Eric Lippert covered both in his C# 4 release notes: blogs.msdn.microsoft.com/ericlippert/2010/04/01/…"]},{"answer":"C and C++ obey the \"maximum munch\" rule. The same way a---b is translated to (a--) - b, in your case x-->0 translates to (x--)>0.\n\nWhat the rule says essentially is that going left to right, expressions are formed by taking the maximum of characters which will form an valid expression.\n\nShare\nImprove this answer\nFollow\nedited Apr 12 '14 at 9:55\ncommunity wiki\n\n\n2 revs, 2 users 60%\nPeter Mortensen","comments":["Which is what the OP assumed: that \"((a)-->)\" was the maximal munch. It turns out that the OP's original assumption was incorrect: \"-->\" is not a maximum valid operator.","Also known as greedy parsing, if I recall correctly.","@RoyTinker Greedy scanning. The parser has nothing to do with this."]},{"answer":"Why all the complication?\n\nThe simple answer to the original question is just:\n\n#include <stdio.h>\n\nint main()\n{\n    int x = 10;\n    while (x > 0)\n    {\n        printf(\"%d \", x);\n        x = x-1;\n    }\n}\n\n\nIt does the same thing. I am not saying you should do it like this, but it does the same thing and would have answered the question in one post.\n\nThe x-- is just shorthand for the above, and > is just a normal greater-than operator. No big mystery!\n\nThere are too many people making simple things complicated nowadays ;)\n\nShare\nImprove this answer\nFollow\nedited Oct 28 '20 at 23:00\ncommunity wiki\n\n\n5 revs, 4 users 74%\nGarry_G","comments":["This question is not about complications, but about ** Hidden Features and Dark Corners of C++/STL**","The program here gives different output than original because x here is decremented after printf. That demonstrates well how \"simple answers\" are usually Incorrect.","The OP's way:      9  8  7  6  5  4  3  2  1  0 and The Garry_G way:  10  9  8  7  6  5  4  3  2  1","It doesn't do the same thing. Move your x=x-1 before printf then you can say \"it does the same thing\"."]},{"answer":"Conventional way we define condition in while loop parenthesis\"()\" and terminating condition inside the braces\"{}\", but this -- & > is a way one defines all at once. For example:\n\nint abc(){\n    int a = 5\n    while((a--) > 0){ // Decrement and comparison both at once\n        // Code\n    }\n}\n\n\nIt says, decrement a and run the loop till the time a is greater than 0\n\nOther way it should have been like:\n\nint abc() {\n    int a = 5;\n    while(a > 0) {\n        a = a -1 // Decrement inside loop\n        // Code\n    }\n}\n\n\nBoth ways, we do the same thing and achieve the same goals.\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '20 at 17:46\ncommunity wiki\n\n\n4 revs, 4 users 56%\nZohaib Ejaz","comments":["This is incorrect. The code in the question does: 'test-write-execute' (test first, write new value, execute the loop), your example is 'test-execute-write'.","@v010dya Fixed the answer, now it's test-write-execute as in the question, thanks for pointing out!","@S.S.Anne Your edit is still wrong. The a-- after the while shouldn't be there.","Both ways, we do the same thing and achieve the same goals. Not really: both loops iterate 5 times, but the final value of a after the loop completes is -1 in the first case and 0 in the second."]},{"answer":"(x --> 0) means (x-- > 0).\n\nYou can use (x -->)\nOutput: 9 8 7 6 5 4 3 2 1 0\nYou can use (-- x > 0) It's mean (--x > 0)\nOutput: 9 8 7 6 5 4 3 2 1\nYou can use\n(--\\\n    \\\n     x > 0)\n\n\nOutput:  9 8 7 6 5 4 3 2 1\n\nYou can use\n(\\\n  \\\n   x --> 0)\n\n\nOutput: 9 8 7 6 5 4 3 2 1 0\n\nYou can use\n(\\\n  \\\n   x --> 0\n          \\\n           \\\n            )\n\n\nOutput: 9 8 7 6 5 4 3 2 1 0\n\nYou can use also\n(\n x \n  --> \n      0\n       )\n\n\nOutput: 9 8 7 6 5 4 3 2 1 0\n\nLikewise, you can try lot of methods to execute this command successfully.\n\nShare\nImprove this answer\nFollow\nedited Oct 28 '20 at 22:58\ncommunity wiki\n\n\n2 revs, 2 users 87%\nKalana","comments":[]},{"answer":"char sep = '\\n'  /1\\\n; int i = 68    /1  \\\n; while (i  ---      1\\\n                       \\\n                       /1/1/1                               /1\\\n                                                            /1\\\n                                                            /1\\\n                                                            /1\\\n                                                            /1\\\n                            /           1\\\n                           /            1 \\\n                          /             1  \\\n                         /              1   \\\n                         /1            /1    \\\n                          /1          /1      \\\n                           /1        /1        /1/1> 0) std::cout \\\n                              <<i<<                               sep;\n\n\nFor larger numbers, C++20 introduces some more advanced looping features. First to catch i we can build an inverse loop-de-loop and deflect it onto the std::ostream. However, the speed of i is implementation-defined, so we can use the new C++20 speed operator <<i<< to speed it up. We must also catch it by building wall, if we don't, i leaves the scope and de referencing it causes undefined behavior. To specify the separator, we can use:\n\n std::cout \\\n           sep\n\n\nand there we have a for loop from 67 to 1.\n\nShare\nImprove this answer\nFollow\nanswered Jan 23 at 7:32\ncommunity wiki\n\n\nlxr196","comments":["I came here looking for bronze, instead I found gold..."]},{"answer":"Instead of regular arrow operator (-->) you can use armor-piercing arrow operator: --x> (note those sharp barbs on the arrow tip). It adds +1 to armor piercing, so it finishes the loop 1 iteration faster than regular arrow operator. Try it yourself:\n\nint x = 10;\nwhile( --x> 0 )\n    printf(\"%d \", x);\n\nShare\nImprove this answer\nFollow\nanswered Jun 3 at 20:01\ncommunity wiki\n\n\nhydrechan","comments":["cute:) to get the OP's behavior, use the armor piercing operator point blank: while( --x>-1 )"]},{"answer":"Here -- is the unary post decrement operator.\n\n while (x-- > 0) // x goes to 0\n {\n     printf(\"%d \", x);\n }\n\nIn the beginning, the condition will evaluate as (x > 0) // 10 > 0\nNow because the condition is true, it will go into the loop with a decremented value x-- // x = 9\nThat's why the first printed value is 9\nAnd so on. In the last loop x=1, so the condition is true. As per the unary operator, the value changed to x = 0 at the time of print.\nNow, x = 0, which evaluates the condition (x > 0 ) as false and the while loop exits.\nShare\nImprove this answer\nFollow\nedited Oct 28 '20 at 22:50\ncommunity wiki\n\n\n2 revs, 2 users 74%\nNeeraj Bansal","comments":[]},{"answer":"This --> is not an operator at all. We have an operator like ->, but not like -->. It is just a wrong interpretation of while(x-- >0) which simply means x has the post decrement operator and this loop will run till it is greater than zero.\n\nAnother simple way of writing this code would be while(x--). The while loop will stop whenever it gets a false condition and here there is only one case, i.e., 0. So it will stop when the x value is decremented to zero.\n\nShare\nImprove this answer\nFollow\nedited Oct 28 '20 at 22:53\ncommunity wiki\n\n\n2 revs, 2 users 60%\nPeter Mortensen","comments":[]},{"answer":"Actually, you can \"create\" a --> operator just for fun )\n\nclass MyClass {\n    class Helper\n    {\n        MyClass* ptr;\n        Helper(MyClass* _this): ptr{_this} {}\n    public:\n        Helper(const Helper&) = delete;\n        Helper(Helper&&) = delete;\n        void operator=(const Helper&) = delete;\n        void operator=(Helper&&) = delete;\n        operator MyClass()\n        {\n            auto tmp = *ptr;\n            tmp._value++;\n            return tmp;\n        }\n        friend MyClass;\n        void operator>(int){std::cout << \"Operator -->\" << std::endl;}\n    };\n\n    int _value = 0;\npublic:\n    MyClass() = default;\n    MyClass(int value): _value{value} {}\n    Helper operator--(int)\n    {\n        _value--;\n        return Helper(this);\n    }\n    int get() const noexcept\n    {\n        return _value;\n    }\n    bool operator>(int num) const noexcept\n    {\n        return _value > num; \n    }\n};\n\nint main()\n{\n    MyClass obj(5);\n    obj > 1;            //operator >\n    obj--;              //operator --\n    MyClass b = obj--;  //still works\n    std::cout << b.get() << std::endl;      //4\n    std::cout << obj.get() << std::endl;    //3\n    b --> 5;            //operator -->\n    //But there is at least one problem\n    auto c = obj--;     //auto can deduce a private type :(\n}\n\n\nBut as I said it's only for fun ;)\n\nShare\nImprove this answer\nFollow\nedited Jul 29 at 7:40\ncommunity wiki\n\n\n3 revs, 2 users 99%\nPoarthur","comments":[]},{"answer":"--> is not an operator, it is the juxtaposition of -- (post-decrement) and > (greater than comparison).\n\nThe loop will look more familiar as:\n\n#include <stdio.h>\nint main() {\n    int x = 10;\n    while (x-- > 0) { // x goes to 0\n        printf(\"%d \", x);\n    }\n}\n\n\nThis loop is a classic idiom to enumerate values between 10 (the excluded upper bound) and 0 the included lower bound, useful to iterate over the elements of an array from the last to the first.\n\nThe initial value 10 is the total number of iterations (for example the length of the array), and one plus the first value used inside the loop. The 0 is the last value of x inside the loop, hence the comment x goes to 0.\n\nNote that the value of x after the loop completes is -1.\n\nNote also that this loop will operate the same way if x has an unsigned type such as size_t, which is a strong advantage over the naive alternative for (i = length-1; i >= 0; i--).\n\nFor this reason, I am actually a fan of this surprising syntax: while (x --> 0). I find this idiom eye-catching and elegant, just like for (;;) vs: while (1) (which looks confusingly similar to while (l)). It also works in other languages whose syntax is inspired by C: C++, Objective-C, java, javascript, C# to name a few.\n\nShare\nImprove this answer\nFollow\nedited Mar 12 at 17:19\ncommunity wiki\n\n\n2 revs\nchqrlie","comments":["I wonder why this answer was automatically made a community wiki...","You have enough reputation to know: a) this is a community wiki question, so all answers are community wiki, and b) this answer is just a duplication of the plethora of existing answers, on a decade old question.","@GManNickG: I was unaware of the implicit connection between questions and answers for the community wiki status, not everything is obvious, even after thousands of hours contributing to the site, but I am not too old to learn. Regarding the answer paraphrasing other answers, I just wanted to underscore an aspect not addressed by other answers and non obvious for casual readers: while (n-- > 0) is perfect for unsigned types.","Fair enough. Perhaps a comment on an existing answer is more appropriate?","@GManNickG: I did comment about signed / unsigned differences on GoodPerson's answer. My answer illustrates how this loop is simple and appropriate to enumerate array members. None of the answers address this either... let's see if other moderators see fit to delete it."]},{"answer":"That's what you mean.\n\nwhile((x--) > 0)\n\n\nWe heard in childhood,\n\nStop don't, Let Go (روکو مت، جانے دو)\n\nWhere a Comma makes confusion\n\nStop, don't let go. (روکو، مت جانے دو)\n\nSame Happens in Programming now, a SPACE makes confusion. :D\n\nShare\nImprove this answer\nFollow\nanswered Jun 2 at 5:47\ncommunity wiki\n\n\nNuman Gillani","comments":["This idea can be abused for distant targets in a bow and arrow style: while((x --)>          0)","That's upto the understanding, whatever seems easy & understandable to a person, it's fine for him/her. Main Goal is to clear the concept and be a successful developer :)","Of course. And IMHO while (x --> 0) is clear and effective. x takes all values below the starting one down to and including 0, which is perfect for a loop enumerating index values for an array for both signed and unsigned types of x."]}]},{"id":"79923","href":"https://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap","title":"What and where are the stack and heap?","description":"\n                \nProgramming language books explain that value types are created on the stack, and reference types are created on the heap, without explaining what these two things are. I haven't read a clear explanation of this.  I understand what a stack is. But, \n\n\nWhere and what are they (physically in a real computer's memory)?\nTo what extent are they controlled by the OS or language run-time?\nWhat is their scope?\nWhat determines the size of each of them?\nWhat makes one faster? \n\n    ","questionComments":["a really good explanation can be found here What’s the difference between a stack and a heap?","Also (really) good: codeproject.com/Articles/76153/… (the stack/heap part)","youtube.com/watch?v=clOUdVDDzIM&spfreload=5","Related, see Stack Clash. The Stack Clash remediations affected some aspects of system variables and behaviors like rlimit_stack. Also see Red Hat Issue 1463241","@mattshane The definitions of stack and heap don't depend on value and reference types whatsoever. In other words, the stack and heap can be fully defined even if value and reference types never existed. Further, when understanding value and reference types, the stack is just an implementation detail. Per Eric Lippert: The Stack Is An Implementation Detail, Part One."],"answers":[{"answer":"The stack is the memory set aside as scratch space for a thread of execution. When a function is called, a block is reserved on the top of the stack for local variables and some bookkeeping data. When that function returns, the block becomes unused and can be used the next time a function is called. The stack is always reserved in a LIFO (last in first out) order; the most recently reserved block is always the next block to be freed. This makes it really simple to keep track of the stack; freeing a block from the stack is nothing more than adjusting one pointer.\n\nThe heap is memory set aside for dynamic allocation. Unlike the stack, there's no enforced pattern to the allocation and deallocation of blocks from the heap; you can allocate a block at any time and free it at any time. This makes it much more complex to keep track of which parts of the heap are allocated or freed at any given time; there are many custom heap allocators available to tune heap performance for different usage patterns.\n\nEach thread gets a stack, while there's typically only one heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).\n\nTo answer your questions directly:\n\nTo what extent are they controlled by the OS or language runtime?\n\nThe OS allocates the stack for each system-level thread when the thread is created. Typically the OS is called by the language runtime to allocate the heap for the application.\n\nWhat is their scope?\n\nThe stack is attached to a thread, so when the thread exits the stack is reclaimed. The heap is typically allocated at application startup by the runtime, and is reclaimed when the application (technically process) exits.\n\nWhat determines the size of each of them?\n\nThe size of the stack is set when a thread is created. The size of the heap is set on application startup, but can grow as space is needed (the allocator requests more memory from the operating system).\n\nWhat makes one faster?\n\nThe stack is faster because the access pattern makes it trivial to allocate and deallocate memory from it (a pointer/integer is simply incremented or decremented), while the heap has much more complex bookkeeping involved in an allocation or deallocation. Also, each byte in the stack tends to be reused very frequently which means it tends to be mapped to the processor's cache, making it very fast. Another performance hit for the heap is that the heap, being mostly a global resource, typically has to be multi-threading safe, i.e. each allocation and deallocation needs to be - typically - synchronized with \"all\" other heap accesses in the program.\n\nA clear demonstration: \nImage source: vikashazrati.wordpress.com\n\nShare\nImprove this answer\nFollow\nedited May 21 at 19:51\nMohammed Aouf Zouag\n16.4k3\n3 gold badges\n37\n37 silver badges\n64\n64 bronze badges\nanswered Sep 17 '08 at 4:52\nJeff Hill\n66.2k3\n3 gold badges\n15\n15 silver badges\n7\n7 bronze badges","comments":["Good answer - but I think you should add that while the stack is allocated by the OS when the process starts (assuming the existence of an OS), it is maintained inline by the program. This is another reason the stack is faster, as well - push and pop operations are typically one machine instruction, and modern machines can do at least 3 of them in one cycle, whereas allocating or freeing heap involves calling into OS code.","I'm really confused by the diagram at the end. I thought I got it until I saw that image.","@Anarelle the processor runs instructions with or without an os. An example close to my heart is the SNES, which had no API calls, no OS as we know it today - but it had a stack. Allocating on a stack is addition and subtraction on these systems and that is fine for variables destroyed when they are popped by returning from the function that created them, but constrast that to, say, a constructor, of which the result can't just be thrown away. For that we need the heap, which is not tied to call and return. Most OS have APIs a heap, no reason to do it on your own","\"stack is the memory set aside as scratch space\". Cool. But where is it actually \"set aside\" in terms of Java memory structure?? Is it Heap memory/Non-heap memory/Other (Java memory structure as per betsol.com/2017/06/… )","@JatinShashoo Java runtime, as bytecode interpreter, adds one more level of virtualization, so what you referred to is just Java application point of view. From operating system point of view all that is just a heap, where Java runtime process allocates some of its space as \"non-heap\" memory for processed bytecode. Rest of that OS-level heap is used as application-level heap, where object's data are stored."]},{"answer":"Stack:\n\nStored in computer RAM just like the heap.\nVariables created on the stack will go out of scope and are automatically deallocated.\nMuch faster to allocate in comparison to variables on the heap.\nImplemented with an actual stack data structure.\nStores local data, return addresses, used for parameter passing.\nCan have a stack overflow when too much of the stack is used (mostly from infinite or too deep recursion, very large allocations).\nData created on the stack can be used without pointers.\nYou would use the stack if you know exactly how much data you need to allocate before compile time and it is not too big.\nUsually has a maximum size already determined when your program starts.\n\nHeap:\n\nStored in computer RAM just like the stack.\nIn C++, variables on the heap must be destroyed manually and never fall out of scope. The data is freed with delete, delete[], or free.\nSlower to allocate in comparison to variables on the stack.\nUsed on demand to allocate a block of data for use by the program.\nCan have fragmentation when there are a lot of allocations and deallocations.\nIn C++ or C, data created on the heap will be pointed to by pointers and allocated with new or malloc respectively.\nCan have allocation failures if too big of a buffer is requested to be allocated.\nYou would use the heap if you don't know exactly how much data you will need at run time or if you need to allocate a lot of data.\nResponsible for memory leaks.\n\nExample:\n\nint foo()\n{\n  char *pBuffer; //<--nothing allocated yet (excluding the pointer itself, which is allocated here on the stack).\n  bool b = true; // Allocated on the stack.\n  if(b)\n  {\n    //Create 500 bytes on the stack\n    char buffer[500];\n\n    //Create 500 bytes on the heap\n    pBuffer = new char[500];\n\n   }//<-- buffer is deallocated here, pBuffer is not\n}//<--- oops there's a memory leak, I should have called delete[] pBuffer;\n\nShare\nImprove this answer\nFollow\nedited Jul 28 '17 at 0:38\nRob♦\n25.8k15\n15 gold badges\n73\n73 silver badges\n88\n88 bronze badges\nanswered Sep 17 '08 at 4:20\nBrian R. Bondy\n317k116\n116 gold badges\n577\n577 silver badges\n621\n621 bronze badges","comments":["The pointer pBuffer and the value of b are located on the stack, and are mostly likely allocated at the entrance to the function. Depending on the compiler, buffer may be allocated at the function entrance, as well.","It is a common misconception that the C language, as defined by the C99 language standard (available at open-std.org/JTC1/SC22/WG14/www/docs/n1256.pdf ), requires a \"stack\". In fact, the word 'stack' does not even appear in the standard. This answers statements wrt/ to C's stack usage are true in general, but is in no way required by the language. See knosof.co.uk/cbook/cbook.html for more info, and in particular how C is implemented on odd-ball architectures such as en.wikipedia.org/wiki/Burroughs_large_systems","@Brian You should explain why buffer[] and the pBuffer pointer are created on the stack and why pBuffer's data is created on the heap. I think some ppl might be confused by your answer as they might think the program is specifically instructing that memory be allocated on the stack vs heap but this is not the case. Is it because Buffer is a value type whereas pBuffer is a reference type?","\"Responsible for memory leaks\" - Heaps are not responsible for memory leaks! Lazy/Forgetful/ex-java coders/coders who dont give a crap are!","Also the comments about scope and allocation are wrong - Scope is not connected to the stack or the heap at all. Variables on the heap must be destroyed manually and never fall out of scope. isn't correct; it would be more correct to say \"Data on the heap isn't freed when variables that reference them go out of scope. It's up to you (or the garbage collector) to free them."]},{"answer":"The most important point is that heap and stack are generic terms for ways in which memory can be allocated. They can be implemented in many different ways, and the terms apply to the basic concepts.\n\nIn a stack of items, items sit one on top of the other in the order they were placed there, and you can only remove the top one (without toppling the whole thing over).\n\nThe simplicity of a stack is that you do not need to maintain a table containing a record of each section of allocated memory; the only state information you need is a single pointer to the end of the stack. To allocate and de-allocate, you just increment and decrement that single pointer. Note: a stack can sometimes be implemented to start at the top of a section of memory and extend downwards rather than growing upwards.\n\nIn a heap, there is no particular order to the way items are placed. You can reach in and remove items in any order because there is no clear 'top' item.\n\nHeap allocation requires maintaining a full record of what memory is allocated and what isn't, as well as some overhead maintenance to reduce fragmentation, find contiguous memory segments big enough to fit the requested size, and so on. Memory can be deallocated at any time leaving free space. Sometimes a memory allocator will perform maintenance tasks such as defragmenting memory by moving allocated memory around, or garbage collecting - identifying at runtime when memory is no longer in scope and deallocating it.\n\nThese images should do a fairly good job of describing the two ways of allocating and freeing memory in a stack and a heap. Yum!\n\nTo what extent are they controlled by the OS or language runtime?\n\nAs mentioned, heap and stack are general terms, and can be implemented in many ways. Computer programs typically have a stack called a call stack which stores information relevant to the current function such as a pointer to whichever function it was called from, and any local variables. Because functions call other functions and then return, the stack grows and shrinks to hold information from the functions further down the call stack. A program doesn't really have runtime control over it; it's determined by the programming language, OS and even the system architecture.\n\nA heap is a general term used for any memory that is allocated dynamically and randomly; i.e. out of order. The memory is typically allocated by the OS, with the application calling API functions to do this allocation. There is a fair bit of overhead required in managing dynamically allocated memory, which is usually handled by the runtime code of the programming language or environment used.\n\nWhat is their scope?\n\nThe call stack is such a low level concept that it doesn't relate to 'scope' in the sense of programming. If you disassemble some code you'll see relative pointer style references to portions of the stack, but as far as a higher level language is concerned, the language imposes its own rules of scope. One important aspect of a stack, however, is that once a function returns, anything local to that function is immediately freed from the stack. That works the way you'd expect it to work given how your programming languages work. In a heap, it's also difficult to define. The scope is whatever is exposed by the OS, but your programming language probably adds its rules about what a \"scope\" is in your application. The processor architecture and the OS use virtual addressing, which the processor translates to physical addresses and there are page faults, etc. They keep track of what pages belong to which applications. You never really need to worry about this, though, because you just use whatever method your programming language uses to allocate and free memory, and check for errors (if the allocation/freeing fails for any reason).\n\nWhat determines the size of each of them?\n\nAgain, it depends on the language, compiler, operating system and architecture. A stack is usually pre-allocated, because by definition it must be contiguous memory. The language compiler or the OS determine its size. You don't store huge chunks of data on the stack, so it'll be big enough that it should never be fully used, except in cases of unwanted endless recursion (hence, \"stack overflow\") or other unusual programming decisions.\n\nA heap is a general term for anything that can be dynamically allocated. Depending on which way you look at it, it is constantly changing size. In modern processors and operating systems the exact way it works is very abstracted anyway, so you don't normally need to worry much about how it works deep down, except that (in languages where it lets you) you mustn't use memory that you haven't allocated yet or memory that you have freed.\n\nWhat makes one faster?\n\nThe stack is faster because all free memory is always contiguous. No list needs to be maintained of all the segments of free memory, just a single pointer to the current top of the stack. Compilers usually store this pointer in a special, fast register for this purpose. What's more, subsequent operations on a stack are usually concentrated within very nearby areas of memory, which at a very low level is good for optimization by the processor on-die caches.\n\nShare\nImprove this answer\nFollow\nedited Mar 12 '20 at 0:37\nanswered Mar 19 '09 at 14:38\nthomasrutter\n106k25\n25 gold badges\n138\n138 silver badges\n161\n161 bronze badges","comments":["David I don't agree that that is a good image or that \"push-down stack\" is a good term to illustrate the concept. When you add something to a stack, the other contents of the stack aren't pushed down, they remain where they are.","This answer includes a big mistake. Static variables are not allocated on the stack. See my answer [link] stackoverflow.com/a/13326916/1763801 for clarification. you are equating \"automatic\" variables with \"static\" variables, but they are not at all the same","Specifically, you say \"statically allocated local variables\" are allocated on the stack. Actually they are allocated in the data segment. Only automatically allocated variables (which includes most but not all local variables and also things like function parameters passed in by value rather than by reference) are allocated on the stack.","I've just realised you're right - in C, static allocation is its own separate thing rather than a term for anything that's not dynamic. I've edited my answer, thanks.","It's not just C. Java, Pascal, Python and many others all have the notions of static versus automatic versus dynamic allocation. Saying \"static allocation\" means the same thing just about everywhere. In no language does static allocation mean \"not dynamic\". You want the term \"automatic\" allocation for what you are describing (i.e. the things on the stack)."]},{"answer":"(I have moved this answer from another question that was more or less a dupe of this one.)\n\nThe answer to your question is implementation specific and may vary across compilers and processor architectures. However, here is a simplified explanation.\n\nBoth the stack and the heap are memory areas allocated from the underlying operating system (often virtual memory that is mapped to physical memory on demand).\nIn a multi-threaded environment each thread will have its own completely independent stack but they will share the heap. Concurrent access has to be controlled on the heap and is not possible on the stack.\nThe heap\nThe heap contains a linked list of used and free blocks. New allocations on the heap (by new or malloc) are satisfied by creating a suitable block from one of the free blocks. This requires updating list of blocks on the heap. This meta information about the blocks on the heap is also stored on the heap often in a small area just in front of every block.\nAs the heap grows new blocks are often allocated from lower addresses towards higher addresses. Thus you can think of the heap as a heap of memory blocks that grows in size as memory is allocated. If the heap is too small for an allocation the size can often be increased by acquiring more memory from the underlying operating system.\nAllocating and deallocating many small blocks may leave the heap in a state where there are a lot of small free blocks interspersed between the used blocks. A request to allocate a large block may fail because none of the free blocks are large enough to satisfy the allocation request even though the combined size of the free blocks may be large enough. This is called heap fragmentation.\nWhen a used block that is adjacent to a free block is deallocated the new free block may be merged with the adjacent free block to create a larger free block effectively reducing the fragmentation of the heap.\n\nThe stack\nThe stack often works in close tandem with a special register on the CPU named the stack pointer. Initially the stack pointer points to the top of the stack (the highest address on the stack).\nThe CPU has special instructions for pushing values onto the stack and popping them back from the stack. Each push stores the value at the current location of the stack pointer and decreases the stack pointer. A pop retrieves the value pointed to by the stack pointer and then increases the stack pointer (don't be confused by the fact that adding a value to the stack decreases the stack pointer and removing a value increases it. Remember that the stack grows to the bottom). The values stored and retrieved are the values of the CPU registers.\nWhen a function is called the CPU uses special instructions that push the current instruction pointer, i.e. the address of the code executing on the stack. The CPU then jumps to the function by setting the instruction pointer to the address of the function called. Later, when the function returns, the old instruction pointer is popped from the stack and execution resumes at the code just after the call to the function.\nWhen a function is entered, the stack pointer is decreased to allocate more space on the stack for local (automatic) variables. If the function has one local 32 bit variable four bytes are set aside on the stack. When the function returns, the stack pointer is moved back to free the allocated area.\nIf a function has parameters, these are pushed onto the stack before the call to the function. The code in the function is then able to navigate up the stack from the current stack pointer to locate these values.\nNesting function calls work like a charm. Each new call will allocate function parameters, the return address and space for local variables and these activation records can be stacked for nested calls and will unwind in the correct way when the functions return.\nAs the stack is a limited block of memory, you can cause a stack overflow by calling too many nested functions and/or allocating too much space for local variables. Often the memory area used for the stack is set up in such a way that writing below the bottom (the lowest address) of the stack will trigger a trap or exception in the CPU. This exceptional condition can then be caught by the runtime and converted into some kind of stack overflow exception.\n\nCan a function be allocated on the heap instead of a stack?\n\nNo, activation records for functions (i.e. local or automatic variables) are allocated on the stack that is used not only to store these variables, but also to keep track of nested function calls.\n\nHow the heap is managed is really up to the runtime environment. C uses malloc and C++ uses new, but many other languages have garbage collection.\n\nHowever, the stack is a more low-level feature closely tied to the processor architecture. Growing the heap when there is not enough space isn't too hard since it can be implemented in the library call that handles the heap. However, growing the stack is often impossible as the stack overflow only is discovered when it is too late; and shutting down the thread of execution is the only viable option.\n\nShare\nImprove this answer\nFollow\nedited Mar 28 '12 at 23:03\nanswered Jul 31 '09 at 15:54\nMartin Liversage\n97.8k20\n20 gold badges\n196\n196 silver badges\n238\n238 bronze badges","comments":["@Martin - A very good answer/explanation than the more abstract accepted answer. A sample assembly program showing stack pointers/registers being used vis a vis function calls would be more illustrative.","Every reference type is composition of value types(int, string etc). As it is said, that value types are stored in stack than how does it work when they are part of reference type.","This answer was the best in my opinion, because it helped me understand what a return statement really is and how it relates to this \"return address\" that I come across every now and then, what it means to push a function onto the stack, and why functions are pushed onto stacks. Great answer!","This is the best in my opinion, namely for mentioning that the heap/stack are very implementation specific. The other answers assume a lot of things about the language and the environment/OS. +1","What do you mean \"The code in the function is then able to navigate up the stack from the current stack pointer to locate these values.\" ? Can you elaborate on this please?"]},{"answer":"In the following C# code\n\npublic void Method1()\n{\n    int i = 4;\n    int y = 2;\n    class1 cls1 = new class1();\n}\n\n\nHere's how the memory is managed\n\nLocal Variables that only need to last as long as the function invocation go in the stack. The heap is used for variables whose lifetime we don't really know up front but we expect them to last a while. In most languages it's critical that we know at compile time how large a variable is if we want to store it on the stack.\n\nObjects (which vary in size as we update them) go on the heap because we don't know at creation time how long they are going to last. In many languages the heap is garbage collected to find objects (such as the cls1 object) that no longer have any references.\n\nIn Java, most objects go directly into the heap. In languages like C / C++, structs and classes can often remain on the stack when you're not dealing with pointers.\n\nMore information can be found here:\n\nThe difference between stack and heap memory allocation « timmurphy.org\n\nand here:\n\nCreating Objects on the Stack and Heap\n\nThis article is the source of picture above: Six important .NET concepts: Stack, heap, value types, reference types, boxing, and unboxing - CodeProject\n\nbut be aware it may contain some inaccuracies.\n\nShare\nImprove this answer\nFollow\nedited Mar 7 '18 at 10:27\nanswered Nov 9 '12 at 12:28\nSnowcrash\n68.3k64\n64 gold badges\n213\n213 silver badges\n329\n329 bronze badges","comments":["This is incorrect. i and cls are not \"static\" variables. they are called \"local\" or \"automatic\" variables. It is a very important distinction. See [link] stackoverflow.com/a/13326916/1763801 for clarification","I did not say they were static variables. I said that int and cls1 are static items. Their memory is statically allocated and therefore they go on the stack. This is in contrast to an object which requires dynamic memory allocation which therefore goes on the heap.","I quote \"Static items... go on the stack\". This is just flat out wrong. Static items go in the data segment, automatic items go on the stack.","Also whoever wrote that codeproject article doesn't know what he is talking about. For instance, he says \"primitive ones needs static type memory\" which is completely untrue. Nothing stops you from allocating primitives in the heap dynamically, just write something like \"int array[] = new int[num]\" and voila, primitives allocated dynamically in .NET. That is just one of several inaccuracies.","I edited your post because you have made serious technical mistakes about what goes in the stack and heap."]},{"answer":"The Stack When you call a function the arguments to that function plus some other overhead is put on the stack. Some info (such as where to go on return) is also stored there. When you declare a variable inside your function, that variable is also allocated on the stack.\n\nDeallocating the stack is pretty simple because you always deallocate in the reverse order in which you allocate. Stack stuff is added as you enter functions, the corresponding data is removed as you exit them. This means that you tend to stay within a small region of the stack unless you call lots of functions that call lots of other functions (or create a recursive solution).\n\nThe Heap The heap is a generic name for where you put the data that you create on the fly. If you don't know how many spaceships your program is going to create, you are likely to use the new (or malloc or equivalent) operator to create each spaceship. This allocation is going to stick around for a while, so it is likely we will free things in a different order than we created them.\n\nThus, the heap is far more complex, because there end up being regions of memory that are unused interleaved with chunks that are - memory gets fragmented. Finding free memory of the size you need is a difficult problem. This is why the heap should be avoided (though it is still often used).\n\nImplementation Implementation of both the stack and heap is usually down to the runtime / OS. Often games and other applications that are performance critical create their own memory solutions that grab a large chunk of memory from the heap and then dish it out internally to avoid relying on the OS for memory.\n\nThis is only practical if your memory usage is quite different from the norm - i.e for games where you load a level in one huge operation and can chuck the whole lot away in another huge operation.\n\nPhysical location in memory This is less relevant than you think because of a technology called Virtual Memory which makes your program think that you have access to a certain address where the physical data is somewhere else (even on the hard disc!). The addresses you get for the stack are in increasing order as your call tree gets deeper. The addresses for the heap are un-predictable (i.e implimentation specific) and frankly not important.\n\nShare\nImprove this answer\nFollow\nedited Sep 17 '08 at 4:34\nanswered Sep 17 '08 at 4:27\nTom Leys\n17.2k6\n6 gold badges\n38\n38 silver badges\n60\n60 bronze badges","comments":["A recommendation to avoid using the heap is pretty strong. Modern systems have good heap managers, and modern dynamic languages use the heap extensively (without the programmer really worrying about it). I'd say use the heap, but with a manual allocator, don't forget to free!","If you can use the stack or the heap, use the stack. If you can't use the stack, really no choice. I use both a lot, and of course using std::vector or similar hits the heap. For a novice, you avoid the heap because the stack is simply so easy!!","If your language doesn't implement garbage collection, Smart pointers (Seporately allocated objects that wrap around a pointer which do reference counting for dynamically allocated chunks of memory) are closely related to garbage collection and are a decent way of managing the heap in a safe and leak free manner. They are implemented in various frameworks, but are also not that tough to implement for your own programs as well.","\"This is why the heap should be avoided (though it is still often used).\" I'm not sure what this practically means, especially as memory is managed differently in many high level languages. As this question is tagged language-agnostic, I'd say this particular comment/line is ill-placed and not applicable.","Good point @JonnoHampson - While you make a valid point, I'd argue that if you're working in a \"high level language\" with a GC you probably don't care about memory allocation mechanisms at all - and so don't even care what the stack and heap are."]},{"answer":"To clarify, this answer has incorrect information (thomas fixed his answer after comments, cool :) ). Other answers just avoid explaining what static allocation means. So I will explain the three main forms of allocation and how they usually relate to the heap, stack, and data segment below. I also will show some examples in both C/C++ and Python to help people understand.\n\n\"Static\" (AKA statically allocated) variables are not allocated on the stack. Do not assume so - many people do only because \"static\" sounds a lot like \"stack\". They actually exist in neither the stack nor the heap. The are part of what's called the data segment.\n\nHowever, it is generally better to consider \"scope\" and \"lifetime\" rather than \"stack\" and \"heap\".\n\nScope refers to what parts of the code can access a variable. Generally we think of local scope (can only be accessed by the current function) versus global scope (can be accessed anywhere) although scope can get much more complex.\n\nLifetime refers to when a variable is allocated and deallocated during program execution. Usually we think of static allocation (variable will persist through the entire duration of the program, making it useful for storing the same information across several function calls) versus automatic allocation (variable only persists during a single call to a function, making it useful for storing information that is only used during your function and can be discarded once you are done) versus dynamic allocation (variables whose duration is defined at runtime, instead of compile time like static or automatic).\n\nAlthough most compilers and interpreters implement this behavior similarly in terms of using stacks, heaps, etc, a compiler may sometimes break these conventions if it wants as long as behavior is correct. For instance, due to optimization a local variable may only exist in a register or be removed entirely, even though most local variables exist in the stack. As has been pointed out in a few comments, you are free to implement a compiler that doesn't even use a stack or a heap, but instead some other storage mechanisms (rarely done, since stacks and heaps are great for this).\n\nI will provide some simple annotated C code to illustrate all of this. The best way to learn is to run a program under a debugger and watch the behavior. If you prefer to read python, skip to the end of the answer :)\n\n// Statically allocated in the data segment when the program/DLL is first loaded\n// Deallocated when the program/DLL exits\n// scope - can be accessed from anywhere in the code\nint someGlobalVariable;\n\n// Statically allocated in the data segment when the program is first loaded\n// Deallocated when the program/DLL exits\n// scope - can be accessed from anywhere in this particular code file\nstatic int someStaticVariable;\n\n// \"someArgument\" is allocated on the stack each time MyFunction is called\n// \"someArgument\" is deallocated when MyFunction returns\n// scope - can be accessed only within MyFunction()\nvoid MyFunction(int someArgument) {\n\n    // Statically allocated in the data segment when the program is first loaded\n    // Deallocated when the program/DLL exits\n    // scope - can be accessed only within MyFunction()\n    static int someLocalStaticVariable;\n\n    // Allocated on the stack each time MyFunction is called\n    // Deallocated when MyFunction returns\n    // scope - can be accessed only within MyFunction()\n    int someLocalVariable;\n\n    // A *pointer* is allocated on the stack each time MyFunction is called\n    // This pointer is deallocated when MyFunction returns\n    // scope - the pointer can be accessed only within MyFunction()\n    int* someDynamicVariable;\n\n    // This line causes space for an integer to be allocated in the heap\n    // when this line is executed. Note this is not at the beginning of\n    // the call to MyFunction(), like the automatic variables\n    // scope - only code within MyFunction() can access this space\n    // *through this particular variable*.\n    // However, if you pass the address somewhere else, that code\n    // can access it too\n    someDynamicVariable = new int;\n\n\n    // This line deallocates the space for the integer in the heap.\n    // If we did not write it, the memory would be \"leaked\".\n    // Note a fundamental difference between the stack and heap\n    // the heap must be managed. The stack is managed for us.\n    delete someDynamicVariable;\n\n    // In other cases, instead of deallocating this heap space you\n    // might store the address somewhere more permanent to use later.\n    // Some languages even take care of deallocation for you... but\n    // always it needs to be taken care of at runtime by some mechanism.\n\n    // When the function returns, someArgument, someLocalVariable\n    // and the pointer someDynamicVariable are deallocated.\n    // The space pointed to by someDynamicVariable was already\n    // deallocated prior to returning.\n    return;\n}\n\n// Note that someGlobalVariable, someStaticVariable and\n// someLocalStaticVariable continue to exist, and are not\n// deallocated until the program exits.\n\n\nA particularly poignant example of why it's important to distinguish between lifetime and scope is that a variable can have local scope but static lifetime - for instance, \"someLocalStaticVariable\" in the code sample above. Such variables can make our common but informal naming habits very confusing. For instance when we say \"local\" we usually mean \"locally scoped automatically allocated variable\" and when we say global we usually mean \"globally scoped statically allocated variable\". Unfortunately when it comes to things like \"file scoped statically allocated variables\" many people just say... \"huh???\".\n\nSome of the syntax choices in C/C++ exacerbate this problem - for instance many people think global variables are not \"static\" because of the syntax shown below.\n\nint var1; // Has global scope and static allocation\nstatic int var2; // Has file scope and static allocation\n\nint main() {return 0;}\n\n\nNote that putting the keyword \"static\" in the declaration above prevents var2 from having global scope. Nevertheless, the global var1 has static allocation. This is not intuitive! For this reason, I try to never use the word \"static\" when describing scope, and instead say something like \"file\" or \"file limited\" scope. However many people use the phrase \"static\" or \"static scope\" to describe a variable that can only be accessed from one code file. In the context of lifetime, \"static\" always means the variable is allocated at program start and deallocated when program exits.\n\nSome people think of these concepts as C/C++ specific. They are not. For instance, the Python sample below illustrates all three types of allocation (there are some subtle differences possible in interpreted languages that I won't get into here).\n\nfrom datetime import datetime\n\nclass Animal:\n    _FavoriteFood = 'Undefined' # _FavoriteFood is statically allocated\n\n    def PetAnimal(self):\n        curTime = datetime.time(datetime.now()) # curTime is automatically allocatedion\n        print(\"Thank you for petting me. But it's \" + str(curTime) + \", you should feed me. My favorite food is \" + self._FavoriteFood)\n\nclass Cat(Animal):\n    _FavoriteFood = 'tuna' # Note since we override, Cat class has its own statically allocated _FavoriteFood variable, different from Animal's\n\nclass Dog(Animal):\n    _FavoriteFood = 'steak' # Likewise, the Dog class gets its own static variable. Important to note - this one static variable is shared among all instances of Dog, hence it is not dynamic!\n\n\nif __name__ == \"__main__\":\n    whiskers = Cat() # Dynamically allocated\n    fido = Dog() # Dynamically allocated\n    rinTinTin = Dog() # Dynamically allocated\n\n    whiskers.PetAnimal()\n    fido.PetAnimal()\n    rinTinTin.PetAnimal()\n\n    Dog._FavoriteFood = 'milkbones'\n    whiskers.PetAnimal()\n    fido.PetAnimal()\n    rinTinTin.PetAnimal()\n\n# Output is:\n# Thank you for petting me. But it's 13:05:02.255000, you should feed me. My favorite food is tuna\n# Thank you for petting me. But it's 13:05:02.255000, you should feed me. My favorite food is steak\n# Thank you for petting me. But it's 13:05:02.255000, you should feed me. My favorite food is steak\n# Thank you for petting me. But it's 13:05:02.255000, you should feed me. My favorite food is tuna\n# Thank you for petting me. But it's 13:05:02.255000, you should feed me. My favorite food is milkbones\n# Thank you for petting me. But it's 13:05:02.256000, you should feed me. My favorite food is milkbones\n\nShare\nImprove this answer\nFollow\nedited Jul 30 '17 at 12:13\ncommunity wiki\n\n\n20 revs, 5 users 72%\ndavec","comments":["I would refer to a static variable declared within a function as having only local accessibility, but would generally not use the term \"scope\" with it. Also, it may be worth noting that the one stack/heap aspect with which languages have essentially zero flexibility: a language which saves execution context on a stack cannot use that same stack to hold things which will need to outlive the contexts wherein they are created. Some languages like PostScript have multiple stacks, but have a \"heap\" that behaves more like a stack.","@supercat That all makes sense. I defined scope as \"what parts of the code can access a variable\" (and feel this is the most standard definition) so I think we agree :)","you must be kidding. can you really define static variable inside a function ?","@zaeemsattar absolutely and this is not ususual to see in C code","@ZaeemSattar Think of the static function variable like a hidden global or like a private static member variable."]},{"answer":"Others have answered the broad strokes pretty well, so I'll throw in a few details.\n\nStack and heap need not be singular. A common situation in which you have more than one stack is if you have more than one thread in a process. In this case each thread has its own stack. You can also have more than one heap, for example some DLL configurations can result in different DLLs allocating from different heaps, which is why it's generally a bad idea to release memory allocated by a different library.\n\nIn C you can get the benefit of variable length allocation through the use of alloca, which allocates on the stack, as opposed to alloc, which allocates on the heap. This memory won't survive your return statement, but it's useful for a scratch buffer.\n\nMaking a huge temporary buffer on Windows that you don't use much of is not free. This is because the compiler will generate a stack probe loop that is called every time your function is entered to make sure the stack exists (because Windows uses a single guard page at the end of your stack to detect when it needs to grow the stack. If you access memory more than one page off the end of the stack you will crash). Example:\n\nvoid myfunction()\n{\n   char big[10000000];\n   // Do something that only uses for first 1K of big 99% of the time.\n}\n\nShare\nImprove this answer\nFollow\nedited Jul 30 '17 at 11:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 17 '08 at 4:48\nDon Neufeld\n21.5k10\n10 gold badges\n49\n49 silver badges\n49\n49 bronze badges","comments":["Re \"as opposed to alloc\": Do you mean \"as opposed to malloc\"?","How portable is alloca?","@PeterMortensen it's not POSIX, portability not guaranteed."]},{"answer":"Others have directly answered your question, but when trying to understand the stack and the heap, I think it is helpful to consider the memory layout of a traditional UNIX process (without threads and mmap()-based allocators). The Memory Management Glossary web page has a diagram of this memory layout.\n\nThe stack and heap are traditionally located at opposite ends of the process's virtual address space. The stack grows automatically when accessed, up to a size set by the kernel (which can be adjusted with setrlimit(RLIMIT_STACK, ...)). The heap grows when the memory allocator invokes the brk() or sbrk() system call, mapping more pages of physical memory into the process's virtual address space.\n\nIn systems without virtual memory, such as some embedded systems, the same basic layout often applies, except the stack and heap are fixed in size. However, in other embedded systems (such as those based on Microchip PIC microcontrollers), the program stack is a separate block of memory that is not addressable by data movement instructions, and can only be modified or read indirectly through program flow instructions (call, return, etc.). Other architectures, such as Intel Itanium processors, have multiple stacks. In this sense, the stack is an element of the CPU architecture.\n\nShare\nImprove this answer\nFollow\nedited Aug 5 '15 at 20:36\nEthanP\n1,5452\n2 gold badges\n19\n19 silver badges\n25\n25 bronze badges\nanswered Sep 17 '08 at 7:16\nbk1e\n22.8k6\n6 gold badges\n48\n48 silver badges\n63\n63 bronze badges","comments":[]},{"answer":"The stack is a portion of memory that can be manipulated via several key assembly language instructions, such as 'pop' (remove and return a value from the stack) and 'push' (push a value to the stack), but also call (call a subroutine - this pushes the address to return to the stack) and return (return from a subroutine - this pops the address off of the stack and jumps to it). It's the region of memory below the stack pointer register, which can be set as needed. The stack is also used for passing arguments to subroutines, and also for preserving the values in registers before calling subroutines.\n\nThe heap is a portion of memory that is given to an application by the operating system, typically through a syscall like malloc. On modern OSes this memory is a set of pages that only the calling process has access to.\n\nThe size of the stack is determined at runtime, and generally does not grow after the program launches. In a C program, the stack needs to be large enough to hold every variable declared within each function. The heap will grow dynamically as needed, but the OS is ultimately making the call (it will often grow the heap by more than the value requested by malloc, so that at least some future mallocs won't need to go back to the kernel to get more memory. This behavior is often customizable)\n\nBecause you've allocated the stack before launching the program, you never need to malloc before you can use the stack, so that's a slight advantage there. In practice, it's very hard to predict what will be fast and what will be slow in modern operating systems that have virtual memory subsystems, because how the pages are implemented and where they are stored is an implementation detail.\n\nShare\nImprove this answer\nFollow\nanswered Sep 17 '08 at 4:29\nDaniel Papasian\n15.6k6\n6 gold badges\n27\n27 silver badges\n32\n32 bronze badges","comments":["Also worth mentioning here that intel heavily optimizes stack accesses, especially things such as predicting where you return from a function."]},{"answer":"What is a stack?\n\nA stack is a pile of objects, typically one that is neatly arranged.\n\nStacks in computing architectures are regions of memory where data is added or removed in a last-in-first-out manner.\nIn a multi-threaded application, each thread will have its own stack.\n\nWhat is a heap?\n\nA heap is an untidy collection of things piled up haphazardly.\n\nIn computing architectures the heap is an area of dynamically-allocated memory that is managed automatically by the operating system or the memory manager library.\nMemory on the heap is allocated, deallocated, and resized regularly during program execution, and this can lead to a problem called fragmentation.\nFragmentation occurs when memory objects are allocated with small spaces in between that are too small to hold additional memory objects.\nThe net result is a percentage of the heap space that is not usable for further memory allocations.\n\nBoth together\n\nIn a multi-threaded application, each thread will have its own stack. But, all the different threads will share the heap.\nBecause the different threads share the heap in a multi-threaded application, this also means that there has to be some coordination between the threads so that they don’t try to access and manipulate the same piece(s) of memory in the heap at the same time.\n\nWhich is faster – the stack or the heap? And why?\n\nThe stack is much faster than the heap.\nThis is because of the way that memory is allocated on the stack.\nAllocating memory on the stack is as simple as moving the stack pointer up.\n\nFor people new to programming, it’s probably a good idea to use the stack since it’s easier.\nBecause the stack is small, you would want to use it when you know exactly how much memory you will need for your data, or if you know the size of your data is very small.\nIt’s better to use the heap when you know that you will need a lot of memory for your data, or you just are not sure how much memory you will need (like with a dynamic array).\n\nJava Memory Model\n\nThe stack is the area of memory where local variables (including method parameters) are stored. When it comes to object variables, these are merely references (pointers) to the actual objects on the heap.\nEvery time an object is instantiated, a chunk of heap memory is set aside to hold the data (state) of that object. Since objects can contain other objects, some of this data can in fact hold references to those nested objects.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jun 11 '14 at 19:42\nShreyos Adikari\n11.5k19\n19 gold badges\n69\n69 silver badges\n76\n76 bronze badges","comments":[]},{"answer":"I think many other people have given you mostly correct answers on this matter.\n\nOne detail that has been missed, however, is that the \"heap\" should in fact probably be called the \"free store\". The reason for this distinction is that the original free store was implemented with a data structure known as a \"binomial heap.\" For that reason, allocating from early implementations of malloc()/free() was allocation from a heap. However, in this modern day, most free stores are implemented with very elaborate data structures that are not binomial heaps.\n\nShare\nImprove this answer\nFollow\nanswered Sep 17 '08 at 4:57\nHeath","comments":["Another nitpick- most of the answers (lightly) imply that the use of a \"stack\" is required by the C language. This is a common misconception, though it is the (by far) dominate paradigm for implementing C99 6.2.4 automatic storage duration objects (variables). In fact, the word \"stack\" does not even appear in the C99 language standard: open-std.org/JTC1/SC22/WG14/www/docs/n1256.pdf","[@Heath] I have a small comment on your answer. Take a look at the accepted answer to this question. It says that the free store most probably is the same as the heap, though not necessarily is."]},{"answer":"You can do some interesting things with the stack. For instance, you have functions like alloca (assuming you can get past the copious warnings concerning its use), which is a form of malloc that specifically uses the stack, not the heap, for memory.\n\nThat said, stack-based memory errors are some of the worst I've experienced. If you use heap memory, and you overstep the bounds of your allocated block, you have a decent chance of triggering a segment fault. (Not 100%: your block may be incidentally contiguous with another that you have previously allocated.) But since variables created on the stack are always contiguous with each other, writing out of bounds can change the value of another variable. I have learned that whenever I feel that my program has stopped obeying the laws of logic, it is probably buffer overflow.\n\nShare\nImprove this answer\nFollow\nanswered Mar 19 '09 at 15:55\nPeter\n1,2868\n8 silver badges\n4\n4 bronze badges","comments":["How portable is alloca? For instance, does it work on Windows? Is it only for Unix-like operating systems?"]},{"answer":"Simply, the stack is where local variables get created. Also, every time you call a subroutine the program counter (pointer to the next machine instruction) and any important registers, and sometimes the parameters get pushed on the stack. Then any local variables inside the subroutine are pushed onto the stack (and used from there). When the subroutine finishes, that stuff all gets popped back off the stack. The PC and register data gets and put back where it was as it is popped, so your program can go on its merry way.\n\nThe heap is the area of memory dynamic memory allocations are made out of (explicit \"new\" or \"allocate\" calls). It is a special data structure that can keep track of blocks of memory of varying sizes and their allocation status.\n\nIn \"classic\" systems RAM was laid out such that the stack pointer started out at the bottom of memory, the heap pointer started out at the top, and they grew towards each other. If they overlap, you are out of RAM. That doesn't work with modern multi-threaded OSes though. Every thread has to have its own stack, and those can get created dynamicly.\n\nShare\nImprove this answer\nFollow\nedited Mar 19 '09 at 15:19\nanswered Mar 19 '09 at 15:13\nT.E.D.\n41.7k8\n8 gold badges\n64\n64 silver badges\n131\n131 bronze badges","comments":["[@T.E.D.] Why did you say \"sometimes the parameters get pushed on the stack\"? What I know is that they always are. Could you please elaborate more?","@OmarOthman - I say that because it is entirely up to the writer of your compiler/interpreter what happens when a subroutine is called. Classic Fortran behavior is to not use a stack at all. Some languages support exotic things like pass-by-name, which is effectively a textual substitution."]},{"answer":"From WikiAnwser.\n\nStack\n\nWhen a function or a method calls another function which in turns calls another function, etc., the execution of all those functions remains suspended until the very last function returns its value.\n\nThis chain of suspended function calls is the stack, because elements in the stack (function calls) depend on each other.\n\nThe stack is important to consider in exception handling and thread executions.\n\nHeap\n\nThe heap is simply the memory used by programs to store variables. Element of the heap (variables) have no dependencies with each other and can always be accessed randomly at any time.\n\nShare\nImprove this answer\nFollow\nedited Jul 30 '17 at 12:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 2 '09 at 1:25\ndevXen\n2,8323\n3 gold badges\n30\n30 silver badges\n43\n43 bronze badges","comments":["\"I like the accepted answer better since it's even more low level.\" That's a bad thing, not a good thing."]},{"answer":"Stack\n\nVery fast access\nDon't have to explicitly de-allocate variables\nSpace is managed efficiently by CPU, memory will not become fragmented\nLocal variables only\nLimit on stack size (OS-dependent)\nVariables cannot be resized\n\nHeap\n\nVariables can be accessed globally\nNo limit on memory size\n(Relatively) slower access\nNo guaranteed efficient use of space, memory may become fragmented over time as blocks of memory are allocated, then freed\nYou must manage memory (you're in charge of allocating and freeing variables)\nVariables can be resized using realloc()\nShare\nImprove this answer\nFollow\nedited Jul 30 '17 at 12:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 30 '14 at 6:33\nunknown\n4,2938\n8 gold badges\n40\n40 silver badges\n57\n57 bronze badges","comments":[]},{"answer":"In Short\n\nA stack is used for static memory allocation and a heap for dynamic memory allocation, both stored in the computer's RAM.\n\nIn Detail\n\nThe Stack\n\nThe stack is a \"LIFO\" (last in, first out) data structure, that is managed and optimized by the CPU quite closely. Every time a function declares a new variable, it is \"pushed\" onto the stack. Then every time a function exits, all of the variables pushed onto the stack by that function, are freed (that is to say, they are deleted). Once a stack variable is freed, that region of memory becomes available for other stack variables.\n\nThe advantage of using the stack to store variables, is that memory is managed for you. You don't have to allocate memory by hand, or free it once you don't need it any more. What's more, because the CPU organizes stack memory so efficiently, reading from and writing to stack variables is very fast.\n\nMore can be found here.\n\nThe Heap\n\nThe heap is a region of your computer's memory that is not managed automatically for you, and is not as tightly managed by the CPU. It is a more free-floating region of memory (and is larger). To allocate memory on the heap, you must use malloc() or calloc(), which are built-in C functions. Once you have allocated memory on the heap, you are responsible for using free() to deallocate that memory once you don't need it any more.\n\nIf you fail to do this, your program will have what is known as a memory leak. That is, memory on the heap will still be set aside (and won't be available to other processes). As we will see in the debugging section, there is a tool called Valgrind that can help you detect memory leaks.\n\nUnlike the stack, the heap does not have size restrictions on variable size (apart from the obvious physical limitations of your computer). Heap memory is slightly slower to be read from and written to, because one has to use pointers to access memory on the heap. We will talk about pointers shortly.\n\nUnlike the stack, variables created on the heap are accessible by any function, anywhere in your program. Heap variables are essentially global in scope.\n\nMore can be found here.\n\nVariables allocated on the stack are stored directly to the memory and access to this memory is very fast, and its allocation is dealt with when the program is compiled. When a function or a method calls another function which in turns calls another function, etc., the execution of all those functions remains suspended until the very last function returns its value. The stack is always reserved in a LIFO order, the most recently reserved block is always the next block to be freed. This makes it really simple to keep track of the stack, freeing a block from the stack is nothing more than adjusting one pointer.\n\nVariables allocated on the heap have their memory allocated at run time and accessing this memory is a bit slower, but the heap size is only limited by the size of virtual memory. Elements of the heap have no dependencies with each other and can always be accessed randomly at any time. You can allocate a block at any time and free it at any time. This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time.\n\nYou can use the stack if you know exactly how much data you need to allocate before compile time, and it is not too big. You can use the heap if you don't know exactly how much data you will need at runtime or if you need to allocate a lot of data.\n\nIn a multi-threaded situation each thread will have its own completely independent stack, but they will share the heap. The stack is thread specific and the heap is application specific. The stack is important to consider in exception handling and thread executions.\n\nEach thread gets a stack, while there's typically only one heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).\n\nAt run-time, if the application needs more heap, it can allocate memory from free memory and if the stack needs memory, it can allocate memory from free memory allocated memory for the application.\n\nEven, more detail is given here and here.\n\nNow come to your question's answers.\n\nTo what extent are they controlled by the OS or language runtime?\n\nThe OS allocates the stack for each system-level thread when the thread is created. Typically the OS is called by the language runtime to allocate the heap for the application.\n\nMore can be found here.\n\nWhat is their scope?\n\nAlready given in top.\n\n\"You can use the stack if you know exactly how much data you need to allocate before compile time, and it is not too big. You can use the heap if you don't know exactly how much data you will need at runtime or if you need to allocate a lot of data.\"\n\nMore can be found in here.\n\nWhat determines the size of each of them?\n\nThe size of the stack is set by OS when a thread is created. The size of the heap is set on application startup, but it can grow as space is needed (the allocator requests more memory from the operating system).\n\nWhat makes one faster?\n\nStack allocation is much faster since all it really does is move the stack pointer. Using memory pools, you can get comparable performance out of heap allocation, but that comes with a slight added complexity and its own headaches.\n\nAlso, stack vs. heap is not only a performance consideration; it also tells you a lot about the expected lifetime of objects.\n\nDetails can be found from here.\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '18 at 15:12\nzgue\n3,4879\n9 gold badges\n31\n31 silver badges\n35\n35 bronze badges\nanswered May 2 '16 at 12:16\nAbrar Jahin\n12.4k20\n20 gold badges\n94\n94 silver badges\n144\n144 bronze badges","comments":[]},{"answer":"OK, simply and in short words, they mean ordered and not ordered...!\n\nStack: In stack items, things get on the top of each-other, means gonna be faster and more efficient to be processed!...\n\nSo there is always an index to point the specific item, also processing gonna be faster, there is relationship between the items as well!...\n\nHeap: No order, processing gonna be slower and values are messed up together with no specific order or index... there are random and there is no relationship between them... so execution and usage time could be vary...\n\nI also create the image below to show how they may look like:\n\nShare\nImprove this answer\nFollow\nedited Apr 23 '18 at 2:06\nanswered Jul 18 '17 at 15:04\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"stack, heap and data of each process in virtual memory:\n\nShare\nImprove this answer\nFollow\nedited Mar 12 '18 at 18:00\nanswered Sep 14 '17 at 17:32\nYousha Aleayoub\n3,4003\n3 gold badges\n44\n44 silver badges\n59\n59 bronze badges","comments":[]},{"answer":"In the 1980s, UNIX propagated like bunnies with big companies rolling their own. Exxon had one as did dozens of brand names lost to history. How memory was laid out was at the discretion of the many implementors.\n\nA typical C program was laid out flat in memory with an opportunity to increase by changing the brk() value. Typically, the HEAP was just below this brk value and increasing brk increased the amount of available heap.\n\nThe single STACK was typically an area below HEAP which was a tract of memory containing nothing of value until the top of the next fixed block of memory. This next block was often CODE which could be overwritten by stack data in one of the famous hacks of its era.\n\nOne typical memory block was BSS (a block of zero values) which was accidentally not zeroed in one manufacturer's offering. Another was DATA containing initialized values, including strings and numbers. A third was CODE containing CRT (C runtime), main, functions, and libraries.\n\nThe advent of virtual memory in UNIX changes many of the constraints. There is no objective reason why these blocks need be contiguous, or fixed in size, or ordered a particular way now. Of course, before UNIX was Multics which didn't suffer from these constraints. Here is a schematic showing one of the memory layouts of that era.\n\nShare\nImprove this answer\nFollow\nanswered Mar 27 '15 at 19:55\njlettvin\n1,0437\n7 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"A couple of cents: I think, it will be good to draw memory graphical and more simple:\n\n\nArrows - show where grow stack and heap, process stack size have limit, defined in OS, thread stack size limits by parameters in thread create API usually. Heap usually limiting by process maximum virtual memory size, for 32 bit 2-4 GB for example.\n\nSo simple way: process heap is general for process and all threads inside, using for memory allocation in common case with something like malloc().\n\nStack is quick memory for store in common case function return pointers and variables, processed as parameters in function call, local function variables.\n\nShare\nImprove this answer\nFollow\nedited Jul 30 '17 at 12:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 17 '15 at 15:08\nMaxim Akristiniy\n2,0432\n2 gold badges\n13\n13 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"I have something to share, although the major points are already covered.\n\nStack\n\nVery fast access.\nStored in RAM.\nFunction calls are loaded here along with the local variables and function parameters passed.\nSpace is freed automatically when program goes out of a scope.\nStored in sequential memory.\n\nHeap\n\nSlow access comparatively to Stack.\nStored in RAM.\nDynamically created variables are stored here, which later requires freeing the allocated memory after use.\nStored wherever memory allocation is done, accessed by pointer always.\n\nInteresting note:\n\nShould the function calls had been stored in heap, it would had resulted in 2 messy points:\nDue to sequential storage in stack, execution is faster. Storage in heap would have resulted in huge time consumption thus making the whole program execute slower.\nIf functions were stored in heap (messy storage pointed by pointer), there would have been no way to return to the caller address back (which stack gives due to sequential storage in memory).\nShare\nImprove this answer\nFollow\nedited Dec 10 '18 at 8:23\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered Nov 15 '17 at 18:27\npkthapa\n9411\n1 gold badge\n14\n14 silver badges\n23\n23 bronze badges","comments":["concise and clean. nice:)"]},{"answer":"Since some answers went nitpicking, I'm going to contribute my mite.\n\nSurprisingly, no one has mentioned that multiple (i.e. not related to the number of running OS-level threads) call stacks are to be found not only in exotic languages (PostScript) or platforms (Intel Itanium), but also in fibers, green threads and some implementations of coroutines.\n\nFibers, green threads and coroutines are in many ways similar, which leads to much confusion. The difference between fibers and green threads is that the former use cooperative multitasking, while the latter may feature either cooperative or preemptive one (or even both). For the distinction between fibers and coroutines, see here.\n\nIn any case, the purpose of both fibers, green threads and coroutines is having multiple functions executing concurrently, but not in parallel (see this SO question for the distinction) within a single OS-level thread, transferring control back and forth from one another in an organized fashion.\n\nWhen using fibers, green threads or coroutines, you usually have a separate stack per function. (Technically, not just a stack but a whole context of execution is per function. Most importantly, CPU registers.) For every thread there're as many stacks as there're concurrently running functions, and the thread is switching between executing each function according to the logic of your program. When a function runs to its end, its stack is destroyed. So, the number and lifetimes of stacks are dynamic and are not determined by the number of OS-level threads!\n\nNote that I said \"usually have a separate stack per function\". There're both stackful and stackless implementations of couroutines. Most notable stackful C++ implementations are Boost.Coroutine and Microsoft PPL's async/await. (However, C++'s resumable functions (a.k.a. \"async and await\"), which were proposed to C++17, are likely to use stackless coroutines.)\n\nFibers proposal to the C++ standard library is forthcoming. Also, there're some third-party libraries. Green threads are extremely popular in languages like Python and Ruby.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:55\nCommunity♦\n11\n1 silver badge\nanswered Mar 2 '15 at 1:29\nshakurov\n2,13321\n21 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"Wow! So many answers and I don't think one of them got it right...\n\n1) Where and what are they (physically in a real computer's memory)?\n\nThe stack is memory that begins as the highest memory address allocated to your program image, and it then decrease in value from there. It is reserved for called function parameters and for all temporary variables used in functions.\n\nThere are two heaps: public and private.\n\nThe private heap begins on a 16-byte boundary (for 64-bit programs) or a 8-byte boundary (for 32-bit programs) after the last byte of code in your program, and then increases in value from there. It is also called the default heap.\n\nIf the private heap gets too large it will overlap the stack area, as will the stack overlap the heap if it gets too big. Because the stack starts at a higher address and works its way down to lower address, with proper hacking you can get make the stack so large that it will overrun the private heap area and overlap the code area. The trick then is to overlap enough of the code area that you can hook into the code. It's a little tricky to do and you risk a program crash, but it's easy and very effective.\n\nThe public heap resides in it's own memory space outside of your program image space. It is this memory that will be siphoned off onto the hard disk if memory resources get scarce.\n\n2) To what extent are they controlled by the OS or language runtime?\n\nThe stack is controlled by the programmer, the private heap is managed by the OS, and the public heap is not controlled by anyone because it is an OS service -- you make requests and either they are granted or denied.\n\n2b) What is their scope?\n\nThey are all global to the program, but their contents can be private, public, or global.\n\n2c) What determines the size of each of them?\n\nThe size of the stack and the private heap are determined by your compiler runtime options. The public heap is initialized at runtime using a size parameter.\n\n2d) What makes one faster?\n\nThey are not designed to be fast, they are designed to be useful. How the programmer utilizes them determines whether they are \"fast\" or \"slow\"\n\nREF:\n\nhttps://norasandler.com/2019/02/18/Write-a-Compiler-10.html\n\nhttps://docs.microsoft.com/en-us/windows/desktop/api/heapapi/nf-heapapi-getprocessheap\n\nhttps://docs.microsoft.com/en-us/windows/desktop/api/heapapi/nf-heapapi-heapcreate\n\nShare\nImprove this answer\nFollow\nanswered Feb 20 '19 at 2:04\nar18\n3252\n2 silver badges\n5\n5 bronze badges","comments":[]},{"answer":"A lot of answers are correct as concepts, but we must note that a stack is needed by the hardware (i.e. microprocessor) to allow calling subroutines (CALL in assembly language..). (OOP guys will call it methods)\n\nOn the stack you save return addresses and call → push / ret → pop is managed directly in hardware.\n\nYou can use the stack to pass parameters.. even if it is slower than using registers (would a microprocessor guru say or a good 1980s BIOS book...)\n\nWithout stack no microprocessor can work. (we can't imagine a program, even in assembly language, without subroutines/functions)\nWithout the heap it can. (An assembly language program can work without, as the heap is a OS concept, as malloc, that is a OS/Lib call.\n\nStack usage is faster as:\n\nIs hardware, and even push/pop are very efficient.\nmalloc requires entering kernel mode, use lock/semaphore (or other synchronization primitives) executing some code and manage some structures needed to keep track of allocation.\nShare\nImprove this answer\nFollow\nedited Aug 7 '17 at 8:27\nanswered Jul 27 '17 at 22:14\ningconti\n9,3802\n2 gold badges\n53\n53 silver badges\n40\n40 bronze badges","comments":["What is OPP? Do you mean OOP (object-oriented_programming)?","Do you mean to say that malloc is a kernel call?","1) yes, sorry.. OOP... 2) malloc: I write shortly, sorry ... malloc is in user space.. but can trigger down other calls.... the point is that using heap CAN be very slow...","\"A lot of answers are correct as concepts, but we must note that a stack is needed by the hardware (i.e. microprocessor) to allow calling subroutines (CALL in assembly language..)\". You're confusing the CPU stack (if there was one in modern CPU) and the language runtime stacks (one per thread). When programmers talk about a stack, this is the thread execution stack of the runtime, e.g. a NET thread stack), we are not talking about the CPU stack.","\"NET thread\" is not a real stack. (the same for JVM) : they are SW concepts. (other call this \"activation record\") We must start from real circuits as in history of PCs to get a real comprehension."]},{"answer":"The stack is essentially an easy-to-access memory that simply manages its items as a - well - stack. Only items for which the size is known in advance can go onto the stack. This is the case for numbers, strings, booleans.\n\nThe heap is a memory for items of which you can’t predetermine the exact size and structure. Since objects and arrays can be mutated and change at runtime, they have to go into the heap.\n\nSource: Academind\n\nShare\nImprove this answer\nFollow\nedited Apr 10 '20 at 5:23\nanswered Mar 22 '20 at 3:16\nnCardot\n3,5472\n2 gold badges\n21\n21 silver badges\n53\n53 bronze badges","comments":[]},{"answer":"CPU stack and heap are physically related to how CPU and registers works with memory, how machine-assembly language works, not high-level languages themselves, even if these languages can decide little things.\n\nAll modern CPUs work with the \"same\" microprocessor theory: they are all based on what's called \"registers\" and some are for \"stack\" to gain performance. All CPUs have stack registers since the beginning and they had been always here, way of talking, as I know. Assembly languages are the same since the beginning, despite variations... up to Microsoft and its Intermediate Language (IL) that changed the paradigm to have a OO virtual machine assembly language. So we'll be able to have some CLI/CIL CPU in the future (one project of MS).\n\nCPUs have stack registers to speed up memories access, but they are limited compared to the use of others registers to get full access to all the available memory for the processus. It why we talked about stack and heap allocations.\n\nIn summary, and in general, the heap is hudge and slow and is for \"global\" instances and objects content, as the stack is little and fast and for \"local\" variables and references (hidden pointers to forget to manage them).\n\nSo when we use the new keyword in a method, the reference (an int) is created in the stack, but the object and all its content (value-types as well as objects) is created in the heap, if I remember. But local elementary value-types and arrays are created in the stack.\n\nThe difference in memory access is at the cells referencing level: addressing the heap, the overall memory of the process, requires more complexity in terms of handling CPU registers, than the stack which is \"more\" locally in terms of addressing because the CPU stack register is used as base address, if I remember.\n\nIt is why when we have very long or infinite recurse calls or loops, we got stack overflow quickly, without freezing the system on modern computers...\n\nC# Heap(ing) Vs Stack(ing) In .NET\n\nStack vs Heap: Know the Difference\n\nStatic class memory allocation where it is stored C#\n\nWhat and where are the stack and heap?\n\nhttps://en.wikipedia.org/wiki/Memory_management\n\nhttps://en.wikipedia.org/wiki/Stack_register\n\nAssembly language resources:\n\nAssembly Programming Tutorial\n\nIntel® 64 and IA-32 Architectures Software Developer Manuals\n\nShare\nImprove this answer\nFollow\nedited Jul 5 '20 at 11:00\nanswered Jul 5 '20 at 10:50\nOlivier Rogier\n9,2894\n4 gold badges\n12\n12 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"Thank you for a really good discussion but as a real noob I wonder where instructions are kept? In the BEGINNING scientists were deciding between two architectures (von NEUMANN where everything is considered DATA and HARVARD where an area of memory was reserved for instructions and another for data). Ultimately, we went with the von Neumann design and now everything is considered 'the same'. This made it hard for me when I was learning assembly https://www.cs.virginia.edu/~evans/cs216/guides/x86.html because they talk about registers and stack pointers.\n\nEverything above talks about DATA. My guess is that since an instruction is a defined thing with a specific memory footprint, it would go on the stack and so all 'those' registers discussed in assembly are on the stack. Of course then came object oriented programming with instructions and data comingled into a structure that was dynamic so now instructions would be kept on the heap as well?\n\nShare\nImprove this answer\nFollow\nanswered Apr 9 '20 at 15:29\naquagremlin\n3,2172\n2 gold badges\n20\n20 silver badges\n42\n42 bronze badges","comments":["AFAIK, there still exist many CPUs with the Harvard architecture (typically optimized DSPs), which have separated memory (and bus) for instructions and data. (Some of them even more than 1 data memory). This is to optimize the cycle duration (Instruction fetch, data fetch and execute of previous instruction all in one machine cycle), thus take advantage from what they call pipe-lining. I am not aware, that instructions should by any means be placed in the stack. Anyway, I have a sneaky feeling this answer might go a bit beyond the scope of the original question..."]}]},{"id":"244777","href":"https://stackoverflow.com/questions/244777/can-comments-be-used-in-json","title":"Can comments be used in JSON?","description":"\n                \nCan I use comments inside a JSON file? If so, how?\n    ","questionComments":["@StingyJack: To explain things that may not be obvious, or whatever else one might do with comments. I for one often have comments in data files. XML, ini files, and many other formats include provisions for comments.","If you, like me, were wondering whether //comments are OK for the specific use-case of a Sublime Text configuration file, the answer is yes (as of version 2). Sublime Text will not complain about it, at least, whereas it will complain about {\"__comment\": ...} in the console, because it is an unexpected field.","and perhaps this is one reason why TOML was created..","Slightly noobish but ,i also tried using // for comments in JSON. Now I realize it is strictly used for interchange/exchange. Sigh! I cant comment any more :(. Life is doomed!.","JSON5 supports comments: stackoverflow.com/a/7901053/108238"],"answers":[{"answer":"No.\n\nThe JSON is data only, and if you include a comment, then it will be data too.\n\nYou could have a designated data element called \"_comment\" (or something) that should be ignored by apps that use the JSON data.\n\nYou would probably be better having the comment in the processes that generates/receives the JSON, as they are supposed to know what the JSON data will be in advance, or at least the structure of it.\n\nBut if you decided to:\n\n{\n   \"_comment\": \"comment text goes here...\",\n   \"glossary\": {\n      \"title\": \"example glossary\",\n      \"GlossDiv\": {\n         \"title\": \"S\",\n         \"GlossList\": {\n            \"GlossEntry\": {\n               \"ID\": \"SGML\",\n               \"SortAs\": \"SGML\",\n               \"GlossTerm\": \"Standard Generalized Markup Language\",\n               \"Acronym\": \"SGML\",\n               \"Abbrev\": \"ISO 8879:1986\",\n               \"GlossDef\": {\n                  \"para\": \"A meta-markup language, used to create markup languages such as DocBook.\",\n                  \"GlossSeeAlso\": [\"GML\", \"XML\"]\n               },\n               \"GlossSee\": \"markup\"\n            }\n         }\n      }\n   }\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 10 '20 at 17:48\nEnzoR\n2,6232\n2 gold badges\n16\n16 silver badges\n20\n20 bronze badges\nanswered Oct 28 '08 at 21:01\nEli\n90.2k20\n20 gold badges\n73\n73 silver badges\n81\n81 bronze badges","comments":["It might pay to have some kind of prefix on the actual comment in case there's ever a valid field named comment: \"__comment\":\"comment text goes here...\",","BTW, the json library for Java google-gson has support for comments.","What about if I wanted a separate comment on the Accronym and Abbrev properties? I've used this pattern before but stopped since it doesn't allow me to do that. It is a hack. Maybe if I prepend a property name with __comment__ instead. That is \"__comment__Abbrev\", still a hack, but would let me comment on all prpoerties","you could also use \"//\": this looks more native and is still repeatable in the same parent","When JSON is used for human-intended configuration files, they should be annotated for humans to understand better. Annotated, such file is no longer valid JSON, but there are solutions. For example, Google's GYP supports #-style comments. JSON.Minify will help you discard C/C++ style comments from your input file."]},{"answer":"No, comments of the form //… or /*…*/ are not allowed in JSON. This answer is based on:\n\nhttps://www.json.org\nRFC 4627: The application/json Media Type for JavaScript Object Notation (JSON)\nRFC 8259 The JavaScript Object Notation (JSON) Data Interchange Format (supercedes RFCs 4627, 7158, 7159)\nShare\nImprove this answer\nFollow\nedited Jun 29 '20 at 8:07\nFederico Navarrete\n2,3034\n4 gold badges\n34\n34 silver badges\n53\n53 bronze badges\nanswered Nov 15 '10 at 9:32\nstakx - no longer contributing\n77.9k17\n17 gold badges\n153\n153 silver badges\n252\n252 bronze badges","comments":["If you'd like to annotate your JSON with comments (thus making it invalid JSON), then minify it before parsing or transmitting. Crockford himself acknowledged this in 2012 in the context of configuration files.","@alkuzad: When it comes to formal grammars, there must be something that explicitly says that they are allowed, not the other way around. For instance, take your programming language of choice: Just because some desired (but missing) feature isn't explicitly disallowed, doesn't mean that your compiler will magically recognize it.","Yes. The JSON format has a lot of dead-space between elements and is space-insensitive in those regions, so there's no reason why you can't have single or multi-line comments there. Many parsers and minifiers support JSON comments as well, so just make sure your parser supports them. JSON is used a lot for application data and configuration settings, so comments are necessary now. The \"official spec\" is a nice idea, but it's insufficient and obsolete, so too bad. Minify your JSON if you're concerned about payload size or performance.","Although your answer is absolutely correct, it should be said that this is BS. With so many end users coming across the need for json configuration, then comments are exceedingly helpful. Just because some tin-foil hats decided that JSON is and must always be machine readable, ignoring the fact that humans needs to read it to, is imho a travesty of small mindedness.","@cmroanirgo: You're obviously not the first to complain about that limitation of JSON... that's why we have parsers that silently allow comments, and other formats such as YAML and JSON5. However this doesn't change the fact that JSON is what it is. Rather, I find it interesting that people started using JSON for purposes where it clearly wasn't sufficient in the first place, given the limitation in question. Don't blame the JSON format; blame ourselves for insisting on using it where it isn't a particularly good fit."]},{"answer":"Include comments if you choose; strip them out with a minifier before parsing or transmitting.\n\nI just released JSON.minify() which strips out comments and whitespace from a block of JSON and makes it valid JSON that can be parsed. So, you might use it like:\n\nJSON.parse(JSON.minify(my_str));\n\n\nWhen I released it, I got a huge backlash of people disagreeing with even the idea of it, so I decided that I'd write a comprehensive blog post on why comments make sense in JSON. It includes this notable comment from the creator of JSON:\n\nSuppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser. - Douglas Crockford, 2012\n\nHopefully that's helpful to those who disagree with why JSON.minify() could be useful.\n\nShare\nImprove this answer\nFollow\nedited Jan 20 '17 at 13:40\nanswered Jun 23 '10 at 18:20\nKyle Simpson\n14.1k2\n2 gold badges\n28\n28 silver badges\n47\n47 bronze badges","comments":["The only problem I have with JSON.minify() is that it is really really slow. So I made my own implementation that does the same thing: gist.github.com/1170297 . On some large test files your implementation takes 74 seconds and mine 0.06 seconds.","it'd be great if you could submit the suggested alternative algorithm to the github repo for JSON.minify(), so that it can be ported to all the supported langs: github.com/getify/json.minify","@MiniGod I have already heard Doug's thoughts on this topic many times. I addressed them long ago in my blog post: blog.getify.com/json-comments","@MarnenLaibow-Koser there are still valid uses for comments even for data stream (or even packet) usage: inclusion of diagnostics metadata like creation time or sources is common use with XML, and perfectly sensible for JSON data as well. Arguments against comments are shallow, and any textual data format should allow for comments, regardless of implied intended usage (nothing spec suggest JSON can not be used elsewhere, fwiw)","If JSON is to have universal acceptance (which it basically does) then it should have universal application. Example: JSON can serve as an application configuration file. This application would desire comments."]},{"answer":"Comments were removed from JSON by design.\n\nI removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability. I know that the lack of comments makes some people sad, but it shouldn't.\n\nSuppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.\n\nSource: Public statement by Douglas Crockford on G+\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jun 11 '12 at 8:52\nArtur Czajka\n16.8k2\n2 gold badges\n25\n25 silver badges\n29\n29 bronze badges","comments":["I thought JSON was to supposed to be more human readable than, say, XML? Comments are for readability.","Anyway, you could be naughty and add parsing directives in the JSON: {\"__directives\":{\"#n#\":\"DateTime.Now\"}, \"validdate\":\"#n#\"}... It looks like YAML is the way forward then...","Personal opinion: not allowing comments IS lame. I had no option other than building a non-standard JSON parser that ignores comments, to decode my config files.","\"I removed comments from JSON because I saw people were using them to hold parsing directive\". By that logic, he should also have removed the string type. Terrible decision.","That's like requiring all bicycles to have training wheels because some people can't ride bicycles. Removing an important feature because stupid people abuse it is bad design. A data format should prioritize usability over being idiot-proof."]},{"answer":"JSON does not support comments. It was also never intended to be used for configuration files where comments would be needed.\n\nHjson is a configuration file format for humans. Relaxed syntax, fewer mistakes, more comments.\n\nSee hjson.github.io for JavaScript, Java, Python, PHP, Rust, Go, Ruby, C++ and C# libraries.\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '20 at 7:40\nanswered Mar 20 '14 at 15:26\nlaktak\n49.2k15\n15 gold badges\n117\n117 silver badges\n151\n151 bronze badges","comments":["Upvoted. It's obviously a good variation un-open conservative people would just love to hate. I hope your implementation gets known further - and perhaps even gets more popular than the original ;) I hope someone gets to implement it with Ruby as well. @adelphus The language being well-defined is your own perspective or opinion. Being a conservative \"developer\" if you are one doesn't prove that you are better and you could be even worse keeping yourself locked up in limited spaces. Don't go judging people as terrible developers easily.","Sorry about that, @konsolebox. Perhaps you might reconsider your \"well-defined JSON is your opinion\" view after reading ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf It is a real standard and devs implementing their own \"special\" versions leads to fragmentation, confusion and a lot of wasted time. Look at the mess web developers are left with when writing code just because each browser implements slightly different versions of standards. The JSON language may not be perfect, but fragmentation is worse. And yes, that's just a opinion and you're free to disagree.","I admire your gumption, but you're kinda re-inventing YAML. If you want lot's of flexibility and human readability, use YAML (don't actually: stackoverflow.com/questions/450399/…) or stick with curmudgeony, yet unambiguous JSON.","I find the most user-friendly configuration format is still INI. It's straightforward and not very syntax heavy. This makes it less intimidating for users just dipping their toes in the configuration pond.","Whenever you need json as config (where comments are needed) - name your file \".js\" instead of \".json\".. js can of course handle any valid json object and additionally can handle comments.. That's the reason why it is \"webpack.config.js\" and not \"webpack.config.json\" (well there's a lot more reasons for that too in webpack :P)"]},{"answer":"DISCLAIMER: YOUR WARRANTY IS VOID\n\nAs has been pointed out, this hack takes advantage of the implementation of the spec. Not all JSON parsers will understand this sort of JSON. Streaming parsers in particular will choke.\n\nIt's an interesting curiosity, but you should really not be using it for anything at all. Below is the original answer.\n\nI've found a little hack that allows you to place comments in a JSON file that will not affect the parsing, or alter the data being represented in any way.\n\nIt appears that when declaring an object literal you can specify two values with the same key, and the last one takes precedence. Believe it or not, it turns out that JSON parsers work the same way. So we can use this to create comments in the source JSON that will not be present in a parsed object representation.\n\n({a: 1, a: 2});\n// => Object {a: 2}\nObject.keys(JSON.parse('{\"a\": 1, \"a\": 2}')).length; \n// => 1\n\n\nIf we apply this technique, your commented JSON file might look like this:\n\n{\n  \"api_host\" : \"The hostname of your API server. You may also specify the port.\",\n  \"api_host\" : \"hodorhodor.com\",\n\n  \"retry_interval\" : \"The interval in seconds between retrying failed API calls\",\n  \"retry_interval\" : 10,\n\n  \"auth_token\" : \"The authentication token. It is available in your developer dashboard under 'Settings'\",\n  \"auth_token\" : \"5ad0eb93697215bc0d48a7b69aa6fb8b\",\n\n  \"favorite_numbers\": \"An array containing my all-time favorite numbers\",\n  \"favorite_numbers\": [19, 13, 53]\n}\n\n\nThe above code is valid JSON. If you parse it, you'll get an object like this:\n\n{\n    \"api_host\": \"hodorhodor.com\",\n    \"retry_interval\": 10,\n    \"auth_token\": \"5ad0eb93697215bc0d48a7b69aa6fb8b\",\n    \"favorite_numbers\": [19,13,53]\n}\n\n\nWhich means there is no trace of the comments, and they won't have weird side-effects.\n\nHappy hacking!\n\nShare\nImprove this answer\nFollow\nedited Jan 15 '16 at 5:58\nthanksd\n46k20\n20 gold badges\n134\n134 silver badges\n133\n133 bronze badges\nanswered Aug 2 '13 at 13:46\np3drosola\n5,5382\n2 gold badges\n20\n20 silver badges\n30\n30 bronze badges","comments":["From the specification: The names within an object SHOULD be unique.","\"all the implementations handle it the same\" — That's a difficult thing to prove.","The order of elements in JSON is not guaranteed. That means the \"last\" item could change!","This clearly violates the spec (see above comments), don't do this. ietf.org/rfc/rfc4627.txt?number=4627","NO - what if the parser is streaming? What if the parser reads it into a dictionary where key ordering is undefined? kill this with fire."]},{"answer":"Consider using YAML. It's nearly a superset of JSON (virtually all valid JSON is valid YAML) and it allows comments.\n\nShare\nImprove this answer\nFollow\nanswered Aug 31 '11 at 2:24\nMarnen Laibow-Koser\n5,2681\n1 gold badge\n24\n24 silver badges\n30\n30 bronze badges","comments":["@g33kz0r Correct, hence my description of YAML as a near-superset of JSON.","@NateS Many people had already pointed out that the answer was no. I suggested a better way to achieve the OP's goal. That's an answer.","Downside: yaml library isn't shipped with Python.","@marnen-laibow-koser: yup, it must have been incompetence to use the available YAML libraries for Java and Perl and expect the YAML produced by each to be consumed by the other without error. That YAML interop was an issue, but JSON interop wasn't, is entirely explained by my lack of knowledge.","@marnen-laibow-koser, a format that accomplishes the same thing with a simpler spec is better. A pragmatic format with perfect implementations is better than an ideal format with imperfect implementations. Not all the blame for faulty libs lies on the implementors' shoulders; the YAML spec is long, dense, and obtuse. Its Wikipedia entry cites two examples of ambiguities; if one must put an emitter between a human and the format to protect them from ambiguities, the format loses its human friendly claim. JSON claims less and mostly succeeds where YAML claims more and falls short."]},{"answer":"You can't. At least that's my experience from a quick glance at json.org.\n\nJSON has its syntax visualized on that page. There isn't any note about comments.\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '17 at 17:20\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 28 '08 at 20:42\nCheery\n22k13\n13 gold badges\n55\n55 silver badges\n80\n80 bronze badges","comments":[]},{"answer":"Comments are not an official standard, although some parsers support C++-style comments. One that I use is JsonCpp. In the examples there is this one:\n\n// Configuration options\n{\n    // Default encoding for text\n    \"encoding\" : \"UTF-8\",\n\n    // Plug-ins loaded at start-up\n    \"plug-ins\" : [\n        \"python\",\n        \"c++\",\n        \"ruby\"\n        ],\n\n    // Tab indent size\n    \"indent\" : { \"length\" : 3, \"use_space\": true }\n}\n\n\njsonlint does not validate this. So comments are a parser specific extension and not standard.\n\nAnother parser is JSON5.\n\nAn alternative to JSON TOML.\n\nA further alternative is jsonc.\n\nThe latest version of nlohmann/json has optional support for ignoring comments on parsing.\n\nShare\nImprove this answer\nFollow\nedited Aug 1 '20 at 20:09\nt-b\n731\n1 silver badge\n6\n6 bronze badges\nanswered Oct 26 '11 at 9:46\nschoetbi\n10.1k8\n8 gold badges\n45\n45 silver badges\n70\n70 bronze badges","comments":["Groovy has some built-in classes for handling JSON. JsonSlurper can handle comments. Of course, comments are not allowed in the official spec, so this behavior in any parser is non-standard and non-portable.","Newtonsoft Json.NET also support C-style comments with no problems"]},{"answer":"You should write a JSON schema instead. JSON schema is currently a proposed Internet draft specification. Besides documentation, the schema can also be used for validating your JSON data.\n\nExample:\n\n{\n    \"description\":\"A person\",\n    \"type\":\"object\",\n    \"properties\":\n        {\n            \"name\":\n                {\n                    \"type\":\"string\"\n                },\n            \"age\":\n                {\n                    \"type\":\"integer\",\n                    \"maximum\":125\n                }\n        }\n}\n\n\nYou can provide documentation by using the description schema attribute.\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '17 at 17:37\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 28 '10 at 18:38\nraffel\n1,1919\n9 silver badges\n8\n8 bronze badges","comments":["Is JSON schema alive? It exists but is it supported by any known library?","yes, the json-schema google group is fairly active and I would recommend JSV for a good JavaScript implementation of a JSON Schema validator.","This only helps with structured documentation, not ad-hoc documentation","If you use clojure (and I'm sure you don't) there's a reasonably featured open-source JSON schema parser here: github.com/bigmlcom/closchema","@Munhitsu Manatee.Json (.Net) extensively supports JSON schema."]},{"answer":"If you are using Jackson as your JSON parser then this is how you enable it to allow comments:\n\nObjectMapper mapper = new ObjectMapper().configure(Feature.ALLOW_COMMENTS, true);\n\n\nThen you can have comments like this:\n\n{\n  key: \"value\" // Comment\n}\n\n\nAnd you can also have comments starting with # by setting:\n\nmapper.configure(Feature.ALLOW_YAML_COMMENTS, true);\n\n\nBut in general (as answered before) the specification does not allow comments.\n\nShare\nImprove this answer\nFollow\nedited Oct 14 '18 at 17:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 6 '14 at 20:44\nAndrejs\n24.4k10\n10 gold badges\n98\n98 silver badges\n92\n92 bronze badges","comments":["is this reversible ? what if you load the file and write it back ?"]},{"answer":"Here is what I found in the Google Firebase documentation that allows you to put comments in JSON:\n\n{\n  \"//\": \"Some browsers will use this to enable push notifications.\",\n  \"//\": \"It is the same for all projects, this is not your project's sender ID\",\n  \"gcm_sender_id\": \"1234567890\"\n}\n\nShare\nImprove this answer\nFollow\nedited May 5 at 4:09\nnp_6\n5126\n6 silver badges\n17\n17 bronze badges\nanswered Jun 22 '17 at 12:58\nmana\n5,6915\n5 gold badges\n45\n45 silver badges\n66\n66 bronze badges","comments":["FYI, Firebase Realtime Database does not allow the use of '/' in a key. so this can be a nice convention for your own use, but you cannot do it in Firebase","This method breaks some libraries, which require that the key must be unique. I'm working around that issue by numbering the comments.","good comment, I found this question on SO ... this part seems not to be covered by the spec stackoverflow.com/questions/21832701/…","I tend to use it like this nowadays: { \"//foo\": \"foo comment\", \"foo\": \"foo value\", \"//bar\": \"bar comment\", \"bar\": \"bar value\" } You can use an array for multiple comments: { \"//foo\": [ \"foo comment 1\", \"foo comment 2\" ], \"foo\": ''foo value\" }"]},{"answer":"NO. JSON used to support comments, but they were abused and removed from the standard.\n\nFrom the creator of JSON:\n\nI removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability. I know that the lack of comments makes some people sad, but it shouldn't. - Douglas Crockford, 2012\n\nThe official JSON site is at JSON.org. JSON is defined as a standard by ECMA International. There is always a petition process to have standards revised. It is unlikely that annotations will be added to the JSON standard for several reasons.\n\nJSON by design is an easily reverse-engineered (human parsed) alternative to XML. It is simplified even to the point that annotations are unnecessary. It is not even a markup language. The goal is stability and interoperablilty.\n\nAnyone who understands the \"has-a\" relationship of object orientation can understand any JSON structure - that is the whole point. It is just a directed acyclic graph (DAG) with node tags (key/value pairs), which is a near universal data structure.\n\nThis only annotation required might be \"//These are DAG tags\". The key names can be as informative as required, allowing arbitrary semantic arity.\n\nAny platform can parse JSON with just a few lines of code. XML requires complex OO libraries that are not viable on many platforms.\n\nAnnotations would just make JSON make less interoperable. There is simply nothing else to add, unless what you really need is a markup language (XML), and don't care if your persisted data is easily parsed.\n\nBUT as the creator of JSON also observed, there has always been JS pipeline support for comments:\n\nGo ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser. - Douglas Crockford, 2012\n\nShare\nImprove this answer\nFollow\nedited Feb 23 '20 at 1:52\nanswered Nov 27 '15 at 19:35\nDominic Cerisano\n2,85925\n25 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"If your text file, which is a JSON string, is going to be read by some program, how difficult would it be to strip out either C or C++ style comments before using it?\n\nAnswer: It would be a one liner. If you do that then JSON files could be used as configuration files.\n\nShare\nImprove this answer\nFollow\nedited Aug 29 '15 at 17:51\nRandika Vishman\n7,2553\n3 gold badges\n56\n56 silver badges\n76\n76 bronze badges\nanswered Apr 9 '10 at 22:30\nJohn T. Vonachen\n5414\n4 silver badges\n2\n2 bronze badges","comments":["Probably the best suggestion so far, though still an issue for keeping files as an interchange format, as they need pre-processing before use.","I agree and have written a JSON parser in Java, available at www.SoftwareMonkey.org, that does exactly that.","Despite I think, it is not a good idea to extend JSON (without calling it a different exchange format): make sure to ignore \"comments\" within strings. { \"foo\": \"/* This is not a comment.*/\" }","\"...would be a one liner\" umm, no, actually, JSON is not a regular grammar where a regular expression can simply find matching pairs of /*. You have to parse the file to find if a /* appears inside a string (and ignore it), or if it's escaped (and ignore it), etc. Also, your answer is unhelpful because you simply speculate (incorrectly) rather than providing any solution.","What @kyle-simpson said. Also, he's too modest to direct readers to his own answer about using JSON.minify as an alternative to ad hoc regexps. Do that, not this."]},{"answer":"If you are using the Newtonsoft.Json library with ASP.NET to read/deserialize you can use comments in the JSON content:\n\n//\"name\": \"string\"\n\n//\"id\": int\n\nor\n\n/* This is a\n\ncomment example */\n\nPS: Single-line comments are only supported with 6+ versions of Newtonsoft Json.\n\nAdditional note for people who can't think out of the box: I use the JSON format for basic settings in an ASP.NET web application I made. I read the file, convert it into the settings object with the Newtonsoft library and use it when necessary.\n\nI prefer writing comments about each individual setting in the JSON file itself, and I really don't care about the integrity of the JSON format as long as the library I use is OK with it.\n\nI think this is an 'easier to use/understand' way than creating a separate 'settings.README' file and explaining the settings in it.\n\nIf you have a problem with this kind of usage; sorry, the genie is out of the lamp. People would find other usages for JSON format, and there is nothing you can do about it.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jul 25 '14 at 13:43\ndvdmn\n5,7596\n6 gold badges\n39\n39 silver badges\n51\n51 bronze badges","comments":["It is hard to understand why someone would have problem with stating a fact.","I would assume someone took exception because the above is no longer JSON, or is invalid JSON. Perhaps adding a short disclaimer would appease.","I completely agree with you, and yet there are 883 upvotes so far for the non-answer that just states the obvious. Ideological purity valued above helpful information, that's SO for you.","The point is a file with comments is not JSON and will fail to be parsed by many JSON libraries. Feel free to do whatever you want in your own program but a file with comments is not JSON. If you claim it is then people will try to parse it with their language/library of choice and it will fail. It's like asking if you can use square brackets instead of angle brackets in XML. You can do whatever you want but it will no longer be XML."]},{"answer":"The idea behind JSON is to provide simple data exchange between applications. These are typically web based and the language is JavaScript.\n\nIt doesn't really allow for comments as such, however, passing a comment as one of the name/value pairs in the data would certainly work, although that data would obviously need to be ignored or handled specifically by the parsing code.\n\nAll that said, it's not the intention that the JSON file should contain comments in the traditional sense. It should just be the data.\n\nHave a look at the JSON website for more detail.\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '17 at 17:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 28 '08 at 23:05\nNeil Albrock\n9759\n9 silver badges\n16\n16 bronze badges","comments":["It is true that JSON format does not have comments. Personally I think that is a significant mistake -- ability to have comments as metadata (not data) is a very useful thing with xml. Earlier draft versions of JSON specification did include comments, but for some reason they were dropped. :-/","@StaxMan they were dropped exactly because people started using them as metadata. Crockford said it breaked the compatibility for what the format was designed, and I agree: if you want metadata, why not include it as actual data? It's even easier to parse this way.","Metadata belongs in metadata constructs (e.g. HTML <meta> tags), not comments. Abusing comments for metadata is just a hack used where no true metadata construct exists.","That's exactly the reason why it was dropped: comments used as metadata would break interoperability. You should just store your meta-data as JSON too.","This answer is redundant with better written, higher upvoted answers, that say essentially the same thing, even though this may have been written earlier. Cest la vie."]},{"answer":"JSON does not support comments natively, but you can make your own decoder or at least preprocessor to strip out comments, that's perfectly fine (as long as you just ignore comments and don't use them to guide how your application should process the JSON data).\n\nJSON does not have comments. A JSON encoder MUST NOT output comments. A JSON decoder MAY accept and ignore comments.\n\nComments should never be used to transmit anything meaningful. That is what JSON is for.\n\nCf: Douglas Crockford, author of JSON spec.\n\nShare\nImprove this answer\nFollow\nanswered Jun 25 '13 at 14:48\ngaborous\n13k8\n8 gold badges\n75\n75 silver badges\n94\n94 bronze badges","comments":["Crockford later went on to write: \"Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.\" See @kyle-simpson's answer about JSON.minify for more info."]},{"answer":"I just encountering this for configuration files. I don't want to use XML (verbose, graphically, ugly, hard to read), or \"ini\" format (no hierarchy, no real standard, etc.) or Java \"Properties\" format (like .ini).\n\nJSON can do all they can do, but it is way less verbose and more human readable - and parsers are easy and ubiquitous in many languages. It's just a tree of data. But out-of-band comments are a necessity often to document \"default\" configurations and the like. Configurations are never to be \"full documents\", but trees of saved data that can be human readable when needed.\n\nI guess one could use \"#\": \"comment\", for \"valid\" JSON.\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '17 at 17:42\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 22 '11 at 13:09\npeterk\n4,5565\n5 gold badges\n28\n28 silver badges\n38\n38 bronze badges","comments":["For config files, I'd suggest YAML, not JSON. It's (almost) a more powerful superset of JSON, but supports more readable constructs as well, including comments.","how many languages do you think supports YAML out of the box compared to json ?","@Hamidam Over a dozen languages support yaml: yaml.org - but you're right to ask how many have support built-in, without the need for a third-party library dependency. Looks like Ruby 1.9.2 does. Anyone know of others? And which languages ship support for json by default?","YAML interop is a lie: stackoverflow.com/questions/450399/… . If your instinct is to use JSON for configuration files, follow it.","This is old, but I believe that using # is not a good idea. Json is close to the syntax of a Javascript litteral. Javascript supports 2 types of comment : // and /* ... */ If I were you I would stick with one or both these types of comments."]},{"answer":"It depends on your JSON library. Json.NET supports JavaScript-style comments, /* commment */.\n\nSee another Stack Overflow question.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 10:31\nCommunity♦\n11\n1 silver badge\nanswered Aug 4 '12 at 0:56\nAZ.\n6,7736\n6 gold badges\n39\n39 silver badges\n61\n61 bronze badges","comments":["And I believe that is why I see a comment in a screenshot on this ASP.NET vNext preview page (under package.json): blogs.msdn.com/b/webdev/archive/2014/06/03/… although I haven't found anything in the spec yet."]},{"answer":"JSON makes a lot of sense for config files and other local usage because it's ubiquitous and because it's much simpler than XML.\n\nIf people have strong reasons against having comments in JSON when communicating data (whether valid or not), then possibly JSON could be split into two:\n\nJSON-COM: JSON on the wire, or rules that apply when communicating JSON data.\nJSON-DOC: JSON document, or JSON in files or locally. Rules that define a valid JSON document.\n\nJSON-DOC will allow comments, and other minor differences might exist such as handling whitespace. Parsers can easily convert from one spec to the other.\n\nWith regards to the remark made by Douglas Crockford on this issues (referenced by @Artur Czajka)\n\nSuppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.\n\nWe're talking about a generic config file issue (cross language/platform), and he's answering with a JS specific utility!\n\nSure a JSON specific minify can be implemented in any language, but standardize this so it becomes ubiquitous across parsers in all languages and platforms so people stop wasting their time lacking the feature because they have good use-cases for it, looking the issue up in online forums, and getting people telling them it's a bad idea or suggesting it's easy to implement stripping comments out of text files.\n\nThe other issue is interoperability. Suppose you have a library or API or any kind of subsystem which has some config or data files associated with it. And this subsystem is to be accessed from different languages. Then do you go about telling people: by the way don't forget to strip out the comments from the JSON files before passing them to the parser!\n\nShare\nImprove this answer\nFollow\nedited Jan 25 '13 at 14:45\nanswered Dec 11 '12 at 1:37\nBasel Shishani\n6,7755\n5 gold badges\n44\n44 silver badges\n62\n62 bronze badges","comments":["No need to fragment JSON. JSON with comments is no longer JSON. But it's perfectly acceptable to annotate your JSON with comments, so long as you make sure to strip them out before parsing or transmitting it. It should never be the receiver's responsibility to do this."]},{"answer":"If you use JSON5 you can include comments.\n\nJSON5 is a proposed extension to JSON that aims to make it easier for humans to write and maintain by hand. It does this by adding some minimal syntax features directly from ECMAScript 5.\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '17 at 18:32\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 24 '15 at 4:34\nSmit Johnth\n1,4271\n1 gold badge\n17\n17 silver badges\n14\n14 bronze badges","comments":["Could you please add an example? Then you may actually need those extra characters.","It's required by the SO guidelines to provide an actual answer. Link-only answers are not desired. You can check the guidelines stackoverflow.com/help/how-to-answer","SO is moderated by its users. That means I can provide an answer if I have it the same way I can comment yours if it doesn't follow guidelines. That's how SO gets to be a great resource."]},{"answer":"The Dojo Toolkit JavaScript toolkit (at least as of version 1.4), allows you to include comments in your JSON. The comments can be of /* */ format. Dojo Toolkit consumes the JSON via the dojo.xhrGet() call.\n\nOther JavaScript toolkits may work similarly.\n\nThis can be helpful when experimenting with alternate data structures (or even data lists) before choosing a final option.\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '17 at 17:39\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 18 '11 at 21:57\nDavid\n1,9222\n2 gold badges\n24\n24 silver badges\n39\n39 bronze badges","comments":["No. Not this. JSON doesn't have comments. If you choose to annotate your JSON with comments, minify it before parsing or transmitting. This shouldn't be the receiver's responsibility.","I didn't say that JSON has comments. Neither did I mean to imply that it's appropriate to include them in your JSON, especially in a production system. I said that the Dojo toolkit permits you to add them, which is (or at least, was) factually true. There are very helpful use-cases out there for doing so in your testing phase.","It's bad voodoo to serve up commented, and thus invalid JSON, which dojo.xhrGet() implicitly encourages by accepting.","I still vote for upgrading the JSON spec to allow comments. I'm all for minifying and stripping the comments before transmitting the JSON, but not having any ability to comment your JSON in any standard way without having to pass it through a separate utility before parsing it just seems silly. I also makes it impossible to use a JSON editor on your JSON configuration files, because your files are not valid JSON."]},{"answer":"JSON is not a framed protocol. It is a language free format. So a comment's format is not defined for JSON.\n\nAs many people have suggested, there are some tricks, for example, duplicate keys or a specific key _comment that you can use. It's up to you.\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '17 at 18:24\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 20 '15 at 9:26\nManish Shrivastava\n26.6k13\n13 gold badges\n89\n89 silver badges\n101\n101 bronze badges","comments":[]},{"answer":"You can have comments in JSONP, but not in pure JSON. I've just spent an hour trying to make my program work with this example from Highcharts: http://www.highcharts.com/samples/data/jsonp.php?filename=aapl-c.json&callback=?\n\nIf you follow the link, you will see\n\n?(/* AAPL historical OHLC data from the Google Finance API */\n[\n/* May 2006 */\n[1147651200000,67.79],\n[1147737600000,64.98],\n...\n[1368057600000,456.77],\n[1368144000000,452.97]\n]);\n\n\nSince I had a similar file in my local folder, there were no issues with the Same-origin policy, so I decided to use pure JSON... and, of course, $.getJSON was failing silently because of the comments.\n\nEventually I just sent a manual HTTP request to the address above and realized that the content-type was text/javascript since, well, JSONP returns pure JavaScript. In this case comments are allowed. But my application returned content-type application/json, so I had to remove the comments.\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '17 at 18:00\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 7 '13 at 20:37\nSergey Orshanskiy\n6,2161\n1 gold badge\n43\n43 silver badges\n48\n48 bronze badges","comments":[]},{"answer":"Disclaimer: This is silly\n\nThere is actually a way to add comments, and stay within the specification (no additional parser needed). It will not result into human-readable comments without any sort of parsing though.\n\nYou could abuse the following:\n\nInsignificant whitespace is allowed before or after any token. Whitespace is any sequence of one or more of the following code points: character tabulation (U+0009), line feed (U+000A), carriage return (U+000D), and space (U+0020).\n\nIn a hacky way, you can abuse this to add a comment. For instance: start and end your comment with a tab. Encode the comment in base3 and use the other whitespace characters to represent them. For instance.\n\n010212 010202 011000 011000 011010 001012 010122 010121 011021 010202 001012 011022 010212 011020 010202 010202\n\n\n(hello base three in ASCII) But instead of 0 use space, for 1 use line feed and for 2 use carriage return.\n\nThis will just leave you with a lot of unreadable whitespace (unless you make an IDE plugin to encode/decode it on the fly).\n\nI never even tried this, for obvious reasons and neither should you.\n\nShare\nImprove this answer\nFollow\nedited Oct 8 '20 at 16:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 17 '19 at 7:18\nRoy Prins\n2,2701\n1 gold badge\n22\n22 silver badges\n38\n38 bronze badges","comments":["This is pretty funny."]},{"answer":"Yes, the new standard, JSON5 allows the C++ style comments, among many other extensions:\n\n// A single line comment.\n\n/* A multi-\n   line comment. */\n\n\nThe JSON5 Data Interchange Format (JSON5) is a superset of JSON that aims to alleviate some of the limitations of JSON. It is fully backwards compatible, and using it is probably better than writing the custom non standard parser, turning non standard features on for the existing one or using various hacks like string fields for commenting. Or, if the parser in use supports, simply agree we are using JSON 5 subset that is JSON and C++ style comments. It is much better than we tweak JSON standard the way we see fit.\n\nThere is already npm package, Python package, Java package and C library available. It is backwards compatible. I see no reason to stay with the \"official\" JSON restrictions.\n\nI think that removing comments from JSON has been driven by the same reasons as removing the operator overloading in Java: can be used the wrong way yet some clearly legitimate use cases were overlooked. For operator overloading, it is matrix algebra and complex numbers. For JSON comments, its is configuration files and other documents that may be written, edited or read by humans and not just by parser.\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '20 at 17:57\nanswered Nov 19 '20 at 7:35\nAudrius Meskauskas\n18.8k10\n10 gold badges\n65\n65 silver badges\n80\n80 bronze badges","comments":["Is JSON5 \"very\" standard? Or still being adopted? I mean... May I expect that any framework in 2021 will understand Json5? Or most probably not?","If you create your own standard, you are the only in the world using it. Something like JSON5 is probably better.","Not meant to create my standard... just wondering if it's time to consider JSON5 or better stick to \"old JSON\" and wait a few months yet before devoting time to exploration.","JSON5 is not \"the new standard\" - It's a separate standard developed by separate people."]},{"answer":"This is a \"can you\" question. And here is a \"yes\" answer.\n\nNo, you shouldn't use duplicative object members to stuff side channel data into a JSON encoding. (See \"The names within an object SHOULD be unique\" in the RFC).\n\nAnd yes, you could insert comments around the JSON, which you could parse out.\n\nBut if you want a way of inserting and extracting arbitrary side-channel data to a valid JSON, here is an answer. We take advantage of the non-unique representation of data in a JSON encoding. This is allowed* in section two of the RFC under \"whitespace is allowed before or after any of the six structural characters\".\n\n*The RFC only states \"whitespace is allowed before or after any of the six structural characters\", not explicitly mentioning strings, numbers, \"false\", \"true\", and \"null\". This omission is ignored in ALL implementations.\n\nFirst, canonicalize your JSON by minifying it:\n\n$jsonMin = json_encode(json_decode($json));\n\n\nThen encode your comment in binary:\n\n$hex = unpack('H*', $comment);\n$commentBinary = base_convert($hex[1], 16, 2);\n\n\nThen steg your binary:\n\n$steg = str_replace('0', ' ', $commentBinary);\n$steg = str_replace('1', \"\\t\", $steg);\n\n\nHere is your output:\n\n$jsonWithComment = $steg . $jsonMin;\n\nShare\nImprove this answer\nFollow\nedited Dec 15 '15 at 5:53\nanswered Apr 24 '14 at 17:23\nWilliam Entriken\n31.4k17\n17 gold badges\n129\n129 silver badges\n175\n175 bronze badges","comments":["The RFC only states \"whitespace is allowed before or after any of the six structural characters\", not explicitly mentioning strings, numbers, \"false\", \"true\", \"null\". This omission is ignored in ALL implementations.","For greater comment density, couldn't you encode your comment in ternary and use space, tab, and newline to steg it?","SHOULD is not MUST. See the explicitly included RFC 2119: MUST: This word, or the terms \"REQUIRED\" or \"SHALL\", mean that the definition is an absolute requirement of the specification. ... SHOULD: This word, or the adjective \"RECOMMENDED\", mean that there may exist valid reasons in particular circumstances to ignore a particular item, but the full implications must be understood and carefully weighed before choosing a different course.","Good reference. A better reasoning against using duplicated keys is the standard's quote \"When the names within an object are not unique, the behavior of software that receives such an object is unpredictable.\". Also now I understand why the standard was not \"MUST be unique,\" this makes a validator simpler, it only needs to track [ and {, it does not need to know which keys were used already."]},{"answer":"JSON doesn't allow comments, per se. The reasoning is utterly foolish, because you can use JSON itself to create comments, which obviates the reasoning entirely, and loads the parser data space for no good reason at all for exactly the same result and potential issues, such as they are: a JSON file with comments.\n\nIf you try to put comments in (using // or /* */ or # for instance), then some parsers will fail because this is strictly not within the JSON specification. So you should never do that.\n\nHere, for instance, where my image manipulation system has saved image notations and some basic formatted (comment) information relating to them (at the bottom):\n\n{\n    \"Notations\": [\n        {\n            \"anchorX\": 333,\n            \"anchorY\": 265,\n            \"areaMode\": \"Ellipse\",\n            \"extentX\": 356,\n            \"extentY\": 294,\n            \"opacity\": 0.5,\n            \"text\": \"Elliptical area on top\",\n            \"textX\": 333,\n            \"textY\": 265,\n            \"title\": \"Notation 1\"\n        },\n        {\n            \"anchorX\": 87,\n            \"anchorY\": 385,\n            \"areaMode\": \"Rectangle\",\n            \"extentX\": 109,\n            \"extentY\": 412,\n            \"opacity\": 0.5,\n            \"text\": \"Rect area\\non bottom\",\n            \"textX\": 98,\n            \"textY\": 385,\n            \"title\": \"Notation 2\"\n        },\n        {\n            \"anchorX\": 69,\n            \"anchorY\": 104,\n            \"areaMode\": \"Polygon\",\n            \"extentX\": 102,\n            \"extentY\": 136,\n            \"opacity\": 0.5,\n            \"pointList\": [\n                {\n                    \"i\": 0,\n                    \"x\": 83,\n                    \"y\": 104\n                },\n                {\n                    \"i\": 1,\n                    \"x\": 69,\n                    \"y\": 136\n                },\n                {\n                    \"i\": 2,\n                    \"x\": 102,\n                    \"y\": 132\n                },\n                {\n                    \"i\": 3,\n                    \"x\": 83,\n                    \"y\": 104\n                }\n            ],\n            \"text\": \"Simple polygon\",\n            \"textX\": 85,\n            \"textY\": 104,\n            \"title\": \"Notation 3\"\n        }\n    ],\n    \"imageXW\": 512,\n    \"imageYW\": 512,\n    \"imageName\": \"lena_std.ato\",\n    \"tinyDocs\": {\n        \"c01\": \"JSON image notation data:\",\n        \"c02\": \"-------------------------\",\n        \"c03\": \"\",\n        \"c04\": \"This data contains image notations and related area\",\n        \"c05\": \"selection information that provides a means for an\",\n        \"c06\": \"image gallery to display notations with elliptical,\",\n        \"c07\": \"rectangular, polygonal or freehand area indications\",\n        \"c08\": \"over an image displayed to a gallery visitor.\",\n        \"c09\": \"\",\n        \"c10\": \"X and Y positions are all in image space. The image\",\n        \"c11\": \"resolution is given as imageXW and imageYW, which\",\n        \"c12\": \"you use to scale the notation areas to their proper\",\n        \"c13\": \"locations and sizes for your display of the image,\",\n        \"c14\": \"regardless of scale.\",\n        \"c15\": \"\",\n        \"c16\": \"For Ellipses, anchor is the  center of the ellipse,\",\n        \"c17\": \"and the extents are the X and Y radii respectively.\",\n        \"c18\": \"\",\n        \"c19\": \"For Rectangles, the anchor is the top left and the\",\n        \"c20\": \"extents are the bottom right.\",\n        \"c21\": \"\",\n        \"c22\": \"For Freehand and Polygon area modes, the pointList\",\n        \"c23\": \"contains a series of numbered XY points. If the area\",\n        \"c24\": \"is closed, the last point will be the same as the\",\n        \"c25\": \"first, so all you have to be concerned with is drawing\",\n        \"c26\": \"lines between the points in the list. Anchor and extent\",\n        \"c27\": \"are set to the top left and bottom right of the indicated\",\n        \"c28\": \"region, and can be used as a simplistic rectangular\",\n        \"c29\": \"detect for the mouse hover position over these types\",\n        \"c30\": \"of areas.\",\n        \"c31\": \"\",\n        \"c32\": \"The textx and texty positions provide basic positioning\",\n        \"c33\": \"information to help you locate the text information\",\n        \"c34\": \"in a reasonable location associated with the area\",\n        \"c35\": \"indication.\",\n        \"c36\": \"\",\n        \"c37\": \"Opacity is a value between 0 and 1, where .5 represents\",\n        \"c38\": \"a 50% opaque backdrop and 1.0 represents a fully opaque\",\n        \"c39\": \"backdrop. Recommendation is that regions be drawn\",\n        \"c40\": \"only if the user hovers the pointer over the image,\",\n        \"c41\": \"and that the text associated with the regions be drawn\",\n        \"c42\": \"only if the user hovers the pointer over the indicated\",\n        \"c43\": \"region.\"\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Oct 8 '20 at 16:56\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 19 '18 at 14:04\nfyngyrz\n1,9482\n2 gold badges\n28\n28 silver badges\n39\n39 bronze badges","comments":["The \"reasoning\" link is broken. Any chance of finding a current link to it?","Don, unfortunately, Google has killed the social media system that contained the post; I have no idea where the original poster went from there, if anywhere. I'll kill the link in the above info, though, so as to remove the ambiguity. Thanks.","The reasoning is not foolish, and you just proved it. Implementing comments as tags preserves interoperability. This is exactly why Crockford wanted comments to be parsed as tags. Now everything is just a tag and parsed the same way.","If the spec stated that \"a line beginning with # is a comment\", then that would be fully interoperable. As it stands, comments both load the parser space, as they are valid parsed items rather than understood to be comments, and they can be different for every .json file in existence. Whereas if (for instance) the spec said \"lines beginning with # are comments\", then the parsers could skip those lines without parsing (faster) and not load the parser space (better memory utilization.) There's no benefit at all from the lack of comments in .json, only downsides."]},{"answer":"In my case, I need to use comments for debug purposes just before the output of the JSON. So I put the debug information in the HTTP header, to avoid breaking the client:\n\nheader(\"My-Json-Comment: Yes, I know it's a workaround ;-) \");\n\n\nShare\nImprove this answer\nFollow\nedited Feb 8 at 12:53\nanswered Aug 26 '16 at 17:31\nWilliamK\n1,44113\n13 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"We are using strip-json-comments for our project. It supports something like:\n\n/*\n * Description \n*/\n{\n    // rainbows\n    \"unicorn\": /* ❤ */ \"cake\"\n}\n\n\nSimply npm install --save strip-json-comments to install and use it like:\n\nvar strip_json_comments = require('strip-json-comments')\nvar json = '{/*rainbows*/\"unicorn\":\"cake\"}';\nJSON.parse(strip_json_comments(json));\n//=> {unicorn: 'cake'}\n\nShare\nImprove this answer\nFollow\nanswered Nov 27 '14 at 11:39\nJoy\n8,8997\n7 gold badges\n39\n39 silver badges\n85\n85 bronze badges","comments":["Note that the json is not a valid JSON anymore when it includes these propriety comments.","In which context does strip-json-comments run? Node.js?","@PeterMortensen i tried for node.js. you can try whether works on client-side js."]}]},{"id":"8318911","href":"https://stackoverflow.com/questions/8318911/why-does-html-think-chucknorris-is-a-color","title":"Why does HTML think “chucknorris” is a color?","description":"\n                \nWhy do certain random strings produce colors when entered as background colors in HTML?\nFor example:\n\n\n<body bgcolor=\"chucknorris\"> test </body>\n Run code snippetHide resultsExpand snippet\n\n\n...produces a document with a red background across all browsers and platforms.\nOn the other hand, chucknorr produces a yellow background!\nWhat’s going on here?\n    ","questionComments":["As a side note: don't use bgcolor. Use CSS background.","and <body bgcolor=\"stevensegal\"> test </body> is green","@pyb: This thing is already a Chuck Norris joke by itself, don't you think?"],"answers":[{"answer":"It’s a holdover from the Netscape days:\n\nMissing digits are treated as 0[...]. An incorrect digit is simply interpreted as 0. For example the values #F0F0F0, F0F0F0, F0F0F, #FxFxFx and FxFxFx are all the same.\n\nIt is from the blog post A little rant about Microsoft Internet Explorer's color parsing which covers it in great detail, including varying lengths of color values, etc.\n\nIf we apply the rules in turn from the blog post, we get the following:\n\nReplace all nonvalid hexadecimal characters with 0’s:\n\nchucknorris becomes c00c0000000\n\n\nPad out to the next total number of characters divisible by 3 (11 → 12):\n\nc00c 0000 0000\n\n\nSplit into three equal groups, with each component representing the corresponding colour component of an RGB colour:\n\nRGB (c00c, 0000, 0000)\n\n\nTruncate each of the arguments from the right down to two characters.\n\nWhich, finally, gives the following result:\n\nRGB (c0, 00, 00) = #C00000 or RGB(192, 0, 0)\n\n\nHere’s an example demonstrating the bgcolor attribute in action, to produce this “amazing” colour swatch:\n\n<table>\n  <tr>\n    <td bgcolor=\"chucknorris\" cellpadding=\"8\" width=\"100\" align=\"center\">chuck norris</td>\n    <td bgcolor=\"mrt\"         cellpadding=\"8\" width=\"100\" align=\"center\" style=\"color:#ffffff\">Mr T</td>\n    <td bgcolor=\"ninjaturtle\" cellpadding=\"8\" width=\"100\" align=\"center\" style=\"color:#ffffff\">ninjaturtle</td>\n  </tr>\n  <tr>\n    <td bgcolor=\"sick\"  cellpadding=\"8\" width=\"100\" align=\"center\">sick</td>\n    <td bgcolor=\"crap\"  cellpadding=\"8\" width=\"100\" align=\"center\">crap</td>\n    <td bgcolor=\"grass\" cellpadding=\"8\" width=\"100\" align=\"center\">grass</td>\n  </tr>\n</table>\n Run code snippetExpand snippet\n\nThis also answers the other part of the question: Why does bgcolor=\"chucknorr\" produce a yellow colour? Well, if we apply the rules, the string is:\n\nc00c00000 => c00 c00 000 => c0 c0 00 [RGB(192, 192, 0)]\n\n\nWhich gives a light yellow gold colour. As the string starts off as 9 characters, we keep the second ‘C’ this time around, hence it ends up in the final colour value.\n\nI originally encountered this when someone pointed out that you could do color=\"crap\" and, well, it comes out brown.\n\nShare\nImprove this answer\nFollow\nedited Sep 30 '20 at 6:03\nib.\n25.6k10\n10 gold badges\n73\n73 silver badges\n97\n97 bronze badges\nanswered Nov 30 '11 at 21:53\ndash\n85.3k4\n4 gold badges\n48\n48 silver badges\n69\n69 bronze badges","comments":["Fun fact - According to this logic then <body bgcolor=\"cabs\"> test </body> would give you the color of a California Taxi Cab! The HQ of Netscape was in Mountain View, California!"]},{"answer":"I'm sorry to disagree, but according to the rules for parsing a legacy color value posted by @Yuhong Bao, chucknorris DOES NOT equate to #CC0000, but rather to #C00000, a very similar but slightly different hue of red. I used the Firefox ColorZilla add-on to verify this.\n\nThe rules state:\n\nmake the string a length that is a multiple of 3 by adding 0s: chucknorris0\nseparate the string into 3 equal length strings: chuc knor ris0\ntruncate each string to 2 characters: ch kn ri\nkeep the hex values, and add 0's where necessary: C0 00 00\n\nI was able to use these rules to correctly interpret the following strings:\n\nLuckyCharms\nLuck\nLuckBeALady\nLuckBeALadyTonight\nGangnamStyle\n\nUPDATE: The original answerers who said the color was #CC0000 have since edited their answers to include the correction.\n\nShare\nImprove this answer\nFollow\nedited Oct 5 '17 at 17:10\nanswered Oct 17 '12 at 17:55\nJeremy Goodell\n16.8k4\n4 gold badges\n33\n33 silver badges\n51\n51 bronze badges","comments":[]},{"answer":"The reason is the browser can not understand it and try to somehow translate it to what it can understand and in this case into a hexadecimal value!...\n\nchucknorris starts with c which is recognised character in hexadecimal, also it's converting all unrecognised characters into 0!\n\nSo chucknorris in hexadecimal format becomes: c00c00000000, all other characters become 0 and c remains where they are...\n\nNow they get divided by 3 for RGB(red, green, blue)... R: c00c, G: 0000, B:0000...\n\nBut we know valid hexadecimal for RGB is just 2 characters, means R: c0, G: 00, B:00\n\nSo the real result is:\n\nbgcolor=\"#c00000\";\n\n\nI also added the steps in the image as a quick reference for you:\n\nShare\nImprove this answer\nFollow\nedited Feb 11 '20 at 11:11\nanswered Jul 1 '17 at 4:08\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"Most browsers will simply ignore any NON-hex values in your color string, substituting non-hex digits with zeros.\n\nChuCknorris translates to c00c0000000. At this point, the browser will divide the string into three equal sections, indicating Red, Green and Blue values: c00c 0000 0000. Extra bits in each section will be ignored, which makes the final result #c00000 which is a reddish color.\n\nNote, this does not apply to CSS color parsing, which follow the CSS standard.\n\n<p><font color='chucknorris'>Redish</font></p>\n<p><font color='#c00000'>Same as above</font></p>\n<p><span style=\"color: chucknorris\">Black</span></p>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Sep 17 '14 at 16:09\nanswered Nov 29 '11 at 23:01\nMike Christensen\n78.5k47\n47 gold badges\n194\n194 silver badges\n301\n301 bronze badges","comments":["The fact that it doesn't apply to CSS is helpful extra information.","You might consider editing your answer, because the <font> element is hereby obsolete by HTML5."]},{"answer":"The browser is trying to convert chucknorris into hex colour code, because it’s not a valid value.\n\nIn chucknorris, everything except c is not a valid hex value.\nSo it gets converted to c00c00000000.\nWhich becomes #c00000, a shade of red.\n\nThis seems to be an issue primarily with Internet Explorer and Opera (12) as both Chrome (31) and Firefox (26) just ignore this.\n\nP.S. The numbers in brackets are the browser versions I tested on.\n\nOn a lighter note\n\nChuck Norris doesn’t conform to web standards. Web standards conform to him. #BADA55\n\nShare\nImprove this answer\nFollow\nedited Sep 30 '20 at 6:08\nib.\n25.6k10\n10 gold badges\n73\n73 silver badges\n97\n97 bronze badges\nanswered Nov 30 '13 at 14:05\naWebDeveloper\n31.8k35\n35 gold badges\n158\n158 silver badges\n224\n224 bronze badges","comments":["I have tested this on Firefox 26 and it works so I don't believe your reference is correct. Also from the following link scrappy-do.blogspot.com/2004/08/… you will see that this was inherited from Netscape so it is not specific to Internet Explorer or Opera!"]},{"answer":"The WHATWG HTML spec has the exact algorithm for parsing a legacy color value: https://html.spec.whatwg.org/multipage/infrastructure.html#rules-for-parsing-a-legacy-colour-value.\n\nThe code Netscape Classic used for parsing color strings is open source: https://github.com/zii/netscape/blob/master/lib/layout/layimage.c#L150.\n\nFor example, notice that each character is parsed as a hex digit and then is shifted into a 32-bit integer without checking for overflow. Only eight hex digits fit into a 32-bit integer, which is why only the last 8 characters are considered. After parsing the hex digits into 32-bit integers, they are then truncated into 8-bit integers by dividing them by 16 until they fit into 8-bit, which is why leading zeros are ignored.\n\nUpdate: This code does not exactly match what is defined in the spec, but the only difference there is a few lines of code. I think it is these lines that were added (in Netscape):\n\nif (bytes_per_val > 4)\n{\n    bytes_per_val = 4;\n}\n\nShare\nImprove this answer\nFollow\nedited May 23 at 5:43\nSoyChai\n3222\n2 silver badges\n11\n11 bronze badges\nanswered Sep 27 '12 at 22:01\nYuhong Bao\n3,6231\n1 gold badge\n17\n17 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"Answer:\n\nThe browser will try to convert chucknorris into a hexadecimal value.\nSince c is the only valid hex character in chucknorris, the value turns into: c00c00000000(0 for all values that were invalid).\nThe browser then divides the result into 3 groupds: Red = c00c, Green = 0000, Blue = 0000.\nSince valid hex values for html backgrounds only contain 2 digits for each color type (r, g, b), the last 2 digits are truncated from each group, leaving an rgb value of c00000 which is a brick-reddish toned color.\nShare\nImprove this answer\nFollow\nedited Jun 8 '18 at 6:20\nb1nary.atr0phy\n2,1933\n3 gold badges\n26\n26 silver badges\n34\n34 bronze badges\nanswered May 24 '16 at 5:18\nWebeng\n6,6064\n4 gold badges\n20\n20 silver badges\n53\n53 bronze badges","comments":[]},{"answer":"chucknorris starts with c, and the browser reads it into a hexadecimal value.\n\nBecause A, B, C, D, E, and F are characters in hexadecimal.\n\nThe browser converts chucknorris to a hexadecimal value, C00C00000000.\n\nThen the C00C00000000 hexadecimal value is converted to RGB format (divided by 3):\n\nC00C00000000 ⇒ R:C00C, G:0000, B:0000\n\nThe browser needs only two digits to indicate the colour:\n\nR:C00C, G:0000, B:0000 ⇒ R:C0, G:00, B:00 ⇒ C00000\n\nFinally, show bgcolor = C00000 in the web browser.\n\nHere's an example demonstrating it:\n\n<table>\n  <tr>\n    <td bgcolor=\"chucknorris\" cellpadding=\"10\" width=\"150\" align=\"center\">chucknorris</td>\n    <td bgcolor=\"c00c00000000\" cellpadding=\"10\" width=\"150\" align=\"center\">c00c00000000</td>\n    <td bgcolor=\"c00000\" cellpadding=\"10\" width=\"150\" align=\"center\">c00000</td>\n  </tr>\n</table>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Sep 30 '20 at 6:08\nib.\n25.6k10\n10 gold badges\n73\n73 silver badges\n97\n97 bronze badges\nanswered Apr 17 '18 at 19:16\nsameera lakshitha\n1,6362\n2 gold badges\n20\n20 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"The rules for parsing colors on legacy attributes involves additional steps than those mentioned in existing answers. The truncate component to 2 digits part is described as:\n\nDiscard all characters except the last 8\nDiscard leading zeros one by one as long as all components have a leading zero\nDiscard all characters except the first 2\n\nSome examples:\n\noooFoooFoooF\n000F 000F 000F                <- replace, pad and chunk\n0F 0F 0F                      <- leading zeros truncated\n0F 0F 0F                      <- truncated to 2 characters from right\n\noooFooFFoFFF\n000F 00FF 0FFF                <- replace, pad and chunk\n00F 0FF FFF                   <- leading zeros truncated\n00 0F FF                      <- truncated to 2 characters from right\n\nABCooooooABCooooooABCoooooo\nABC000000 ABC000000 ABC000000 <- replace, pad and chunk\nBC000000 BC000000 BC000000    <- truncated to 8 characters from left\nBC BC BC                      <- truncated to 2 characters from right\n\nAoCooooooAoCooooooAoCoooooo\nA0C000000 A0C000000 A0C000000 <- replace, pad and chunk\n0C000000 0C000000 0C000000    <- truncated to 8 characters from left\nC000000 C000000 C000000       <- leading zeros truncated\nC0 C0 C0                      <- truncated to 2 characters from right\n\n\nBelow is a partial implementation of the algorithm. It does not handle errors or cases where the user enters a valid color.\n\nShow code snippet\n\nShare\nImprove this answer\nFollow\nanswered Oct 17 '18 at 14:53\nSalman A\n233k77\n77 gold badges\n399\n399 silver badges\n493\n493 bronze badges","comments":[]}]},{"id":"1125968","href":"https://stackoverflow.com/questions/1125968/how-do-i-force-git-pull-to-overwrite-local-files","title":"How do I force “git pull” to overwrite local files?","description":"\n                \nHow do I force an overwrite of local files on a git pull?\n\nThe scenario is the following:\n\n\nA team member is modifying the templates for a website we are working on\nThey are adding some images to the images directory (but forgets to add them under source control)\nThey are sending the images by mail, later, to me\nI'm adding the images under the source control and pushing them to GitHub together with other changes\nThey cannot pull updates from GitHub because Git doesn't want to overwrite their files.\n\n\nThis is the error I'm getting:\n\n\n  error: Untracked working tree file 'public/images/icon.gif' would be overwritten by merge\n\n\nHow do I force Git to overwrite them? The person is a designer - usually, I resolve all the conflicts by hand, so the server has the most recent version that they just need to update on their computer.\n    ","questionComments":["anyone reading this who thinks they might lose files, I've been in this position and found Sublime Text's buffer has saved me - if I'm working on something, then accidentally delete everything by trying to solve a similar problem to this or by using an answer on this question and have had the files open in Sublime (which there's a good chance of) then the files will still be there is Sublime, either just there, or in the undo history","git reset --hard origin/branch_to_overwrite","basically, only do a pull from develop after the initial checkout -b. do your work, then push back in.","Short answer: delete and re-create branch. 1. Delete branch: git branch <branch> -D 2. Reset to a commit before the conflict: git reset <commit> --hard 3. Re-create the branch: git branch <branch> 4. Set tracking to the server: git --set-upstream-to=origin/<branch> <branch> 5. Pull: git pull`","To change all CRLF to LF endings, (start clean) git config core.autocrlf false; git ls-files -z | xargs -0 rm; git checkout ."],"answers":[{"answer":"⚠ Important: If you have any local changes, they will be lost. With or without --hard option, any local commits that haven't been pushed will be lost.[*]\n\nIf you have any files that are not tracked by Git (e.g. uploaded user content), these files will not be affected.\n\nFirst, run a fetch to update all origin/<branch> refs to latest:\n\ngit fetch --all\n\n\nBackup your current branch:\n\ngit branch backup-master\n\n\nThen, you have two options:\n\ngit reset --hard origin/master\n\n\nOR If you are on some other branch:\n\ngit reset --hard origin/<branch_name>\n\nExplanation:\n\ngit fetch downloads the latest from remote without trying to merge or rebase anything.\n\nThen the git reset resets the master branch to what you just fetched. The --hard option changes all the files in your working tree to match the files in origin/master\n\nMaintain current local commits\n\n[*]: It's worth noting that it is possible to maintain current local commits by creating a branch from master before resetting:\n\ngit checkout master\ngit branch new-branch-to-save-current-commits\ngit fetch --all\ngit reset --hard origin/master\n\n\nAfter this, all of the old commits will be kept in new-branch-to-save-current-commits.\n\nUncommitted changes\n\nUncommitted changes, however (even staged), will be lost. Make sure to stash and commit anything you need. For that you can run the following:\n\ngit stash\n\n\nAnd then to reapply these uncommitted changes:\n\ngit stash pop\n\nShare\nImprove this answer\nFollow\nedited Apr 19 at 1:00\nkevinnls\n4122\n2 silver badges\n12\n12 bronze badges\nanswered Jan 17 '12 at 0:02\nRNA\n129k12\n12 gold badges\n45\n45 silver badges\n62\n62 bronze badges","comments":["Watch out! If you have local unpushed commits this will remove them from your branch! This solution keeps untracked files not in the repository intact, but overwrites everything else.","It's a popular question, so I'd like to clarify on the top comment here. I just executed commands as described in this answer and it hasn't removed ALL the local files. Only the remotely tracked files were overwritten, and every local file that has been here was left untouched.","in case you're pulling from a repo that has its remote branch name different from \"master\", use git reset --hard origin/branch-name","Given the amount of upvotes to this question and answer, I think that git should incorporate a command like git pull -f","Commits that weren't pushes before the hard reset can be recovered using git reflog, which list all commits, also those without a base. Until you cleanup your local copy using git gc, then all is lost"]},{"answer":"Try this:\n\ngit reset --hard HEAD\ngit pull\n\n\nIt should do what you want.\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 9 '10 at 19:45\nTravis Reeder\n32.1k12\n12 gold badges\n80\n80 silver badges\n80\n80 bronze badges","comments":["I've done this and some local files that were no longer in repo were left on the disk.","I do not think that this is correct. the above will perform a merge, not overwrite which was requested in the question: \"How to force git to overwrite them?\" I do not have the answer, I am currently looking for it.. at the moment I switch to the branch with with the code that I want to keep \"git checkout BranchWithCodeToKeep\", then do \"git branch -D BranchToOverwrite\" and then finally \"git checkout -b BranchToOverwrite\". you will now have the exact code from BranchWithCodeToKeep on the branch BranchToOverwrite without having to perform a merge.","instead of merging using 'git pull', try git fetch --all followed by 'git reset --hard origin/master'","yep, the @lloydmoore solution worked for me. Could do with being an answer rather than just a comment.","This will reset the current changes back to the last branch commit pulled. Then git pull merges the changes from the latest branch. This did exactly what I wanted it to do.. Thanks!"]},{"answer":"WARNING: git clean deletes all your untracked files/directories and can't be undone.\n\nSometimes just clean -f does not help. In case you have untracked DIRECTORIES, -d option also needed:\n\n# WARNING: this can't be undone!\n\ngit reset --hard HEAD\ngit clean -f -d\ngit pull\n\n\nWARNING: git clean deletes all your untracked files/directories and can't be undone.\n\nConsider using -n (--dry-run) flag first. This will show you what will be deleted without actually deleting anything:\n\ngit clean -n -f -d\n\n\nExample output:\n\nWould remove untracked-file-1.txt\nWould remove untracked-file-2.txt\nWould remove untracked/folder\n...\n\nShare\nImprove this answer\nFollow\nedited Aug 17 '18 at 19:32\nanswered Mar 19 '11 at 9:10\nDavid Avsajanishvili\n6,7382\n2 gold badges\n20\n20 silver badges\n24\n24 bronze badges","comments":["You can give git clean a path argument to be more specific and avoid deleting untracked files that aren't conflicting.","I think the scenario description makes it clear that he doesn't really want to throw away the content. Rather what he wants is to stop git baulking at overwriting the files. @Lauri, this should not have happened to you. Unfortunately people seem to have misread the essence of scenario description - see my suggestion.","FINALLY. git clean -f -d is handy when make clean fails to clean everything.","@crizCraig unless they are added in .gitignore","@earthmeLon, for that you might want git clean -dfx. The -x ignores .gitignore. Typically your build products will be in .gitignore."]},{"answer":"Like Hedgehog I think the answers are terrible. But though Hedgehog's answer might be better, I don't think it is as elegant as it could be. The way I found to do this is by using fetch and merge with a defined strategy. Which should make it so that your local changes are preserved as long as they are not one of the files that you are trying to force an overwrite with.\n\nFirst do a commit of your changes\n git add *\n git commit -a -m \"local file server commit message\"\n\nThen fetch the changes and overwrite if there is a conflict\n git fetch origin master\n git merge -s recursive -X theirs origin/master\n\n\n-X is an option name, and theirs is the value for that option. You're choosing to use their changes (the other option is ours changes) if there is a conflict.\n\nShare\nImprove this answer\nFollow\nedited Feb 24 at 14:23\nTheTechRobo36414519\n7499\n9 silver badges\n23\n23 bronze badges\nanswered Apr 11 '12 at 20:13\nRichard Kersey\n4,7711\n1 gold badge\n14\n14 silver badges\n19\n19 bronze badges","comments":["This is the best answer I've seen so far. I haven't tried it, but unlike other answers, this doesn't attempt to nuke all your untracked files, which is very dangerous for obvious reasons.","Ditto - this worked for me when doing a very large merge (GitHub pull request) where I just wanted to accept it all on top of what I had. Good answer! In my case the last two commands were: 1) get fetch other-repo; 2) git merge -s recursive -X theirs other-repo/master","This will overwrite any conflicts with the repositories files and not your local ones, correct?","Best answer. The highest accepted answer left me in my case on detached head. I switched back to local master branch and ran git merge -X theirs origin/master","i just wanted freaking git to overwrite everything and shut up about it. after all im just using it between my work pc and some raspberry pi systems. Whishing for a force overwrite option, at least for project leader"]},{"answer":"Instead of doing:\n\ngit fetch --all\ngit reset --hard origin/master\n\n\nI'd advise doing the following:\n\ngit fetch origin master\ngit reset --hard origin/master\n\n\nNo need to fetch all remotes and branches if you're going to reset to the origin/master branch right?\n\nShare\nImprove this answer\nFollow\nedited Sep 14 '16 at 9:46\nanswered Apr 26 '13 at 13:48\nJohanneke\n4,3513\n3 gold badges\n16\n16 silver badges\n32\n32 bronze badges","comments":["Your answer is just what you needed for your rep. I must ask, does this also remove all untracked files?","Yeah, most of my rep is coming from here :) This will also remove all untracked files. Something I had forgotten and was painfully reminded of just 2 days ago...","See the comments on this other answer: stackoverflow.com/a/8888015/2151700","This did not remove my untracked files; which is actually what I'd expect. Is there a reason it might for some people and not for others?","Untracked files are not affect4ed by git reset. If you want them to be removed as well, do git add . first, before git reset --hard"]},{"answer":"It looks like the best way is to first do:\n\ngit clean\n\n\nTo delete all untracked files and then continue with the usual git pull...\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 14 '09 at 15:16\nJakub Troszok\n86.5k10\n10 gold badges\n36\n36 silver badges\n50\n50 bronze badges","comments":["I tried using \"git clean\" to solve the same issue, but it did not resolve it. git status says \"Your branch and 'origin/master' have diverged, # and have 2 and 9 different commit(s) each, respectively.\" and git pull says something similar to what you have above.","git clean is a rather blunt instrument, and could throw away a lot of things that you may want to keep. Better to remove or rename the files that git is complaining about until the pull succeeds.","I do not think this works in general. Isn't there a way to do basically a git clone remote via a forced git pull?","@mathick: git fetch origin && git reset --hard origin/master","Is git clean the best answer here? Seems like removing files isn't necessarily what the OP wants. They asked for 'an overwrite of local files' not deletion."]},{"answer":"Warning, doing this will permanently delete your files if you have any directory/* entries in your gitignore file.\n\nSome answers seem to be terrible. Terrible in the sense of what happened to @Lauri by following David Avsajanishvili suggestion.\n\nRather (git > v1.7.6):\n\ngit stash --include-untracked\ngit pull\n\n\nLater you can clean the stash history.\n\nManually, one-by-one:\n\n$ git stash list\nstash@{0}: WIP on <branch>: ...\nstash@{1}: WIP on <branch>: ...\n\n$ git stash drop stash@{0}\n$ git stash drop stash@{1}\n\n\nBrutally, all-at-once:\n\n$ git stash clear\n\n\nOf course if you want to go back to what you stashed:\n\n$ git stash list\n...\n$ git stash apply stash@{5}\n\nShare\nImprove this answer\nFollow\nedited Mar 7 '18 at 7:00\nanswered Feb 11 '12 at 23:00\nHedgehog\n4,9703\n3 gold badges\n31\n31 silver badges\n39\n39 bronze badges","comments":["No I don't think so. Stashing just moves uncommitted files out of the way. The above also moves (stashes) files that git does not track. This prevents files that have been added to the remote, which have not yet pulled down to your machine - but which you have created (!) - to be pulled down. All without destroying the uncommitted work. Hope that makes sense?","If you don't have 1.7.6, you can mimic --include-untracked simply by temporarily git add-ing your entire repo, then immediately stashing it.","I agree with Hedgehog. If you do the popular answers here, you are more than likely going to find you've inadvertently killed a lot of stuff that you didn't really want to lose.","I had other untracked files--besides the one the merge/pull wanted to overwrite, so this solution worked best. git stash apply brought back all my untracked files with the exception (rightly) of the ones that the merge had already created: \"already exists, no checkout.\" Worked perfectly.","This is the cleanest answer, and should be the accepted one. To save some typing you can use the short form: git stash -u."]},{"answer":"You might find this command helpful to throw away local changes:\n\ngit checkout <your-branch> -f\n\n\nAnd then do a cleanup (removes untracked files from the working tree):\n\ngit clean -f\n\n\nIf you want to remove untracked directories in addition to untracked files:\n\ngit clean -fd\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 5 '10 at 18:06\nVishal\n18k17\n17 gold badges\n73\n73 silver badges\n91\n91 bronze badges","comments":["I think the scenario description makes it clear that he doesn't really want to throw away the content. Rather what he wants is to stop git baulking at overwriting the files. See my suggestion.","Though that answer might not fit exactly the description, it still saved me from the frustration of git twiddling with the carriage returns (event with autocrlf false). When git reset --hard HEAD does not leave you with \"no\" modified files, these \"-f\" flags are quite helpful. Thanks a bunch."]},{"answer":"Instead of merging with git pull, try this:\n\ngit fetch --all\n\nfollowed by:\n\ngit reset --hard origin/master.\n\nShare\nImprove this answer\nFollow\nedited Mar 21 '18 at 7:21\nsbarb\n852\n2 silver badges\n8\n8 bronze badges\nanswered Nov 22 '12 at 10:56\nLloyd Moore\n2,94928\n28 silver badges\n31\n31 bronze badges","comments":[]},{"answer":"The only thing that worked for me was:\n\ngit reset --hard HEAD~5\n\n\nThis will take you back five commits and then with\n\ngit pull\n\n\nI found that by looking up how to undo a Git merge.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 10:31\nCommunity♦\n11\n1 silver badge\nanswered May 5 '11 at 21:53\nChris BIllante\n7015\n5 silver badges\n3\n3 bronze badges","comments":["This was what ultimately worked for me as I had force pushed my branch to the origin repo and kept getting merge conflicts when trying to pull it to my remote repo..","Hi, actually this is a trick for a work around but really effective. Because some conflicts may happen just in few commits then reverting 5 commits will make sure no conflicts with remote code."]},{"answer":"The problem with all these solutions is that they are all either too complex, or, an even bigger problem, is that they remove all untracked files from the web server, which we don't want since there are always needed configuration files which are on the server and not in the Git repository.\n\nHere is the cleanest solution which we are using:\n\n# Fetch the newest code\ngit fetch\n\n# Delete all files which are being added, so there\n# are no conflicts with untracked files\nfor file in `git diff HEAD..origin/master --name-status | awk '/^A/ {print $2}'`\ndo\n    rm -f -- \"$file\"\ndone\n\n# Checkout all files which were locally modified\nfor file in `git diff --name-status | awk '/^[CDMRTUX]/ {print $2}'`\ndo\n    git checkout -- \"$file\"\ndone\n\n# Finally pull all the changes\n# (you could merge as well e.g. 'merge origin/master')\ngit pull\n\n\nThe first command fetches newest data.\n\nThe second command checks if there are any files which are being added to the repository and deletes those untracked files from the local repository which would cause conflicts.\n\nThe third command checks-out all the files which were locally modified.\n\nFinally we do a pull to update to the newest version, but this time without any conflicts, since untracked files which are in the repo don't exist anymore and all the locally modified files are already the same as in the repository.\n\nShare\nImprove this answer\nFollow\nedited May 23 '14 at 21:14\nuser456814\nanswered Nov 5 '12 at 23:32\nStrahinja Kustudic\n3,39721\n21 silver badges\n17\n17 bronze badges","comments":["Using \"git merge origin/master\" as the last line (like you say in your note) instead of \"git pull\" will be faster as you've already pulled down any changes from the git repo.","Yeah of course, git merge origin/master will be faster and probably even safer. Since if someone pushed new changes during the removal of of files of this script (which is not likely to happen, but possible), the whole pull could fail. The only reason I put pull in there is because someone might not be working on the master branch, but some other branch and I wanted the script to be universal.","If you have locally created files like option files, put them in .gitignore."]},{"answer":"First of all, try the standard way:\n\ngit reset HEAD --hard # To remove all not committed changes!\ngit clean -fd         # To remove all untracked (non-git) files and folders!\n\n\nWarning: Above commands can results in data/files loss only if you don't have them committed! If you're not sure, make the backup first of your whole repository folder.\n\nThen pull it again.\n\nIf above won't help and you don't care about your untracked files/directories (make the backup first just in case), try the following simple steps:\n\ncd your_git_repo  # where 'your_git_repo' is your git repository folder\nrm -rfv *         # WARNING: only run inside your git repository!\ngit pull          # pull the sources again\n\n\nThis will REMOVE all git files (excempt .git/ dir, where you have all commits) and pull it again.\n\nWhy git reset HEAD --hard could fail in some cases?\n\nCustom rules in .gitattributes file\n\nHaving eol=lf rule in .gitattributes could cause git to modify some file changes by converting CRLF line-endings into LF in some text files.\n\nIf that's the case, you've to commit these CRLF/LF changes (by reviewing them in git status), or try: git config core.autcrlf false to temporary ignore them.\n\nFile system incompability\n\nWhen you're using file-system which doesn't support permission attributes. In example you have two repositories, one on Linux/Mac (ext3/hfs+) and another one on FAT32/NTFS based file-system.\n\nAs you notice, there are two different kind of file systems, so the one which doesn't support Unix permissions basically can't reset file permissions on system which doesn't support that kind of permissions, so no matter how --hard you try, git always detect some \"changes\".\n\nShare\nImprove this answer\nFollow\nedited Jan 31 '19 at 15:48\nanswered Oct 26 '12 at 9:17\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges","comments":[]},{"answer":"I had the same problem. No one gave me this solution, but it worked for me.\n\nI solved it by:\n\nDelete all the files. Leave just the .git directory.\ngit reset --hard HEAD\ngit pull\ngit push\n\nNow it works.\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '19 at 23:00\nSherylHohman\n12.8k16\n16 gold badges\n73\n73 silver badges\n78\n78 bronze badges\nanswered Jan 12 '11 at 23:58\nJohn John Pichler\n3,8894\n4 gold badges\n37\n37 silver badges\n69\n69 bronze badges","comments":["Same here. Sometimes only the very hard solution works, it happens often that only reset and clean are not enough somehow..."]},{"answer":"Bonus:\n\nIn speaking of pull/fetch/merge in the previous answers, I would like to share an interesting and productive trick,\n\ngit pull --rebase\n\nThis above command is the most useful command in my Git life which saved a lot of time.\n\nBefore pushing your newly commit to server, try this command and it will automatically synchronise the latest server changes (with a fetch + merge) and will place your commit at the top in the Git log. There isn't any need to worry about manual pull/merge.\n\nFind details in What does \"git pull --rebase\" do?.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Dec 23 '15 at 15:41\nSazzad Hissain Khan\n30.5k21\n21 gold badges\n138\n138 silver badges\n201\n201 bronze badges","comments":["In short: git pull -r.","In my case, before doing that, I had to 1) git add -A, 2) git commit -m 3) and finally git pull rebase. Thank you."]},{"answer":"I had a similar problem. I had to do this:\n\ngit reset --hard HEAD\ngit clean -f\ngit pull\n\nShare\nImprove this answer\nFollow\nedited Nov 6 '11 at 16:35\nAlexsander Akers\n15.8k12\n12 gold badges\n55\n55 silver badges\n81\n81 bronze badges\nanswered Jan 14 '11 at 15:18\nRyan\n3513\n3 silver badges\n2\n2 bronze badges","comments":["use git clean with caution"]},{"answer":"I summarized other answers. You can execute git pull without errors:\n\ngit fetch --all\ngit reset --hard origin/master\ngit reset --hard HEAD\ngit clean -f -d\ngit pull\n\n\nWarning: This script is very powerful, so you could lose your changes.\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:42\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 7 '15 at 3:03\nRobert Moon\n9579\n9 silver badges\n17\n17 bronze badges","comments":["This will overwrite modified files (files that were previously checked in) and it will remove untracked files (files that have never been checked in). Exactly what I was looking for, thanks!","I suspect the third line git reset --hard HEAD may be redundant; my local man page (2.6.3) say that reset in the second line git reset --hard origin/master \"defaults to HEAD in all forms.\"","@arichards I think your suspect is right but if second line will not work(by any reason) third line work well to reset. This solution doesn't need to be optimized. I just summarized other answers. That's all. Thank you for your comment. :)","Thanks for the summary. These steps are indeed powerful :)"]},{"answer":"Based on my own similar experiences, the solution offered by Strahinja Kustudic above is by far the best. As others have pointed out, simply doing hard reset will remove all the untracked files which could include lots of things that you don't want removed, such as config files. What is safer, is to remove only the files that are about to be added, and for that matter, you'd likely also want to checkout any locally-modified files that are about to be updated.\n\nThat in mind, I updated Kustudic's script to do just that. I also fixed a typo (a missing ' in the original).\n\n#/bin/sh\n\n# Fetch the newest code\ngit fetch\n\n# Delete all files which are being added,\n# so there are no conflicts with untracked files\nfor file in `git diff HEAD..origin/master --name-status | awk '/^A/ {print $2}'`\ndo\n    echo \"Deleting untracked file $file...\"\n    rm -vf \"$file\"\ndone\n\n# Checkout all files which have been locally modified\nfor file in `git diff HEAD..origin/master --name-status | awk '/^M/ {print $2}'`\ndo\n    echo \"Checking out modified file $file...\"\n    git checkout $file\ndone\n\n# Finally merge all the changes (you could use merge here as well)\ngit pull\n\nShare\nImprove this answer\nFollow\nedited Aug 13 '15 at 23:12\nNathaniel Ford\n17.2k19\n19 gold badges\n75\n75 silver badges\n89\n89 bronze badges\nanswered Feb 27 '13 at 14:43\nRolf Kaiser\n5296\n6 silver badges\n8\n8 bronze badges","comments":["Using \"git merge origin/master\" as the last line (like you say in your note) instead of \"git pull\" will be faster as you've already pulled down any changes from the git repo.","The checkout of modified files is needed, so this works 100% of times. I updated my script with that a long time ago, but forgot to update here as well. I also use it a little differently than you. I checkout files which have any type of modification, not just M, so it works all the time."]},{"answer":"I believe there are two possible causes of conflict, which must be solved separately, and as far as I can tell none of the above answers deals with both:\n\nLocal files that are untracked need to be deleted, either manually (safer) or as suggested in other answers, by git clean -f -d\n\nLocal commits that are not on the remote branch need to be deleted as well. IMO the easiest way to achieve this is with: git reset --hard origin/master (replace 'master' by whatever branch you are working on, and run a git fetch origin first)\n\nShare\nImprove this answer\nFollow\nedited Dec 12 '11 at 20:05\nanswered Dec 12 '11 at 19:54\ntiho\n6,0012\n2 gold badges\n27\n27 silver badges\n30\n30 bronze badges","comments":[]},{"answer":"It seems like most answers here are focused on the master branch; however, there are times when I'm working on the same feature branch in two different places and I want a rebase in one to be reflected in the other without a lot of jumping through hoops.\n\nBased on a combination of RNA's answer and torek's answer to a similar question, I've come up with this which works splendidly:\n\ngit fetch\ngit reset --hard @{u}\n\n\nRun this from a branch and it'll only reset your local branch to the upstream version.\n\nThis can be nicely put into a git alias (git forcepull) as well:\n\ngit config alias.forcepull \"!git fetch ; git reset --hard @{u}\"\n\nOr, in your .gitconfig file:\n\n[alias]\n  forcepull = \"!git fetch ; git reset --hard @{u}\"\n\n\nEnjoy!\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:18\nCommunity♦\n11\n1 silver badge\nanswered Feb 25 '14 at 17:19\nJacobEvelyn\n3,5131\n1 gold badge\n36\n36 silver badges\n49\n49 bronze badges","comments":["This answer is also nice because it works regardless of which branch you are on!"]},{"answer":"I had the same problem and for some reason, even a git clean -f -d would not do it. Here is why: For some reason, if your file is ignored by Git (via a .gitignore entry, I assume), it still bothers about overwriting this with a later pull, but a clean will not remove it, unless you add -x.\n\nShare\nImprove this answer\nFollow\nedited Mar 18 '15 at 19:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 3 '11 at 9:23\nTierlieb\n2572\n2 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"An easier way would be to:\n\ngit checkout --theirs /path/to/file.extension\ngit pull origin master\n\n\nThis will override your local file with the file on git\n\nShare\nImprove this answer\nFollow\nanswered May 5 '15 at 8:03\nmaximus 69\n1,2583\n3 gold badges\n19\n19 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"I know of a much easier and less painful method:\n\n$ git branch -m [branch_to_force_pull] tmp\n$ git fetch\n$ git checkout [branch_to_force_pull]\n$ git branch -D tmp\n\n\nThat's it!\n\nShare\nImprove this answer\nFollow\nedited Sep 5 '18 at 16:52\nRicky McMaster\n3,3871\n1 gold badge\n22\n22 silver badges\n19\n19 bronze badges\nanswered Sep 5 '15 at 18:23\nddmytrenko\n7787\n7 silver badges\n16\n16 bronze badges","comments":["I tried doing as suggested in this answer. NO FILES AT ALL were pulled down from the remote repository. Actually not very surprising when you think about it - after all there is no reference at all to origin/<branch_to_force_pull>."]},{"answer":"I just solved this myself by:\n\ngit checkout -b tmp # \"tmp\" or pick a better name for your local changes branch\ngit add -A\ngit commit -m 'tmp'\ngit pull\ngit checkout master # Or whatever branch you were on originally\ngit pull\ngit diff tmp\n\n\nwhere the last command gives a list of what your local changes were. Keep modifying the \"tmp\" branch until it is acceptable and then merge back onto master with:\n\ngit checkout master && git merge tmp\n\n\nFor next time, you can probably handle this in a cleaner way by looking up \"git stash branch\" though stash is likely to cause you trouble on the first few tries, so do first experiment on a non-critical project...\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 3 '10 at 15:00\nSimon B.\n2,07018\n18 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"I have a strange situation that neither git clean or git reset works. I have to remove the conflicting file from git index by using the following script on every untracked file:\n\ngit rm [file]\n\n\nThen I am able to pull just fine.\n\nShare\nImprove this answer\nFollow\nedited Dec 5 '17 at 4:35\nJacob Gunther\n3033\n3 silver badges\n13\n13 bronze badges\nanswered Sep 19 '11 at 14:18\nChen Zhang\n2072\n2 silver badges\n3\n3 bronze badges","comments":[]},{"answer":"Just do\n\ngit fetch origin branchname\ngit checkout -f origin/branchname // This will overwrite ONLY new included files\ngit checkout branchname\ngit merge origin/branchname\n\n\nSo you avoid all unwanted side effects, like deleting files or directories you wanted to keep, etc.\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 19 '15 at 9:54\nuser2696128\n1711\n1 silver badge\n2\n2 bronze badges","comments":["Nice. By first using checkout -f into the branch I wanted to merge from, that got rid of all the problematic untracked files. Then I could checkout again my destination, and finally merge without issues."]},{"answer":"Despite the original question, the top answers can cause problems for people who have a similar problem, but don't want to lose their local files. For example, see Al-Punk and crizCraig's comments.\n\nThe following version commits your local changes to a temporary branch (tmp), checks out the original branch (which I'm assuming is master) and merges the updates. You could do this with stash, but I've found it's usually easier to simply use the branch / merge approach.\n\ngit checkout -b tmp\ngit add *; git commit -am \"my temporary files\"\ngit checkout master\n\ngit fetch origin master\ngit merge -s recursive -X theirs origin master\n\n\nwhere we assume the other repository is origin master.\n\nShare\nImprove this answer\nFollow\nedited Mar 18 '15 at 19:43\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 22 '14 at 17:31\nSnowcrash\n68.3k64\n64 gold badges\n213\n213 silver badges\n329\n329 bronze badges","comments":[]},{"answer":"Reset the index and the head to origin/master, but do not reset the working tree:\n\ngit reset origin/master\n\nShare\nImprove this answer\nFollow\nanswered Feb 15 '13 at 13:41\nuser811773","comments":["I personally found this to be most useful. It then keeps your working tree so you can check it in again. For my issue, I had the same files deleted as being added so it was stuck. Weird, I know."]},{"answer":"These four commands work for me.\n\ngit reset --hard HEAD\ngit checkout origin/master\ngit branch -D master\ngit checkout -b master\n\n\nTo check/pull after executing these commands\n\ngit pull origin master\n\n\nI tried a lot but finally got success with these commands.\n\nShare\nImprove this answer\nFollow\nanswered Mar 20 '14 at 4:24\nVishesh Chandra\n6,7616\n6 gold badges\n32\n32 silver badges\n38\n38 bronze badges","comments":["\"git branch -D master\" delete the branch. so be careful with it. I prefer to use \"git checkout origin/master -b <new branch name>\" which create a new branch with a new name and you done need 3,4 lines. Also recommended to use \"git clean -f\" as well."]},{"answer":"Requirements:\n\nTrack local changes so no-one here ever loses them.\nMake the local repository match the remote origin repository.\n\nSolution:\n\nStash the local changes.\n\nFetch with a clean of files and directories ignoring .gitignore and hard reset to origin.\n\ngit stash --include-untracked\ngit fetch --all\ngit clean -fdx\ngit reset --hard origin/master\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:44\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 1 '15 at 23:00\nvezenkov\n3,44924\n24 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"I read through all the answers but I was looking for a single command to do this. Here is what I did. Added a git alias to .gitconfig\n\n[alias]\n      fp = \"!f(){ git fetch ${1} ${2} && git reset --hard ${1}/${2};};f\"\n\n\nRun your command as\n\ngit fp origin master\n\n\nequivalent to\n\ngit fetch origin master\ngit reset --hard origin/master\n\nShare\nImprove this answer\nFollow\nanswered Jul 8 '16 at 13:11\nVenkat Kotra\n9,4063\n3 gold badges\n40\n40 silver badges\n49\n49 bronze badges","comments":[]}]},{"id":"178325","href":"https://stackoverflow.com/questions/178325/how-do-i-check-if-an-element-is-hidden-in-jquery","title":"How do I check if an element is hidden in jQuery?","description":"\n                \nIs it possible to toggle the visibility of an element, using the functions .hide(), .show() or .toggle()?\n\nHow would you test if an element is visible or hidden?\n    ","questionComments":["It's worth mentioning (even after all this time), that $(element).is(\":visible\") works for jQuery 1.4.4, but not for jQuery 1.3.2, under Internet&nbsp;Explorer&nbsp;8. This can be tested using Tsvetomir Tsonev's helpful test snippet. Just remember to change the version of jQuery, to test under each one.","This is related although a different question: stackoverflow.com/questions/17425543/…","If you are not interested in virtual css element hiding, but physical visibility in \"viewport area\" for user then cosider to see stackoverflow.com/questions/487073/… and stackoverflow.com/questions/123999/…"],"answers":[{"answer":"Since the question refers to a single element, this code might be more suitable:\n\n// Checks CSS content for display:[none|block], ignores visibility:[true|false]\n$(element).is(\":visible\");\n\n// The same works with hidden\n$(element).is(\":hidden\");\n\n\nIt is the same as twernt's suggestion, but applied to a single element; and it matches the algorithm recommended in the jQuery FAQ.\n\nWe use jQuery's is() to check the selected element with another element, selector or any jQuery object. This method traverses along the DOM elements to find a match, which satisfies the passed parameter. It will return true if there is a match, otherwise return false.\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 4:07\nashleedawg\n17.6k5\n5 gold badges\n60\n60 silver badges\n83\n83 bronze badges\nanswered Oct 7 '08 at 13:30\nTsvetomir Tsonev\n102k5\n5 gold badges\n25\n25 silver badges\n33\n33 bronze badges","comments":["This solution would seem to encourage the confustion of visible=false and display:none; whereas Mote's solution clearly illistrates the coders intent to check the display:none; (via mention of hide and show which control display:none not visible=true)","That is correct, but :visible will also check if the parent elements are visible, as chiborg pointed out.","You have a point - I'll make it clear that the code checks only for the display property. Given that the the original question is for show() and hide(), and they set display, my answer is correct. By the way it does work with IE7, here's a test snippet - jsfiddle.net/MWZss ;","I actually found that the reverse logic words better: !$('selector').is(':hidden'); for some reason. Worth a try.","Here's a simple benchmark testing is() against regexp:jsperf.com/jquery-is-vs-regexp-for-css-visibility. Conclusion: if you're out for performance, use regexp over is() (since is() looks for all hidden nodes first before looking at the actual element)."]},{"answer":"You can use the hidden selector:\n\n// Matches all elements that are hidden\n$('element:hidden')\n\n\nAnd the visible selector:\n\n// Matches all elements that are visible\n$('element:visible')\n\nShare\nImprove this answer\nFollow\nedited Mar 8 '18 at 15:38\nanswered Oct 7 '08 at 13:16\ntwernt\n19.4k5\n5 gold badges\n31\n31 silver badges\n41\n41 bronze badges","comments":["just be careful, there are some good performance related tips in this presentation: addyosmani.com/jqprovenperformance","On pages 21 to 28 it shows how slow :hidden or :visible is compared to other selectors. Thanks for pointing this.","When you're dealing with a couple of elements and very little is going on - i.e. THE ABSURDLY VAST MAJORITY OF CASES - the time issue is a ridiculously minor concern. Oh, noes! It took 42 ms instead of 19 ms!!!","I am toggling the element mamually using this selector. $('element:hidden') is always true for me!","@cwingrav You might want to re-read the documentation, :hidden applies to all elements. Form elements with type=\"hidden\" is just one case that can trigger :hidden. Elements with no height and width, elements with display: none, and elements with hidden ancestors will also qualify as :hidden."]},{"answer":"if ( $(element).css('display') == 'none' || $(element).css(\"visibility\") == \"hidden\"){\n    // 'element' is hidden\n}\n\n\nThe above method does not consider the visibility of the parent. To consider the parent as well, you should use .is(\":hidden\") or .is(\":visible\").\n\nFor example,\n\n<div id=\"div1\" style=\"display:none\">\n  <div id=\"div2\" style=\"display:block\">Div2</div>\n</div>\n\n\nThe above method will consider div2 visible while :visible not. But the above might be useful in many cases, especially when you need to find if there is any error divs visible in the hidden parent because in such conditions :visible will not work.\n\nShare\nImprove this answer\nFollow\nedited May 6 '20 at 13:39\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 7 '08 at 13:09\nMote\n10.5k1\n1 gold badge\n16\n16 silver badges\n10\n10 bronze badges","comments":["This only checks for the display property of a single element. The :visible attribute checks also the visibility of the parent elements.","This is the only solution that worked for me when testing with IE 8.","@chiborg Yes, but sometimes that's what you want and I had to learn the hard way how \"clever\" jQuery was...","This does answer the question, being the question is about a single element and by using the hide(), show() and toggle() functions, however, as most have already said, we should use the :visible and :hidden pseudo-classes.","This answer can be used when an element exists but is not currently on the page, such as after detach()."]},{"answer":"None of these answers address what I understand to be the question, which is what I was searching for, \"How do I handle items that have visibility: hidden?\". Neither :visible nor :hidden will handle this, as they are both looking for display per the documentation. As far as I could determine, there is no selector to handle CSS visibility. Here is how I resolved it (standard jQuery selectors, there may be a more condensed syntax):\n\n$(\".item\").each(function() {\n    if ($(this).css(\"visibility\") == \"hidden\") {\n        // handle non visible state\n    } else {\n        // handle visible state\n    }\n});\n\nShare\nImprove this answer\nFollow\nedited Jun 26 '17 at 7:12\nAndrii Abramov\n8,1978\n8 gold badges\n59\n59 silver badges\n81\n81 bronze badges\nanswered Mar 24 '11 at 18:44\naaronLile\n5,6571\n1 gold badge\n12\n12 silver badges\n3\n3 bronze badges","comments":["This answer is good to handle visibility literally, but the question was How you would test if an element has been hidden or shown using jQuery?. Using jQuery means: the display property.","Elements with visibility: hidden or opacity: 0 are considered to be visible, since they still consume space in the layout. See answer by Pedro Rainho and jQuery documentation on the :visible selector.","you need to traverse up the DOM to check the node's parents, or else ,this is useless."]},{"answer":"From How do I determine the state of a toggled element?\n\nYou can determine whether an element is collapsed or not by using the :visible and :hidden selectors.\n\nvar isVisible = $('#myDiv').is(':visible');\nvar isHidden = $('#myDiv').is(':hidden');\n\n\nIf you're simply acting on an element based on its visibility, you can just include :visible or :hidden in the selector expression. For example:\n\n $('#myDiv:visible').animate({left: '+=200px'}, 'slow');\n\nShare\nImprove this answer\nFollow\nedited Jan 12 '16 at 14:08\nChris\n1352\n2 silver badges\n7\n7 bronze badges\nanswered Jan 13 '11 at 21:13\nuser574889\n4,1291\n1 gold badge\n12\n12 silver badges\n2\n2 bronze badges","comments":["wondering why no answer mentions the case when element is moved away from the visible window, like top:-1000px... Guess it's an edge-case"]},{"answer":"Often when checking if something is visible or not, you are going to go right ahead immediately and do something else with it. jQuery chaining makes this easy.\n\nSo if you have a selector and you want to perform some action on it only if is visible or hidden, you can use filter(\":visible\") or filter(\":hidden\") followed by chaining it with the action you want to take.\n\nSo instead of an if statement, like this:\n\nif ($('#btnUpdate').is(\":visible\"))\n{\n     $('#btnUpdate').animate({ width: \"toggle\" });   // Hide button\n}\n\n\nOr more efficient, but even uglier:\n\nvar button = $('#btnUpdate');\nif (button.is(\":visible\"))\n{\n     button.animate({ width: \"toggle\" });   // Hide button\n}\n\n\nYou can do it all in one line:\n\n$('#btnUpdate').filter(\":visible\").animate({ width: \"toggle\" });\n\nShare\nImprove this answer\nFollow\nedited Apr 27 '15 at 20:10\necarrizo\n2,68815\n15 silver badges\n27\n27 bronze badges\nanswered Jul 25 '09 at 10:21\nSimon_Weaver\n123k73\n73 gold badges\n587\n587 silver badges\n628\n628 bronze badges","comments":["No reason to extract the DOM node in the snippet used in the example, and then have to look it back up again. Better to just do: var $button = $('#btnUpdate'); And then in the If expressions just use $button instead of $(button). Has the advantage of caching the jQuery object.","here's is a simple example jquerypot.com/…"]},{"answer":"The :visible selector according to the jQuery documentation:\n\nThey have a CSS display value of none.\nThey are form elements with type=\"hidden\".\nTheir width and height are explicitly set to 0.\nAn ancestor element is hidden, so the element is not shown on the page.\n\nElements with visibility: hidden or opacity: 0 are considered to be visible, since they still consume space in the layout.\n\nThis is useful in some cases and useless in others, because if you want to check if the element is visible (display != none), ignoring the parents visibility, you will find that doing .css(\"display\") == 'none' is not only faster, but will also return the visibility check correctly.\n\nIf you want to check visibility instead of display, you should use: .css(\"visibility\") == \"hidden\".\n\nAlso take into consideration the additional jQuery notes:\n\nBecause :visible is a jQuery extension and not part of the CSS specification, queries using :visible cannot take advantage of the performance boost provided by the native DOM querySelectorAll() method. To achieve the best performance when using :visible to select elements, first select the elements using a pure CSS selector, then use .filter(\":visible\").\n\nAlso, if you are concerned about performance, you should check Now you see me… show/hide performance (2010-05-04). And use other methods to show and hide elements.\n\nShare\nImprove this answer\nFollow\nedited Jun 21 '17 at 1:41\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered Nov 25 '11 at 9:16\nPedro Rainho\n4,0461\n1 gold badge\n16\n16 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"How element visibility and jQuery works;\n\nAn element could be hidden with display:none, visibility:hidden or opacity:0. The difference between those methods:\n\ndisplay:none hides the element, and it does not take up any space;\nvisibility:hidden hides the element, but it still takes up space in the layout;\n\nopacity:0 hides the element as \"visibility:hidden\", and it still takes up space in the layout; the only difference is that opacity lets one to make an element partly transparent;\n\nif ($('.target').is(':hidden')) {\n  $('.target').show();\n} else {\n  $('.target').hide();\n}\nif ($('.target').is(':visible')) {\n  $('.target').hide();\n} else {\n  $('.target').show();\n}\n\nif ($('.target-visibility').css('visibility') == 'hidden') {\n  $('.target-visibility').css({\n    visibility: \"visible\",\n    display: \"\"\n  });\n} else {\n  $('.target-visibility').css({\n    visibility: \"hidden\",\n    display: \"\"\n  });\n}\n\nif ($('.target-visibility').css('opacity') == \"0\") {\n  $('.target-visibility').css({\n    opacity: \"1\",\n    display: \"\"\n  });\n} else {\n  $('.target-visibility').css({\n    opacity: \"0\",\n    display: \"\"\n  });\n}\n\n\nUseful jQuery toggle methods:\n\n$('.click').click(function() {\n  $('.target').toggle();\n});\n\n$('.click').click(function() {\n  $('.target').slideToggle();\n});\n\n$('.click').click(function() {\n  $('.target').fadeToggle();\n});\n\nShare\nImprove this answer\nFollow\nedited Jul 30 '17 at 22:00\nEugen\n5006\n6 silver badges\n14\n14 bronze badges\nanswered Apr 24 '12 at 21:04\nwebvitaly\n4,0327\n7 gold badges\n28\n28 silver badges\n46\n46 bronze badges","comments":["Another difference between visibility:hidden and opacity:0 is that the element will still respond to events (like clicks) with opacity:0. I learned that trick making a custom button for file uploads.","also if you hide input with opacity:0, it still gets selected with tab key"]},{"answer":"This works for me, and I am using show() and hide() to make my div hidden/visible:\n\nif( $(this).css('display') == 'none' ){\n    /* your code goes here */\n} else {\n    /* alternate logic   */\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 14 '15 at 21:32\nwebvitaly\n4,0327\n7 gold badges\n28\n28 silver badges\n46\n46 bronze badges\nanswered Jul 6 '11 at 20:19\nAbiy\n2,2831\n1 gold badge\n12\n12 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"You can also do this using plain JavaScript:\n\nfunction isRendered(domObj) {\n    if ((domObj.nodeType != 1) || (domObj == document.body)) {\n        return true;\n    }\n    if (domObj.currentStyle && domObj.currentStyle[\"display\"] != \"none\" && domObj.currentStyle[\"visibility\"] != \"hidden\") {\n        return isRendered(domObj.parentNode);\n    } else if (window.getComputedStyle) {\n        var cs = document.defaultView.getComputedStyle(domObj, null);\n        if (cs.getPropertyValue(\"display\") != \"none\" && cs.getPropertyValue(\"visibility\") != \"hidden\") {\n            return isRendered(domObj.parentNode);\n        }\n    }\n    return false;\n}\n\n\nNotes:\n\nWorks everywhere\n\nWorks for nested elements\n\nWorks for CSS and inline styles\n\nDoesn't require a framework\n\nShare\nImprove this answer\nFollow\nedited Mar 19 '14 at 8:15\nLucas\n15.8k27\n27 gold badges\n100\n100 silver badges\n171\n171 bronze badges\nanswered Jul 16 '12 at 19:18\nMatt Brock\n5,1331\n1 gold badge\n24\n24 silver badges\n26\n26 bronze badges","comments":["Works slightly differently to jQuery's; it considers visibility: hidden to be visible.","It's easy enough to change the code above to mimic the (arguably stupid) jQuery behavior. . . . . function isRendered(o){if((o.nodeType!=1)||(o==document.body)){return true;}if(o.currentStyle&&o.currentStyle[\"display\"]!=\"none\"){return isRendered(o.parentNode);}else if(window.getComputedStyle){if(document.defaultView.getComputedStyle(o, null).getPropertyValue(\"display\")!=\"none\"){return isRendered(o.parentNode);}}return false;}","Sure, I was just adding that for the benefit of users who used this without scanning its code. :)"]},{"answer":"I would use CSS class .hide { display: none!important; }.\n\nFor hiding/showing, I call .addClass(\"hide\")/.removeClass(\"hide\"). For checking visibility, I use .hasClass(\"hide\").\n\nIt's a simple and clear way to check/hide/show elements, if you don't plan to use .toggle() or .animate() methods.\n\nShare\nImprove this answer\nFollow\nedited Mar 19 '14 at 8:15\nLucas\n15.8k27\n27 gold badges\n100\n100 silver badges\n171\n171 bronze badges\nanswered Feb 3 '12 at 16:04\nEvgeny Levin\n6,0834\n4 gold badges\n43\n43 silver badges\n78\n78 bronze badges","comments":[".hasClass('hide') doesn't check if an ancestor of the parent is hidden (which would make it hidden too). You could possibly get this to work correctly by checking if .closest('.hide').length > 0, but why reinvent the wheel?","Variant you propose returns if element visible on html, my variant returns if element was directly hidden by your javascript code/view engine. If your know that parent elements should never be hidden - use .hasClass() to be more strict and prevent future bugs. If you want to check not only visibility but element state set too - use .hasClass() too. In other cases .closest() is better.","Why dont you just use .is(\":visible\")?"]},{"answer":"Demo Link\n\n$('#clickme').click(function() {\n  $('#book').toggle('slow', function() {\n    // Animation complete.\n    alert($('#book').is(\":visible\")); //<--- TRUE if Visible False if Hidden\n  });\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div id=\"clickme\">\n  Click here\n</div>\n<img id=\"book\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/87/Google_Chrome_icon_%282011%29.png\" alt=\"\" width=\"300\"/>\n Run code snippetExpand snippet\n\nSource (from my blog):\n\nBlogger Plug n Play - jQuery Tools and Widgets: How to See if Element is hidden or Visible Using jQuery\n\nShare\nImprove this answer\nFollow\nedited May 31 at 21:24\nJean-François Fabre♦\n128k22\n22 gold badges\n107\n107 silver badges\n171\n171 bronze badges\nanswered Jan 25 '13 at 5:34\nCode Spy\n7,8604\n4 gold badges\n58\n58 silver badges\n40\n40 bronze badges","comments":["@Adrew but this link is showing working example of this function. I think a practical answer may weight over a full page of text :)"]},{"answer":"One can simply use the hidden or visible attribute, like:\n\n$('element:hidden')\n$('element:visible')\n\n\nOr you can simplify the same with is as follows.\n\n$(element).is(\":visible\")\n\nShare\nImprove this answer\nFollow\nedited Mar 16 '13 at 10:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 23 '12 at 12:59\nScoRpion\n11k24\n24 gold badges\n63\n63 silver badges\n87\n87 bronze badges","comments":[]},{"answer":"ebdiv should be set to style=\"display:none;\". It works for both show and hide:\n\n$(document).ready(function(){\n    $(\"#eb\").click(function(){\n        $(\"#ebdiv\").toggle();\n    });    \n});\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '18 at 7:33\nCommunity♦\n11\n1 silver badge\nanswered Jun 13 '12 at 13:20\nVaishu\n2,2253\n3 gold badges\n20\n20 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"Another answer you should put into consideration is if you are hiding an element, you should use jQuery, but instead of actually hiding it, you remove the whole element, but you copy its HTML content and the tag itself into a jQuery variable, and then all you need to do is test if there is such a tag on the screen, using the normal if (!$('#thetagname').length).\n\nShare\nImprove this answer\nFollow\nedited Mar 26 '13 at 22:12\nanswered Apr 21 '12 at 23:40\nLucas\n15.8k27\n27 gold badges\n100\n100 silver badges\n171\n171 bronze badges","comments":[]},{"answer":"When testing an element against :hidden selector in jQuery it should be considered that an absolute positioned element may be recognized as hidden although their child elements are visible.\n\nThis seems somewhat counter-intuitive in the first place – though having a closer look at the jQuery documentation gives the relevant information:\n\nElements can be considered hidden for several reasons: [...] Their width and height are explicitly set to 0. [...]\n\nSo this actually makes sense in regards to the box-model and the computed style for the element. Even if width and height are not set explicitly to 0 they may be set implicitly.\n\nHave a look at the following example:\n\nconsole.log($('.foo').is(':hidden')); // true\nconsole.log($('.bar').is(':hidden')); // false\n.foo {\n  position: absolute;\n  left: 10px;\n  top: 10px;\n  background: #ff0000;\n}\n\n.bar {\n  position: absolute;\n  left: 10px;\n  top: 10px;\n  width: 20px;\n  height: 20px;\n  background: #0000ff;\n}\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div class=\"foo\">\n  <div class=\"bar\"></div>\n</div>\n Run code snippetExpand snippet\n\nUpdate for jQuery 3.x:\n\nWith jQuery 3 the described behavior will change! Elements will be considered visible if they have any layout boxes, including those of zero width and/or height.\n\nJSFiddle with jQuery 3.0.0-alpha1:\n\nhttp://jsfiddle.net/pM2q3/7/\n\nThe same JavaScript code will then have this output:\n\nconsole.log($('.foo').is(':hidden')); // false\nconsole.log($('.bar').is(':hidden')); // false\n\nShare\nImprove this answer\nFollow\nedited May 6 '20 at 13:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 6 '14 at 10:50\nconceptdeluxe\n3,4163\n3 gold badges\n20\n20 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"This may work:\n\nexpect($(\"#message_div\").css(\"display\")).toBe(\"none\");\n\nShare\nImprove this answer\nFollow\nedited Mar 6 '13 at 6:41\nLucas\n15.8k27\n27 gold badges\n100\n100 silver badges\n171\n171 bronze badges\nanswered Jul 20 '12 at 12:44\nManeesh Kumar\n1,2671\n1 gold badge\n9\n9 silver badges\n13\n13 bronze badges","comments":["What language/dialect/library is this? I'm not familiar with this syntax in JS..."]},{"answer":"Example:\n\n$(document).ready(function() {\n  if ($(\"#checkme:hidden\").length) {\n    console.log('Hidden');\n  }\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div id=\"checkme\" class=\"product\" style=\"display:none\">\n  <span class=\"itemlist\"><!-- Shows Results for Fish --></span> Category:Fish\n  <br>Product: Salmon Atlantic\n  <br>Specie: Salmo salar\n  <br>Form: Steaks\n</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jul 16 '17 at 13:52\ndippas\n50k15\n15 gold badges\n95\n95 silver badges\n108\n108 bronze badges\nanswered Oct 28 '13 at 6:43\nIrfan DANISH\n7,58711\n11 gold badges\n35\n35 silver badges\n64\n64 bronze badges","comments":[]},{"answer":"To check if it is not visible I use !:\n\nif ( !$('#book').is(':visible')) {\n    alert('#book is not visible')\n}\n\n\nOr the following is also the sam, saving the jQuery selector in a variable to have better performance when you need it multiple times:\n\nvar $book = $('#book')\n\nif(!$book.is(':visible')) {\n    alert('#book is not visible')\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 14 '13 at 8:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 4 '13 at 13:42\nMatthias Wegtun\n1,2119\n9 silver badges\n13\n13 bronze badges","comments":["How did you determined that saving a selector in variable is really faster?","Hi @Ilia Rostovtsev jsperf.com/caching-jquery-selectors There you can run the test. Anyways it's nice to have it cached so it can be accessed faster","This is suitable if you want to use a single variable through out the process instead of calling and calling the same object."]},{"answer":"Use class toggling, not style editing . . .\n\nUsing classes designated for \"hiding\" elements is easy and also one of the most efficient methods. Toggling a class 'hidden' with a Display style of 'none' will perform faster than editing that style directly. I explained some of this pretty thoroughly in Stack Overflow question Turning two elements visible/hidden in the same div.\n\nJavaScript Best Practices and Optimization\n\nHere is a truly enlightening video of a Google Tech Talk by Google front-end engineer Nicholas Zakas:\n\nSpeed Up Your Javascript (YouTube)\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jul 18 '13 at 21:17\nLopsided\n3,6891\n1 gold badge\n23\n23 silver badges\n44\n44 bronze badges","comments":[]},{"answer":"Example of using the visible check for adblocker is activated:\n\n$(document).ready(function(){\n  if(!$(\"#ablockercheck\").is(\":visible\"))\n    $(\"#ablockermsg\").text(\"Please disable adblocker.\").show();\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div class=\"ad-placement\" id=\"ablockercheck\"></div>\n<div id=\"ablockermsg\" style=\"display: none\"></div>\n Run code snippetExpand snippet\n\n\"ablockercheck\" is a ID which adblocker blocks. So checking it if it is visible you are able to detect if adblocker is turned On.\n\nShare\nImprove this answer\nFollow\nedited Sep 13 '16 at 14:07\nCameron\n25.3k91\n91 gold badges\n264\n264 silver badges\n456\n456 bronze badges\nanswered Apr 27 '15 at 7:57\nRoman Losev\n1,79218\n18 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"After all, none of examples suits me, so I wrote my own.\n\nTests (no support of Internet Explorer filter:alpha):\n\na) Check if the document is not hidden\n\nb) Check if an element has zero width / height / opacity or display:none / visibility:hidden in inline styles\n\nc) Check if the center (also because it is faster than testing every pixel / corner) of element is not hidden by other element (and all ancestors, example: overflow:hidden / scroll / one element over another) or screen edges\n\nd) Check if an element has zero width / height / opacity or display:none / visibility:hidden in computed styles (among all ancestors)\n\nTested on\n\nAndroid 4.4 (Native browser/Chrome/Firefox), Firefox (Windows/Mac), Chrome (Windows/Mac), Opera (Windows Presto/Mac WebKit), Internet Explorer (Internet Explorer 5-11 document modes + Internet Explorer 8 on a virtual machine), and Safari (Windows/Mac/iOS).\n\nvar is_visible = (function () {\n    var x = window.pageXOffset ? window.pageXOffset + window.innerWidth - 1 : 0,\n        y = window.pageYOffset ? window.pageYOffset + window.innerHeight - 1 : 0,\n        relative = !!((!x && !y) || !document.elementFromPoint(x, y));\n        function inside(child, parent) {\n            while(child){\n                if (child === parent) return true;\n                child = child.parentNode;\n            }\n        return false;\n    };\n    return function (elem) {\n        if (\n            document.hidden ||\n            elem.offsetWidth==0 ||\n            elem.offsetHeight==0 ||\n            elem.style.visibility=='hidden' ||\n            elem.style.display=='none' ||\n            elem.style.opacity===0\n        ) return false;\n        var rect = elem.getBoundingClientRect();\n        if (relative) {\n            if (!inside(document.elementFromPoint(rect.left + elem.offsetWidth/2, rect.top + elem.offsetHeight/2),elem)) return false;\n        } else if (\n            !inside(document.elementFromPoint(rect.left + elem.offsetWidth/2 + window.pageXOffset, rect.top + elem.offsetHeight/2 + window.pageYOffset), elem) ||\n            (\n                rect.top + elem.offsetHeight/2 < 0 ||\n                rect.left + elem.offsetWidth/2 < 0 ||\n                rect.bottom - elem.offsetHeight/2 > (window.innerHeight || document.documentElement.clientHeight) ||\n                rect.right - elem.offsetWidth/2 > (window.innerWidth || document.documentElement.clientWidth)\n            )\n        ) return false;\n        if (window.getComputedStyle || elem.currentStyle) {\n            var el = elem,\n                comp = null;\n            while (el) {\n                if (el === document) {break;} else if(!el.parentNode) return false;\n                comp = window.getComputedStyle ? window.getComputedStyle(el, null) : el.currentStyle;\n                if (comp && (comp.visibility=='hidden' || comp.display == 'none' || (typeof comp.opacity !=='undefined' && comp.opacity != 1))) return false;\n                el = el.parentNode;\n            }\n        }\n        return true;\n    }\n})();\n\n\nHow to use:\n\nis_visible(elem) // boolean\n\nShare\nImprove this answer\nFollow\nedited May 6 '20 at 13:44\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 9 '14 at 17:06\nAleko\n9301\n1 gold badge\n9\n9 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"You need to check both... Display as well as visibility:\n\nif ($(this).css(\"display\") == \"none\" || $(this).css(\"visibility\") == \"hidden\") {\n    // The element is not visible\n} else {\n    // The element is visible\n}\n\n\nIf we check for $(this).is(\":visible\"), jQuery checks for both the things automatically.\n\nShare\nImprove this answer\nFollow\nedited Jul 19 '14 at 15:23\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 31 '14 at 6:24\nPremshankar Tiwari\n2,8823\n3 gold badges\n20\n20 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"Maybe you can do something like this\n\n$(document).ready(function() {\n   var visible = $('#tElement').is(':visible');\n\n   if(visible) {\n      alert(\"visible\");\n                    // Code\n   }\n   else\n   {\n      alert(\"hidden\");\n   }\n});\n<script src=\"https://code.jquery.com/jquery-1.10.2.js\"></script>\n\n<input type=\"text\" id=\"tElement\" style=\"display:block;\">Firstname</input>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited May 2 '16 at 12:59\nAbrar Jahin\n12.4k20\n20 gold badges\n94\n94 silver badges\n144\n144 bronze badges\nanswered Apr 7 '15 at 12:26\nMathias Stavrou\n7511\n1 gold badge\n7\n7 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"Simply check visibility by checking for a boolean value, like:\n\nif (this.hidden === false) {\n    // Your code\n}\n\n\nI used this code for each function. Otherwise you can use is(':visible') for checking the visibility of an element.\n\nShare\nImprove this answer\nFollow\nedited Jul 16 '17 at 13:56\ndippas\n50k15\n15 gold badges\n95\n95 silver badges\n108\n108 bronze badges\nanswered Aug 11 '14 at 5:28\npixellabme\n5254\n4 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"Because Elements with visibility: hidden or opacity: 0 are considered visible, since they still consume space in the layout (as described for jQuery :visible Selector) - we can check if element is really visible in this way:\n\nfunction isElementReallyHidden (el) {\n    return $(el).is(\":hidden\") || $(el).css(\"visibility\") == \"hidden\" || $(el).css('opacity') == 0;\n}\n\nvar booElementReallyShowed = !isElementReallyHidden(someEl);\n$(someEl).parents().each(function () {\n    if (isElementReallyHidden(this)) {\n        booElementReallyShowed = false;\n    }\n});\n\nShare\nImprove this answer\nFollow\nedited Mar 20 '14 at 10:32\nanswered Mar 19 '14 at 12:42\nAndron\n5,8674\n4 gold badges\n39\n39 silver badges\n48\n48 bronze badges","comments":[]},{"answer":"But what if the element's CSS is like the following?\n\n.element{\n    position: absolute;left:-9999;    \n}\n\n\nSo this answer to Stack Overflow question How to check if an element is off-screen should also be considered.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:55\nCommunity♦\n11\n1 silver badge\nanswered Aug 23 '14 at 20:53\nRN Kushwaha\n1,9153\n3 gold badges\n26\n26 silver badges\n37\n37 bronze badges","comments":[]},{"answer":"A function can be created in order to check for visibility/display attributes in order to gauge whether the element is shown in the UI or not.\n\nfunction checkUIElementVisible(element) {\n    return ((element.css('display') !== 'none') && (element.css('visibility') !== 'hidden'));\n}\n\n\nWorking Fiddle\n\nShare\nImprove this answer\nFollow\nedited Nov 22 '14 at 11:23\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 29 '14 at 20:20\nV31\n7,5183\n3 gold badges\n24\n24 silver badges\n44\n44 bronze badges","comments":[]},{"answer":"Also here's a ternary conditional expression to check the state of the element and then to toggle it:\n\n$('someElement').on('click', function(){ $('elementToToggle').is(':visible') ? $('elementToToggle').hide('slow') : $('elementToToggle').show('slow'); });\n\nShare\nImprove this answer\nFollow\nanswered Nov 5 '13 at 23:32\ncssimsek\n1,18913\n13 silver badges\n17\n17 bronze badges","comments":["Or, y'kno, just get rid of the entire conditional and say $('elementToToggle').toggle('slow');... :)"]},{"answer":"if($('#postcode_div').is(':visible')) {\n    if($('#postcode_text').val()=='') {\n        $('#spanPost').text('\\u00a0');\n    } else {\n        $('#spanPost').text($('#postcode_text').val());\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 7 '13 at 13:51\ndcodesmith\n9,3454\n4 gold badges\n37\n37 silver badges\n38\n38 bronze badges\nanswered Nov 15 '13 at 10:41\nGaurav\n4035\n5 silver badges\n9\n9 bronze badges","comments":[]}]},{"id":"1335851","href":"https://stackoverflow.com/questions/1335851/what-does-use-strict-do-in-javascript-and-what-is-the-reasoning-behind-it","title":"What does “use strict” do in JavaScript, and what is the reasoning behind it?","description":"\n                \nRecently, I ran some of my JavaScript code through Crockford's JSLint, and it gave the following error:\n\n\n  Problem at line 1 character 1: Missing \"use strict\" statement.\n\n\nDoing some searching, I realized that some people add \"use strict\"; into their JavaScript code. Once I added the statement, the error stopped appearing. Unfortunately, Google did not reveal much of the history behind this string statement. Certainly it must have something to do with how the JavaScript is interpreted by the browser, but I have no idea what the effect would be.\n\nSo what is \"use strict\"; all about, what does it imply, and is it still relevant?\n\nDo any of the current browsers respond to the \"use strict\"; string or is it for future use?\n    ","questionComments":["The answers here are old but they are wrong. The main reasoning for strict mode was not to prevent programming errors - it was to make JavaScript lexically scoped so it could be statically analysable :]"],"answers":[{"answer":"This article about Javascript Strict Mode might interest you: John Resig - ECMAScript 5 Strict Mode, JSON, and More\n\nTo quote some interesting parts:\n\nStrict Mode is a new feature in ECMAScript 5 that allows you to place a program, or a function, in a \"strict\" operating context. This strict context prevents certain actions from being taken and throws more exceptions.\n\nAnd:\n\nStrict mode helps out in a couple ways:\n\nIt catches some common coding bloopers, throwing exceptions.\nIt prevents, or throws errors, when relatively \"unsafe\" actions are taken (such as gaining access to the global object).\nIt disables features that are confusing or poorly thought out.\n\nAlso note you can apply \"strict mode\" to the whole file... Or you can use it only for a specific function (still quoting from John Resig's article):\n\n// Non-strict code...\n\n(function(){\n  \"use strict\";\n\n  // Define your library strictly...\n})();\n\n// Non-strict code...\n\n\nWhich might be helpful if you have to mix old and new code ;-)\n\nSo, I suppose it's a bit like the \"use strict\" you can use in Perl (hence the name?): it helps you make fewer errors, by detecting more things that could lead to breakages.\n\nStrict mode is now supported by all major browsers.\n\nInside native ECMAScript modules (with import and export statements) and ES6 classes, strict mode is always enabled and cannot be disabled.\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 4:11\nashleedawg\n17.6k5\n5 gold badges\n60\n60 silver badges\n83\n83 bronze badges\nanswered Aug 26 '09 at 16:15\nPascal MARTIN\n377k74\n74 gold badges\n635\n635 silver badges\n650\n650 bronze badges","comments":[]},{"answer":"It's a new feature of ECMAScript 5. John Resig wrote up a nice summary of it.\n\nIt's just a string you put in your JavaScript files (either at the top of your file or inside of a function) that looks like this:\n\n\"use strict\";\n\n\nPutting it in your code now shouldn't cause any problems with current browsers as it's just a string. It may cause problems with your code in the future if your code violates the pragma. For instance, if you currently have foo = \"bar\" without defining foo first, your code will start failing...which is a good thing in my opinion.\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '14 at 10:31\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 26 '09 at 16:14\nseth\n35k7\n7 gold badges\n58\n58 silver badges\n57\n57 bronze badges","comments":[]},{"answer":"The statement \"use strict\";  instructs the browser to use the Strict mode, which is a reduced and safer feature set of JavaScript.\n\nList of features (non-exhaustive)\n\nDisallows global variables. (Catches missing var declarations and typos in variable names)\n\nSilent failing assignments will throw error in strict mode (assigning NaN = 5;)\n\nAttempts to delete undeletable properties will throw (delete Object.prototype)\n\nRequires all property names in an object literal to be unique (var x = {x1: \"1\", x1: \"2\"})\n\nFunction parameter names must be unique (function sum (x, x) {...})\n\nForbids octal syntax (var x = 023; some devs assume wrongly that a preceding zero does nothing to change the number.)\n\nForbids the with keyword\n\neval in strict mode does not introduce new variables\n\nForbids deleting plain names (delete x;)\n\nForbids binding or assignment of the names eval and arguments in any form\n\nStrict mode does not alias properties of the arguments object with the formal parameters. (e.g. in function sum (a,b) { return arguments[0] + b;} This works because arguments[0] is bound to a and so on. )\n\narguments.callee is not supported\n\n[Ref: Strict mode, Mozilla Developer Network]\n\nShare\nImprove this answer\nFollow\nedited Mar 11 at 23:34\nRobG\n127k30\n30 gold badges\n158\n158 silver badges\n192\n192 bronze badges\nanswered Nov 24 '14 at 21:22\ngprasant\n13.8k8\n8 gold badges\n40\n40 silver badges\n56\n56 bronze badges","comments":["The example for 11. is unclear, it's not clear what the difference in strict mode is."]},{"answer":"If people are worried about using use strict it might be worth checking out this article:\n\nECMAScript 5 'Strict mode' support in browsers. What does this mean?\nNovoGeek.com - Krishna's weblog\n\nIt talks about browser support, but more importantly how to deal with it safely:\n\nfunction isStrictMode(){\n    return !this;\n} \n/*\n   returns false, since 'this' refers to global object and \n   '!this' becomes false\n*/\n\nfunction isStrictMode(){   \n    \"use strict\";\n    return !this;\n} \n/* \n   returns true, since in strict mode the keyword 'this'\n   does not refer to global object, unlike traditional JS. \n   So here, 'this' is 'undefined' and '!this' becomes true.\n*/\n\nShare\nImprove this answer\nFollow\nedited Jan 22 '18 at 11:13\nCommunity♦\n11\n1 silver badge\nanswered Jul 15 '12 at 23:25\nJamie Hutber\n23.5k37\n37 gold badges\n138\n138 silver badges\n237\n237 bronze badges","comments":[]},{"answer":"A word of caution, all you hard-charging programmers: applying \"use strict\" to existing code can be hazardous! This thing is not some feel-good, happy-face sticker that you can slap on the code to make it 'better'. With the \"use strict\" pragma, the browser will suddenly THROW exceptions in random places that it never threw before just because at that spot you are doing something that default/loose JavaScript happily allows but strict JavaScript abhors! You may have strictness violations hiding in seldom used calls in your code that will only throw an exception when they do eventually get run - say, in the production environment that your paying customers use!\n\nIf you are going to take the plunge, it is a good idea to apply \"use strict\" alongside comprehensive unit tests and a strictly configured JSHint build task that will give you some confidence that there is no dark corner of your module that will blow up horribly just because you've turned on Strict Mode. Or, hey, here's another option: just don't add \"use strict\" to any of your legacy code, it's probably safer that way, honestly. DEFINITELY DO NOT add \"use strict\" to any modules you do not own or maintain, like third party modules.\n\nI think even though it is a deadly caged animal, \"use strict\" can be good stuff, but you have to do it right. The best time to go strict is when your project is greenfield and you are starting from scratch. Configure JSHint/JSLint with all the warnings and options cranked up as tight as your team can stomach, get a good build/test/assert system du jour rigged like Grunt+Karma+Chai, and only THEN start marking all your new modules as \"use strict\". Be prepared to cure lots of niggly errors and warnings. Make sure everyone understands the gravity by configuring the build to FAIL if JSHint/JSLint produces any violations.\n\nMy project was not a greenfield project when I adopted \"use strict\". As a result, my IDE is full of red marks because I don't have \"use strict\" on half my modules, and JSHint complains about that. It's a reminder to me about what refactoring I should do in the future. My goal is to be red mark free due to all of my missing \"use strict\" statements, but that is years away now.\n\nShare\nImprove this answer\nFollow\nedited Oct 16 '16 at 9:10\nAtaur Rahman Munna\n3,6461\n1 gold badge\n23\n23 silver badges\n31\n31 bronze badges\nanswered Mar 3 '14 at 7:37\nDWoldrich\n3,4651\n1 gold badge\n17\n17 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"Using 'use strict'; does not suddenly make your code better.\n\nThe JavaScript strict mode is a feature in ECMAScript 5. You can enable the strict mode by declaring this in the top of your script/function.\n\n'use strict';\n\n\nWhen a JavaScript engine sees this directive, it will start to interpret the code in a special mode. In this mode, errors are thrown up when certain coding practices that could end up being potential bugs are detected (which is the reasoning behind the strict mode).\n\nConsider this example:\n\nvar a = 365;\nvar b = 030;\n\n\nIn their obsession to line up the numeric literals, the developer has inadvertently initialized variable b with an octal literal. Non-strict mode will interpret this as a numeric literal with value 24 (in base 10). However, strict mode will throw an error.\n\nFor a non-exhaustive list of specialties in strict mode, see this answer.\n\nWhere should I use 'use strict';?\n\nIn my new JavaScript application: Absolutely! Strict mode can be used as a whistleblower when you are doing something stupid with your code.\n\nIn my existing JavaScript code: Probably not! If your existing JavaScript code has statements that are prohibited in strict-mode, the application will simply break. If you want strict mode, you should be prepared to debug and correct your existing code. This is why using 'use strict'; does not suddenly make your code better.\n\nHow do I use strict mode?\n\nInsert a 'use strict'; statement on top of your script:\n\n// File: myscript.js\n\n'use strict';\nvar a = 2;\n....\n\n\nNote that everything in the file myscript.js will be interpreted in strict mode.\n\nOr, insert a 'use strict'; statement on top of your function body:\n\nfunction doSomething() {\n    'use strict';\n    ...\n}\n\n\nEverything in the lexical scope of function doSomething will be interpreted in strict mode. The word lexical scope is important here. For example, if your strict code calls a function of a library that is not strict, only your code is executed in strict mode, and not the called function. See this answer for a better explanation.\n\nWhat things are prohibited in strict mode?\n\nI found a nice article describing several things that are prohibited in strict mode (note that this is not an exclusive list):\n\nScope\n\nHistorically, JavaScript has been confused about how functions are scoped. Sometimes they seem to be statically scoped, but some features make them behave like they are dynamically scoped. This is confusing, making programs difficult to read and understand. Misunderstanding causes bugs. It also is a problem for performance. Static scoping would permit variable binding to happen at compile time, but the requirement for dynamic scope means the binding must be deferred to runtime, which comes with a significant performance penalty.\n\nStrict mode requires that all variable binding be done statically. That means that the features that previously required dynamic binding must be eliminated or modified. Specifically, the with statement is eliminated, and the eval function’s ability to tamper with the environment of its caller is severely restricted.\n\nOne of the benefits of strict code is that tools like YUI Compressor can do a better job when processing it.\n\nImplied Global Variables\n\nJavaScript has implied global variables. If you do not explicitly declare a variable, a global variable is implicitly declared for you. This makes programming easier for beginners because they can neglect some of their basic housekeeping chores. But it makes the management of larger programs much more difficult and it significantly degrades reliability. So in strict mode, implied global variables are no longer created. You should explicitly declare all of your variables.\n\nGlobal Leakage\n\nThere are a number of situations that could cause this to be bound to the global object. For example, if you forget to provide the new prefix when calling a constructor function, the constructor's this will be bound unexpectedly to the global object, so instead of initializing a new object, it will instead be silently tampering with global variables. In these situations, strict mode will instead bind this to undefined, which will cause the constructor to throw an exception instead, allowing the error to be detected much sooner.\n\nNoisy Failure\n\nJavaScript has always had read-only properties, but you could not create them yourself until ES5’s Object.createProperty function exposed that capability. If you attempted to assign a value to a read-only property, it would fail silently. The assignment would not change the property’s value, but your program would proceed as though it had. This is an integrity hazard that can cause programs to go into an inconsistent state. In strict mode, attempting to change a read-only property will throw an exception.\n\nOctal\n\nThe octal (or base 8) representation of numbers was extremely useful when doing machine-level programming on machines whose word sizes were a multiple of 3. You needed octal when working with the CDC 6600 mainframe, which had a word size of 60 bits. If you could read octal, you could look at a word as 20 digits. Two digits represented the op code, and one digit identified one of 8 registers. During the slow transition from machine codes to high level languages, it was thought to be useful to provide octal forms in programming languages.\n\nIn C, an extremely unfortunate representation of octalness was selected: Leading zero. So in C, 0100 means 64, not 100, and 08 is an error, not 8. Even more unfortunately, this anachronism has been copied into nearly all modern languages, including JavaScript, where it is only used to create errors. It has no other purpose. So in strict mode, octal forms are no longer allowed.\n\nEt cetera\n\nThe arguments pseudo array becomes a little bit more array-like in ES5. In strict mode, it loses its callee and caller properties. This makes it possible to pass your arguments to untrusted code without giving up a lot of confidential context. Also, the arguments property of functions is eliminated.\n\nIn strict mode, duplicate keys in a function literal will produce a syntax error. A function can’t have two parameters with the same name. A function can’t have a variable with the same name as one of its parameters. A function can’t delete its own variables. An attempt to delete a non-configurable property now throws an exception. Primitive values are not implicitly wrapped.\n\nReserved words for future JavaScript versions\n\nECMAScript 5 adds a list of reserved words. If you use them as variables or arguments, strict mode will throw an error. The reserved words are:\n\nimplements, interface, let, package, private, protected, public, static, and yield\n\nFurther Reading\nStrict Mode - JavaScript | MDN\nBrowser support for strict mode\nTransitioning to strict mode\nShare\nImprove this answer\nFollow\nedited Nov 27 '19 at 6:08\nanswered Jan 29 '16 at 11:35\nsampathsris\n19.5k11\n11 gold badges\n60\n60 silver badges\n91\n91 bronze badges","comments":[]},{"answer":"I strongly recommend every developer to start using strict mode now. There are enough browsers supporting it that strict mode will legitimately help save us from errors we didn’t even know were in your code.\n\nApparently, at the initial stage there will be errors we have never encountered before. To get the full benefit, we need to do proper testing after switching to strict mode to make sure we have caught everything. Definitely we don’t just throw use strict in our code and assume there are no errors. So the churn is that it’s time to start using this incredibly useful language feature to write better code.\n\nFor example,\n\nvar person = {\n    name : 'xyz',\n    position : 'abc',\n    fullname : function () {  \"use strict\"; return this.name; }\n};\n\n\nJSLint is a debugger written by Douglas Crockford. Simply paste in your script, and it’ll quickly scan for any noticeable issues and errors in your code.\n\nShare\nImprove this answer\nFollow\nedited Feb 25 '16 at 15:54\nWilli Mentzel\n22.3k16\n16 gold badges\n92\n92 silver badges\n103\n103 bronze badges\nanswered Jul 5 '13 at 19:38\nPank\n12.1k10\n10 gold badges\n30\n30 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"I would like to offer a somewhat more founded answer complementing the other answers. I was hoping to edit the most popular answer, but failed. I tried to make it as comprehensive and complete as I could.\n\nYou can refer to the MDN documentation for more information.\n\n\"use strict\" a directive introduced in ECMAScript 5.\n\nDirectives are similar to statements, yet different.\n\nuse strict does not contain key words: The directive is a simple expression statement, which consists of a special string literal (in single or double quotes). JavaScript engines, that do not implement ECMAScript 5, merely see an expression statement without side effects. It is expected that future versions of ECMAScript standards introduce use as a real key word; the quotes would thereby become obsolete.\nuse strict can be used only at the beginning of a script or of a function, i.e. it must precede every other (real) statement. It does not have to be the first instruction in a script of function: it can be preceded by other statement expressions that consist of string literals ( and JavaScript implementations can treat them as implementation specific directives). String literals statements, which follow a first real statement (in a script or function) are simple expression statements. Interpreters must not interpret them as directives and they have no effect.\n\nThe use strict directive indicates that the following code (in a script or a function) is strict code. The code in the highest level of a script (code that is not in a function) is considered strict code when the script contains a use strict directive. The content of a function is considered strict code when the function itself is defined in a strict code or when the function contains a use strict directive. Code that is passed to an eval() method is considered strict code when eval() was called from a strict code or contains the use strict directive itself.\n\nThe strict mode of ECMAScript 5 is a restricted subset of the JavaScript language, which eliminates relevant deficits of the language and features more stringent error checking and higher security. The following lists the differences between strict mode and normal mode (of which the first three are particularly important):\n\nYou cannot use the with-statement in strict mode.\nIn strict mode all variables have to be declared: if you assign a value to an identifier that has not been declared as variable, function, function parameter, catch-clause parameter or property of the global Object, then you will get a ReferenceError. In normal mode the identifier is implicitly declared as a global variable (as a property of the global Object)\nIn strict mode the keyword this has the value undefined in functions that were invoked as functions (not as methods). (In normal mode this always points to the global Object). This difference can be used to test if an implementation supports the strict mode:\nvar hasStrictMode = (function() { \"use strict\"; return this===undefined }());\n\n\nAlso when a function is invoked with call() or apply in strict mode, then this is exactly the value of the first argument of the call()or apply() invocation. (In normal mode null and undefined are replaced by the global Object and values, which are not objects, are cast into objects.)\n\nIn strict mode you will get a TypeError, when you try to assign to readonly properties or to define new properties for a non extensible object. (In normal mode both simply fail without error message.)\n\nIn strict mode, when passing code to eval(), you cannot declare or define variables or functions in the scope of the caller (as you can do it in normal mode). Instead, a new scope is created for eval() and the variables and functions are within that scope. That scope is destroyed after eval() finishes execution.\nIn strict mode the arguments-object of a function contains a static copy of the values, which are passed to that function. In normal mode the arguments-object has a somewhat \"magical\" behaviour: The elements of the array and the named function parameters reference both the same value.\nIn strict mode you will get a SyntaxError when the delete operator is followed by a non qualified identifier (a variable, function or function parameter). In normal mode the delete expression would do nothing and is evaluated to false.\nIn strict mode you will get a TypeError when you try to delete a non configurable property. (In normal mode the attempt simply fails and the delete expression is evaluated to false).\nIn strict mode it is considered a syntactical error when you try to define several properties with the same name for an object literal. (In normal mode there is no error.)\nIn strict mode it is considered a syntactical error when a function declaration has multiple parameters with the same name. (In normal mode there is no error.)\nIn strict mode octal literals are not allowed (these are literals that start with 0x. (In normal mode some implementations do allow octal literals.)\nIn strict mode the identifiers eval and arguments are treated like keywords. You cannot change their value, cannot assign a value to them, and you cannot use them as names for variables, functions, function parameters or identifiers of a catch block.\nIn strict mode are more restrictions on the possibilities to examine the call stack. arguments.caller and arguments.callee cause a TypeError in a function in strict mode. Furthermore, some caller- and arguments properties of functions in strict mode cause a TypeError when you try to read them.\nShare\nImprove this answer\nFollow\nedited Jul 12 '15 at 20:31\nanswered May 15 '15 at 6:58\nEly\n10.1k4\n4 gold badges\n40\n40 silver badges\n60\n60 bronze badges","comments":["\"In strict mode octal literals are not allowed (these are literals that start with 0x ...)\" octal literals start with a leading 0."]},{"answer":"My two cents:\n\nOne of the goals of strict mode is to allow for faster debugging of issues. It helps the developers by throwing exception when certain wrong things occur that can cause silent & strange behaviour of your webpage. The moment we use use strict, the code will throw out errors which helps developer to fix it in advance.\n\nFew important things which I have learned after using use strict :\n\nPrevents Global Variable Declaration:\n\nvar tree1Data = { name: 'Banana Tree',age: 100,leafCount: 100000};\n\nfunction Tree(typeOfTree) {\n    var age;\n    var leafCount;\n\n    age = typeOfTree.age;\n    leafCount = typeOfTree.leafCount;\n    nameoftree = typeOfTree.name;\n};\n\nvar tree1 = new Tree(tree1Data);\nconsole.log(window);\n\n\nNow,this code creates nameoftree in global scope which could be accessed using window.nameoftree. When we implement use strict the code would throw error.\n\nUncaught ReferenceError: nameoftree is not defined\n\nSample\n\nEliminates with statement :\n\nwith statements can't be minified using tools like uglify-js. They're also deprecated and removed from future JavaScript versions.\n\nSample\n\nPrevents Duplicates :\n\nWhen we have duplicate property, it throws an exception\n\nUncaught SyntaxError: Duplicate data property in object literal not allowed in strict mode\n\n\"use strict\";\nvar tree1Data = {\n    name: 'Banana Tree',\n    age: 100,\n    leafCount: 100000,\n    name:'Banana Tree'\n};\n\n\nThere are few more but I need to gain more knowledge on that.\n\nShare\nImprove this answer\nFollow\nanswered Oct 21 '14 at 13:31\ncommunity wiki\n\n\nShubh","comments":[]},{"answer":"If you use a browser released in the last year or so then it most likely supports JavaScript Strict mode. Only older browsers around before ECMAScript 5 became the current standard don't support it.\n\nThe quotes around the command make sure that the code will still work in older browsers as well (although the things that generate a syntax error in strict mode will generally just cause the script to malfunction in some hard to detect way in those older browsers).\n\nShare\nImprove this answer\nFollow\nanswered Mar 10 '12 at 3:31\nStephen\n7555\n5 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"When adding \"use strict\";, the following cases will throw a SyntaxError before the script is executing:\n\nPaving the way for future ECMAScript versions, using one of the newly reserved keywords (in prevision for ECMAScript 6): implements, interface, let, package, private, protected, public, static, and yield.\n\nDeclaring function in blocks\n\nif(a<b){ function f(){} }\n\n\nOctal syntax\n\nvar n = 023;\n\n\nthis point to the global object.\n\n function f() {\n      \"use strict\";\n      this.a = 1;\n };\n f(); \n\n\nDeclaring twice the same name for a property name in an object literal\n\n {a: 1, b: 3, a: 7} \n\n\nThis is no longer the case in ECMAScript 6 (bug 1041128).\n\nDeclaring two function arguments with the same name function\n\nf(a, b, b){}\n\n\nSetting a value to an undeclared variable\n\nfunction f(x){\n   \"use strict\";\n   var a = 12;\n   b = a + x*35; // error!\n}\nf();\n\n\nUsing delete on a variable name delete myVariable;\n\nUsing eval or arguments as variable or function argument name\n\n\"use strict\";\narguments++;\nvar obj = { set p(arguments) { } };\ntry { } catch (arguments) { }\nfunction arguments() { } \n\n\nSources:\n\nTransitioning to strict mode on MDN\n\nStrict mode on MDN\n\nJavaScript’s Strict Mode and Why You Should Use It on Colin J. Ihrig's blog (archived version)\n\nShare\nImprove this answer\nFollow\nedited Oct 24 '17 at 10:50\nPalec\n10.6k7\n7 gold badges\n53\n53 silver badges\n116\n116 bronze badges\nanswered Dec 23 '15 at 3:10\nzangw\n34.7k17\n17 gold badges\n132\n132 silver badges\n157\n157 bronze badges","comments":["With ECMAScript 2015 duplicate property names are allowed again! See MDN documentation."]},{"answer":"Strict mode makes several changes to normal JavaScript semantics:\n\neliminates some JavaScript silent errors by changing them to throw errors.\n\nfixes mistakes that make it difficult for JavaScript engines to perform optimizations.\n\nprohibits some syntax likely to be defined in future versions of ECMAScript.\n\nfor more information vistit Strict Mode- Javascript\n\nShare\nImprove this answer\nFollow\nedited Oct 29 '14 at 17:34\nalexyorke\n4,0923\n3 gold badges\n32\n32 silver badges\n54\n54 bronze badges\nanswered Mar 27 '14 at 12:18\nRenganathan M G\n4,3892\n2 gold badges\n27\n27 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"\"Use Strict\"; is an insurance that programmer will not use the loose or the bad properties of JavaScript. It is a guide, just like a ruler will help you make straight lines. \"Use Strict\" will help you do \"Straight coding\".\n\nThose that prefer not to use rulers to do their lines straight usually end up in those pages asking for others to debug their code.\n\nBelieve me. The overhead is negligible compared to poorly designed code. Doug Crockford, who has been a senior JavaScript developer for several years, has a very interesting post here. Personally, I like to return to his site all the time to make sure I don't forget my good practice.\n\nModern JavaScript practice should always evoke the \"Use Strict\"; pragma. The only reason that the ECMA Group has made the \"Strict\" mode optional is to permit less experienced coders access to JavaScript and give then time to adapt to the new and safer coding practices.\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '14 at 10:34\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 31 '13 at 18:29\nuser2436758\n8496\n6 silver badges\n3\n3 bronze badges","comments":[]},{"answer":"Including use strict in the beginning of your all sensitive JavaScript files from this point is a small way to be a better JavaScript programmer and avoid random variables becoming global and things change silently.\n\nShare\nImprove this answer\nFollow\nedited Feb 25 '16 at 15:55\nWilli Mentzel\n22.3k16\n16 gold badges\n92\n92 silver badges\n103\n103 bronze badges\nanswered Sep 5 '14 at 12:53\nPlaceholder\n3,7796\n6 gold badges\n27\n27 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"Quoting from w3schools:\n\nThe \"use strict\" Directive\n\nThe \"use strict\" directive is new in JavaScript 1.8.5 (ECMAScript version 5).\n\nIt is not a statement, but a literal expression, ignored by earlier versions of JavaScript.\n\nThe purpose of \"use strict\" is to indicate that the code should be executed in \"strict mode\".\n\nWith strict mode, you can not, for example, use undeclared variables.\n\nWhy Strict Mode?\n\nStrict mode makes it easier to write \"secure\" JavaScript.\n\nStrict mode changes previously accepted \"bad syntax\" into real errors.\n\nAs an example, in normal JavaScript, mistyping a variable name creates a new global variable. In strict mode, this will throw an error, making it impossible to accidentally create a global variable.\n\nIn normal JavaScript, a developer will not receive any error feedback assigning values to non-writable properties.\n\nIn strict mode, any assignment to a non-writable property, a getter-only property, a non-existing property, a non-existing variable, or a non-existing object, will throw an error.\n\nPlease refer to http://www.w3schools.com/js/js_strict.asp to know more\n\nShare\nImprove this answer\nFollow\nedited Aug 13 '18 at 3:15\nShog9\n148k34\n34 gold badges\n222\n222 silver badges\n231\n231 bronze badges\nanswered Apr 29 '15 at 10:10\nHeich-B\n6026\n6 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"\"use strict\" makes JavaScript code to run in strict mode, which basically means everything needs to be defined before use. The main reason for using strict mode is to avoid accidental global uses of undefined methods.\n\nAlso in strict mode, things run faster, some warnings or silent warnings throw fatal errors, it's better to always use it to make a neater code.\n\n\"use strict\" is widely needed to be used in ECMA5, in ECMA6 it's part of JavaScript by default, so it doesn't need to be added if you're using ES6.\n\nLook at these statements and examples from MDN:\n\nThe \"use strict\" Directive\nThe \"use strict\" directive is new in JavaScript 1.8.5 (ECMAScript version 5). It is not a statement, but a literal expression, ignored by earlier versions of JavaScript. The purpose of \"use strict\" is to indicate that the code should be executed in \"strict mode\". With strict mode, you can not, for example, use undeclared variables.\n\nExamples of using \"use strict\":\nStrict mode for functions: Likewise, to invoke strict mode for a function, put the exact statement \"use strict\"; (or 'use strict';) in the function's body before any other statements.\n\n1) strict mode in functions\n\n function strict() {\n     // Function-level strict mode syntax\n     'use strict';\n     function nested() { return 'And so am I!'; }\n     return \"Hi!  I'm a strict mode function!  \" + nested();\n }\n function notStrict() { return \"I'm not strict.\"; }\n\n console.log(strict(), notStrict());\n\n\n2) whole-script strict mode\n\n'use strict';\nvar v = \"Hi! I'm a strict mode script!\";\nconsole.log(v);\n\n\n3) Assignment to a non-writable global\n\n'use strict';\n\n// Assignment to a non-writable global\nvar undefined = 5; // throws a TypeError\nvar Infinity = 5; // throws a TypeError\n\n// Assignment to a non-writable property\nvar obj1 = {};\nObject.defineProperty(obj1, 'x', { value: 42, writable: false });\nobj1.x = 9; // throws a TypeError\n\n// Assignment to a getter-only property\nvar obj2 = { get x() { return 17; } };\nobj2.x = 5; // throws a TypeError\n\n// Assignment to a new property on a non-extensible object.\nvar fixed = {};\nObject.preventExtensions(fixed);\nfixed.newProp = 'ohai'; // throws a TypeError\n\n\nYou can read more on MDN.\n\nShare\nImprove this answer\nFollow\nedited Aug 30 '18 at 15:16\nPalec\n10.6k7\n7 gold badges\n53\n53 silver badges\n116\n116 bronze badges\nanswered May 22 '17 at 12:38\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"There's a good talk by some people who were on the ECMAScript committee: Changes to JavaScript, Part 1: ECMAScript 5\" about how incremental use of the \"use strict\" switch allows JavaScript implementers to clean up a lot of the dangerous features of JavaScript without suddenly breaking every website in the world.\n\nOf course it also talks about just what a lot of those misfeatures are (were) and how ECMAScript 5 fixes them.\n\nShare\nImprove this answer\nFollow\nedited Mar 29 '14 at 19:39\nanswered Mar 29 '14 at 0:47\nFutureNerd\n6997\n7 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"Small examples to compare:\n\nNon-strict mode:\n\nfor (i of [1,2,3]) console.log(i)\n    \n// output:\n// 1\n// 2\n// 3\n Run code snippetExpand snippet\n\nStrict mode:\n\n'use strict';\nfor (i of [1,2,3]) console.log(i)\n\n// output:\n// Uncaught ReferenceError: i is not defined\n Run code snippetExpand snippet\n\nNon-strict mode:\n\nString.prototype.test = function () {\n  console.log(typeof this === 'string');\n};\n\n'a'.test();\n\n// output\n// false\n Run code snippetExpand snippet\n\nString.prototype.test = function () {\n  'use strict';\n  \n  console.log(typeof this === 'string');\n};\n\n'a'.test();\n\n// output\n// true\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Nov 18 '18 at 16:31\nanswered Aug 21 '16 at 21:43\nTân\n1","comments":[]},{"answer":"Note that use strict was introduced in EcmaScript 5 and was kept since then.\n\nBelow are the conditions to trigger strict mode in ES6 and ES7:\n\nGlobal code is strict mode code if it begins with a Directive Prologue that contains a Use Strict Directive (see 14.1.1).\nModule code is always strict mode code.\nAll parts of a ClassDeclaration or a ClassExpression are strict mode code.\nEval code is strict mode code if it begins with a Directive Prologue that contains a Use Strict Directive or if the call to eval is a direct eval (see 12.3.4.1) that is contained in strict mode code.\nFunction code is strict mode code if the associated FunctionDeclaration, FunctionExpression, GeneratorDeclaration, GeneratorExpression, MethodDefinition, or ArrowFunction is contained in strict mode code or if the code that produces the value of the function’s [[ECMAScriptCode]] internal slot begins with a Directive Prologue that contains a Use Strict Directive.\nFunction code that is supplied as the arguments to the built-in Function and Generator constructors is strict mode code if the last argument is a String that when processed is a FunctionBody that begins with a Directive Prologue that contains a Use Strict Directive.\nShare\nImprove this answer\nFollow\nanswered Apr 12 '16 at 0:25\nOriol\n8,4263\n3 gold badges\n32\n32 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"The main reasons why developers should use \"use strict\" are:\n\nPrevents accidental declaration of global variables.Using \"use strict()\" will make sure that variables are declared with var before use. Eg:\n\nfunction useStrictDemo(){\n 'use strict';\n //works fine\n var a = 'No Problem';\n\n //does not work fine and throws error\n k = \"problem\"\n\n //even this will throw error\n someObject = {'problem': 'lot of problem'};\n}\n\nN.B: The \"use strict\" directive is only recognized at the beginning of a script or a function.\n\nThe string \"arguments\" cannot be used as a variable:\n\n\"use strict\";\nvar arguments = 3.14;    // This will cause an error\n\n\nWill restrict uses of keywords as variables. Trying to use them will throw errors.\n\nIn short will make your code less error prone and in turn will make you write good code.\n\nTo read more about it you can refer here.\n\nShare\nImprove this answer\nFollow\nedited Jun 18 '17 at 3:14\nanswered Nov 18 '16 at 9:53\nPritam Banerjee\n15.6k10\n10 gold badges\n73\n73 silver badges\n95\n95 bronze badges","comments":[]},{"answer":"JavaScript “strict” mode was introduced in ECMAScript 5.\n\n(function() {\n  \"use strict\";\n  your code...\n})();\n\n\nWriting \"use strict\"; at the very top of your JS file turns on strict syntax checking. It does the following tasks for us:\n\nshows an error if you try to assign to an undeclared variable\n\nstops you from overwriting key JS system libraries\n\nforbids some unsafe or error-prone language features\n\nuse strict also works inside of individual functions. It is always a better practice to include use strict in your code.\n\nBrowser compatibility issue: The \"use\" directives are meant to be backwards-compatible. Browsers that do not support them will just see a string literal that isn't referenced further. So, they will pass over it and move on.\n\nShare\nImprove this answer\nFollow\nedited Feb 6 '19 at 9:40\njkdev\n9,29514\n14 gold badges\n53\n53 silver badges\n76\n76 bronze badges\nanswered Nov 11 '16 at 5:40\nRabin Pantha\n8439\n9 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"use strict is a way to make your code safer, because you can't use dangerous features that can work not as you expect. And, as was written before, it makes code more strict.\n\nShare\nImprove this answer\nFollow\nedited Jan 13 '20 at 14:56\nSethO\n2,5815\n5 gold badges\n26\n26 silver badges\n38\n38 bronze badges\nanswered May 17 '16 at 22:31\nПросто программист\n1852\n2 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"\"use strict\"; is the ECMA effort to make JavaScript a little bit more robust. It brings in JS an attempt to make it at least a little \"strict\" (other languages implement strict rules since the 90s). It actually \"forces\" JavaScript developers to follow some sort of coding best practices. Still, JavaScript is very fragile. There is no such thing as typed variables, typed methods, etc. I strongly recommend JavaScript developers to learn a more robust language such as Java or ActionScript3, and implement the same best practices in your JavaScript code, it will work better and be easier to debug.\n\nShare\nImprove this answer\nFollow\nedited Jun 14 '16 at 23:18\nhologram\n5011\n1 gold badge\n5\n5 silver badges\n20\n20 bronze badges\nanswered May 3 '16 at 12:59\nPippoApps.com\n5263\n3 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"Normally, JavaScript does not follow strict rules, hence increasing chances of errors. After using \"use strict\", the JavaScript code should follow strict set of rules as in other programming languages such as use of terminators, declaration before initialization, etc.\n\nIf \"use strict\" is used, the code should be written by following a strict set of rules, hence decreasing the chances of errors and ambiguities.\n\nShare\nImprove this answer\nFollow\nedited Jan 4 '19 at 2:04\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered Nov 20 '16 at 16:23\nBikash Chapagain\n1841\n1 silver badge\n9\n9 bronze badges","comments":[]},{"answer":"Use Strict is used to show common and repeated errors so that it is handled differently , and changes the way java script runs , such changes are :\n\nPrevents accidental globals\n\nNo duplicates\n\nEliminates with\n\nEliminates this coercion\n\nSafer eval()\n\nErrors for immutables\n\nyou can also read this article for the details\n\nShare\nImprove this answer\nFollow\nedited Oct 17 '16 at 14:09\nanswered Oct 17 '16 at 13:59\nWesam\n8483\n3 gold badges\n15\n15 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"\"use strict\"; Defines that JavaScript code should be executed in \"strict mode\".\n\nThe \"use strict\" directive was new in ECMAScript version 5.\nIt is not a statement, but a literal expression, ignored by earlier versions of JavaScript.\nThe purpose of \"use strict\" is to indicate that the code should be executed in \"strict mode\".\nWith strict mode, you can not, for example, use undeclared variables.\n\nAll modern browsers support \"use strict\" except Internet Explorer 9 and lower.\n\nDisadvantage\n\nIf a developer used a library that was in strict mode, but the developer was used to working in normal mode, they might call some actions on the library that wouldn’t work as expected.\n\nWorse, since the developer is in normal mode, they don’t have the advantages of extra errors being thrown, so the error might fail silently.\n\nAlso, as listed above, strict mode stops you from doing certain things.\n\nPeople generally think that you shouldn’t use those things in the first place, but some developers don’t like the constraint and want to use all the features of the language.\n\nFor basic example and for reference go through :\n\nhttps://www.tutorialsteacher.com/javascript/javascript-strict\n\nShare\nImprove this answer\nFollow\nedited Jul 19 '19 at 12:01\nanswered Jan 28 '19 at 10:42\nAshish\n1,58812\n12 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"Strict mode can prevent memory leaks.\n\nPlease check the function below written in non-strict mode:\n\nfunction getname(){\n    name = \"Stack Overflow\"; // Not using var keyword\n    return name;\n}\ngetname();\nconsole.log(name); // Stack Overflow\n\n\nIn this function, we are using a variable called name inside the function. Internally, the compiler will first check if there is any variable declared with that particular name in that particular function scope. Since the compiler understood that there is no such variable, it will check in the outer scope. In our case, it is the global scope. Again, the compiler understood that there is also no variable declared in the global space with that name, so it creates such a variable for us in the global space. Conceptually, this variable will be created in the global scope and will be available in the entire application.\n\nAnother scenario is that, say, the variable is declared in a child function. In that case, the compiler checks the validity of that variable in the outer scope, i.e., the parent function. Only then it will check in the global space and create a variable for us there. That means additional checks need to be done. This will affect the performance of the application.\n\nNow let's write the same function in strict mode.\n\n\"use strict\"\nfunction getname(){\n    name = \"Stack Overflow\"; // Not using var keyword\n    return name;\n}\ngetname();\nconsole.log(name); \n\n\nWe will get the following error.\n\nUncaught ReferenceError: name is not defined\nat getname (<anonymous>:3:15)\nat <anonymous>:6:5\n\n\nHere, the compiler throws the reference error. In strict mode, the compiler does not allow us to use the variable without declaring it. So memory leaks can be prevented. In addition, we can write more optimized code.\n\nShare\nImprove this answer\nFollow\nedited Jul 9 '19 at 6:01\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered Jul 8 '19 at 8:46\nJerin K Alexander\n2536\n6 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"Strict mode eliminates errors that would be ignored in non-strict mode, thus making javascript “more secured”.\n\nIs it considered among best practices?\n\nYes, It's considered part of the best practices while working with javascript to include Strict mode. This is done by adding the below line of code in your JS file.\n\n'use strict'; \n\nin your code.\n\nWhat does it mean to user agents?\n\nIndicating that code should be interpreted in strict mode specifies to user agents like browsers that they should treat code literally as written, and throw an error if the code doesn't make sense.\n\nFor example: Consider in your .js file you have the following code:\n\nScenario 1: [NO STRICT MODE]\n\nvar city = \"Chicago\"\nconsole.log(city) // Prints the city name, i.e. Chicago\n\n\nScenario 2: [NO STRICT MODE]\n\ncity = \"Chicago\"\nconsole.log(city) // Prints the city name, i.e. Chicago\n\n\nSo why does the variable name is being printed in both cases?\n\nWithout strict mode turned on, user agents often go through a series of modifications to problematic code in an attempt to get it to make sense. On the surface, this can seem like a fine thing, and indeed, working outside of strict mode makes it possible for people to get their feet wet with JavaScript code without having all the details quite nailed down. However, as a developer, I don't want to leave a bug in my code, because I know it could come back and bite me later on, and I also just want to write good code. And that's where strict mode helps out.\n\nScenario 3: [STRICT MODE]\n\n'use strict';\n\ncity = \"Chicago\"\nconsole.log(city) // Reference Error: asignment is undeclared variable city.\n\n\nAdditional tip: To maintain code quality using strict mode, you don't need to write this over and again especially if you have multiple .js file. You can enforce this rule globally in eslint rules as follows:\n\nFilename: .eslintrc.js\n\nmodule.exports = {\n    env: {\n        es6: true\n    },\n    rules : {\n        strict: ['error', 'global'],\n        },\n    };\n    \n\n\nOkay, so what is prevented in strict mode?\n\nUsing a variable without declaring it will throw an error in strict mode. This is to prevent unintentionally creating global variables throughout your application. The example with printing Chicago covers this in particular.\n\nDeleting a variable or a function or an argument is a no-no in strict mode.\n\n\"use strict\";\n function x(p1, p2) {}; \n delete x; // This will cause an error\n\n\nDuplicating a parameter name is not allowed in strict mode.\n\n \"use strict\";\n function x(p1, p1) {};   // This will cause an error\n\n\nReserved words in the Javascript language are not allowed in strict mode. The words are implements interface, let, packages, private, protected, public. static, and yield\n\nFor a more comprehensive list check out the MDN documentation here: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Strict_mode\n\nShare\nImprove this answer\nFollow\nanswered Jul 10 '20 at 7:21\nmishsx\n1,2014\n4 gold badges\n15\n15 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"JavaScript was designed and implemented hastily because of browser wars and bad management. As a result many poor design decisions, un-intuitive syntax and confusing semantics found their way into the language. Strict mode aims to amend some of these mistakes.\n\nBut fixing these mistakes without creating alternative interpretation breaks backward compatibility. So, \"use strict\" directive creates that alternative interpretation of the code while communicating it to the programmer.\n\nFor example, this keywords refers to the object in a method definition, like this or self in other languages.\n\nlet o = {\n  name: 'John Doe',\n  sayName: function(){\n    console.log(this.name);\n  }\n};\n\no.sayName(); // 'John Doe'\n\n\nthis has no purpose outside the method context but all JavaScript functions have this keyword whether they are methods or not:\n\nfunction run() {\n  console.log(this);\n}\n\nrun(); // Window\n\n\nHere this resolves to the global object which does not make sense and serves no purpose because global object is already available in the scope.\n\nIn strict mode this in a global function resolves to undefined, which is what we expect.\n\n\"use strict\"\n\nfunction run() {\n  console.log(this);\n}\n\nrun(); // undefined\n\n\nSome mistakes can not be fixed even in strict mode because syntax should be valid for older browsers since they ignore \"strict mode\" directive. This is by design.\n\nShare\nImprove this answer\nFollow\nedited Jul 25 at 7:35\nanswered Jul 25 at 7:14\nsnnsnn\n3,51821\n21 silver badges\n27\n27 bronze badges","comments":[]}]},{"id":"503093","href":"https://stackoverflow.com/questions/503093/how-do-i-redirect-to-another-webpage","title":"How do I redirect to another webpage?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nHow can I redirect the user from one page to another using jQuery or pure JavaScript?\n    ","questionComments":[],"answers":[{"answer":"One does not simply redirect using jQuery\n\njQuery is not necessary, and window.location.replace(...) will best simulate an HTTP redirect.\n\nwindow.location.replace(...) is better than using window.location.href, because replace() does not keep the originating page in the session history, meaning the user won't get stuck in a never-ending back-button fiasco.\n\nIf you want to simulate someone clicking on a link, use location.href\n\nIf you want to simulate an HTTP redirect, use location.replace\n\nFor example:\n\n// similar behavior as an HTTP redirect\nwindow.location.replace(\"http://stackoverflow.com\");\n\n// similar behavior as clicking on a link\nwindow.location.href = \"http://stackoverflow.com\";\n\nShare\nImprove this answer\nFollow\nedited Jun 17 '20 at 22:22\nanswered Feb 3 '09 at 4:24\nRyan McGeary\n224k11\n11 gold badges\n90\n90 silver badges\n103\n103 bronze badges","comments":["Note: Similar behaviour to HTTP redirect for replace() means it won't create an entry in your browser's history.","I created this 5 years ago after seeing your answer imgflip.com/i/11ua9c","If you display a page only to make a redirect, location.replace() will probably be more appropriate (exclude the page with a redirect from history). But why don't you do the redirect on the server side in the first place?","If anyone still has a problem that all the great answers you've applied but page redirect is not working then please visit: stackoverflow.com/questions/15759020/… it works for my case."]},{"answer":"WARNING: This answer has merely been provided as a possible solution; it is obviously not the best solution, as it requires jQuery. Instead, prefer the pure JavaScript solution.\n\n$(location).attr('href', 'http://stackoverflow.com')\n\nShare\nImprove this answer\nFollow\nedited May 19 '19 at 13:36\nduplode\n31.6k7\n7 gold badges\n70\n70 silver badges\n132\n132 bronze badges\nanswered Oct 28 '09 at 16:35\nBoris Guéry\n45.9k7\n7 gold badges\n49\n49 silver badges\n86\n86 bronze badges","comments":[]},{"answer":"Standard \"vanilla\" JavaScript way to redirect a page\nwindow.location.href = 'newPage.html';\n\nOr more simply: (since window is Global)\nlocation.href = 'newPage.html';\n\n\nIf you are here because you are losing HTTP_REFERER when redirecting, keep reading:\n\n(Otherwise ignore this last part)\n\nThe following section is for those using HTTP_REFERER as one of many security measures (although it isn't a great protective measure). If you're using Internet Explorer 8 or lower, these variables get lost when using any form of JavaScript page redirection (location.href, etc.).\n\nBelow we are going to implement an alternative for IE8 & lower so that we don't lose HTTP_REFERER. Otherwise, you can almost always simply use window.location.href.\n\nTesting against HTTP_REFERER (URL pasting, session, etc.) can help tell whether a request is legitimate. (Note: there are also ways to work-around / spoof these referrers, as noted by droop's link in the comments)\n\nSimple cross-browser testing solution (fallback to window.location.href for Internet Explorer 9+ and all other browsers)\n\nUsage: redirect('anotherpage.aspx');\n\nfunction redirect (url) {\n    var ua        = navigator.userAgent.toLowerCase(),\n        isIE      = ua.indexOf('msie') !== -1,\n        version   = parseInt(ua.substr(4, 2), 10);\n\n    // Internet Explorer 8 and lower\n    if (isIE && version < 9) {\n        var link = document.createElement('a');\n        link.href = url;\n        document.body.appendChild(link);\n        link.click();\n    }\n\n    // All other browsers can use the standard window.location.href (they don't lose HTTP_REFERER like Internet Explorer 8 & lower does)\n    else { \n        window.location.href = url; \n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jul 27 '12 at 14:41\nMark Pieszak - Trilon.io\n46.1k13\n13 gold badges\n76\n76 silver badges\n90\n90 bronze badges","comments":[]},{"answer":"There are lots of ways of doing this.\n\n// window.location\nwindow.location.replace('http://www.example.com')\nwindow.location.assign('http://www.example.com')\nwindow.location.href = 'http://www.example.com'\ndocument.location.href = '/path'\n\n// window.history\nwindow.history.back()\nwindow.history.go(-1)\n\n// window.navigate; ONLY for old versions of Internet Explorer\nwindow.navigate('top.jsp')\n\n\n// Probably no bueno\nself.location = 'http://www.example.com';\ntop.location = 'http://www.example.com';\n\n// jQuery\n$(location).attr('href','http://www.example.com')\n$(window).attr('location','http://www.example.com')\n$(location).prop('href', 'http://www.example.com')\n\nShare\nImprove this answer\nFollow\nedited Jan 16 '19 at 10:28\nanswered Jan 28 '14 at 4:28\nGovind Singh\n14.2k13\n13 gold badges\n62\n62 silver badges\n94\n94 bronze badges","comments":[]},{"answer":"This works for every browser:\n\nwindow.location.href = 'your_url';\n\nShare\nImprove this answer\nFollow\nedited Dec 4 '14 at 20:30\nJeremy W\n1,7716\n6 gold badges\n25\n25 silver badges\n33\n33 bronze badges\nanswered Oct 22 '10 at 23:45\nFred\n3,5211\n1 gold badge\n12\n12 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"It would help if you were a little more descriptive in what you are trying to do. If you are trying to generate paged data, there are some options in how you do this. You can generate separate links for each page that you want to be able to get directly to.\n\n<a href='/path-to-page?page=1' class='pager-link'>1</a>\n<a href='/path-to-page?page=2' class='pager-link'>2</a>\n<span class='pager-link current-page'>3</a>\n...\n\n\nNote that the current page in the example is handled differently in the code and with CSS.\n\nIf you want the paged data to be changed via AJAX, this is where jQuery would come in. What you would do is add a click handler to each of the anchor tags corresponding to a different page. This click handler would invoke some jQuery code that goes and fetches the next page via AJAX and updates the table with the new data. The example below assumes that you have a web service that returns the new page data.\n\n$(document).ready( function() {\n    $('a.pager-link').click( function() {\n        var page = $(this).attr('href').split(/\\?/)[1];\n        $.ajax({\n            type: 'POST',\n            url: '/path-to-service',\n            data: page,\n            success: function(content) {\n               $('#myTable').html(content);  // replace\n            }\n        });\n        return false; // to stop link\n    });\n});\n\nShare\nImprove this answer\nFollow\nanswered Feb 2 '09 at 13:18\ntvanfosson\n495k93\n93 gold badges\n684\n684 silver badges\n783\n783 bronze badges","comments":[]},{"answer":"I also think that location.replace(URL) is the best way, but if you want to notify the search engines about your redirection (they don't analyze JavaScript code to see the redirection) you should add the rel=\"canonical\" meta tag to your website.\n\nAdding a noscript section with a HTML refresh meta tag in it, is also a good solution. I suggest you to use this JavaScript redirection tool to create redirections. It also has Internet Explorer support to pass the HTTP referrer.\n\nSample code without delay looks like this:\n\n<!-- Place this snippet right after opening the head tag to make it work properly -->\n\n<!-- This code is licensed under GNU GPL v3 -->\n<!-- You are allowed to freely copy, distribute and use this code, but removing author credit is strictly prohibited -->\n<!-- Generated by http://insider.zone/tools/client-side-url-redirect-generator/ -->\n\n<!-- REDIRECTING STARTS -->\n<link rel=\"canonical\" href=\"https://yourdomain.com/\"/>\n<noscript>\n    <meta http-equiv=\"refresh\" content=\"0;URL=https://yourdomain.com/\">\n</noscript>\n<!--[if lt IE 9]><script type=\"text/javascript\">var IE_fix=true;</script><![endif]-->\n<script type=\"text/javascript\">\n    var url = \"https://yourdomain.com/\";\n    if(typeof IE_fix != \"undefined\") // IE8 and lower fix to pass the http referer\n    {\n        document.write(\"redirecting...\"); // Don't remove this line or appendChild() will fail because it is called before document.onload to make the redirect as fast as possible. Nobody will see this text, it is only a tech fix.\n        var referLink = document.createElement(\"a\");\n        referLink.href = url;\n        document.body.appendChild(referLink);\n        referLink.click();\n    }\n    else { window.location.replace(url); } // All other browsers\n</script>\n<!-- Credit goes to http://insider.zone/ -->\n<!-- REDIRECTING ENDS -->\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '18 at 15:42\nYauhen Yakimovich\n12.4k7\n7 gold badges\n54\n54 silver badges\n64\n64 bronze badges\nanswered Apr 25 '13 at 10:12\nPatartics Milán\n4,4824\n4 gold badges\n23\n23 silver badges\n32\n32 bronze badges","comments":["This is no longer true re: Search Engines not analyzing Javascript"]},{"answer":"But if someone wants to redirect back to home page then he may use the following snippet.\n\nwindow.location = window.location.host\n\n\nIt would be helpful if you have three different environments as development, staging, and production.\n\nYou can explore this window or window.location object by just putting these words in Chrome Console or Firebug's Console.\n\nShare\nImprove this answer\nFollow\nedited Jan 21 '17 at 20:07\nanswered Oct 30 '12 at 12:15\nNadeem Yasin\n4,2933\n3 gold badges\n29\n29 silver badges\n38\n38 bronze badges","comments":[]},{"answer":"JavaScript provides you many methods to retrieve and change the current URL which is displayed in browser's address bar. All these methods uses the Location object, which is a property of the Window object. You can create a new Location object that has the current URL as follows..\n\nvar currentLocation = window.location;\n\n\nBasic Structure of a URL\n\n<protocol>//<hostname>:<port>/<pathname><search><hash>\n\n\nProtocol -- Specifies the protocol name be used to access the resource on the Internet. (HTTP (without SSL) or HTTPS (with SSL))\n\nhostname -- Host name specifies the host that owns the resource. For example, www.stackoverflow.com. A server provides services using the name of the host.\n\nport -- A port number used to recognize a specific process to which an Internet or other network message is to be forwarded when it arrives at a server.\n\npathname -- The path gives info about the specific resource within the host that the Web client wants to access. For example, stackoverflow.com/index.html.\n\nquery -- A query string follows the path component, and provides a string of information that the resource can utilize for some purpose (for example, as parameters for a search or as data to be processed).\n\nhash -- The anchor portion of a URL, includes the hash sign (#).\n\nWith these Location object properties you can access all of these URL components\n\nhash -Sets or returns the anchor portion of a URL.\nhost -Sets or returns the hostname and port of a URL.\nhostname -Sets or returns the hostname of a URL.\nhref -Sets or returns the entire URL.\npathname -Sets or returns the path name of a URL.\nport -Sets or returns the port number the server uses for a URL.\nprotocol -Sets or returns the protocol of a URL.\nsearch -Sets or returns the query portion of a URL\n\nNow If you want to change a page or redirect the user to some other page you can use the href property of the Location object like this\n\nYou can use the href property of the Location object.\n\nwindow.location.href = \"http://www.stackoverflow.com\";\n\n\nLocation Object also have these three methods\n\nassign() -- Loads a new document.\nreload() -- Reloads the current document.\nreplace() -- Replaces the current document with a new one\n\nYou can use assign() and replace methods also to redirect to other pages like these\n\nlocation.assign(\"http://www.stackoverflow.com\");\n\nlocation.replace(\"http://www.stackoverflow.com\");\n\n\nHow assign() and replace() differs -- The difference between replace() method and assign() method(), is that replace() removes the URL of the current document from the document history, means it is not possible to use the \"back\" button to navigate back to the original document. So Use the assign() method if you want to load a new document, andwant to give the option to navigate back to the original document.\n\nYou can change the location object href property using jQuery also like this\n\n$(location).attr('href',url);\n\n\nAnd hence you can redirect the user to some other url.\n\nShare\nImprove this answer\nFollow\nedited Oct 24 '17 at 9:52\nOndrej\n4421\n1 gold badge\n3\n3 silver badges\n10\n10 bronze badges\nanswered Dec 23 '13 at 13:35\nNikhil Agrawal\n24.2k19\n19 gold badges\n85\n85 silver badges\n117\n117 bronze badges","comments":[]},{"answer":"Basically jQuery is just a JavaScript framework and for doing some of the things like redirection in this case, you can just use pure JavaScript, so in that case you have 3 options using vanilla JavaScript:\n\n1) Using location replace, this will replace the current history of the page, means that it is not possible to use the back button to go back to the original page.\n\nwindow.location.replace(\"http://stackoverflow.com\");\n\n\n2) Using location assign, this will keep the history for you and with using back button, you can go back to the original page:\n\nwindow.location.assign(\"http://stackoverflow.com\");\n\n\n3) I recommend using one of those previous ways, but this could be the third option using pure JavaScript:\n\nwindow.location.href=\"http://stackoverflow.com\";\n\n\nYou can also write a function in jQuery to handle it, but not recommended as it's only one line pure JavaScript function, also you can use all of above functions without window if you are already in the window scope, for example window.location.replace(\"http://stackoverflow.com\"); could be location.replace(\"http://stackoverflow.com\");\n\nAlso I show them all on the image below:\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '19 at 23:52\nanswered Feb 26 '17 at 13:36\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"Should just be able to set using window.location.\n\nExample:\n\nwindow.location = \"https://stackoverflow.com/\";\n\n\nHere is a past post on the subject: How do I redirect to another webpage?\n\nShare\nImprove this answer\nFollow\nedited May 19 '19 at 13:36\nduplode\n31.6k7\n7 gold badges\n70\n70 silver badges\n132\n132 bronze badges\nanswered Feb 16 '14 at 14:42\nNewse\n2,3001\n1 gold badge\n10\n10 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"Before I start, jQuery is a JavaScript library used for DOM manipulation. So you should not be using jQuery for a page redirect.\n\nA quote from Jquery.com:\n\nWhile jQuery might run without major issues in older browser versions, we do not actively test jQuery in them and generally do not fix bugs that may appear in them.\n\nIt was found here: https://jquery.com/browser-support/\n\nSo jQuery is not an end-all and be-all solution for backwards compatibility.\n\nThe following solution using raw JavaScript works in all browsers and have been standard for a long time so you don't need any libraries for cross browser support.\n\nThis page will redirect to Google after 3000 milliseconds\n\n<!DOCTYPE html>\n<html>\n    <head>\n        <title>example</title>\n    </head>\n    <body>\n        <p>You will be redirected to google shortly.</p>\n        <script>\n            setTimeout(function(){\n                window.location.href=\"http://www.google.com\"; // The URL that will be redirected too.\n            }, 3000); // The bigger the number the longer the delay.\n        </script>\n    </body>\n</html>\n\n\nDifferent options are as follows:\n\nwindow.location.href=\"url\"; // Simulates normal navigation to a new page\nwindow.location.replace(\"url\"); // Removes current URL from history and replaces it with a new URL\nwindow.location.assign(\"url\"); // Adds new URL to the history stack and redirects to the new URL\n\nwindow.history.back(); // Simulates a back button click\nwindow.history.go(-1); // Simulates a back button click\nwindow.history.back(-1); // Simulates a back button click\nwindow.navigate(\"page.html\"); // Same as window.location=\"url\"\n\n\nWhen using replace, the back button will not go back to the redirect page, as if it was never in the history. If you want the user to be able to go back to the redirect page then use window.location.href or window.location.assign. If you do use an option that lets the user go back to the redirect page, remember that when you enter the redirect page it will redirect you back. So put that into consideration when picking an option for your redirect. Under conditions where the page is only redirecting when an action is done by the user then having the page in the back button history will be okay. But if the page auto redirects then you should use replace so that the user can use the back button without getting forced back to the page the redirect sends.\n\nYou can also use meta data to run a page redirect as followed.\n\nMETA Refresh\n\n<meta http-equiv=\"refresh\" content=\"0;url=http://evil.com/\" />\n\n\nMETA Location\n\n<meta http-equiv=\"location\" content=\"URL=http://evil.com\" />\n\n\nBASE Hijacking\n\n<base href=\"http://evil.com/\" />\n\n\nMany more methods to redirect your unsuspecting client to a page they may not wish to go can be found on this page (not one of them is reliant on jQuery):\n\nhttps://code.google.com/p/html5security/wiki/RedirectionMethods\n\nI would also like to point out, people don't like to be randomly redirected. Only redirect people when absolutely needed. If you start redirecting people randomly they will never go to your site again.\n\nThe next paragraph is hypothetical:\n\nYou also may get reported as a malicious site. If that happens then when people click on a link to your site the users browser may warn them that your site is malicious. What may also happen is search engines may start dropping your rating if people are reporting a bad experience on your site.\n\nPlease review Google Webmaster Guidelines about redirects: https://support.google.com/webmasters/answer/2721217?hl=en&ref_topic=6001971\n\nHere is a fun little page that kicks you out of the page.\n\n<!DOCTYPE html>\n<html>\n    <head>\n        <title>Go Away</title>\n    </head>\n    <body>\n        <h1>Go Away</h1>\n        <script>\n            setTimeout(function(){\n                window.history.back();\n            }, 3000);\n        </script>\n    </body>\n</html>\n\n\nIf you combine the two page examples together you would have an infant loop of rerouting that will guarantee that your user will never want to use your site ever again.\n\nShare\nImprove this answer\nFollow\nedited May 19 '19 at 13:38\nduplode\n31.6k7\n7 gold badges\n70\n70 silver badges\n132\n132 bronze badges\nanswered Aug 27 '14 at 21:50\nPatrick W. McMahon\n3,1511\n1 gold badge\n16\n16 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"var url = 'asdf.html';\nwindow.location.href = url;\n\nShare\nImprove this answer\nFollow\nedited May 1 '12 at 20:35\nBen Lee\n50.3k12\n12 gold badges\n119\n119 silver badges\n143\n143 bronze badges\nanswered Oct 13 '09 at 9:36\nuser188973","comments":[]},{"answer":"You can do that without jQuery as:\n\nwindow.location = \"http://yourdomain.com\";\n\n\nAnd if you want only jQuery then you can do it like:\n\n$jq(window).attr(\"location\",\"http://yourdomain.com\");\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '14 at 6:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 23 '12 at 13:03\nScoRpion\n11k24\n24 gold badges\n63\n63 silver badges\n87\n87 bronze badges","comments":[]},{"answer":"This works with jQuery:\n\n$(window).attr(\"location\", \"http://google.fr\");\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 16:11\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 5 '11 at 17:25\nxloadx\n1,5231\n1 gold badge\n9\n9 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"# HTML Page Redirect Using jQuery/JavaScript Method\n\nTry this example code:\n\nfunction YourJavaScriptFunction()\n{\n    var i = $('#login').val();\n    if (i == 'login')\n        window.location = \"Login.php\";\n    else\n        window.location = \"Logout.php\";\n}\n\n\nIf you want to give a complete URL as window.location = \"www.google.co.in\";.\n\nShare\nImprove this answer\nFollow\nedited Aug 20 '20 at 4:53\nanswered Feb 6 '14 at 10:28\nSakthi Karthik\n2,6962\n2 gold badges\n22\n22 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"Original question: \"How to redirect using jQuery?\", hence the answer implements jQuery >> Complimentary usage case.\n\nTo just redirect to a page with JavaScript:\n\nwindow.location.href = \"/contact/\";\n\n\nOr if you need a delay:\n\nsetTimeout(function () {\n  window.location.href = \"/contact/\";\n}, 2000);   // Time in milliseconds\n\n\njQuery allows you to select elements from a web page with ease. You can find anything you want on a page and then use jQuery to add special effects, react to user actions, or show and hide content inside or outside the element you have selected. All these tasks start with knowing how to select an element or an event.\n\n$('a,img').on('click',function(e){\n  e.preventDefault();\n  $(this).animate({\n    opacity: 0 //Put some CSS animation here\n  }, 500);\n  setTimeout(function(){\n    // OK, finished jQuery staff, let's go redirect\n    window.location.href = \"/contact/\";\n  },500);\n});\n\n\nImagine someone wrote a script/plugin with 10000 lines of code. With jQuery you can connect to this code with just a line or two.\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '19 at 16:17\njonju\n2,6411\n1 gold badge\n11\n11 silver badges\n19\n19 bronze badges\nanswered Dec 26 '14 at 19:08\nSergeDirect\n1,69713\n13 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"You need to put this line in your code:\n\n$(location).attr(\"href\",\"http://stackoverflow.com\");\n\n\nIf you don't have jQuery, go with JavaScript:\n\nwindow.location.replace(\"http://stackoverflow.com\");\nwindow.location.href(\"http://stackoverflow.com\");\n\nShare\nImprove this answer\nFollow\nedited Mar 28 '19 at 5:20\nanswered Jan 27 '14 at 10:11\nAshish Ratan\n2,73120\n20 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"So, the question is how to make a redirect page, and not how to redirect to a website?\n\nYou only need to use JavaScript for this. Here is some tiny code that will create a dynamic redirect page.\n\n<script>\n    var url = window.location.search.split('url=')[1]; // Get the URL after ?url=\n    if( url ) window.location.replace(url);\n</script>\n\n\nSo say you just put this snippet into a redirect/index.html file on your website you can use it like so.\n\nhttp://www.mywebsite.com/redirect?url=http://stackoverflow.com\n\nAnd if you go to that link it will automatically redirect you to stackoverflow.com.\n\nLink to Documentation\n\nAnd that's how you make a Simple redirect page with JavaScript\n\nEdit:\n\nThere is also one thing to note. I have added window.location.replace in my code because I think it suits a redirect page, but, you must know that when using window.location.replace and you get redirected, when you press the back button in your browser it will not got back to the redirect page, and it will go back to the page before it, take a look at this little demo thing.\n\nExample:\n\nThe process: store home => redirect page to google => google\n\nWhen at google: google => back button in browser => store home\n\nSo, if this suits your needs then everything should be fine. If you want to include the redirect page in the browser history replace this\n\nif( url ) window.location.replace(url);\n\n\nwith\n\nif( url ) window.location.href = url;\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Aug 30 '13 at 23:46\niConnor\n19.2k13\n13 gold badges\n57\n57 silver badges\n91\n91 bronze badges","comments":[]},{"answer":"On your click function, just add:\n\nwindow.location.href = \"The URL where you want to redirect\";\n$('#id').click(function(){\n    window.location.href = \"http://www.google.com\";\n});\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '14 at 10:44\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 14 '12 at 2:17\nSwaprks\n1,48311\n11 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"Try this:\n\nlocation.assign(\"http://www.google.com\");\n\n\nCode snippet of example.\n\nShare\nImprove this answer\nFollow\nedited Jan 2 '16 at 4:29\nstites\n4,0435\n5 gold badges\n29\n29 silver badges\n43\n43 bronze badges\nanswered Nov 19 '13 at 4:01\ntilak\n4,0755\n5 gold badges\n31\n31 silver badges\n44\n44 bronze badges","comments":[]},{"answer":"jQuery is not needed. You can do this:\n\nwindow.open(\"URL\",\"_self\",\"\",\"\")\n\n\nIt is that easy!\n\nThe best way to initiate an HTTP request is with document.loacation.href.replace('URL').\n\nShare\nImprove this answer\nFollow\nedited Apr 3 '14 at 21:23\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 11 '13 at 17:40\nMayorMonty\n3,9963\n3 gold badges\n23\n23 silver badges\n40\n40 bronze badges","comments":[]},{"answer":"First write properly. You want to navigate within an application for another link from your application for another link. Here is the code:\n\nwindow.location.href = \"http://www.google.com\";\n\n\nAnd if you want to navigate pages within your application then I also have code, if you want.\n\nShare\nImprove this answer\nFollow\nedited Apr 3 '14 at 21:20\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 6 '13 at 12:37\nAnup\n3,1451\n1 gold badge\n24\n24 silver badges\n37\n37 bronze badges","comments":[]},{"answer":"You can redirect in jQuery like this:\n\n$(location).attr('href', 'http://yourPage.com/');\n\nShare\nImprove this answer\nFollow\nedited Jul 3 '16 at 5:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 5 '14 at 16:36\nAzam Alvi\n6,2545\n5 gold badges\n57\n57 silver badges\n80\n80 bronze badges","comments":[]},{"answer":"Using JavaScript:\nMethod 1:\nwindow.location.href=\"http://google.com\";\n\nMethod 2:\nwindow.location.replace(\"http://google.com\");\n\nUsing jQuery:\nMethod 1: $(location)\n$(location).attr('href', 'http://google.com');\n\nMethod 2: Reusable Function\njQuery.fn.redirectTo = function(url){\n    window.location.href = url;\n}\n\njQuery(window).redirectTo(\"http://google.com\");\n\nShare\nImprove this answer\nFollow\nedited Sep 25 '19 at 17:32\nSouleste\n1,6321\n1 gold badge\n8\n8 silver badges\n34\n34 bronze badges\nanswered Feb 23 '17 at 23:01\nKalpesh Panchal\n8778\n8 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"In JavaScript and jQuery we can use the following code to redirect the one page to another page:\n\nwindow.location.href=\"http://google.com\";\nwindow.location.replace(\"page1.html\");\n\nShare\nImprove this answer\nFollow\nedited Apr 3 '14 at 21:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 1 '13 at 4:11\nuser2496033","comments":[]},{"answer":"ECMAScript 6 + jQuery, 85 bytes\n$({jQueryCode:(url)=>location.replace(url)}).attr(\"jQueryCode\")(\"http://example.com\")\n\n\nPlease don't kill me, this is a joke. It's a joke. This is a joke.\n\nThis did \"provide an answer to the question\", in the sense that it asked for a solution \"using jQuery\" which in this case entails forcing it into the equation somehow.\n\nFerrybig apparently needs the joke explained (still joking, I'm sure there are limited options on the review form), so without further ado:\n\nOther answers are using jQuery's attr() on the location or window objects unnecessarily.\n\nThis answer also abuses it, but in a more ridiculous way. Instead of using it to set the location, this uses attr() to retrieve a function that sets the location.\n\nThe function is named jQueryCode even though there's nothing jQuery about it, and calling a function somethingCode is just horrible, especially when the something is not even a language.\n\nThe \"85 bytes\" is a reference to Code Golf. Golfing is obviously not something you should do outside of code golf, and furthermore this answer is clearly not actually golfed.\n\nBasically, cringe.\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 16:27\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 13 '16 at 16:23\n1j01\n3,0372\n2 gold badges\n23\n23 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"Javascript:\n\nwindow.location.href='www.your_url.com';\nwindow.top.location.href='www.your_url.com';\nwindow.location.replace('www.your_url.com');\n\n\nJquery:\n\nvar url='www.your_url.com';\n$(location).attr('href',url);\n$(location).prop('href',url);//instead of location you can use window\n\nShare\nImprove this answer\nFollow\nedited May 4 '17 at 12:12\nanswered May 22 '15 at 5:18\nlalithkumar\n3,2123\n3 gold badges\n22\n22 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"Here is a time-delay redirection. You can set the delay time to whatever you want:\n\n<!doctype html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Your Document Title</title>\n    <script type=\"text/javascript\">\n        function delayer(delay) {\n            onLoad = setTimeout('window.location.href = \"http://www.google.com/\"', delay);\n        }\n    </script>\n</head>\n\n<body>\n    <script>\n        delayer(8000)\n    </script>\n    <div>You will be redirected in 8 seconds!</div>\n</body>\n\n</html>\n\nShare\nImprove this answer\nFollow\nedited Feb 23 '16 at 6:26\nMilap\n6,2068\n8 gold badges\n21\n21 silver badges\n44\n44 bronze badges\nanswered Nov 29 '13 at 0:49\nStefan Gruenwald\n2,36022\n22 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"There are three main ways to do this,\n\nwindow.location.href='blaah.com';\nwindow.location.assign('blaah.com');\n\n\nand...\n\nwindow.location.replace('blaah.com');\n\n\nThe last one is best, for a traditional redirect, because it will not save the page you went to before being redirected in your search history. However, if you just want to open a tab with JavaScript, you can use any of the above.1\n\nEDIT: The window prefix is optional.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jul 7 '14 at 0:54\nBen\n1,87018\n18 silver badges\n23\n23 bronze badges","comments":[]}]},{"id":"179123","href":"https://stackoverflow.com/questions/179123/how-to-modify-existing-unpushed-commit-messages","title":"How to modify existing, unpushed commit messages?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nI wrote the wrong thing in a commit message.\n\nHow can I change the message? The commit has not been pushed yet.\n    ","questionComments":["For those somewhat new to git: Laurie's point about having not yet pushed is important. Like rebasing, this is changing the history. If someone has cloned/pulled from your repo between the original and rewritten history then they won't be able to pull after the rewrite (for that branch)."],"answers":[{"answer":"Amending the most recent commit message\ngit commit --amend\n\n\nwill open your editor, allowing you to change the commit message of the most recent commit. Additionally, you can set the commit message directly in the command line with:\n\ngit commit --amend -m \"New commit message\"\n\n\n…however, this can make multi-line commit messages or small corrections more cumbersome to enter.\n\nMake sure you don't have any working copy changes staged before doing this or they will get committed too. (Unstaged changes will not get committed.)\n\nChanging the message of a commit that you've already pushed to your remote branch\n\nIf you've already pushed your commit up to your remote branch, then - after amending your commit locally (as described above) - you'll also need to force push the commit with:\n\ngit push <remote> <branch> --force\n# Or\ngit push <remote> <branch> -f\n\n\nWarning: force-pushing will overwrite the remote branch with the state of your local one. If there are commits on the remote branch that you don't have in your local branch, you will lose those commits.\n\nWarning: be cautious about amending commits that you have already shared with other people. Amending commits essentially rewrites them to have different SHA IDs, which poses a problem if other people have copies of the old commit that you've rewritten. Anyone who has a copy of the old commit will need to synchronize their work with your newly re-written commit, which can sometimes be difficult, so make sure you coordinate with others when attempting to rewrite shared commit history, or just avoid rewriting shared commits altogether.\n\nPerform an interactive rebase\n\nAnother option is to use interactive rebase. This allows you to edit any message you want to update even if it's not the latest message.\n\nIn order to do a Git squash, follow these steps:\n\n// n is the number of commits up to the last commit you want to be able to edit\ngit rebase -i HEAD~n\n\n\nOnce you squash your commits - choose the e/r for editing the message:\n\nImportant note about interactive rebase\n\nWhen you use git rebase -i HEAD~n there can be more than n commits. Git will \"collect\" all the commits in the last n commits, and if there was a merge somewhere in between that range you will see all the commits as well, so the outcome will be n + .\n\nGood tip:\n\nIf you have to do it for more than a single branch and you might face conflicts when amending the content, set up git rerere and let Git resolve those conflicts automatically for you.\n\nDocumentation\n\ngit-commit(1) Manual Page\n\ngit-rebase(1) Manual Page\n\ngit-push(1) Manual Page\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n32 revs, 27 users 23%\nuser456814","comments":["However git commit --amend isnt as powerful as git rebase -i.","@jeffjose, It definitely doesn't need to be. Also, git commit --amend can fix up the (a?) master commit.","If you've already pushed, just force push again: git push -f origin branchname","@hughes isn't git push -f a bit dangerous if other people are using the same repository?","If you don't want to rewrite the entire commit message, go for git commit --amend -c HEAD. This will open the editor pre-populated with your old commit message, so you can change it."]},{"answer":"git commit --amend -m \"your new message\"\n\nShare\nImprove this answer\nFollow\nedited Mar 1 '16 at 18:19\nDavid Ferenczy Rogožan\n19.6k8\n8 gold badges\n70\n70 silver badges\n67\n67 bronze badges\nanswered Feb 8 '10 at 4:26\nlfx_cool\n25.8k1\n1 gold badge\n13\n13 silver badges\n2\n2 bronze badges","comments":["I did git commit --amend -m \"New message\", but pushing to Github generated the \"Merge the remote changes before pushing again\". After pull, commit --amend, and push again, the new message doesn't appear. Instead I have \"Merge branch 'master' of github.com:[myrepo]\"","@DaveEveritt you most likely pushed your commit upstream before trying to fix it.","@Kyralessa not true. In bash you can easily compose multiline commit messages by just not closing the quote until you're done (hitting return at the end of each line within the quotes).","I don't get how an answer that looks a lot like just the main idea of an answer that was written two years ago and also the accepted answer gets so many votes. Strange. (nothing wrong with the answer though)","@AmalMurali, well. My point wasn't so much about the popularity of the question, nor the utility of the answer. But this particular answer is not the oldest answer, nor does it offer any further insight into the accepted answer. It appears to be a copy of a section of the accepted answer. That was my point. CHEERS!"]},{"answer":"If the commit you want to fix isn’t the most recent one:\n\ngit rebase --interactive $parent_of_flawed_commit\n\nIf you want to fix several flawed commits, pass the parent of the oldest one of them.\n\nAn editor will come up, with a list of all commits since the one you gave.\n\nChange pick to reword (or on old versions of Git, to edit) in front of any commits you want to fix.\nOnce you save, Git will replay the listed commits.\n\n\n\nFor each commit you want to reword, Git will drop you back into your editor. For each commit you want to edit, Git drops you into the shell. If you’re in the shell:\n\nChange the commit in any way you like.\ngit commit --amend\ngit rebase --continue\n\nMost of this sequence will be explained to you by the output of the various commands as you go. It’s very easy; you don’t need to memorise it – just remember that git rebase --interactive lets you correct commits no matter how long ago they were.\n\nNote that you will not want to change commits that you have already pushed. Or maybe you do, but in that case you will have to take great care to communicate with everyone who may have pulled your commits and done work on top of them. How do I recover/resynchronise after someone pushes a rebase or a reset to a published branch?\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 11:58\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 7 '08 at 19:52\nAristotle Pagaltzis\n103k21\n21 gold badges\n94\n94 silver badges\n96\n96 bronze badges","comments":["Can one change the message of the first commit (which doesn't have a parent)?","This is mentioned in one of the other answers but I will put a note of it here. Since git 1.6.6 you can use reword in place of pick to edit the log message.","Incidentally, $parent_of_flawed_commit is equivalent to $flawed_commit^.","Never EVER do this (or rebase in general) if you have already pushed upstream!","Use -p (--preserve-merges) if there was a merge after the flawed commit."]},{"answer":"To amend the previous commit, make the changes you want and stage those changes, and then run\n\ngit commit --amend\n\n\nThis will open a file in your text editor representing your new commit message. It starts out populated with the text from your old commit message. Change the commit message as you want, then save the file and quit your editor to finish.\n\nTo amend the previous commit and keep the same log message, run\n\ngit commit --amend -C HEAD\n\n\nTo fix the previous commit by removing it entirely, run\n\ngit reset --hard HEAD^\n\n\nIf you want to edit more than one commit message, run\n\ngit rebase -i HEAD~commit_count\n\n(Replace commit_count with number of commits that you want to edit.) This command launches your editor. Mark the first commit (the one that you want to change) as “edit” instead of “pick”, then save and exit your editor. Make the change you want to commit and then run\n\ngit commit --amend\ngit rebase --continue\n\n\nNote: You can also \"Make the change you want\" from the editor opened by git commit --amend\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 15 '11 at 21:20\nFatih Acet\n26.2k9\n9 gold badges\n49\n49 silver badges\n56\n56 bronze badges","comments":["git rebase -i HEAD~commit_count will also allow you to change the commit messages of however many commits you choose. Just mark the chosen commits as \"reword\" instead of \"pick\".","What if you don't want to rebase? You just want to change an older message?","git reset --hard annihilates uncommitted changes. Please replace --hard with --soft.","Agreed, git reset --hard is a perfectly legitimate command, but it is misleading given the question. You use --hard if you committed changes you want to throw away, not if you made a typo in the commit message!","git commit --amend -C HEAD is golden! Thank you"]},{"answer":"As already mentioned, git commit --amend is the way to overwrite the last commit. One note: if you would like to also overwrite the files, the command would be\n\ngit commit -a --amend -m \"My new commit message\"\n\nShare\nImprove this answer\nFollow\nedited Feb 23 '14 at 23:10\nSteven Penny\n1\nanswered Jun 6 '11 at 21:16\nJohn\n4,2641\n1 gold badge\n13\n13 silver badges\n10\n10 bronze badges","comments":["And if you don't want to add everything, you can first do git add file.ext then just git commit --amend"]},{"answer":"You also can use git filter-branch for that.\n\ngit filter-branch -f --msg-filter \"sed 's/errror/error/'\" $flawed_commit..HEAD\n\n\nIt's not as easy as a trivial git commit --amend, but it's especially useful, if you already have some merges after your erroneous commit message.\n\nNote that this will try to rewrite every commit between HEAD and the flawed commit, so you should choose your msg-filter command very wisely ;-)\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 1 '12 at 20:35\nMark\n5,9151\n1 gold badge\n17\n17 silver badges\n14\n14 bronze badges","comments":["Is there a version of this that does not change the commit if the regex doesn't find anything?","AFAIK filter-branch --msg-filter will generate new commits in any case. However, you could check within the msg-filter, if the sed succeeded and use this information when the filter-branch operation ends to reset your tree to refs/original.","@DavidHogue This is only true when using the filter-branch method. The commit IDs following a modified commit do not change if you use the interactive rebase.","@Mark Yes they do, they are required to. Commit ids are dependent on previous commits. If they didn't change, git would be useless.","You need $flawed_commit^..HEAD, not $flawed_commit..HEAD. as stated by the man page: «The command will only rewrite the positive refs mentioned in the command line (e.g. if you pass a..b, only b will be rewritten).»"]},{"answer":"I prefer this way:\n\ngit commit --amend -c <commit ID>\n\n\nOtherwise, there will be a new commit with a new commit ID.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 10 '13 at 14:23\nkrevedko\n4,0071\n1 gold badge\n15\n15 silver badges\n13\n13 bronze badges","comments":["For me, using your command above actually creates a new commit with a new commit ID plus an extra commit saying \"merge branch\" as a default commit message.","Amending always creates a new commit with a new commit ID. The commit ID is the SHA hash of the contents of the commit, including the commit message and authored/committed timestamps. This is a feature of Git that, barring hash collisions, ensures that two commits with the same ID are exactly the same commit, with exactly the same content, history and so on.","Agree with Emil. Additionally, reading the docs - it seems that all \"-c\" does is tell git which commit's message to use as the default/template for your new commit..Really its already going to do \"-c <commit ID>\" by default, so no need to specify it.","The -c does a few things. It uses the old message by default, but it also copies authorship information (person and time). -C does the same thing except that it does not ask you to edit the message.","Like @SantanuDey , it didn't work for me. I got fatal: Option -m cannot be combined with -c/-C/-F/--fixup."]},{"answer":"If you are using the Git GUI tool, there is a button named Amend last commit. Click on that button and then it will display your last commit files and message. Just edit that message, and you can commit it with a new commit message.\n\nOr use this command from a console/terminal:\n\ngit commit -a --amend -m \"My new commit message\"\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 8 '12 at 3:51\nAkhilraj N S\n8,3835\n5 gold badges\n30\n30 silver badges\n37\n37 bronze badges","comments":["This answer is literally identical to this older one. Have you checked existing answers before supplying another one?"]},{"answer":"You can use Git rebasing. For example, if you want to modify back to commit bbc643cd, run\n\n$ git rebase bbc643cd^ --interactive\n\n\nIn the default editor, modify 'pick' to 'edit' in the line whose commit you want to modify. Make your changes and then stage them with\n\n$ git add <filepattern>\n\n\nNow you can use\n\n$ git commit --amend\n\n\nto modify the commit, and after that\n\n$ git rebase --continue\n\n\nto return back to the previous head commit.\n\nShare\nImprove this answer\nFollow\nedited Mar 16 '13 at 9:39\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 22 '13 at 17:23\nShoaib Ud-Din\n4,4243\n3 gold badges\n20\n20 silver badges\n23\n23 bronze badges","comments":["If you want to make sure your change from git commit --amend took affect you can use git show and it will show the new message."]},{"answer":"If you only want to modify your last commit message, then do:\n\ngit commit --amend\n\n\nThat will drop you into your text editor and let you change the last commit message.\n\nIf you want to change the last three commit messages, or any of the commit messages up to that point, supply HEAD~3 to the git rebase -i command:\n\ngit rebase -i HEAD~3\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:07\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 22 '12 at 11:22\nHeena Hussain\n3,5931\n1 gold badge\n18\n18 silver badges\n20\n20 bronze badges","comments":["This earlier answer already says that you can use git commit --amend, and it also says that you can use git rebase -i HEAD~commit_count, all you did was plug in 3 for commit_count.","Downvoted as well. People just don't bother to read existing answers.","This is not complete answer, missing \"Find the commit you want, change pick to r (reword)...\" as explained explained here stackoverflow.com/a/28421811/1818723"]},{"answer":"If you have to change an old commit message over multiple branches (i.e., the commit with the erroneous message is present in multiple branches) you might want to use:\n\ngit filter-branch -f --msg-filter \\\n'sed \"s/<old message>/<new message>/g\"' -- --all\n\n\nGit will create a temporary directory for rewriting and additionally backup old references in refs/original/.\n\n-f will enforce the execution of the operation. This is necessary if the temporary directory is already present or if there are already references stored under refs/original. If that is not the case, you can drop this flag.\n\n-- separates filter-branch options from revision options.\n\n--all will make sure that all branches and tags are rewritten.\n\nDue to the backup of your old references, you can easily go back to the state before executing the command.\n\nSay, you want to recover your master and access it in branch old_master:\n\ngit checkout -b old_master refs/original/refs/heads/master\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 15 '12 at 9:29\nsebers\n2,8561\n1 gold badge\n11\n11 silver badges\n12\n12 bronze badges","comments":["This answer doesn't address the OP's question, as they're purely interested in fixing a commit they've only just done. I regularly use git commit --amend to fix up comments or add files I forgot to git add, but only ever before I've git pushed. I also use git filter-branch when I want to totally mess with the version history, but the OP doesn't want this, so this answer needs a big health warning - don't try this at home, peeps!!"]},{"answer":"Use\n\ngit commit --amend\n\n\nTo understand it in detail, an excellent post is 4. Rewriting Git History. It also talks about when not to use git commit --amend.\n\nShare\nImprove this answer\nFollow\nedited May 22 '18 at 19:46\nanswered Mar 27 '13 at 20:43\nskin\n2,5401\n1 gold badge\n14\n14 silver badges\n13\n13 bronze badges","comments":["Is there a good way to fix commit messages already pushed to a public repository? So far I have come to the conclusion that, once pushed, my commit message typos and thinkos have to live forever.","In a word, NOPE! There is no GOOD way to retract something you have pushed. All retractions are BAD to a greater or lesser degree. You need to adopt the discipline of working in a branch in your own private repository, doing multiple commits as you add a bit, test a bit, tweak a bit. Then merge your entire branch into a single commit, write a new commit message describing the overall change, PROOFREAD it, and push.","Just to point out the obvious that one doesn't have to make a single commit when going back from a feature branch. What many people do is rebase on the target branch (to make things look clean) then merge with the option to suppress fast-forwarding. Agree with the main point of being careful before you push up though.","The git commit --amend answer had already been given (several times) before you wrote yours. Why did you post it again? If you wanted to add a link to \"Rewriting Git History\" you could've edited one of the existing answers, or left a comment."]},{"answer":"If it's your last commit, just amend the commit:\n\ngit commit --amend -o -m \"New commit message\"\n\n\n(Using the -o (--only) flag to make sure you change only the commit message)\n\n\n\n\nIf it's a buried commit, use the awesome interactive rebase:\n\ngit rebase -i @~9   # Show the last 9 commits in a text editor\n\n\nFind the commit you want, change pick to r (reword), and save and close the file. Done!\n\n\n\n\nMiniature Vim tutorial (or, how to rebase with only 8 keystrokes 3jcwrEscZZ):\n\nRun vimtutor if you have time\nhjkl correspond to movement keys ←↓↑→\nAll commands can be prefixed with a \"range\", e.g. 3j moves down three lines\ni to enter insert mode — text you type will appear in the file\nEsc or Ctrlc to exit insert mode and return to \"normal\" mode\nu to undo\nCtrlr to redo\ndd, dw, dl to delete a line, word, or letter, respectively\ncc, cw, cl to change a line, word, or letter, respectively (same as ddi)\nyy, yw, yl to copy (\"yank\") a line, word, or letter, respectively\np or P to paste after, or before current position, respectively\n:wEnter to save (write) a file\n:q!Enter to quit without saving\n:wqEnter or ZZ to save and quit\n\nIf you edit text a lot, then switch to the Dvorak keyboard layout, learn to touch-type, and learn Vim. Is it worth the effort? Yes.\n\n\n\n\nProTip™: Don't be afraid to experiment with \"dangerous\" commands that rewrite history* — Git doesn't delete your commits for 90 days by default; you can find them in the reflog:\n\n$ git reset @~3   # Go back three commits\n$ git reflog\nc4f708b HEAD@{0}: reset: moving to @~3\n2c52489 HEAD@{1}: commit: more changes\n4a5246d HEAD@{2}: commit: make important changes\ne8571e4 HEAD@{3}: commit: make some changes\n... earlier commits ...\n$ git reset 2c52489\n... and you're back where you started\n\n\n* Watch out for options like --hard and --force though — they can discard data. * Also, don't rewrite history on any branches you're collaborating on.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 10 '15 at 0:01\nZaz\n40.4k10\n10 gold badges\n71\n71 silver badges\n93\n93 bronze badges","comments":["The vim part is completely off-topic, and instead of encouraging users to spend time learning to use an arcane editor, why not teach them something more on-topic, like how to set up the default git editor to be something user friendly, like nano? We're talking about trivial modifications that need to be made to a text file, not hardcore coding that would generate a flame war about the \"best\" text editor.","@DanDascalescu: Because it's quicker to learn Vim using the instructions above than perform several rebases using nano. The whole reason git opens a text editor and not its own interface for rebasing is because Vim exists: it's lightweight, installed by default on most systems, and very easy to learn enough to perform a rebase with ease: e.g. ddjjpZZ moves a commit 2 down. There's nothing arcane about basic Vim knowledge; it takes 10min to become more comfortable with Vim than nano."]},{"answer":"Amend\n\nYou have a couple of options here. You can do\n\ngit commit --amend\n\n\nas long as it's your last commit.\n\nInteractive rebase\n\nOtherwise, if it's not your last commit, you can do an interactive rebase,\n\ngit rebase -i [branched_from] [hash before commit]\n\n\nThen inside the interactive rebase you simply add edit to that commit. When it comes up, do a git commit --amend and modify the commit message. If you want to roll back before that commit point, you could also use git reflog and just delete that commit. Then you just do a git commit again.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:20\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 18 '13 at 1:45\nwallerjake\n3,8593\n3 gold badges\n24\n24 silver badges\n31\n31 bronze badges","comments":[]},{"answer":"If you are using the Git GUI, you can amend the last commit which hasn't been pushed with:\n\nCommit/Amend Last Commit\n\nShare\nImprove this answer\nFollow\nedited Mar 16 '13 at 9:37\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 1 '12 at 5:03\ngulchrider\n4,2263\n3 gold badges\n23\n23 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"I use the Git GUI as much as I can, and that gives you the option to amend the last commit:\n\nAlso, git rebase -i origin/masteris a nice mantra that will always present you with the commits you have done on top of master, and give you the option to amend, delete, reorder or squash. No need to get hold of that hash first.\n\nShare\nImprove this answer\nFollow\nedited May 21 '14 at 2:44\nAmal Murali\n71.2k17\n17 gold badges\n121\n121 silver badges\n140\n140 bronze badges\nanswered Aug 4 '13 at 23:13\nHavard Graff\n2,7291\n1 gold badge\n12\n12 silver badges\n16\n16 bronze badges","comments":["How do I get to that screen that you have displayed in your example?","It's the lower right portion of the Windows Git Gui. Just select the 'Amend Last Commit' toggle, and it will populate with the most recent commit info."]},{"answer":"Wow, so there are a lot of ways to do this.\n\nYet another way to do this is to delete the last commit, but keep its changes so that you won't lose your work. You can then do another commit with the corrected message. This would look something like this:\n\ngit reset --soft HEAD~1\ngit commit -m 'New and corrected commit message'\n\n\nI always do this if I forget to add a file or do a change.\n\nRemember to specify --soft instead of --hard, otherwise you lose that commit entirely.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 '14 at 8:21\nuser456814\nanswered Dec 2 '13 at 21:31\nRadu Murzea\n10.1k10\n10 gold badges\n44\n44 silver badges\n69\n69 bronze badges","comments":["This does the exact same thing as git commit --amend except that it is a 2-step process.","@JosephK.Strauss I believe ammending the commit also keeps original commit author and date information, having the new commiter and date info separately. I'm not sure this approach does that.","@EvertonAgner You are correct. --amend will keep the author information, but the question only asks to change the message.","Small correction over here you to added the files back again if all files than git add . can be used an post that git commit -m \"New message\" and git push origin BRANCH_NAME"]},{"answer":"For anyone looking for a Windows/Mac GUI to help with editing older messages (i.e. not just the latest message), I'd recommend Sourcetree. The steps to follow are below the image.\n\nFor commits that haven't been pushed to a remote yet:\n\nMake sure you've committed or stashed all current changes (i.e., so there are no files listed in the \"File Status\" tab) - it won't work otherwise.\nIn the \"Log / History\" tab, right click on the entry with an adjoining line in the graph one below the commit(s) you wish to edit and select \"Rebase children of <commit ref> interactively...\"\nSelect the whole row for a commit message you wish to change (click on the \"Message\" column).\nClick the \"Edit Message\" button.\nEdit the message as desired in the dialog that comes up and then click OK.\nRepeat steps 3-4 if there are other commit messages to change.\nClick OK: Rebasing will commence. If all is well, the output will end \"Completed successfully\". NOTE: I've sometimes seen this fail with Unable to create 'project_path/.git/index.lock': File exists. when trying to modify multiple commit messages at the same time. Not sure exactly what the issue is, or whether it will be fixed in a future version of Sourcetree, but if this happens would recommend rebasing them one at a time (slower but seems more reliable).\n\n...Or... for commits that have already been pushed:\n\nFollow the steps in this answer, which are similar to above, but require a further command to be run from the command line (git push origin <branch> -f) to force-push the branch. I'd recommend reading it all and applying the necessary caution!\n\nShare\nImprove this answer\nFollow\nedited Sep 15 '20 at 10:02\nDeni J.\n1,2173\n3 silver badges\n21\n21 bronze badges\nanswered Nov 6 '14 at 15:01\nSteve Chambers\n32.4k15\n15 gold badges\n131\n131 silver badges\n175\n175 bronze badges","comments":["out of all answers — this is the most appropriate for all git newbies ^^^ (use a free program SourceTree and apply \"Rebase children of\" on a commit before the one you want to edit)","That was exactly what I was looking for! It's a pity SourceTree is not available for Linux..."]},{"answer":"If you just want to edit the latest commit, use:\n\ngit commit --amend\n\n\nor\n\ngit commit --amend -m 'one line message'\n\n\nBut if you want to edit several commits in a row, you should use rebasing instead:\n\ngit rebase -i <hash of one commit before the wrong commit>\n\n\nIn a file, like the one above, write edit/e or one of the other options, and hit save and exit.\n\nNow you'll be at the first wrong commit. Make changes in the files, and they'll be automatically staged for you. Type\n\ngit commit --amend\n\n\nSave and exit that and type\n\ngit rebase --continue\n\n\nto move to next selection until finished with all your selections.\n\nNote that these things change all your SHA hashes after that particular commit.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:33\ncommunity wiki\n\n\n4 revs, 3 users 81%\nShubham Chaudhary","comments":["git rebase -i <hash of one commit before the wrong commit> works for me. thanks."]},{"answer":"If you only want to change your last message you should use the --only flag or its shortcut -o with commit --amend:\n\ngit commit --amend -o -m \"New commit message\"\n\n\nThis ensures that you don't accidentally enhance your commit with staged stuff. Of course it's best to have a proper $EDITOR configuration. Then you can leave the -m option out, and Git will pre-fill the commit message with the old one. In this way it can be easily edited.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:38\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 23 '14 at 8:40\nDavid Ongaro\n2,9011\n1 gold badge\n20\n20 silver badges\n34\n34 bronze badges","comments":["The \"top\" answer doesn't answer the question. It just gives a general introduction to git commit --amend. The question was very specific, therefore longer != better. The decisive mentioning of the -o flag would probably be buried in the rest of the information. I'm also not comfortable editing an answer which has so many votes already.","That being said you're free to edit the top answer, since there is a real danger that people are using that as the \"correct\" answer. It can easily happen to amend your commit with staged stuff -- it happened to me, and it's really annoying when you happen to push that. But still, quantity is no guarantee for correctness. Neither in number of answers nor in number of votes.","I wouldn't go so far to say that the top answer is \"incorrect\" and that it \"doesn't answer the question\". It definitely works and answers the question, you just need to make sure that you don't have staged changes when you try to amend. But I see your point about having to warn people about that. I'll edit it in later if I have time.","To be fair: even though the --only option with --amend is available since git 1.3.0 it didn't work correctly till it was fixed in 1.7.11.3 (ea2d4ed35902ce15959965ab86d80527731a177c). So the right answer back in 2008 would probably have been something like: git stash; git commit --amend; git stash pop."]},{"answer":"Update your last wrong commit message with the new commit message in one line:\n\ngit commit --amend -m \"your new commit message\"\n\n\nOr, try Git reset like below:\n\n# You can reset your head to n number of commit\n# NOT a good idea for changing last commit message,\n# but you can get an idea to split commit into multiple commits\ngit reset --soft HEAD^\n\n# It will reset you last commit. Now, you\n# can re-commit it with new commit message.\n\nUsing reset to split commits into smaller commits\n\ngit reset can help you to break one commit into multiple commits too:\n\n# Reset your head. I am resetting to last commits:\ngit reset --soft HEAD^\n# (You can reset multiple commit by doing HEAD~2(no. of commits)\n\n# Now, reset your head for splitting it to multiple commits\ngit reset HEAD\n\n# Add and commit your files separately to make multiple commits: e.g\ngit add app/\ngit commit -m \"add all files in app directory\"\n\ngit add config/\ngit commit -m \"add all files in config directory\"\n\n\nHere you have successfully broken your last commit into two commits.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 22 '14 at 8:57\nprzbadu\n5,1612\n2 gold badges\n38\n38 silver badges\n55\n55 bronze badges","comments":["If all you want to do is to edit the message of your last commit, using a soft reset for that purpose is over-kill. Just use git commit --amend, exactly like how it says in the top voted answer. Additionally, git reset --soft HEAD^ works identically to the soft reset in this earlier answer, because they both reset back to the first parent commit.","I only bother to add git reset in the solution just to give an idea to split one commit message into multiple commit messages. Because, I have faced that problem when, I was starting to use git. Sometimes, this can be really helpfull. :)"]},{"answer":"On this question there are a lot of answers, but none of them explains in super detail how to change older commit messages using Vim. I was stuck trying to do this myself, so here I'll write down in detail how I did this especially for people who have no experience in Vim!\n\nI wanted to change my five latest commits that I already pushed to the server. This is quite 'dangerous' because if someone else already pulled from this, you can mess things up by changing the commit messages. However, when you’re working on your own little branch and are sure no one pulled it you can change it like this:\n\nLet's say you want to change your five latest commits, and then you type this in the terminal:\n\ngit rebase -i HEAD~5\n\n\n*Where 5 is the number of commit messages you want to change (so if you want to change the 10th to last commit, you type in 10).\n\nThis command will get you into Vim there you can ‘edit’ your commit history. You’ll see your last five commits at the top like this:\n\npick <commit hash> commit message\n\n\nInstead of pick you need to write reword. You can do this in Vim by typing in i. That makes you go in to insert mode. (You see that you’re in insert mode by the word INSERT at the bottom.) For the commits you want to change, type in reword instead of pick.\n\nThen you need to save and quit this screen. You do that by first going in to ‘command-mode’ by pressing the Escbutton (you can check that you’re in command-mode if the word INSERT at the bottom has disappeared). Then you can type in a command by typing :. The command to save and quit is wq. So if you type in :wq you’re on the right track.\n\nThen Vim will go over every commit message you want to reword, and here you can actually change the commit messages. You’ll do this by going into insert mode, changing the commit message, going into the command-mode, and save and quit. Do this five times and you’re out of Vim!\n\nThen, if you already pushed your wrong commits, you need to git push --force to overwrite them. Remember that git push --force is quite a dangerous thing to do, so make sure that no one pulled from the server since you pushed your wrong commits!\n\nNow you have changed your commit messages!\n\n(As you see, I'm not that experienced in Vim, so if I used the wrong 'lingo' to explain what's happening, feel free to correct me!)\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 7 '14 at 9:18\nMarijn\n1,34910\n10 silver badges\n12\n12 bronze badges","comments":["<nitpick>There are no \"threads\" on Stack Overflow, because it's not a discussion forum, there are only \"questions\", \"answers\", and \"posts\".</nitpick>. Also, not all versions of Vim are the same, not all of them will let you delete characters in insertion mode (makes sense in a way, right?). If you want to always be able to delete characters in Vim, X and x will do that (little x deletes characters in front of the cursor, X will delete behind). If you make mistakes, you can use u repeatedly to undo. Finally, r is shorthand for reword in the interactive rebase editor.","To change a word in vim is cw typed at its beginning (though the question is not about vim, I agree).","You don't need to use that abomination. You can set your git editor to something sane and user-friendly, like nano or Midnight Commander's mcedit."]},{"answer":"You can use git-rebase-reword\n\nIt is designed to edit any commit (not just last) same way as commit --amend\n\n$ git rebase-reword <commit-or-refname>\n\n\nIt is named after the action on rebase interactive to amend a commit: \"reword\". See this post and man -section interactive mode-\n\nExamples:\n\n$ git rebase-reword b68f560\n$ git rebase-reword HEAD^\n\nShare\nImprove this answer\nFollow\nedited Jul 29 '15 at 22:28\nanswered Feb 21 '15 at 12:21\nalbfan\n11.1k2\n2 gold badges\n51\n51 silver badges\n74\n74 bronze badges","comments":["This requires installing an external program. In my opinion, it would be better to learn to use the built-in tools and aliases more effectively. I would type: g c; g rb -i @~9 (commit and rebase), move the new commit to where I want it, change commit to f (fixup), and save. If you wanted something faster than that, you could alias git commit --fixup=<commit>; git rebase -i --autosquash <commit>^"]},{"answer":"I have added the aliases reci and recm for recommit (amend) it. Now I can do it with git recm or git recm -m:\n\n$ vim ~/.gitconfig\n\n[alias]\n\n    ......\n    cm = commit\n    reci = commit --amend\n    recm = commit --amend\n    ......\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 12:29\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 6 '14 at 7:24\nChu-Siang Lai\n2,38022\n22 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"I realised that I had pushed a commit with a typo in it. In order to undo, I did the following:\n\ngit commit --amend -m \"T-1000, advanced prototype\"\ngit push --force\n\n\nWarning: force pushing your changes will overwrite the remote branch with your local one. Make sure that you aren't going to be overwriting anything that you want to keep. Also be cautious about force pushing an amended (rewritten) commit if anyone else shares the branch with you, because they'll need to rewrite their own history if they have the old copy of the commit that you've just rewritten.\n\nShare\nImprove this answer\nFollow\nedited Aug 5 '14 at 14:44\nuser456814\nanswered Jul 19 '14 at 17:27\nneoneye\n45.1k23\n23 gold badges\n156\n156 silver badges\n145\n145 bronze badges","comments":["Nothing gets ever \"overwritten\" in git. In this case the branch pointer will be set to your new commit and the old commit will get stale if no references are left to it and it might get cleaned up after a few weeks. (Until then others still can find and reference it, e.g. by looking into the reflog.)"]},{"answer":"I like to use the following:\n\ngit status\ngit add --all\ngit commit -am \"message goes here about the change\"\ngit pull <origin master>\ngit push <origin master>\nShare\nImprove this answer\nFollow\nedited Feb 3 '15 at 11:08\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 8 '14 at 9:14\nKedar Adhikari\n6915\n5 silver badges\n5\n5 bronze badges","comments":[]},{"answer":"If you have not pushed the code to your remote branch (GitHub/Bitbucket) you can change the commit message on the command line as below.\n\n git commit --amend -m \"Your new message\"\n\n\nIf you're working on a specific branch do this:\n\ngit commit --amend -m \"BRANCH-NAME: new message\"\n\n\nIf you've already pushed the code with the wrong message, and you need to be careful when changing the message. That is, after you change the commit message and try pushing it again, you end up with having issues. To make it smooth, follow these steps.\n\nPlease read my entire answer before doing it.\n\ngit commit --amend -m \"BRANCH-NAME : your new message\"\n\ngit push -f origin BRANCH-NAME                # Not a best practice. Read below why?\n\n\nImportant note: When you use the force push directly you might end up with code issues that other developers are working on the same branch. So to avoid those conflicts, you need to pull the code from your branch before making the force push:\n\n git commit --amend -m \"BRANCH-NAME : your new message\"\n git pull origin BRANCH-NAME\n git push -f origin BRANCH-NAME\n\n\nThis is the best practice when changing the commit message, if it was already pushed.\n\nShare\nImprove this answer\nFollow\nedited Feb 3 '15 at 11:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 13 '15 at 7:03\nPrabhakar Undurthi\n5,8862\n2 gold badges\n37\n37 silver badges\n46\n46 bronze badges","comments":[]}]},{"id":"111102","href":"https://stackoverflow.com/questions/111102/how-do-javascript-closures-work","title":"How do JavaScript closures work?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nHow would you explain JavaScript closures to someone with a knowledge of the concepts they consist of (for example functions, variables and the like), but does not understand closures themselves?\n\nI have seen the Scheme example given on Wikipedia, but unfortunately it did not help.\n    ","questionComments":[],"answers":[{"answer":"A closure is a pairing of:\n\nA function, and\nA reference to that function's outer scope (lexical environment)\n\nA lexical environment is part of every execution context (stack frame) and is a map between identifiers (ie. local variable names) and values.\n\nEvery function in JavaScript maintains a reference to its outer lexical environment. This reference is used to configure the execution context created when a function is invoked. This reference enables code inside the function to \"see\" variables declared outside the function, regardless of when and where the function is called.\n\nIf a function was called by a function, which in turn was called by another function, then a chain of references to outer lexical environments is created. This chain is called the scope chain.\n\nIn the following code, inner forms a closure with the lexical environment of the execution context created when foo is invoked, closing over variable secret:\n\nfunction foo() {\n  const secret = Math.trunc(Math.random()*100)\n  return function inner() {\n    console.log(`The secret number is ${secret}.`)\n  }\n}\nconst f = foo() // `secret` is not directly accessible from outside `foo`\nf() // The only way to retrieve `secret`, is to invoke `f`\n Run code snippetExpand snippet\n\nIn other words: in JavaScript, functions carry a reference to a private \"box of state\", to which only they (and any other functions declared within the same lexical environment) have access. This box of the state is invisible to the caller of the function, delivering an excellent mechanism for data-hiding and encapsulation.\n\nAnd remember: functions in JavaScript can be passed around like variables (first-class functions), meaning these pairings of functionality and state can be passed around your program: similar to how you might pass an instance of a class around in C++.\n\nIf JavaScript did not have closures, then more states would have to be passed between functions explicitly, making parameter lists longer and code noisier.\n\nSo, if you want a function to always have access to a private piece of state, you can use a closure.\n\n...and frequently we do want to associate the state with a function. For example, in Java or C++, when you add a private instance variable and a method to a class, you are associating state with functionality.\n\nIn C and most other common languages, after a function returns, all the local variables are no longer accessible because the stack-frame is destroyed. In JavaScript, if you declare a function within another function, then the local variables of the outer function can remain accessible after returning from it. In this way, in the code above, secret remains available to the function object inner, after it has been returned from foo.\n\nUses of Closures\n\nClosures are useful whenever you need a private state associated with a function. This is a very common scenario - and remember: JavaScript did not have a class syntax until 2015, and it still does not have a private field syntax. Closures meet this need.\n\nPrivate Instance Variables\n\nIn the following code, the function toString closes over the details of the car.\n\nfunction Car(manufacturer, model, year, color) {\n  return {\n    toString() {\n      return `${manufacturer} ${model} (${year}, ${color})`\n    }\n  }\n}\nconst car = new Car('Aston Martin','V8 Vantage','2012','Quantum Silver')\nconsole.log(car.toString())\n Run code snippetExpand snippet\n\nFunctional Programming\n\nIn the following code, the function inner closes over both fn and args.\n\nfunction curry(fn) {\n  const args = []\n  return function inner(arg) {\n    if(args.length === fn.length) return fn(...args)\n    args.push(arg)\n    return inner\n  }\n}\n\nfunction add(a, b) {\n  return a + b\n}\n\nconst curriedAdd = curry(add)\nconsole.log(curriedAdd(2)(3)()) // 5\n Run code snippetExpand snippet\n\nEvent-Oriented Programming\n\nIn the following code, function onClick closes over variable BACKGROUND_COLOR.\n\nconst $ = document.querySelector.bind(document)\nconst BACKGROUND_COLOR = 'rgba(200,200,242,1)'\n\nfunction onClick() {\n  $('body').style.background = BACKGROUND_COLOR\n}\n\n$('button').addEventListener('click', onClick)\n<button>Set background color</button>\n Run code snippetExpand snippet\n\nModularization\n\nIn the following example, all the implementation details are hidden inside an immediately executed function expression. The functions tick and toString close over the private state and functions they need to complete their work. Closures have enabled us to modularise and encapsulate our code.\n\nlet namespace = {};\n\n(function foo(n) {\n  let numbers = []\n  function format(n) {\n    return Math.trunc(n)\n  }\n  function tick() {\n    numbers.push(Math.random() * 100)\n  }\n  function toString() {\n    return numbers.map(format)\n  }\n  n.counter = {\n    tick,\n    toString\n  }\n}(namespace))\n\nconst counter = namespace.counter\ncounter.tick()\ncounter.tick()\nconsole.log(counter.toString())\n Run code snippetExpand snippet\n\nExamples\nExample 1\n\nThis example shows that the local variables are not copied in the closure: the closure maintains a reference to the original variables themselves. It is as though the stack-frame stays alive in memory even after the outer function exits.\n\nfunction foo() {\n  let x = 42\n  let inner  = function() { console.log(x) }\n  x = x+1\n  return inner\n}\nvar f = foo()\nf() // logs 43\n Run code snippetExpand snippet\n\nExample 2\n\nIn the following code, three methods log, increment, and update all close over the same lexical environment.\n\nAnd every time createObject is called, a new execution context (stack frame) is created and a completely new variable x, and a new set of functions (log etc.) are created, that close over this new variable.\n\nfunction createObject() {\n  let x = 42;\n  return {\n    log() { console.log(x) },\n    increment() { x++ },\n    update(value) { x = value }\n  }\n}\n\nconst o = createObject()\no.increment()\no.log() // 43\no.update(5)\no.log() // 5\nconst p = createObject()\np.log() // 42\n Run code snippetExpand snippet\n\nExample 3\n\nIf you are using variables declared using var, be careful you understand which variable you are closing over. Variables declared using var are hoisted. This is much less of a problem in modern JavaScript due to the introduction of let and const.\n\nIn the following code, each time around the loop, a new function inner is created, which closes over i. But because var i is hoisted outside the loop, all of these inner functions close over the same variable, meaning that the final value of i (3) is printed, three times.\n\nfunction foo() {\n  var result = []\n  for (var i = 0; i < 3; i++) {\n    result.push(function inner() { console.log(i) } )\n  }\n  return result\n}\n\nconst result = foo()\n// The following will print `3`, three times...\nfor (var i = 0; i < 3; i++) {\n  result[i]() \n}\n Run code snippetExpand snippet\n\nFinal points:\nWhenever a function is declared in JavaScript closure is created.\nReturning a function from inside another function is the classic example of closure, because the state inside the outer function is implicitly available to the returned inner function, even after the outer function has completed execution.\nWhenever you use eval() inside a function, a closure is used. The text you eval can reference local variables of the function, and in the non-strict mode, you can even create new local variables by using eval('var foo = …').\nWhen you use new Function(…) (the Function constructor) inside a function, it does not close over its lexical environment: it closes over the global context instead. The new function cannot reference the local variables of the outer function.\nA closure in JavaScript is like keeping a reference (NOT a copy) to the scope at the point of function declaration, which in turn keeps a reference to its outer scope, and so on, all the way to the global object at the top of the scope chain.\nA closure is created when a function is declared; this closure is used to configure the execution context when the function is invoked.\nA new set of local variables is created every time a function is called.\nLinks\nDouglas Crockford's simulated private attributes and private methods for an object, using closures.\nA great explanation of how closures can cause memory leaks in IE if you are not careful.\nMDN documentation on JavaScript Closures.\nShare\nImprove this answer\nFollow\nedited Jan 26 at 13:08\ncommunity wiki\n\n\n64 revs, 53 users 30%\nBen Aston","comments":[]},{"answer":"Every function in JavaScript maintains a link to its outer lexical environment. A lexical environment is a map of all the names (eg. variables, parameters) within a scope, with their values.\n\nSo, whenever you see the function keyword, code inside that function has access to variables declared outside the function.\n\nfunction foo(x) {\n  var tmp = 3;\n\n  function bar(y) {\n    console.log(x + y + (++tmp)); // will log 16\n  }\n\n  bar(10);\n}\n\nfoo(2);\n Run code snippetExpand snippet\n\nThis will log 16 because function bar closes over the parameter x and the variable tmp, both of which exist in the lexical environment of outer function foo.\n\nFunction bar, together with its link with the lexical environment of function foo is a closure.\n\nA function doesn't have to return in order to create a closure. Simply by virtue of its declaration, every function closes over its enclosing lexical environment, forming a closure.\n\nfunction foo(x) {\n  var tmp = 3;\n\n  return function (y) {\n    console.log(x + y + (++tmp)); // will also log 16\n  }\n}\n\nvar bar = foo(2);\nbar(10); // 16\nbar(10); // 17\n Run code snippetExpand snippet\n\nThe above function will also log 16, because the code inside bar can still refer to argument x and variable tmp, even though they are no longer directly in scope.\n\nHowever, since tmp is still hanging around inside bar's closure, it is available to be incremented. It will be incremented each time you call bar.\n\nThe simplest example of a closure is this:\n\nvar a = 10;\n\nfunction test() {\n  console.log(a); // will output 10\n  console.log(b); // will output 6\n}\nvar b = 6;\ntest();\n Run code snippetExpand snippet\n\nWhen a JavaScript function is invoked, a new execution context ec is created. Together with the function arguments and the target object, this execution context also receives a link to the lexical environment of the calling execution context, meaning the variables declared in the outer lexical environment (in the above example, both a and b) are available from ec.\n\nEvery function creates a closure because every function has a link to its outer lexical environment.\n\nNote that variables themselves are visible from within a closure, not copies.\n\nShare\nImprove this answer\nFollow\nedited Mar 28 '20 at 5:44\ncommunity wiki\n\n\n41 revs, 31 users 31%\nAli","comments":[]},{"answer":"FOREWORD: this answer was written when the question was:\n\nLike the old Albert said : \"If you can't explain it to a six-year old, you really don't understand it yourself.”. Well I tried to explain JS closures to a 27 years old friend and completely failed.\n\nCan anybody consider that I am 6 and strangely interested in that subject ?\n\nI'm pretty sure I was one of the only people that attempted to take the initial question literally. Since then, the question has mutated several times, so my answer may now seem incredibly silly & out of place. Hopefully the general idea of the story remains fun for some.\n\nI'm a big fan of analogy and metaphor when explaining difficult concepts, so let me try my hand with a story.\n\nOnce upon a time:\n\nThere was a princess...\n\nfunction princess() {\n\n\nShe lived in a wonderful world full of adventures. She met her Prince Charming, rode around her world on a unicorn, battled dragons, encountered talking animals, and many other fantastical things.\n\n    var adventures = [];\n\n    function princeCharming() { /* ... */ }\n\n    var unicorn = { /* ... */ },\n        dragons = [ /* ... */ ],\n        squirrel = \"Hello!\";\n\n    /* ... */\n\n\nBut she would always have to return back to her dull world of chores and grown-ups.\n\n    return {\n\n\nAnd she would often tell them of her latest amazing adventure as a princess.\n\n        story: function() {\n            return adventures[adventures.length - 1];\n        }\n    };\n}\n\n\nBut all they would see is a little girl...\n\nvar littleGirl = princess();\n\n\n...telling stories about magic and fantasy.\n\nlittleGirl.story();\n\n\nAnd even though the grown-ups knew of real princesses, they would never believe in the unicorns or dragons because they could never see them. The grown-ups said that they only existed inside the little girl's imagination.\n\nBut we know the real truth; that the little girl with the princess inside...\n\n...is really a princess with a little girl inside.\n\nShare\nImprove this answer\nFollow\nedited Nov 1 '17 at 11:40\ncommunity wiki\n\n\n11 revs, 5 users 58%\nJacob Swartwood","comments":["I love this explanation, truly. For those who read it and don't follow, the analogy is this: the princess() function is a complex scope containing private data. Outside the function, the private data can't be seen or accessed. The princess keeps the unicorns, dragons, adventures etc. in her imagination (private data) and the grown-ups can't see them for themselves. BUT the princess's imagination is captured in the closure for the story() function, which is the only interface the littleGirl instance exposes into the world of magic.","Having undefined values makes it more difficult to understand. Here is the true story jsfiddle.net/rjdx34k0/3","Oh nice, I was that close to make an edit to remove the what I thought to be the extra space in the beginning. Nice job, +1","And Prince Charming can add to her adventures, can kill all the dragons to save her from dangers like below: function princeCharming {    adventures.push('Honeymoon Trip', 'Skydiving', 'Visiting Somalia');    const pickADragonToKill = dragons.pop(); }"]},{"answer":"Taking the question seriously, we should find out what a typical 6-year-old is capable of cognitively, though admittedly, one who is interested in JavaScript is not so typical.\n\nOn Childhood Development: 5 to 7 Years it says:\n\nYour child will be able to follow two-step directions. For example, if you say to your child, \"Go to the kitchen and get me a trash bag\" they will be able to remember that direction.\n\nWe can use this example to explain closures, as follows:\n\nThe kitchen is a closure that has a local variable, called trashBags. There is a function inside the kitchen called getTrashBag that gets one trash bag and returns it.\n\nWe can code this in JavaScript like this:\n\nfunction makeKitchen() {\n  var trashBags = ['A', 'B', 'C']; // only 3 at first\n\n  return {\n    getTrashBag: function() {\n      return trashBags.pop();\n    }\n  };\n}\n\nvar kitchen = makeKitchen();\n\nconsole.log(kitchen.getTrashBag()); // returns trash bag C\nconsole.log(kitchen.getTrashBag()); // returns trash bag B\nconsole.log(kitchen.getTrashBag()); // returns trash bag A\n Run code snippetExpand snippet\n\nFurther points that explain why closures are interesting:\n\nEach time makeKitchen() is called, a new closure is created with its own separate trashBags.\nThe trashBags variable is local to the inside of each kitchen and is not accessible outside, but the inner function on the getTrashBag property does have access to it.\nEvery function call creates a closure, but there would be no need to keep the closure around unless an inner function, which has access to the inside of the closure, can be called from outside the closure. Returning the object with the getTrashBag function does that here.\nShare\nImprove this answer\nFollow\nedited Oct 10 '18 at 17:50\ncommunity wiki\n\n\n18 revs, 5 users 84%\ndlaliberte","comments":[]},{"answer":"The Straw Man\n\nI need to know how many times a button has been clicked and do something on every third click...\n\nFairly Obvious Solution\n\n// Declare counter outside event handler's scope\nvar counter = 0;\nvar element = document.getElementById('button');\n\nelement.addEventListener(\"click\", function() {\n  // Increment outside counter\n  counter++;\n\n  if (counter === 3) {\n    // Do something every third time\n    console.log(\"Third time's the charm!\");\n\n    // Reset counter\n    counter = 0;\n  }\n});\n<button id=\"button\">Click Me!</button>\n Run code snippetExpand snippet\n\nNow this will work, but it does encroach into the outer scope by adding a variable, whose sole purpose is to keep track of the count. In some situations, this would be preferable as your outer application might need access to this information. But in this case, we are only changing every third click's behavior, so it is preferable to enclose this functionality inside the event handler.\n\nConsider this option\n\nvar element = document.getElementById('button');\n\nelement.addEventListener(\"click\", (function() {\n  // init the count to 0\n  var count = 0;\n\n  return function(e) { // <- This function becomes the click handler\n    count++; //    and will retain access to the above `count`\n\n    if (count === 3) {\n      // Do something every third time\n      console.log(\"Third time's the charm!\");\n\n      //Reset counter\n      count = 0;\n    }\n  };\n})());\n<button id=\"button\">Click Me!</button>\n Run code snippetExpand snippet\n\nNotice a few things here.\n\nIn the above example, I am using the closure behavior of JavaScript. This behavior allows any function to have access to the scope in which it was created, indefinitely. To practically apply this, I immediately invoke a function that returns another function, and because the function I'm returning has access to the internal count variable (because of the closure behavior explained above) this results in a private scope for usage by the resulting function... Not so simple? Let's dilute it down...\n\nA simple one-line closure\n\n//          _______________________Immediately invoked______________________\n//         |                                                                |\n//         |        Scope retained for use      ___Returned as the____      |\n//         |       only by returned function   |    value of func     |     |\n//         |             |            |        |                      |     |\n//         v             v            v        v                      v     v\nvar func = (function() { var a = 'val'; return function() { alert(a); }; })();\n\n\nAll variables outside the returned function are available to the returned function, but they are not directly available to the returned function object...\n\nfunc();  // Alerts \"val\"\nfunc.a;  // Undefined\n\n\nGet it? So in our primary example, the count variable is contained within the closure and always available to the event handler, so it retains its state from click to click.\n\nAlso, this private variable state is fully accessible, for both readings and assigning to its private scoped variables.\n\nThere you go; you're now fully encapsulating this behavior.\n\nFull Blog Post (including jQuery considerations)\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n17 revs, 8 users 64%\njondavidjohn","comments":[]},{"answer":"Closures are hard to explain because they are used to make some behaviour work that everybody intuitively expects to work anyway. I find the best way to explain them (and the way that I learned what they do) is to imagine the situation without them:\n\nconst makePlus = function(x) {\n    return function(y) { return x + y; };\n}\n\nconst plus5 = makePlus(5);\nconsole.log(plus5(3));\n Run code snippetExpand snippet\n\nWhat would happen here if JavaScript didn't know closures? Just replace the call in the last line by its method body (which is basically what function calls do) and you get:\n\nconsole.log(x + 3);\n\n\nNow, where's the definition of x? We didn't define it in the current scope. The only solution is to let plus5 carry its scope (or rather, its parent's scope) around. This way, x is well-defined and it is bound to the value 5.\n\nShare\nImprove this answer\nFollow\nedited Jun 30 '20 at 8:16\ncommunity wiki\n\n\n4 revs, 3 users 70%\nKonrad Rudolph","comments":["\"they are used to make some behaviour work that everybody intuitively expects to work anyway\" Appreciate this comment, as that was partly what I was struggling with. I felt like I was missing something, but it turns out I wasn't!"]},{"answer":"TLDR\n\nA closure is a link between a function and its outer lexical (ie. as-written) environment, such that the identifiers (variables, parameters, function declarations etc) defined within that environment are visible from within the function, regardless of when or from where the function is invoked.\n\nDetails\n\nIn the terminology of the ECMAScript specification, a closure can be said to be implemented by the [[Environment]] reference of every function-object, which points to the lexical environment within which the function is defined.\n\nWhen a function is invoked via the internal [[Call]] method, the [[Environment]] reference on the function-object is copied into the outer environment reference of the environment record of the newly-created execution context (stack frame).\n\nIn the following example, function f closes over the lexical environment of the global execution context:\n\nfunction f() {}\n\n\nIn the following example, function h closes over the lexical environment of function g, which, in turn, closes over the lexical environment of the global execution context.\n\nfunction g() {\n    function h() {}\n}\n\n\nIf an inner function is returned by an outer, then the outer lexical environment will persist after the outer function has returned. This is because the outer lexical environment needs to be available if the inner function is eventually invoked.\n\nIn the following example, function j closes over the lexical environment of function i, meaning that variable x is visible from inside function j, long after function i has completed execution:\n\nfunction i() {\n    var x = 'mochacchino'\n    return function j() {\n        console.log('Printing the value of x, from within function j: ', x)\n    }\n} \n\nconst k = i()\nsetTimeout(k, 500) // invoke k (which is j) after 500ms\n Run code snippetExpand snippet\n\nIn a closure, the variables in the outer lexical environment themselves are available, not copies.\n\nfunction l() {\n  var y = 'vanilla';\n\n  return {\n    setY: function(value) {\n      y = value;\n    },\n    logY: function(value) {\n      console.log('The value of y is: ', y);\n    }\n  }\n}\n\nconst o = l()\no.logY() // The value of y is: vanilla\no.setY('chocolate')\no.logY() // The value of y is: chocolate\n Run code snippetExpand snippet\n\nThe chain of lexical environments, linked between execution contexts via outer environment references, forms a scope chain and defines the identifiers visible from any given function.\n\nPlease note that in an attempt to improve clarity and accuracy, this answer has been substantially changed from the original.\n\nShare\nImprove this answer\nFollow\nedited Feb 17 '20 at 19:56\ncommunity wiki\n\n\n17 revs, 6 users 49%\nBen","comments":[]},{"answer":"OK, 6-year-old closures fan. Do you want to hear the simplest example of closure?\n\nLet's imagine the next situation: a driver is sitting in a car. That car is inside a plane. Plane is in the airport. The ability of driver to access things outside his car, but inside the plane, even if that plane leaves an airport, is a closure. That's it. When you turn 27, look at the more detailed explanation or at the example below.\n\nHere is how I can convert my plane story into the code.\n\nvar plane = function(defaultAirport) {\n\n  var lastAirportLeft = defaultAirport;\n\n  var car = {\n    driver: {\n      startAccessPlaneInfo: function() {\n        setInterval(function() {\n          console.log(\"Last airport was \" + lastAirportLeft);\n        }, 2000);\n      }\n    }\n  };\n  car.driver.startAccessPlaneInfo();\n\n  return {\n    leaveTheAirport: function(airPortName) {\n      lastAirportLeft = airPortName;\n    }\n  }\n}(\"Boryspil International Airport\");\n\nplane.leaveTheAirport(\"John F. Kennedy\");\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Oct 10 '18 at 18:38\ncommunity wiki\n\n\n8 revs, 6 users 46%\nMax Tkachenko","comments":[]},{"answer":"This is an attempt to clear up several (possible) misunderstandings about closures that appear in some of the other answers.\n\nA closure is not only created when you return an inner function. In fact, the enclosing function does not need to return at all in order for its closure to be created. You might instead assign your inner function to a variable in an outer scope, or pass it as an argument to another function where it could be called immediately or any time later. Therefore, the closure of the enclosing function is probably created as soon as the enclosing function is called since any inner function has access to that closure whenever the inner function is called, before or after the enclosing function returns.\nA closure does not reference a copy of the old values of variables in its scope. The variables themselves are part of the closure, and so the value seen when accessing one of those variables is the latest value at the time it is accessed. This is why inner functions created inside of loops can be tricky, since each one has access to the same outer variables rather than grabbing a copy of the variables at the time the function is created or called.\nThe \"variables\" in a closure include any named functions declared within the function. They also include arguments of the function. A closure also has access to its containing closure's variables, all the way up to the global scope.\nClosures use memory, but they don't cause memory leaks since JavaScript by itself cleans up its own circular structures that are not referenced. Internet Explorer memory leaks involving closures are created when it fails to disconnect DOM attribute values that reference closures, thus maintaining references to possibly circular structures.\nShare\nImprove this answer\nFollow\nedited May 5 '16 at 15:00\ncommunity wiki\n\n\n4 revs, 2 users 76%\ndlaliberte","comments":[]},{"answer":"I wrote a blog post a while back explaining closures. Here's what I said about closures in terms of why you'd want one.\n\nClosures are a way to let a function have persistent, private variables - that is, variables that only one function knows about, where it can keep track of info from previous times that it was run.\n\nIn that sense, they let a function act a bit like an object with private attributes.\n\nFull post:\n\nSo what are these closure thingys?\n\nShare\nImprove this answer\nFollow\nedited Jan 28 '13 at 2:23\ncommunity wiki\n\n\nNathan Long","comments":[]},{"answer":"Closures are simple:\n\nThe following simple example covers all the main points of JavaScript closures.*  \n\nHere is a factory that produces calculators that can add and multiply:\n\nfunction make_calculator() {\n  var n = 0; // this calculator stores a single number n\n  return {\n    add: function(a) {\n      n += a;\n      return n;\n    },\n    multiply: function(a) {\n      n *= a;\n      return n;\n    }\n  };\n}\n\nfirst_calculator = make_calculator();\nsecond_calculator = make_calculator();\n\nfirst_calculator.add(3); // returns 3\nsecond_calculator.add(400); // returns 400\n\nfirst_calculator.multiply(11); // returns 33\nsecond_calculator.multiply(10); // returns 4000\n\n\nThe key point: Each call to make_calculator creates a new local variable n, which continues to be usable by that calculator's add and multiply functions long after make_calculator returns.\n\nIf you are familiar with stack frames, these calculators seem strange: How can they keep accessing n after make_calculator returns? The answer is to imagine that JavaScript doesn't use \"stack frames\", but instead uses \"heap frames\", which can persist after the function call that made them returns.\n\nInner functions like add and multiply, which access variables declared in an outer function**, are called closures.\n\nThat is pretty much all there is to closures.\n\n\n\n\n* For example, it covers all the points in the \"Closures for Dummies\" article given in another answer, except example 6, which simply shows that variables can be used before they are declared, a nice fact to know but completely unrelated to closures. It also covers all the points in the accepted answer, except for the points (1) that functions copy their arguments into local variables (the named function arguments), and (2) that copying numbers creates a new number, but copying an object reference gives you another reference to the same object. These are also good to know but again completely unrelated to closures. It is also very similar to the example in this answer but a bit shorter and less abstract. It does not cover the point of this answer or this comment, which is that JavaScript makes it difficult to plug the current value of a loop variable into your inner function: The \"plugging in\" step can only be done with a helper function that encloses your inner function and is invoked on each loop iteration. (Strictly speaking, the inner function accesses the helper function's copy of the variable, rather than having anything plugged in.) Again, very useful when creating closures, but not part of what a closure is or how it works. There is additional confusion due to closures working differently in functional languages like ML, where variables are bound to values rather than to storage space, providing a constant stream of people who understand closures in a way (namely the \"plugging in\" way) that is simply incorrect for JavaScript, where variables are always bound to storage space, and never to values.\n\n** Any outer function, if several are nested, or even in the global context, as this answer points out clearly.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:10\ncommunity wiki\n\n\n7 revs, 2 users 81%\nMatt","comments":[]},{"answer":"How I'd explain it to a six-year-old:\n\nYou know how grown-ups can own a house, and they call it home? When a mom has a child, the child doesn't really own anything, right? But its parents own a house, so whenever someone asks the child \"Where's your home?\", he/she can answer \"that house!\", and point to the house of its parents. A \"Closure\" is the ability of the child to always (even if abroad) be able to say it has a home, even though it's really the parent's who own the house.\n\nShare\nImprove this answer\nFollow\nedited Jan 16 '16 at 2:30\ncommunity wiki\n\n\n3 revs, 3 users 50%\nMagne","comments":[]},{"answer":"Can you explain closures to a 5-year-old?*\n\nI still think Google's explanation works very well and is concise:\n\n/*\n*    When a function is defined in another function and it\n*    has access to the outer function's context even after\n*    the outer function returns.\n*\n* An important concept to learn in JavaScript.\n*/\n\nfunction outerFunction(someNum) {\n    var someString = 'Hey!';\n    var content = document.getElementById('content');\n    function innerFunction() {\n        content.innerHTML = someNum + ': ' + someString;\n        content = null; // Internet Explorer memory leak for DOM reference\n    }\n    innerFunction();\n}\n\nouterFunction(1);​\n\n\n*A C# question\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n7 revs, 3 users 70%\nChris S","comments":[]},{"answer":"I tend to learn better by GOOD/BAD comparisons. I like to see working code followed by non-working code that someone is likely to encounter. I put together a jsFiddle that does a comparison and tries to boil down the differences to the simplest explanations I could come up with.\n\nClosures done right:\nconsole.log('CLOSURES DONE RIGHT');\n\nvar arr = [];\n\nfunction createClosure(n) {\n    return function () {\n        return 'n = ' + n;\n    }\n}\n\nfor (var index = 0; index < 10; index++) {\n    arr[index] = createClosure(index);\n}\n\nfor (var index in arr) {\n    console.log(arr[index]());\n}\n\n\nIn the above code createClosure(n) is invoked in every iteration of the loop. Note that I named the variable n to highlight that it is a new variable created in a new function scope and is not the same variable as index which is bound to the outer scope.\n\nThis creates a new scope and n is bound to that scope; this means we have 10 separate scopes, one for each iteration.\n\ncreateClosure(n) returns a function that returns the n within that scope.\n\nWithin each scope n is bound to whatever value it had when createClosure(n) was invoked so the nested function that gets returned will always return the value of n that it had when createClosure(n) was invoked.\n\nClosures done wrong:\nconsole.log('CLOSURES DONE WRONG');\n\nfunction createClosureArray() {\n    var badArr = [];\n\n    for (var index = 0; index < 10; index++) {\n        badArr[index] = function () {\n            return 'n = ' + index;\n        };\n    }\n    return badArr;\n}\n\nvar badArr = createClosureArray();\n\nfor (var index in badArr) {\n    console.log(badArr[index]());\n}\n\n\nIn the above code the loop was moved within the createClosureArray() function and the function now just returns the completed array, which at first glance seems more intuitive.\n\nWhat might not be obvious is that since createClosureArray() is only invoked once only one scope is created for this function instead of one for every iteration of the loop.\n\nWithin this function a variable named index is defined. The loop runs and adds functions to the array that return index. Note that index is defined within the createClosureArray function which only ever gets invoked one time.\n\nBecause there was only one scope within the createClosureArray() function, index is only bound to a value within that scope. In other words, each time the loop changes the value of index, it changes it for everything that references it within that scope.\n\nAll of the functions added to the array return the SAME index variable from the parent scope where it was defined instead of 10 different ones from 10 different scopes like the first example. The end result is that all 10 functions return the same variable from the same scope.\n\nAfter the loop finished and index was done being modified the end value was 10, therefore every function added to the array returns the value of the single index variable which is now set to 10.\n\nResult\n\nCLOSURES DONE RIGHT\nn = 0\nn = 1\nn = 2\nn = 3\nn = 4\nn = 5\nn = 6\nn = 7\nn = 8\nn = 9\n\nCLOSURES DONE WRONG\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n5 revs, 3 users 82%\nChev","comments":[]},{"answer":"Wikipedia on closures:\n\nIn computer science, a closure is a function together with a referencing environment for the nonlocal names (free variables) of that function.\n\nTechnically, in JavaScript, every function is a closure. It always has an access to variables defined in the surrounding scope.\n\nSince scope-defining construction in JavaScript is a function, not a code block like in many other languages, what we usually mean by closure in JavaScript is a function working with nonlocal variables defined in already executed surrounding function.\n\nClosures are often used for creating functions with some hidden private data (but it's not always the case).\n\nvar db = (function() {\n    // Create a hidden object, which will hold the data\n    // it's inaccessible from the outside.\n    var data = {};\n\n    // Make a function, which will provide some access to the data.\n    return function(key, val) {\n        if (val === undefined) { return data[key] } // Get\n        else { return data[key] = val } // Set\n    }\n    // We are calling the anonymous surrounding function,\n    // returning the above inner function, which is a closure.\n})();\n\ndb('x')    // -> undefined\ndb('x', 1) // Set x to 1\ndb('x')    // -> 1\n// It's impossible to access the data object itself.\n// We are able to get or set individual it.\n\n\nems\n\nThe example above is using an anonymous function, which was executed once. But it does not have to be. It can be named (e.g. mkdb) and executed later, generating a database function each time it is invoked. Every generated function will have its own hidden database object. Another usage example of closures is when we don't return a function, but an object containing multiple functions for different purposes, each of those function having access to the same data.\n\nShare\nImprove this answer\nFollow\nedited Dec 18 '13 at 16:48\ncommunity wiki\n\n\n6 revs, 3 users 78%\nmykhal","comments":[]},{"answer":"I put together an interactive JavaScript tutorial to explain how closures work. What's a Closure?\n\nHere's one of the examples:\n\nvar create = function (x) {\n    var f = function () {\n        return x; // We can refer to x here!\n    };\n    return f;\n};\n// 'create' takes one argument, creates a function\n\nvar g = create(42);\n// g is a function that takes no arguments now\n\nvar y = g();\n// y is 42 here\n\nShare\nImprove this answer\nFollow\nedited Oct 25 '14 at 22:38\ncommunity wiki\n\n\n3 revs, 3 users 89%\nNathan Whitehead","comments":[]},{"answer":"The children will always remember the secrets they have shared with their parents, even after their parents are gone. This is what closures are for functions.\n\nThe secrets for JavaScript functions are the private variables\n\nvar parent = function() {\n var name = \"Mary\"; // secret\n}\n\n\nEvery time you call it, local variable \"name\" is created and given name \"Mary\". And every time the function exits the variable is lost and the name is forgotten.\n\nAs you may guess, because the variables are re-created every time the function is called, and nobody else will know them, there must be a secret place where they are stored. It could be called Chamber of Secrets or stack or local scope but it doesn't really matter. We know they are there, somewhere, hidden in the memory.\n\nBut, in JavaScript there is this very special thing that functions which are created inside other functions, can also know the local variables of their parents and keep them as long as they live.\n\nvar parent = function() {\n  var name = \"Mary\";\n  var child = function(childName) {\n    // I can also see that \"name\" is \"Mary\"\n  }\n}\n\n\nSo, as long as we are in the parent -function, it can create one or more child functions which do share the secret variables from the secret place.\n\nBut the sad thing is, if the child is also a private variable of its parent function, it would also die when the parent ends, and the secrets would die with them.\n\nSo to live, the child has to leave before it's too late\n\nvar parent = function() {\n  var name = \"Mary\";\n  var child = function(childName) {\n    return \"My name is \" + childName  +\", child of \" + name; \n  }\n  return child; // child leaves the parent ->\n}\nvar child = parent(); // < - and here it is outside \n\n\nAnd now, even though Mary is \"no longer running\", the memory of her is not lost and her child will always remember her name and other secrets they shared during their time together.\n\nSo, if you call the child \"Alice\", she will respond\n\nchild(\"Alice\") => \"My name is Alice, child of Mary\"\n\n\nThat's all there is to tell.\n\nShare\nImprove this answer\nFollow\nedited Jul 13 '17 at 11:27\ncommunity wiki\n\n\n3 revs, 3 users 95%\nTero Tolonen","comments":[]},{"answer":"I do not understand why the answers are so complex here.\n\nHere is a closure:\n\nvar a = 42;\n\nfunction b() { return a; }\n\n\nYes. You probably use that many times a day.\n\n\n\n\nThere is no reason to believe closures are a complex design hack to address specific problems. No, closures are just about using a variable that comes from a higher scope from the perspective of where the function was declared (not run).\n\nNow what it allows you to do can be more spectacular, see other answers.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n2 revs, 2 users 97%\nfloribon","comments":[]},{"answer":"Example for the first point by dlaliberte:\n\nA closure is not only created when you return an inner function. In fact, the enclosing function does not need to return at all. You might instead assign your inner function to a variable in an outer scope, or pass it as an argument to another function where it could be used immediately. Therefore, the closure of the enclosing function probably already exists at the time that enclosing function was called since any inner function has access to it as soon as it is called.\n\nvar i;\nfunction foo(x) {\n    var tmp = 3;\n    i = function (y) {\n        console.log(x + y + (++tmp));\n    }\n}\nfoo(2);\ni(3);\n\nShare\nImprove this answer\nFollow\nedited Jan 16 '16 at 2:39\ncommunity wiki\n\n\n3 revs, 3 users 64%\nsomeisaac","comments":[]},{"answer":"A closure is where an inner function has access to variables in its outer function. That's probably the simplest one-line explanation you can get for closures.\n\nShare\nImprove this answer\nFollow\nedited Dec 24 '12 at 11:10\ncommunity wiki\n\n\nRakesh Pai","comments":[]},{"answer":"I know there are plenty of solutions already, but I guess that this small and simple script can be useful to demonstrate the concept:\n\n// makeSequencer will return a \"sequencer\" function\nvar makeSequencer = function() {\n    var _count = 0; // not accessible outside this function\n    var sequencer = function () {\n        return _count++;\n    }\n    return sequencer;\n}\n\nvar fnext = makeSequencer();\nvar v0 = fnext();     // v0 = 0;\nvar v1 = fnext();     // v1 = 1;\nvar vz = fnext._count // vz = undefined\n\nShare\nImprove this answer\nFollow\nedited May 9 '16 at 11:32\ncommunity wiki\n\n\n3 revs, 2 users 90%\nGerardo Lima","comments":[]},{"answer":"You're having a sleep over and you invite Dan. You tell Dan to bring one XBox controller.\n\nDan invites Paul. Dan asks Paul to bring one controller. How many controllers were brought to the party?\n\nfunction sleepOver(howManyControllersToBring) {\n\n    var numberOfDansControllers = howManyControllersToBring;\n\n    return function danInvitedPaul(numberOfPaulsControllers) {\n        var totalControllers = numberOfDansControllers + numberOfPaulsControllers;\n        return totalControllers;\n    }\n}\n\nvar howManyControllersToBring = 1;\n\nvar inviteDan = sleepOver(howManyControllersToBring);\n\n// The only reason Paul was invited is because Dan was invited. \n// So we set Paul's invitation = Dan's invitation.\n\nvar danInvitedPaul = inviteDan(howManyControllersToBring);\n\nalert(\"There were \" + danInvitedPaul + \" controllers brought to the party.\");\n\nShare\nImprove this answer\nFollow\nedited Jul 20 '11 at 15:16\ncommunity wiki\n\n\nStewShack","comments":[]},{"answer":"The author of Closures has explained closures pretty well, explaining the reason why we need them and also explaining LexicalEnvironment which is necessary to understanding closures.\nHere is the summary:\n\nWhat if a variable is accessed, but it isn’t local? Like here:\n\nIn this case, the interpreter finds the variable in the outer LexicalEnvironment object.\n\nThe process consists of two steps:\n\nFirst, when a function f is created, it is not created in an empty space. There is a current LexicalEnvironment object. In the case above, it’s window (a is undefined at the time of function creation).\n\nWhen a function is created, it gets a hidden property, named [[Scope]], which references the current LexicalEnvironment.\n\nIf a variable is read, but can not be found anywhere, an error is generated.\n\nNested functions\n\nFunctions can be nested one inside another, forming a chain of LexicalEnvironments which can also be called a scope chain.\n\nSo, function g has access to g, a and f.\n\nClosures\n\nA nested function may continue to live after the outer function has finished:\n\nMarking up LexicalEnvironments:\n\nAs we see, this.say is a property in the user object, so it continues to live after User completed.\n\nAnd if you remember, when this.say is created, it (as every function) gets an internal reference this.say.[[Scope]] to the current LexicalEnvironment. So, the LexicalEnvironment of the current User execution stays in memory. All variables of User also are its properties, so they are also carefully kept, not junked as usually.\n\nThe whole point is to ensure that if the inner function wants to access an outer variable in the future, it is able to do so.\n\nTo summarize:\n\nThe inner function keeps a reference to the outer LexicalEnvironment.\nThe inner function may access variables from it any time even if the outer function is finished.\nThe browser keeps the LexicalEnvironment and all its properties (variables) in memory until there is an inner function which references it.\n\nThis is called a closure.\n\nShare\nImprove this answer\nFollow\nedited May 14 '18 at 20:51\ncommunity wiki\n\n\n7 revs, 2 users 81%\nArvand","comments":[]},{"answer":"JavaScript functions can access their:\n\nArguments\nLocals (that is, their local variables and local functions)\nEnvironment, which includes:\nglobals, including the DOM\nanything in outer functions\n\nIf a function accesses its environment, then the function is a closure.\n\nNote that outer functions are not required, though they do offer benefits I don't discuss here. By accessing data in its environment, a closure keeps that data alive. In the subcase of outer/inner functions, an outer function can create local data and eventually exit, and yet, if any inner function(s) survive after the outer function exits, then the inner function(s) keep the outer function's local data alive.\n\nExample of a closure that uses the global environment:\n\nImagine that the Stack Overflow Vote-Up and Vote-Down button events are implemented as closures, voteUp_click and voteDown_click, that have access to external variables isVotedUp and isVotedDown, which are defined globally. (For simplicity's sake, I am referring to StackOverflow's Question Vote buttons, not the array of Answer Vote buttons.)\n\nWhen the user clicks the VoteUp button, the voteUp_click function checks whether isVotedDown == true to determine whether to vote up or merely cancel a down vote. Function voteUp_click is a closure because it is accessing its environment.\n\nvar isVotedUp = false;\nvar isVotedDown = false;\n\nfunction voteUp_click() {\n  if (isVotedUp)\n    return;\n  else if (isVotedDown)\n    SetDownVote(false);\n  else\n    SetUpVote(true);\n}\n\nfunction voteDown_click() {\n  if (isVotedDown)\n    return;\n  else if (isVotedUp)\n    SetUpVote(false);\n  else\n    SetDownVote(true);\n}\n\nfunction SetUpVote(status) {\n  isVotedUp = status;\n  // Do some CSS stuff to Vote-Up button\n}\n\nfunction SetDownVote(status) {\n  isVotedDown = status;\n  // Do some CSS stuff to Vote-Down button\n}\n\n\nAll four of these functions are closures as they all access their environment.\n\nShare\nImprove this answer\nFollow\nedited Jun 8 '16 at 22:16\ncommunity wiki\n\n\n4 revs, 3 users 81%\nJohn Pick","comments":[]},{"answer":"As a father of a 6-year-old, currently teaching young children (and a relative novice to coding with no formal education so corrections will be required), I think the lesson would stick best through hands-on play. If the 6-year-old is ready to understand what a closure is, then they are old enough to have a go themselves. I'd suggest pasting the code into jsfiddle.net, explaining a bit, and leaving them alone to concoct a unique song. The explanatory text below is probably more appropriate for a 10 year old.\n\nfunction sing(person) {\n\n    var firstPart = \"There was \" + person + \" who swallowed \";\n\n    var fly = function() {\n        var creature = \"a fly\";\n        var result = \"Perhaps she'll die\";\n        alert(firstPart + creature + \"\\n\" + result);\n    };\n\n    var spider = function() {\n        var creature = \"a spider\";\n        var result = \"that wiggled and jiggled and tickled inside her\";\n        alert(firstPart + creature + \"\\n\" + result);\n    };\n\n    var bird = function() {\n        var creature = \"a bird\";\n        var result = \"How absurd!\";\n        alert(firstPart + creature + \"\\n\" + result);\n    };\n\n    var cat = function() {\n        var creature = \"a cat\";\n        var result = \"Imagine That!\";\n        alert(firstPart + creature + \"\\n\" + result);\n    };\n\n    fly();\n    spider();\n    bird();\n    cat();\n}\n\nvar person=\"an old lady\";\n\nsing(person);\n\n\nINSTRUCTIONS\n\nDATA: Data is a collection of facts. It can be numbers, words, measurements, observations or even just descriptions of things. You can't touch it, smell it or taste it. You can write it down, speak it and hear it. You could use it to create touch smell and taste using a computer. It can be made useful by a computer using code.\n\nCODE: All the writing above is called code. It is written in JavaScript.\n\nJAVASCRIPT: JavaScript is a language. Like English or French or Chinese are languages. There are lots of languages that are understood by computers and other electronic processors. For JavaScript to be understood by a computer it needs an interpreter. Imagine if a teacher who only speaks Russian comes to teach your class at school. When the teacher says \"все садятся\", the class would not understand. But luckily you have a Russian pupil in your class who tells everyone this means \"everybody sit down\" - so you all do. The class is like a computer and the Russian pupil is the interpreter. For JavaScript the most common interpreter is called a browser.\n\nBROWSER: When you connect to the Internet on a computer, tablet or phone to visit a website, you use a browser. Examples you may know are Internet Explorer, Chrome, Firefox and Safari. The browser can understand JavaScript and tell the computer what it needs to do. The JavaScript instructions are called functions.\n\nFUNCTION: A function in JavaScript is like a factory. It might be a little factory with only one machine inside. Or it might contain many other little factories, each with many machines doing different jobs. In a real life clothes factory you might have reams of cloth and bobbins of thread going in and T-shirts and jeans coming out. Our JavaScript factory only processes data, it can't sew, drill a hole or melt metal. In our JavaScript factory data goes in and data comes out.\n\nAll this data stuff sounds a bit boring, but it is really very cool; we might have a function that tells a robot what to make for dinner. Let's say I invite you and your friend to my house. You like chicken legs best, I like sausages, your friend always wants what you want and my friend does not eat meat.\n\nI haven't got time to go shopping, so the function needs to know what we have in the fridge to make decisions. Each ingredient has a different cooking time and we want everything to be served hot by the robot at the same time. We need to provide the function with the data about what we like, the function could 'talk' to the fridge, and the function could control the robot.\n\nA function normally has a name, parentheses and braces. Like this:\n\nfunction cookMeal() {  /*  STUFF INSIDE THE FUNCTION  */  }\n\n\nNote that /*...*/ and // stop code being read by the browser.\n\nNAME: You can call a function just about whatever word you want. The example \"cookMeal\" is typical in joining two words together and giving the second one a capital letter at the beginning - but this is not necessary. It can't have a space in it, and it can't be a number on its own.\n\nPARENTHESES: \"Parentheses\" or () are the letter box on the JavaScript function factory's door or a post box in the street for sending packets of information to the factory. Sometimes the postbox might be marked for example cookMeal(you, me, yourFriend, myFriend, fridge, dinnerTime), in which case you know what data you have to give it.\n\nBRACES: \"Braces\" which look like this {} are the tinted windows of our factory. From inside the factory you can see out, but from the outside you can't see in.\n\nTHE LONG CODE EXAMPLE ABOVE\n\nOur code begins with the word function, so we know that it is one! Then the name of the function sing - that's my own description of what the function is about. Then parentheses (). The parentheses are always there for a function. Sometimes they are empty, and sometimes they have something in. This one has a word in: (person). After this there is a brace like this { . This marks the start of the function sing(). It has a partner which marks the end of sing() like this }\n\nfunction sing(person) {  /* STUFF INSIDE THE FUNCTION */  }\n\n\nSo this function might have something to do with singing, and might need some data about a person. It has instructions inside to do something with that data.\n\nNow, after the function sing(), near the end of the code is the line\n\nvar person=\"an old lady\";\n\n\nVARIABLE: The letters var stand for \"variable\". A variable is like an envelope. On the outside this envelope is marked \"person\". On the inside it contains a slip of paper with the information our function needs, some letters and spaces joined together like a piece of string (it's called a string) that make a phrase reading \"an old lady\". Our envelope could contain other kinds of things like numbers (called integers), instructions (called functions), lists (called arrays). Because this variable is written outside of all the braces {}, and because you can see out through the tinted windows when you are inside the braces, this variable can be seen from anywhere in the code. We call this a 'global variable'.\n\nGLOBAL VARIABLE: person is a global variable, meaning that if you change its value from \"an old lady\" to \"a young man\", the person will keep being a young man until you decide to change it again and that any other function in the code can see that it's a young man. Press the F12 button or look at the Options settings to open the developer console of a browser and type \"person\" to see what this value is. Type person=\"a young man\" to change it and then type \"person\" again to see that it has changed.\n\nAfter this we have the line\n\nsing(person);\n\n\nThis line is calling the function, as if it were calling a dog\n\n\"Come on sing, Come and get person!\"\n\nWhen the browser has loaded the JavaScript code an reached this line, it will start the function. I put the line at the end to make sure that the browser has all the information it needs to run it.\n\nFunctions define actions - the main function is about singing. It contains a variable called firstPart which applies to the singing about the person that applies to each of the verses of the song: \"There was \" + person + \" who swallowed\". If you type firstPart into the console, you won't get an answer because the variable is locked up in a function - the browser can't see inside the tinted windows of the braces.\n\nCLOSURES: The closures are the smaller functions that are inside the big sing() function. The little factories inside the big factory. They each have their own braces which mean that the variables inside them can't be seen from the outside. That's why the names of the variables (creature and result) can be repeated in the closures but with different values. If you type these variable names in the console window, you won't get its value because it's hidden by two layers of tinted windows.\n\nThe closures all know what the sing() function's variable called firstPart is, because they can see out from their tinted windows.\n\nAfter the closures come the lines\n\nfly();\nspider();\nbird();\ncat();\n\n\nThe sing() function will call each of these functions in the order they are given. Then the sing() function's work will be done.\n\nShare\nImprove this answer\nFollow\nedited Jun 8 '16 at 22:11\ncommunity wiki\n\n\n5 revs, 3 users 77%\ngrateful","comments":[]},{"answer":"Okay, talking with a 6-year old child, I would possibly use following associations.\n\nImagine - you are playing with your little brothers and sisters in the entire house, and you are moving around with your toys and brought some of them into your older brother's room. After a while your brother returned from the school and went to his room, and he locked inside it, so now you could not access toys left there anymore in a direct way. But you could knock the door and ask your brother for that toys. This is called toy's closure; your brother made it up for you, and he is now into outer scope.\n\nCompare with a situation when a door was locked by draft and nobody inside (general function execution), and then some local fire occur and burn down the room (garbage collector:D), and then a new room was build and now you may leave another toys there (new function instance), but never get the same toys which were left in the first room instance.\n\nFor an advanced child I would put something like the following. It is not perfect, but it makes you feel about what it is:\n\nfunction playingInBrothersRoom (withToys) {\n  // We closure toys which we played in the brother's room. When he come back and lock the door\n  // your brother is supposed to be into the outer [[scope]] object now. Thanks god you could communicate with him.\n  var closureToys = withToys || [],\n      returnToy, countIt, toy; // Just another closure helpers, for brother's inner use.\n\n  var brotherGivesToyBack = function (toy) {\n    // New request. There is not yet closureToys on brother's hand yet. Give him a time.\n    returnToy = null;\n    if (toy && closureToys.length > 0) { // If we ask for a specific toy, the brother is going to search for it.\n\n      for ( countIt = closureToys.length; countIt; countIt--) {\n        if (closureToys[countIt - 1] == toy) {\n          returnToy = 'Take your ' + closureToys.splice(countIt - 1, 1) + ', little boy!';\n          break;\n        }\n      }\n      returnToy = returnToy || 'Hey, I could not find any ' + toy + ' here. Look for it in another room.';\n    }\n    else if (closureToys.length > 0) { // Otherwise, just give back everything he has in the room.\n      returnToy = 'Behold! ' + closureToys.join(', ') + '.';\n      closureToys = [];\n    }\n    else {\n      returnToy = 'Hey, lil shrimp, I gave you everything!';\n    }\n    console.log(returnToy);\n  }\n  return brotherGivesToyBack;\n}\n// You are playing in the house, including the brother's room.\nvar toys = ['teddybear', 'car', 'jumpingrope'],\n    askBrotherForClosuredToy = playingInBrothersRoom(toys);\n\n// The door is locked, and the brother came from the school. You could not cheat and take it out directly.\nconsole.log(askBrotherForClosuredToy.closureToys); // Undefined\n\n// But you could ask your brother politely, to give it back.\naskBrotherForClosuredToy('teddybear'); // Hooray, here it is, teddybear\naskBrotherForClosuredToy('ball'); // The brother would not be able to find it.\naskBrotherForClosuredToy(); // The brother gives you all the rest\naskBrotherForClosuredToy(); // Nothing left in there\n\n\nAs you can see, the toys left in the room are still accessible via the brother and no matter if the room is locked. Here is a jsbin to play around with it.\n\nShare\nImprove this answer\nFollow\nedited Oct 25 '14 at 22:52\ncommunity wiki\n\n\n9 revs, 2 users 88%\ndmi3y","comments":[]},{"answer":"An answer for a six-year-old (assuming he knows what a function is and what a variable is, and what data is):\n\nFunctions can return data. One kind of data you can return from a function is another function. When that new function gets returned, all the variables and arguments used in the function that created it don't go away. Instead, that parent function \"closes.\" In other words, nothing can look inside of it and see the variables it used except for the function it returned. That new function has a special ability to look back inside the function that created it and see the data inside of it.\n\nfunction the_closure() {\n  var x = 4;\n  return function () {\n    return x; // Here, we look back inside the_closure for the value of x\n  }\n}\n\nvar myFn = the_closure();\nmyFn(); //=> 4\n\n\nAnother really simple way to explain it is in terms of scope:\n\nAny time you create a smaller scope inside of a larger scope, the smaller scope will always be able to see what is in the larger scope.\n\nShare\nImprove this answer\nFollow\nedited Oct 25 '14 at 23:02\ncommunity wiki\n\n\n2 revs, 2 users 90%\nStupid Stupid","comments":[]},{"answer":"A function in JavaScript is not just a reference to a set of instructions (as in C language), but it also includes a hidden data structure which is composed of references to all nonlocal variables it uses (captured variables). Such two-piece functions are called closures. Every function in JavaScript can be considered a closure.\n\nClosures are functions with a state. It is somewhat similar to \"this\" in the sense that \"this\" also provides state for a function but function and \"this\" are separate objects (\"this\" is just a fancy parameter, and the only way to bind it permanently to a function is to create a closure). While \"this\" and function always live separately, a function cannot be separated from its closure and the language provides no means to access captured variables.\n\nBecause all these external variables referenced by a lexically nested function are actually local variables in the chain of its lexically enclosing functions (global variables can be assumed to be local variables of some root function), and every single execution of a function creates new instances of its local variables, it follows that every execution of a function returning (or otherwise transferring it out, such as registering it as a callback) a nested function creates a new closure (with its own potentially unique set of referenced nonlocal variables which represent its execution context).\n\nAlso, it must be understood that local variables in JavaScript are created not on the stack frame, but on the heap and destroyed only when no one is referencing them. When a function returns, references to its local variables are decremented, but they can still be non-null if during the current execution they became part of a closure and are still referenced by its lexically nested functions (which can happen only if the references to these nested functions were returned or otherwise transferred to some external code).\n\nAn example:\n\nfunction foo (initValue) {\n   //This variable is not destroyed when the foo function exits.\n   //It is 'captured' by the two nested functions returned below.\n   var value = initValue;\n\n   //Note that the two returned functions are created right now.\n   //If the foo function is called again, it will return\n   //new functions referencing a different 'value' variable.\n   return {\n       getValue: function () { return value; },\n       setValue: function (newValue) { value = newValue; }\n   }\n}\n\nfunction bar () {\n    //foo sets its local variable 'value' to 5 and returns an object with\n    //two functions still referencing that local variable\n    var obj = foo(5);\n\n    //Extracting functions just to show that no 'this' is involved here\n    var getValue = obj.getValue;\n    var setValue = obj.setValue;\n\n    alert(getValue()); //Displays 5\n    setValue(10);\n    alert(getValue()); //Displays 10\n\n    //At this point getValue and setValue functions are destroyed\n    //(in reality they are destroyed at the next iteration of the garbage collector).\n    //The local variable 'value' in the foo is no longer referenced by\n    //anything and is destroyed too.\n}\n\nbar();\n\nShare\nImprove this answer\nFollow\nedited May 5 '16 at 16:04\ncommunity wiki\n\n\n6 revs, 2 users 77%\nsrgstm","comments":[]},{"answer":"Perhaps a little beyond all but the most precocious of six-year-olds, but a few examples that helped make the concept of closure in JavaScript click for me.\n\nA closure is a function that has access to another function's scope (its variables and functions). The easiest way to create a closure is with a function within a function; the reason being that in JavaScript a function always has access to its containing function’s scope.\n\nfunction outerFunction() {\n    var outerVar = \"monkey\";\n    \n    function innerFunction() {\n        alert(outerVar);\n    }\n    \n    innerFunction();\n}\n\nouterFunction();\n Run code snippetExpand snippet\n\nALERT: monkey\n\nIn the above example, outerFunction is called which in turn calls innerFunction. Note how outerVar is available to innerFunction, evidenced by its correctly alerting the value of outerVar.\n\nNow consider the following:\n\nfunction outerFunction() {\n    var outerVar = \"monkey\";\n    \n    function innerFunction() {\n        return outerVar;\n    }\n    \n    return innerFunction;\n}\n\nvar referenceToInnerFunction = outerFunction();\nalert(referenceToInnerFunction());\n Run code snippetExpand snippet\n\nALERT: monkey\n\nreferenceToInnerFunction is set to outerFunction(), which simply returns a reference to innerFunction. When referenceToInnerFunction is called, it returns outerVar. Again, as above, this demonstrates that innerFunction has access to outerVar, a variable of outerFunction. Furthermore, it is interesting to note that it retains this access even after outerFunction has finished executing.\n\nAnd here is where things get really interesting. If we were to get rid of outerFunction, say set it to null, you might think that referenceToInnerFunction would loose its access to the value of outerVar. But this is not the case.\n\nfunction outerFunction() {\n    var outerVar = \"monkey\";\n    \n    function innerFunction() {\n        return outerVar;\n    }\n    \n    return innerFunction;\n}\n\nvar referenceToInnerFunction = outerFunction();\nalert(referenceToInnerFunction());\n\nouterFunction = null;\nalert(referenceToInnerFunction());\n Run code snippetExpand snippet\n\nALERT: monkey ALERT: monkey\n\nBut how is this so? How can referenceToInnerFunction still know the value of outerVar now that outerFunction has been set to null?\n\nThe reason that referenceToInnerFunction can still access the value of outerVar is because when the closure was first created by placing innerFunction inside of outerFunction, innerFunction added a reference to outerFunction’s scope (its variables and functions) to its scope chain. What this means is that innerFunction has a pointer or reference to all of outerFunction’s variables, including outerVar. So even when outerFunction has finished executing, or even if it is deleted or set to null, the variables in its scope, like outerVar, stick around in memory because of the outstanding reference to them on the part of the innerFunction that has been returned to referenceToInnerFunction. To truly release outerVar and the rest of outerFunction’s variables from memory you would have to get rid of this outstanding reference to them, say by setting referenceToInnerFunction to null as well.\n\n//////////\n\nTwo other things about closures to note. First, the closure will always have access to the last values of its containing function.\n\nfunction outerFunction() {\n    var outerVar = \"monkey\";\n    \n    function innerFunction() {\n        alert(outerVar);\n    }\n    \n    outerVar = \"gorilla\";\n\n    innerFunction();\n}\n\nouterFunction();\n Run code snippetExpand snippet\n\nALERT: gorilla\n\nSecond, when a closure is created, it retains a reference to all of its enclosing function’s variables and functions; it doesn’t get to pick and choose. And but so, closures should be used sparingly, or at least carefully, as they can be memory intensive; a lot of variables can be kept in memory long after a containing function has finished executing.\n\nShare\nImprove this answer\nFollow\nedited Apr 29 '15 at 15:37\ncommunity wiki\n\n\n2 revs, 2 users 99%\nMichael Dziedzic","comments":[]},{"answer":"I'd simply point them to the Mozilla Closures page. It's the best, most concise and simple explanation of closure basics and practical usage that I've found. It is highly recommended to anyone learning JavaScript.\n\nAnd yes, I'd even recommend it to a 6-year old -- if the 6-year old is learning about closures, then it's logical they're ready to comprehend the concise and simple explanation provided in the article.\n\nShare\nImprove this answer\nFollow\nedited Oct 25 '14 at 22:54\ncommunity wiki\n\n\n3 revs, 2 users 50%\nmjmoody383","comments":[]}]},{"id":"4114095","href":"https://stackoverflow.com/questions/4114095/how-do-i-revert-a-git-repository-to-a-previous-commit","title":"How do I revert a Git repository to a previous commit?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nHow do I revert from my current state to a snapshot made on a certain commit?\n\nIf I do git log, then I get the following output:\n\n$ git log\ncommit a867b4af366350be2e7c21b8de9cc6504678a61b`\nAuthor: Me <me@me.com>\nDate:   Thu Nov 4 18:59:41 2010 -0400\n\nblah blah blah...\n\ncommit 25eee4caef46ae64aa08e8ab3f988bc917ee1ce4\nAuthor: Me <me@me.com>\nDate:   Thu Nov 4 05:13:39 2010 -0400\n\nmore blah blah blah...\n\ncommit 0766c053c0ea2035e90f504928f8df3c9363b8bd\nAuthor: Me <me@me.com>\nDate:   Thu Nov 4 00:55:06 2010 -0400\n\nAnd yet more blah blah...\n\ncommit 0d1d7fc32e5a947fbd92ee598033d85bfc445a50\nAuthor: Me <me@me.com>\nDate:   Wed Nov 3 23:56:08 2010 -0400\n\nYep, more blah blah.\n\n\nHow do I revert to the commit from November 3, i.e. commit 0d1d7fc?\n    ","questionComments":["Related How to undo the last Git commit?.","Here's a very clear and thorough post about undoing things in git, straight from Github.","I love git, but the fact that there's 35 answers to something that should be incredibly simple exposes a huge issue with git. Or is it the docs?"],"answers":[{"answer":"This depends a lot on what you mean by \"revert\".\n\nTemporarily switch to a different commit\n\nIf you want to temporarily go back to it, fool around, then come back to where you are, all you have to do is check out the desired commit:\n\n# This will detach your HEAD, that is, leave you with no branch checked out:\ngit checkout 0d1d7fc32\n\n\nOr if you want to make commits while you're there, go ahead and make a new branch while you're at it:\n\ngit checkout -b old-state 0d1d7fc32\n\n\nTo go back to where you were, just check out the branch you were on again. (If you've made changes, as always when switching branches, you'll have to deal with them as appropriate. You could reset to throw them away; you could stash, checkout, stash pop to take them with you; you could commit them to a branch there if you want a branch there.)\n\nHard delete unpublished commits\n\nIf, on the other hand, you want to really get rid of everything you've done since then, there are two possibilities. One, if you haven't published any of these commits, simply reset:\n\n# This will destroy any local modifications.\n# Don't do it if you have uncommitted work you want to keep.\ngit reset --hard 0d1d7fc32\n\n# Alternatively, if there's work to keep:\ngit stash\ngit reset --hard 0d1d7fc32\ngit stash pop\n# This saves the modifications, then reapplies that patch after resetting.\n# You could get merge conflicts, if you've modified things which were\n# changed since the commit you reset to.\n\n\nIf you mess up, you've already thrown away your local changes, but you can at least get back to where you were before by resetting again.\n\nUndo published commits with new commits\n\nOn the other hand, if you've published the work, you probably don't want to reset the branch, since that's effectively rewriting history. In that case, you could indeed revert the commits. With Git, revert has a very specific meaning: create a commit with the reverse patch to cancel it out. This way you don't rewrite any history.\n\n# This will create three separate revert commits:\ngit revert a867b4af 25eee4ca 0766c053\n\n# It also takes ranges. This will revert the last two commits:\ngit revert HEAD~2..HEAD\n\n#Similarly, you can revert a range of commits using commit hashes (non inclusive of first hash):\ngit revert 0d1d7fc..a867b4a\n\n# Reverting a merge commit\ngit revert -m 1 <merge_commit_sha>\n\n# To get just one, you could use `rebase -i` to squash them afterwards\n# Or, you could do it manually (be sure to do this at top level of the repo)\n# get your index and work tree into the desired state, without changing HEAD:\ngit checkout 0d1d7fc32 .\n\n# Then commit. Be sure and write a good message describing what you just did\ngit commit\n\n\nThe git-revert manpage actually covers a lot of this in its description. Another useful link is this git-scm.com section discussing git-revert.\n\nIf you decide you didn't want to revert after all, you can revert the revert (as described here) or reset back to before the revert (see the previous section).\n\nYou may also find this answer helpful in this case:\nHow can I move HEAD back to a previous location? (Detached head) & Undo commits\n\nShare\nFollow\nedited Jun 11 at 7:38\nJoel Hoisko\n151\n1 silver badge\n5\n5 bronze badges\nanswered Nov 6 '10 at 17:04\nCascabel\n430k65\n65 gold badges\n358\n358 silver badges\n309\n309 bronze badges","comments":["@Rod's comment on git revert HEAD~3 as the best wat to revert back 3 commits is am important convention.","Could you write the whole number? like: git reset --hard 0d1d7fc32e5a947fbd92ee598033d85bfc445a50","@MathiasMadsenStav Yes, you can of course specify commits by the full SHA1. I used abbreviated hashes to make the answer more readable, and you also tend to use them if you're typing out. If you're copying and pasting, by all means use the full hash. See Specifying Revisions in man git rev-parse for a full description of how you can name commits.","You can use git revert --no-commit hash1 hash2 ... and after this just commit every single revert in one commit git commit -m \"Message\""]},{"answer":"Lots of complicated and dangerous answers here, but it's actually easy:\n\ngit revert --no-commit 0766c053..HEAD\ngit commit\n\n\nThis will revert everything from the HEAD back to the commit hash, meaning it will recreate that commit state in the working tree as if every commit after 0766c053 had been walked back. You can then commit the current tree, and it will create a brand new commit essentially equivalent to the commit you \"reverted\" to.\n\n(The --no-commit flag lets git revert all the commits at once- otherwise you'll be prompted for a message for each commit in the range, littering your history with unnecessary new commits.)\n\nThis is a safe and easy way to rollback to a previous state. No history is destroyed, so it can be used for commits that have already been made public.\n\nShare\nImprove this answer\nFollow\nedited Jun 15 '20 at 19:16\nJoonas\n3873\n3 silver badges\n10\n10 bronze badges\nanswered Feb 12 '14 at 4:18\nYarin\n147k140\n140 gold badges\n366\n366 silver badges\n492\n492 bronze badges","comments":["If you really do want to have individual commits (instead of reverting everything with one big commit), then you can pass --no-edit instead of --no-commit, so that you don't have to edit a commit message for each reversion.","If one of the commits between 0766c053..HEAD is a merge then there will be an error popping up (to do with no -m specified). This may help those encountering that: stackoverflow.com/questions/5970889/…","$ git revert --no-commit 53742ae..HEAD returns fatal: empty commit set passed","If you remove that '..HEAD' at the end of the command, you can remove only a specific commit. For example: git revert --no-commit 0766c053 will remove only the specific changes made for 0766c053 keeping all changes after 0766c053 untouched."]},{"answer":"Rogue Coder?\n\nWorking on your own and just want it to work? Follow these instructions below, they’ve worked reliably for me and many others for years.\n\nWorking with others? Git is complicated. Read the comments below this answer before you do something rash.\n\nReverting Working Copy to Most Recent Commit\n\nTo revert to a previous commit, ignoring any changes:\n\ngit reset --hard HEAD\n\n\nwhere HEAD is the last commit in your current branch\n\nReverting The Working Copy to an Older Commit\n\nTo revert to a commit that's older than the most recent commit:\n\n# Resets index to former commit; replace '56e05fced' with your commit code\ngit reset 56e05fced \n\n# Moves pointer back to previous HEAD\ngit reset --soft HEAD@{1}\n\ngit commit -m \"Revert to 56e05fced\"\n\n# Updates working copy to reflect the new commit\ngit reset --hard\n\n\nCredits go to a similar Stack Overflow question, Revert to a commit by a SHA hash in Git?.\n\nShare\nImprove this answer\nFollow\nedited Jun 13 '19 at 2:36\nanswered Aug 21 '12 at 6:19\nboulder_ruby\n33.5k8\n8 gold badges\n67\n67 silver badges\n93\n93 bronze badges","comments":["I did that, but then I wasn't able to commit and push to the remote repository. I want a specific older commit to become HEAD..."]},{"answer":"The best option for me and probably others is the Git reset option:\n\ngit reset --hard <commidId> && git clean -f\n\n\nThis has been the best option for me! It is simple, fast and effective!\n\n** Note:** As mentioned in comments don't do this if you're sharing your branch with other people who have copies of the old commits\n\nAlso from the comments, if you wanted a less 'ballzy' method you could use\n\ngit clean -i\n\nShare\nImprove this answer\nFollow\nedited Dec 8 '19 at 13:30\nPhoenix\n3,5504\n4 gold badges\n22\n22 silver badges\n35\n35 bronze badges\nanswered Oct 22 '13 at 11:53\nPogrindis\n6,6705\n5 gold badges\n26\n26 silver badges\n40\n40 bronze badges","comments":["Obligatory Warning: don't do this if you're sharing your branch with other people who have copies of the old commits, because using a hard reset like this will force them to have to resynchronize their work with the newly reset branch. For a solution that explains in detail how to safely revert commits without losing work with a hard reset, see this answer."]},{"answer":"Before answering let's add some background, explaining what this HEAD is.\n\nFirst of all what is HEAD?\n\nHEAD is simply a reference to the current commit (latest) on the current branch. There can only be a single HEAD at any given time (excluding git worktree).\n\nThe content of HEAD is stored inside .git/HEAD, and it contains the 40 bytes SHA-1 of the current commit.\n\ndetached HEAD\n\nIf you are not on the latest commit - meaning that HEAD is pointing to a prior commit in history it's called detached HEAD.\n\nOn the command line it will look like this - SHA-1 instead of the branch name since the HEAD is not pointing to the the tip of the current branch:\n\nA few options on how to recover from a detached HEAD:\ngit checkout\ngit checkout <commit_id>\ngit checkout -b <new branch> <commit_id>\ngit checkout HEAD~X // x is the number of commits t go back\n\n\nThis will checkout new branch pointing to the desired commit. This command will checkout to a given commit.\n\nAt this point you can create a branch and start to work from this point on:\n\n# Checkout a given commit.\n# Doing so will result in a `detached HEAD` which mean that the `HEAD`\n# is not pointing to the latest so you will need to checkout branch\n# in order to be able to update the code.\ngit checkout <commit-id>\n\n# Create a new branch forked to the given commit\ngit checkout -b <branch name>\n\ngit reflog\n\nYou can always use the reflog as well. git reflog  will display any change which updated the HEAD and checking out the desired reflog entry will set the HEAD back to this commit.\n\nEvery time the HEAD is modified there will be a new entry in the reflog\n\ngit reflog\ngit checkout HEAD@{...}\n\n\nThis will get you back to your desired commit\n\ngit reset HEAD --hard <commit_id>\n\n\"Move\" your head back to the desired commit.\n\n# This will destroy any local modifications.\n# Don't do it if you have uncommitted work you want to keep.\ngit reset --hard 0d1d7fc32\n\n# Alternatively, if there's work to keep:\ngit stash\ngit reset --hard 0d1d7fc32\ngit stash pop\n# This saves the modifications, then reapplies that patch after resetting.\n# You could get merge conflicts, if you've modified things which were\n# changed since the commit you reset to.\n\nNote: (Since Git 2.7) you can also use the git rebase --no-autostash as well.\n\nThis schema illustrates which command does what. As you can see there reset && checkout modify the HEAD.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Feb 5 '15 at 21:56\nCodeWizard\n96.8k19\n19 gold badges\n113\n113 silver badges\n139\n139 bronze badges","comments":[]},{"answer":"If you want to \"uncommit\", erase the last commit message, and put the modified files back in staging, you would use the command:\n\ngit reset --soft HEAD~1\n\n--soft indicates that the uncommitted files should be retained as working files opposed to --hard which would discard them.\nHEAD~1 is the last commit. If you want to rollback 3 commits you could use HEAD~3. If you want to rollback to a specific revision number, you could also do that using its SHA hash.\n\nThis is an extremely useful command in situations where you committed the wrong thing and you want to undo that last commit.\n\nSource: http://nakkaya.com/2009/09/24/git-delete-last-commit/\n\nShare\nImprove this answer\nFollow\nanswered Mar 4 '14 at 17:25\nStephen Ostermiller\n18.8k8\n8 gold badges\n74\n74 silver badges\n95\n95 bronze badges","comments":[]},{"answer":"You can do this by the following two commands:\n\ngit reset --hard [previous Commit SHA id here]\ngit push origin [branch Name] -f\n\n\nIt will remove your previous Git commit.\n\nIf you want to keep your changes, you can also use:\n\ngit reset --soft [previous Commit SHA id here]\n\n\nThen it will save your changes.\n\nShare\nImprove this answer\nFollow\nedited Jul 3 '16 at 6:30\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 12 '14 at 6:52\nkiran boghra\n3,1622\n2 gold badges\n16\n16 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"I have tried a lot of ways to revert local changes in Git, and it seems that this works the best if you just want to revert to the latest commit state.\n\ngit add . && git checkout master -f\n\n\nShort description:\n\nIt will NOT create any commits as git revert does.\nIt will NOT detach your HEAD like git checkout <commithashcode> does.\nIt WILL override all your local changes and DELETE all added files since the last commit in the branch.\nIt works only with branches names, so you can revert only to latest commit in the branch this way.\n\nI found a much more convenient and simple way to achieve the results above:\n\ngit add . && git reset --hard HEAD\n\n\nwhere HEAD points to the latest commit at you current branch.\n\nIt is the same code code as boulder_ruby suggested, but I have added git add . before git reset --hard HEAD to erase all new files created since the last commit since this is what most people expect I believe when reverting to the latest commit.\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '14 at 20:08\nfranzwr\n915\n5 bronze badges\nanswered Jul 29 '12 at 11:01\nRoman Minenok\n8,9604\n4 gold badges\n24\n24 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"The best way is:\n\ngit reset --hard <commidId> && git push --force\n\n\nThis will reset the branch to the specific commit and then will upload the remote server with the same commits as you have in local.\n\nBe careful with the --force flag as it removes all the subsequent commits after the selected commit without the option to recover them.\n\nShare\nImprove this answer\nFollow\nedited Jan 13 at 16:16\nanswered Feb 25 '20 at 17:00\ndavid.t_92\n1,4511\n1 gold badge\n9\n9 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"OK, going back to a previous commit in Git is quite easy...\n\nRevert back without keeping the changes:\n\ngit reset --hard <commit>\n\n\nRevert back with keeping the changes:\n\ngit reset --soft <commit>\n\n\nExplanation: using git reset, you can reset to a specific state. It's common using it with a commit hash as you see above.\n\nBut as you see the difference is using the two flags --soft and --hard, by default git reset using --soft flag, but it's a good practice always using the flag, I explain each flag:\n\n--soft\n\nThe default flag as explained, not need to provide it, does not change the working tree, but it adds all changed files ready to commit, so you go back to the commit status which changes to files get unstaged.\n\n--hard\n\nBe careful with this flag. It resets the working tree and all changes to tracked files and all will be gone!\n\nI also created the image below that may happen in a real life working with Git:\n\nShare\nImprove this answer\nFollow\nedited Jan 26 '20 at 17:28\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 20 '17 at 15:55\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"Assuming you're talking about master and on that respective branch (that said, this could be any working branch you're concerned with):\n\n# Reset local master branch to November 3rd commit ID\ngit reset --hard 0d1d7fc32e5a947fbd92ee598033d85bfc445a50\n\n# Reset remote master branch to November 3rd commit ID\ngit push -f origin 0d1d7fc32e5a947fbd92ee598033d85bfc445a50:master\n\n\nI found the answer from in a blog post (now no longer exists)\n\nNote that this is Resetting and Forcing the change to the remote, so that if others on your team have already git pulled, you will cause problems for them. You are destroying the change history, which is an important reason why people use git in the first place.\n\nBetter to use revert (see other answers) than reset. If you're a one man team then it probably doesn't matter.\n\nShare\nImprove this answer\nFollow\nedited Apr 28 '19 at 19:59\nrmcsharry\n4,4754\n4 gold badges\n51\n51 silver badges\n90\n90 bronze badges\nanswered May 10 '16 at 17:21\nmarkreyes\n1,12010\n10 silver badges\n22\n22 bronze badges","comments":[]},{"answer":"Say you have the following commits in a text file named ~/commits-to-revert.txt (I used git log --pretty=oneline to get them)\n\nfe60adeba6436ed8f4cc5f5c0b20df7ac9d93219\n0c27ecfdab3cbb08a448659aa61764ad80533a1b\nf85007f35a23a7f29fa14b3b47c8b2ef3803d542\ne9ec660ba9c06317888f901e3a5ad833d4963283\n6a80768d44ccc2107ce410c4e28c7147b382cd8f\n9cf6c21f5adfac3732c76c1194bbe6a330fb83e3\nfff2336bf8690fbfb2b4890a96549dc58bf548a5\n1f7082f3f52880cb49bc37c40531fc478823b4f5\ne9b317d36a9d1db88bd34831a32de327244df36a\nf6ea0e7208cf22fba17952fb162a01afb26de806\n137a681351037a2204f088a8d8f0db6e1f9179ca\n\n\nCreate a Bash shell script to revert each of them:\n\n#!/bin/bash\ncd /path/to/working/copy\nfor i in `cat ~/commits-to-revert.txt`\ndo\n    git revert $i --no-commit\ndone\n\n\nThis reverts everything back to the previous state, including file and directory creations, and deletions, commit it to your branch and you retain the history, but you have it reverted back to the same file structure. Why Git doesn't have a git revert --to <hash> is beyond me.\n\nShare\nImprove this answer\nFollow\nedited Jun 29 '14 at 0:13\nuser456814\nanswered Oct 13 '11 at 21:51\nLance Caraccioli\n1,35312\n12 silver badges\n14\n14 bronze badges","comments":["You could do a git revert HEAD~3 to remove the last 3 commits","@Rod - No, that's not right. That command will revert the commit that is the third grandparent of HEAD (not the last three commits)."]},{"answer":"Extra Alternatives to Jefromi's Solutions\n\nJefromi's solutions are definitely the best ones, and you should definitely use them. However, for the sake of completeness, I also wanted to show these other alternative solutions that can also be used to revert a commit (in the sense that you create a new commit that undoes changes in previous commit, just like what git revert does).\n\nTo be clear, these alternatives are not the best way to revert commits, Jefromi's solutions are, but I just want to point out that you can also use these other methods to achieve the same thing as git revert.\n\nAlternative 1: Hard and Soft Resets\n\nThis is a very slightly modified version of Charles Bailey's solution to Revert to a commit by a SHA hash in Git?:\n\n# Reset the index to the desired commit\ngit reset --hard <commit>\n\n# Move the branch pointer back to the previous HEAD\ngit reset --soft HEAD@{1}\n\n# Commit the changes\ngit commit -m \"Revert to <commit>\"\n\n\nThis basically works by using the fact that soft resets will leave the state of the previous commit staged in the index/staging-area, which you can then commit.\n\nAlternative 2: Delete the Current Tree and Replace with the New One\n\nThis solution comes from svick's solution to Checkout old commit and make it a new commit:\n\ngit rm -r .\ngit checkout <commit> .\ngit commit\n\n\nSimilarly to alternative #1, this reproduces the state of <commit> in the current working copy. It is necessary to do git rm first because git checkout won't remove files that have been added since <commit>.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:47\ncommunity wiki\n\n\n2 revs\nuser456814","comments":[]},{"answer":"Here is a much simpler way to go back to a previous commit (and have it in an uncommited state, to do with it whatever you like):\n\ngit reset HEAD~1\n\n\nSo, no need for commit ids and so on :)\n\nShare\nImprove this answer\nFollow\nedited Jul 3 '16 at 10:56\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 29 '16 at 8:40\nPaul Walczewski\n1,1969\n9 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"Caution! This command can cause losing commit history, if user put the wrong commit mistakenly. Always have en extra backup of your git some where else just in case if you do mistakes, than you are a bit safer. :)\n\nI have had a similar issue and wanted to revert back to an earlier commit. In my case I was not interested to keep the newer commit, hence I used Hard.\n\nThis is how I did it:\n\ngit reset --hard CommitId && git clean -f\n\n\nThis will revert on the local repository, and here after using git push -f will update the remote repository.\n\ngit push -f\n\n\nFor instance, if you want to completely ignore the commit with the name enforce non-group manage policies from the next image\n\nyou'd run\n\ngit reset --hard dd52eb9 && git clean -f\n\n\nfollowed by\n\ngit push -f\n\n\nAfter, you won't see that commit (enforce non-group manage policies) there\n\nShare\nImprove this answer\nFollow\nedited Mar 23 at 12:57\nTiago Martins Peres 李大仁\n10.9k13\n13 gold badges\n58\n58 silver badges\n89\n89 bronze badges\nanswered Jan 8 '18 at 14:15\nmaytham-ɯɐɥʇʎɐɯ\n22.4k10\n10 gold badges\n88\n88 silver badges\n110\n110 bronze badges","comments":[]},{"answer":"After all the changes, when you push all these commands, you might have to use:\n\ngit push -f ...\n\n\nAnd not only git push.\n\nShare\nImprove this answer\nFollow\nedited Sep 28 '13 at 19:07\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 5 '13 at 14:03\nsivi\n9,2642\n2 gold badges\n44\n44 silver badges\n47\n47 bronze badges","comments":[]},{"answer":"There is a command (not a part of core Git, but it is in the git-extras package) specifically for reverting and staging old commits:\n\ngit back\n\n\nPer the man page, it can also be used as such:\n\n# Remove the latest three commits\ngit back 3\n\nShare\nImprove this answer\nFollow\nedited Jun 28 '14 at 20:19\nFlexo♦\n82.9k22\n22 gold badges\n175\n175 silver badges\n258\n258 bronze badges\nanswered Aug 8 '13 at 18:30\nShadow Man\n2,9601\n1 gold badge\n20\n20 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"You can complete all these initial steps yourself and push back to the Git repository.\n\nPull the latest version of your repository from Bitbucket using the git pull --all command.\n\nRun the Git log command with -n 4 from your terminal. The number after the -n determines the number of commits in the log starting from the most recent commit in your local history.\n\n$ git log -n 4\n\n\nReset the head of your repository's history using the git reset --hard HEAD~N where N is the number of commits you want to take the head back. In the following example the head would be set back one commit, to the last commit in the repository history:\n\nPush the change to Git repository using git push --force to force push the change.\n\nIf you want the Git repository to a previous commit:\n\ngit pull --all\ngit reset --hard HEAD~1\ngit push --force\n\nShare\nImprove this answer\nFollow\nedited Jan 26 '20 at 17:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 6 '17 at 12:20\nNanhe Kumar\n13.1k3\n3 gold badges\n69\n69 silver badges\n63\n63 bronze badges","comments":[]},{"answer":"Select your required commit, and check it by\n\ngit show HEAD\ngit show HEAD~1\ngit show HEAD~2 \n\n\ntill you get the required commit. To make the HEAD point to that, do\n\ngit reset --hard HEAD~1\n\n\nor git reset --hard HEAD~2 or whatever.\n\nShare\nImprove this answer\nFollow\nedited Jun 28 '14 at 19:51\nuser456814\nanswered Feb 26 '14 at 12:52\ntonythomas01\n4701\n1 gold badge\n5\n5 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"Revert to most recent commit and ignoring all local changes:\n\ngit reset --hard HEAD\n\nShare\nImprove this answer\nFollow\nedited Jul 4 '18 at 19:28\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 26 '16 at 13:13\nMohammed Irfan Tirupattur\n1,39917\n17 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"If the situation is an urgent one, and you just want to do what the questioner asked in a quick and dirty way, assuming your project is under a directory called, for example, \"my project\":\n\nQUICK AND DIRTY: depending on the circumstances, quick and dirty may in fact be very GOOD. What my solution here does is NOT replace irreversibly the files you have in your working directory with files hauled up/extracted from the depths of the git repository lurking beneath your .git/ directory using fiendishly clever and diabolically powerful git commands, of which there are many. YOU DO NOT HAVE TO DO SUCH DEEP-SEA DIVING TO RECOVER what may appear to be a disastrous situation, and attempting to do so without sufficient expertise may prove fatal.\n\nCopy the whole directory and call it something else, like \"my project - copy\". Assuming your git repository (\"repo\") files are under the \"my project\" directory (the default place for them, under a directory called \".git\"), you will now have copied both your work files and your repo files.\n\nDo this in the directory \"my project\":\n\n.../my project $ git reset --hard [first-4-letters&numbers-of-commit's-SHA]\n\n\nThis will return the state of the repo under \"my project\" to what it was when you made that commit (a \"commit\" means a snapshot of your working files). All commits since then will be lost forever under \"my project\", BUT... they will still be present in the repo under \"my project - copy\" since you copied all those files - including the ones under .../.git/.\n\nYou then have two versions on your system... you can examine or copy or modify files of interest, or whatever, from the previous commit. You can completely discard the files under \"my project - copy\", if you have decided the new work since the restored commit was going nowhere...\n\nThe obvious thing if you want to carry on with the state of the project without actually discarding the work since this retrieved commit is to rename your directory again: Delete the project containing the retrieved commit (or give it a temporary name) and rename your \"my project - copy\" directory back to \"my project\". Then maybe try to understand some of the other answers here, and probably do another commit fairly soon.\n\nGit is a brilliant creation but absolutely no-one is able to just \"pick it up on the fly\": also people who try to explain it far too often assume prior knowledge of other VCS [Version Control Systems] and delve far too deep far too soon, and commit other crimes, like using interchangeable terms for \"checking out\" - in ways which sometimes appear almost calculated to confuse a beginner.\n\nTo save yourself much stress, learn from my scars. You have to pretty much have to read a book on Git - I'd recommend \"Version Control with Git\". Do it sooner rather than later. If you do, bear in mind that much of the complexity of Git comes from branching and then remerging: you can skip those parts in any book. From your question there's no reason why people should be blinding you with science.\n\nEspecially if, for example, this is a desperate situation and you're a newbie with Git!\n\nPS: One other thought: It is (now) actually quite simple to keep the Git repo in a directory other than the one with the working files. This would mean you would not have to copy the entire Git repository using the above quick & dirty solution. See the answer by Fryer using --separate-git-dir here. Be warned, though: If you have a \"separate-directory\" repository which you don't copy, and you do a hard reset, all versions subsequent to the reset commit will be lost forever, unless you have, as you absolutely should, regularly backed up your repository, preferably to the Cloud (e.g. Google Drive) among other places.\n\nOn this subject of \"backing up to the Cloud\", the next step is to open an account (free of course) with GitHub or (better in my view) GitLab. You can then regularly do a git push command to make your Cloud repo up-to-date \"properly\". But again, talking about this may be too much too soon.\n\nShare\nImprove this answer\nFollow\nedited Nov 25 '19 at 20:55\nanswered Mar 19 '15 at 17:33\nmike rodent\n10.9k11\n11 gold badges\n80\n80 silver badges\n106\n106 bronze badges","comments":[]},{"answer":"This is one more way to directly reset to a recent commit\ngit stash\ngit stash clear\n\n\nIt directly clears all the changes that you have been making since the last commit.\n\nPS: It has a little problem; it also deletes all you recently stored stash changes. Which I guess in most cases should not matter.\n\nShare\nImprove this answer\nFollow\nedited Jul 3 '16 at 10:57\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 5 '16 at 11:43\nPoint Networks\n9119\n9 silver badges\n29\n29 bronze badges","comments":["NOTE: New files not added in index are not stashed. You have too add them or manually delete them.","Why oh why clearing stash? In addition to being a non-solution, this is actually harmful. Reading the very first sentence of the question immediately invalidates the stash solution (which could be useful ONLY to reset to the LAST commit)."]},{"answer":"To completely clean a coder's directory up from some accidental changes, we used:\n\ngit add -A .\ngit reset --hard HEAD\n\n\nJust git reset --hard HEAD will get rid of modifications, but it won't get rid of \"new\" files. In their case they'd accidentally dragged an important folder somewhere random, and all those files were being treated as new by Git, so a reset --hard didn't fix it. By running the git add -A . beforehand, it explicitly tracked them all with git, to be wiped out by the reset.\n\nShare\nImprove this answer\nFollow\nedited Jul 3 '16 at 10:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 11 '15 at 0:10\nChris Moschini\n33.8k18\n18 gold badges\n150\n150 silver badges\n181\n181 bronze badges","comments":["I think this is an answer to a rather different question - stackoverflow.com/q/1125968. I interpret the question here to concern the remote repository."]},{"answer":"Revert is the command to rollback the commits.\n\ngit revert <commit1> <commit2> \n\n\nSample:\n\ngit revert 2h3h23233\n\n\nIt is capable of taking range from the HEAD like below. Here 1 says \"revert last commit.\"\n\ngit revert HEAD~1..HEAD\n\n\nAnd then do:\n\ngit push\n\nShare\nImprove this answer\nFollow\nedited Jul 12 at 19:53\ngaloget\n5906\n6 silver badges\n14\n14 bronze badges\nanswered Aug 20 '15 at 14:45\nSireesh Yarlagadda\n10.8k2\n2 gold badges\n65\n65 silver badges\n72\n72 bronze badges","comments":[]},{"answer":"I believe some people may come to this question wanting to know how to rollback committed changes they've made in their master - ie throw everything away and go back to origin/master, in which case, do this:\n\ngit reset --hard origin/master\n\n\nhttps://superuser.com/questions/273172/how-to-reset-master-to-origin-master\n\nShare\nImprove this answer\nFollow\nedited Mar 20 '17 at 10:18\nCommunity♦\n11\n1 silver badge\nanswered Feb 5 '15 at 1:28\nnevster\n5,8686\n6 gold badges\n32\n32 silver badges\n40\n40 bronze badges","comments":[]},{"answer":"To keep the changes from the previous commit to HEAD and move to the previous commit, do:\n\ngit reset <SHA>\n\n\nIf changes are not required from the previous commit to HEAD and just discard all changes, do:\n\ngit reset --hard <SHA>\n\nShare\nImprove this answer\nFollow\nedited Jul 3 '16 at 10:21\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 28 '15 at 8:35\nVishnu Atrai\n2,18518\n18 silver badges\n22\n22 bronze badges","comments":[]},{"answer":"Idea: You basically want to replace the current working tree state with the one from a previous commit and then create a commit out of it. Ignored files should best be not changed. Here is how:\n\nEmtpy the working tree *.\n\n git rm -r --cached . && git clean -f -d\n\n\nBring the working tree in the state we want **.\n\n git checkout 0d1d7fc3 .\n\n\nCreate the revert commit.\n\n git add --all && git commit -m \"revert to 0d1d7fc3\"\n\n\nAt first I thought that Yarins answer would be the best, but it doesn't work for merge commits. This solution does.\n\nAdditionally it does not delete anything (pushed or upushed) from the history. It produces one clean commit which represents the state we want to revert back to.\n\n* by removing untracked but not ignored files (the ones specified in .gitignore) from working tree. The working tree is empty except for the ignored files which we wanted to keep (if not specifiy -x option for clean)\n\n** When a path is specified (here: .), checkout leaves HEAD alone.\n\nShare\nImprove this answer\nFollow\nedited Aug 24 '20 at 8:54\nanswered Nov 10 '19 at 10:10\nWilli Mentzel\n22.3k16\n16 gold badges\n92\n92 silver badges\n103\n103 bronze badges","comments":[]},{"answer":"Try resetting to the desired commit:\n\ngit reset <COMMIT_ID>\n\n\nTo check COMMIT_ID use:\n\ngit log\n\n\nThis will reset all changed files to un-added state.\n\nNow you can checkout all un-added files by\n\ngit checkout .\n\n\nTo verify your changes use:\n\ngit log\n\n\nUPDATE\n\nIf you have one and only commit in your repo, try\n\ngit update-ref -d HEAD\n\nShare\nImprove this answer\nFollow\nedited Jul 13 at 13:42\ngaloget\n5906\n6 silver badges\n14\n14 bronze badges\nanswered May 6 '17 at 23:03\noptimistanoop\n6241\n1 gold badge\n9\n9 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"As your commits are pushed remotely, you need to remove them. Let me assume your branch is develop and it is pushed over origin.\n\nYou first need to remove develop from origin:\n\ngit push origin :develop (note the colon)\n\n\nThen you need to get develop to the status you want, let me assume the commit hash is EFGHIJK:\n\ngit reset --hard EFGHIJK\n\n\nLastly, push develop again:\n\ngit push origin develop\n\nShare\nImprove this answer\nFollow\nedited Jan 26 '20 at 17:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 20 '17 at 7:33\nGeorge Ninan\n1,5691\n1 gold badge\n11\n11 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"For rollback (or to revert):\n\n1. git revert --no-commit \"commit-code-to-remove\" HEAD\n(e.g. git revert --no-commit d57a39d HEAD)\n2. git commit\n3. git push\n\n\nTry the above two steps, and if you find this is what you want then git push.\n\nIf you find something wrong, do:\n\ngit revert --abort\n\nShare\nImprove this answer\nFollow\nedited Jan 26 '20 at 17:00\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 1 '16 at 14:29\nJagraj Singh\n3844\n4 silver badges\n6\n6 bronze badges","comments":[]}]},{"id":"1783405","href":"https://stackoverflow.com/questions/1783405/how-do-i-check-out-a-remote-git-branch","title":"How do I check out a remote Git branch?","description":"\n                \nSomebody pushed a branch called test with git push origin test to a shared repository. I can see the branch with git branch -r.\n\nNow I'm trying to check out the remote test branch.\n\nI've tried:\n\n\ngit checkout test which does nothing\ngit checkout origin/test gives * (no branch). Which is confusing. How can I be on \"no branch\"?\n\n\nHow do I check out a remote Git branch?\n    ","questionComments":["I think this thread is unhelpful. Nothing seems to work, the original question seems to have been lost in many of the answers. I have read every word, tried everything below, and have no idea how to do what the OP wants to do.","I feel like I'm taking crazy pills. I'm trying to checkout a branch from an upstream, not just origin, and every recommended answer doesn't do anything remotely helpful (pun-intended). EDIT - excuse me, the multitude of suggestions contained in the top 2 answers were useless; 3rd one (git branch test origin/test) is what works. Glad the top 2 have 20x the number of votes..."],"answers":[{"answer":"With One Remote\n\nJakub's answer actually improves on this. With Git versions ≥ 1.6.6, with only one remote, you can do:\n\ngit fetch\ngit checkout test\n\n\nAs user masukomi points out in a comment, git checkout test will NOT work in modern git if you have multiple remotes. In this case use\n\ngit checkout -b test <name of remote>/test\n\n\nor the shorthand\n\ngit checkout -t <name of remote>/test\n\nWith >1 Remotes\n\nBefore you can start working locally on a remote branch, you need to fetch it as called out in answers below.\n\nTo fetch a branch, you simply need to:\n\ngit fetch origin\n\n\nThis will fetch all of the remote branches for you. You can see the branches available for checkout with:\n\ngit branch -v -a\n\n\nWith the remote branches in hand, you now need to check out the branch you are interested in, giving you a local working copy:\n\ngit checkout -b test origin/test\n\n\nI also created the image below for you to share the differences, look at how to fetch works, and also how it's different to pull:\n\nShare\nImprove this answer\nFollow\nedited Aug 6 at 8:43\nFarrukh Malik\n3602\n2 silver badges\n10\n10 bronze badges\nanswered Nov 23 '09 at 14:26\nhallski\n110k4\n4 gold badges\n30\n30 silver badges\n21\n21 bronze badges","comments":["To expand on this: git doesn't allow you to work on someone else's branches. You can only work on your own. So if you want to add to someone else's branch, you need to create your own \"copy\" of that branch, which is what the above command does (well, it creates your branch and checks it out, too).","If it's a new remote branch you may need to git fetch before doing this so that git is aware of origin/test","...and you would do this with git fetch origin test","Error: \"git checkout: updating paths is incompatible with switching branches. Did you intend to checkout origin/test which can not be resolved as commit?\"","git checkout test will NOT work in modern git if you have multiple remotes which have the same branch name. It can't know which one to use."]},{"answer":"Sidenote: With modern Git (>= 1.6.6), you are able to use just\n\ngit checkout test\n\n\n(note that it is 'test' not 'origin/test') to perform magical DWIM-mery and create local branch 'test' for you, for which upstream would be remote-tracking branch 'origin/test'.\n\nThe * (no branch) in git branch output means that you are on unnamed branch, in so called \"detached HEAD\" state (HEAD points directly to commit, and is not symbolic reference to some local branch). If you made some commits on this unnamed branch, you can always create local branch off current commit:\n\ngit checkout -b test HEAD\n\n** EDIT (by editor not author) **\n\nI found a comment buried below which seems to modernize this answer:\n\n@Dennis: git checkout <non-branch>, for example git checkout origin/test results in detached HEAD / unnamed branch, while git checkout test or git checkout -b test origin/test results in local branch test (with remote-tracking branch origin/test as upstream) – Jakub Narębski Jan 9 '14 at 8:17\n\nemphasis on git checkout origin/test\n\nShare\nImprove this answer\nFollow\nedited Jul 29 '20 at 16:13\nPaul\n4,2862\n2 gold badges\n27\n27 silver badges\n54\n54 bronze badges\nanswered Nov 24 '09 at 0:17\nJakub Narębski\n273k59\n59 gold badges\n209\n209 silver badges\n228\n228 bronze badges","comments":["Unsurprising, but this version has been released in the last few years - knowing this syntax can save a lot of time since there's still a lot of old documentation and comment threads floating around that suggest the older method for doing this.","\"modern git\"--for the record, (approx) what version are you referring to? Sometimes we have to work on systems running older distros.","@aidan If you get a response like error: pathspec 'branch_name' did not match any file(s) known to git. then you should do a git fetch first.","Using git version 1.8.3.msysgit.0 and this doesn't work for me - did not match any file(s) known to git - I've done many git fetches","@Dennis: git checkout <non-branch>, for example git checkout origin/test results in detached HEAD / unnamed branch, while git checkout test or git checkout -b test origin/test results in local branch test (with remote-tracking branch origin/test as upstream)"]},{"answer":"In this case, you probably want to create a local test branch which is tracking the remote test branch:\n\n$ git branch test origin/test\n\n\nIn earlier versions of git, you needed an explicit --track option, but that is the default now when you are branching off a remote branch.\n\nShare\nImprove this answer\nFollow\nedited Feb 24 '16 at 9:06\nanswered Nov 23 '09 at 14:27\nndim\n31.3k12\n12 gold badges\n43\n43 silver badges\n55\n55 bronze badges","comments":["This will create a local branch without switching to it."]},{"answer":"Accepted answer not working for you?\n\nWhile the first and selected answer is technically correct, there's the possibility you have not yet retrieved all objects and refs from the remote repository. If that is the case, you'll receive the following error:\n\n$ git checkout -b remote_branch origin/remote_branch\n\n\nfatal: git checkout: updating paths is incompatible with switching branches.\nDid you intend to checkout 'origin/remote_branch' which can not be resolved as commit?\n\nSolution\n\nIf you receive this message, you must first do a git fetch origin where origin is the name of the remote repository prior to running git checkout remote_branch. Here's a full example with responses:\n\n$ git fetch origin\nremote: Counting objects: 140, done.\nremote: Compressing objects: 100% (30/30), done.\nremote: Total 69 (delta 36), reused 66 (delta 33)\nUnpacking objects: 100% (69/69), done.\nFrom https://github.com/githubuser/repo-name\n   e6ef1e0..5029161  develop    -> origin/develop\n * [new branch]      demo       -> origin/demo\n   d80f8d7..359eab0  master     -> origin/master\n\n$ git checkout demo\nBranch demo set up to track remote branch demo from origin.\nSwitched to a new branch 'demo'\n\n\nAs you can see, running git fetch origin retrieved any remote branches we were not yet setup to track on our local machine. From there, since we now have a ref to the remote branch, we can simply run git checkout remote_branch and we'll gain the benefits of remote tracking.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:26\nCommunity♦\n11\n1 silver badge\nanswered Dec 7 '12 at 20:52\nCorey Ballou\n39.7k8\n8 gold badges\n60\n60 silver badges\n75\n75 bronze badges","comments":[]},{"answer":"I tried the above solution, but it didn't work. Try this, it works:\n\ngit fetch origin 'remote_branch':'local_branch_name'\n\n\nThis will fetch the remote branch and create a new local branch (if not exists already) with name local_branch_name and track the remote one in it.\n\nShare\nImprove this answer\nFollow\nedited May 4 '15 at 1:45\nanswered Oct 18 '13 at 5:55\nSahil kalra\n6,7383\n3 gold badges\n21\n21 silver badges\n29\n29 bronze badges","comments":["This worked for me when neither git fetch origin or git remote update created local branches. I'm not sure why.","This was the most direct way to accomplish what I needed which was to use a remote branch (not master) to create a new branch.","Worked seamlessly, especially when having cloned a single branch from a remote with multiple branches.","this worked for me too, where accepted answers and other high voted didn't. My git version is 2.5.0","Does anyone have any idea why this works when everything else doesn't? (I'm on git 2.13.0)"]},{"answer":"This will DWIM for a remote not named origin (documentation):\n\n$ git checkout -t remote_name/remote_branch\n\n\nTo add a new remote, you will need to do the following first:\n\n$ git remote add remote_name location_of_remote\n$ git fetch remote_name\n\n\nThe first tells Git the remote exists, the second gets the commits.\n\nShare\nImprove this answer\nFollow\nedited Jul 13 '14 at 23:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 27 '12 at 22:37\ntacaswell\n75.1k16\n16 gold badges\n192\n192 silver badges\n183\n183 bronze badges","comments":[]},{"answer":"Use:\n\ngit checkout -b <BRANCH-NAME> <REMOTE-NAME>/<BRANCH-NAME>\n\n\nOther answers do not work with modern Git in my benign case. You might need to pull first if the remote branch is new, but I haven't checked that case.\n\nShare\nImprove this answer\nFollow\nedited Jun 30 '16 at 16:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 21 '16 at 10:58\nmatanster\n14k15\n15 gold badges\n78\n78 silver badges\n138\n138 bronze badges","comments":["Looking at it now, they do overlap. Only mine is succinct and tells you what to do rather than tell a story. I assume it can be more useful therefore, especially for nowadays git versions. You can downvote it if you think it is a bad answer.","do not foget to do git pull afetr that ..."]},{"answer":"You basically see the branch, but you don't have a local copy yet!...\n\nYou need to fetch the branch...\n\nYou can simply fetch and then checkout to the branch, use the one line command below to do that:\n\ngit fetch && git checkout test\n\n\nI also created the image below for you to share the differences, look at how fetch works and also how it's different to pull:\n\nShare\nImprove this answer\nFollow\nedited May 17 at 17:44\nNoel Yap\n15.8k17\n17 gold badges\n78\n78 silver badges\n124\n124 bronze badges\nanswered Sep 5 '17 at 14:20\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"To clone a Git repository, do:\n\ngit clone <either ssh url /http url>\n\n\nThe above command checks out all of the branches, but only the master branch will be initialized. If you want to checkout the other branches, do:\n\ngit checkout -t origin/future_branch (for example)\n\n\nThis command checks out the remote branch, and your local branch name will be same as the remote branch.\n\nIf you want to override your local branch name on checkout:\n\ngit checkout -t -b enhancement origin/future_branch\n\n\nNow your local branch name is enhancement, but your remote branch name is future_branch.\n\nShare\nImprove this answer\nFollow\nedited Nov 20 '20 at 12:04\nOndrej\n4421\n1 gold badge\n3\n3 silver badges\n10\n10 bronze badges\nanswered Jan 21 '13 at 10:04\nMadhan Ayyasamy\n13.7k3\n3 gold badges\n16\n16 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"You can try\n\ngit fetch remote\ngit checkout --track -b local_branch_name origin/branch_name\n\n\nor\n\ngit fetch\ngit checkout -b local_branch_name origin/branch_name\n\nShare\nImprove this answer\nFollow\nedited Jul 13 '14 at 23:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 24 '14 at 13:11\numa\n2,69822\n22 silver badges\n20\n20 bronze badges","comments":["FYI, --track is no longer needed in newer versions of git, because it's set by default, as explained in this earlier answer."]},{"answer":"First, you need to do:\n\ngit fetch # If you don't know about branch name\n\ngit fetch origin branch_name\n\n\nSecond, you can check out remote branch into your local by:\n\ngit checkout -b branch_name origin/branch_name\n\n\n-b will create new branch in specified name from your selected remote branch.\n\nShare\nImprove this answer\nFollow\nedited May 21 '17 at 11:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 18 '17 at 13:55\nMohideen bin Mohammed\n14.9k7\n7 gold badges\n87\n87 silver badges\n101\n101 bronze badges","comments":[]},{"answer":"I use the following command:\n\ngit checkout --track origin/other_remote_branch\n\nShare\nImprove this answer\nFollow\nedited Mar 21 '18 at 18:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 6 '17 at 14:41\npriyankvex\n5,1425\n5 gold badges\n24\n24 silver badges\n42\n42 bronze badges","comments":["This answer would be a lot more useful if you explain why you are using it this way. i.e. why someone should use '--track' and so on..."]},{"answer":"Commands\n\ngit fetch --all\ngit checkout -b <ur_new_local_branch_name> origin/<Remote_Branch_Name>\n\n\nare equal to\n\n git fetch --all\n\n\nand then\n\n git checkout -b fixes_for_dev origin/development\n\n\nBoth will create a latest fixes_for_dev from development\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '16 at 21:58\nmadhead\n26.6k14\n14 gold badges\n135\n135 silver badges\n180\n180 bronze badges\nanswered Apr 21 '16 at 19:10\nsreekumar\n2,1091\n1 gold badge\n19\n19 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"Simply run git checkout with the name of the remote branch. Git will automatically create a local branch that tracks the remote one:\n\ngit fetch\ngit checkout test\n\n\nHowever, if that branch name is found in more than one remote, this won't work as Git doesn't know which to use. In that case you can use either:\n\ngit checkout --track origin/test\n\n\nor\n\ngit checkout -b test origin/test\n\n\nIn 2.19, Git learned the checkout.defaultRemote configuration, which specifies a remote to default to when resolving such an ambiguity.\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 12:51\nanswered Sep 13 '18 at 12:21\nEugene Yarmash\n123k34\n34 gold badges\n284\n284 silver badges\n342\n342 bronze badges","comments":[]},{"answer":"If the branch is on something other than the origin remote I like to do the following:\n\n$ git fetch\n$ git checkout -b second/next upstream/next\n\n\nThis will checkout the next branch on the upstream remote in to a local branch called second/next. Which means if you already have a local branch named next it will not conflict.\n\n$ git branch -a\n* second/next\n  remotes/origin/next\n  remotes/upstream/next\n\nShare\nImprove this answer\nFollow\nedited May 30 '13 at 5:54\nprusswan\n6,5233\n3 gold badges\n37\n37 silver badges\n57\n57 bronze badges\nanswered Mar 1 '13 at 10:00\nKris\n17.2k6\n6 gold badges\n82\n82 silver badges\n100\n100 bronze badges","comments":[]},{"answer":"none of these answers worked for me. this worked:\n\ngit checkout -b feature/branch remotes/origin/feature/branch\n\nShare\nImprove this answer\nFollow\nanswered Jul 10 '18 at 2:11\nbrianyang\n9109\n9 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"I was stuck in a situation seeing error: pathspec 'desired-branch' did not match any file(s) known to git. for all of the suggestions above. I'm on git version 1.8.3.1.\n\nSo this worked for me:\n\ngit fetch origin desired-branch\ngit checkout -b desired-branch FETCH_HEAD\n\n\nThe explanation behind is that I've noticed that when fetching the remote branch, it was fetched to FETCH_HEAD:\n\n$ git fetch origin desired-branch\nFrom github.com:MYTEAM/my-repo\n    * branch            desired-branch -> FETCH_HEAD\n\nShare\nImprove this answer\nFollow\nanswered Oct 10 '18 at 21:52\nalisa\n9682\n2 gold badges\n9\n9 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"git fetch && git checkout your-branch-name\n\nShare\nImprove this answer\nFollow\nanswered Mar 26 '14 at 7:00\nInder Kumar Rathore\n37.7k14\n14 gold badges\n122\n122 silver badges\n177\n177 bronze badges","comments":[]},{"answer":"The git remote show <origin name> command will list all branches (including un-tracked branches). Then you can find the remote branch name that you need to fetch.\n\nExample:\n\n$ git remote show origin\n\n\nUse these steps to fetch remote branches:\n\ngit fetch <origin name> <remote branch name>:<local branch name>\ngit checkout <local branch name > (local branch name should the name that you given fetching)\n\n\nExample:\n\n$ git fetch origin test:test\n$ git checkout test\n\nShare\nImprove this answer\nFollow\nedited Mar 21 '18 at 18:34\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 7 '18 at 13:12\nThushan\n1,00212\n12 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"git branch -r says the object name is invalid, because that branch name isn't in Git's local branch list. Update your local branch list from origin with:\n\ngit remote update\n\n\nAnd then try checking out your remote branch again.\n\nThis worked for me.\n\nI believe git fetch pulls in all remote branches, which is not what the original poster wanted.\n\nShare\nImprove this answer\nFollow\nedited Jul 13 '14 at 23:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 6 '13 at 12:21\nwebdevguy\n9079\n9 silver badges\n16\n16 bronze badges","comments":["FYI, git remote update will also fetch all remote branches."]},{"answer":"Fetch from the remote and checkout the branch.\n\ngit fetch <remote_name> && git checkout <branch_name> \n\n\nE.g.:\n\ngit fetch origin && git checkout feature/XYZ-1234-Add-alerts\n\nShare\nImprove this answer\nFollow\nedited Mar 12 '19 at 9:10\nanswered May 21 '18 at 11:33\nPranav\n8518\n8 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"Other guys and gals give the solutions, but maybe I can tell you why.\n\ngit checkout test which does nothing\n\nDoes nothing doesn't equal doesn't work, so I guess when you type 'git checkout test' in your terminal and press enter key, no message appears and no error occurs. Am I right?\n\nIf the answer is 'yes', I can tell you the cause.\n\nThe cause is that there is a file (or folder) named 'test' in your work tree.\n\nWhen git checkout xxx parsed,\n\nGit looks on xxx as a branch name at first, but there isn't any branch named test.\nThen Git thinks xxx is a path, and fortunately (or unfortunately), there is a file named test. So git checkout xxx means discard any modification in xxx file.\nIf there isn't file named xxx either, then Git will try to create the xxx according to some rules. One of the rules is create a branch named xxx if remotes/origin/xxx exists.\nShare\nImprove this answer\nFollow\nedited Mar 21 '18 at 18:39\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 10 '17 at 7:45\noldman\n4,1562\n2 gold badges\n18\n18 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"To get newly created branches\n\ngit fetch\n\n\nTo switch into another branch\n\ngit checkout BranchName\n\nShare\nImprove this answer\nFollow\nedited Jul 7 '18 at 3:59\nCommunity♦\n11\n1 silver badge\nanswered Mar 15 '18 at 8:49\nHasib Kamal\n2,04520\n20 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"git checkout -b \"Branch_name\" [ B means Create local branch]\n\ngit branch --all\n\ngit checkout -b \"Your Branch name\"\n\ngit branch\n\ngit pull origin \"Your Branch name\"\n\nsuccessfully checkout from the master branch to dev branch\n\nShare\nImprove this answer\nFollow\nedited Apr 23 at 7:28\nanswered Dec 10 '19 at 6:29\nKeshav Gera\n8,7221\n1 gold badge\n59\n59 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"You can start tracking all remote branches with the following Bash script:\n\n#!/bin/bash\ngit fetch --all\nfor branch in `git branch -r --format=\"%(refname:short)\" | sed 's/origin\\///'`\n  do git branch -f --track \"$branch\" \"origin/$branch\"\ndone\n\n\nHere is also a single-line version:\n\ngit fetch --all; for branch in `git branch -r --format=\"%(refname:short)\" | sed 's/origin\\///'`; do git branch --track \"$branch\" \"origin/$branch\" ; done ;\n\nShare\nImprove this answer\nFollow\nedited Mar 21 '18 at 18:37\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 11 '17 at 12:06\nOzzyCzech\n7,7352\n2 gold badges\n39\n39 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"to get all remote branches use this :\n\ngit fetch --all\n\n\nthen checkout to the branch :\n\ngit checkout test\n\nShare\nImprove this answer\nFollow\nanswered Sep 23 '19 at 6:46\nZahra Badri\n8261\n1 gold badge\n9\n9 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"I always do: git fetch origin && git checkout --track origin/branch_name\n\nShare\nImprove this answer\nFollow\nanswered Jan 13 at 11:59\nM. Wojcik\n1,1982\n2 gold badges\n14\n14 silver badges\n26\n26 bronze badges","comments":["This works for me and is simple."]},{"answer":"Just run these two commands and you should be good to go.\n\ngit checkout <branch-name>\ngit pull <remote> <branch-name>\n\nShare\nImprove this answer\nFollow\nedited May 28 at 0:21\nCraigo\n2,74025\n25 silver badges\n18\n18 bronze badges\nanswered Jun 26 '20 at 5:15\nSateesh\n5746\n6 silver badges\n5\n5 bronze badges","comments":[]},{"answer":"For us, it seems the remote.origin.fetch configuration gave a problem. Therefore, we could not see any other remote branches than master, so git fetch [--all] did not help. Neither git checkout mybranch nor git checkout -b mybranch --track origin/mybranch did work, although it certainly was at remote.\n\nThe previous configuration only allowed master to be fetched:\n\n$ git config --list | grep fetch\nremote.origin.fetch=+refs/heads/master:refs/remotes/origin/master\n\n\nFix it by using * and fetch the new information from origin:\n\n$ git config remote.origin.fetch '+refs/heads/*:refs/remotes/origin/*'\n\n$ git fetch\n...\n * [new branch] ...\n...\n\n\nNow we could git checkout the remote branch locally.\n\nNo idea how this config ended up in our local repo.\n\nShare\nImprove this answer\nFollow\nanswered Sep 20 '19 at 10:20\nhzpc-joostk\n1812\n2 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"If the remote branch name begins with special characteres you need to use single quotes around it in the checkout command, or else git won't know which branch you are talking about.\n\nFor example, I tried to checkout a remote branch named as #9773 but the command didn't work properly, as shown in the picture below:\n\nFor some reason I wondered if the sharp symbol (#) could have something to do with it, and then I tried surrounding the branch name with single quotes, like '#9773' rathen than just #9773, and fortunately it worked fine.\n\n$ git checkout -b '#9773' origin/'#9773'\n\nShare\nImprove this answer\nFollow\nedited Mar 26 '20 at 14:51\nanswered Nov 7 '18 at 11:17\nUlysses Alves\n1,9901\n1 gold badge\n19\n19 silver badges\n32\n32 bronze badges","comments":[]}]},{"id":"1789945","href":"https://stackoverflow.com/questions/1789945/how-to-check-whether-a-string-contains-a-substring-in-javascript","title":"How to check whether a string contains a substring in JavaScript?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nUsually I would expect a String.contains() method, but there doesn't seem to be one. \n\nWhat is a reasonable way to check for this?\n    ","questionComments":[],"answers":[{"answer":"ECMAScript 6 introduced String.prototype.includes:\n\nconst string = \"foo\";\nconst substring = \"oo\";\n\nconsole.log(string.includes(substring));\n Run code snippetExpand snippet\n\nincludes doesn’t have Internet Explorer support, though. In ECMAScript 5 or older environments, use String.prototype.indexOf, which returns -1 when a substring cannot be found:\n\nvar string = \"foo\";\nvar substring = \"oo\";\n\nconsole.log(string.indexOf(substring) !== -1);\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Aug 17 at 6:20\ncommunity wiki\n\n\n44 revs, 35 users 19%\nRy-","comments":["While this is a good answer, and the OP never requested for a \"case-sensitive\" search, it should be noted that includes performs a case-sensitive search."]},{"answer":"There is a String.prototype.includes in ES6:\n\n\"potato\".includes(\"to\");\n> true\n\n\nNote that this does not work in Internet Explorer or some other old browsers with no or incomplete ES6 support. To make it work in old browsers, you may wish to use a transpiler like Babel, a shim library like es6-shim, or this polyfill from MDN:\n\nif (!String.prototype.includes) {\n  String.prototype.includes = function(search, start) {\n    'use strict';\n    if (typeof start !== 'number') {\n      start = 0;\n    }\n\n    if (start + search.length > this.length) {\n      return false;\n    } else {\n      return this.indexOf(search, start) !== -1;\n    }\n  };\n}\n\nShare\nImprove this answer\nFollow\nedited May 29 at 4:31\nmeagar♦\n213k39\n39 gold badges\n308\n308 silver badges\n317\n317 bronze badges\nanswered Jan 7 '13 at 10:23\neliocs\n17.1k7\n7 gold badges\n37\n37 silver badges\n50\n50 bronze badges","comments":["just curious, why do you need to check the length? Does IE fail in that case or something?","Also the checking for number fails to perform like includes. Example: es6 includes returns false for \"abc\".includes(\"ab\", \"1\") this polyfill will return true"]},{"answer":"Another alternative is KMP (Knuth–Morris–Pratt).\n\nThe KMP algorithm searches for a length-m substring in a length-n string in worst-case O(n+m) time, compared to a worst-case of O(n⋅m) for the naive algorithm, so using KMP may be reasonable if you care about worst-case time complexity.\n\nHere's a JavaScript implementation by Project Nayuki, taken from https://www.nayuki.io/res/knuth-morris-pratt-string-matching/kmp-string-matcher.js:\n\n// Searches for the given pattern string in the given text string using the Knuth-Morris-Pratt string matching algorithm.\n// If the pattern is found, this returns the index of the start of the earliest match in 'text'. Otherwise -1 is returned.\n\n\nfunction kmpSearch(pattern, text) {\n  if (pattern.length == 0)\n    return 0; // Immediate match\n\n  // Compute longest suffix-prefix table\n  var lsp = [0]; // Base case\n  for (var i = 1; i < pattern.length; i++) {\n    var j = lsp[i - 1]; // Start by assuming we're extending the previous LSP\n    while (j > 0 && pattern.charAt(i) != pattern.charAt(j))\n      j = lsp[j - 1];\n    if (pattern.charAt(i) == pattern.charAt(j))\n      j++;\n    lsp.push(j);\n  }\n\n  // Walk through text string\n  var j = 0; // Number of chars matched in pattern\n  for (var i = 0; i < text.length; i++) {\n    while (j > 0 && text.charAt(i) != pattern.charAt(j))\n      j = lsp[j - 1]; // Fall back in the pattern\n    if (text.charAt(i) == pattern.charAt(j)) {\n      j++; // Next char matched, increment position\n      if (j == pattern.length)\n        return i - (j - 1);\n    }\n  }\n  return -1; // Not found\n}\n\nconsole.log(kmpSearch('ays', 'haystack') != -1) // true\nconsole.log(kmpSearch('asdf', 'haystack') != -1) // false\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited May 31 '20 at 17:54\ncommunity wiki\n\n\n9 revs, 5 users 50%\nMark Amery","comments":["Not questioning anything on this approach... but why implementing KMP where there's a includes or indexOf on the table. (Although the underneath impl of those maybe using KMP... not sure)","KMP provides linear O(n) performance here.","@wz366 KMP provides O(n), what about the rest? Any Idea?","If this is used for speed, it would likely run faster if you replaced .charAt(i) with [i] to avoid the extra function calls."]}]},{"id":"61212","href":"https://stackoverflow.com/questions/61212/how-to-remove-local-untracked-files-from-the-current-git-working-tree","title":"How to remove local (untracked) files from the current Git working tree","description":"\n                \nHow do you delete untracked local files from your current working tree?\n    ","questionComments":["This interactive git cheat sheet ndpsoftware.com/git-cheatsheet.html shows the git workspace (google gives you better results with \"workspace\" than \"working copy\").","Note: if you only want to remove some untracked files, but not all of them, git clean has now an interactive mode! See my answer to this other question: git 1.8.4+","Note that you're not removing files from git branch, as branch is a reference to a commit and therefore doesn't contain untracked files. Those are only present in the working directory and have nothing to do with branches. That's probably just terminology clarification.","To clarify for the understanding of the uninitiated and those new to Git - run git status and if it shows a file as untracked, and you don't want that file in the repo, you can just go to your filesystem and delete or move it. This will not do anything bad to your local repo or to Git. You can also use git clean or some variation in the answers below, including the interactive version to delete just selective files, but interactive mode can be tedious. Whatever you do, make sure you understand what git clean will delete or use --dry-run to have it tell you without deleting anything.","If the files are not yet being tracked, couldn't you just remove them without git? rm files-to-be-deleted"],"answers":[{"answer":"git-clean - Remove untracked files from the working tree\nSynopsis\ngit clean [-d] [-f] [-i] [-n] [-q] [-e <pattern>] [-x | -X] [--] <path>…​\n\nDescription\n\nCleans the working tree by recursively removing files that are not under version control, starting from the current directory.\n\nNormally, only files unknown to Git are removed, but if the -x option is specified, ignored files are also removed. This can, for example, be useful to remove all build products.\n\nIf any optional <path>... arguments are given, only those paths are affected.\n\nStep 1 is to show what will be deleted by using the -n option:\n\n# Print out the list of files and directories which will be removed (dry run)\ngit clean -n -d\n\n\nClean Step - beware: this will delete files:\n\n# Delete the files from the repository\ngit clean -f\n\nTo remove directories, run git clean -f -d or git clean -fd\nTo remove ignored files, run git clean -f -X or git clean -fX\nTo remove ignored and non-ignored files, run git clean -f -x or git clean -fx\n\nNote the case difference on the X for the two latter commands.\n\nIf clean.requireForce is set to \"true\" (the default) in your configuration, one needs to specify -f otherwise nothing will actually happen.\n\nAgain see the git-clean docs for more information.\n\nOptions\n\n-f, --force\n\nIf the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or -i.\n\n-x\n\nDon’t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in conjunction with git reset) to create a pristine working directory to test a clean build.\n\n-X\n\nRemove only files ignored by Git. This may be useful to rebuild everything from scratch, but keep manually created files.\n\n-n, --dry-run\n\nDon’t actually remove anything, just show what would be done.\n\n-d\n\nRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use -f option twice if you really want to remove such a directory.\n\nShare\nImprove this answer\nFollow\nedited Nov 7 '20 at 10:51\ncommunity wiki\n\n\n24 revs, 22 users 18%\nAshkan Sirous","comments":["git clean -f works only in the directory where it's called (and subdirectories). If you want to clean the whole working copy, you should call it in its root directory.","It is also removing all files inside .gitignore. I need to delete only files/folders which are new and not in .gitignore","@Kostanos If you don't want to remove files that are in .gitignore, then do not provide the -x flag.","git clean -f :/ works as if you had run it in the root repo dir. See also later answers also accounting for submodules with git clean -ffxd :/","@Michelle git clean -xfd WILL also REMOVE ALL FILES CURRENTLY IGNORED IN YOUR .gitignore and they are not recoverable"]},{"answer":"Use git clean -f -d to make sure that directories are also removed.\n\nDon’t actually remove anything, just show what would be done.\n\ngit clean -n\n\n\nor\n\ngit clean --dry-run\n\n\nRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use the -f option twice if you really want to remove such a directory.\n\ngit clean -fd\n\n\nYou can then check if your files are really gone with git status.\n\nShare\nImprove this answer\nFollow\nedited May 29 '20 at 19:20\nGabriel Staples\n13.4k4\n4 gold badges\n84\n84 silver badges\n119\n119 bronze badges\nanswered May 26 '09 at 20:59\nrobert.berger\n11.8k1\n1 gold badge\n14\n14 silver badges\n6\n6 bronze badges","comments":["As previously stated, good to dry-run it with git clean -n -d","Same thing is to do git clean -nd and git clean -fd.","It is better to add the git clean -ffdx too. very clean and short description. thanks a lot."]},{"answer":"I am surprised nobody mentioned this before:\n\ngit clean -i\n\n\nThat stands for interactive and you will get a quick overview of what is going to be deleted offering you the possibility to include/exclude the affected files. Overall, still faster than running the mandatory --dry-run before the real cleaning.\n\nYou will have to toss in a -d if you also want to take care of empty folders. At the end, it makes for a nice alias:\n\ngit iclean\n\n\nThat being said, the extra hand holding of interactive commands can be tiring for experienced users. These days I just use the already mentioned git clean -fd\n\nShare\nImprove this answer\nFollow\nedited Feb 25 '16 at 7:40\nShashank Agrawal\n22.2k9\n9 gold badges\n73\n73 silver badges\n106\n106 bronze badges\nanswered Dec 30 '13 at 20:12\nSystematicFrank\n14.9k5\n5 gold badges\n51\n51 silver badges\n95\n95 bronze badges","comments":["@pal4life It was added in 1.8.4, you might be running an older version of git? github.com/git/git/blob/master/Documentation/RelNotes/1.8.4.txt","I like this – I'm more comfortable having it in my bash history than any of the other options, because it's no big deal if I accidentally ctrl-r or ctrl-p to it.","Could it be that git clean -i works only if called from the root of the working copy?"]},{"answer":"git-clean - Remove untracked files from the working tree\n\nShare\nImprove this answer\nFollow\nedited May 4 '17 at 19:33\nmeagar♦\n213k39\n39 gold badges\n308\n308 silver badges\n317\n317 bronze badges\nanswered Sep 14 '08 at 9:09\nFire Lancer\n27.8k27\n27 gold badges\n109\n109 silver badges\n168\n168 bronze badges","comments":["git clean -f 'untracked file path'"]},{"answer":"Simple Way to remove untracked files\n\nTo remove all untracked files, The simple way is to add all of them first and reset the repo as below\n\ngit add --all\ngit reset --hard HEAD\n\nShare\nImprove this answer\nFollow\nedited Jan 28 '19 at 15:59\nsoniiic\n2,5982\n2 gold badges\n24\n24 silver badges\n36\n36 bronze badges\nanswered Jun 3 '16 at 12:16\nThanga\n6,9253\n3 gold badges\n14\n14 silver badges\n35\n35 bronze badges","comments":["You can replace git add --all by git add .. So you can do it in a shorter way in oneline git add . && git reset --hard HEAD ( be very carefull with this command).","Why use this over git clean?","Because git clean apparently also deletes everything that is ignored. It just deleted my node_modules folder. Doing this would first stage all files except for the ignored ones, and then delete them by doing a reset. Ignored files will not be touched.","@Andreas it doesn't delete ignored files for me (git 2.14.1). You should run git clean -n anyway before doing the real deletion (or use git clean -i).","git clean deletes ignored files only if you use either the -x or -X option, otherwise it just deletes untracked files."]},{"answer":"If untracked directory is a git repository of its own (e.g. submodule), you need to use -f twice:\n\ngit clean -d -f -f\n\nShare\nImprove this answer\nFollow\nanswered Jan 25 '13 at 12:24\nMichał Szajbe\n8,1753\n3 gold badges\n30\n30 silver badges\n37\n37 bronze badges","comments":["BTW, this is written in documentation : Git will refuse to delete directories with .git sub directory or file unless a second -f is given. But thanks anyway!","Thank you tons. This was driving me nuts."]},{"answer":"I like git stash push -u because you can undo them all with git stash pop.\n\nEDIT: Also I found a way to show untracked file in a stash (e.g. git show stash@{0}^3) https://stackoverflow.com/a/12681856/338986\n\nEDIT2: git stash save is deprecated in favor of push. Thanks @script-wolf.\n\nShare\nImprove this answer\nFollow\nedited Oct 25 '18 at 0:03\nanswered Jan 11 '14 at 0:41\nhiroshi\n6,1433\n3 gold badges\n40\n40 silver badges\n57\n57 bronze badges","comments":["Can you explain the -u on the stash? I do not follow how that works differently from git stash save. I tried this and it worked. Looked on git docs and could not find it there either.","-u is equivalent to --include-untracked. You can find a help with git help stash.","@hiroshi Thanks! after trying every darn solution from a dozen different people this is the one that finally worked...whew ! Even a git stash did nada. The save - u took care of untracked. reset hard /clean force/etc none of these did anything for me.","The save option was deprecated in favor of push, which does the same but more. You can read more here, https://stackoverflow.com/questions/44680028/whats-the-difference-between-git-stash-save-and-git-stash-push/44681952"]},{"answer":"This is what I always use:\n\ngit clean -fdx\n\n\nFor a very large project you might want to run it a couple of times.\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '15 at 20:47\nanswered Nov 25 '13 at 14:16\nOscar Fraxedas\n3,8592\n2 gold badges\n24\n24 silver badges\n29\n29 bronze badges","comments":["@Martin One of the projects I'm working on is +8 years old with +80 developers actively coding. Git sometimes fails to clean it on the first pass.","I can confirm this, so this is still valid in 2020. We are also working on a large project and I had to run it 4-5 times until GIT did not find any more files to be deleted."]},{"answer":"git-clean is what you are looking for. It is used to remove untracked files from the working tree.\n\nShare\nImprove this answer\nFollow\nedited Oct 29 '13 at 5:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 14 '08 at 9:08\nEspo\n39.7k20\n20 gold badges\n128\n128 silver badges\n156\n156 bronze badges","comments":[]},{"answer":"If needed to remove untracked files from particular subdirectory,\n\ngit clean -f {dir_path}\n\n\nAnd combined way to delete untracked dir/files and ignored files.\n\ngit clean -fxd {dir_path}\n\n\nafter this you will have modified files only in git status.\n\nShare\nImprove this answer\nFollow\nanswered Sep 24 '13 at 6:28\nVijay C\n4,4991\n1 gold badge\n39\n39 silver badges\n46\n46 bronze badges","comments":[]},{"answer":"Remove all extra folders and files in this repo + submodules\n\nThis gets you in same state as fresh clone.\n\ngit clean -ffdx\n\n\nRemove all extra folders and files in this repo but not its submodules\n\ngit clean -fdx\n\n\nRemove extra folders but not files (ex. build or logs folder)\n\ngit clean -fd\n\n\nRemove extra folders + ignored files (but not newly added files)\n\nIf file wasn't ignored and not yet checked-in then it stays. Note the capital X.\n\ngit clean -fdX\n\n\nNew interactive mode\n\ngit clean\n\nShare\nImprove this answer\nFollow\nedited Nov 18 '19 at 0:00\nanswered Feb 12 '17 at 8:33\nShital Shah\n49.5k10\n10 gold badges\n196\n196 silver badges\n162\n162 bronze badges","comments":["This answer works great! You can always add --dry-run option to list the files/folders to remove before commit the action"]},{"answer":"OK, deleting unwanted untracked files and folders are easy using git in command line, just do it like this:\n\ngit clean -fd\n\n\nDouble check before doing it as it will delete the files and folders without making any history...\n\nAlso in this case, -f stands for force and -d stands for directory...\n\nSo, if you want to delete files only, you can use -f only:\n\ngit clean -f\n\n\nIf you want to delete(directories) and files, you can delete only untracked directories and files like this:\n\ngit clean -fd\n\n\nAlso, you can use -x flag for including the files which are ignored by git. This would be helpful if you want to delete everything.\n\nAnd adding -i flag, makes git asking you for permission for deleting files one by one on the go.\n\nIf you not sure and want to check things first, add -n flag.\n\nUse -q if you don't want to see any report after successful deletion.\n\nI also create the image below to make it more memorable, especially I have seen many people confuse -f for cleaning folder sometimes or mix it up somehow!\n\n\n\n\nShare\nImprove this answer\nFollow\nedited Nov 17 '19 at 11:51\nanswered Jul 20 '17 at 16:42\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":["What's with that image?","+ for easy to memorize graphic :D"]},{"answer":"git clean -fd removes directory\n\ngit clean -fX removes ignored files\n\ngit clean -fx removes ignored and un-ignored files\n\ncan be used all above options in combination as\n\ngit clean -fdXx\n\ncheck git manual for more help\n\nShare\nImprove this answer\nFollow\nedited Mar 28 '16 at 7:56\nanswered Jan 22 '15 at 6:33\nPooja\n1,16413\n13 silver badges\n17\n17 bronze badges","comments":["The command git clean -fdXx produces the error message \"fatal: -x and -X cannot be used together\" (using git-2.8). For your last sentence within your answer, please provide a link to git manual. Cheers","run the two commands in sequence: git clean -fdX, git clean -fdx"]},{"answer":"A better way is to use: git clean\n\ngit clean -d -x -f\n\n\nThis removes untracked files, including directories (-d) and files ignored by git (-x).\n\nAlso, replace the -f argument with -n to perform a dry-run or -i for interactive mode and it will tell you what will be removed.\n\nShare\nImprove this answer\nFollow\nedited Apr 22 '15 at 10:48\nPiyush\n3,7577\n7 gold badges\n32\n32 silver badges\n64\n64 bronze badges\nanswered Apr 16 '15 at 6:49\nChhabilal\n1,04611\n11 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"User interactive approach:\n\ngit clean -i -fd\n\nRemove .classpath [y/N]? N\nRemove .gitignore [y/N]? N\nRemove .project [y/N]? N\nRemove .settings/ [y/N]? N\nRemove src/com/arsdumpgenerator/inspector/ [y/N]? y\nRemove src/com/arsdumpgenerator/manifest/ [y/N]? y\nRemove src/com/arsdumpgenerator/s3/ [y/N]? y\nRemove tst/com/arsdumpgenerator/manifest/ [y/N]? y\nRemove tst/com/arsdumpgenerator/s3/ [y/N]? y\n\n\n-i for interactive\n-f for force\n-d for directory\n-x for ignored files(add if required)\n\nNote: Add -n or --dry-run to just check what it will do.\n\nShare\nImprove this answer\nFollow\nedited Jul 7 '17 at 4:35\nanswered Mar 2 '17 at 20:09\nbit_cracker007\n1,7131\n1 gold badge\n21\n21 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"A lifehack for such situation I just invented and tried (that works perfectly):\n\ngit add .\ngit reset --hard HEAD\n\n\nBeware! Be sure to commit any needed changes (even in non-untracked files) before performing this.\n\nShare\nImprove this answer\nFollow\nedited Feb 21 '16 at 17:36\nanswered Feb 21 '16 at 17:29\nthybzi\n1,12311\n11 silver badges\n15\n15 bronze badges","comments":["At least this is a different approach. :) Another way, that would remember the deleted files in the reflog but not in any branches, would be: git add . git commit -m 'about to delete' git reset --hard HEAD~","even more quick way is git add . && git reset --hard HEAD","git add . && git reset --hard","This might not be what you want if there are also changes you do wish to commit.","@AlexanderMills git reset --hard resets all uncommited changes BUT UNTRACKED FILES to the state of the latest commit. That is why we first need git add . -- that stages all untracked files (so they are reset, too)"]},{"answer":"For me only following worked:\n\ngit clean -ffdx\n\n\nIn all other cases, I was getting message \"Skipping Directory\" for some subdirectories.\n\nShare\nImprove this answer\nFollow\nanswered Aug 16 '16 at 15:29\nrahul286\n9392\n2 gold badges\n9\n9 silver badges\n27\n27 bronze badges","comments":["Thanks. I left out the -x and just used git clean -ffd to avoid erasing files in the .gitignore."]},{"answer":"git clean -f -d -x $(git rev-parse --show-cdup) applies clean to the root directory, no matter where you call it within a repository directory tree. I use it all the time as it does not force you to leave the folder where you working now and allows to clean & commit right from the place where you are.\n\nBe sure that flags -f, -d, -x match your needs:\n\n-d\n       Remove untracked directories in addition to untracked files. If an\n       untracked directory is managed by a different Git repository, it is\n       not removed by default. Use -f option twice if you really want to\n       remove such a directory.\n\n-f, --force\n       If the Git configuration variable clean.requireForce is not set to\n       false, git clean will refuse to delete files or directories unless\n       given -f, -n or -i. Git will refuse to delete directories with .git\n       sub directory or file unless a second -f is given. This affects\n       also git submodules where the storage area of the removed submodule\n       under .git/modules/ is not removed until -f is given twice.\n\n-x\n       Don't use the standard ignore rules read from .gitignore (per\n       directory) and $GIT_DIR/info/exclude, but do still use the ignore\n       rules given with -e options. This allows removing all untracked\n       files, including build products. This can be used (possibly in\n       conjunction with git reset) to create a pristine working directory\n       to test a clean build.\n\n\nThere are other flags as well available, just check git clean --help.\n\nShare\nImprove this answer\nFollow\nanswered Dec 2 '15 at 17:57\nNikita Leonov\n5,65428\n28 silver badges\n37\n37 bronze badges","comments":["BTW you can just do git clean {flags} :/ so it will be as if you ran the command in the repo root"]},{"answer":"To remove Untracked files :\n\ngit add .\ngit reset --hard HEAD\n\nShare\nImprove this answer\nFollow\nanswered May 20 '20 at 16:05\nRajeev Shetty\n8611\n1 gold badge\n10\n10 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"If you just want to delete the files listed as untracked by 'git status'\n\ngit stash save -u\ngit stash drop \"stash@{0}\"\n\n\nI prefer this to 'git clean' because 'git clean' will delete files ignored by git, so your next build will have to rebuild everything and you may lose your IDE settings too.\n\nShare\nImprove this answer\nFollow\nanswered Mar 2 '16 at 2:09\nJD Brennan\n8221\n1 gold badge\n10\n10 silver badges\n19\n19 bronze badges","comments":["This will also remove valid changes to tracked files. I wouldn't recommend it.","Yeah, you'd want to commit changes to tracked files first."]},{"answer":"To know what will be deleted before actually deleting:\n\ngit clean -d -n\n\nIt will output something like:\n\nWould remove sample.txt\n\nTo delete everything listed in the output of the previous command:\n\ngit clean -d -f\n\nIt will output something like:\n\nRemoving sample.txt\n\nShare\nImprove this answer\nFollow\nanswered Feb 16 '16 at 8:42\nOmar Mowafi\n8545\n5 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"Be careful while running `git clean` command.\n\nAlways use -n before running the actual command as it will show you what files would get removed.\n\ngit clean -n -d \ngit clean -f -d\n\n\nBy default, git clean will only remove untracked files that are not ignored. Any file that matches a pattern in your .gitignore or other ignore files will not be removed. If you want to remove those files too, you can add a -x to the clean command.\n\ngit clean -f -d -x\n\n\nThere is also interactive mode available -i with the clean command\n\ngit clean -x -i\n\nAlternatively\nIf you are not 100% sure that deleting your uncommitted work is safe, you could use stashing instead\ngit stash --all\n\n\nIt will also clear your directory but give you flexibility to retrieve the files at any point in time using stash with apply or pop. Then if you are fine with removing your stashed files you could run:\n\ngit stash drop // or clean\n\n\nTo see full instruction on how to work with stash see this How to name and retrieve a stash by name in git?\n\nShare\nImprove this answer\nFollow\nedited Jul 28 at 16:00\nanswered Oct 21 '17 at 21:44\nDevWL\n12.5k5\n5 gold badges\n76\n76 silver badges\n71\n71 bronze badges","comments":["the stash is a good idea, however you might wanna use git stash save and type some comment as to what this stash was for"]},{"answer":"To remove the untracked files you should first use command to view the files that will be affected by cleaning\n\ngit clean -fdn\n\n\nThis will show you the list of files that will be deleted. Now to actually delete those files use this command:\n\ngit clean -fd\n\nShare\nImprove this answer\nFollow\nanswered Oct 25 '16 at 9:09\nGaurav\n5995\n5 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"uggested Command for Removing Untracked Files from git docs is git clean\n\ngit clean - Remove untracked files from the working tree\n\nSuggested Method: Interative Mode by using git clean -i so we can have control over it. let see remaining available options.\n\nAvailable Options:\n\ngit clean \n    -d -f -i -n -q -e -x -X (can use either)\n\n\nExplanation:\n\n1. -d\n\nRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use -f option twice if you really want to remove such a directory.\n\n2. -f, --force\n\nIf the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or -i.\n\n3. -i, --interactive\n\nShow what would be done and clean files interactively. See “Interactive mode” for details.\n\n4. -n, --dry-run\n\nDon’t actually remove anything, just show what would be done.\n\n5. -q, --quiet\n\nBe quiet, only report errors, but not the files that are successfully removed.\n\n6. -e , --exclude=\n\nIn addition to those found in .gitignore (per directory) and $GIT_DIR/info/exclude, also consider these patterns to be in the set of the ignore rules in effect.\n\n7. -x\n\nDon’t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in conjunction with git reset) to create a pristine working directory to test a clean build.\n\n8. -X\n\nRemove only files ignored by Git. This may be useful to rebuild everything from scratch, but keep manually created files.\n\nShare\nImprove this answer\nFollow\nanswered Sep 1 '17 at 6:23\nMohideen bin Mohammed\n14.9k7\n7 gold badges\n87\n87 silver badges\n101\n101 bronze badges","comments":["I think you have a typo uggested but that's just a \"uggestion lol"]},{"answer":"Normal git clean command doesn't remove untracked files with my git version 2.9.0.windows.1.\n\n$ git clean -fdx     # doesn't remove untracked files\n$ git clean -fdx *   # Append star then it works!\n\nShare\nImprove this answer\nFollow\nanswered Oct 11 '16 at 0:14\nkujiy\n4,5041\n1 gold badge\n25\n25 silver badges\n31\n31 bronze badges","comments":[]},{"answer":"git clean -f to remove untracked files from working directory.\n\nI have covered some basics here in my blog, git-intro-basic-commands\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '17 at 7:06\nanswered Feb 16 '17 at 9:05\nVaisakh VM\n96310\n10 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"We can easily removed local untracked files from the current git working tree by using below git comments.\n\ngit reset [--soft | --mixed [-N] | --hard | --merge | --keep] [-q] [<commit>]\n\n\nExample:\n\ngit reset --hard HEAD\n\n\nLinks :\n\nhttps://git-scm.com/docs/git-reset\nHow do I use 'git reset --hard HEAD' to revert to a previous commit?\nReset local repository branch to be just like remote repository HEAD\nhttps://jwiegley.github.io/git-from-the-bottom-up/3-Reset/4-doing-a-hard-reset.html\nShare\nImprove this answer\nFollow\nanswered Dec 4 '17 at 6:30\nElangovan\n3,2034\n4 gold badges\n29\n29 silver badges\n37\n37 bronze badges","comments":["This will also remove changes staged for commit, not only untracked files, which may not be what you want.","Doesn't work: leaves some files. git clean -ffdx is the solution"]},{"answer":"Clean out git repository and all submodules recursively\n\nThe following command will clean out the current git repository and all its submodules recursively:\n\n(git clean -d -x -f && git submodule foreach --recursive git clean -d -x -f)\n\nShare\nImprove this answer\nFollow\nedited Apr 19 '18 at 6:46\nanswered Sep 25 '17 at 16:25\nSergey\n1,44419\n19 silver badges\n16\n16 bronze badges","comments":["surely this should be used with great caution"]},{"answer":"git clean -f\n\n\nwill remove the untracked files from the current git\n\ngit clean -fd\n\n\nwhen you want to remove directories and files, this will delete only untracked directories and files\n\nShare\nImprove this answer\nFollow\nanswered May 18 '18 at 6:04\nSudhir Vishwakarma\n6299\n9 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"git add --all, git stash and git stash drop, try these three commands in this order inorder to remove all untracked files. By adding all those untracked files to git and stashing them will move all those untracked files to stash list and dropping out top one i.e., stash@{0} will remove the stashed changes from stash list.\n\nShare\nImprove this answer\nFollow\nanswered Apr 14 at 20:18\njenny\n3904\n4 silver badges\n17\n17 bronze badges","comments":[]}]},{"id":"336859","href":"https://stackoverflow.com/questions/336859/var-functionname-function-vs-function-functionname","title":"var functionName = function() {} vs function functionName() {}","description":"\n                \nI've recently started maintaining someone else's JavaScript code. I'm fixing bugs, adding features and also trying to tidy up the code and make it more consistent.\n\nThe previous developer used two ways of declaring functions and I can't work out if there is a reason behind it or not.\n\nThe two ways are:\n\nvar functionOne = function() {\n    // Some code\n};\n\n\n\n\nfunction functionTwo() {\n    // Some code\n}\n\n\nWhat are the reasons for using these two different methods and what are the pros and cons of each? Is there anything that can be done with one method that can't be done with the other?\n    ","questionComments":[],"answers":[{"answer":"The difference is that functionOne is a function expression and so only defined when that line is reached, whereas functionTwo is a function declaration and is defined as soon as its surrounding function or script is executed (due to hoisting).\n\nFor example, a function expression:\n\n// TypeError: functionOne is not a function\nfunctionOne();\n\nvar functionOne = function() {\n  console.log(\"Hello!\");\n};\n Run code snippetExpand snippet\n\nAnd, a function declaration:\n\n// Outputs: \"Hello!\"\nfunctionTwo();\n\nfunction functionTwo() {\n  console.log(\"Hello!\");\n}\n Run code snippetExpand snippet\n\nHistorically, function declarations defined within blocks were handled inconsistently between browsers. Strict mode (introduced in ES5) resolved this by scoping function declarations to their enclosing block.\n\n'use strict';    \n{ // note this block!\n  function functionThree() {\n    console.log(\"Hello!\");\n  }\n}\nfunctionThree(); // ReferenceError\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Apr 23 '20 at 15:33\nBen Aston\n46.7k56\n56 gold badges\n181\n181 silver badges\n306\n306 bronze badges\nanswered Dec 3 '08 at 11:37\nGreg\n299k52\n52 gold badges\n359\n359 silver badges\n327\n327 bronze badges","comments":["Function definitions are executed when code enters the surrounding block, rather than when it enters the enclosing function. I don't know if things always worked that way, but it would be unavoidable if a block used let or const to define a variable that was closed over by a function within it, and applying that rule consistently is probably better than applying it only when unavoidable.","The sentence \"due to hoisting\" might give a wrong impression that only the named function gets hoisted. In fact, both var functionOne as well as function functionTwo get hoisted to some degree - it's just that functionOne is set to undefined (you could call it half-hoisting, variables always get hoisted only to that degree) whereas function functionTwo is fully hoisted in that it's defined and declared. Invoking something that's undefined will of course then throw a typeError.","Thanks Greg and @Ben_Aston for explaining the difference. But could one of you also give some light on the 'pros' and 'cons' as the user asks?"]},{"answer":"First I want to correct Greg: function abc(){} is scoped too — the name abc is defined in the scope where this definition is encountered. Example:\n\nfunction xyz(){\n  function abc(){};\n  // abc is defined here...\n}\n// ...but not here\n\n\nSecondly, it is possible to combine both styles:\n\nvar xyz = function abc(){};\n\n\nxyz is going to be defined as usual, abc is undefined in all browsers but Internet Explorer — do not rely on it being defined. But it will be defined inside its body:\n\nvar xyz = function abc(){\n  // xyz is visible here\n  // abc is visible here\n}\n// xyz is visible here\n// abc is undefined here\n\n\nIf you want to alias functions on all browsers, use this kind of declaration:\n\nfunction abc(){};\nvar xyz = abc;\n\n\nIn this case, both xyz and abc are aliases of the same object:\n\nconsole.log(xyz === abc); // prints \"true\"\n\n\nOne compelling reason to use the combined style is the \"name\" attribute of function objects (not supported by Internet Explorer). Basically when you define a function like\n\nfunction abc(){};\nconsole.log(abc.name); // prints \"abc\"\n\n\nits name is automatically assigned. But when you define it like\n\nvar abc = function(){};\nconsole.log(abc.name); // prints \"\"\n\n\nits name is empty — we created an anonymous function and assigned it to some variable.\n\nAnother good reason to use the combined style is to use a short internal name to refer to itself, while providing a long non-conflicting name for external users:\n\n// Assume really.long.external.scoped is {}\nreally.long.external.scoped.name = function shortcut(n){\n  // Let it call itself recursively:\n  shortcut(n - 1);\n  // ...\n  // Let it pass itself as a callback:\n  someFunction(shortcut);\n  // ...\n}\n\n\nIn the example above we can do the same with an external name, but it'll be too unwieldy (and slower).\n\n(Another way to refer to itself is to use arguments.callee, which is still relatively long, and not supported in the strict mode.)\n\nDeep down, JavaScript treats both statements differently. This is a function declaration:\n\nfunction abc(){}\n\n\nabc here is defined everywhere in the current scope:\n\n// We can call it here\nabc(); // Works\n\n// Yet, it is defined down there.\nfunction abc(){}\n\n// We can call it again\nabc(); // Works\n\n\nAlso, it hoisted through a return statement:\n\n// We can call it here\nabc(); // Works\nreturn;\nfunction abc(){}\n\n\nThis is a function expression:\n\nvar xyz = function(){};\n\n\nxyz here is defined from the point of assignment:\n\n// We can't call it here\nxyz(); // UNDEFINED!!!\n\n// Now it is defined\nxyz = function(){}\n\n// We can call it here\nxyz(); // works\n\n\nFunction declaration vs. function expression is the real reason why there is a difference demonstrated by Greg.\n\nFun fact:\n\nvar xyz = function abc(){};\nconsole.log(xyz.name); // Prints \"abc\"\n\n\nPersonally, I prefer the \"function expression\" declaration because this way I can control the visibility. When I define the function like\n\nvar abc = function(){};\n\n\nI know that I defined the function locally. When I define the function like\n\nabc = function(){};\n\n\nI know that I defined it globally providing that I didn't define abc anywhere in the chain of scopes. This style of definition is resilient even when used inside eval(). While the definition\n\nfunction abc(){};\n\n\ndepends on the context and may leave you guessing where it is actually defined, especially in the case of eval() — the answer is: It depends on the browser.\n\nShare\nImprove this answer\nFollow\nedited Oct 10 '16 at 20:38\nMerlin\n4,6922\n2 gold badges\n27\n27 silver badges\n47\n47 bronze badges\nanswered Dec 3 '08 at 17:43\nEugene Lazutkin\n42.4k8\n8 gold badges\n47\n47 silver badges\n56\n56 bronze badges","comments":["var abc = function(){}; console.log(abc.name); // \"abc\" // from 2021","Apparently, the JS runtime became smarter. Yet wrap it up and: var abc = (() => function(){})(); console.log(abc.name); // nothing"]},{"answer":"Here's the rundown on the standard forms that create functions: (Originally written for another question, but adapted after being moved into the canonical question.)\n\nTerms:\n\nES5: ECMAScript 5th edition, 2009\nES2015: ECMAScript 2015 (also known as \"ES6\")\n\nThe quick list:\n\nFunction Declaration\n\n\"Anonymous\" function Expression (which despite the term, sometimes create functions with names)\n\nNamed function Expression\n\nAccessor Function Initializer (ES5+)\n\nArrow Function Expression (ES2015+) (which, like anonymous function expressions, don't involve an explicit name, and yet can create functions with names)\n\nMethod Declaration in Object Initializer (ES2015+)\n\nConstructor and Method Declarations in class (ES2015+)\n\nFunction Declaration\n\nThe first form is a function declaration, which looks like this:\n\nfunction x() {\n    console.log('x');\n}\n\n\nA function declaration is a declaration; it's not a statement or expression. As such, you don't follow it with a ; (although doing so is harmless).\n\nA function declaration is processed when execution enters the context in which it appears, before any step-by-step code is executed. The function it creates is given a proper name (x in the example above), and that name is put in the scope in which the declaration appears.\n\nBecause it's processed before any step-by-step code in the same context, you can do things like this:\n\nx(); // Works even though it's above the declaration\nfunction x() {\n    console.log('x');\n}\n\n\nUntil ES2015, the spec didn't cover what a JavaScript engine should do if you put a function declaration inside a control structure like try, if, switch, while, etc., like this:\n\nif (someCondition) {\n    function foo() {    // <===== HERE THERE\n    }                   // <===== BE DRAGONS\n}\n\n\nAnd since they're processed before step-by-step code is run, it's tricky to know what to do when they're in a control structure.\n\nAlthough doing this wasn't specified until ES2015, it was an allowable extension to support function declarations in blocks. Unfortunately (and inevitably), different engines did different things.\n\nAs of ES2015, the specification says what to do. In fact, it gives three separate things to do:\n\nIf in loose mode not on a web browser, the JavaScript engine is supposed to do one thing\nIf in loose mode on a web browser, the JavaScript engine is supposed to do something else\nIf in strict mode (browser or not), the JavaScript engine is supposed to do yet another thing\n\nThe rules for the loose modes are tricky, but in strict mode, function declarations in blocks are easy: They're local to the block (they have block scope, which is also new in ES2015), and they're hoisted to the top of the block. So:\n\n\"use strict\";\nif (someCondition) {\n    foo();               // Works just fine\n    function foo() {\n    }\n}\nconsole.log(typeof foo); // \"undefined\" (`foo` is not in scope here\n                         // because it's not in the same block)\n\n\"Anonymous\" function Expression\n\nThe second common form is called an anonymous function expression:\n\nvar y = function () {\n    console.log('y');\n};\n\n\nLike all expressions, it's evaluated when it's reached in the step-by-step execution of the code.\n\nIn ES5, the function this creates has no name (it's anonymous). In ES2015, the function is assigned a name if possible by inferring it from context. In the example above, the name would be y. Something similar is done when the function is the value of a property initializer. (For details on when this happens and the rules, search for SetFunctionName in the the specification — it appears all over the place.)\n\nNamed function Expression\n\nThe third form is a named function expression (\"NFE\"):\n\nvar z = function w() {\n    console.log('zw')\n};\n\n\nThe function this creates has a proper name (w in this case). Like all expressions, this is evaluated when it's reached in the step-by-step execution of the code. The name of the function is not added to the scope in which the expression appears; the name is in scope within the function itself:\n\nvar z = function w() {\n    console.log(typeof w); // \"function\"\n};\nconsole.log(typeof w);     // \"undefined\"\n\n\nNote that NFEs have frequently been a source of bugs for JavaScript implementations. IE8 and earlier, for instance, handle NFEs completely incorrectly, creating two different functions at two different times. Early versions of Safari had issues as well. The good news is that current versions of browsers (IE9 and up, current Safari) don't have those issues any more. (But as of this writing, sadly, IE8 remains in widespread use, and so using NFEs with code for the web in general is still problematic.)\n\nAccessor Function Initializer (ES5+)\n\nSometimes functions can sneak in largely unnoticed; that's the case with accessor functions. Here's an example:\n\nvar obj = {\n    value: 0,\n    get f() {\n        return this.value;\n    },\n    set f(v) {\n        this.value = v;\n    }\n};\nconsole.log(obj.f);         // 0\nconsole.log(typeof obj.f);  // \"number\"\n\n\nNote that when I used the function, I didn't use ()! That's because it's an accessor function for a property. We get and set the property in the normal way, but behind the scenes, the function is called.\n\nYou can also create accessor functions with Object.defineProperty, Object.defineProperties, and the lesser-known second argument to Object.create.\n\nArrow Function Expression (ES2015+)\n\nES2015 brings us the arrow function. Here's one example:\n\nvar a = [1, 2, 3];\nvar b = a.map(n => n * 2);\nconsole.log(b.join(\", \")); // 2, 4, 6\n\n\nSee that n => n * 2 thing hiding in the map() call? That's a function.\n\nA couple of things about arrow functions:\n\nThey don't have their own this. Instead, they close over the this of the context where they're defined. (They also close over arguments and, where relevant, super.) This means that the this within them is the same as the this where they're created, and cannot be changed.\n\nAs you'll have noticed with the above, you don't use the keyword function; instead, you use =>.\n\nThe n => n * 2 example above is one form of them. If you have multiple arguments to pass the function, you use parens:\n\nvar a = [1, 2, 3];\nvar b = a.map((n, i) => n * i);\nconsole.log(b.join(\", \")); // 0, 2, 6\n\n\n(Remember that Array#map passes the entry as the first argument, and the index as the second.)\n\nIn both cases, the body of the function is just an expression; the function's return value will automatically be the result of that expression (you don't use an explicit return).\n\nIf you're doing more than just a single expression, use {} and an explicit return (if you need to return a value), as normal:\n\nvar a = [\n  {first: \"Joe\", last: \"Bloggs\"},\n  {first: \"Albert\", last: \"Bloggs\"},\n  {first: \"Mary\", last: \"Albright\"}\n];\na = a.sort((a, b) => {\n  var rv = a.last.localeCompare(b.last);\n  if (rv === 0) {\n    rv = a.first.localeCompare(b.first);\n  }\n  return rv;\n});\nconsole.log(JSON.stringify(a));\n\n\nThe version without { ... } is called an arrow function with an expression body or concise body. (Also: A concise arrow function.) The one with { ... } defining the body is an arrow function with a function body. (Also: A verbose arrow function.)\n\nMethod Declaration in Object Initializer (ES2015+)\n\nES2015 allows a shorter form of declaring a property that references a function called a method definition; it looks like this:\n\nvar o = {\n    foo() {\n    }\n};\n\n\nthe almost-equivalent in ES5 and earlier would be:\n\nvar o = {\n    foo: function foo() {\n    }\n};\n\n\nthe difference (other than verbosity) is that a method can use super, but a function cannot. So for instance, if you had an object that defined (say) valueOf using method syntax, it could use super.valueOf() to get the value Object.prototype.valueOf would have returned (before presumably doing something else with it), whereas the ES5 version would have to do Object.prototype.valueOf.call(this) instead.\n\nThat also means that the method has a reference to the object it was defined on, so if that object is temporary (for instance, you're passing it into Object.assign as one of the source objects), method syntax could mean that the object is retained in memory when otherwise it could have been garbage collected (if the JavaScript engine doesn't detect that situation and handle it if none of the methods uses super).\n\nConstructor and Method Declarations in class (ES2015+)\n\nES2015 brings us class syntax, including declared constructors and methods:\n\nclass Person {\n    constructor(firstName, lastName) {\n        this.firstName = firstName;\n        this.lastName = lastName;\n    }\n\n    getFullName() {\n        return this.firstName + \" \" + this.lastName;\n    }\n}\n\n\nThere are two function declarations above: One for the constructor, which gets the name Person, and one for getFullName, which is a function assigned to Person.prototype.\n\nShare\nImprove this answer\nFollow\nedited Jan 11 '19 at 13:58\nanswered Mar 4 '14 at 13:35\nT.J. Crowder\n897k166\n166 gold badges\n1650\n1650 silver badges\n1666\n1666 bronze badges","comments":[]},{"answer":"Speaking about the global context, both, the var statement and a FunctionDeclaration at the end will create a non-deleteable property on the global object, but the value of both can be overwritten.\n\nThe subtle difference between the two ways is that when the Variable Instantiation process runs (before the actual code execution) all identifiers declared with var will be initialized with undefined, and the ones used by the FunctionDeclaration's will be available since that moment, for example:\n\n alert(typeof foo); // 'function', it's already available\n alert(typeof bar); // 'undefined'\n function foo () {}\n var bar = function () {};\n alert(typeof bar); // 'function'\n\n\nThe assignment of the bar FunctionExpression takes place until runtime.\n\nA global property created by a FunctionDeclaration can be overwritten without any problems just like a variable value, e.g.:\n\n function test () {}\n test = null;\n\n\nAnother obvious difference between your two examples is that the first function doesn't have a name, but the second has it, which can be really useful when debugging (i.e. inspecting a call stack).\n\nAbout your edited first example (foo = function() { alert('hello!'); };), it is an undeclared assignment, I would highly encourage you to always use the var keyword.\n\nWith an assignment, without the var statement, if the referenced identifier is not found in the scope chain, it will become a deleteable property of the global object.\n\nAlso, undeclared assignments throw a ReferenceError on ECMAScript 5 under Strict Mode.\n\nA must read:\n\nNamed function expressions demystified\n\nNote: This answer has been merged from another question, in which the major doubt and misconception from the OP was that identifiers declared with a FunctionDeclaration, couldn't be overwritten which is not the case.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:10\nCommunity♦\n11\n1 silver badge\nanswered Aug 8 '10 at 19:32\nChristian C. Salvadó\n735k174\n174 gold badges\n900\n900 silver badges\n828\n828 bronze badges","comments":[]},{"answer":"The two code snippets you've posted there will, for almost all purposes, behave the same way.\n\nHowever, the difference in behaviour is that with the first variant (var functionOne = function() {}), that function can only be called after that point in the code.\n\nWith the second variant (function functionTwo()), the function is available to code that runs above where the function is declared.\n\nThis is because with the first variant, the function is assigned to the variable foo at run time. In the second, the function is assigned to that identifier, foo, at parse time.\n\nMore technical information\n\nJavaScript has three ways of defining functions.\n\nYour first snippet shows a function expression. This involves using the \"function\" operator to create a function - the result of that operator can be stored in any variable or object property. The function expression is powerful that way. The function expression is often called an \"anonymous function\", because it does not have to have a name,\nYour second example is a function declaration. This uses the \"function\" statement to create a function. The function is made available at parse time and can be called anywhere in that scope. You can still store it in a variable or object property later.\nThe third way of defining a function is the \"Function()\" constructor, which is not shown in your original post. It's not recommended to use this as it works the same way as eval(), which has its problems.\nShare\nImprove this answer\nFollow\nedited Dec 28 '15 at 19:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 20 '10 at 4:54\nthomasrutter\n106k25\n25 gold badges\n138\n138 silver badges\n161\n161 bronze badges","comments":[]},{"answer":"A better explanation to Greg's answer\n\nfunctionTwo();\nfunction functionTwo() {\n}\n\n\nWhy no error? We were always taught that expressions are executed from top to bottom(??)\n\nBecause:\n\nFunction declarations and variable declarations are always moved (hoisted) invisibly to the top of their containing scope by the JavaScript interpreter. Function parameters and language-defined names are, obviously, already there. ben cherry\n\nThis means that code like this:\n\nfunctionOne();                  ---------------      var functionOne;\n                                | is actually |      functionOne();\nvar functionOne = function(){   | interpreted |-->\n};                              |    like     |      functionOne = function(){\n                                ---------------      };\n\n\nNotice that the assignment portion of the declarations were not hoisted. Only the name is hoisted.\n\nBut in the case with function declarations, the entire function body will be hoisted as well:\n\nfunctionTwo();              ---------------      function functionTwo() {\n                            | is actually |      };\nfunction functionTwo() {    | interpreted |-->\n}                           |    like     |      functionTwo();\n                            ---------------\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Aug 9 '14 at 2:45\nsuhailvs\n15.5k8\n8 gold badges\n84\n84 silver badges\n93\n93 bronze badges","comments":[]},{"answer":"Other commenters have already covered the semantic difference of the two variants above. I wanted to note a stylistic difference: Only the \"assignment\" variation can set a property of another object.\n\nI often build JavaScript modules with a pattern like this:\n\n(function(){\n    var exports = {};\n\n    function privateUtil() {\n            ...\n    }\n\n    exports.publicUtil = function() {\n            ...\n    };\n\n    return exports;\n})();\n\n\nWith this pattern, your public functions will all use assignment, while your private functions use declaration.\n\n(Note also that assignment should require a semicolon after the statement, while declaration prohibits it.)\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 22:24\nElrond_EGLDer\n48.5k25\n25 gold badges\n192\n192 silver badges\n180\n180 bronze badges\nanswered Mar 3 '11 at 19:19\nSean McMillan\n9,7355\n5 gold badges\n53\n53 silver badges\n62\n62 bronze badges","comments":[]},{"answer":"An illustration of when to prefer the first method to the second one is when you need to avoid overriding a function's previous definitions.\n\nWith\n\nif (condition){\n    function myfunction(){\n        // Some code\n    }\n}\n\n\n, this definition of myfunction will override any previous definition, since it will be done at parse-time.\n\nWhile\n\nif (condition){\n    var myfunction = function (){\n        // Some code\n    }\n}\n\n\ndoes the correct job of defining myfunction only when condition is met.\n\nShare\nImprove this answer\nFollow\nedited Jun 29 '17 at 14:08\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges\nanswered Mar 29 '13 at 13:26\nMbengue Assane\n2,7151\n1 gold badge\n15\n15 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"An important reason is to add one and only one variable as the \"Root\" of your namespace...\n\nvar MyNamespace = {}\nMyNamespace.foo= function() {\n\n}\n\n\nor\n\nvar MyNamespace = {\n  foo: function() {\n  },\n  ...\n}\n\n\nThere are many techniques for namespacing. It's become more important with the plethora of JavaScript modules available.\n\nAlso see How do I declare a namespace in JavaScript?\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:55\nCommunity♦\n11\n1 silver badge\nanswered Aug 8 '10 at 19:44\nRob\n5,3151\n1 gold badge\n22\n22 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"Hoisting is the JavaScript interpreter’s action of moving all variable and function declarations to the top of the current scope.\n\nHowever, only the actual declarations are hoisted. by leaving assignments where they are.\n\nvariable's/Function's declared inside the page are global can access anywhere in that page.\nvariable's/Functions declared inside the function are having local scope. means they are available/accessed inside the function body (scope), they are not available outside the function body.\n\nVariable\n\nJavascript is called loosely typed language. Which means Javascript variables can hold value of any Data-Type. Javascript automatically takes care of changing the variable-type based on the value/literal provided during runtime.\n\nglobal_Page = 10;                                               var global_Page;      « undefined\n    « Integer literal, Number Type.   -------------------       global_Page = 10;     « Number         \nglobal_Page = 'Yash';                 |   Interpreted   |       global_Page = 'Yash'; « String\n    « String literal, String Type.    «       AS        «       global_Page = true;   « Boolean \nvar global_Page = true;               |                 |       global_Page = function (){          « function\n    « Boolean Type                    -------------------                 var local_functionblock;  « undefined\nglobal_Page = function (){                                                local_functionblock = 777;« Number\n    var local_functionblock = 777;                              };  \n    // Assigning function as a data.\n};  \n\n\nFunction\n\nfunction Identifier_opt ( FormalParameterList_opt ) { \n      FunctionBody | sequence of statements\n\n      « return;  Default undefined\n      « return 'some data';\n}\n\nfunctions declared inside the page are hoisted to top of the page having global access.\nfunctions declared inside the function-block are hoisted to top of the block.\n\nDefault return value of function is 'undefined', Variable declaration default value also 'undefined'\n\nScope with respect to function-block global. \nScope with respect to page undefined | not available.\n\n\nFunction Declaration\n\nfunction globalAccess() {                                  function globalAccess() {      \n}                                  -------------------     }\nglobalAccess();                    |                 |     function globalAccess() { « Re-Defined / overridden.\nlocalAccess();                     «   Hoisted  As   «         function localAccess() {\nfunction globalAccess() {          |                 |         }\n     localAccess();                -------------------         localAccess(); « function accessed with in globalAccess() only.\n     function localAccess() {                              }\n     }                                                     globalAccess();\n}                                                          localAccess(); « ReferenceError as the function is not defined\n\n\nFunction Expression\n\n        10;                 « literal\n       (10);                « Expression                (10).toString() -> '10'\nvar a;                      \n    a = 10;                 « Expression var              a.toString()  -> '10'\n(function invoke() {        « Expression Function\n console.log('Self Invoking');                      (function () {\n});                                                               }) () -> 'Self Invoking'\n\nvar f; \n    f = function (){        « Expression var Function\n    console.log('var Function');                                   f ()  -> 'var Function'\n    };\n\n\nFunction assigned to variable Example:\n\n(function selfExecuting(){\n    console.log('IIFE - Immediately-Invoked Function Expression');\n}());\n\nvar anonymous = function (){\n    console.log('anonymous function Expression');\n};\n\nvar namedExpression = function for_InternalUSE(fact){\n    if(fact === 1){\n        return 1;\n    }\n\n    var localExpression = function(){\n        console.log('Local to the parent Function Scope');\n    };\n    globalExpression = function(){ \n        console.log('creates a new global variable, then assigned this function.');\n    };\n\n    //return; //undefined.\n    return fact * for_InternalUSE( fact - 1);   \n};\n\nnamedExpression();\nglobalExpression();\n\n\njavascript interpreted as\n\nvar anonymous;\nvar namedExpression;\nvar globalExpression;\n\nanonymous = function (){\n    console.log('anonymous function Expression');\n};\n\nnamedExpression = function for_InternalUSE(fact){\n    var localExpression;\n\n    if(fact === 1){\n        return 1;\n    }\n    localExpression = function(){\n        console.log('Local to the parent Function Scope');\n    };\n    globalExpression = function(){ \n        console.log('creates a new global variable, then assigned this function.');\n    };\n\n    return fact * for_InternalUSE( fact - 1);    // DEFAULT UNDEFINED.\n};\n\nnamedExpression(10);\nglobalExpression();\n\n\nYou can check function declaration, expression test over different browser's using jsperf Test Runner\n\nES5 Constructor Function Classes: Function objects created using Function.prototype.bind\n\nJavaScript treats functions as first-class objects, so being an object, you can assign properties to a function.\n\nfunction Shape(id) { // Function Declaration\n    this.id = id;\n};\n    // Adding a prototyped method to a function.\n    Shape.prototype.getID = function () {\n        return this.id;\n    };\n    Shape.prototype.setID = function ( id ) {\n        this.id = id;\n    };\n\nvar expFn = Shape; // Function Expression\n\nvar funObj = new Shape( ); // Function Object\nfunObj.hasOwnProperty('prototype'); // false\nfunObj.setID( 10 );\nconsole.log( funObj.getID() ); // 10\n\n\nES6 introduced Arrow function: An arrow function expression has a shorter syntax, they are best suited for non-method functions, and they cannot be used as constructors.\n\nArrowFunction : ArrowParameters => ConciseBody.\n\nconst fn = (item) => { return item & 1 ? 'Odd' : 'Even'; };\nconsole.log( fn(2) ); // Even\nconsole.log( fn(3) ); // Odd\n\nShare\nImprove this answer\nFollow\nedited Sep 28 '17 at 6:35\nanswered Jan 25 '16 at 14:46\nYash\n7,6202\n2 gold badges\n57\n57 silver badges\n64\n64 bronze badges","comments":[]},{"answer":"I'm adding my own answer just because everyone else has covered the hoisting part thoroughly.\n\nI've wondered about which way is better for a long while now, and thanks to http://jsperf.com now I know :)\n\nFunction declarations are faster, and that's what really matters in web dev right? ;)\n\nShare\nImprove this answer\nFollow\nanswered May 1 '15 at 15:06\nLeon Gaban\n28.8k86\n86 gold badges\n286\n286 silver badges\n484\n484 bronze badges","comments":["see answer about performance below, different results"]},{"answer":"A function declaration and a function expression assigned to a variable behave the same once the binding is established.\n\nThere is a difference however at how and when the function object is actually associated with its variable. This difference is due to the mechanism called variable hoisting in JavaScript.\n\nBasically, all function declarations and variable declarations are hoisted to the top of the function in which the declaration occurs (this is why we say that JavaScript has function scope).\n\nWhen a function declaration is hoisted, the function body \"follows\" so when the function body is evaluated, the variable will immediately be bound to a function object.\n\nWhen a variable declaration is hoisted, the initialization does not follow, but is \"left behind\". The variable is initialized to undefined at the start of the function body, and will be assigned a value at its original location in the code. (Actually, it will be assigned a value at every location where a declaration of a variable with the same name occurs.)\n\nThe order of hoisting is also important: function declarations take precedence over variable declarations with the same name, and the last function declaration takes precedence over previous function declarations with the same name.\n\nSome examples...\n\nvar foo = 1;\nfunction bar() {\n  if (!foo) {\n    var foo = 10 }\n  return foo; }\nbar() // 10\n\n\nVariable foo is hoisted to the top of the function, initialized to undefined, so that !foo is true, so foo is assigned 10. The foo outside of bar's scope plays no role and is untouched.\n\nfunction f() {\n  return a; \n  function a() {return 1}; \n  var a = 4;\n  function a() {return 2}}\nf()() // 2\n\nfunction f() {\n  return a;\n  var a = 4;\n  function a() {return 1};\n  function a() {return 2}}\nf()() // 2\n\n\nFunction declarations take precedence over variable declarations, and the last function declaration \"sticks\".\n\nfunction f() {\n  var a = 4;\n  function a() {return 1}; \n  function a() {return 2}; \n  return a; }\nf() // 4\n\n\nIn this example a is initialized with the function object resulting from evaluating the second function declaration, and then is assigned 4.\n\nvar a = 1;\nfunction b() {\n  a = 10;\n  return;\n  function a() {}}\nb();\na // 1\n\n\nHere the function declaration is hoisted first, declaring and initializing variable a. Next, this variable is assigned 10. In other words: the assignment does not assign to outer variable a.\n\nShare\nImprove this answer\nFollow\nanswered Feb 6 '13 at 16:29\neljenso\n16.1k6\n6 gold badges\n53\n53 silver badges\n62\n62 bronze badges","comments":[]},{"answer":"The first example is a function declaration:\n\nfunction abc(){}\n\n\nThe second example is a function expression:\n\nvar abc = function() {};\n\n\nThe main difference is how they are hoisted (lifted and declared). In the first example, the whole function declaration is hoisted. In the second example only the var 'abc' is hoisted, its value (the function) will be undefined, and the function itself remains at the position that it is declared.\n\nTo put it simply:\n\n//this will work\nabc(param);\nfunction abc(){}\n\n//this would fail\nabc(param);\nvar abc = function() {}\n\n\nTo study more about this topic I strongly recommend you this link\n\nShare\nImprove this answer\nFollow\nedited May 9 '15 at 9:37\nanswered Jun 5 '14 at 8:28\nsla55er\n7511\n1 gold badge\n8\n8 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"𝗧𝗵𝗲𝗿𝗲 𝗮𝗿𝗲 𝗳𝗼𝘂𝗿 𝗻𝗼𝘁𝗲𝘄𝗼𝗿𝘁𝗵𝘆 𝗰𝗼𝗺𝗽𝗮𝗿𝗶𝘀𝗼𝗻𝘀 𝗯𝗲𝘁𝘄𝗲𝗲𝗻 𝘁𝗵𝗲 𝘁𝘄𝗼 𝗱𝗶𝗳𝗳𝗲𝗿𝗲𝗻𝘁 𝗱𝗲𝗰𝗹𝗮𝗿𝗮𝘁𝗶𝗼𝗻𝘀 𝗼𝗳 𝗳𝘂𝗻𝗰𝘁𝗶𝗼𝗻𝘀 𝗮𝘀 𝗹𝗶𝘀𝘁𝗲𝗱 𝗯𝗲𝗹𝗼𝘄.\nAvailability (scope) of the function\n\nThe following works because function add() is scoped to the nearest block:\n\ntry {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nfunction add(a, b){\n  return a + b;\n}\n Run code snippetExpand snippet\n\nThe following does not work because the variable is called before a function value is assigned to the variable add.\n\ntry {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nvar add=function(a, b){\n  return a + b;\n}\n Run code snippetExpand snippet\n\nThe above code is identical in functionality to the code below. Note that explicitly assigning add = undefined is superfluous because simply doing var add; is the exact same as var add=undefined.\n\nvar add = undefined;\n\ntry {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nadd = function(a, b){\n  return a + b;\n}\n Run code snippetExpand snippet\n\nThe following does not work because var add= begins an expression and causes the following function add() to be an expression instead of a block. Named functions are only visible to themselves and their surrounding block. As function add() is an expression here, it has no surrounding block, so it is only visible to itself.\n\ntry {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nvar add=function add(a, b){\n  return a + b;\n}\n Run code snippetExpand snippet\n\n(function).name\n\nThe name of a function function thefuncname(){} is thefuncname when it is declared this way.\n\nfunction foobar(a, b){}\n\nconsole.log(foobar.name);\n Run code snippetExpand snippet\n\nvar a = function foobar(){};\n\nconsole.log(a.name);\n Run code snippetExpand snippet\n\nOtherwise, if a function is declared as function(){}, the function.name is the first variable used to store the function.\n\nvar a = function(){};\nvar b = (function(){ return function(){} });\n\nconsole.log(a.name);\nconsole.log(b.name);\n Run code snippetExpand snippet\n\nIf there are no variables set to the function, then the functions name is the empty string (\"\").\n\nconsole.log((function(){}).name === \"\");\n Run code snippetExpand snippet\n\nLastly, while the variable the function is assigned to initially sets the name, successive variables set to the function do not change the name.\n\nvar a = function(){};\nvar b = a;\nvar c = b;\n\nconsole.log(a.name);\nconsole.log(b.name);\nconsole.log(c.name);\n Run code snippetExpand snippet\n\nPerformance\n\nIn Google's V8 and Firefox's Spidermonkey there might be a few microsecond JIST compilation difference, but ultimately the result is the exact same. To prove this, let's examine the efficiency of JSPerf at microbenchmarks by comparing the speed of two blank code snippets. The JSPerf tests are found here. And, the jsben.ch testsare found here. As you can see, there is a noticable difference when there should be none. If you are really a performance freak like me, then it might be more worth your while trying to reduce the number of variables and functions in the scope and especially eliminating polymorphism (such as using the same variable to store two different types).\n\nVariable Mutability\n\nWhen you use the var keyword to declare a variable, you can then reassign a different value to the variable like so.\n\n(function(){\n    \"use strict\";\n    var foobar = function(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();\n Run code snippetExpand snippet\n\nHowever, when we use the const-statement, the variable reference becomes immutable. This means that we cannot assign a new value to the variable. Please note, however, that this does not make the contents of the variable immutable: if you do const arr = [], then you can still do arr[10] = \"example\". Only doing something like arr = \"new value\" or arr = [] would throw an error as seen below.\n\n(function(){\n    \"use strict\";\n    const foobar = function(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();\n Run code snippetExpand snippet\n\nInterestingly, if we declare the variable as function funcName(){}, then the immutability of the variable is the same as declaring it with var.\n\n(function(){\n    \"use strict\";\n    function foobar(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();\n Run code snippetExpand snippet\n\n𝗪𝗵𝗮𝘁 𝗜𝘀 𝗧𝗵𝗲 \"𝗡𝗲𝗮𝗿𝗲𝘀𝘁 𝗕𝗹𝗼𝗰𝗸\"\n\nThe \"nearest block\" is the nearest \"function,\" (including asynchronous functions, generator functions, and asynchronous generator functions). However, interestingly, a function functionName() {} behaves like a var functionName = function() {} when in a non-closure block to items outside said closure. Observe.\n\nNormal var add=function(){}\n\ntry {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}');\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\nvar add=function(a, b){return a + b}\n Run code snippetExpand snippet\n\nNormal function add(){}\n\ntry {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\nfunction add(a, b){\n  return a + b;\n}\n Run code snippetExpand snippet\n\nFunction\n\ntry {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(function () {\n    function add(a, b){\n      return a + b;\n    }\n})();\n Run code snippetExpand snippet\n\nStatement (such as if, else, for, while, try/catch/finally, switch, do/while, with)\n\ntry {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n{\n    function add(a, b){\n      return a + b;\n    }\n}\n Run code snippetExpand snippet\n\nArrow Function with var add=function()\n\ntry {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(() => {\n    var add=function(a, b){\n      return a + b;\n    }\n})();\n Run code snippetExpand snippet\n\nArrow Function With function add()\n\ntry {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(() => {\n    function add(a, b){\n      return a + b;\n    }\n})();\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jan 4 at 14:35\nanswered Jan 15 '18 at 1:55\nJack G\n3,2702\n2 gold badges\n27\n27 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"In terms of code maintenance cost, named functions are more preferable:\n\nIndependent from the place where they are declared (but still limited by scope).\nMore resistant to mistakes like conditional initialization (you are still able to override if wanted to).\nThe code becomes more readable by allocating local functions separately of scope functionality. Usually in the scope the functionality goes first, followed by declarations of local functions.\nIn a debugger you will clearly see the function name on the call stack instead of an \"anonymous/evaluated\" function.\n\nI suspect more PROS for named functions are follow. And what is listed as an advantage of named functions is a disadvantage for anonymous ones.\n\nHistorically, anonymous functions appeared from the inability of JavaScript as a language to list members with named functions:\n\n{\n    member:function() { /* How do I make \"this.member\" a named function? */\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 28 '15 at 19:44\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 23 '10 at 20:32\nSasha Firsov\n6418\n8 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"In computer science terms, we talk about anonymous functions and named functions. I think the most important difference is that an anonymous function is not bound to a name, hence the name anonymous function. In JavaScript it is a first class object dynamically declared at runtime.\n\nFor more information on anonymous functions and lambda calculus, Wikipedia is a good start: Anonymous Functions.\n\nShare\nImprove this answer\nFollow\nedited Apr 22 at 5:26\nshy-tan\n6112\n2 gold badges\n5\n5 silver badges\n18\n18 bronze badges\nanswered Dec 18 '08 at 19:30\nKafka\n4523\n3 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"I use the variable approach in my code for a very specific reason, the theory of which has been covered in an abstract way above, but an example might help some people like me, with limited JavaScript expertise.\n\nI have code that I need to run with 160 independently-designed brandings. Most of the code is in shared files, but branding-specific stuff is in a separate file, one for each branding.\n\nSome brandings require specific functions, and some do not. Sometimes I have to add new functions to do new branding-specific things. I am happy to change the shared coded, but I don't want to have to change all 160 sets of branding files.\n\nBy using the variable syntax, I can declare the variable (a function pointer essentially) in the shared code and either assign a trivial stub function, or set to null.\n\nThe one or two brandings that need a specific implementation of the function can then define their version of the function and assign this to the variable if they want, and the rest do nothing. I can test for a null function before I execute it in the shared code.\n\nFrom people's comments above, I gather it may be possible to redefine a static function too, but I think the variable solution is nice and clear.\n\nShare\nImprove this answer\nFollow\nedited Dec 28 '15 at 20:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 29 '12 at 11:28\nHerc\n4874\n4 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"Greg's Answer is good enough, but I still would like to add something to it that I learned just now watching Douglas Crockford's videos.\n\nFunction expression:\n\nvar foo = function foo() {};\n\n\nFunction statement:\n\nfunction foo() {};\n\n\nThe function statement is just a shorthand for var statement with a function value.\n\nSo\n\nfunction foo() {};\n\n\nexpands to\n\nvar foo = function foo() {};\n\n\nWhich expands further to:\n\nvar foo = undefined;\nfoo = function foo() {};\n\n\nAnd they are both hoisted to the top of the code.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:18\nCommunity♦\n11\n1 silver badge\nanswered Jul 21 '15 at 7:45\nRohan\n11.4k20\n20 gold badges\n66\n66 silver badges\n133\n133 bronze badges","comments":[]},{"answer":"@EugeneLazutkin gives an example where he names an assigned function to be able to use shortcut() as an internal reference to itself. John Resig gives another example - copying a recursive function assigned to another object in his Learning Advanced Javascript tutorial. While assigning functions to properties isn't strictly the question here, I recommend actively trying the tutorial out - run the code by clicking the button in the upper right corner, and double click the code to edit to your liking.\n\nExamples from the tutorial: recursive calls in yell():\n\nTests fail when the original ninja object is removed. (page 13)\n\nvar ninja = { \n  yell: function(n){ \n    return n > 0 ? ninja.yell(n-1) + \"a\" : \"hiy\"; \n  } \n}; \nassert( ninja.yell(4) == \"hiyaaaa\", \"A single object isn't too bad, either.\" ); \n\nvar samurai = { yell: ninja.yell }; \nvar ninja = null; \n\ntry { \n  samurai.yell(4); \n} catch(e){ \n  assert( false, \"Uh, this isn't good! Where'd ninja.yell go?\" ); \n}\n\n\nIf you name the function that will be called recursively, the tests will pass. (page 14)\n\nvar ninja = { \n  yell: function yell(n){ \n    return n > 0 ? yell(n-1) + \"a\" : \"hiy\"; \n  } \n}; \nassert( ninja.yell(4) == \"hiyaaaa\", \"Works as we would expect it to!\" ); \n\nvar samurai = { yell: ninja.yell }; \nvar ninja = {}; \nassert( samurai.yell(4) == \"hiyaaaa\", \"The method correctly calls itself.\" );\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Aug 4 '12 at 15:24\nJoel Purra\n21.3k7\n7 gold badges\n53\n53 silver badges\n58\n58 bronze badges","comments":[]},{"answer":"Another difference that is not mentioned in the other answers is that if you use the anonymous function\n\nvar functionOne = function() {\n    // Some code\n};\n\n\nand use that as a constructor as in\n\nvar one = new functionOne();\n\n\nthen one.constructor.name will not be defined. Function.name is non-standard but is supported by Firefox, Chrome, other Webkit-derived browsers and IE 9+.\n\nWith\n\nfunction functionTwo() {\n    // Some code\n}\ntwo = new functionTwo();\n\n\nit is possible to retrieve the name of the constructor as a string with two.constructor.name.\n\nShare\nImprove this answer\nFollow\nedited Jan 17 '13 at 8:48\nanswered Oct 15 '12 at 10:42\nIngo Kegel\n43.2k9\n9 gold badges\n66\n66 silver badges\n99\n99 bronze badges","comments":[]},{"answer":"The first one (function doSomething(x)) should be part of an object notation.\n\nThe second one (var doSomething = function(x){ alert(x);}) is simply creating an anonymous function and assigning it to a variable, doSomething. So doSomething() will call the function.\n\nYou may want to know what a function declaration and function expression is.\n\nA function declaration defines a named function variable without requiring variable assignment. Function declarations occur as standalone constructs and cannot be nested within non-function blocks.\n\nfunction foo() {\n    return 3;\n}\n\n\nECMA 5 (13.0) defines the syntax as\nfunction Identifier ( FormalParameterListopt ) { FunctionBody }\n\nIn above condition the function name is visible within its scope and the scope of its parent (otherwise it would be unreachable).\n\nAnd in a function expression\n\nA function expression defines a function as a part of a larger expression syntax (typically a variable assignment ). Functions defined via functions expressions can be named or anonymous. Function expressions should not start with “function”.\n\n// Anonymous function expression\nvar a = function() {\n    return 3;\n}\n\n// Named function expression\nvar a = function foo() {\n    return 3;\n}\n\n// Self-invoking function expression\n(function foo() {\n    alert(\"hello!\");\n})();\n\n\nECMA 5 (13.0) defines the syntax as\nfunction Identifieropt ( FormalParameterListopt ) { FunctionBody }\n\nShare\nImprove this answer\nFollow\nedited Dec 28 '15 at 20:29\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 5 '13 at 18:37\nNullPoiиteя\n53.8k22\n22 gold badges\n120\n120 silver badges\n138\n138 bronze badges","comments":[]},{"answer":"I'm listing out the differences below:\n\nA function declaration can be placed anywhere in the code. Even if it is invoked before the definition appears in code, it gets executed as function declaration is committed to memory or in a way it is hoisted up, before any other code in the page starts execution.\n\nTake a look at the function below:\n\nfunction outerFunction() {\n    function foo() {\n       return 1;\n    }\n    return foo();\n    function foo() {\n       return 2;\n    }\n}\nalert(outerFunction()); // Displays 2\n\n\nThis is because, during execution, it looks like:-\n\nfunction foo() {  // The first function declaration is moved to top\n    return 1;\n}\nfunction foo() {  // The second function declaration is moved to top\n    return 2;\n}\nfunction outerFunction() {\n    return foo();\n}\nalert(outerFunction()); //So executing from top to bottom,\n                        //the last foo() returns 2 which gets displayed\n\n\nA function expression, if not defined before calling it, will result in an error. Also, here the function definition itself is not moved to the top or committed to memory like in the function declarations. But the variable to which we assign the function gets hoisted up and undefined gets assigned to it.\n\nSame function using function expressions:\n\nfunction outerFunction() {\n    var foo = function() {\n       return 1;\n    }\n    return foo();\n    var foo = function() {\n       return 2;\n    }\n}\nalert(outerFunction()); // Displays 1\n\n\nThis is because during execution, it looks like:\n\nfunction outerFunction() {\n   var foo = undefined;\n   var foo = undefined;\n\n   foo = function() {\n      return 1;\n   };\n   return foo ();\n   foo = function() {   // This function expression is not reachable\n      return 2;\n   };\n}\nalert(outerFunction()); // Displays 1\n\n\nIt is not safe to write function declarations in non-function blocks like if because they won't be accessible.\n\nif (test) {\n    function x() { doSomething(); }\n}\n\n\nNamed function expression like the one below, may not work in Internet Explorer browsers prior to version 9.\n\nvar today = function today() {return new Date()}\n\nShare\nImprove this answer\nFollow\nedited Dec 28 '15 at 20:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 9 '15 at 10:30\nvarna\n9118\n8 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"If you would use those functions to create objects, you would get:\n\nvar objectOne = new functionOne();\nconsole.log(objectOne.__proto__); // prints \"Object {}\" because constructor is an anonymous function\n\nvar objectTwo = new functionTwo();\nconsole.log(objectTwo.__proto__); // prints \"functionTwo {}\" because constructor is a named function\n\nShare\nImprove this answer\nFollow\nanswered Oct 25 '13 at 16:38\nPawel Furmaniak\n4,0643\n3 gold badges\n27\n27 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"In light of the \"named functions show up in stack traces\" argument, modern JavaScript engines are actually quite capable of representing anonymous functions.\n\nAs of this writing, V8, SpiderMonkey, Chakra and Nitro always refer to named functions by their names. They almost always refer to an anonymous function by its identifier if it has one.\n\nSpiderMonkey can figure out the name of an anonymous function returned from another function. The rest can't.\n\nIf you really, really wanted your iterator and success callbacks to show up in the trace, you could name those too...\n\n[].forEach(function iterator() {});\n\n\nBut for the most part it's not worth stressing over.\n\nHarness (Fiddle)\n'use strict';\n\nvar a = function () {\n    throw new Error();\n},\n    b = function b() {\n        throw new Error();\n    },\n    c = function d() {\n        throw new Error();\n    },\n    e = {\n        f: a,\n        g: b,\n        h: c,\n        i: function () {\n            throw new Error();\n        },\n        j: function j() {\n            throw new Error();\n        },\n        k: function l() {\n            throw new Error();\n        }\n    },\n    m = (function () {\n        return function () {\n            throw new Error();\n        };\n    }()),\n    n = (function () {\n        return function n() {\n            throw new Error();\n        };\n    }()),\n    o = (function () {\n        return function p() {\n            throw new Error();\n        };\n    }());\n\nconsole.log([a, b, c].concat(Object.keys(e).reduce(function (values, key) {\n    return values.concat(e[key]);\n}, [])).concat([m, n, o]).reduce(function (logs, func) {\n\n    try {\n        func();\n    } catch (error) {\n        return logs.concat('func.name: ' + func.name + '\\n' +\n                           'Trace:\\n' +\n                           error.stack);\n        // Need to manually log the error object in Nitro.\n    }\n\n}, []).join('\\n\\n'));\n\nV8\nfunc.name: \nTrace:\nError\n    at a (http://localhost:8000/test.js:4:11)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: b\nTrace:\nError\n    at b (http://localhost:8000/test.js:7:15)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: d\nTrace:\nError\n    at d (http://localhost:8000/test.js:10:15)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: \nTrace:\nError\n    at a (http://localhost:8000/test.js:4:11)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: b\nTrace:\nError\n    at b (http://localhost:8000/test.js:7:15)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: d\nTrace:\nError\n    at d (http://localhost:8000/test.js:10:15)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: \nTrace:\nError\n    at e.i (http://localhost:8000/test.js:17:19)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: j\nTrace:\nError\n    at j (http://localhost:8000/test.js:20:19)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: l\nTrace:\nError\n    at l (http://localhost:8000/test.js:23:19)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: \nTrace:\nError\n    at http://localhost:8000/test.js:28:19\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: n\nTrace:\nError\n    at n (http://localhost:8000/test.js:33:19)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27\n\nfunc.name: p\nTrace:\nError\n    at p (http://localhost:8000/test.js:38:19)\n    at http://localhost:8000/test.js:47:9\n    at Array.reduce (native)\n    at http://localhost:8000/test.js:44:27 test.js:42\n\nSpiderMonkey\nfunc.name: \nTrace:\na@http://localhost:8000/test.js:4:5\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: b\nTrace:\nb@http://localhost:8000/test.js:7:9\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: d\nTrace:\nd@http://localhost:8000/test.js:10:9\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: \nTrace:\na@http://localhost:8000/test.js:4:5\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: b\nTrace:\nb@http://localhost:8000/test.js:7:9\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: d\nTrace:\nd@http://localhost:8000/test.js:10:9\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: \nTrace:\ne.i@http://localhost:8000/test.js:17:13\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: j\nTrace:\nj@http://localhost:8000/test.js:20:13\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: l\nTrace:\nl@http://localhost:8000/test.js:23:13\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: \nTrace:\nm</<@http://localhost:8000/test.js:28:13\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: n\nTrace:\nn@http://localhost:8000/test.js:33:13\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\n\nfunc.name: p\nTrace:\np@http://localhost:8000/test.js:38:13\n@http://localhost:8000/test.js:47:9\n@http://localhost:8000/test.js:54:1\n\nChakra\nfunc.name: undefined\nTrace:\nError\n   at a (http://localhost:8000/test.js:4:5)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at b (http://localhost:8000/test.js:7:9)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at d (http://localhost:8000/test.js:10:9)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at a (http://localhost:8000/test.js:4:5)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at b (http://localhost:8000/test.js:7:9)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at d (http://localhost:8000/test.js:10:9)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at e.i (http://localhost:8000/test.js:17:13)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at j (http://localhost:8000/test.js:20:13)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at l (http://localhost:8000/test.js:23:13)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at Anonymous function (http://localhost:8000/test.js:28:13)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at n (http://localhost:8000/test.js:33:13)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\n\nfunc.name: undefined\nTrace:\nError\n   at p (http://localhost:8000/test.js:38:13)\n   at Anonymous function (http://localhost:8000/test.js:47:9)\n   at Global code (http://localhost:8000/test.js:42:1)\n\nNitro\nfunc.name: \nTrace:\na@http://localhost:8000/test.js:4:22\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: b\nTrace:\nb@http://localhost:8000/test.js:7:26\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: d\nTrace:\nd@http://localhost:8000/test.js:10:26\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: \nTrace:\na@http://localhost:8000/test.js:4:22\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: b\nTrace:\nb@http://localhost:8000/test.js:7:26\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: d\nTrace:\nd@http://localhost:8000/test.js:10:26\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: \nTrace:\ni@http://localhost:8000/test.js:17:30\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: j\nTrace:\nj@http://localhost:8000/test.js:20:30\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: l\nTrace:\nl@http://localhost:8000/test.js:23:30\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: \nTrace:\nhttp://localhost:8000/test.js:28:30\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: n\nTrace:\nn@http://localhost:8000/test.js:33:30\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nfunc.name: p\nTrace:\np@http://localhost:8000/test.js:38:30\nhttp://localhost:8000/test.js:47:13\nreduce@[native code]\nglobal code@http://localhost:8000/test.js:44:33\n\nShare\nImprove this answer\nFollow\nedited Jan 13 '15 at 3:24\nanswered Oct 12 '14 at 0:58\nJackson\n8,0874\n4 gold badges\n43\n43 silver badges\n66\n66 bronze badges","comments":[]},{"answer":"About performance:\n\nNew versions of V8 introduced several under-the-hood optimizations and so did SpiderMonkey.\n\nThere is almost no difference now between expression and declaration.\nFunction expression appears to be faster now.\n\nChrome 62.0.3202 \n\nFireFox 55 \n\nChrome Canary 63.0.3225 \n\n\n\n\nAnonymous function expressions appear to have better performance against Named function expression.\n\n\n\n\nFirefox  Chrome Canary  Chrome \n\nShare\nImprove this answer\nFollow\nedited Sep 28 '17 at 5:13\nanswered Sep 28 '17 at 4:34\nPanos Kal.\n11.8k8\n8 gold badges\n60\n60 silver badges\n74\n74 bronze badges","comments":["The results differences are too small to be considered as a difference. If you'll run the test 100 times, you will get 100 results.","@RonnySherer, are you familiar with jsperf? Tests were made after running more than 10 million times!","Every measurement has disturbances. The computer it not in the same state and this is not the only process running on the computer. When the difference is so small, it means that you cannot rely on it and it is virtually the same. Try to run the sane test 10 times one after the other and you'll see that the numbers are different. Pretty close, but not the same.","@RonnySherer js perf creates a virtual environment especially to account for processes with those small differences. It is not running on my computer. It runs only that. When something is so small maybe someone should not give a damn. BUT never the less I count it correctly and I report it. If someone wants to use it inside a loop with billions of iterations then he should pick the function with the best performance.","The virtual environment is on a server which might do some other stuff. I did some tests. The results are never exactly the same."]},{"answer":"Both are different ways of defining a function. The difference is how the browser interprets and loads them into an execution context.\n\nThe first case is of function expressions which loads only when the interpreter reaches that line of code. So if you do it like the following, you will get an error that the functionOne is not a function.\n\nfunctionOne();\nvar functionOne = function() {\n    // Some code\n};\n\n\nThe reason is that on the first line no value is assigned to functionOne, and hence it is undefined. We are trying to call it as a function, and hence we are getting an error.\n\nOn the second line we are assigning the reference of an anonymous function to functionOne.\n\nThe second case is of function declarations that loads before any code is executed. So if you do like the following you won't get any error as the declaration loads before code execution.\n\nfunctionOne();\nfunction functionOne() {\n   // Some code\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 28 '15 at 20:42\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 28 '15 at 20:18\nNitin9791\n94412\n12 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"In JavaScript there are two ways to create functions:\n\nFunction declaration:\n\nfunction fn(){\n  console.log(\"Hello\");\n}\nfn();\n\n\nThis is very basic, self-explanatory, used in many languages and standard across C family of languages. We declared a function defined it and executed it by calling it.\n\nWhat you should be knowing is that functions are actually objects in JavaScript; internally we have created an object for above function and given it a name called fn or the reference to the object is stored in fn. Functions are objects in JavaScript; an instance of function is actually an object instance.\n\nFunction expression:\n\nvar fn=function(){\n  console.log(\"Hello\");\n}\nfn();\n\n\nJavaScript has first-class functions, that is, create a function and assign it to a variable just like you create a string or number and assign it to a variable. Here, the fn variable is assigned to a function. The reason for this concept is functions are objects in JavaScript; fn is pointing to the object instance of the above function. We have initialized a function and assigned it to a variable. It's not executing the function and assigning the result.\n\nReference: JavaScript function declaration syntax: var fn = function() {} vs function fn() {}\n\nShare\nImprove this answer\nFollow\nedited Apr 9 '17 at 7:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 14 '16 at 9:13\nAnoop Rai\n3594\n4 silver badges\n5\n5 bronze badges","comments":[]},{"answer":"They are pretty similar with some small differences, first one is a variable which assigned to an anonymous function (Function Declaration) and second one is the normal way to create a function in JavaScript(Anonymous function Declaration), both has usage, cons and pros:\n\n1. Function Expression\n\n\nvar functionOne = function() {\n    // Some code\n};\n\n\nA Function Expression defines a function as a part of a larger expression syntax (typically a variable assignment ). Functions defined via Functions Expressions can be named or anonymous. Function Expressions must not start with “function” (hence the parentheses around the self invoking example below).\n\nAssign a variable to a function, means no Hoisting, as we know functions in JavaScript can Hoist, means they can be called before they get declared, while variables need to be declared before getting access to them, so means in this case we can not access the function before where it's declared, also it could be a way that you write your functions, for the functions which return another function, this kind of declaration could make sense, also in ECMA6 & above you can assign this to an arrow function which can be used to call anonymous functions, also this way of declaring is a better way to create Constructor functions in JavaScript.\n\n2. Function Declaration\n\n\nfunction functionTwo() {\n    // Some code\n}\n\n\nA Function Declaration defines a named function variable without requiring variable assignment. Function Declarations occur as standalone constructs and cannot be nested within non-function blocks. It’s helpful to think of them as siblings of Variable Declarations. Just as Variable Declarations must start with “var”, Function Declarations must begin with “function”.\n\nThis is the normal way of calling a function in JavaScript, this function can be called before you even declare it as in JavaScript all functions get Hoisted, but if you have 'use strict' this won't Hoist as expected, it's a good way to call all normal functions which are not big in lines and neither are a constructor function.\n\nAlso, if you need more info about how hoisting works in JavaScript, visit the link below:\n\nhttps://developer.mozilla.org/en-US/docs/Glossary/Hoisting\n\nShare\nImprove this answer\nFollow\nedited Jul 30 '17 at 4:30\nanswered May 9 '17 at 13:56\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"This is just two possible ways of declaring functions, and in the second way, you can use the function before declaration.\n\nShare\nImprove this answer\nFollow\nedited Dec 28 '15 at 20:32\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 24 '15 at 10:08\nTao\n5115\n5 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"new Function() can be used to pass the function's body in a string. And hence this can be used to create dynamic functions. Also passing the script without executing the script.\n\nvar func = new Function(\"x\", \"y\", \"return x*y;\");\nfunction secondFunction(){\n   var result;\n   result = func(10,20);\n   console.log ( result );\n}\n\nsecondFunction()\n\nShare\nImprove this answer\nFollow\nanswered May 10 '16 at 7:05\nSuperNova\n16.2k6\n6 gold badges\n67\n67 silver badges\n48\n48 bronze badges","comments":["While this is good and true, how exactly does this alone relate to the quesiton being asked?"]}]},{"id":"6841333","href":"https://stackoverflow.com/questions/6841333/why-is-subtracting-these-two-times-in-1927-giving-a-strange-result","title":"Why is subtracting these two times (in 1927) giving a strange result?","description":"\n                \nIf I run the following program, which parses two date strings referencing times 1 second apart and compares them:\npublic static void main(String[] args) throws ParseException {\n    SimpleDateFormat sf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");  \n    String str3 = \"1927-12-31 23:54:07\";  \n    String str4 = \"1927-12-31 23:54:08\";  \n    Date sDt3 = sf.parse(str3);  \n    Date sDt4 = sf.parse(str4);  \n    long ld3 = sDt3.getTime() /1000;  \n    long ld4 = sDt4.getTime() /1000;\n    System.out.println(ld4-ld3);\n}\n\nThe output is:\n353\n\nWhy is ld4-ld3, not 1 (as I would expect from the one-second difference in the times), but 353?\nIf I change the dates to times 1 second later:\nString str3 = \"1927-12-31 23:54:08\";  \nString str4 = \"1927-12-31 23:54:09\";  \n\nThen ld4-ld3 will be 1.\n\nJava version:\njava version \"1.6.0_22\"\nJava(TM) SE Runtime Environment (build 1.6.0_22-b04)\nDynamic Code Evolution Client VM (build 0.2-b02-internal, 19.0-b04-internal, mixed mode)\n\nTimezone(`TimeZone.getDefault()`):\n\nsun.util.calendar.ZoneInfo[id=\"Asia/Shanghai\",\noffset=28800000,dstSavings=0,\nuseDaylight=false,\ntransitions=19,\nlastRule=null]\n\nLocale(Locale.getDefault()): zh_CN\n\n    ","questionComments":["This might be a locale problem.","The real answer is to always, always use seconds since an epoch for logging, like the Unix epoch, with 64 bit integer representation (signed, if you want to allow stamps before the epoch). Any real-world time system has some non-linear, non-monotonic behaviour like leap hours or daylight savings.","A great video about these kind of things: youtube.com/watch?v=-5wpm-gesOY","And another from the same guy, @ThorbjørnRavnAndersen: youtube.com/watch?v=Uqjg8Kk1HXo (Leap seconds). (This one is from Tom Scott's own YouTube channel, not from Computerphile.)","@Phil H \"seconds since the epoch\" (i.e. Unix time) is non-linear as well, in the sense that POSIX seconds are not SI seconds and vary in length"],"answers":[{"answer":"It's a time zone change on December 31st in Shanghai.\n\nSee this page for details of 1927 in Shanghai. Basically at midnight at the end of 1927, the clocks went back 5 minutes and 52 seconds. So \"1927-12-31 23:54:08\" actually happened twice, and it looks like Java is parsing it as the later possible instant for that local date/time - hence the difference.\n\nJust another episode in the often weird and wonderful world of time zones.\n\nEDIT: Stop press! History changes...\n\nThe original question would no longer demonstrate quite the same behaviour, if rebuilt with version 2013a of TZDB. In 2013a, the result would be 358 seconds, with a transition time of 23:54:03 instead of 23:54:08.\n\nI only noticed this because I'm collecting questions like this in Noda Time, in the form of unit tests... The test has now been changed, but it just goes to show - not even historical data is safe.\n\nEDIT: History has changed again...\n\nIn TZDB 2014f, the time of the change has moved to 1900-12-31, and it's now a mere 343 second change (so the time between t and t+1 is 344 seconds, if you see what I mean).\n\nEDIT: To answer a question around a transition at 1900... it looks like the Java timezone implementation treats all time zones as simply being in their standard time for any instant before the start of 1900 UTC:\n\nimport java.util.TimeZone;\n\npublic class Test {\n    public static void main(String[] args) throws Exception {\n        long startOf1900Utc = -2208988800000L;\n        for (String id : TimeZone.getAvailableIDs()) {\n            TimeZone zone = TimeZone.getTimeZone(id);\n            if (zone.getRawOffset() != zone.getOffset(startOf1900Utc - 1)) {\n                System.out.println(id);\n            }\n        }\n    }\n}\n\n\nThe code above produces no output on my Windows machine. So any time zone which has any offset other than its standard one at the start of 1900 will count that as a transition. TZDB itself has some data going back earlier than that, and doesn't rely on any idea of a \"fixed\" standard time (which is what getRawOffset assumes to be a valid concept) so other libraries needn't introduce this artificial transition.\n\nShare\nImprove this answer\nFollow\nedited Feb 7 '19 at 9:29\nanswered Jul 27 '11 at 8:31\nJon Skeet\n1.3m800\n800 gold badges\n8772\n8772 silver badges\n8958\n8958 bronze badges","comments":[]},{"answer":"You've encountered a local time discontinuity:\n\nWhen local standard time was about to reach Sunday, 1. January 1928, 00:00:00 clocks were turned backward 0:05:52 hours to Saturday, 31. December 1927, 23:54:08 local standard time instead\n\nThis is not particularly strange and has happened pretty much everywhere at one time or another as timezones were switched or changed due to political or administrative actions.\n\nShare\nImprove this answer\nFollow\nanswered Jul 27 '11 at 8:38\nMichael Borgwardt\n329k74\n74 gold badges\n459\n459 silver badges\n700\n700 bronze badges","comments":["It happens twice a year anywhere that observes DST."]},{"answer":"The moral of this strangeness is:\n\nUse dates and times in UTC wherever possible.\nIf you can not display a date or time in UTC, always indicate the time-zone.\nIf you can not require an input date/time in UTC, require an explicitly indicated time-zone.\nShare\nImprove this answer\nFollow\nanswered Jul 28 '11 at 11:50\nRaedwald\n41k35\n35 gold badges\n133\n133 silver badges\n215\n215 bronze badges","comments":["None of these points would affect this result - it falls squarely under the third bullet point - and moreover, this is a time several decades before UTC was even defined, and thus can not really meaningfully be expressed in UTC.","While your comment is technically correct (the best kind of correct!) Greenwich Mean Time has been around for a long long time before the invention of the acronym UTC."]},{"answer":"When incrementing time you should convert back to UTC and then add or subtract. Use the local time only for display.\n\nThis way you will be able to walk through any periods where hours or minutes happen twice.\n\nIf you converted to UTC, add each second, and convert to local time for display. You would go through 11:54:08 p.m. LMT - 11:59:59 p.m. LMT and then 11:54:08 p.m. CST - 11:59:59 p.m. CST.\n\nShare\nImprove this answer\nFollow\nedited Dec 27 '11 at 20:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 30 '11 at 16:55\nPatrickO\n3,9271\n1 gold badge\n11\n11 silver badges\n3\n3 bronze badges","comments":[]},{"answer":"Instead of converting each date, you can use the following code:\n\nlong difference = (sDt4.getTime() - sDt3.getTime()) / 1000;\nSystem.out.println(difference);\n\n\nAnd then see that the result is:\n\n1\n\nShare\nImprove this answer\nFollow\nedited Dec 24 '19 at 15:52\nnew QOpenGLWidget\n1,4342\n2 gold badges\n13\n13 silver badges\n26\n26 bronze badges\nanswered May 16 '12 at 5:31\nRajshri\n3,9412\n2 gold badges\n13\n13 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"I'm sorry to say, but the time discontinuity has moved a bit in\n\nJDK 6 two years ago, and in JDK 7 just recently in update 25.\n\nLesson to learn: avoid non-UTC times at all costs, except maybe for display.\n\nShare\nImprove this answer\nFollow\nedited Dec 17 '18 at 0:31\ndavnicwil\n21.1k10\n10 gold badges\n89\n89 silver badges\n101\n101 bronze badges\nanswered Feb 17 '14 at 22:44\nuser1050755\n9,6033\n3 gold badges\n35\n35 silver badges\n51\n51 bronze badges","comments":[]},{"answer":"As explained by others, there's a time discontinuity there. There are two possible timezone offsets for 1927-12-31 23:54:08 at Asia/Shanghai, but only one offset for 1927-12-31 23:54:07. So, depending on which offset is used, there's either a one second difference or a 5 minutes and 53 seconds difference.\n\nThis slight shift of offsets, instead of the usual one-hour daylight savings (summer time) we are used to, obscures the problem a bit.\n\nNote that the 2013a update of the timezone database moved this discontinuity a few seconds earlier, but the effect would still be observable.\n\nThe new java.time package on Java 8 let use see this more clearly, and provide tools to handle it. Given:\n\nDateTimeFormatterBuilder dtfb = new DateTimeFormatterBuilder();\ndtfb.append(DateTimeFormatter.ISO_LOCAL_DATE);\ndtfb.appendLiteral(' ');\ndtfb.append(DateTimeFormatter.ISO_LOCAL_TIME);\nDateTimeFormatter dtf = dtfb.toFormatter();\nZoneId shanghai = ZoneId.of(\"Asia/Shanghai\");\n\nString str3 = \"1927-12-31 23:54:07\";  \nString str4 = \"1927-12-31 23:54:08\";  \n\nZonedDateTime zdt3 = LocalDateTime.parse(str3, dtf).atZone(shanghai);\nZonedDateTime zdt4 = LocalDateTime.parse(str4, dtf).atZone(shanghai);\n\nDuration durationAtEarlierOffset = Duration.between(zdt3.withEarlierOffsetAtOverlap(), zdt4.withEarlierOffsetAtOverlap());\n\nDuration durationAtLaterOffset = Duration.between(zdt3.withLaterOffsetAtOverlap(), zdt4.withLaterOffsetAtOverlap());\n\n\nThen durationAtEarlierOffset will be one second, while durationAtLaterOffset will be five minutes and 53 seconds.\n\nAlso, these two offsets are the same:\n\n// Both have offsets +08:05:52\nZoneOffset zo3Earlier = zdt3.withEarlierOffsetAtOverlap().getOffset();\nZoneOffset zo3Later = zdt3.withLaterOffsetAtOverlap().getOffset();\n\n\nBut these two are different:\n\n// +08:05:52\nZoneOffset zo4Earlier = zdt4.withEarlierOffsetAtOverlap().getOffset();\n\n// +08:00\nZoneOffset zo4Later = zdt4.withLaterOffsetAtOverlap().getOffset();\n\n\nYou can see the same problem comparing 1927-12-31 23:59:59 with 1928-01-01 00:00:00, though, in this case, it is the earlier offset that produces the longer divergence, and it is the earlier date that has two possible offsets.\n\nAnother way to approach this is to check whether there's a transition going on. We can do this like this:\n\n// Null\nZoneOffsetTransition zot3 = shanghai.getRules().getTransition(ld3.toLocalDateTime);\n\n// An overlap transition\nZoneOffsetTransition zot4 = shanghai.getRules().getTransition(ld3.toLocalDateTime);\n\n\nYou can check whether the transition is an overlap where there's more than one valid offset for that date/time or a gap where that date/time is not valid for that zone id - by using the isOverlap() and isGap() methods on zot4.\n\nI hope this helps people handle this sort of issue once Java 8 becomes widely available, or to those using Java 7 who adopt the JSR 310 backport.\n\nShare\nImprove this answer\nFollow\nedited Dec 24 '19 at 0:17\nnew QOpenGLWidget\n1,4342\n2 gold badges\n13\n13 silver badges\n26\n26 bronze badges\nanswered Jan 3 '14 at 14:43\nDaniel C. Sobral\n286k82\n82 gold badges\n484\n484 silver badges\n670\n670 bronze badges","comments":[]},{"answer":"IMHO the pervasive, implicit localization in Java is its single largest design flaw. It may be intended for user interfaces, but frankly, who really uses Java for user interfaces today except for some IDEs where you can basically ignore localization because programmers aren't exactly the target audience for it. You can fix it (especially on Linux servers) by:\n\nexport LC_ALL=C TZ=UTC\nset your system clock to UTC\nnever use localized implementations unless absolutely necessary (ie for display only)\n\nTo the Java Community Process members I recommend:\n\nmake localized methods, not the default, but require the user to explicitly request localization.\nuse UTF-8/UTC as the FIXED default instead because that's simply the default today. There is no reason to do something else, except if you want to produce threads like this.\n\nI mean, come on, aren't global static variables an anti-OO pattern? Nothing else is those pervasive defaults given by some rudimentary environment variables.......\n\nShare\nImprove this answer\nFollow\nedited Oct 20 '20 at 3:40\nDerek Wang\n9,7304\n4 gold badges\n15\n15 silver badges\n36\n36 bronze badges\nanswered Nov 26 '14 at 15:58\nuser1050755\n9,6033\n3 gold badges\n35\n35 silver badges\n51\n51 bronze badges","comments":[]},{"answer":"As others said, it's a time change in 1927 in Shanghai.\n\nIt was 23:54:07 in Shanghai, in the local standard time, but then after 5 minutes and 52 seconds, it turned to the next day at 00:00:00, and then local standard time changed back to 23:54:08. So, that's why the difference between the two times is 343 seconds, not 1 second, as you would have expected.\n\nThe time can also mess up in other places like the US. The US has Daylight Saving Time. When the Daylight Saving Time starts the time goes forward 1 hour. But after a while, the Daylight Saving Time ends, and it goes backward 1 hour back to the standard time zone. So sometimes when comparing times in the US the difference is about 3600 seconds not 1 second.\n\nBut there is something different about these two-time changes. The latter changes continuously and the former was just a change. It didn't change back or change again by the same amount.\n\nIt's better to use UTC unless if needed to use non-UTC time like in display.\n\nShare\nImprove this answer\nFollow\nedited Nov 15 '20 at 1:01\nanswered Feb 10 '19 at 21:47\nnew QOpenGLWidget\n1,4342\n2 gold badges\n13\n13 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"To avoid that issue, when incrementing time you should convert back to UTC and then add or subtract.\n\nThis way you will be able to walk through any periods where hours or minutes happen twice.\n\nIf you converted to UTC, add each second, and convert to local time for display. You would go through 11:54:08 p.m. LMT - 11:59:59 p.m. LMT and then 11:54:08 p.m. CST - 11:59:59 p.m. CST.\n\nShare\nImprove this answer\nFollow\nanswered Dec 22 '20 at 12:27\nVlad\n946\n6 bronze badges","comments":[]}]},{"id":"40480","href":"https://stackoverflow.com/questions/40480/is-java-pass-by-reference-or-pass-by-value","title":"Is Java “pass-by-reference” or “pass-by-value”?","description":"\n                \nI always thought Java uses pass-by-reference.\nHowever, I've seen a couple of blog posts (for example, this blog) that claim that it isn't (the blog post says that Java uses pass-by-value).\nI don't think I understand the distinction they're making.\nWhat is the explanation?\n    ","questionComments":["We would more commonly say that a variable \"passed-by-reference\" can be mutated. The term appears in textbooks because language theorists needed a way to distinguish how you treat primitive data types (int, bool, byte) from complex and structured objects (array, streams, class) -- that is to say, those of possibly unbounded memory allocation.","I want to note that you do not have to think about this in most cases. I programmed java for many years until i learned c++. Until this point in time i had no clue what pass-by-reference and pass-by-value are. The intuitive solution always worked for me, which is why java is one of the best languages for beginners. So if you currently are worried, if your function needs a reference or a value, just pass it as it is and you will be fine.","Java pass the reference by value.","Putting it very concisely, this confusion arises because in Java all non-primitive data types are handled/accessed by references. However, passing is always be value. So for all non-primitive types reference is passed by its value. All primitive types are also passed by value.","For those coming from C++ and start to be confused when touching Java, this might help as shortcut."],"answers":[{"answer":"Java is always pass-by-value. Unfortunately, when we deal with objects we are really dealing with object-handles called references which are passed-by-value as well. This terminology and semantics easily confuse many beginners.\n\nIt goes like this:\n\npublic static void main(String[] args) {\n    Dog aDog = new Dog(\"Max\");\n    Dog oldDog = aDog;\n\n    // we pass the object to foo\n    foo(aDog);\n    // aDog variable is still pointing to the \"Max\" dog when foo(...) returns\n    aDog.getName().equals(\"Max\"); // true\n    aDog.getName().equals(\"Fifi\"); // false\n    aDog == oldDog; // true\n}\n\npublic static void foo(Dog d) {\n    d.getName().equals(\"Max\"); // true\n    // change d inside of foo() to point to a new Dog instance \"Fifi\"\n    d = new Dog(\"Fifi\");\n    d.getName().equals(\"Fifi\"); // true\n}\n\n\nIn the example above aDog.getName() will still return \"Max\". The value aDog within main is not changed in the function foo with the Dog \"Fifi\" as the object reference is passed by value. If it were passed by reference, then the aDog.getName() in main would return \"Fifi\" after the call to foo.\n\nLikewise:\n\npublic static void main(String[] args) {\n    Dog aDog = new Dog(\"Max\");\n    Dog oldDog = aDog;\n\n    foo(aDog);\n    // when foo(...) returns, the name of the dog has been changed to \"Fifi\"\n    aDog.getName().equals(\"Fifi\"); // true\n    // but it is still the same dog:\n    aDog == oldDog; // true\n}\n\npublic static void foo(Dog d) {\n    d.getName().equals(\"Max\"); // true\n    // this changes the name of d to be \"Fifi\"\n    d.setName(\"Fifi\");\n}\n\n\nIn the above example, Fifi is the dog's name after call to foo(aDog) because the object's name was set inside of foo(...). Any operations that foo performs on d are such that, for all practical purposes, they are performed on aDog, but it is not possible to change the value of the variable aDog itself.\n\nShare\nImprove this answer\nFollow\nedited May 13 at 16:12\ncommunity wiki\n\n\n32 revs, 26 users 32%\nerlando","comments":["so what happens to \"Fifi\" in the 1st example? Does it cease to exist, was it never created, or does it exist in the heap but without a reference variable in the stack?","To me, saying that an object's reference is passed by value is the same as saying that the object is passed by reference. I'm a Java novice, but I presume that (in contrast) primitive data is pass by value.","@user36800: You're wrong. Did you work through the example with Fifi and look carefully through the results? Check that indeed foo(aDog); did not change aDog despite foo overwriting the value of d, showing that indeed all inputs to a function are passed by value.","@user36800: Well, both statements are wrong. To pass an object by reference would mean that if the function modifies the variable then it modifies the object itself. That is not what happens in Java; objects cannot be passed by reference, but instead one can only pass references as inputs to a function, and when a function performs d = new Dog(\"Fifi\"); it overwrites the input variable d, which stores a reference but is not 'the object passed by reference'. Contrast with &d in the function signature in C, which would be pass-by-reference. [cont]","@dbrewster i'm sorry but ... \"Fifi\" is not among us anymore"]},{"answer":"I just noticed you referenced my article.\n\nThe Java Spec says that everything in Java is pass-by-value. There is no such thing as \"pass-by-reference\" in Java.\n\nThe key to understanding this is that something like\n\nDog myDog;\n\n\nis not a Dog; it's actually a pointer to a Dog. The use of the term \"reference\" in Java is very misleading and is what causes most of the confusion here. What they call \"references\" act/feel more like what we'd call \"pointers\" in most other languages.\n\nWhat that means, is when you have\n\nDog myDog = new Dog(\"Rover\");\nfoo(myDog);\n\n\nyou're essentially passing the address of the created Dog object to the foo method.\n\n(I say essentially because Java pointers/references aren't direct addresses, but it's easiest to think of them that way.)\n\nSuppose the Dog object resides at memory address 42. This means we pass 42 to the method.\n\nif the Method were defined as\n\npublic void foo(Dog someDog) {\n    someDog.setName(\"Max\");     // AAA\n    someDog = new Dog(\"Fifi\");  // BBB\n    someDog.setName(\"Rowlf\");   // CCC\n}\n\n\nlet's look at what's happening.\n\nthe parameter someDog is set to the value 42\nat line \"AAA\"\nsomeDog is followed to the Dog it points to (the Dog object at address 42)\nthat Dog (the one at address 42) is asked to change his name to Max\nat line \"BBB\"\na new Dog is created. Let's say he's at address 74\nwe assign the parameter someDog to 74\nat line \"CCC\"\nsomeDog is followed to the Dog it points to (the Dog object at address 74)\nthat Dog (the one at address 74) is asked to change his name to Rowlf\nthen, we return\n\nNow let's think about what happens outside the method:\n\nDid myDog change?\n\nThere's the key.\n\nKeeping in mind that myDog is a pointer, and not an actual Dog, the answer is NO. myDog still has the value 42; it's still pointing to the original Dog (but note that because of line \"AAA\", its name is now \"Max\" - still the same Dog; myDog's value has not changed.)\n\nIt's perfectly valid to follow an address and change what's at the end of it; that does not change the variable, however.\n\nJava works exactly like C. You can assign a pointer, pass the pointer to a method, follow the pointer in the method and change the data that was pointed to. However, the caller will not see any changes you make to where that pointer points. (In a language with pass-by-reference semantics, the method function can change the pointer and the caller will see that change.)\n\nIn C++, Ada, Pascal and other languages that support pass-by-reference, you can actually change the variable that was passed.\n\nIf Java had pass-by-reference semantics, the foo method we defined above would have changed where myDog was pointing when it assigned someDog on line BBB.\n\nThink of reference parameters as being aliases for the variable passed in. When that alias is assigned, so is the variable that was passed in.\n\nShare\nImprove this answer\nFollow\nedited Jun 10 at 7:03\ncommunity wiki\n\n\n14 revs, 7 users 65%\nScott Stanchfield","comments":["Minor clarification question on the above example, so when creating new Dog at BBB at address 72, does this imply upon return the created Dog at 72 and it’s value is lost and reverts back to 42?","@ebresie javarevisited.blogspot.com/2015/09/….","@ebresie Mostly yes (I'll clarify the \"mostly\" in a moment). The only pointer to the new dog at 74 (I assume you meant 74 rather than 72) is the parameter to the foo function. When foo returns, all of its parameters are popped off the stack, so nothing is left pointing to 72 and it can be garbage collected. I say \"mostly\" as there is no \"revert\" happening; the pointer myDog in the caller was pointing to 42 all along and never changed, no matter what happened in the function, hence, no \"revert\".","@NiharGht Good point - I've clarified it (please comment again if it's still not clear)","Wow. Simple and elegant. I got the whole dilemma."]},{"answer":"Java always passes arguments by value, NOT by reference.\n\nLet me explain this through an example:\n\npublic class Main {\n\n     public static void main(String[] args) {\n          Foo f = new Foo(\"f\");\n          changeReference(f); // It won't change the reference!\n          modifyReference(f); // It will modify the object that the reference variable \"f\" refers to!\n     }\n\n     public static void changeReference(Foo a) {\n          Foo b = new Foo(\"b\");\n          a = b;\n     }\n\n     public static void modifyReference(Foo c) {\n          c.setAttribute(\"c\");\n     }\n\n}\n\n\nI will explain this in steps:\n\nDeclaring a reference named f of type Foo and assign it a new object of type Foo with an attribute \"f\".\n\nFoo f = new Foo(\"f\");\n\n\nFrom the method side, a reference of type Foo with a name a is declared and it's initially assigned null.\n\npublic static void changeReference(Foo a)\n\n\nAs you call the method changeReference, the reference a will be assigned the object which is passed as an argument.\n\nchangeReference(f);\n\n\nDeclaring a reference named b of type Foo and assign it a new object of type Foo with an attribute \"b\".\n\nFoo b = new Foo(\"b\");\n\n\na = b makes a new assignment to the reference a, not f, of the object whose attribute is \"b\".\n\nAs you call modifyReference(Foo c) method, a reference c is created and assigned the object with attribute \"f\".\n\nc.setAttribute(\"c\"); will change the attribute of the object that reference c points to it, and it's the same object that reference f points to it.\n\nI hope you understand now how passing objects as arguments works in Java :)\n\nShare\nImprove this answer\nFollow\nedited Dec 7 '20 at 10:37\ncommunity wiki\n\n\n8 revs, 8 users 74%\nEng.Fouad","comments":["Java always passes arguments by value, but what you are passing by value is a reference to an object, not a copy of the object. Simple eh?","I hope the Herbert Schildt book that I've learned Java from had taught this"]},{"answer":"Java is always pass by value, with no exceptions, ever.\n\nSo how is it that anyone can be at all confused by this, and believe that Java is pass by reference, or think they have an example of Java acting as pass by reference? The key point is that Java never provides direct access to the values of objects themselves, in any circumstances. The only access to objects is through a reference to that object. Because Java objects are always accessed through a reference, rather than directly, it is common to talk about fields and variables and method arguments as being objects, when pedantically they are only references to objects. The confusion stems from this (strictly speaking, incorrect) change in nomenclature.\n\nSo, when calling a method\n\nFor primitive arguments (int, long, etc.), the pass by value is the actual value of the primitive (for example, 3).\nFor objects, the pass by value is the value of the reference to the object.\n\nSo if you have doSomething(foo) and public void doSomething(Foo foo) { .. } the two Foos have copied references that point to the same objects.\n\nNaturally, passing by value a reference to an object looks very much like (and is indistinguishable in practice from) passing an object by reference.\n\nShare\nImprove this answer\nFollow\nedited Jan 22 '16 at 3:37\ncommunity wiki\n\n\n4 revs, 4 users 40%\nSCdF","comments":["JVMS 2.2 makes this pretty clear: There are ... two kinds of values that can be stored in variables, passed as arguments, returned by methods, and operated upon: primitive values and reference values.\" Object references are values. Everything is passed by value.","geeksforgeeks.org/g-fact-31-java-is-strictly-pass-by-value"]},{"answer":"This will give you some insights of how Java really works to the point that in your next discussion about Java passing by reference or passing by value you'll just smile :-)\n\nStep one please erase from your mind that word that starts with 'p' \"_ _ _ _ _ _ _\", especially if you come from other programming languages. Java and 'p' cannot be written in the same book, forum, or even txt.\n\nStep two remember that when you pass an Object into a method you're passing the Object reference and not the Object itself.\n\nStudent: Master, does this mean that Java is pass-by-reference?\nMaster: Grasshopper, No.\n\nNow think of what an Object's reference/variable does/is:\n\nA variable holds the bits that tell the JVM how to get to the referenced Object in memory (Heap).\nWhen passing arguments to a method you ARE NOT passing the reference variable, but a copy of the bits in the reference variable. Something like this: 3bad086a. 3bad086a represents a way to get to the passed object.\nSo you're just passing 3bad086a that it's the value of the reference.\nYou're passing the value of the reference and not the reference itself (and not the object).\nThis value is actually COPIED and given to the method.\n\nIn the following (please don't try to compile/execute this...):\n\n1. Person person;\n2. person = new Person(\"Tom\");\n3. changeName(person);\n4.\n5. //I didn't use Person person below as an argument to be nice\n6. static void changeName(Person anotherReferenceToTheSamePersonObject) {\n7.     anotherReferenceToTheSamePersonObject.setName(\"Jerry\");\n8. }\n\n\nWhat happens?\n\nThe variable person is created in line #1 and it's null at the beginning.\nA new Person Object is created in line #2, stored in memory, and the variable person is given the reference to the Person object. That is, its address. Let's say 3bad086a.\nThe variable person holding the address of the Object is passed to the function in line #3.\nIn line #4 you can listen to the sound of silence\nCheck the comment on line #5\nA method local variable -anotherReferenceToTheSamePersonObject- is created and then comes the magic in line #6:\nThe variable/reference person is copied bit-by-bit and passed to anotherReferenceToTheSamePersonObject inside the function.\nNo new instances of Person are created.\nBoth \"person\" and \"anotherReferenceToTheSamePersonObject\" hold the same value of 3bad086a.\nDon't try this but person==anotherReferenceToTheSamePersonObject would be true.\nBoth variables have IDENTICAL COPIES of the reference and they both refer to the same Person Object, the SAME Object on the Heap and NOT A COPY.\n\nA picture is worth a thousand words:\n\nNote that the anotherReferenceToTheSamePersonObject arrows is directed towards the Object and not towards the variable person!\n\nIf you didn't get it then just trust me and remember that it's better to say that Java is pass by value. Well, pass by reference value. Oh well, even better is pass-by-copy-of-the-variable-value! ;)\n\nNow feel free to hate me but note that given this there is no difference between passing primitive data types and Objects when talking about method arguments.\n\nYou always pass a copy of the bits of the value of the reference!\n\nIf it's a primitive data type these bits will contain the value of the primitive data type itself.\nIf it's an Object the bits will contain the value of the address that tells the JVM how to get to the Object.\n\nJava is pass-by-value because inside a method you can modify the referenced Object as much as you want but no matter how hard you try you'll never be able to modify the passed variable that will keep referencing (not p _ _ _ _ _ _ _) the same Object no matter what!\n\nThe changeName function above will never be able to modify the actual content (the bit values) of the passed reference. In other word changeName cannot make Person person refer to another Object.\n\nOf course you can cut it short and just say that Java is pass-by-value!\n\nShare\nImprove this answer\nFollow\nedited Jan 4 '18 at 10:17\ncommunity wiki\n\n\n3 revs, 2 users 95%\nGevorg","comments":["I tried this: <br /> File file = new File(\"C:/\"); changeFile(file); System.out.println(file.getAbsolutePath()); } public static void changeFile(File f) { f = new File(\"D:/\"); }`"]},{"answer":"Java passes references by value.\n\nSo you can't change the reference that gets passed in.\n\nShare\nImprove this answer\nFollow\nanswered Sep 2 '08 at 20:20\ncommunity wiki\n\n\nScArcher2","comments":[]},{"answer":"I feel like arguing about \"pass-by-reference vs pass-by-value\" is not super-helpful.\n\nIf you say, \"Java is pass-by-whatever (reference/value)\", in either case, you're not provide a complete answer. Here's some additional information that will hopefully aid in understanding what's happening in memory.\n\nCrash course on stack/heap before we get to the Java implementation: Values go on and off the stack in a nice orderly fashion, like a stack of plates at a cafeteria. Memory in the heap (also known as dynamic memory) is haphazard and disorganized. The JVM just finds space wherever it can, and frees it up as the variables that use it are no longer needed.\n\nOkay. First off, local primitives go on the stack. So this code:\n\nint x = 3;\nfloat y = 101.1f;\nboolean amIAwesome = true;\n\n\nresults in this:\n\nWhen you declare and instantiate an object. The actual object goes on the heap. What goes on the stack? The address of the object on the heap. C++ programmers would call this a pointer, but some Java developers are against the word \"pointer\". Whatever. Just know that the address of the object goes on the stack.\n\nLike so:\n\nint problems = 99;\nString name = \"Jay-Z\";\n\n\nAn array is an object, so it goes on the heap as well. And what about the objects in the array? They get their own heap space, and the address of each object goes inside the array.\n\nJButton[] marxBros = new JButton[3];\nmarxBros[0] = new JButton(\"Groucho\");\nmarxBros[1] = new JButton(\"Zeppo\");\nmarxBros[2] = new JButton(\"Harpo\");\n\n\nSo, what gets passed in when you call a method? If you pass in an object, what you're actually passing in is the address of the object. Some might say the \"value\" of the address, and some say it's just a reference to the object. This is the genesis of the holy war between \"reference\" and \"value\" proponents. What you call it isn't as important as that you understand that what's getting passed in is the address to the object.\n\nprivate static void shout(String name){\n    System.out.println(\"There goes \" + name + \"!\");\n}\n\npublic static void main(String[] args){\n    String hisName = \"John J. Jingleheimerschmitz\";\n    String myName = hisName;\n    shout(myName);\n}\n\n\nOne String gets created and space for it is allocated in the heap, and the address to the string is stored on the stack and given the identifier hisName, since the address of the second String is the same as the first, no new String is created and no new heap space is allocated, but a new identifier is created on the stack. Then we call shout(): a new stack frame is created and a new identifier, name is created and assigned the address of the already-existing String.\n\nSo, value, reference? You say \"potato\".\n\nShare\nImprove this answer\nFollow\nedited Jan 4 '18 at 16:18\ncommunity wiki\n\n\n6 revs, 4 users 97%\ncutmancometh","comments":["Such an awesome answer that even a fool like myself was able to understand. I would add also amend that \"pass by value\" literally means that the literal value in the stack is passed."]},{"answer":"Just to show the contrast, compare the following C++ and Java snippets:\n\nIn C++: Note: Bad code - memory leaks! But it demonstrates the point.\n\nvoid cppMethod(int val, int &ref, Dog obj, Dog &objRef, Dog *objPtr, Dog *&objPtrRef)\n{\n    val = 7; // Modifies the copy\n    ref = 7; // Modifies the original variable\n    obj.SetName(\"obj\"); // Modifies the copy of Dog passed\n    objRef.SetName(\"objRef\"); // Modifies the original Dog passed\n    objPtr->SetName(\"objPtr\"); // Modifies the original Dog pointed to \n                               // by the copy of the pointer passed.\n    objPtr = new Dog(\"newObjPtr\");  // Modifies the copy of the pointer, \n                                   // leaving the original object alone.\n    objPtrRef->SetName(\"objRefPtr\"); // Modifies the original Dog pointed to \n                                    // by the original pointer passed. \n    objPtrRef = new Dog(\"newObjPtrRef\"); // Modifies the original pointer passed\n}\n\nint main()\n{\n    int a = 0;\n    int b = 0;\n    Dog d0 = Dog(\"d0\");\n    Dog d1 = Dog(\"d1\");\n    Dog *d2 = new Dog(\"d2\");\n    Dog *d3 = new Dog(\"d3\");\n    cppMethod(a, b, d0, d1, d2, d3);\n    // a is still set to 0\n    // b is now set to 7\n    // d0 still have name \"d0\"\n    // d1 now has name \"objRef\"\n    // d2 now has name \"objPtr\"\n    // d3 now has name \"newObjPtrRef\"\n}\n\n\nIn Java,\n\npublic static void javaMethod(int val, Dog objPtr)\n{\n   val = 7; // Modifies the copy\n   objPtr.SetName(\"objPtr\") // Modifies the original Dog pointed to \n                            // by the copy of the pointer passed.\n   objPtr = new Dog(\"newObjPtr\");  // Modifies the copy of the pointer, \n                                  // leaving the original object alone.\n}\n\npublic static void main()\n{\n    int a = 0;\n    Dog d0 = new Dog(\"d0\");\n    javaMethod(a, d0);\n    // a is still set to 0\n    // d0 now has name \"objPtr\"\n}\n\n\nJava only has the two types of passing: by value for built-in types, and by value of the pointer for object types.\n\nShare\nImprove this answer\nFollow\nedited Sep 27 '16 at 14:42\ncommunity wiki\n\n\n4 revs, 4 users 94%\nEclipse","comments":["This shows that java is not pass by value as it doesn't copy the whole object onto the stack like C++ does, as shown in the example above - ..., Dog obj,...","No, Java passes references by value. That's why when you overwrite objPtr in the java example, the original Dog object doesn't change. But if modify the object being pointed to by objPtr, it does."]},{"answer":"Java passes references to objects by value.\n\nShare\nImprove this answer\nFollow\nanswered Sep 2 '08 at 20:23\ncommunity wiki\n\n\nJohn Channing","comments":["Please someone vote down this answer as it does not contain any explanation and smells copy answer from others! I have not enough reputation to vote down this useless answer.","The answer is concise, correct, and my own work. I answered the question in 2008, a decade before many of the longer and more elaborate answers which may be confusing you into thinking it was copied."]},{"answer":"Basically, reassigning Object parameters doesn't affect the argument, e.g.,\n\nprivate void foo(Object bar) {\n    bar = null;\n}\n\npublic static void main(String[] args) {\n    String baz = \"Hah!\";\n    foo(baz);\n    System.out.println(baz);\n}\n\n\nwill print out \"Hah!\" instead of null. The reason this works is because bar is a copy of the value of baz, which is just a reference to \"Hah!\". If it were the actual reference itself, then foo would have redefined baz to null.\n\nShare\nImprove this answer\nFollow\nedited Jul 10 '18 at 9:57\ncommunity wiki\n\n\n2 revs, 2 users 97%\nHank Gay","comments":[]},{"answer":"I can't believe that nobody mentioned Barbara Liskov yet. When she designed CLU in 1974, she ran into this same terminology problem, and she invented the term call by sharing (also known as call by object-sharing and call by object) for this specific case of \"call by value where the value is a reference\".\n\nShare\nImprove this answer\nFollow\nanswered Sep 7 '10 at 22:07\ncommunity wiki\n\n\nJörg W Mittag","comments":[]},{"answer":"The crux of the matter is that the word reference in the expression \"pass by reference\" means something completely different from the usual meaning of the word reference in Java.\n\nUsually in Java reference means a a reference to an object. But the technical terms pass by reference/value from programming language theory is talking about a reference to the memory cell holding the variable, which is something completely different.\n\nShare\nImprove this answer\nFollow\nedited Feb 6 '18 at 10:18\ncommunity wiki\n\n\n4 revs, 2 users 89%\nJacquesB","comments":[]},{"answer":"In java everything is reference, so when you have something like: Point pnt1 = new Point(0,0); Java does following:\n\nCreates new Point object\nCreates new Point reference and initialize that reference to point (refer to) on previously created Point object.\nFrom here, through Point object life, you will access to that object through pnt1 reference. So we can say that in Java you manipulate object through its reference.\n\n\nJava doesn't pass method arguments by reference; it passes them by value. I will use example from this site:\n\npublic static void tricky(Point arg1, Point arg2) {\n  arg1.x = 100;\n  arg1.y = 100;\n  Point temp = arg1;\n  arg1 = arg2;\n  arg2 = temp;\n}\npublic static void main(String [] args) {\n  Point pnt1 = new Point(0,0);\n  Point pnt2 = new Point(0,0);\n  System.out.println(\"X1: \" + pnt1.x + \" Y1: \" +pnt1.y); \n  System.out.println(\"X2: \" + pnt2.x + \" Y2: \" +pnt2.y);\n  System.out.println(\" \");\n  tricky(pnt1,pnt2);\n  System.out.println(\"X1: \" + pnt1.x + \" Y1:\" + pnt1.y); \n  System.out.println(\"X2: \" + pnt2.x + \" Y2: \" +pnt2.y);  \n}\n\n\nFlow of the program:\n\nPoint pnt1 = new Point(0,0);\nPoint pnt2 = new Point(0,0);\n\n\nCreating two different Point object with two different reference associated. \n\nSystem.out.println(\"X1: \" + pnt1.x + \" Y1: \" +pnt1.y); \nSystem.out.println(\"X2: \" + pnt2.x + \" Y2: \" +pnt2.y);\nSystem.out.println(\" \");\n\n\nAs expected output will be:\n\nX1: 0     Y1: 0\nX2: 0     Y2: 0\n\n\nOn this line 'pass-by-value' goes into the play...\n\n\ntricky(pnt1,pnt2);           public void tricky(Point arg1, Point arg2);\n\n\nReferences pnt1 and pnt2 are passed by value to the tricky method, which means that now yours references pnt1 and pnt2 have their copies named arg1 and arg2.So pnt1 and arg1 points to the same object. (Same for the pnt2 and arg2) \n\nIn the tricky method:\n\n arg1.x = 100;\n arg1.y = 100;\n\n\nNext in the tricky method\n\nPoint temp = arg1;\narg1 = arg2;\narg2 = temp;\n\n\nHere, you first create new temp Point reference which will point on same place like arg1 reference. Then you move reference arg1 to point to the same place like arg2 reference. Finally arg2 will point to the same place like temp.\n\nFrom here scope of tricky method is gone and you don't have access any more to the references: arg1, arg2, temp. But important note is that everything you do with these references when they are 'in life' will permanently affect object on which they are point to.\n\nSo after executing method tricky, when you return to main, you have this situation: \n\nSo now, completely execution of program will be:\n\nX1: 0         Y1: 0\nX2: 0         Y2: 0\nX1: 100       Y1: 100\nX2: 0         Y2: 0\n\nShare\nImprove this answer\nFollow\nedited Sep 16 '15 at 15:18\ncommunity wiki\n\n\n3 revs, 3 users 91%\nSrle","comments":[]},{"answer":"Java is always pass by value, not pass by reference\n\nFirst of all, we need to understand what pass by value and pass by reference are.\n\nPass by value means that you are making a copy in memory of the actual parameter's value that is passed in. This is a copy of the contents of the actual parameter.\n\nPass by reference (also called pass by address) means that a copy of the address of the actual parameter is stored.\n\nSometimes Java can give the illusion of pass by reference. Let's see how it works by using the example below:\n\npublic class PassByValue {\n    public static void main(String[] args) {\n        Test t = new Test();\n        t.name = \"initialvalue\";\n        new PassByValue().changeValue(t);\n        System.out.println(t.name);\n    }\n    \n    public void changeValue(Test f) {\n        f.name = \"changevalue\";\n    }\n}\n\nclass Test {\n    String name;\n}\n\n\nThe output of this program is:\n\nchangevalue\n\n\nLet's understand step by step:\n\nTest t = new Test();\n\n\nAs we all know it will create an object in the heap and return the reference value back to t. For example, suppose the value of t is 0x100234 (we don't know the actual JVM internal value, this is just an example) .\n\nnew PassByValue().changeValue(t);\n\n\nWhen passing reference t to the function it will not directly pass the actual reference value of object test, but it will create a copy of t and then pass it to the function. Since it is passing by value, it passes a copy of the variable rather than the actual reference of it. Since we said the value of t was 0x100234, both t and f will have the same value and hence they will point to the same object.\n\nIf you change anything in the function using reference f it will modify the existing contents of the object. That is why we got the output changevalue, which is updated in the function.\n\nTo understand this more clearly, consider the following example:\n\npublic class PassByValue {\n    public static void main(String[] args) {\n        Test t = new Test();\n        t.name = \"initialvalue\";\n        new PassByValue().changeRefence(t);\n        System.out.println(t.name);\n    }\n    \n    public void changeRefence(Test f) {\n        f = null;\n    }\n}\n\nclass Test {\n    String name;\n}\n\n\nWill this throw a NullPointerException? No, because it only passes a copy of the reference. In the case of passing by reference, it could have thrown a NullPointerException, as seen below:\n\nHopefully this will help.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n4 revs, 3 users 80%\nGanesh","comments":[]},{"answer":"There are already great answers that cover this. I wanted to make a small contribution by sharing a very simple example (which will compile) contrasting the behaviors between Pass-by-reference in c++ and Pass-by-value in Java.\n\nA few points:\n\nThe term \"reference\" is a overloaded with two separate meanings. In Java it simply means a pointer, but in the context of \"Pass-by-reference\" it means a handle to the original variable which was passed in.\nJava is Pass-by-value. Java is a descendent of C (among other languages). Before C, several (but not all) earlier languages like FORTRAN and COBOL supported PBR, but C did not. PBR allowed these other languages to make changes to the passed variables inside sub-routines. In order to accomplish the same thing (i.e. change the values of variables inside functions), C programmers passed pointers to variables into functions. Languages inspired by C, such as Java, borrowed this idea and continue to pass pointer to methods as C did, except that Java calls its pointers References. Again, this is a different use of the word \"Reference\" than in \"Pass-By-Reference\".\nC++ allows Pass-by-reference by declaring a reference parameter using the \"&\" character (which happens to be the same character used to indicate \"the address of a variable\" in both C and C++). For example, if we pass in a pointer by reference, the parameter and the argument are not just pointing to the same object. Rather, they are the same variable. If one gets set to a different address or to null, so does the other.\nIn the C++ example below I'm passing a pointer to a null terminated string by reference. And in the Java example below I'm passing a Java reference to a String (again, the same as a pointer to a String) by value. Notice the output in the comments.\n\nC++ pass by reference example:\n\nusing namespace std;\n#include <iostream>\n\nvoid change (char *&str){   // the '&' makes this a reference parameter\n    str = NULL;\n}\n\nint main()\n{\n    char *str = \"not Null\";\n    change(str);\n    cout<<\"str is \" << str;      // ==>str is <null>\n}\n\n\nJava pass \"a Java reference\" by value example\n\npublic class ValueDemo{\n\n    public void change (String str){\n        str = null;\n    }\n\n     public static void main(String []args){\n        ValueDemo vd = new ValueDemo();\n        String str = \"not null\";\n        vd.change(str);\n        System.out.println(\"str is \" + str);    // ==> str is not null!!\n                                                // Note that if \"str\" was\n                                                // passed-by-reference, it\n                                                // WOULD BE NULL after the\n                                                // call to change().\n     }\n}\n\n\nEDIT\n\nSeveral people have written comments which seem to indicate that either they are not looking at my examples or they don't get the c++ example. Not sure where the disconnect is, but guessing the c++ example is not clear. I'm posting the same example in pascal because I think pass-by-reference looks cleaner in pascal, but I could be wrong. I might just be confusing people more; I hope not.\n\nIn pascal, parameters passed-by-reference are called \"var parameters\". In the procedure setToNil below, please note the keyword 'var' which precedes the parameter 'ptr'. When a pointer is passed to this procedure, it will be passed by reference. Note the behavior: when this procedure sets ptr to nil (that's pascal speak for NULL), it will set the argument to nil--you can't do that in Java.\n\nprogram passByRefDemo;\ntype \n   iptr = ^integer;\nvar\n   ptr: iptr;\n\n   procedure setToNil(var ptr : iptr);\n   begin\n       ptr := nil;\n   end;\n\nbegin\n   new(ptr);\n   ptr^ := 10;\n   setToNil(ptr);\n   if (ptr = nil) then\n       writeln('ptr seems to be nil');     { ptr should be nil, so this line will run. }\nend.\n\n\nEDIT 2\n\nSome excerpts from \"THE Java Programming Language\" by Ken Arnold, James Gosling (the guy who invented Java), and David Holmes, chapter 2, section 2.6.5\n\nAll parameters to methods are passed \"by value\". In other words, values of parameter variables in a method are copies of the invoker specified as arguments.\n\nHe goes on to make the same point regarding objects . . .\n\nYou should note that when the parameter is an object reference, it is the object reference-not the object itself-that is passed \"by value\".\n\nAnd towards the end of the same section he makes a broader statement about java being only pass by value and never pass by reference.\n\nThe Java programming language does not pass objects by reference; it passes object references by value. Because two copies of the same reference refer to the same actual object, changes made through one reference variable are visible through the other. There is exactly one parameter passing mode-pass by value-and that helps keep things simple.\n\nThis section of the book has a great explanation of parameter passing in Java and of the distinction between pass-by-reference and pass-by-value and it's by the creator of Java. I would encourage anyone to read it, especially if you're still not convinced.\n\nI think the difference between the two models is very subtle and unless you've done programming where you actually used pass-by-reference, it's easy to miss where two models differ.\n\nI hope this settles the debate, but probably won't.\n\nEDIT 3\n\nI might be a little obsessed with this post. Probably because I feel that the makers of Java inadvertently spread misinformation. If instead of using the word \"reference\" for pointers they had used something else, say dingleberry, there would've been no problem. You could say, \"Java passes dingleberries by value and not by reference\", and nobody would be confused.\n\nThat's the reason only Java developers have issue with this. They look at the word \"reference\" and think they know exactly what that means, so they don't even bother to consider the opposing argument.\n\nAnyway, I noticed a comment in an older post, which made a balloon analogy which I really liked. So much so that I decided to glue together some clip-art to make a set of cartoons to illustrate the point.\n\nPassing a reference by value--Changes to the reference are not reflected in the caller's scope, but the changes to the object are. This is because the reference is copied, but the both the original and the copy refer to the same object. \n\nPass by reference--There is no copy of the reference. Single reference is shared by both the caller and the function being called. Any changes to the reference or the Object's data are reflected in the caller's scope. \n\nEDIT 4\n\nI have seen posts on this topic which describe the low level implementation of parameter passing in Java, which I think is great and very helpful because it makes an abstract idea concrete. However, to me the question is more about the behavior described in the language specification than about the technical implementation of the behavior. This is an exerpt from the Java Language Specification, section 8.4.1 :\n\nWhen the method or constructor is invoked (§15.12), the values of the actual argument expressions initialize newly created parameter variables, each of the declared type, before execution of the body of the method or constructor. The Identifier that appears in the DeclaratorId may be used as a simple name in the body of the method or constructor to refer to the formal parameter.\n\nWhich means, java creates a copy of the passed parameters before executing a method. Like most people who studied compilers in college, I used \"The Dragon Book\" which is THE compilers book. It has a good description of \"Call-by-value\" and \"Call-by-Reference\" in Chapter 1. The Call-by-value description matches up with Java Specs exactly.\n\nBack when I studied compilers-in the 90's, I used the first edition of the book from 1986 which pre-dated Java by about 9 or 10 years. However, I just ran across a copy of the 2nd Eddition from 2007 which actually mentions Java! Section 1.6.6 labeled \"Parameter Passing Mechanisms\" describes parameter passing pretty nicely. Here is an excerpt under the heading \"Call-by-value\" which mentions Java:\n\nIn call-by-value, the actual parameter is evaluated (if it is an expression) or copied (if it is a variable). The value is placed in the location belonging to the corresponding formal parameter of the called procedure. This method is used in C and Java, and is a common option in C++ , as well as in most other languages.\n\nShare\nImprove this answer\nFollow\nedited Apr 4 '20 at 19:05\ncommunity wiki\n\n\n21 revs\nSanjeev","comments":[]},{"answer":"Java is a pass by value(stack memory)\n\nHow it works\n\nLet's first understand that where java stores primitive data type and object data type.\n\nPrimitive data types itself and object references are stored in the stack. Objects themselves are stored in the heap.\n\nIt means, Stack memory stores primitive data types and also the addresses of objects.\n\nAnd you always pass a copy of the bits of the value of the reference.\n\nIf it's a primitive data type then these copied bits contain the value of the primitive data type itself, That's why when we change the value of argument inside the method then it does not reflect the changes outside.\n\nIf it's an object data type like Foo foo=new Foo() then in this case copy of the address of the object passes like file shortcut , suppose we have a text file abc.txt at C:\\desktop and suppose we make shortcut of the same file and put this inside C:\\desktop\\abc-shortcut so when you access the file from C:\\desktop\\abc.txt and write 'Stack Overflow' and close the file and again you open the file from shortcut then you write ' is the largest online community for programmers to learn' then total file change will be 'Stack Overflow is the largest online community for programmers to learn' which means it doesn't matter from where you open the file , each time we were accessing the same file , here we can assume Foo as a file and suppose foo stored at 123hd7h(original address like C:\\desktop\\abc.txt ) address and 234jdid(copied address like C:\\desktop\\abc-shortcut which actually contains the original address of the file inside) .. So for better understanding make shortcut file and feel.\n\nShare\nImprove this answer\nFollow\nedited Jun 12 at 7:13\ncommunity wiki\n\n\n23 revs\nHimanshu arora","comments":["Good job man, You was make it clearly."]},{"answer":"A reference is always a value when represented, no matter what language you use.\n\nGetting an outside of the box view, let's look at Assembly or some low level memory management. At the CPU level a reference to anything immediately becomes a value if it gets written to memory or to one of the CPU registers. (That is why pointer is a good definition. It is a value, which has a purpose at the same time).\n\nData in memory has a Location and at that location there is a value (byte,word, whatever). In Assembly we have a convenient solution to give a Name to certain Location (aka variable), but when compiling the code, the assembler simply replaces Name with the designated location just like your browser replaces domain names with IP addresses.\n\nDown to the core it is technically impossible to pass a reference to anything in any language without representing it (when it immediately becomes a value).\n\nLets say we have a variable Foo, its Location is at the 47th byte in memory and its Value is 5. We have another variable Ref2Foo which is at 223rd byte in memory, and its value will be 47. This Ref2Foo might be a technical variable, not explicitly created by the program. If you just look at 5 and 47 without any other information, you will see just two Values. If you use them as references then to reach to 5 we have to travel:\n\n(Name)[Location] -> [Value at the Location]\n---------------------\n(Ref2Foo)[223]  -> 47\n(Foo)[47]       -> 5\n\n\nThis is how jump-tables work.\n\nIf we want to call a method/function/procedure with Foo's value, there are a few possible way to pass the variable to the method, depending on the language and its several method invocation modes:\n\n5 gets copied to one of the CPU registers (ie. EAX).\n5 gets PUSHd to the stack.\n47 gets copied to one of the CPU registers\n47 PUSHd to the stack.\n223 gets copied to one of the CPU registers.\n223 gets PUSHd to the stack.\n\nIn every cases above a value - a copy of an existing value - has been created, it is now upto the receiving method to handle it. When you write \"Foo\" inside the method, it is either read out from EAX, or automatically dereferenced, or double dereferenced, the process depends on how the language works and/or what the type of Foo dictates. This is hidden from the developer until she circumvents the dereferencing process. So a reference is a value when represented, because a reference is a value that has to be processed (at language level).\n\nNow we have passed Foo to the method:\n\nin case 1. and 2. if you change Foo (Foo = 9) it only affects local scope as you have a copy of the Value. From inside the method we cannot even determine where in memory the original Foo was located.\nin case 3. and 4. if you use default language constructs and change Foo (Foo = 11), it could change Foo globally (depends on the language, ie. Java or like Pascal's procedure findMin(x, y, z: integer;var m: integer);). However if the language allows you to circumvent the dereference process, you can change 47, say to 49. At that point Foo seems to have been changed if you read it, because you have changed the local pointer to it. And if you were to modify this Foo inside the method (Foo = 12) you will probably FUBAR the execution of the program (aka. segfault) because you will write to a different memory than expected, you can even modify an area that is destined to hold executable program and writing to it will modify running code (Foo is now not at 47). BUT Foo's value of 47 did not change globally, only the one inside the method, because 47 was also a copy to the method.\nin case 5. and 6. if you modify 223 inside the method it creates the same mayhem as in 3. or 4. (a pointer, pointing to a now bad value, that is again used as a pointer) but this is still a local problem, as 223 was copied. However if you are able to dereference Ref2Foo (that is 223), reach to and modify the pointed value 47, say, to 49, it will affect Foo globally, because in this case the methods got a copy of 223 but the referenced 47 exists only once, and changing that to 49 will lead every Ref2Foo double-dereferencing to a wrong value.\n\nNitpicking on insignificant details, even languages that do pass-by-reference will pass values to functions, but those functions know that they have to use it for dereferencing purposes. This pass-the-reference-as-value is just hidden from the programmer because it is practically useless and the terminology is only pass-by-reference.\n\nStrict pass-by-value is also useless, it would mean that a 100 Mbyte array should have to be copied every time we call a method with the array as argument, therefore Java cannot be stricly pass-by-value. Every language would pass a reference to this huge array (as a value) and either employs copy-on-write mechanism if that array can be changed locally inside the method or allows the method (as Java does) to modify the array globally (from the caller's view) and a few languages allows to modify the Value of the reference itself.\n\nSo in short and in Java's own terminology, Java is pass-by-value where value can be: either a real value or a value that is a representation of a reference.\n\nShare\nImprove this answer\nFollow\nedited Dec 28 '15 at 7:36\ncommunity wiki\n\n\n6 revs\nkaratedog","comments":[]},{"answer":"As far as I know, Java only knows call by value. This means for primitive datatypes you will work with an copy and for objects you will work with an copy of the reference to the objects. However I think there are some pitfalls; for example, this will not work:\n\npublic static void swap(StringBuffer s1, StringBuffer s2) {\n    StringBuffer temp = s1;\n    s1 = s2;\n    s2 = temp;\n}\n\n\npublic static void main(String[] args) {\n    StringBuffer s1 = new StringBuffer(\"Hello\");\n    StringBuffer s2 = new StringBuffer(\"World\");\n    swap(s1, s2);\n    System.out.println(s1);\n    System.out.println(s2);\n}\n\n\nThis will populate Hello World and not World Hello because in the swap function you use copys which have no impact on the references in the main. But if your objects are not immutable you can change it for example:\n\npublic static void appendWorld(StringBuffer s1) {\n    s1.append(\" World\");\n}\n\npublic static void main(String[] args) {\n    StringBuffer s = new StringBuffer(\"Hello\");\n    appendWorld(s);\n    System.out.println(s);\n}\n\n\nThis will populate Hello World on the command line. If you change StringBuffer into String it will produce just Hello because String is immutable. For example:\n\npublic static void appendWorld(String s){\n    s = s+\" World\";\n}\n\npublic static void main(String[] args) {\n    String s = new String(\"Hello\");\n    appendWorld(s);\n    System.out.println(s);\n}\n\n\nHowever you could make a wrapper for String like this which would make it able to use it with Strings:\n\nclass StringWrapper {\n    public String value;\n\n    public StringWrapper(String value) {\n        this.value = value;\n    }\n}\n\npublic static void appendWorld(StringWrapper s){\n    s.value = s.value +\" World\";\n}\n\npublic static void main(String[] args) {\n    StringWrapper s = new StringWrapper(\"Hello\");\n    appendWorld(s);\n    System.out.println(s.value);\n}\n\n\nedit: i believe this is also the reason to use StringBuffer when it comes to \"adding\" two Strings because you can modifie the original object which u can't with immutable objects like String is.\n\nShare\nImprove this answer\nFollow\nedited Apr 2 '09 at 17:58\ncommunity wiki\n\n\n4 revs, 2 users 76%\nkukudas","comments":[]},{"answer":"No, it's not pass by reference.\n\nJava is pass by value according to the Java Language Specification:\n\nWhen the method or constructor is invoked (§15.12), the values of the actual argument expressions initialize newly created parameter variables, each of the declared type, before execution of the body of the method or constructor. The Identifier that appears in the DeclaratorId may be used as a simple name in the body of the method or constructor to refer to the formal parameter.\n\nShare\nImprove this answer\nFollow\nedited Aug 22 '15 at 5:50\ncommunity wiki\n\n\n3 revs, 3 users 82%\nrorrohprog","comments":[]},{"answer":"Let me try to explain my understanding with the help of four examples. Java is pass-by-value, and not pass-by-reference\n\n/**\n\nPass By Value\n\nIn Java, all parameters are passed by value, i.e. assigning a method argument is not visible to the caller.\n\n*/\n\nExample 1:\n\npublic class PassByValueString {\n    public static void main(String[] args) {\n        new PassByValueString().caller();\n    }\n\n    public void caller() {\n        String value = \"Nikhil\";\n        boolean valueflag = false;\n        String output = method(value, valueflag);\n        /*\n         * 'output' is insignificant in this example. we are more interested in\n         * 'value' and 'valueflag'\n         */\n        System.out.println(\"output : \" + output);\n        System.out.println(\"value : \" + value);\n        System.out.println(\"valueflag : \" + valueflag);\n\n    }\n\n    public String method(String value, boolean valueflag) {\n        value = \"Anand\";\n        valueflag = true;\n        return \"output\";\n    }\n}\n\n\nResult\n\noutput : output\nvalue : Nikhil\nvalueflag : false\n\n\nExample 2:\n\n/** * * Pass By Value * */\n\npublic class PassByValueNewString {\n    public static void main(String[] args) {\n        new PassByValueNewString().caller();\n    }\n\n    public void caller() {\n        String value = new String(\"Nikhil\");\n        boolean valueflag = false;\n        String output = method(value, valueflag);\n        /*\n         * 'output' is insignificant in this example. we are more interested in\n         * 'value' and 'valueflag'\n         */\n        System.out.println(\"output : \" + output);\n        System.out.println(\"value : \" + value);\n        System.out.println(\"valueflag : \" + valueflag);\n\n    }\n\n    public String method(String value, boolean valueflag) {\n        value = \"Anand\";\n        valueflag = true;\n        return \"output\";\n    }\n}\n\n\nResult\n\noutput : output\nvalue : Nikhil\nvalueflag : false\n\n\nExample 3:\n\n/** This 'Pass By Value has a feeling of 'Pass By Reference'\n\nSome people say primitive types and 'String' are 'pass by value' and objects are 'pass by reference'.\n\nBut from this example, we can understand that it is infact pass by value only, keeping in mind that here we are passing the reference as the value. ie: reference is passed by value. That's why are able to change and still it holds true after the local scope. But we cannot change the actual reference outside the original scope. what that means is demonstrated by next example of PassByValueObjectCase2.\n\n*/\n\npublic class PassByValueObjectCase1 {\n\n    private class Student {\n        int id;\n        String name;\n        public Student() {\n        }\n        public Student(int id, String name) {\n            super();\n            this.id = id;\n            this.name = name;\n        }\n        public int getId() {\n            return id;\n        }\n        public void setId(int id) {\n            this.id = id;\n        }\n        public String getName() {\n            return name;\n        }\n        public void setName(String name) {\n            this.name = name;\n        }\n        @Override\n        public String toString() {\n            return \"Student [id=\" + id + \", name=\" + name + \"]\";\n        }\n    }\n\n    public static void main(String[] args) {\n        new PassByValueObjectCase1().caller();\n    }\n\n    public void caller() {\n        Student student = new Student(10, \"Nikhil\");\n        String output = method(student);\n        /*\n         * 'output' is insignificant in this example. we are more interested in\n         * 'student'\n         */\n        System.out.println(\"output : \" + output);\n        System.out.println(\"student : \" + student);\n    }\n\n    public String method(Student student) {\n        student.setName(\"Anand\");\n        return \"output\";\n    }\n}\n\n\nResult\n\noutput : output\nstudent : Student [id=10, name=Anand]\n\n\nExample 4:\n\n/**\n\nIn addition to what was mentioned in Example3 (PassByValueObjectCase1.java), we cannot change the actual reference outside the original scope.\"\n\nNote: I am not pasting the code for private class Student. The class definition for Student is same as Example3.\n\n*/\n\npublic class PassByValueObjectCase2 {\n\n    public static void main(String[] args) {\n        new PassByValueObjectCase2().caller();\n    }\n\n    public void caller() {\n        // student has the actual reference to a Student object created\n        // can we change this actual reference outside the local scope? Let's see\n        Student student = new Student(10, \"Nikhil\");\n        String output = method(student);\n        /*\n         * 'output' is insignificant in this example. we are more interested in\n         * 'student'\n         */\n        System.out.println(\"output : \" + output);\n        System.out.println(\"student : \" + student); // Will it print Nikhil or Anand?\n    }\n\n    public String method(Student student) {\n        student = new Student(20, \"Anand\");\n        return \"output\";\n    }\n\n}\n\n\nResult\n\noutput : output\nstudent : Student [id=10, name=Nikhil]\n\nShare\nImprove this answer\nFollow\nedited May 12 '15 at 21:30\ncommunity wiki\n\n\n2 revs\nspiderman","comments":[]},{"answer":"You can never pass by reference in Java, and one of the ways that is obvious is when you want to return more than one value from a method call. Consider the following bit of code in C++:\n\nvoid getValues(int& arg1, int& arg2) {\n    arg1 = 1;\n    arg2 = 2;\n}\nvoid caller() {\n    int x;\n    int y;\n    getValues(x, y);\n    cout << \"Result: \" << x << \" \" << y << endl;\n}\n\n\nSometimes you want to use the same pattern in Java, but you can't; at least not directly. Instead you could do something like this:\n\nvoid getValues(int[] arg1, int[] arg2) {\n    arg1[0] = 1;\n    arg2[0] = 2;\n}\nvoid caller() {\n    int[] x = new int[1];\n    int[] y = new int[1];\n    getValues(x, y);\n    System.out.println(\"Result: \" + x[0] + \" \" + y[0]);\n}\n\n\nAs was explained in previous answers, in Java you're passing a pointer to the array as a value into getValues. That is enough, because the method then modifies the array element, and by convention you're expecting element 0 to contain the return value. Obviously you can do this in other ways, such as structuring your code so this isn't necessary, or constructing a class that can contain the return value or allow it to be set. But the simple pattern available to you in C++ above is not available in Java.\n\nShare\nImprove this answer\nFollow\nanswered Mar 8 '09 at 6:28\ncommunity wiki\n\n\nJared Oberhaus","comments":[]},{"answer":"I thought I'd contribute this answer to add more details from the Specifications.\n\nFirst, What's the difference between passing by reference vs. passing by value?\n\nPassing by reference means the called functions' parameter will be the same as the callers' passed argument (not the value, but the identity - the variable itself).\n\nPass by value means the called functions' parameter will be a copy of the callers' passed argument.\n\nOr from wikipedia, on the subject of pass-by-reference\n\nIn call-by-reference evaluation (also referred to as pass-by-reference), a function receives an implicit reference to a variable used as argument, rather than a copy of its value. This typically means that the function can modify (i.e. assign to) the variable used as argument—something that will be seen by its caller.\n\nAnd on the subject of pass-by-value\n\nIn call-by-value, the argument expression is evaluated, and the resulting value is bound to the corresponding variable in the function [...]. If the function or procedure is able to assign values to its parameters, only its local copy is assigned [...].\n\nSecond, we need to know what Java uses in its method invocations. The Java Language Specification states\n\nWhen the method or constructor is invoked (§15.12), the values of the actual argument expressions initialize newly created parameter variables, each of the declared type, before execution of the body of the method or constructor.\n\nSo it assigns (or binds) the value of the argument to the corresponding parameter variable.\n\nWhat is the value of the argument?\n\nLet's consider reference types, the Java Virtual Machine Specification states\n\nThere are three kinds of reference types: class types, array types, and interface types. Their values are references to dynamically created class instances, arrays, or class instances or arrays that implement interfaces, respectively.\n\nThe Java Language Specification also states\n\nThe reference values (often just references) are pointers to these objects, and a special null reference, which refers to no object.\n\nThe value of an argument (of some reference type) is a pointer to an object. Note that a variable, an invocation of a method with a reference type return type, and an instance creation expression (new ...) all resolve to a reference type value.\n\nSo\n\npublic void method (String param) {}\n...\nString var = new String(\"ref\");\nmethod(var);\nmethod(var.toString());\nmethod(new String(\"ref\"));\n\n\nall bind the value of a reference to a String instance to the method's newly created parameter, param. This is exactly what the definition of pass-by-value describes. As such, Java is pass-by-value.\n\nThe fact that you can follow the reference to invoke a method or access a field of the referenced object is completely irrelevant to the conversation. The definition of pass-by-reference was\n\nThis typically means that the function can modify (i.e. assign to) the variable used as argument—something that will be seen by its caller.\n\nIn Java, modifying the variable means reassigning it. In Java, if you reassigned the variable within the method, it would go unnoticed to the caller. Modifying the object referenced by the variable is a different concept entirely.\n\nPrimitive values are also defined in the Java Virtual Machine Specification, here. The value of the type is the corresponding integral or floating point value, encoded appropriately (8, 16, 32, 64, etc. bits).\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:18\ncommunity wiki\n\n\n3 revs\nSotirios Delimanolis","comments":[]},{"answer":"In Java only references are passed and are passed by value:\n\nJava arguments are all passed by value (the reference is copied when used by the method) :\n\nIn the case of primitive types, Java behaviour is simple: The value is copied in another instance of the primitive type.\n\nIn case of Objects, this is the same: Object variables are pointers (buckets) holding only Object’s address that was created using the \"new\" keyword, and are copied like primitive types.\n\nThe behaviour can appear different from primitive types: Because the copied object-variable contains the same address (to the same Object). Object's content/members might still be modified within a method and later access outside, giving the illusion that the (containing) Object itself was passed by reference.\n\n\"String\" Objects appear to be a good counter-example to the urban legend saying that \"Objects are passed by reference\":\n\nIn effect, using a method, you will never be able, to update the value of a String passed as argument:\n\nA String Object, holds characters by an array declared final that can't be modified. Only the address of the Object might be replaced by another using \"new\". Using \"new\" to update the variable, will not let the Object be accessed from outside, since the variable was initially passed by value and copied.\n\nShare\nImprove this answer\nFollow\nedited Jan 22 '20 at 19:54\ncommunity wiki\n\n\n7 revs\nuser1767316","comments":[]},{"answer":"The distinction, or perhaps just the way I remember as I used to be under the same impression as the original poster is this: Java is always pass by value. All objects( in Java, anything except for primitives) in Java are references. These references are passed by value.\n\nShare\nImprove this answer\nFollow\nedited Apr 30 '14 at 4:50\ncommunity wiki\n\n\n2 revs, 2 users 50%\nshsteimer","comments":[]},{"answer":"As many people mentioned it before, Java is always pass-by-value\n\nHere is another example that will help you understand the difference (the classic swap example):\n\npublic class Test {\n  public static void main(String[] args) {\n    Integer a = new Integer(2);\n    Integer b = new Integer(3);\n    System.out.println(\"Before: a = \" + a + \", b = \" + b);\n    swap(a,b);\n    System.out.println(\"After: a = \" + a + \", b = \" + b);\n  }\n\n  public static swap(Integer iA, Integer iB) {\n    Integer tmp = iA;\n    iA = iB;\n    iB = tmp;\n  }\n}\n\n\nPrints:\n\nBefore: a = 2, b = 3\nAfter: a = 2, b = 3\n\nThis happens because iA and iB are new local reference variables that have the same value of the passed references (they point to a and b respectively). So, trying to change the references of iA or iB will only change in the local scope and not outside of this method.\n\nShare\nImprove this answer\nFollow\nanswered Sep 3 '08 at 20:01\ncommunity wiki\n\n\npek","comments":[]},{"answer":"I always think of it as \"pass by copy\". It is a copy of the value be it primitive or reference. If it is a primitive it is a copy of the bits that are the value and if it is an Object it is a copy of the reference.\n\npublic class PassByCopy{\n    public static void changeName(Dog d){\n        d.name = \"Fido\";\n    }\n    public static void main(String[] args){\n        Dog d = new Dog(\"Maxx\");\n        System.out.println(\"name= \"+ d.name);\n        changeName(d);\n        System.out.println(\"name= \"+ d.name);\n    }\n}\nclass Dog{\n    public String name;\n    public Dog(String s){\n        this.name = s;\n    }\n}\n\n\noutput of java PassByCopy:\n\nname= Maxx\nname= Fido\n\nPrimitive wrapper classes and Strings are immutable so any example using those types will not work the same as other types/objects.\n\nShare\nImprove this answer\nFollow\nedited Jan 12 '09 at 20:47\ncommunity wiki\n\n\n3 revs, 2 users 71%\nSWD","comments":[]},{"answer":"Unlike some other languages, Java does not allow you to choose between pass-by-value and pass-by-reference—all arguments are passed by value. A method call can pass two types of values to a method—copies of primitive values (e.g., values of int and double) and copies of references to objects.\n\nWhen a method modifies a primitive-type parameter, changes to the parameter have no effect on the original argument value in the calling method.\n\nWhen it comes to objects, objects themselves cannot be passed to methods. So we pass the reference(address) of the object. We can manipulate the original object using this reference.\n\nHow Java creates and stores objects: When we create an object we store the object’s address in a reference variable. Let's analyze the following statement.\n\nAccount account1 = new Account();\n\n\n“Account account1” is the type and name of the reference variable, “=” is the assignment operator, “new” asks for the required amount of space from the system. The constructor to the right of keyword new which creates the object is called implicitly by the keyword new. Address of the created object(result of right value, which is an expression called \"class instance creation expression\") is assigned to the left value (which is a reference variable with a name and a type specified) using the assign operator.\n\nAlthough an object’s reference is passed by value, a method can still interact with the referenced object by calling its public methods using the copy of the object’s reference. Since the reference stored in the parameter is a copy of the reference that was passed as an argument, the parameter in the called method and the argument in the calling method refer to the same object in memory.\n\nPassing references to arrays, instead of the array objects themselves, makes sense for performance reasons. Because everything in Java is passed by value, if array objects were passed, a copy of each element would be passed. For large arrays, this would waste time and consume considerable storage for the copies of the elements.\n\nIn the image below you can see we have two reference variables(These are called pointers in C/C++, and I think that term makes it easier to understand this feature.) in the main method. Primitive and reference variables are kept in stack memory(left side in images below). array1 and array2 reference variables \"point\" (as C/C++ programmers call it) or reference to a and b arrays respectively, which are objects (values these reference variables hold are addresses of objects) in heap memory (right side in images below).\n\nIf we pass the value of array1 reference variable as an argument to the reverseArray method, a reference variable is created in the method and that reference variable starts pointing to the same array (a).\n\npublic class Test\n{\n    public static void reverseArray(int[] array1)\n    {\n        // ...\n    }\n\n    public static void main(String[] args)\n    {\n        int[] array1 = { 1, 10, -7 };\n        int[] array2 = { 5, -190, 0 };\n\n        reverseArray(array1);\n    }\n}\n\n\nSo, if we say\n\narray1[0] = 5;\n\n\nin reverseArray method, it will make a change in array a.\n\nWe have another reference variable in reverseArray method (array2) that points to an array c. If we were to say\n\narray1 = array2;\n\n\nin reverseArray method, then the reference variable array1 in method reverseArray would stop pointing to array a and start pointing to array c (Dotted line in second image).\n\nIf we return value of reference variable array2 as the return value of method reverseArray and assign this value to reference variable array1 in main method, array1 in main will start pointing to array c.\n\nSo let's write all the things we have done at once now.\n\npublic class Test\n{\n    public static int[] reverseArray(int[] array1)\n    {\n        int[] array2 = { -7, 0, -1 };\n\n        array1[0] = 5; // array a becomes 5, 10, -7\n\n        array1 = array2; /* array1 of reverseArray starts\n          pointing to c instead of a (not shown in image below) */\n        return array2;\n    }\n\n    public static void main(String[] args)\n    {\n        int[] array1 = { 1, 10, -7 };\n        int[] array2 = { 5, -190, 0 };\n\n        array1 = reverseArray(array1); /* array1 of \n         main starts pointing to c instead of a */\n    }\n}\n\n\nAnd now that reverseArray method is over, its reference variables(array1 and array2) are gone. Which means we now only have the two reference variables in main method array1 and array2 which point to c and b arrays respectively. No reference variable is pointing to object (array) a. So it is eligible for garbage collection.\n\nYou could also assign value of array2 in main to array1. array1 would start pointing to b.\n\nShare\nImprove this answer\nFollow\nedited May 2 '20 at 20:18\ncommunity wiki\n\n\n15 revs, 3 users 76%\nMichael","comments":[]},{"answer":"Java has only pass by value. A very simple example to validate this.\n\npublic void test() {\n    MyClass obj = null;\n    init(obj);\n    //After calling init method, obj still points to null\n    //this is because obj is passed as value and not as reference.\n}\nprivate void init(MyClass objVar) {\n    objVar = new MyClass();\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 29 '17 at 4:31\ncommunity wiki\n\n\n2 revs, 2 users 86%\nGaurav","comments":[]},{"answer":"To make a long story short, Java objects have some very peculiar properties.\n\nIn general, Java has primitive types (int, bool, char, double, etc) that are passed directly by value. Then Java has objects (everything that derives from java.lang.Object). Objects are actually always handled through a reference (a reference being a pointer that you can't touch). That means that in effect, objects are passed by reference, as the references are normally not interesting. It does however mean that you cannot change which object is pointed to as the reference itself is passed by value.\n\nDoes this sound strange and confusing? Let's consider how C implements pass by reference and pass by value. In C, the default convention is pass by value. void foo(int x) passes an int by value. void foo(int *x) is a function that does not want an int a, but a pointer to an int: foo(&a). One would use this with the & operator to pass a variable address.\n\nTake this to C++, and we have references. References are basically (in this context) syntactic sugar that hide the pointer part of the equation: void foo(int &x) is called by foo(a), where the compiler itself knows that it is a reference and the address of the non-reference a should be passed. In Java, all variables referring to objects are actually of reference type, in effect forcing call by reference for most intends and purposes without the fine grained control (and complexity) afforded by, for example, C++.\n\nShare\nImprove this answer\nFollow\nedited May 4 '14 at 9:33\ncommunity wiki\n\n\n3 revs, 2 users 65%\nPaul de Vrieze","comments":["This is just wrong. What Java calls \"reference\" C++ calls \"pointer\". What C++ calls \"reference\" does not exist in Java. C++ reference is pointer like type but with global scope. When you change a C++ reference all occurrences of that references are changed, both in called function but also in a calling function. Java can't do that. Java is strictly pass by value, and changes to java references are strictly local. Java called function can't change reference value of calling function. You can emulate C++ reference by using wrapper objects like AtomicReference.","C++ references have nothing to do with scopes. In implementation they are like pointers that are not allowed to have null values. The main difference beyond that is that syntactically they behave as aliases of the referenced data. In Java references work almost the same way, but have special rules that allow for: comparison with null and other reference values (using the == operator). C++ is also pass by value, although that value could be a pointer/reference to the reference.","Changes to C++ references made by called method are also visible by calling method. That doesn't exist in Java and it is not a pointer like behaviour. In Java and C changes to pointer values are local only. I don't know how to properly call to this kind behaviour but it is somewhat similar to \"outer scope\" of some scripting languages.","For example of proper pass-by-reference see swap program here: geeksforgeeks.org/references-in-c It is not possible to write swap method in Java with same side-effects. There is \"quality\" (a behaviour of language operators) to C++ references which does not exists in Java references or C pointers."]},{"answer":"I have created a thread devoted to these kind of questions for any programming languages here.\n\nJava is also mentioned. Here is the short summary:\n\nJava passes it parameters by value\n\"by value\" is the only way in java to pass a parameter to a method\nusing methods from the object given as parameter will alter the object as the references point to the original objects. (if that method itself alters some values)\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:02\ncommunity wiki\n\n\n2 revs\nsven","comments":[]}]},{"id":"419163","href":"https://stackoverflow.com/questions/419163/what-does-if-name-main-do","title":"What does if __name__ == “__main__”: do?","description":"\n                \nGiven the following code, what does the if __name__ == \"__main__\": do?\n\n# Threading example\nimport time, thread\n\ndef myfunction(string, sleeptime, lock, *args):\n    while True:\n        lock.acquire()\n        time.sleep(sleeptime)\n        lock.release()\n        time.sleep(sleeptime)\n\nif __name__ == \"__main__\":\n    lock = thread.allocate_lock()\n    thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))\n    thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))\n\n    ","questionComments":["Just for the record - what is \"main\": docs.python.org/3/reference/… and what is \"name\": docs.python.org/3/reference/…"],"answers":[{"answer":"Short Answer\n\nIt's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:\n\nIf you import the guardless script in another script (e.g. import my_script_without_a_name_eq_main_guard), then the second script will trigger the first to run at import time and using the second script's command line arguments. This is almost always a mistake.\n\nIf you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.\n\nLong Answer\n\nTo better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.\n\nWhenever the Python interpreter reads a source file, it does two things:\n\nit sets a few special variables like __name__, and then\n\nit executes all of the code found in the file.\n\nLet's see how this works and how it relates to your question about the __name__ checks we always see in Python scripts.\n\nCode Sample\n\nLet's use a slightly different code sample to explore how imports and scripts work. Suppose the following is in a file called foo.py.\n\n# Suppose this is foo.py.\n\nprint(\"before import\")\nimport math\n\nprint(\"before functionA\")\ndef functionA():\n    print(\"Function A\")\n\nprint(\"before functionB\")\ndef functionB():\n    print(\"Function B {}\".format(math.sqrt(100)))\n\nprint(\"before __name__ guard\")\nif __name__ == '__main__':\n    functionA()\n    functionB()\nprint(\"after __name__ guard\")\n\nSpecial Variables\n\nWhen the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the __name__ variable.\n\nWhen Your Module Is the Main Program\n\nIf you are running your module (the source file) as the main program, e.g.\n\npython foo.py\n\n\nthe interpreter will assign the hard-coded string \"__main__\" to the __name__ variable, i.e.\n\n# It's as if the interpreter inserts this at the top\n# of your module when run as the main program.\n__name__ = \"__main__\" \n\n\nWhen Your Module Is Imported By Another\n\nOn the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:\n\n# Suppose this is in some other main program.\nimport foo\n\n\nThe interpreter will search for your foo.py file (along with searching for a few other variants), and prior to executing that module, it will assign the name \"foo\" from the import statement to the __name__ variable, i.e.\n\n# It's as if the interpreter inserts this at the top\n# of your module when it's imported from another module.\n__name__ = \"foo\"\n\nExecuting the Module's Code\n\nAfter the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.\n\nAlways\n\nIt prints the string \"before import\" (without quotes).\n\nIt loads the math module and assigns it to a variable called math. This is equivalent to replacing import math with the following (note that __import__ is a low-level function in Python that takes a string and triggers the actual import):\n\n# Find and load a module given its string name, \"math\",\n# then assign it to a local variable called math.\nmath = __import__(\"math\")\n\n\nIt prints the string \"before functionA\".\n\nIt executes the def block, creating a function object, then assigning that function object to a variable called functionA.\n\nIt prints the string \"before functionB\".\n\nIt executes the second def block, creating another function object, then assigning it to a variable called functionB.\n\nIt prints the string \"before __name__ guard\".\n\nOnly When Your Module Is the Main Program\n\nIf your module is the main program, then it will see that __name__ was indeed set to \"__main__\" and it calls the two functions, printing the strings \"Function A\" and \"Function B 10.0\".\n\nOnly When Your Module Is Imported by Another\n\n(instead) If your module is not the main program but was imported by another one, then __name__ will be \"foo\", not \"__main__\", and it'll skip the body of the if statement.\n\nAlways\n\nIt will print the string \"after __name__ guard\" in both situations.\n\nSummary\n\nIn summary, here's what'd be printed in the two cases:\n\n# What gets printed if foo is the main program\nbefore import\nbefore functionA\nbefore functionB\nbefore __name__ guard\nFunction A\nFunction B 10.0\nafter __name__ guard\n\n# What gets printed if foo is imported as a regular module\nbefore import\nbefore functionA\nbefore functionB\nbefore __name__ guard\nafter __name__ guard\n\nWhy Does It Work This Way?\n\nYou might naturally wonder why anybody would want this. Well, sometimes you want to write a .py file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself. Examples:\n\nYour module is a library, but you want to have a script mode where it runs some unit tests or a demo.\n\nYour module is only used as a main program, but it has some unit tests, and the testing framework works by importing .py files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.\n\nYour module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.\n\nBeyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. \"Running\" the script is a side effect of importing the script's module.\n\nFood for Thought\n\nQuestion: Can I have multiple __name__ checking blocks? Answer: it's strange to do so, but the language won't stop you.\n\nSuppose the following is in foo2.py. What happens if you say python foo2.py on the command-line? Why?\n\n# Suppose this is foo2.py.\nimport os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters\n\ndef functionA():\n    print(\"a1\")\n    from foo2 import functionB\n    print(\"a2\")\n    functionB()\n    print(\"a3\")\n\ndef functionB():\n    print(\"b\")\n\nprint(\"t1\")\nif __name__ == \"__main__\":\n    print(\"m1\")\n    functionA()\n    print(\"m2\")\nprint(\"t2\")\n      \n\nNow, figure out what will happen if you remove the __name__ check in foo3.py:\n# Suppose this is foo3.py.\nimport os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters\n\ndef functionA():\n    print(\"a1\")\n    from foo3 import functionB\n    print(\"a2\")\n    functionB()\n    print(\"a3\")\n\ndef functionB():\n    print(\"b\")\n\nprint(\"t1\")\nprint(\"m1\")\nfunctionA()\nprint(\"m2\")\nprint(\"t2\")\n\nWhat will this do when used as a script? When imported as a module?\n# Suppose this is in foo4.py\n__name__ = \"__main__\"\n\ndef bar():\n    print(\"bar\")\n    \nprint(\"before __name__ guard\")\nif __name__ == \"__main__\":\n    bar()\nprint(\"after __name__ guard\")\n\nShare\nImprove this answer\nFollow\nedited Apr 5 at 21:28\nanswered Jan 7 '09 at 4:26\nMr Fooz\n97.6k5\n5 gold badges\n65\n65 silver badges\n95\n95 bronze badges","comments":["Out of curiosity: What hapens if I run subprocess.run('foo_bar.py') in a python script? I suppose that foo_bar will be started with __name__ = '__main__' just like when I tipe foo_bar.py in cmd manually. Is that the case? Taking @MrFooz' Answer into account there should not be any problem doing this and having as many \"main\" modules at a time as I like. Even changing the __name__ value or having several independantly creates instances (or instances that created each other by subprocess) interact with each other should be business as usual for Python. Do I miss something?","@hajef You're correct about how things would work with subprocess.run. That said, a generally better way of sharing code between scripts is to create modules and have the scripts call the shared modules instead of invoking each other as scripts. It's hard to debug subprocess.run calls since most debuggers don't jump across process boundaries, it can add non-trivial system overhead to create and destroy the extra processes, etc.","i have a doubt in foo2.py example in the food for thought section.what does from foo2.py import functionB do? In my view it just imports foo2.py from functionB","One of the modules that may import your code is multiprocessing, in particular making this test necessary on Windows.","Extremely minor point, but I believe python actually determines the __name__ of an imported module from the import statement, not from stripping \".py\" off the filename. Because python identifiers are case sensitive but file names may not be (e.g. on windows), there isn't necessarily enough information in the filename to determine the correct python module name."]},{"answer":"When your script is run by passing it as a command to the Python interpreter,\n\npython myscript.py\n\n\nall of the code that is at indentation level 0 gets executed. Functions and classes that are defined are, well, defined, but none of their code gets run. Unlike other languages, there's no main() function that gets run automatically - the main() function is implicitly all the code at the top level.\n\nIn this case, the top-level code is an if block. __name__ is a built-in variable which evaluates to the name of the current module. However, if a module is being run directly (as in myscript.py above), then __name__ instead is set to the string \"__main__\". Thus, you can test whether your script is being run directly or being imported by something else by testing\n\nif __name__ == \"__main__\":\n    ...\n\n\nIf your script is being imported into another module, its various function and class definitions will be imported and its top-level code will be executed, but the code in the then-body of the if clause above won't get run as the condition is not met. As a basic example, consider the following two scripts:\n\n# file one.py\ndef func():\n    print(\"func() in one.py\")\n\nprint(\"top-level in one.py\")\n\nif __name__ == \"__main__\":\n    print(\"one.py is being run directly\")\nelse:\n    print(\"one.py is being imported into another module\")\n\n# file two.py\nimport one\n\nprint(\"top-level in two.py\")\none.func()\n\nif __name__ == \"__main__\":\n    print(\"two.py is being run directly\")\nelse:\n    print(\"two.py is being imported into another module\")\n\n\nNow, if you invoke the interpreter as\n\npython one.py\n\n\nThe output will be\n\ntop-level in one.py\none.py is being run directly\n\n\nIf you run two.py instead:\n\npython two.py\n\n\nYou get\n\ntop-level in one.py\none.py is being imported into another module\ntop-level in two.py\nfunc() in one.py\ntwo.py is being run directly\n\n\nThus, when module one gets loaded, its __name__ equals \"one\" instead of \"__main__\".\n\nShare\nImprove this answer\nFollow\nedited Jan 31 '18 at 13:28\nTonechas\n11.8k15\n15 gold badges\n38\n38 silver badges\n69\n69 bronze badges\nanswered Jan 7 '09 at 4:28\nAdam Rosenfield\n364k94\n94 gold badges\n489\n489 silver badges\n575\n575 bronze badges","comments":["So, if __name__ == \"__main__\": basically checks if you are running your python script itself, and not importing it or something?"]},{"answer":"The simplest explanation for the __name__ variable (imho) is the following:\n\nCreate the following files.\n\n# a.py\nimport b\n\n\nand\n\n# b.py\nprint \"Hello World from %s!\" % __name__\n\nif __name__ == '__main__':\n    print \"Hello World again from %s!\" % __name__\n\n\nRunning them will get you this output:\n\n$ python a.py\nHello World from b!\n\n\nAs you can see, when a module is imported, Python sets globals()['__name__'] in this module to the module's name. Also, upon import all the code in the module is being run. As the if statement evaluates to False this part is not executed.\n\n$ python b.py\nHello World from __main__!\nHello World again from __main__!\n\n\nAs you can see, when a file is executed, Python sets globals()['__name__'] in this file to \"__main__\". This time, the if statement evaluates to True and is being run.\n\nShare\nImprove this answer\nFollow\nedited Dec 18 '18 at 9:25\nanswered Jan 7 '09 at 11:35\npi.\n19.4k7\n7 gold badges\n36\n36 silver badges\n59\n59 bronze badges","comments":[]},{"answer":"What does the if __name__ == \"__main__\": do?\n\nTo outline the basics:\n\nThe global variable, __name__, in the module that is the entry point to your program, is '__main__'. Otherwise, it's the name you import the module by.\n\nSo, code under the if block will only run if the module is the entry point to your program.\n\nIt allows the code in the module to be importable by other modules, without executing the code block beneath on import.\n\nWhy do we need this?\n\nDeveloping and Testing Your Code\n\nSay you're writing a Python script designed to be used as a module:\n\ndef do_important():\n    \"\"\"This function does something very important\"\"\"\n\n\nYou could test the module by adding this call of the function to the bottom:\n\ndo_important()\n\n\nand running it (on a command prompt) with something like:\n\n~$ python important.py\n\nThe Problem\n\nHowever, if you want to import the module to another script:\n\nimport important\n\n\nOn import, the do_important function would be called, so you'd probably comment out your function call, do_important(), at the bottom.\n\n# do_important() # I must remember to uncomment to execute this!\n\n\nAnd then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome.\n\nA Better Way\n\nThe __name__ variable points to the namespace wherever the Python interpreter happens to be at the moment.\n\nInside an imported module, it's the name of that module.\n\nBut inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its \"__main__\".\n\nSo if you check before executing:\n\nif __name__ == \"__main__\":\n    do_important()\n\n\nWith the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script).\n\nAn Even Better Way\n\nThere's a Pythonic way to improve on this, though.\n\nWhat if we want to run this business process from outside the module?\n\nIf we put the code we want to exercise as we develop and test in a function like this and then do our check for '__main__' immediately after:\n\ndef main():\n    \"\"\"business logic for when running this module as the primary one!\"\"\"\n    setup()\n    foo = do_important()\n    bar = do_even_more_important(foo)\n    for baz in bar:\n        do_super_important(baz)\n    teardown()\n\n# Here's our payoff idiom!\nif __name__ == '__main__':\n    main()\n\n\nWe now have a final function for the end of our module that will run if we run the module as the primary module.\n\nIt will allow the module and its functions and classes to be imported into other scripts without running the main function, and will also allow the module (and its functions and classes) to be called when running from a different '__main__' module, i.e.\n\nimport important\nimportant.main()\n\n\nThis idiom can also be found in the Python documentation in an explanation of the __main__ module. That text states:\n\nThis module represents the (otherwise anonymous) scope in which the interpreter’s main program executes — commands read either from standard input, from a script file, or from an interactive prompt. It is this environment in which the idiomatic “conditional script” stanza causes a script to run:\n\nif __name__ == '__main__':\n    main()\n\nShare\nImprove this answer\nFollow\nedited Mar 27 '18 at 2:27\nanswered Nov 23 '13 at 4:38\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":[]},{"answer":"if __name__ == \"__main__\" is the part that runs when the script is run from (say) the command line using a command like python myscript.py.\n\nShare\nImprove this answer\nFollow\nedited Jul 10 '15 at 15:49\nMark Amery\n115k61\n61 gold badges\n361\n361 silver badges\n414\n414 bronze badges\nanswered Jan 7 '09 at 4:14\nHarley Holcombe\n158k15\n15 gold badges\n68\n68 silver badges\n62\n62 bronze badges","comments":["Why does a file helloworld.py with just print(\"hello world\") in it can run with command python helloworld.py even when there is no if __name__ == \"__main__\"?","When you run python helloworld.py it will run the whole script file (whether you specify if __name__ == \"__main__\" or not ) . There is only a difference in execution when you are importing helloworld.py from a different script. In that case the if __name__ == \"__main__\" codeblock does not execute at all."]},{"answer":"What does if __name__ == \"__main__\": do?\n\n__name__ is a global variable (in Python, global actually means on the module level) that exists in all namespaces. It is typically the module's name (as a str type).\n\nAs the only special case, however, in whatever Python process you run, as in mycode.py:\n\npython mycode.py\n\n\nthe otherwise anonymous global namespace is assigned the value of '__main__' to its __name__.\n\nThus, including the final lines\n\nif __name__ == '__main__':\n    main()\n\nat the end of your mycode.py script,\nwhen it is the primary, entry-point module that is run by a Python process,\n\nwill cause your script's uniquely defined main function to run.\n\nAnother benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides:\n\nimport mycode\n# ... any amount of other code\nmycode.main()\n\nShare\nImprove this answer\nFollow\nedited Jan 10 '17 at 17:35\ncoffee-grinder\n25.3k19\n19 gold badges\n53\n53 silver badges\n81\n81 bronze badges\nanswered Oct 14 '14 at 20:22\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":[]},{"answer":"There are lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers.\n\nTake file \"ab.py\":\n\ndef a():\n    print('A function in ab file');\na()\n\n\nAnd a second file \"xy.py\":\n\nimport ab\ndef main():\n    print('main function: this is where the action is')\ndef x():\n    print ('peripheral task: might be useful in other projects')\nx()\nif __name__ == \"__main__\":\n    main()\n\n\nWhat is this code actually doing?\n\nWhen you execute xy.py, you import ab. The import statement runs the module immediately on import, so ab's operations get executed before the remainder of xy's. Once finished with ab, it continues with xy.\n\nThe interpreter keeps track of which scripts are running with __name__. When you run a script - no matter what you've named it - the interpreter calls it \"__main__\", making it the master or 'home' script that gets returned to after running an external script.\n\nAny other script that's called from this \"__main__\" script is assigned its filename as its __name__ (e.g., __name__ == \"ab.py\"). Hence, the line if __name__ == \"__main__\": is the interpreter's test to determine if it's interpreting/parsing the 'home' script that was initially executed, or if it's temporarily peeking into another (external) script. This gives the programmer flexibility to have the script behave differently if it's executed directly vs. called externally.\n\nLet's step through the above code to understand what's happening, focusing first on the unindented lines and the order they appear in the scripts. Remember that function - or def - blocks don't do anything by themselves until they're called. What the interpreter might say if mumbled to itself:\n\nOpen xy.py as the 'home' file; call it \"__main__\" in the __name__ variable.\nImport and open file with the __name__ == \"ab.py\".\nOh, a function. I'll remember that.\nOk, function a(); I just learned that. Printing 'A function in ab file'.\nEnd of file; back to \"__main__\"!\nOh, a function. I'll remember that.\nAnother one.\nFunction x(); ok, printing 'peripheral task: might be useful in other projects'.\nWhat's this? An if statement. Well, the condition has been met (the variable __name__ has been set to \"__main__\"), so I'll enter the main() function and print 'main function: this is where the action is'.\n\nThe bottom two lines mean: \"If this is the \"__main__\" or 'home' script, execute the function called main()\". That's why you'll see a def main(): block up top, which contains the main flow of the script's functionality.\n\nWhy implement this?\n\nRemember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the main() function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script.\n\nAgain, there will be exceptions, but common practice is that main() doesn't usually get called externally. So you may be wondering one more thing: if we're not calling main(), why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run independent of the rest of the code in the file. They're then later called somewhere else in the body of the script. Which brings me to this:\n\nBut the code works without it\n\nYes, that's right. These separate functions can be called from an in-line script that's not contained inside a main() function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read.\n\nBut that's a script that probably can't have its functions called externally, because if it did it would immediately start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there will be conflicting variables.\n\nIn splitting out independent functions, you gain the ability to re-use your previous work by calling them into another script. For example, \"example.py\" might import \"xy.py\" and call x(), making use of the 'x' function from \"xy.py\". (Maybe it's capitalizing the third word of a given text string; creating a NumPy array from a list of numbers and squaring them; or detrending a 3D surface. The possibilities are limitless.)\n\n(As an aside, this question contains an answer by @kindall that finally helped me to understand - the why, not the how. Unfortunately it's been marked as a duplicate of this one, which I think is a mistake.)\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:29\nanswered Sep 29 '16 at 4:33\njoechoj\n1,1597\n7 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"When there are certain statements in our module (M.py) we want to be executed when it'll be running as main (not imported), we can place those statements (test-cases, print statements) under this if block.\n\nAs by default (when module running as main, not imported) the __name__ variable is set to \"__main__\", and when it'll be imported the __name__ variable will get a different value, most probably the name of the module ('M'). This is helpful in running different variants of a modules together, and separating their specific input & output statements and also if there are any test-cases.\n\nIn short, use this 'if __name__ == \"main\" ' block to prevent (certain) code from being run when the module is imported.\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:07\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 3 '13 at 14:09\nNabeel Ahmed\n15k4\n4 gold badges\n51\n51 silver badges\n54\n54 bronze badges","comments":[]},{"answer":"Put simply, __name__ is a variable defined for each script that defines whether the script is being run as the main module or it is being run as an imported module.\n\nSo if we have two scripts;\n\n#script1.py\nprint \"Script 1's name: {}\".format(__name__)\n\n\nand\n\n#script2.py\nimport script1\nprint \"Script 2's name: {}\".format(__name__)\n\n\nThe output from executing script1 is\n\nScript 1's name: __main__\n\n\nAnd the output from executing script2 is:\n\nScript1's name is script1\nScript 2's name: __main__\n\n\nAs you can see, __name__ tells us which code is the 'main' module. This is great, because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library.\n\nSay you write a Python script that does something great and you implement a boatload of functions that are useful for other purposes. If I want to use them I can just import your script and use them without executing your program (given that your code only executes within the if __name__ == \"__main__\": context). Whereas in C/C++ you would have to portion out those pieces into a separate module that then includes the file. Picture the situation below;\n\nThe arrows are import links. For three modules each trying to include the previous modules code there are six files (nine, counting the implementation files) and five links. This makes it difficult to include other code into a C project unless it is compiled specifically as a library. Now picture it for Python:\n\nYou write a module, and if someone wants to use your code they just import it and the __name__ variable can help to separate the executable portion of the program from the library part.\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:28\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 15 '16 at 9:07\nredbandit\n1,90314\n14 silver badges\n11\n11 bronze badges","comments":["The C/C++ illustration is wrong: 3 times the same unit name (file1)."]},{"answer":"Let's look at the answer in a more abstract way:\n\nSuppose we have this code in x.py:\n\n...\n<Block A>\nif __name__ == '__main__':\n    <Block B>\n...\n\n\nBlocks A and B are run when we are running x.py.\n\nBut just block A (and not B) is run when we are running another module, y.py for example, in which x.py is imported and the code is run from there (like when a function in x.py is called from y.py).\n\nShare\nImprove this answer\nFollow\nedited May 27 '20 at 10:50\nkubuntu\n2,5151\n1 gold badge\n20\n20 silver badges\n24\n24 bronze badges\nanswered Jan 20 '15 at 17:48\nAlisa\n2,3543\n3 gold badges\n26\n26 silver badges\n43\n43 bronze badges","comments":["I wasn't able to edit the post (minimum 6 characters if change required). Line 14 has 'x.y' rather than 'x.py'."]},{"answer":"I've been reading so much throughout the answers on this page. I would say, if you know the thing, for sure you will understand those answers, otherwise, you are still confused.\n\nTo be short, you need to know several points:\n\nimport a action actually runs all that can be ran in a.py, meaning each line in a.py\n\nBecause of point 1, you may not want everything to be run in a.py when importing it\n\nTo solve the problem in point 2, python allows you to put a condition check\n\n__name__ is an implicit variable in all .py modules:\n\nwhen a.py is imported, the value of __name__ of a.py module is set to its file name \"a\"\nwhen a.py is run directly using \"python a.py\", the value of __name__ is set to a string __main__\nBased on the mechanism how python sets the variable __name__ for each module, do you know how to achieve point 3? The answer is fairly easy, right? Put a if condition: if __name__ == \"__main__\": // do A\nthen python a.py will run the part // do A\nand import a will skip the part // do A\nYou can even put if __name__ == \"a\" depending on your functional need, but rarely do\n\nThe important thing that python is special at is point 4! The rest is just basic logic.\n\nShare\nImprove this answer\nFollow\nedited Aug 9 '20 at 22:19\nanswered Jun 24 '18 at 15:48\njack\n1,0357\n7 silver badges\n20\n20 bronze badges","comments":["Yes, point 1 is vital to understand. From that, the need for this mechanism become clear.","Nailed it, was totally confused still with the above answers, but now it's crystal clear!","this should be the accepted answer..","This is by far the best \"understandable\" answer."]},{"answer":"When you run Python interactively the local __name__ variable is assigned a value of __main__. Likewise, when you execute a Python module from the command line, rather than importing it into another module, its __name__ attribute is assigned a value of __main__, rather than the actual name of the module. In this way, modules can look at their own __name__ value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules:\n\nif __name__ == '__main__':\n    # Do something appropriate here, like calling a\n    # main() function defined elsewhere in this module.\n    main()\nelse:\n    # Do nothing. This module has been imported by another\n    # module that wants to make use of the functions,\n    # classes and other useful bits it has defined.\n\nShare\nImprove this answer\nFollow\nanswered Dec 11 '13 at 11:23\nZain\n1,1461\n1 gold badge\n14\n14 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"Consider:\n\nif __name__ == \"__main__\":\n    main()\n\n\nIt checks if the __name__ attribute of the Python script is \"__main__\". In other words, if the program itself is executed, the attribute will be __main__, so the program will be executed (in this case the main() function).\n\nHowever, if your Python script is used by a module, any code outside of the if statement will be executed, so if \\__name__ == \"\\__main__\" is used just to check if the program is used as a module or not, and therefore decides whether to run the code.\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:31\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 22 '17 at 18:53\nLarry\n1,1121\n1 gold badge\n11\n11 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"The code under if __name__ == '__main__': will be executed only if the module is invoked as a script.\n\nAs an example consider the following module my_test_module.py:\n\n# my_test_module.py\n\nprint('This is going to be printed out, no matter what')\n\nif __name__ == '__main__':\n    print('This is going to be printed out, only if user invokes the module as a script')\n\n\n1st possibility: Import my_test_module.py in another module\n\n# main.py\n\nimport my_test_module\n\nif __name__ == '__main__':\n    print('Hello from main.py')\n\n\nNow if you invoke main.py:\n\npython main.py \n\n>> 'This is going to be printed out, no matter what'\n>> 'Hello from main.py'\n\n\nNote that only the top-level print() statement in my_test_module is executed.\n\n2nd possibility: Invoke my_test_module.py as a script\n\nNow if you run my_test_module.py as a Python script, both print() statements will be exectued:\n\npython my_test_module.py\n\n>>> 'This is going to be printed out, no matter what'\n>>> 'This is going to be printed out, only if user invokes the module as a script'\n\n\nFor a more comprehensive explanation you can read What does if __name__ == '__main__' do in Python.\n\nShare\nImprove this answer\nFollow\nedited May 6 at 21:56\nanswered Feb 1 '20 at 13:26\nGiorgos Myrianthous\n25.4k10\n10 gold badges\n86\n86 silver badges\n118\n118 bronze badges","comments":[]},{"answer":"Before explaining anything about if __name__ == '__main__' it is important to understand what __name__ is and what it does.\n\nWhat is __name__?\n\n__name__ is a DunderAlias - can be thought of as a global variable (accessible from modules) and works in a similar way to global.\n\nIt is a string (global as mentioned above) as indicated by type(__name__) (yielding <class 'str'>), and is an inbuilt standard for both Python 3 and Python 2 versions.\n\nWhere:\n\nIt can not only be used in scripts but can also be found in both the interpreter and modules/packages.\n\nInterpreter:\n\n>>> print(__name__)\n__main__\n>>>\n\n\nScript:\n\ntest_file.py:\n\nprint(__name__)\n\n\nResulting in __main__\n\nModule or package:\n\nsomefile.py:\n\ndef somefunction():\n    print(__name__)\n\n\ntest_file.py:\n\nimport somefile\nsomefile.somefunction()\n\n\nResulting in somefile\n\nNotice that when used in a package or module, __name__ takes the name of the file. The path of the actual module or package path is not given, but has its own DunderAlias __file__, that allows for this.\n\nYou should see that, where __name__, where it is the main file (or program) will always return __main__, and if it is a module/package, or anything that is running off some other Python script, will return the name of the file where it has originated from.\n\nPractice:\n\nBeing a variable means that it's value can be overwritten (\"can\" does not mean \"should\"), overwriting the value of __name__ will result in a lack of readability. So do not do it, for any reason. If you need a variable define a new variable.\n\nIt is always assumed that the value of __name__ to be __main__ or the name of the file. Once again changing this default value will cause more confusion that it will do good, causing problems further down the line.\n\nexample:\n\n>>> __name__ = 'Horrify' # Change default from __main__\n>>> if __name__ == 'Horrify': print(__name__)\n...\n>>> else: print('Not Horrify')\n...\nHorrify\n>>>\n\n\nIt is considered good practice in general to include the if __name__ == '__main__' in scripts.\n\nNow to answer if __name__ == '__main__':\n\nNow we know the behaviour of __name__ things become clearer:\n\nAn if is a flow control statement that contains the block of code will execute if the value given is true. We have seen that __name__ can take either __main__ or the file name it has been imported from.\n\nThis means that if __name__ is equal to __main__ then the file must be the main file and must actually be running (or it is the interpreter), not a module or package imported into the script.\n\nIf indeed __name__ does take the value of __main__ then whatever is in that block of code will execute.\n\nThis tells us that if the file running is the main file (or you are running from the interpreter directly) then that condition must execute. If it is a package then it should not, and the value will not be __main__.\n\nModules:\n\n__name__ can also be used in modules to define the name of a module\n\nVariants:\n\nIt is also possible to do other, less common but useful things with __name__, some I will show here:\n\nExecuting only if the file is a module or package:\n\nif __name__ != '__main__':\n    # Do some useful things \n\n\nRunning one condition if the file is the main one and another if it is not:\n\nif __name__ == '__main__':\n    # Execute something\nelse:\n    # Do some useful things\n\n\nYou can also use it to provide runnable help functions/utilities on packages and modules without the elaborate use of libraries.\n\nIt also allows modules to be run from the command line as main scripts, which can be also very useful.\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:39\nanswered Apr 3 '18 at 19:32\nSimon\n9,4028\n8 gold badges\n53\n53 silver badges\n78\n78 bronze badges","comments":[]},{"answer":"I think it's best to break the answer in depth and in simple words:\n\n__name__: Every module in Python has a special attribute called __name__. It is a built-in variable that returns the name of the module.\n\n__main__: Like other programming languages, Python too has an execution entry point, i.e., main. '__main__' is the name of the scope in which top-level code executes. Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its __name__ is set to __main__.\n\nThus, the value of the __name__ attribute is set to __main__ when the module is run as the main program. Otherwise the value of __name__ is set to contain the name of the module.\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:30\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 30 '16 at 6:47\nInconnu\n5,0482\n2 gold badges\n32\n32 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance.\n\nIt could be written in several ways. Another is:\n\ndef some_function_for_instance_main():\n    dosomething()\n\n\n__name__ == '__main__' and some_function_for_instance_main()\n\n\nI am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about if __name__ == '__main__'.\n\nIt just a convention for invoking a main function in Python files.\n\nShare\nImprove this answer\nFollow\nedited Jun 15 at 15:46\nanswered Jan 24 '13 at 13:48\nProf. Falken\n22.5k18\n18 gold badges\n95\n95 silver badges\n166\n166 bronze badges","comments":["I would consider this bad form as you're 1) relying on side effects and 2) abusing and. and is used for checking if two boolean statements are both true. Since you're not interested in the result of the and, an if statement more clearly communicates your intentions.","Leaving aside the question of whether exploiting the short-circuit behaviour of boolean operators as a flow control mechanism is bad style or not, the bigger problem is that this doesn't answer the question at all.","@jpmc26 Anyone with a background in Perl or Javascript is totally comfortable with this idiom, using and as a control statement. I don't have any issue with it. Another similar idiom is using or to set default values. For example, x = input(\"what is your name? \") or \"Nameless Person\".","@JohnHenckel This is not Perl or JavaScript. This is not a Python idiom. It is considered bad form to use a function with side effects in the middle of a Boolean statement in Python. Particularly in this case, there is absolutely no benefit to using and here; the function doesn't even return a value. It just makes the code less obvious.","@jpmc26 I'm trying to find an authoritative source that agrees with you. Is this mentioned somewhere? For example in PEP8 does it say that we should avoid using and for control purposes, or using or to assign a default value? I tried to google it, but I could not find anything."]},{"answer":"There are a number of variables that the system (Python interpreter) provides for source files (modules). You can get their values anytime you want, so, let us focus on the __name__ variable/attribute:\n\nWhen Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.)\n\nBefore the interpreter executes the source code file though, it defines a few special variables for that file; __name__ is one of those special variables that Python automatically defines for each source code file.\n\nIf Python is loading this source code file as the main program (i.e. the file you run), then it sets the special __name__ variable for this file to have a value \"__main__\".\n\nIf this is being imported from another module, __name__ will be set to that module's name.\n\nSo, in your example in part:\n\nif __name__ == \"__main__\":\n   lock = thread.allocate_lock()\n   thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))\n   thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))\n\n\nmeans that the code block:\n\nlock = thread.allocate_lock()\nthread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))\nthread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))\n\n\nwill be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of __name__ will not equal to \"main\" in that particular instance.\n\nHope this helps out.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 '16 at 9:30\nanswered Nov 25 '15 at 12:26\ncodewizard\n3262\n2 silver badges\n8\n8 bronze badges","comments":[]},{"answer":"if __name__ == \"__main__\": is basically the top-level script environment, and it specifies the interpreter that ('I have the highest priority to be executed first').\n\n'__main__' is the name of the scope in which top-level code executes. A module’s __name__ is set equal to '__main__' when read from standard input, a script, or from an interactive prompt.\n\nif __name__ == \"__main__\":\n    # Execute only if run as a script\n    main()\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 24 '16 at 8:23\nThe Gr8 Adakron\n1,0621\n1 gold badge\n11\n11 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"Consider:\n\nprint __name__\n\n\nThe output for the above is __main__.\n\nif __name__ == \"__main__\":\n  print \"direct method\"\n\n\nThe above statement is true and prints \"direct method\". Suppose if they imported this class in another class it doesn't print \"direct method\" because, while importing, it will set __name__ equal to \"first model name\".\n\nShare\nImprove this answer\nFollow\nedited Feb 6 '19 at 23:16\nsimhumileco\n23k14\n14 gold badges\n112\n112 silver badges\n95\n95 bronze badges\nanswered Jun 22 '16 at 10:47\nJanarthanan Ramu\n1,09510\n10 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"You can make the file usable as a script as well as an importable module.\n\nfibo.py (a module named fibo)\n\n# Other modules can IMPORT this MODULE to use the function fib\ndef fib(n):    # write Fibonacci series up to n\n    a, b = 0, 1\n    while b < n:\n        print(b, end=' ')\n        a, b = b, a+b\n    print()\n\n# This allows the file to be used as a SCRIPT\nif __name__ == \"__main__\":\n    import sys\n    fib(int(sys.argv[1]))\n\n\nReference: https://docs.python.org/3.5/tutorial/modules.html\n\nShare\nImprove this answer\nFollow\nanswered Mar 13 '17 at 21:44\nkgf3JfUtW\n10.2k7\n7 gold badges\n41\n41 silver badges\n62\n62 bronze badges","comments":[]},{"answer":"The reason for\n\nif __name__ == \"__main__\":\n    main()\n\n\nis primarily to avoid the import lock problems that would arise from having code directly imported. You want main() to run if your file was directly invoked (that's the __name__ == \"__main__\" case), but if your code was imported then the importer has to enter your code from the true main module to avoid import lock problems.\n\nA side-effect is that you automatically sign on to a methodology that supports multiple entry points. You can run your program using main() as the entry point, but you don't have to. While setup.py expects main(), other tools use alternate entry points. For example, to run your file as a gunicorn process, you define an app() function instead of a main(). Just as with setup.py, gunicorn imports your code so you don't want it do do anything while it's being imported (because of the import lock issue).\n\nShare\nImprove this answer\nFollow\nedited Apr 18 '18 at 21:05\nanswered Sep 22 '17 at 18:32\npersonal_cloud\n3,0461\n1 gold badge\n19\n19 silver badges\n26\n26 bronze badges","comments":["Good to learn about import lock. Could you please explain sign on to a methodology that [...] part a little bit more?","@Wolf: Sure. I've added a few sentences about the multiple entry points methodology."]},{"answer":"Every module in python has a attribute called __name__. The value of __name__ attribute is __main__ when the module is run directly, like python my_module.py. Otherwise (like when you say import my_module) the value of __name__ is the name of the module.\n\nSmall example to explain in short.\n\n#Script test.py\n\napple = 42\n\ndef hello_world():\n    print(\"I am inside hello_world\")\n\nif __name__ == \"__main__\":\n    print(\"Value of __name__ is: \", __name__)\n    print(\"Going to call hello_world\")\n    hello_world()\n\n\nWe can execute this directly as\n\npython test.py  \n\n\nOutput\n\nValue of __name__ is: __main__\nGoing to call hello_world\nI am inside hello_world\n\n\nNow suppose we call above script from other script\n\n#script external_calling.py\n\nimport test\nprint(test.apple)\ntest.hello_world()\n\nprint(test.__name__)\n\n\nWhen you execute this\n\npython external_calling.py\n\n\nOutput\n\n42\nI am inside hello_world\ntest\n\n\nSo, above is self explanatory that when you call test from other script, if loop __name__ in test.py will not execute.\n\nShare\nImprove this answer\nFollow\nedited Dec 23 '19 at 23:43\ncharlesreid1\n3,3182\n2 gold badges\n26\n26 silver badges\n43\n43 bronze badges\nanswered Jun 12 '19 at 9:28\nRishi Bansal\n2,7192\n2 gold badges\n19\n19 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"This answer is for Java programmers learning Python. Every Java file typically contains one public class. You can use that class in two ways:\n\nCall the class from other files. You just have to import it in the calling program.\n\nRun the class stand alone, for testing purposes.\n\nFor the latter case, the class should contain a public static void main() method. In Python this purpose is served by the globally defined label '__main__'.\n\nShare\nImprove this answer\nFollow\nedited Oct 18 '18 at 3:09\neyllanesc\n202k15\n15 gold badges\n96\n96 silver badges\n156\n156 bronze badges\nanswered Oct 7 '18 at 4:52\nRaja\n87410\n10 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"If this .py file are imported by other .py files, the code under \"the if statement\" will not be executed.\n\nIf this .py are run by python this_py.py under shell, or double clicked in Windows. the code under \"the if statement\" will be executed.\n\nIt is usually written for testing.\n\nShare\nImprove this answer\nFollow\nanswered Jun 19 '18 at 11:44\npah8J\n7177\n7 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"If the python interpreter is running a particular module then __name__ global variable will have value \"__main__\"\n\n  def a():\n      print(\"a\")\n  def b():\n      print(\"b\")\n\n  if __name__ == \"__main__\": \n\n          print (\"you can see me\" )\n          a()\n  else: \n\n          print (\"You can't see me\")\n          b()\n\n\nWhen you run this script prints you can see me\n\na\n\nIf you import this file say A to file B and execute the file B then if __name__ == \"__main__\" in file A becomes false, so it prints You can't see me\n\nb\n\nShare\nImprove this answer\nFollow\nanswered Jul 30 '19 at 16:22\nNikil Munireddy\n1681\n1 silver badge\n5\n5 bronze badges","comments":[]},{"answer":"if name == 'main':\n\nWe see if __name__ == '__main__': quite often.\n\nIt checks if a module is being imported or not.\n\nIn other words, the code within the if block will be executed only when the code runs directly. Here directly means not imported.\n\nLet's see what it does using a simple code that prints the name of the module:\n\n# test.py\ndef test():\n   print('test module name=%s' %(__name__))\n\nif __name__ == '__main__':\n   print('call test()')\n   test()\n\n\nIf we run the code directly via python test.py, the module name is __main__:\n\ncall test()\ntest module name=__main__\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 4 '18 at 14:32\nAli Hallaji\n1,8481\n1 gold badge\n18\n18 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"In simple words:\n\nThe code you see under if __name__ == \"__main__\": will only get called upon when your python file is executed as \"python example1.py\".\n\nHowever, if you wish to import your python file 'example1.py' as a module to work with another python file say 'example2.py', the code under if __name__ == \"__main__\": will not run or take any effect.\n\nShare\nImprove this answer\nFollow\nanswered Oct 22 '20 at 18:01\nMustapha Babatunde\n4034\n4 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"All the answers have pretty much explained the functionality. But I will provide one example of its usage which might help clearing out the concept further.\n\nAssume that you have two Python files, a.py and b.py. Now, a.py imports b.py. We run the a.py file, where the \"import b.py\" code is executed first. Before the rest of the a.py code runs, the code in the file b.py must run completely.\n\nIn the b.py code there is some code that is exclusive to that file b.py and we don't want any other file (other than b.py file), that has imported the b.py file, to run it.\n\nSo that is what this line of code checks. If it is the main file (i.e., b.py) running the code, which in this case it is not (a.py is the main file running), then only the code gets executed.\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:38\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 4 '18 at 8:25\npreetika mondal\n1711\n1 silver badge\n8\n8 bronze badges","comments":[]},{"answer":"Create a file, a.py:\n\nprint(__name__) # It will print out __main__\n\n\n__name__ is always equal to __main__ whenever that file is run directly showing that this is the main file.\n\nCreate another file, b.py, in the same directory:\n\nimport a  # Prints a\n\n\nRun it. It will print a, i.e., the name of the file which is imported.\n\nSo, to show two different behavior of the same file, this is a commonly used trick:\n\n# Code to be run when imported into another python file\n\nif __name__ == '__main__':\n    # Code to be run only when run directly\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 22:34\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 8 '18 at 15:24\nDARK_C0D3R\n1,34911\n11 silver badges\n19\n19 bronze badges","comments":[]}]},{"id":"7074","href":"https://stackoverflow.com/questions/7074/what-is-the-difference-between-string-and-string-in-c","title":"What is the difference between String and string in C#?","description":"\n                \nExample (note the case):\n\nstring s = \"Hello world!\";\nString s = \"Hello world!\";\n\n\nWhat are the guidelines for the use of each? And what are the differences?\n    ","questionComments":["@O.R.Mapper, but the fact remains that string is a lexical construct of the C# grammar whereas System.String is just a type. Regardless of any explicit difference mentioned in any spec, there is still this implicit difference that could be accomodated with some ambiguity. The language itself must support string in a way that the implementation is not (quite) so obligated to consider for a particular class in the BCL.","@KirkWoll: According to the language specification, the language itself must consider string to be exactly the same as the BCL type System.String, nothing else. That is not ambiguous at all. Of course, you can implement your own compiler, using the C# grammar, and use all of the tokens found like that for something arbitrary, unrelated to what is defined in the C# language specification. However, the resulting language would only be a C# lookalike, it could not be considered C#.","You can use string without a using directive for System. You can't do that with String.","For someone coming from Algol and Fortran, this discussion shows there is something wrong with string. It is needed to abbreviate System.String, but, as an alias, it seems quite like, but not exactly the same thing. After several years of C#, though, I'd say, it is safe to simply use string and string.Format() and not to worry about System.String.","@Sangeeta What are you saying? The System.String class is still there, and the string keyword is still an alias for it. Just like System.Int32 and int. They are literally the same thing."],"answers":[{"answer":"string is an alias in C# for System.String.\nSo technically, there is no difference. It's like int vs. System.Int32.\n\nAs far as guidelines, it's generally recommended to use string any time you're referring to an object.\n\ne.g.\n\nstring place = \"world\";\n\n\nLikewise, I think it's generally recommended to use String if you need to refer specifically to the class.\n\ne.g.\n\nstring greet = String.Format(\"Hello {0}!\", place);\n\nThis is the style that Microsoft tends to use in their examples.\n\nIt appears that the guidance in this area may have changed, as StyleCop now enforces the use of the C# specific aliases.\n\nShare\nImprove this answer\nFollow\nedited Jan 22 '19 at 18:50\ncommunity wiki\n\n\n26 revs, 21 users 26%\nDerek Park","comments":["If you decide to use StyleCop and follow that, that will say to use the types specific to the language. So for C# you'll have string (instead of String), int (instead of Int32), float (instead of Single) - stylecop.soyuz5.com/SA1121.html","I always use the aliases because I've assumed one day it might come in handy because they are acting as an abstraction, so therefore can have their implementations changed without me having to know.","Visual Studio 2015 says that String.Format should be changed to string.Format, so I guess Microsoft is going that way. I have also always used String for the static methods.","What do you say to the fact that you could define your own type “String” but can’t do the same for “string” as it’s a keyword, as explained in stackoverflow.com/questions/7074/…","I gues then... Just be conistent. Use string or String or use a cerntain one in a specific case, but always in that case."]},{"answer":"Just for the sake of completeness, here's a brain dump of related information...\n\nAs others have noted, string is an alias for System.String. Assuming your code using String compiles to System.String (i.e. you haven't got a using directive for some other namespace with a different String type), they compile to the same code, so at execution time there is no difference whatsoever. This is just one of the aliases in C#. The complete list is:\n\nobject:  System.Object\nstring:  System.String\nbool:    System.Boolean\nbyte:    System.Byte\nsbyte:   System.SByte\nshort:   System.Int16\nushort:  System.UInt16\nint:     System.Int32\nuint:    System.UInt32\nlong:    System.Int64\nulong:   System.UInt64\nfloat:   System.Single\ndouble:  System.Double\ndecimal: System.Decimal\nchar:    System.Char\n\n\nApart from string and object, the aliases are all to value types. decimal is a value type, but not a primitive type in the CLR. The only primitive type which doesn't have an alias is System.IntPtr.\n\nIn the spec, the value type aliases are known as \"simple types\". Literals can be used for constant values of every simple type; no other value types have literal forms available. (Compare this with VB, which allows DateTime literals, and has an alias for it too.)\n\nThere is one circumstance in which you have to use the aliases: when explicitly specifying an enum's underlying type. For instance:\n\npublic enum Foo : UInt32 {} // Invalid\npublic enum Bar : uint   {} // Valid\n\n\nThat's just a matter of the way the spec defines enum declarations - the part after the colon has to be the integral-type production, which is one token of sbyte, byte, short, ushort, int, uint, long, ulong, char... as opposed to a type production as used by variable declarations for example. It doesn't indicate any other difference.\n\nFinally, when it comes to which to use: personally I use the aliases everywhere for the implementation, but the CLR type for any APIs. It really doesn't matter too much which you use in terms of implementation - consistency among your team is nice, but no-one else is going to care. On the other hand, it's genuinely important that if you refer to a type in an API, you do so in a language-neutral way. A method called ReadInt32 is unambiguous, whereas a method called ReadInt requires interpretation. The caller could be using a language that defines an int alias for Int16, for example. The .NET framework designers have followed this pattern, good examples being in the BitConverter, BinaryReader and Convert classes.\n\nShare\nImprove this answer\nFollow\nedited Oct 18 '20 at 5:47\ncommunity wiki\n\n\n14 revs, 9 users 62%\nJon Skeet","comments":[]},{"answer":"String stands for System.String and it is a .NET Framework type. string is an alias in the C# language for System.String. Both of them are compiled to System.String in IL (Intermediate Language), so there is no difference. Choose what you like and use that. If you code in C#, I'd prefer string as it's a C# type alias and well-known by C# programmers.\n\nI can say the same about (int, System.Int32) etc..\n\nShare\nImprove this answer\nFollow\nedited Dec 3 '11 at 19:53\ncommunity wiki\n\n\n3 revs, 3 users 57%\nartur02","comments":["I personally prefer using \"Int32\", since it immediately shows the range of the value. Imagine if they upgraded the type of \"int\" on later higher-bit systems. 'int' in c is apparently seen as \"the integer type that the target processor is most efficient working with\", and defined as \"at least 16 bit\". I'd prefer predictable consistency there, thank you very much.","@MyDaftQuestions I concur. If anything it would make sense to consistently use the .net types because they are language ignorant and the type is obvious, independent of any language (do I know all of F#'s or VB's idiosyncrasies?).","@Nyerguds There are two reasons to simply not worry about it. One is that int is defined in the C# language spec as a 32 bit integer regardless of the hardware. C#, despite a shared heritage in the mists of time, is not actually C. Changing int to a 64 bit integer would be a breaking change in the specification and the language. It would also require redefining long, as long is currently the 64 bit integer. The other reason not to worry is irrelevant since the types will never change, but .NET is just abstract enough that 99% of the time you don't have to think about it anyway. ;-)","@Craig I dig into lots of old proprietary game formats where I do have to think about that all the time, though. And then using Int16, Int32 and Int64 is a lot more transparent in the code than using the rather nondescriptive short, int and long","But short, not, long, float, double, et al are descriptive, because they’re in the language spec. C# is not C. I prefer them on declarations because they’re concise, small, and aesthetically pleasing. I do prefer the Torre library names on API’s where the API has a data type dependency."]},{"answer":"The best answer I have ever heard about using the provided type aliases in C# comes from Jeffrey Richter in his book CLR Via C#. Here are his 3 reasons:\n\nI've seen a number of developers confused, not knowing whether to use string or String in their code. Because in C# the string (a keyword) maps exactly to System.String (an FCL type), there is no difference and either can be used.\nIn C#, long maps to System.Int64, but in a different programming language, long could map to an Int16 or Int32. In fact, C++/CLI does in fact treat long as an Int32. Someone reading source code in one language could easily misinterpret the code's intention if he or she were used to programming in a different programming language. In fact, most languages won't even treat long as a keyword and won't compile code that uses it.\nThe FCL has many methods that have type names as part of their method names. For example, the BinaryReader type offers methods such as ReadBoolean, ReadInt32, ReadSingle, and so on, and the System.Convert type offers methods such as ToBoolean, ToInt32, ToSingle, and so on. Although it's legal to write the following code, the line with float feels very unnatural to me, and it's not obvious that the line is correct:\nBinaryReader br = new BinaryReader(...);\nfloat val  = br.ReadSingle(); // OK, but feels unnatural\nSingle val = br.ReadSingle(); // OK and feels good\n\n\nSo there you have it. I think these are all really good points. I however, don't find myself using Jeffrey's advice in my own code. Maybe I am too stuck in my C# world but I end up trying to make my code look like the framework code.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 '18 at 11:05\ncommunity wiki\n\n\n4 revs, 3 users 89%\nLuke Foust","comments":[]},{"answer":"string is a reserved word, but String is just a class name. This means that string cannot be used as a variable name by itself.\n\nIf for some reason you wanted a variable called string, you'd see only the first of these compiles:\n\nStringBuilder String = new StringBuilder();  // compiles\nStringBuilder string = new StringBuilder();  // doesn't compile \n\n\nIf you really want a variable name called string you can use @ as a prefix:\n\nStringBuilder @string = new StringBuilder();\n\n\nAnother critical difference: Stack Overflow highlights them differently.\n\nShare\nImprove this answer\nFollow\nedited Dec 27 '17 at 17:33\ncommunity wiki\n\n\n5 revs, 4 users 79%\nSimon_Weaver","comments":[]},{"answer":"There is one difference - you can't use String without using System; beforehand.\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '16 at 18:32\ncommunity wiki\n\n\n3 revs, 3 users 50%\nuser3296","comments":[]},{"answer":"It's been covered above; however, you can't use string in reflection; you must use String.\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '11 at 9:36\ncommunity wiki\n\n\n2 revs, 2 users 67%\nTraumaPony","comments":["I do not understand what this answer means and why it was upvoted. You can use typeof(string) in reflection. Example one: if (someMethodInfo.ReturnType == typeof(string)) { ... } Example two: var p = typeof(string).GetProperty(\"FirstChar\", BindingFlags.NonPublic | BindingFlags.Instance); Where is it that you must use String, not string? If you try things like Type.GetType(\"String\") or Type.GetType(\"string\"), neither will find the class because the namespace is missing. If for some silly reason you compare .Name of a type to \"string\" in a case-sensitive way, you are right."]},{"answer":"System.String is the .NET string class - in C# string is an alias for System.String - so in use they are the same.\n\nAs for guidelines I wouldn't get too bogged down and just use whichever you feel like - there are more important things in life and the code is going to be the same anyway.\n\nIf you find yourselves building systems where it is necessary to specify the size of the integers you are using and so tend to use Int16, Int32, UInt16, UInt32 etc. then it might look more natural to use String - and when moving around between different .net languages it might make things more understandable - otherwise I would use string and int.\n\nShare\nImprove this answer\nFollow\nedited Feb 6 '18 at 12:39\ncommunity wiki\n\n\n3 revs, 3 users 73%\nRonnie","comments":[]},{"answer":"I prefer the capitalized .NET types (rather than the aliases) for formatting reasons. The .NET types are colored the same as other object types (the value types are proper objects, after all).\n\nConditional and control keywords (like if, switch, and return) are lowercase and colored dark blue (by default). And I would rather not have the disagreement in use and format.\n\nConsider:\n\nString someString; \nstring anotherString; \n\nShare\nImprove this answer\nFollow\nedited Sep 28 '16 at 11:58\ncommunity wiki\n\n\n4 revs, 4 users 50%\nStuartLC","comments":[]},{"answer":"string and String are identical in all ways (except the uppercase \"S\"). There are no performance implications either way.\n\nLowercase string is preferred in most projects due to the syntax highlighting\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '11 at 9:37\ncommunity wiki\n\n\n2 revs, 2 users 80%\nTheSoftwareJedi","comments":[]},{"answer":"C# is a language which is used together with the CLR.\n\nstring is a type in C#.\n\nSystem.String is a type in the CLR.\n\nWhen you use C# together with the CLR string will be mapped to System.String.\n\nTheoretically, you could implement a C#-compiler that generated Java bytecode. A sensible implementation of this compiler would probably map string to java.lang.String in order to interoperate with the Java runtime library.\n\nShare\nImprove this answer\nFollow\nedited Dec 25 '15 at 12:55\ncommunity wiki\n\n\n3 revs, 2 users 81%\nRasmus Faber","comments":[]},{"answer":"This YouTube video demonstrates practically how they differ.\n\nBut now for a long textual answer.\n\nWhen we talk about .NET there are two different things one there is .NET framework and the other there are languages ( C#, VB.NET etc) which use that framework.\n\n\"System.String\" a.k.a \"String\" ( capital \"S\") is a .NET framework data type while \"string\" is a C# data type.\n\nIn short \"String\" is an alias ( the same thing called with different names) of \"string\". So technically both the below code statements will give the same output.\n\nString s = \"I am String\";\n\n\nor\n\nstring s = \"I am String\";\n\n\nIn the same way, there are aliases for other c# data type as shown below:-\n\nobject: System.Object, string: System.String, bool: System.Boolean, byte: System.Byte, sbyte: System.SByte, short: System.Int16 and so on\n\nNow the million-dollar question from programmer's point of view So when to use \"String\" and \"string\"?\n\nThe first thing to avoid confusion use one of them consistently. But from best practices perspective when you do variable declaration it's good to use \"string\" ( small \"s\") and when you are using it as a class name then \"String\" ( capital \"S\") is preferred.\n\nIn the below code the left-hand side is a variable declaration and it declared using \"string\". On the right-hand side, we are calling a method so \"String\" is more sensible.\n\nstring s = String.ToUpper() ;\n\nShare\nImprove this answer\nFollow\nedited Jan 26 at 9:38\ncommunity wiki\n\n\n4 revs, 4 users 80%\nShivprasad Koirala","comments":["But now you have 2 styles in one line? :)"]},{"answer":"Lower case string is an alias for System.String. They are the same in C#.\n\nThere's a debate over whether you should use the System types (System.Int32, System.String, etc.) types or the C# aliases (int, string, etc). I personally believe you should use the C# aliases, but that's just my personal preference.\n\nShare\nImprove this answer\nFollow\nedited Aug 14 '17 at 4:33\ncommunity wiki\n\n\n3 revs, 3 users 60%\nurini","comments":["That's the problem, they are not 'C#' aliases, they are 'C' aliases. There is no native 'string' or 'int' in the C# language, just syntactic sugar.","not sure where \"C\" came from here, since C# 5 language specification reads \"The keyword string is simply an alias for the predefined class System.String.\" on page 85, paragraph 4.2.4. All high level languages are syntactic sugar over CPU instruction sets and bytecode."]},{"answer":"string is just an alias for System.String. The compiler will treat them identically.\n\nThe only practical difference is the syntax highlighting as you mention, and that you have to write using System if you use String.\n\nShare\nImprove this answer\nFollow\nedited Dec 3 '11 at 19:53\ncommunity wiki\n\n\n4 revs, 3 users 63%\nHallgrim","comments":["You don't need to prefix System to use String.","You do have to include a using System when using String, otherwise you get the following error: The type or namespace name 'String' could not be found (are you missing a using directive or an assembly reference?)"]},{"answer":"Both are same. But from coding guidelines perspective it's better to use string instead of String. This is what generally developers use. e.g. instead of using Int32 we use int as int is alias to Int32\n\nFYI “The keyword string is simply an alias for the predefined class System.String.” - C# Language Specification 4.2.3 http://msdn2.microsoft.com/En-US/library/aa691153.aspx\n\nShare\nImprove this answer\nFollow\nedited Aug 14 '17 at 5:16\ncommunity wiki\n\n\n2 revs, 2 users 80%\nPradeep Kumar Mishra","comments":[]},{"answer":"As the others are saying, they're the same. StyleCop rules, by default, will enforce you to use string as a C# code style best practice, except when referencing System.String static functions, such as String.Format, String.Join, String.Concat, etc...\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '11 at 9:35\ncommunity wiki\n\n\n2 revs, 2 users 67%\nLloyd Cotten","comments":[]},{"answer":"New answer after 6 years and 5 months (procrastination).\n\nWhile string is a reserved C# keyword that always has a fixed meaning, String is just an ordinary identifier which could refer to anything. Depending on members of the current type, the current namespace and the applied using directives and their placement, String could be a value or a type distinct from global::System.String.\n\nI shall provide two examples where using directives will not help.\n\nFirst, when String is a value of the current type (or a local variable):\n\nclass MySequence<TElement>\n{\n  public IEnumerable<TElement> String { get; set; }\n\n  void Example()\n  {\n    var test = String.Format(\"Hello {0}.\", DateTime.Today.DayOfWeek);\n  }\n}\n\n\nThe above will not compile because IEnumerable<> does not have a non-static member called Format, and no extension methods apply. In the above case, it may still be possible to use String in other contexts where a type is the only possibility syntactically. For example String local = \"Hi mum!\"; could be OK (depending on namespace and using directives).\n\nWorse: Saying String.Concat(someSequence) will likely (depending on usings) go to the Linq extension method Enumerable.Concat. It will not go to the static method string.Concat.\n\nSecondly, when String is another type, nested inside the current type:\n\nclass MyPiano\n{\n  protected class String\n  {\n  }\n\n  void Example()\n  {\n    var test1 = String.Format(\"Hello {0}.\", DateTime.Today.DayOfWeek);\n    String test2 = \"Goodbye\";\n  }\n}\n\n\nNeither statement in the Example method compiles. Here String is always a piano string, MyPiano.String. No member (static or not) Format exists on it (or is inherited from its base class). And the value \"Goodbye\" cannot be converted into it.\n\nShare\nImprove this answer\nFollow\nanswered Jan 15 '15 at 14:21\ncommunity wiki\n\n\nJeppe Stig Nielsen","comments":[]},{"answer":"Using System types makes it easier to port between C# and VB.Net, if you are into that sort of thing.\n\nShare\nImprove this answer\nFollow\nanswered Sep 22 '08 at 19:40\ncommunity wiki\n\n\nIshmael","comments":[]},{"answer":"Against what seems to be common practice among other programmers, I prefer String over string, just to highlight the fact that String is a reference type, as Jon Skeet mentioned.\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '11 at 9:35\ncommunity wiki\n\n\n2 revs, 2 users 67%\nRolandK","comments":["Good point. If 'string' was not invented, we would not have any confusion and not need this pointless discussion. All our apps would just run fine with String. 'int' seems useful if you don't care about the bit size, which happens most of the time, and 'string' seems only added for consistency."]},{"answer":"string is an alias (or shorthand) of System.String. That means, by typing string we meant System.String. You can read more in think link: 'string' is an alias/shorthand of System.String.\n\nShare\nImprove this answer\nFollow\nedited Oct 8 '16 at 18:50\ncommunity wiki\n\n\n4 revs, 3 users 78%\nJeeShen Lee","comments":[]},{"answer":"I'd just like to add this to lfousts answer, from Ritchers book:\n\nThe C# language specification states, “As a matter of style, use of the keyword is favored over use of the complete system type name.” I disagree with the language specification; I prefer to use the FCL type names and completely avoid the primitive type names. In fact, I wish that compilers didn’t even offer the primitive type names and forced developers to use the FCL type names instead. Here are my reasons:\n\nI’ve seen a number of developers confused, not knowing whether to use string or String in their code. Because in C# string (a keyword) maps exactly to System.String (an FCL type), there is no difference and either can be used. Similarly, I’ve heard some developers say that int represents a 32-bit integer when the application is running on a 32-bit OS and that it represents a 64-bit integer when the application is running on a 64-bit OS. This statement is absolutely false: in C#, an int always maps to System.Int32, and therefore it represents a 32-bit integer regardless of the OS the code is running on. If programmers would use Int32 in their code, then this potential confusion is also eliminated.\n\nIn C#, long maps to System.Int64, but in a different programming language, long could map to an Int16 or Int32. In fact, C++/CLI does treat long as an Int32. Someone reading source code in one language could easily misinterpret the code’s intention if he or she were used to programming in a different programming language. In fact, most languages won’t even treat long as a keyword and won’t compile code that uses it.\n\nThe FCL has many methods that have type names as part of their method names. For example, the BinaryReader type offers methods such as ReadBoolean, ReadInt32, ReadSingle, and so on, and the System.Convert type offers methods such as ToBoolean, ToInt32, ToSingle, and so on. Although it’s legal to write the following code, the line with float feels very unnatural to me, and it’s not obvious that the line is correct:\n\nBinaryReader br = new BinaryReader(...);\nfloat val = br.ReadSingle(); // OK, but feels unnatural\nSingle val = br.ReadSingle(); // OK and feels good\n\n\nMany programmers that use C# exclusively tend to forget that other programming languages can be used against the CLR, and because of this, C#-isms creep into the class library code. For example, Microsoft’s FCL is almost exclusively written in C# and developers on the FCL team have now introduced methods into the library such as Array’s GetLongLength, which returns an Int64 value that is a long in C# but not in other languages (like C++/CLI). Another example is System.Linq.Enumerable’s LongCount method.\n\nI didn't get his opinion before I read the complete paragraph.\n\nShare\nImprove this answer\nFollow\nedited Dec 5 '18 at 9:34\ncommunity wiki\n\n\n2 revs, 2 users 58%\nOtiel","comments":[]},{"answer":"String (System.String) is a class in the base class library. string (lower case) is a reserved work in C# that is an alias for System.String. Int32 vs int is a similar situation as is Boolean vs. bool. These C# language specific keywords enable you to declare primitives in a style similar to C.\n\nShare\nImprove this answer\nFollow\nedited Dec 24 '13 at 4:50\ncommunity wiki\n\n\n2 revs, 2 users 67%\nJoe Alfano","comments":[]},{"answer":"It's a matter of convention, really. string just looks more like C/C++ style. The general convention is to use whatever shortcuts your chosen language has provided (int/Int for Int32). This goes for \"object\" and decimal as well.\n\nTheoretically this could help to port code into some future 64-bit standard in which \"int\" might mean Int64, but that's not the point, and I would expect any upgrade wizard to change any int references to Int32 anyway just to be safe.\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '18 at 4:24\ncommunity wiki\n\n\n2 revs, 2 users 67%\nMel","comments":[]},{"answer":"String is not a keyword and it can be used as Identifier whereas string is a keyword and cannot be used as Identifier. And in function point of view both are same.\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '11 at 9:35\ncommunity wiki\n\n\n2 revs, 2 users 67%\nuser576533","comments":[]},{"answer":"Coming late to the party: I use the CLR types 100% of the time (well, except if forced to use the C# type, but I don't remember when the last time that was).\n\nI originally started doing this years ago, as per the CLR books by Ritchie. It made sense to me that all CLR languages ultimately have to be able to support the set of CLR types, so using the CLR types yourself provided clearer, and possibly more \"reusable\" code.\n\nNow that I've been doing it for years, it's a habit and I like the coloration that VS shows for the CLR types.\n\nThe only real downer is that auto-complete uses the C# type, so I end up re-typing automatically generated types to specify the CLR type instead.\n\nAlso, now, when I see \"int\" or \"string\", it just looks really wrong to me, like I'm looking at 1970's C code.\n\nShare\nImprove this answer\nFollow\nanswered Aug 24 '12 at 15:22\ncommunity wiki\n\n\nMichael Ray Lovett","comments":[]},{"answer":"@JaredPar (a developer on the C# compiler and prolific SO user!) wrote a great blog post on this issue. I think it is worth sharing here. It is a nice perspective on our subject.\n\nstring vs. String is not a style debate\n\n[...]\n\nThe keyword string has concrete meaning in C#. It is the type System.String which exists in the core runtime assembly. The runtime intrinsically understands this type and provides the capabilities developers expect for strings in .NET. Its presence is so critical to C# that if that type doesn’t exist the compiler will exit before attempting to even parse a line of code. Hence string has a precise, unambiguous meaning in C# code.\n\nThe identifier String though has no concrete meaning in C#. It is an identifier that goes through all the name lookup rules as Widget, Student, etc … It could bind to string or it could bind to a type in another assembly entirely whose purposes may be entirely different than string. Worse it could be defined in a way such that code like String s = \"hello\"; continued to compile.\n\nclass TricksterString { \n  void Example() {\n    String s = \"Hello World\"; // Okay but probably not what you expect.\n  }\n}\n\nclass String {\n  public static implicit operator String(string s) => null;\n}\n\n\nThe actual meaning of String will always depend on name resolution. That means it depends on all the source files in the project and all the types defined in all the referenced assemblies. In short it requires quite a bit of context to know what it means.\n\nTrue that in the vast majority of cases String and string will bind to the same type. But using String still means developers are leaving their program up to interpretation in places where there is only one correct answer. When String does bind to the wrong type it can leave developers debugging for hours, filing bugs on the compiler team, and generally wasting time that could’ve been saved by using string.\n\nAnother way to visualize the difference is with this sample:\n\nstring s1 = 42; // Errors 100% of the time  \nString s2 = 42; // Might error, might not, depends on the code\n\n\nMany will argue that while this is information technically accurate using String is still fine because it’s exceedingly rare that a codebase would define a type of this name. Or that when String is defined it’s a sign of a bad codebase.\n\n[...]\n\nYou’ll see that String is defined for a number of completely valid purposes: reflection helpers, serialization libraries, lexers, protocols, etc … For any of these libraries String vs. string has real consequences depending on where the code is used.\n\nSo remember when you see the String vs. string debate this is about semantics, not style. Choosing string gives crisp meaning to your codebase. Choosing String isn’t wrong but it’s leaving the door open for surprises in the future.\n\nNote: I copy/pasted most of the blog posts for archive reasons. I ignore some parts, so I recommend skipping and reading the blog post if you can.\n\nShare\nImprove this answer\nFollow\nedited Jan 26 at 0:42\ncommunity wiki\n\n\n4 revs, 3 users 92%\naloisdg","comments":["Glad to find this answer here. There is a difference and it's important."]},{"answer":"There is no difference.\n\nThe C# keyword string maps to the .NET type System.String - it is an alias that keeps to the naming conventions of the language.\n\nSimilarly, int maps to System.Int32.\n\nShare\nImprove this answer\nFollow\nedited Jan 15 '12 at 0:30\ncommunity wiki\n\n\n2 revs, 2 users 89%\nOded","comments":[]},{"answer":"There's a quote on this issue from Daniel Solis' book.\n\nAll the predefined types are mapped directly to underlying .NET types. The C# type names (string) are simply aliases for the .NET types (String or System.String), so using the .NET names works fine syntactically, although this is discouraged. Within a C# program, you should use the C# names rather than the .NET names.\n\nShare\nImprove this answer\nFollow\nedited Dec 11 '16 at 5:27\ncommunity wiki\n\n\n3 revs, 3 users 67%\nuser2771704","comments":[]},{"answer":"Yes, that's no difference between them, just like the bool and Boolean.\n\nShare\nImprove this answer\nFollow\nedited Dec 25 '15 at 12:55\ncommunity wiki\n\n\n2 revs, 2 users 67%\nCoder","comments":[]},{"answer":"string is a keyword, and you can't use string as an identifier.\n\nString is not a keyword, and you can use it as an identifier:\n\nExample\n\nstring String = \"I am a string\";\n\n\nThe keyword string is an alias for System.String aside from the keyword issue, the two are exactly equivalent.\n\n typeof(string) == typeof(String) == typeof(System.String)\n\nShare\nImprove this answer\nFollow\nedited Mar 16 '16 at 19:35\ncommunity wiki\n\n\n2 revs, 2 users 73%\nCoreDeveloper","comments":["The only tiny difference is that if you use the String class, you need to import the System namespace on top of your file, whereas you don’t have to do this when using the string keyword.","There are simple use-cases where the equality statement would fail... Such as defining a type call String in the blah namespace and importing that namespace into the file in which the equality statement is running."]}]},{"id":"394809","href":"https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator","title":"Does Python have a ternary conditional operator?","description":"\n                \nIf Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?\n    ","questionComments":["In the Python 3.0 official documentation referenced in a comment above, this is referred to as \"conditional_expressions\" and is very cryptically defined. That documentation doesn't even include the term \"ternary\", so you would be hard-pressed to find it via Google unless you knew exactly what to look for. The version 2 documentation is somewhat more helpful and includes a link to \"PEP 308\", which includes a lot of interesting historical context related to this question.","\"ternary\" (having three inputs) is a consequential property of this impelmentation, not a defining property of the concept. eg: SQL has case [...] { when ... then ...} [ else ... ] end for a similar effect but not at all ternary.","also ISO/IEC 9899 (the C programming language standard) section 6.5.15 calls it the \"the condtitional operator\"","Wikipedia covers this thoroughly in the article \"?:\".","In the years since nobar's comment the conditional expression documentation has been updated to say Conditional expressions (sometimes called a “ternary operator”)..."],"answers":[{"answer":"Yes, it was added in version 2.5. The expression syntax is:\n\na if condition else b\n\n\nFirst condition is evaluated, then exactly one of either a or b is evaluated and returned based on the Boolean value of condition. If condition evaluates to True, then a is evaluated and returned but b is ignored, or else when b is evaluated and returned but a is ignored.\n\nThis allows short-circuiting because when condition is true only a is evaluated and b is not evaluated at all, but when condition is false only b is evaluated and a is not evaluated at all.\n\nFor example:\n\n>>> 'true' if True else 'false'\n'true'\n>>> 'true' if False else 'false'\n'false'\n\n\nNote that conditionals are an expression, not a statement. This means you can't use assignment statements or pass or other statements within a conditional expression:\n\n>>> pass if False else x = 3\n  File \"<stdin>\", line 1\n    pass if False else x = 3\n          ^\nSyntaxError: invalid syntax\n\n\nYou can, however, use conditional expressions to assign a variable like so:\n\nx = a if True else b\n\n\nThink of the conditional expression as switching between two values. It is very useful when you're in a 'one value or another' situation, it but doesn't do much else.\n\nIf you need to use statements, you have to use a normal if statement instead of a conditional expression.\n\nKeep in mind that it's frowned upon by some Pythonistas for several reasons:\n\nThe order of the arguments is different from those of the classic condition ? a : b ternary operator from many other languages (such as C, C++, Go, Perl, Ruby, Java, Javascript, etc.), which may lead to bugs when people unfamiliar with Python's \"surprising\" behaviour use it (they may reverse the argument order).\nSome find it \"unwieldy\", since it goes contrary to the normal flow of thought (thinking of the condition first and then the effects).\nStylistic reasons. (Although the 'inline if' can be really useful, and make your script more concise, it really does complicate your code)\n\nIf you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, x = 4 if b > 8 else 9 is read aloud as x will be 4 if b is greater than 8 otherwise 9.\n\nOfficial documentation:\n\nConditional expressions\nIs there an equivalent of C’s ”?:” ternary operator?\nShare\nImprove this answer\nFollow\nedited Aug 5 '20 at 23:52\ncommunity wiki\n\n\n19 revs, 15 users 23%\nVinko Vrsalovic","comments":["The order may seems strange for coders however f(x) = |x| = x if x > 0 else -x sounds very natural to mathematicians. You may also understand it as do A in most case, except when C then you should do B instead...","Be careful with order of operations when using this. For example, the line z = 3 + x if x < y else y. If x=2 and y=1, you might expect that to yield 4, but it would actually yield 1. z = 3 + (x if x > y else y) is the correct usage.","The point was if you want to perform additional evaluations after the conditional is evaluated, like adding a value to the result, you'll either need to add the additional expression to both sides (z = 3 + x if x < y else 3 + y), or group the conditional (z = 3 + (x if x < y else y) or z = (x if x < y else y) + 3)","@MrGeek, I see what you mean, so you would basically be nesting the operations: ` \"foo\" if Bool else (\"bar\" if Bool else \"foobar\") `","Programmers need precise correct formulation even more than mathematician, because in mathematics there is always a resort to underlying concepts. A convincing argument is the % operator, mimicking the way \"mod\" is used in math would have been a disaster. So no, I don't accept your argument. It is like adhering to imperial units. Groetjes Albert"]},{"answer":"You can index into a tuple:\n\n(falseValue, trueValue)[test]\n\n\ntest needs to return True or False.\nIt might be safer to always implement it as:\n\n(falseValue, trueValue)[test == True]\n\n\nor you can use the built-in bool() to assure a Boolean value:\n\n(falseValue, trueValue)[bool(<expression>)]\n\nShare\nImprove this answer\nFollow\nedited Oct 17 '15 at 7:35\ncommunity wiki\n\n\nLandon Kuhn","comments":["Note that this one always evaluates everything, whereas the if/else construct only evaluates the winning expression.","(lambda: print(\"a\"), lambda: print(\"b\"))[test==true]()","It should be noted that what's within the []s can be an arbitrary expression. Also, for safety you can explicitly test for truthiness by writing [bool(<expression>)]. The bool() function has been around since v2.2.1.","I've done a similar trick -- only once or twice, but done it -- by indexing into a dictionary with True and False as the keys: {True:trueValue, False:falseValue}[test] I don't know whether this is any less efficient, but it does at least avoid the whole \"elegant\" vs. \"ugly\" debate. There's no ambiguity that you're dealing with a boolean rather than an int.","comparisons to singletons should always use is/is not instead of =="]},{"answer":"For versions prior to 2.5, there's the trick:\n\n[expression] and [on_true] or [on_false]\n\n\nIt can give wrong results when on_true has a false boolean value.1\nAlthough it does have the benefit of evaluating expressions left to right, which is clearer in my opinion.\n\n1. Is there an equivalent of C’s ”?:” ternary operator?\n\nShare\nImprove this answer\nFollow\nedited Jan 13 '14 at 7:16\ncommunity wiki\n\n\nJames Brady","comments":["The remedy is to use (test and [true_value] or [false_value])[0], which avoids this trap.","Ternary operator usually executes faster(sometimes by 10-25%).","@volcano Do you have source for me?","@OrangeTux Here's the disassembled code. Using the method ThomasH suggested would be even slower."]},{"answer":" <expression 1> if <condition> else <expression 2> \n\na = 1\nb = 2\n\n1 if a > b else -1 \n# Output is -1\n\n1 if a > b else -1 if a < b else 0\n# Output is -1\n\nShare\nImprove this answer\nFollow\nedited May 15 '19 at 15:03\ncommunity wiki\n\n\n3 revs, 2 users 62%\nSimon Zimmermann","comments":["This one emphasizes the primary intent of the ternary operator: value selection. It also shows that more than one ternary can be chained together into a single expression.","@Craig , I agree, but it's also helpful to know what will happen when there are no parentheses. In real code, I too would tend to insert explicit parens.","Use: return 3 if t > 10 else t/2"]},{"answer":"From the documentation:\n\nConditional expressions (sometimes called a “ternary operator”) have the lowest priority of all Python operations.\n\nThe expression x if C else y first evaluates the condition, C (not x); if C is true, x is evaluated and its value is returned; otherwise, y is evaluated and its value is returned.\n\nSee PEP 308 for more details about conditional expressions.\n\nNew since version 2.5.\n\nShare\nImprove this answer\nFollow\nedited Oct 17 '15 at 7:43\ncommunity wiki\n\n\nMichael Burr","comments":[]},{"answer":"An operator for a conditional expression in Python was added in 2006 as part of Python Enhancement Proposal 308. Its form differ from common ?: operator and it's:\n\n<expression1> if <condition> else <expression2>\n\n\nwhich is equivalent to:\n\nif <condition>: <expression1> else: <expression2>\n\n\nHere is an example:\n\nresult = x if a > b else y\n\n\nAnother syntax which can be used (compatible with versions before 2.5):\n\nresult = (lambda:y, lambda:x)[a > b]()\n\n\nwhere operands are lazily evaluated.\n\nAnother way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages):\n\nresult = (y, x)[a > b]\n\n\nor explicitly constructed dictionary:\n\nresult = {True: x, False: y}[a > b]\n\n\nAnother (less reliable), but simpler method is to use and and or operators:\n\nresult = (a > b) and x or y\n\n\nhowever this won't work if x would be False.\n\nA possible workaround is to make x and y lists or tuples as in the following:\n\nresult = ((a > b) and [x] or [y])[0]\n\n\nor:\n\nresult = ((a > b) and (x,) or (y,))[0]\n\n\nIf you're working with dictionaries, instead of using a ternary conditional, you can take advantage of get(key, default), for example:\n\nshell = os.environ.get('SHELL', \"/bin/sh\")\n\n\nSource: ?: in Python at Wikipedia\n\nShare\nImprove this answer\nFollow\nedited Aug 7 '17 at 14:22\ncommunity wiki\n\n\n2 revs, 2 users 98%\nkenorb","comments":["result = {1: x, 0: y}[a > b] is another possible variant (True and False are actually integers with values 1 and 0)"]},{"answer":"Unfortunately, the\n\n(falseValue, trueValue)[test]\n\n\nsolution doesn't have short-circuit behaviour; thus both falseValue and trueValue are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both trueValue and falseValue could be methods and have side-effects).\n\nOne solution to this would be\n\n(lambda: falseValue, lambda: trueValue)[test]()\n\n\n(execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties.\n\nAnd so the story goes - choosing between 3 mentioned solutions is a trade-off between having the short-circuit feature, using at least Зython 2.5 (IMHO not a problem anymore) and not being prone to \"trueValue-evaluates-to-false\" errors.\n\nShare\nImprove this answer\nFollow\nedited May 9 '19 at 9:45\ncommunity wiki\n\n\n5 revs, 4 users 76%\ngorsky","comments":["While the tuple of lambdas trick works, it takes roughly 3x as long as the ternary operator. It's only likely to be a reasonable idea if it can replace a long chain of if else if."]},{"answer":"Ternary Operator in different programming Languages\n\nHere I just try to show some important difference in ternary operator between a couple of programming languages.\n\nTernary Operator in Javascript\n\nvar a = true ? 1 : 0;\n# 1\nvar b = false ? 1 : 0;\n# 0\n\n\nTernary Operator in Ruby\n\na = true ? 1 : 0\n# 1\nb = false ? 1 : 0\n# 0\n\n\nTernary operator in Scala\n\nval a = true ? 1 | 0\n# 1\nval b = false ? 1 | 0\n# 0\n\n\nTernary operator in R programming\n\na <- if (TRUE) 1 else 0\n# 1\nb <- if (FALSE) 1 else 0\n# 0\n\n\nTernary operator in Python\n\na = 1 if True else 0\n# 1\nb = 1 if False else 0\n# 0\n\nShare\nImprove this answer\nFollow\nedited Jan 26 '19 at 14:05\ncommunity wiki\n\n\n3 revs, 3 users 96%\nSimplans","comments":["This blogger found python's ternary operator to be unnecessarily different than most other languages.","It may sound opinionated; but what it essentially says is that it the Python syntax is likely to be understood by a person who never saw a ternary operator, while very few people will understand the more usual syntax unless they have been told first what it means.","Algol68: a=.if. .true. .then. 1 .else. 0 .fi. This may be expressed also a=(.true.|1|0) As usual Algol68 is an improvement over its successors.","something simple as print a || '<alt text>' in ruby is pita in python print a if a is not None else 'alt text'","@VarunGarg But of course you can say print(a or 'alt text') in Python."]},{"answer":"For Python 2.5 and newer there is a specific syntax:\n\n[on_true] if [cond] else [on_false]\n\n\nIn older Pythons a ternary operator is not implemented but it's possible to simulate it.\n\ncond and on_true or on_false\n\n\nThough, there is a potential problem, which if cond evaluates to True and on_true evaluates to False then on_false is returned instead of on_true. If you want this behavior the method is OK, otherwise use this:\n\n{True: on_true, False: on_false}[cond is True] # is True, not == True\n\n\nwhich can be wrapped by:\n\ndef q(cond, on_true, on_false)\n    return {True: on_true, False: on_false}[cond is True]\n\n\nand used this way:\n\nq(cond, on_true, on_false)\n\n\nIt is compatible with all Python versions.\n\nShare\nImprove this answer\nFollow\nedited Apr 25 '12 at 12:02\ncommunity wiki\n\n\nPaolo","comments":["The behaviour is not identical - q(\"blob\", on_true, on_false) returns on_false, whereas on_true if cond else on_false returns on_true. A workaround is to replace cond with cond is not None in these cases, although that is not a perfect solution.","Why not bool(cond) instead of cond is True? The former checks the truthiness of cond, the latter checks for pointer-equality with the True object. As highlighted by @AndrewCecil, \"blob\" is truthy but it is not True.","Wow, that looks really hacky! :) Technically, you can even write [on_false, on_True][cond is True] so the expression becomes shorter.","There is no short circuit in this answer. If on_true and on_false are expensive to call this is a bad answer."]},{"answer":"You might often find\n\ncond and on_true or on_false\n\n\nbut this lead to problem when on_true == 0\n\n>>> x = 0\n>>> print x == 0 and 0 or 1 \n1\n>>> x = 1\n>>> print x == 0 and 0 or 1 \n1\n\n\nwhere you would expect for a normal ternary operator this result\n\n>>> x = 0\n>>> print 0 if x == 0 else 1 \n0\n>>> x = 1\n>>> print 0 if x == 0 else 1 \n1\n\nShare\nImprove this answer\nFollow\nanswered Jan 14 '13 at 15:56\ncommunity wiki\n\n\nBenoit Bertholon","comments":[]},{"answer":"Does Python have a ternary conditional operator?\n\nYes. From the grammar file:\n\ntest: or_test ['if' or_test 'else' test] | lambdef\n\n\nThe part of interest is:\n\nor_test ['if' or_test 'else' test]\n\n\nSo, a ternary conditional operation is of the form:\n\nexpression1 if expression2 else expression3\n\n\nexpression3 will be lazily evaluated (that is, evaluated only if expression2 is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.)\n\nexpression1 if expression2 else expression3 if expression4 else expression5 # and so on\n\nA note on usage:\n\nNote that every if must be followed with an else. People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else:\n\n[expression1 if expression2 for element in iterable]\n#                          ^-- need an else here\n\n\nwhich raises a SyntaxError: invalid syntax. So the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use expression2 as a filter - notes that the following is legal Python:\n\n[expression1 for element in iterable if expression2]\n\n\nexpression2 works as a filter for the list comprehension, and is not a ternary conditional operator.\n\nAlternative syntax for a more narrow case:\n\nYou may find it somewhat painful to write the following:\n\nexpression1 if expression1 else expression2\n\n\nexpression1 will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use or's shortcutting behavior:\n\nexpression1 or expression2\n\n\nwhich is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax.\n\nShare\nImprove this answer\nFollow\nedited Aug 8 '16 at 18:56\ncommunity wiki\n\n\n2 revs\nAaron Hall","comments":["expression1 or expression2 being similar and with the same drawbacks/positives as expression1 || expression2 in javascript","Thanks, @selurvedu - it can be confusing until you get it straight. I learned the hard way, so your way might not be as hard. ;) Using if without the else, at the end of a generator expression or list comprehension will filter the iterable. In the front, it's a ternary conditional operation, and requires the else. Cheers!!","@AaronHall Although your use of metasyntactic expressionN for all instances is consistent, it might be easier to understand with naming that distinguished the conditional test expression from the two result expressions; eg, result1 if condition else result2. This is especially evident when nesting (aka chaining): result1 if condition1 else result2 if condition2 else result3. See how much better that reads this way?","@tchrist thanks for the review - if you look at the revision history, this post currently has two revisions. Most of my other answers, especially the top ones, have been revisited again and again. This answer never gets my attention because the community wiki status gives me no credit for the content, and so I never see any votes on it. As I don't really have time for an edit on this right now, frog knows when it will come to my attention again in the future. I can see you've edited the top answer, so feel free to borrow/quote my material from this post in that one (and cite me if apropos!)"]},{"answer":"Simulating the python ternary operator.\n\nFor example\n\na, b, x, y = 1, 2, 'a greather than b', 'b greater than a'\nresult = (lambda:y, lambda:x)[a > b]()\n\n\noutput:\n\n'b greater than a'\n\nShare\nImprove this answer\nFollow\nanswered Nov 20 '13 at 10:44\ncommunity wiki\n\n\nSasikiran Vaddi","comments":["Why not simply result = (y, x)[a < b] Why do you uses lambda function ?","@GrijeshChauhan Because on \"compliated\" expressions, e. g. involving a function call etc., this would be executed in both cases. This might not be wanted.","The use of lambda functions is an overkill for this question","@GrijeshChauhan In short, this implements the so-called “short-circuit evaluation”. Generally, P ? x : y or x if P else y can be written as (lambda:y, lambda:x)[P]() — but I doubt it has better performance and thus its necessity."]},{"answer":"a if condition else b\n\n\nJust memorize this pyramid if you have trouble remembering:\n\n     condition\n  if           else\na                   b \n\nShare\nImprove this answer\nFollow\nanswered Dec 6 '18 at 14:45\ncommunity wiki\n\n\nshivtej","comments":[]},{"answer":"One of the alternatives to Python's conditional expression\n\n\"yes\" if boolean else \"no\"\n\n\nis the following:\n\n{True:\"yes\", False:\"no\"}[boolean]\n\n\nwhich has the following nice extension:\n\n{True:\"yes\", False:\"no\", None:\"maybe\"}[boolean_or_none]\n\n\nThe shortest alternative remains:\n\n(\"no\", \"yes\")[boolean]\n\n\nbut there is no alternative to\n\nyes() if boolean else no()\n\n\nif you want to avoid the evaluation of yes() and no(), because in\n\n(no(), yes())[boolean]  # bad\n\n\nboth no() and yes() are evaluated.\n\nShare\nImprove this answer\nFollow\nedited Feb 22 '20 at 13:03\ncommunity wiki\n\n\n4 revs\nWalter Tross","comments":[]},{"answer":"Ternary conditional operator simply allows testing a condition in a single line replacing the multiline if-else making the code compact.\n\nSyntax :\n\n[on_true] if [expression] else [on_false]\n\n1- Simple Method to use ternary operator:\n# Program to demonstrate conditional operator\na, b = 10, 20\n# Copy value of a in min if a < b else copy b\nmin = a if a < b else b\nprint(min)  # Output: 10\n\n2- Direct Method of using tuples, Dictionary, and lambda:\n# Python program to demonstrate ternary operator\na, b = 10, 20\n# Use tuple for selecting an item\nprint( (b, a) [a < b] )\n# Use Dictionary for selecting an item\nprint({True: a, False: b} [a < b])\n# lamda is more efficient than above two methods\n# because in lambda  we are assure that\n# only one expression will be evaluated unlike in\n# tuple and Dictionary\nprint((lambda: b, lambda: a)[a < b]()) # in output you should see three 10\n\n3- Ternary operator can be written as nested if-else:\n# Python program to demonstrate nested ternary operator\na, b = 10, 20\nprint (\"Both a and b are equal\" if a == b else \"a is greater than b\"\n        if a > b else \"b is greater than a\")\n\n\nAbove approach can be written as:\n\n# Python program to demonstrate nested ternary operator\na, b = 10, 20\nif a != b:\n    if a > b:\n        print(\"a is greater than b\")\n    else:\n        print(\"b is greater than a\")\nelse:\n    print(\"Both a and b are equal\") \n# Output: b is greater than a\n\nShare\nImprove this answer\nFollow\nanswered Apr 4 '18 at 14:02\ncommunity wiki\n\n\nAli Hallaji","comments":["Note that the ternary operator is smaller (in memory) and faster than the nested if. Also, your nested if-else isn't actually a rewrite of the ternary operator, and will produce different output for select values of a and b (specifically if one is a type which implements a weird __ne__ method)."]},{"answer":"you can do this :-\n\n[condition] and [expression_1] or [expression_2] ;\n\nExample:-\n\nprint(number%2 and \"odd\" or \"even\")\n\nThis would print \"odd\" if the number is odd or \"even\" if the number is even.\n\nThe result :- If condition is true exp_1 is executed else exp_2 is executed.\n\nNote :- 0 , None , False , emptylist , emptyString evaluates as False. And any data other than 0 evaluates to True.\n\nHere's how it works:\n\nif the condition [condition] becomes \"True\" then , expression_1 will be evaluated but not expression_2 . If we \"and\" something with 0 (zero) , the result will always to be fasle .So in the below statement ,\n\n0 and exp\n\n\nThe expression exp won't be evaluated at all since \"and\" with 0 will always evaluate to zero and there is no need to evaluate the expression . This is how the compiler itself works , in all languages.\n\nIn\n\n1 or exp\n\n\nthe expression exp won't be evaluated at all since \"or\" with 1 will always be 1. So it won't bother to evaluate the expression exp since the result will be 1 anyway . (compiler optimization methods).\n\nBut in case of\n\nTrue and exp1 or exp2\n\n\nThe second expression exp2 won't be evaluated since True and exp1 would be True when exp1 isn't false .\n\nSimilarly in\n\nFalse and exp1 or exp2\n\n\nThe expression exp1 won't be evaluated since False is equivalent to writing 0 and doing \"and\" with 0 would be 0 itself but after exp1 since \"or\" is used, it will evaluate the expression exp2 after \"or\" .\n\nNote:- This kind of branching using \"or\" and \"and\" can only be used when the expression_1 doesn't have a Truth value of False (or 0 or None or emptylist [ ] or emptystring ' '.) since if expression_1 becomes False , then the expression_2 will be evaluated because of the presence \"or\" between exp_1 and exp_2.\n\nIn case you still want to make it work for all the cases regardless of what exp_1 and exp_2 truth values are, do this :-\n\n[condition] and ([expression_1] or 1) or [expression_2] ;\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n3 revs\nNatesh bhat","comments":["If you want to use that in the context of x = [condition] and ([expression_1] or 1) or [expression_2] and expression_1 evaluates to false, x will be 1, not expression_1. Use the accepted answer."]},{"answer":"More a tip than an answer (don't need to repeat the obvious for the hundreth time), but I sometimes use it as a oneliner shortcut in such constructs:\n\nif conditionX:\n    print('yes')\nelse:\n    print('nah')\n\n\n, becomes:\n\nprint('yes') if conditionX else print('nah')\n\n\nSome (many :) may frown upon it as unpythonic (even, ruby-ish :), but I personally find it more natural - i.e. how you'd express it normally, plus a bit more visually appealing in large blocks of code.\n\nShare\nImprove this answer\nFollow\nedited May 23 '16 at 19:16\ncommunity wiki\n\n\n2 revs, 2 users 96%\nTodor","comments":["I prefer print( 'yes' if conditionX else 'nah' ) over your answer. :-)","That is if you want to print() in both cases - and it looks a bit more pythonic, I have to admit :) But what if the expressions/functions are not the same - like print('yes') if conditionX else True - to get the print() only in truthy conditionX ","To add to Frederick99's remark, another reason to avoid print('yes') if conditionX else print('nah') is that it gives a SyntaxError in Python2.","The only reason it gives a syntax error is because in Python 2 print is a statement - print \"yes\", while in Python 3 it is a function - print(\"yes\"). That can be resolved by either using it as a statement, or better - from future import print_function."]},{"answer":"As already answered, yes there is a ternary operator in python:\n\n<expression 1> if <condition> else <expression 2>\n\n\nAdditional information:\n\nIf <expression 1> is the condition you can use Short-cirquit evaluation:\n\na = True\nb = False\n\n# Instead of this:\nx = a if a else b\n\n# You could use Short-cirquit evaluation:\nx = a or b\n\n\nPS: Of course, a Short-cirquit evaluation is not a ternary operator but often the ternary is used in cases where the short circuit would be enough.\n\nShare\nImprove this answer\nFollow\nanswered Oct 16 '19 at 8:37\ncommunity wiki\n\n\nFrank","comments":[]},{"answer":"Vinko Vrsalovic's answer is good enough. There is only one more thing:\n\nNote that conditionals are an expression, not a statement. This means you can't use assignment statements or pass or other statements within a conditional expression\n\nWalrus operator in Python 3.8\n\nAfter that walrus operator was introduced in Python 3.8, there is something changed.\n\n(a := 3) if True else (b := 5)\n\n\ngives a = 3 and b is not defined,\n\n(a := 3) if False else (b := 5)\n\n\ngives a is not defined and b = 5, and\n\nc = (a := 3) if False else (b := 5)\n\n\ngives c = 5, a is not defined and b = 5.\n\nEven if this may be ugly, assignments can be done inside conditional expressions after Python 3.8. Anyway, it is still better to use normal if statement instead in this case.\n\nShare\nImprove this answer\nFollow\nanswered Dec 23 '20 at 10:01\ncommunity wiki\n\n\nDavid Chung","comments":["In the first example: (a := 3) if True else (b := 5) actually it's a redundant first walrus operator. This will do: a = 3 if True else (b := 5)","@AndrewAnderson No it's not redundant. You should compare both the first and the second examples. You can combine them and consider this: (a := 3) if x else (b := 5), you always get either a or b assigned, not both. However, consider a = 3 if x else (b := 5), when x == False, you will get a = 5 and b = 5, where both them are assigned.","Yes, that's correct :). I considered this only for x=True case which is of course is limited.","Because we don't really write down this code if True else, the reason of the first example is only compared with other examples."]},{"answer":"Many programming languages derived from C usually have the following syntax of ternary conditional operator:\n\n<condition> ? <expression1> : <expression2>\n\n\nAt first, the Python Benevolent Dictator For Life (I mean Guido van Rossum, of course) rejected it (as non-Pythonic style), since it's quite hard to understand for people not used to C language. Also, the colon sign : already has many uses in Python. After PEP 308 was approved, Python finally received its own shortcut conditional expression (what we use now):\n\n<expression1> if <condition> else <expression2>\n\n\nSo, firstly it evaluates the condition. If it returns True, expression1 will be evaluated to give the result, otherwise expression2 will be evaluated. Due to Lazy Evaluation mechanics – only one expression will be executed.\n\nHere are some examples (conditions will be evaluated from left to right):\n\npressure = 10\nprint('High' if pressure < 20 else 'Critical')\n\n# Result is 'High'\n\n\nTernary operators can be chained in series:\n\npressure = 5\nprint('Normal' if pressure < 10 else 'High' if pressure < 20 else 'Critical')\n\n# Result is 'Normal'\n\n\nThe following one is the same as previous one:\n\npressure = 5\n\nif pressure < 20:\n    if pressure < 10:\n        print('Normal')\n    else:\n        print('High')\nelse:\n    print('Critical')\n\n# Result is 'Normal'\n\n\nHope this helps.\n\nShare\nImprove this answer\nFollow\nedited Jan 4 '19 at 22:02\ncommunity wiki\n\n\n3 revs, 2 users 99%\nARGeo","comments":[]},{"answer":"YES, python have a ternary operator, here is the syntax and an example code to demonstrate the same :)\n\n#[On true] if [expression] else[On false]\n# if the expression evaluates to true then it will pass On true otherwise On false\n\n\na= input(\"Enter the First Number \")\nb= input(\"Enter the Second Number \")\n\nprint(\"A is Bigger\") if a>b else print(\"B is Bigger\")\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '18 at 20:46\ncommunity wiki\n\n\n2 revs\nPythonLover","comments":["I have added a one line statement example to check which number is big to elaborate it further","print is really not a good choice, as this will give a SyntaxError in Python2.","@Thierry Lathuille here I used print() function not print statement, print function is for Python 3 while print statement is for Python 2","The question has already been asked on SO, just try it with Python 2 and you will see by yourself. 'print('hello') is a perfectly valid syntax in Python 2.7, but the way it is parsed makes your code above throw a SyntaxError."]},{"answer":"Other answers correctly talk about the Python ternary operator. I would like to complement by mentioning a scenario for which the ternary operator is often used but for which there is a better idiom. This is the scenario of using a default value.\n\nSuppose we want to use option_value with a default value if it is not set:\n\nrun_algorithm(option_value if option_value is not None else 10)\n\n\nor, if option_value is never set to a falsy value (0, \"\", etc), simply\n\nrun_algorithm(option_value if option_value else 10)\n\n\nHowever, in this case an ever better solution is simply to write\n\nrun_algorithm(option_value or 10)\n\nShare\nImprove this answer\nFollow\nedited Oct 22 '20 at 14:04\ncommunity wiki\n\n\n2 revs\nuser118967","comments":["A valuable complement, but I disagree: option_value or 10 is not better than option_value if option_value is not None else 10. It is shorter, indeed, but looks weird to me and may lead to bugs. What happens if option_value = 0, for instance? The first snippet will run run_algorithm(0) because option_value is not None. The second and third snippets, however, will run run_algorithm(10) because 0 is a falsy. The two snippets are not equivalent, and hence one is not better than the other. And explicit is better than implicit.","@ruancomelli: Good point. I've modified the answer to reflect that correction.","As for it looking weird, I wonder if it looked weird to you because you noticed the imprecision (that it was not really equivalent). To me it sounds natural because it reminds me saying in English: \"Use this or that (if the first option is unavailable)\". But of course that is subjective. It is useful to know it does not look natural to everybody.","Much better! And thanks for the explanation regarding the \"or\"-idiom. It looks weird to me because I tend to think of or as a function mapping two arguments to a boolean, so I expect it to return either True or False (this happens in many other programming languages). But \"use this or that\" is a nice mnemonic and will definitely help me (and hopefully others) to remember this pattern."]},{"answer":"Python has a ternary form for assignments; however there may be even a shorter form that people should be aware of.\n\nIt's very common to need to assign to a variable one value or another depending on a condition.\n\n>>> li1 = None\n>>> li2 = [1, 2, 3]\n>>> \n>>> if li1:\n...     a = li1\n... else:\n...     a = li2\n...     \n>>> a\n[1, 2, 3]\n\n\n^ This is the long form for doing such assignments.\n\nBelow is the ternary form. But this isn't most succinct way - see last example.\n\n>>> a = li1 if li1 else li2\n>>> \n>>> a\n[1, 2, 3]\n>>> \n\n\nWith Python, you can simply use or for alternative assignments.\n\n>>> a = li1 or li2\n>>> \n>>> a\n[1, 2, 3]\n>>> \n\n\nThe above works since li1 is None and the interp treats that as False in logic expressions. The interp then moves on and evaluates the second expression, which is not None and it's not an empty list - so it gets assigned to a.\n\nThis also works with empty lists. For instance, if you want to assign a whichever list has items.\n\n>>> li1 = []\n>>> li2 = [1, 2, 3]\n>>> \n>>> a = li1 or li2\n>>> \n>>> a\n[1, 2, 3]\n>>> \n\n\nKnowing this, you can simply such assignments whenever you encounter them. This also works with strings and other iterables. You could assign a whichever string isn't empty.\n\n>>> s1 = ''\n>>> s2 = 'hello world'\n>>> \n>>> a = s1 or s2\n>>> \n>>> a\n'hello world'\n>>> \n\n\nI always liked the C ternary syntax, but Python takes it a step further!\n\nI understand that some may say this isn't a good stylistic choice because it relies on mechanics that aren't immediately apparent to all developers. I personally disagree with that viewpoint. Python is a syntax rich language with lots of idiomatic tricks that aren't immediately apparent to the dabler. But the more you learn and understand the mechanics of the underlying system, the more you appreciate it.\n\nShare\nImprove this answer\nFollow\nedited Mar 15 '20 at 6:42\ncommunity wiki\n\n\n3 revs\nTodd","comments":[]},{"answer":"A neat way to chain multiple operators:\n\nf = lambda x,y: 'greater' if x > y else 'less' if y > x else 'equal'\n\narray = [(0,0),(0,1),(1,0),(1,1)]\n\nfor a in array:\n  x, y = a[0], a[1]\n  print(f(x,y))\n\n# Output is:\n#   equal,\n#   less,\n#   greater,\n#   equal\n\n\nShare\nImprove this answer\nFollow\nanswered May 12 '19 at 13:03\ncommunity wiki\n\n\nYaakov Bressler","comments":[]},{"answer":"I find cumbersome the default python syntax val = a if cond else b, so sometimes I do this:\n\niif = lambda (cond, a, b): a if cond else b\n# so I can then use it like:\nval = iif(cond, a, b)\n\n\nOf course, it has the downside of always evaluating both sides (a and b), but the syntax it's way clearer to me\n\nShare\nImprove this answer\nFollow\nanswered Mar 26 '20 at 21:59\ncommunity wiki\n\n\nBaruc Almaguer","comments":["This seems to be twice the amount of work, more RAM usage and more obfuscated than the simpler val = a if cond else b statement.","Also both a and b get evaluated here every time, unlike in a if cond else b"]},{"answer":"if variable is defined and you want to check if it has value you can just a or b\n\ndef test(myvar=None):\n    # shorter than: print myvar if myvar else \"no Input\"\n    print myvar or \"no Input\"\n\ntest()\ntest([])\ntest(False)\ntest('hello')\ntest(['Hello'])\ntest(True)\n\n\nwill output\n\nno Input\nno Input\nno Input\nhello\n['Hello']\nTrue\n\nShare\nImprove this answer\nFollow\nedited Apr 26 '18 at 16:22\ncommunity wiki\n\n\n2 revs\newwink","comments":["While useful for similar problems, this is not a ternary conditional. It works to replace x if x else y, but not x if z else y."]},{"answer":"is_spacial=True if gender = \"Female\" else (True if age >= 65 else False)\n\n\n**\n\nit can be nested as your need. best of luck\n\n**\n\nShare\nImprove this answer\nFollow\nanswered Oct 23 '19 at 7:22\ncommunity wiki\n\n\nThat's Enam","comments":[]}]},{"id":"208105","href":"https://stackoverflow.com/questions/208105/how-do-i-remove-a-property-from-a-javascript-object","title":"How do I remove a property from a JavaScript object?","description":"\n                \nSay I create an object as follows:\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nHow should I remove the property regex to end up with new myObject as follows?\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\"\n};\n\n    ","questionComments":["stackoverflow.com/questions/66047314/… Check this link out. It deals with something very similar","delete myObject.regex; // or, delete myObject['regex']; // or, var prop = \"regex\"; delete myObject[prop];"],"answers":[{"answer":"To remove a property from an object (mutating the object), you can do it like this:\n\ndelete myObject.regex;\n// or,\ndelete myObject['regex'];\n// or,\nvar prop = \"regex\";\ndelete myObject[prop];\n\n\nDemo\n\nvar myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\ndelete myObject.regex;\n\nconsole.log(myObject);\n Run code snippetExpand snippet\n\nFor anyone interested in reading more about it, Stack Overflow user kangax has written an incredibly in-depth blog post about the delete statement on their blog, Understanding delete. It is highly recommended.\n\nIf you'd like a new object with all the keys of the original except some, you could use the destructuring.\n\nDemo\n\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nconst {regex, ...newObj} = myObject;\n\nconsole.log(newObj);   // has no 'regex' key\nconsole.log(myObject); // remains unchanged\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Feb 4 at 14:07\nanswered Oct 16 '08 at 10:58\nnickf\n504k196\n196 gold badges\n617\n617 silver badges\n709\n709 bronze badges","comments":["This is a nice way to do it, but only good if you're actually going to use regex, otherwise eslint will complain about an unused variable.","@Loolooii you can rename the variable in your destructuring assignment to meet your argsIgnorePattern in the no-unused-vars rule. Easy problem to solve."]},{"answer":"Objects in JavaScript can be thought of as maps between keys and values. The delete operator is used to remove these keys, more commonly known as object properties, one at a time.\n\nvar obj = {\n  myProperty: 1    \n}\nconsole.log(obj.hasOwnProperty('myProperty')) // true\ndelete obj.myProperty\nconsole.log(obj.hasOwnProperty('myProperty')) // false\n Run code snippetExpand snippet\n\nThe delete operator does not directly free memory, and it differs from simply assigning the value of null or undefined to a property, in that the property itself is removed from the object. Note that if the value of a deleted property was a reference type (an object), and another part of your program still holds a reference to that object, then that object will, of course, not be garbage collected until all references to it have disappeared.\n\ndelete will only work on properties whose descriptor marks them as configurable.\n\nShare\nImprove this answer\nFollow\nedited Apr 18 '20 at 19:28\nBen Aston\n46.7k56\n56 gold badges\n181\n181 silver badges\n306\n306 bronze badges\nanswered Feb 12 '14 at 17:48\nDan\n49.7k36\n36 gold badges\n111\n111 silver badges\n142\n142 bronze badges","comments":[]},{"answer":"var myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\n    \ndelete myObject.regex;\n\nconsole.log ( myObject.regex); // logs: undefined\n Run code snippetExpand snippet\n\nThis works in Firefox and Internet Explorer, and I think it works in all others.\n\nShare\nImprove this answer\nFollow\nedited Jun 1 '18 at 16:29\nstr\n34.5k12\n12 gold badges\n92\n92 silver badges\n118\n118 bronze badges\nanswered Oct 16 '08 at 11:03\nredsquare\n76.1k18\n18 gold badges\n148\n148 silver badges\n156\n156 bronze badges","comments":[]},{"answer":"Old question, modern answer. Using object destructuring, an ECMAScript 6 feature, it's as simple as:\n\nconst { a, ...rest } = { a: 1, b: 2, c: 3 };\n\n\nOr with the questions sample:\n\nconst myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\nconst { regex, ...newObject } = myObject;\nconsole.log(newObject);\n\n\nYou can see it in action in the Babel try-out editor.\n\nEdit:\n\nTo reassign to the same variable, use a let:\n\nlet myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\n({ regex, ...myObject } = myObject);\nconsole.log(myObject);\n\nShare\nImprove this answer\nFollow\nedited Dec 1 '16 at 20:51\nanswered Nov 8 '16 at 18:02\nKoen.\n21.5k6\n6 gold badges\n77\n77 silver badges\n76\n76 bronze badges","comments":[]},{"answer":"The delete operator is used to remove properties from objects.\n\nconst obj = { foo: \"bar\" }\ndelete obj.foo\nobj.hasOwnProperty(\"foo\") // false\n\n\nNote that, for arrays, this is not the same as removing an element. To remove an element from an array, use Array#splice or Array#pop. For example:\n\narr // [0, 1, 2, 3, 4]\narr.splice(3,1); // 3\narr // [0, 1, 2, 4]\n\nDetails\n\ndelete in JavaScript has a different function to that of the keyword in C and C++: it does not directly free memory. Instead, its sole purpose is to remove properties from objects.\n\nFor arrays, deleting a property corresponding to an index, creates a sparse array (ie. an array with a \"hole\" in it). Most browsers represent these missing array indices as \"empty\".\n\nvar array = [0, 1, 2, 3]\ndelete array[2] // [0, 1, empty, 3]\n\n\nNote that delete does not relocate array[3] into array[2].\n\nDifferent built-in functions in JavaScript handle sparse arrays differently.\n\nfor...in will skip the empty index completely.\n\nA traditional for loop will return undefined for the value at the index.\n\nAny method using Symbol.iterator will return undefined for the value at the index.\n\nforEach, map and reduce will simply skip the missing index.\n\nSo, the delete operator should not be used for the common use-case of removing elements from an array. Arrays have a dedicated methods for removing elements and reallocating memory: Array#splice() and Array#pop.\n\nArray#splice(start[, deleteCount[, item1[, item2[, ...]]]])\n\nArray#splice mutates the array, and returns any removed indices. deleteCount elements are removed from index start, and item1, item2... itemN are inserted into the array from index start. If deleteCount is omitted then elements from startIndex are removed to the end of the array.\n\nlet a = [0,1,2,3,4]\na.splice(2,2) // returns the removed elements [2,3]\n// ...and `a` is now [0,1,4]\n\n\nThere is also a similarly named, but different, function on Array.prototype: Array#slice.\n\nArray#slice([begin[, end]])\n\nArray#slice is non-destructive, and returns a new array containing the indicated indices from start to end. If end is left unspecified, it defaults to the end of the array. If end is positive, it specifies the zero-based non-inclusive index to stop at. If end is negative it, it specifies the index to stop at by counting back from the end of the array (eg. -1 will omit the final index). If end <= start, the result is an empty array.\n\nlet a = [0,1,2,3,4]\nlet slices = [\n    a.slice(0,2),\n    a.slice(2,2),\n    a.slice(2,3),\n    a.slice(2,5) ]\n\n//   a           [0,1,2,3,4]\n//   slices[0]   [0 1]- - -   \n//   slices[1]    - - - - -\n//   slices[2]    - -[3]- -\n//   slices[3]    - -[2 4 5]\n\nArray#pop\n\nArray#pop removes the last element from an array, and returns that element. This operation changes the length of the array.\n\nShare\nImprove this answer\nFollow\nedited Apr 18 '20 at 18:40\nBen Aston\n46.7k56\n56 gold badges\n181\n181 silver badges\n306\n306 bronze badges\nanswered Sep 18 '12 at 0:56\nBraden Best\n7,8443\n3 gold badges\n29\n29 silver badges\n42\n42 bronze badges","comments":[]},{"answer":"Spread Syntax (ES6)\n\nTo complete Koen's answer, in case you want to remove a dynamic variable using the spread syntax, you can do it like so:\n\nconst key = 'a';\n\nconst { [key]: foo, ...rest } = { a: 1, b: 2, c: 3 };\n\nconsole.log(foo);  // 1\nconsole.log(rest); // { b: 2, c: 3 }\n Run code snippetExpand snippet\n\n* foo will be a new variable with the value of a (which is 1).\n\nExtended answer 😇\n\nThere are a few common ways to remove a property from an object.\nEach one has its own pros and cons (check this performance comparison):\n\nDelete Operator\n\nIt is readable and short, however, it might not be the best choice if you are operating on a large number of objects as its performance is not optimized.\n\ndelete obj[key];\n\n\nReassignment\n\nIt is more than two times faster than delete, however the property is not deleted and can be iterated.\n\nobj[key] = null;\nobj[key] = false;\nobj[key] = undefined;\n\n\nSpread Operator\n\nThis ES6 operator allows us to return a brand new object, excluding any properties, without mutating the existing object. The downside is that it has the worse performance out of the above and is not suggested to be used when you need to remove many properties at a time.\n\n{ [key]: val, ...rest } = obj;\n\nShare\nImprove this answer\nFollow\nedited Jul 19 at 13:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 12 '18 at 18:39\nLior Elrom\n15.8k15\n15 gold badges\n68\n68 silver badges\n86\n86 bronze badges","comments":["the best answer without altering original object!","This isn't removing the property, it's creating a shallow copy and not copying across the specified key and value. That's a very big difference."]},{"answer":"Another alternative is to use the Underscore.js library.\n\nNote that _.pick() and _.omit() both return a copy of the object and don't directly modify the original object. Assigning the result to the original object should do the trick (not shown).\n\nReference: link _.pick(object, *keys)\n\nReturn a copy of the object, filtered to only have values for the whitelisted keys (or array of valid keys).\n\nvar myJSONObject = \n{\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\n\n_.pick(myJSONObject, \"ircEvent\", \"method\");\n=> {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\"};\n\n\nReference: link _.omit(object, *keys)\n\nReturn a copy of the object, filtered to omit the blacklisted keys (or array of keys).\n\nvar myJSONObject = \n{\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\n\n_.omit(myJSONObject, \"regex\");\n=> {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\"};\n\n\nFor arrays, _.filter() and _.reject() can be used in a similar manner.\n\nShare\nImprove this answer\nFollow\nedited Feb 3 '18 at 19:51\nanswered May 24 '14 at 18:53\nThaddeus Albers\n3,7005\n5 gold badges\n30\n30 silver badges\n39\n39 bronze badges","comments":[]},{"answer":"To clone an object without a property:\n\nFor example:\n\nlet object = { a: 1, b: 2, c: 3 };\n\n\nAnd we need to delete a.\n\nWith an explicit prop key:\n\nconst { a, ...rest } = object;\nobject = rest;\n\n\nWith a variable prop key:\n\nconst propKey = 'a';\nconst { [propKey]: propValue, ...rest } = object;\nobject = rest;\n\n\nA cool arrow function 😎:\n\n const removeProperty = (propKey, { [propKey]: propValue, ...rest }) => rest;\n\n object = removeProperty('a', object);\n\n\nFor multiple properties\n\nconst removeProperties = (object, ...keys) => Object.entries(object).reduce((prev, [key, value]) => ({...prev, ...(!keys.includes(key) && { [key]: value }) }), {})\n\n\nUsage\n\nobject = removeProperties(object, 'a', 'b') // result => { c: 3 }\n\n\nOr\n\n    const propsToRemove = ['a', 'b']\n    object = removeProperties(object, ...propsToRemove) // result => { c: 3 }\n\nShare\nImprove this answer\nFollow\nedited Jun 23 at 20:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 7 '19 at 20:35\nYairTawil\n2,94218\n18 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"The term you have used in your question title, Remove a property from a JavaScript object, can be interpreted in some different ways. The one is to remove it for whole the memory and the list of object keys or the other is just to remove it from your object. As it has been mentioned in some other answers, the delete keyword is the main part. Let's say you have your object like:\n\nmyJSONObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\n\n\nIf you do:\n\nconsole.log(Object.keys(myJSONObject));\n\n\nthe result would be:\n\n[\"ircEvent\", \"method\", \"regex\"]\n\n\nYou can delete that specific key from your object keys like:\n\ndelete myJSONObject[\"regex\"];\n\n\nThen your objects key using Object.keys(myJSONObject) would be:\n\n[\"ircEvent\", \"method\"]\n\n\nBut the point is if you care about memory and you want to whole the object gets removed from the memory, it is recommended to set it to null before you delete the key:\n\nmyJSONObject[\"regex\"] = null;\ndelete myJSONObject[\"regex\"];\n\n\nThe other important point here is to be careful about your other references to the same object. For instance, if you create a variable like:\n\nvar regex = myJSONObject[\"regex\"];\n\n\nOr add it as a new pointer to another object like:\n\nvar myOtherObject = {};\nmyOtherObject[\"regex\"] = myJSONObject[\"regex\"];\n\n\nThen even if you remove it from your object myJSONObject, that specific object won't get deleted from the memory, since the regex variable and myOtherObject[\"regex\"] still have their values. Then how could we remove the object from the memory for sure?\n\nThe answer would be to delete all the references you have in your code, pointed to that very object and also not use var statements to create new references to that object. This last point regarding var statements, is one of the most crucial issues that we are usually faced with, because using var statements would prevent the created object from getting removed.\n\nWhich means in this case you won't be able to remove that object because you have created the regex variable via a var statement, and if you do:\n\ndelete regex; //False\n\n\nThe result would be false, which means that your delete statement haven't been executed as you expected. But if you had not created that variable before, and you only had myOtherObject[\"regex\"] as your last existing reference, you could have done this just by removing it like:\n\nmyOtherObject[\"regex\"] = null;\ndelete myOtherObject[\"regex\"];\n\n\nIn other words, a JavaScript object gets killed as soon as there is no reference left in your code pointed to that object.\n\nUpdate:\n\nThanks to @AgentME:\n\nSetting a property to null before deleting it doesn't accomplish anything (unless the object has been sealed by Object.seal and the delete fails. That's not usually the case unless you specifically try).\n\nTo get more information on Object.seal: Object.seal()\n\nShare\nImprove this answer\nFollow\nedited Jul 19 at 12:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 12 '14 at 6:29\nMehran Hatami\n11.9k5\n5 gold badges\n26\n26 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"ECMAScript 2015 (or ES6) came with built-in Reflect object. It is possible to delete object property by calling Reflect.deleteProperty() function with target object and property key as parameters:\n\nReflect.deleteProperty(myJSONObject, 'regex');\n\n\nwhich is equivalent to:\n\ndelete myJSONObject['regex'];\n\n\nBut if the property of the object is not configurable it cannot be deleted neither with deleteProperty function nor delete operator:\n\nlet obj = Object.freeze({ prop: \"value\" });\nlet success = Reflect.deleteProperty(obj, \"prop\");\nconsole.log(success); // false\nconsole.log(obj.prop); // value\n\n\nObject.freeze() makes all properties of object not configurable (besides other things). deleteProperty function (as well as delete operator) returns false when tries to delete any of it's properties. If property is configurable it returns true, even if property does not exist.\n\nThe difference between delete and deleteProperty is when using strict mode:\n\n\"use strict\";\n\nlet obj = Object.freeze({ prop: \"value\" });\nReflect.deleteProperty(obj, \"prop\"); // false\ndelete obj[\"prop\"];\n// TypeError: property \"prop\" is non-configurable and can't be deleted\n\nShare\nImprove this answer\nFollow\nedited Jan 25 '16 at 17:22\nanswered Jan 10 '16 at 16:36\nmadox2\n40.8k14\n14 gold badges\n90\n90 silver badges\n92\n92 bronze badges","comments":[]},{"answer":"Suppose you have an object that looks like this:\n\nvar Hogwarts = {\n    staff : [\n        'Argus Filch',\n        'Filius Flitwick',\n        'Gilderoy Lockhart',\n        'Minerva McGonagall',\n        'Poppy Pomfrey',\n        ...\n    ],\n    students : [\n        'Hannah Abbott',\n        'Katie Bell',\n        'Susan Bones',\n        'Terry Boot',\n        'Lavender Brown',\n        ...\n    ]\n};\n\nDeleting an object property\n\nIf you want to use the entire staff array, the proper way to do this, would be to do this:\n\ndelete Hogwarts.staff;\n\n\nAlternatively, you could also do this:\n\ndelete Hogwarts['staff'];\n\n\nSimilarly, removing the entire students array would be done by calling delete Hogwarts.students; or delete Hogwarts['students'];.\n\nDeleting an array index\n\nNow, if you want to remove a single staff member or student, the procedure is a bit different, because both properties are arrays themselves.\n\nIf you know the index of your staff member, you could simply do this:\n\nHogwarts.staff.splice(3, 1);\n\n\nIf you do not know the index, you'll also have to do an index search:\n\nHogwarts.staff.splice(Hogwarts.staff.indexOf('Minerva McGonnagall') - 1, 1);\n\nNote\n\nWhile you technically can use delete for an array, using it would result in getting incorrect results when calling for example Hogwarts.staff.length later on. In other words, delete would remove the element, but it wouldn't update the value of length property. Using delete would also mess up your indexing.\n\nSo, when deleting values from an object, always first consider whether you're dealing with object properties or whether you're dealing with array values, and choose the appropriate strategy based on that.\n\nIf you want to experiment with this, you can use this Fiddle as a starting point.\n\nShare\nImprove this answer\nFollow\nedited Nov 23 '16 at 9:17\nanswered Feb 21 '16 at 18:09\nJohn Slegers\n39.1k17\n17 gold badges\n186\n186 silver badges\n155\n155 bronze badges","comments":[]},{"answer":"I personally use Underscore.js or Lodash for object and array manipulation:\n\nmyObject = _.omit(myObject, 'regex');\n\nShare\nImprove this answer\nFollow\nedited Jan 21 '19 at 11:24\nanswered Jan 22 '16 at 2:29\nemil\n5,1984\n4 gold badges\n24\n24 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"Using delete method is the best way to do that, as per MDN description, the delete operator removes a property from an object. So you can simply write:\n\ndelete myObject.regex;\n// OR\ndelete myObject['regex'];\n\n\nThe delete operator removes a given property from an object. On successful deletion, it will return true, else false will be returned. However, it is important to consider the following scenarios:\n\nIf the property which you are trying to delete does not exist, delete will not have any effect and will return true\n\nIf a property with the same name exists on the object's prototype chain, then, after deletion, the object will use the property from the prototype chain (in other words, delete only has an effect on own properties).\n\nAny property declared with var cannot be deleted from the global scope or from a function's scope.\n\nAs such, delete cannot delete any functions in the global scope (whether this is part from a function definition or a function (expression).\n\nFunctions which are part of an object (apart from the\nglobal scope) can be deleted with delete.\n\nAny property declared with let or const cannot be deleted from the scope within which they were defined. Non-configurable properties cannot be removed. This includes properties of built-in objects like Math, Array, Object and properties that are created as non-configurable with methods like Object.defineProperty().\n\nThe following snippet gives another simple example:\n\nvar Employee = {\n      age: 28,\n      name: 'Alireza',\n      designation: 'developer'\n    }\n    \n    console.log(delete Employee.name);   // returns true\n    console.log(delete Employee.age);    // returns true\n    \n    // When trying to delete a property that does \n    // not exist, true is returned \n    console.log(delete Employee.salary); // returns true\n Run code snippetExpand snippet\n\nFor more info about and seeing more example, visit the link below:\n\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/delete\n\nShare\nImprove this answer\nFollow\nedited Apr 16 '19 at 23:22\nanswered Apr 7 '17 at 16:16\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"Another solution, using Array#reduce.\n\nvar myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nmyObject = Object.keys(myObject).reduce(function(obj, key) {\n  if (key != \"regex\") {           //key you want to remove\n    obj[key] = myObject[key];\n  }\n  return obj;\n}, {});\n\nconsole.log(myObject);\n Run code snippetExpand snippet\n\nHowever, it will mutate the original object. If you want to create a new object without the specified key, just assign the reduce function to a new variable, e.g.:\n\n(ES6)\n\nconst myObject = {\n  ircEvent: 'PRIVMSG',\n  method: 'newURI',\n  regex: '^http://.*',\n};\n\nconst myNewObject = Object.keys(myObject).reduce((obj, key) => {\n  key !== 'regex' ? obj[key] = myObject[key] : null;\n  return obj;\n}, {});\n\nconsole.log(myNewObject);\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Oct 24 '17 at 9:58\nanswered Mar 26 '17 at 15:19\nkind user\n32.9k6\n6 gold badges\n51\n51 silver badges\n65\n65 bronze badges","comments":[]},{"answer":"There are a lot of good answers here but I just want to chime in that when using delete to remove a property in JavaScript, it is often wise to first check if that property exists to prevent errors.\n\nE.g\n\nvar obj = {\"property\":\"value\", \"property2\":\"value\"};\n\nif (obj && obj.hasOwnProperty(\"property2\")) {\n  delete obj.property2;\n} else {\n  //error handling\n}\n\n\nDue to the dynamic nature of JavaScript there are often cases where you simply don't know if the property exists or not. Checking if obj exists before the && also makes sure you don't throw an error due to calling the hasOwnProperty() function on an undefined object.\n\nSorry if this didn't add to your specific use case but I believe this to be a good design to adapt when managing objects and their properties.\n\nShare\nImprove this answer\nFollow\nanswered Sep 15 '14 at 0:48\nWillem\n1,0121\n1 gold badge\n11\n11 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"This post is very old and I find it very helpful so I decided to share the unset function I wrote in case someone else see this post and think why it's not so simple as it in PHP unset function.\n\nThe reason for writing this new unset function, is to keep the index of all other variables in this hash_map. Look at the following example, and see how the index of \"test2\" did not change after removing a value from the hash_map.\n\nfunction unset(unsetKey, unsetArr, resort) {\n  var tempArr = unsetArr;\n  var unsetArr = {};\n  delete tempArr[unsetKey];\n  if (resort) {\n    j = -1;\n  }\n  for (i in tempArr) {\n    if (typeof(tempArr[i]) !== 'undefined') {\n      if (resort) {\n        j++;\n      } else {\n        j = i;\n      }\n      unsetArr[j] = tempArr[i];\n    }\n  }\n  return unsetArr;\n}\n\nvar unsetArr = ['test', 'deletedString', 'test2'];\n\nconsole.log(unset('1', unsetArr, true)); // output Object {0: \"test\", 1: \"test2\"}\nconsole.log(unset('1', unsetArr, false)); // output Object {0: \"test\", 2: \"test2\"}\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jan 30 at 20:18\nCertainPerformance\n274k33\n33 gold badges\n192\n192 silver badges\n217\n217 bronze badges\nanswered Dec 1 '14 at 7:33\ntalsibony\n7,5485\n5 gold badges\n43\n43 silver badges\n42\n42 bronze badges","comments":[]},{"answer":"Using ramda#dissoc you will get a new object without the attribute regex:\n\nconst newObject = R.dissoc('regex', myObject);\n// newObject !== myObject\n\n\nYou can also use other functions to achieve the same effect - omit, pick, ...\n\nShare\nImprove this answer\nFollow\nanswered Nov 28 '16 at 15:14\nAmio.io\n17.6k12\n12 gold badges\n69\n69 silver badges\n102\n102 bronze badges","comments":[]},{"answer":"Try the following method. Assign the Object property value to undefined. Then stringify the object and parse.\n\n var myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\n\nmyObject.regex = undefined;\nmyObject = JSON.parse(JSON.stringify(myObject));\n\nconsole.log(myObject);\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Nov 22 '16 at 22:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 6 '16 at 14:51\nMohammed Safeer\n18k8\n8 gold badges\n66\n66 silver badges\n75\n75 bronze badges","comments":[]},{"answer":"If you want to delete a property deeply nested in the object then you can use the following recursive function with path to the property as the second argument:\n\nvar deepObjectRemove = function(obj, path_to_key){\n    if(path_to_key.length === 1){\n        delete obj[path_to_key[0]];\n        return true;\n    }else{\n        if(obj[path_to_key[0]])\n            return deepObjectRemove(obj[path_to_key[0]], path_to_key.slice(1));\n        else\n            return false;\n    }\n};\n\n\nExample:\n\nvar a = {\n    level1:{\n        level2:{\n            level3: {\n                level4: \"yolo\"\n            }\n        }\n    }\n};\n\ndeepObjectRemove(a, [\"level1\", \"level2\", \"level3\"]);\nconsole.log(a);\n\n//Prints {level1: {level2: {}}}\n\nShare\nImprove this answer\nFollow\nanswered Jun 23 '16 at 9:38\nayushgp\n4,0853\n3 gold badges\n31\n31 silver badges\n69\n69 bronze badges","comments":[]},{"answer":"Object.assign() & Object.keys() & Array.map()\n\nconst obj = {\n    \"Filters\":[\n        {\n            \"FilterType\":\"between\",\n            \"Field\":\"BasicInformationRow.A0\",\n            \"MaxValue\":\"2017-10-01\",\n            \"MinValue\":\"2017-09-01\",\n            \"Value\":\"Filters value\"\n        }\n    ]\n};\n\nlet new_obj1 = Object.assign({}, obj.Filters[0]);\nlet new_obj2 = Object.assign({}, obj.Filters[0]);\n\n/*\n\n// old version\n\nlet shaped_obj1 = Object.keys(new_obj1).map(\n    (key, index) => {\n        switch (key) {\n            case \"MaxValue\":\n                delete new_obj1[\"MaxValue\"];\n                break;\n            case \"MinValue\":\n                delete new_obj1[\"MinValue\"];\n                break;\n        }\n        return new_obj1;\n    }\n)[0];\n\n\nlet shaped_obj2 = Object.keys(new_obj2).map(\n    (key, index) => {\n        if(key === \"Value\"){\n            delete new_obj2[\"Value\"];\n        }\n        return new_obj2;\n    }\n)[0];\n\n\n*/\n\n\n// new version!\n\nlet shaped_obj1 = Object.keys(new_obj1).forEach(\n    (key, index) => {\n        switch (key) {\n            case \"MaxValue\":\n                delete new_obj1[\"MaxValue\"];\n                break;\n            case \"MinValue\":\n                delete new_obj1[\"MinValue\"];\n                break;\n            default:\n                break;\n        }\n    }\n);\n\nlet shaped_obj2 = Object.keys(new_obj2).forEach(\n    (key, index) => {\n        if(key === \"Value\"){\n            delete new_obj2[\"Value\"];\n        }\n    }\n);\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Nov 10 '17 at 6:36\nanswered Sep 19 '17 at 8:37\nuser8629798","comments":[]},{"answer":"Here's an ES6 way to remove the entry easily:\n\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nconst removeItem = 'regex';\n\nconst { [removeItem]: remove, ...rest } = myObject;\n\nconsole.log(remove); // \"^http://.*\"\nconsole.log(rest); // Object { ircEvent: \"PRIVMSG\", method: \"newURI\" }\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 23 at 20:34\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 18 at 15:54\nJohn Doe\n5741\n1 gold badge\n7\n7 silver badges\n19\n19 bronze badges","comments":["How is this anything other than a copy paste of earlier answers?"]},{"answer":"Property Removal in JavaScript\n\nThere are many different options presented on this page, not because most of the options are wrong—or because the answers are duplicates—but because the appropriate technique depends on the situation you're in and the goals of the tasks you and/or you team are trying to fulfill. To answer you question unequivocally, one needs to know:\n\nThe version of ECMAScript you're targeting\nThe range of object types you want to remove properties on and the type of property names you need to be able to omit (Strings only? Symbols? Weak references mapped from arbitrary objects? These have all been types of property pointers in JavaScript for years now)\nThe programming ethos/patterns you and your team use. Do you favor functional approaches and mutation is verboten on your team, or do you employ wild west mutative object-oriented techniques?\nAre you looking to achieve this in pure JavaScript or are you willing & able to use a 3rd-party library?\n\nOnce those four queries have been answered, there are essentially four categories of \"property removal\" in JavaScript to chose from in order to meet your goals. They are:\n\nMutative object property deletion, unsafe\n\nThis category is for operating on object literals or object instances when you want to retain/continue to use the original reference and aren't using stateless functional principles in your code. An example piece of syntax in this category:\n\n'use strict'\nconst iLikeMutatingStuffDontI = { myNameIs: 'KIDDDDD!', [Symbol.for('amICool')]: true }\ndelete iLikeMutatingStuffDontI[Symbol.for('amICool')] // true\nObject.defineProperty({ myNameIs: 'KIDDDDD!', 'amICool', { value: true, configurable: false })\ndelete iLikeMutatingStuffDontI['amICool'] // throws\n\n\nThis category is the oldest, most straightforward & most widely supported category of property removal. It supports Symbol & array indexes in addition to strings and works in every version of JavaScript except for the very first release. However, it's mutative which violates some programming principles and has performance implications. It also can result in uncaught exceptions when used on non-configurable properties in strict mode.\n\nRest-based string property omission\n\nThis category is for operating on plain object or array instances in newer ECMAScript flavors when a non-mutative approach is desired and you don't need to account for Symbol keys:\n\nconst foo = { name: 'KIDDDDD!', [Symbol.for('isCool')]: true }\nconst { name, ...coolio } = foo // coolio doesn't have \"name\"\nconst { isCool, ...coolio2 } = foo // coolio2 has everything from `foo` because `isCool` doesn't account for Symbols :(\n\nMutative object property deletion, safe\n\nThis category is for operating on object literals or object instances when you want to retain/continue to use the original reference while guarding against exceptions being thrown on unconfigurable properties:\n\n'use strict'\nconst iLikeMutatingStuffDontI = { myNameIs: 'KIDDDDD!', [Symbol.for('amICool')]: true }\nReflect.deleteProperty(iLikeMutatingStuffDontI, Symbol.for('amICool')) // true\nObject.defineProperty({ myNameIs: 'KIDDDDD!', 'amICool', { value: true, configurable: false })\nReflect.deleteProperty(iLikeMutatingStuffDontI, 'amICool') // false\n\n\nIn addition, while mutating objects in-place isn't stateless, you can use the functional nature of Reflect.deleteProperty to do partial application and other functional techniques that aren't possible with delete statements.\n\nSyntax-based string property omission\n\nThis category is for operating on plain object or array instances in newer ECMAScript flavors when a non-mutative approach is desired and you don't need to account for Symbol keys:\n\nconst foo = { name: 'KIDDDDD!', [Symbol.for('isCool')]: true }\nconst { name, ...coolio } = foo // coolio doesn't have \"name\"\nconst { isCool, ...coolio2 } = foo // coolio2 has everything from `foo` because `isCool` doesn't account for Symbols :(\n\nLibrary-based property omission\n\nThis category is generally allows for greater functional flexibility, including accounting for Symbols & omitting more than one property in one statement:\n\nconst o = require(\"lodash.omit\")\nconst foo = { [Symbol.for('a')]: 'abc', b: 'b', c: 'c' }\nconst bar = o(foo, 'a') // \"'a' undefined\"\nconst baz = o(foo, [ Symbol.for('a'), 'b' ]) // Symbol supported, more than one prop at a time, \"Symbol.for('a') undefined\"\n\nShare\nImprove this answer\nFollow\nanswered Dec 14 '17 at 2:35\njames_womack\n9,5566\n6 gold badges\n50\n50 silver badges\n73\n73 bronze badges","comments":[]},{"answer":"@johnstock, we can also use JavaScript's prototyping concept to add method to objects to delete any passed key available in calling object.\n\nAbove answers are appreciated.\n\nvar myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\n// 1st and direct way \ndelete myObject.regex; // delete myObject[\"regex\"]\nconsole.log(myObject); // { ircEvent: 'PRIVMSG', method: 'newURI' }\n\n// 2 way -  by using the concept of JavaScript's prototyping concept\nObject.prototype.removeFromObjectByKey = function(key) {\n  // If key exists, remove it and return true\n  if (this[key] !== undefined) {\n    delete this[key]\n    return true;\n  }\n  // Else return false\n  return false;\n}\n\nvar isRemoved = myObject.removeFromObjectByKey('method')\nconsole.log(myObject) // { ircEvent: 'PRIVMSG' }\n\n// More examples\nvar obj = {\n  a: 45,\n  b: 56,\n  c: 67\n}\nconsole.log(obj) // { a: 45, b: 56, c: 67 }\n\n// Remove key 'a' from obj\nisRemoved = obj.removeFromObjectByKey('a')\nconsole.log(isRemoved); //true\nconsole.log(obj); // { b: 56, c: 67 }\n\n// Remove key 'd' from obj which doesn't exist\nvar isRemoved = obj.removeFromObjectByKey('d')\nconsole.log(isRemoved); // false\nconsole.log(obj); // { b: 56, c: 67 }\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jan 30 at 20:19\nCertainPerformance\n274k33\n33 gold badges\n192\n192 silver badges\n217\n217 bronze badges\nanswered May 24 '18 at 18:42\nhygull\n7,2762\n2 gold badges\n36\n36 silver badges\n43\n43 bronze badges","comments":["What does \"johnstock\" refer to? Can you provide a link?"]},{"answer":"Dan's assertion that 'delete' is very slow and the benchmark he posted were doubted. So I carried out the test myself in Chrome 59. It does seem that 'delete' is about 30 times slower:\n\nvar iterationsTotal = 10000000;  // 10 million\nvar o;\nvar t1 = Date.now(),t2;\nfor (let i=0; i<iterationsTotal; i++) {\n   o = {a:1,b:2,c:3,d:4,e:5};\n   delete o.a; delete o.b; delete o.c; delete o.d; delete o.e;\n}\nconsole.log ((t2=Date.now())-t1);  // 6135\nfor (let i=0; i<iterationsTotal; i++) {\n   o = {a:1,b:2,c:3,d:4,e:5};\n   o.a = o.b = o.c = o.d = o.e = undefined;\n}\nconsole.log (Date.now()-t2);  // 205\n\n\nNote that I purposedly carried out more than one 'delete' operations in one loop cycle to minimize the effect caused by the other operations.\n\nShare\nImprove this answer\nFollow\nedited Jul 19 at 12:08\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 26 '17 at 7:19\nChong Lip Phang\n6,8845\n5 gold badges\n52\n52 silver badges\n76\n76 bronze badges","comments":[]},{"answer":"Using Lodash\nimport omit from 'lodash/omit';\n\nconst prevObject = {test: false, test2: true};\n// Removes test2 key from previous object\nconst nextObject = omit(prevObject, 'test2');\n\nUsing Ramda\nR.omit(['a', 'd'], {a: 1, b: 2, c: 3, d: 4}); //=> {b: 2, c: 3}\n\nShare\nImprove this answer\nFollow\nedited Jul 19 at 12:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 14 '17 at 14:14\njohndavedecano\n4405\n5 silver badges\n10\n10 bronze badges","comments":["What is \"Ramda\"? Can you add a reference to it? (Without \"Edit:\", \"Update:\", or similar - the answer should appear as if it was written today.)"]},{"answer":"You can use a filter like below\n\nvar myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\n\n// Way 1\n\nlet filter1 = {}\n  Object.keys({...myObject}).filter(d => {\n  if(d !== 'regex'){\n    filter1[d] = myObject[d];\n  }\n})\n\nconsole.log(filter1)\n\n// Way 2\n\nlet filter2 = Object.fromEntries(Object.entries({...myObject}).filter(d =>\nd[0] !== 'regex'\n))\n\nconsole.log(filter2)\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 23 at 20:43\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 18 '19 at 10:59\nking neo\n2,2811\n1 gold badge\n19\n19 silver badges\n28\n28 bronze badges","comments":["You don't need filter in this case you can use forEach","obviously you can.","but The filter() method creates an array filled with all array elements that pass a test so the sole purpose of the filter is reducing and creating a new array","Yes it does but that's only useful if you are using the returned value of filter by resigning it to the original variable or another one, and also it only works if it's given a return value in the function passed in as a parameter to it, but none if those things are done here so it's only purpose is iterating the array elements, which is what forEach is for","You could instead do let filter =    Object.fromEntries(Object.entries(myObject).filter(d =>  d !== 'regex' )) "]},{"answer":"I have used Lodash \"unset\" to make it happen for a nested object also... only this needs to write small logic to get the path of the property key which is expected by the omit method.\n\nMethod which returns the property path as an array\n\nvar a = {\"bool\":{\"must\":[{\"range\":{\"price_index.final_price\":{\"gt\":\"450\", \"lt\":\"500\"}}}, {\"bool\":{\"should\":[{\"term\":{\"color_value.keyword\":\"Black\"}}]}}]}};\n\nfunction getPathOfKey(object,key,currentPath, t){\n    var currentPath = currentPath || [];\n\n    for(var i in object){\n        if(i == key){\n            t = currentPath;\n        }\n        else if(typeof object[i] == \"object\"){\n            currentPath.push(i)\n            return getPathOfKey(object[i], key,currentPath)\n        }\n    }\n    t.push(key);\n    return t;\n}\ndocument.getElementById(\"output\").innerHTML =JSON.stringify(getPathOfKey(a,\"price_index.final_price\"))\n<div id=\"output\">\n\n</div>\n Run code snippetExpand snippet\n\nThen just using Lodash unset method remove property from object.\n\nvar unset = require('lodash.unset');\nunset(a, getPathOfKey(a, \"price_index.final_price\"));\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jul 19 at 12:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 29 '17 at 8:03\nBEJGAM SHIVA PRASAD\n1,4961\n1 gold badge\n14\n14 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"let myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\n\n\nobj = Object.fromEntries(\n    Object.entries(myObject).filter(function (m){\n        return m[0] != \"regex\"/*or whatever key to delete*/\n    }\n))\n\nconsole.log(obj)\n Run code snippetExpand snippet\n\nYou can also just treat the object like a2d array using Object.entries, and use splice to remove an element as you would in a normal array, or simply filter through the object, as one would an array, and assign the reconstructed object back to the original variable\n\nShare\nImprove this answer\nFollow\nedited Oct 20 '20 at 3:36\nDerek Wang\n9,7304\n4 gold badges\n15\n15 silver badges\n36\n36 bronze badges\nanswered Sep 16 '20 at 5:56\nbluejayke\n2,8992\n2 gold badges\n20\n20 silver badges\n53\n53 bronze badges","comments":[]},{"answer":"If you don't want to modify the original object.\n\nRemove a property without mutating the object\n\nIf mutability is a concern, you can create a completely new object by copying all the properties from the old, except the one you want to remove.\n\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nlet prop = 'regex';\nconst updatedObject = Object.keys(myObject).reduce((object, key) => {\n  if (key !== prop) {\n    object[key] = myObject[key]\n  }\n  return object\n}, {})\n\nconsole.log(updatedObject);\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nanswered Nov 17 '20 at 4:37\nakhtarvahid\n7,4512\n2 gold badges\n15\n15 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"Two ways to delete an object\n\nusing for ... in\n\n function deleteUser(key) {\n\n     const newUsers = {};\n     for (const uid in users) {\n         if (uid !== key) {\n             newUsers[uid] = users[uid];\n         }\n\n     return newUsers\n }\n\n\nor\n\ndelete users[key]\n\nShare\nImprove this answer\nFollow\nedited Jun 23 at 20:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 22 at 15:15\nRashid Iqbal\n6378\n8 silver badges\n10\n10 bronze badges","comments":["So you are recommending that to remove one property, the whole object should be copied into a new object without the targeted property?!?","Is that valid code? A } seems to be missing. You can edit your answer - but without \"Edit:\", \"Update:\", or similar - the answer should appear as if it was written today."]}]},{"id":"1274057","href":"https://stackoverflow.com/questions/1274057/how-can-i-make-git-forget-about-a-file-that-was-tracked-but-is-now-in-gitign","title":"How can I make Git “forget” about a file that was tracked, but is now in .gitignore?","description":"\n                \nThere is a file that was being tracked by Git, but now the file is on the .gitignore list.\nHowever, that file keeps showing up in git status after it's edited. How do you force Git to completely forget about it?\n    ","questionComments":["git clean -X sounds similar, but it doesn't apply in this situation (when the files are still being tracked by Git). I'm writing this for anyone looking for a solution not to follow the wrong route.","The only real answer to this is down below, see git update-index --assume-unchanged. This solution 1) keeps the file on server (index), 2) lets you modify it freely locally.","You need to use --skip-worktree, see: stackoverflow.com/questions/13630849/…","An important question is: should the file remain in the repository or not? Eg if someone new clones the repo, should they get the file or not? If YES then git update-index --assume-unchanged <file> is correct and the file will remain in the repository and changes will not be added with git add. If NO (for example it was some cache file, generated file etc), then git rm --cached <file> will remove it from repository.","@Martin @Qwerty Everyon should stop to advise for --assume-unchanged which is for performance to prevent git to check status of big tracked files but prefer --skip-worktree which is for modified tracked files that the user don't want to commit anymore. See stackoverflow.com/questions/13630849/…"],"answers":[{"answer":".gitignore will prevent untracked files from being added (without an add -f) to the set of files tracked by Git, however Git will continue to track any files that are already being tracked.\n\nTo stop tracking a file you need to remove it from the index. This can be achieved with this command.\n\ngit rm --cached <file>\n\n\nIf you want to remove a whole folder, you need to remove all files in it recursively.\n\ngit rm -r --cached <folder>\n\n\nThe removal of the file from the head revision will happen on the next commit.\n\nWARNING: While this will not remove the physical file from your local, it will remove the files from other developers machines on next git pull.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 21:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 13 '09 at 20:40\nCB Bailey\n661k95\n95 gold badges\n610\n610 silver badges\n639\n639 bronze badges","comments":["the process that workd for me was 1. commit pending changes first 2. git rm --cached <file> and commit again 3. add the file to .gitignore, check with git status and commit again","Very important adding. If file that is ignored would be modified (but in spite of this should be not committed), after modifying and executing git add . it would be added to index. And next commit would commit it to repository. To avoid this execute right after all that mataal said one more command: git update-index --assume-unchanged <path&filename>","@AkiraYamamoto 's method worked well for me as well. In my case I suppressed the output since my repository had thousands of files: git rm -r -q --cached .","This will delete the file on git pull though.","git rm --cached <file> just remove file from repository, git update-index --assume-unchanged <file> not shown file in unstaged changes and does not make pull a new changes. But i want GIT JUST IGNORE CONTENT OF FILE PLEEEEEASE"]},{"answer":"The series of commands below will remove all of the items from the Git index (not from the working directory or local repository), and then will update the Git index, while respecting Git ignores. PS. Index = Cache\n\nFirst:\n\ngit rm -r --cached .\ngit add .\n\n\nThen:\n\ngit commit -am \"Remove ignored files\"\n\n\nOr as a one-liner:\n\ngit rm -r --cached . && git add . && git commit -am \"Remove ignored files\"\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 21:58\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 30 '13 at 13:51\nMatt Frear\n46.4k10\n10 gold badges\n68\n68 silver badges\n84\n84 bronze badges","comments":["To highlight the difference between this answer and the accepted one: Using this commands you don't need to actually know the affected files. (Imagine a temporary dir with lots of random files that should be cleared off the index).","Same as the accepted answer. Files will get deleted on git pull.","It would be nice to have this as a standard git command. Something like git rmignored.","@gudthing -r stands for \"recursive\"","With this you may end up adding other useless files that are not currently in .gitignore. Which may be difficult to find out if depending on how noise your git status is after this command. A command that only removes newly ignored files would be better. That's why I prefer thSoft's answer"]},{"answer":"git update-index does the job for me:\n\ngit update-index --assume-unchanged <file>\n\n\nNote: This solution is actually independent on .gitignore as gitignore is only for untracked files.\n\nUpdate, a better option\n\nSince this answer was posted, a new option has been created and that should be preferred. You should use --skip-worktree which is for modified tracked files that the user don't want to commit anymore and keep --assume-unchanged for performance to prevent git to check status of big tracked files. See https://stackoverflow.com/a/13631525/717372 for more details...\n\ngit update-index --skip-worktree <file>\n\n\nTo cancel\n\ngit update-index --no-skip-worktree <file>\n\nShare\nImprove this answer\nFollow\nedited Apr 23 at 0:21\nrofrol\n12.2k7\n7 gold badges\n66\n66 silver badges\n65\n65 bronze badges\nanswered Nov 27 '13 at 11:24\nKonstantin\n14.3k1\n1 gold badge\n11\n11 silver badges\n8\n8 bronze badges","comments":["This IS the real answer. Awesome actually, very simple, doesn't pollute git status and actually very intuitive. Thanks.","git update-index --assume-unchanged <path> … will cause git to ignore changes in the specified path(s), regardless of .gitignore. If you pull from a remote and that remote has changes to this path, git will fail the merge with a conflict and you will need to merge manually. git rm --cached <path> … will cause git to stop tracking that path. If you do not add the path to .gitignore you will see the path in future git status. The first option has less noise in the git commit history and allows changes to the \"ignored\" file to be distributed in the future.","I'm quite confused as to how this isn't the accepted answer. The accepted answer here clearly isn't answering the actual question being asked. This answer ignores changes to the file that is in the repository whilst not removing it from the repository.","This answer would be a lot more useful if it explained exactly what the given command does, e.g. how it's different from the other suggested solutions.","this command will only be effective on your machine right? what if i want to stop tracking the file on all machines ? also on the machines that will clone the rep in the future?"]},{"answer":"git ls-files --ignored --exclude-standard -z | xargs -0 git rm --cached\ngit commit -am \"Remove ignored files\"\n\n\nThis takes the list of the ignored files, removes them from the index, and commits the changes.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 22:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 23 '14 at 22:29\nthSoft\n19.6k5\n5 gold badges\n83\n83 silver badges\n98\n98 bronze badges","comments":["If you need to remove them from the working directory, too, then simply run git ls-files --ignored --exclude-standard | xargs git rm . I believe this answer is the best! Because it's very clear, Unix-way, and does the wanted thing in a direct manner, without composing the side-effects of other, more complex commands.","Great answer; however, the command will fail if you have paths with spaces on the middle, e.g.: \"My dir/my_ignored_file.txt\"","git ls-files --ignored --exclude-standard | sed 's/.*/\"&\"/' | xargs git rm --cached","git rm will complain if ls-files didn't match anything. Use xargs -r git rm ... to tell xargs not to run git rm if no files matched.","It would be better to use \\0 as separator: git ls-files --ignored --exclude-standard -z|xargs -0 git rm --cached"]},{"answer":"I always use this command to remove those untracked files. One-line, Unix-style, clean output:\n\ngit ls-files --ignored --exclude-standard | sed 's/.*/\"&\"/' | xargs git rm -r --cached\n\n\nIt lists all your ignored files, replaces every output line with a quoted line instead to handle paths with spaces inside, and passes everything to git rm -r --cached to remove the paths/files/directories from the index.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 22:05\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 19 '15 at 15:42\nDavid Hernandez\n2,64222\n22 silver badges\n18\n18 bronze badges","comments":["Great solution! Worked perfectly and feels more correct that removing all files then adding them back in.","I too found this \"cleanest\". It might be obvious, but just running the first part, git ls-files --ignored --exclude-standard, on its own lets you first understand/verify what files your new .gitignore is going to exclude/remove, before you go ahead and execute the final git rm.","Be aware, fails on filenames with certain \"nasty\" characters in them, e.g. \\n. I have posted my solution to cater for this.","Another caveat: on pull, this will cause the file to be deleted in others' working directories, right?","tried, but didn't work for me: sed: 1: \"s/.*/\": unterminated substitute in regular expression in a filter-branch command on a repo with spaces. (Seemed to work outside the filter-branch though). I used git ls-files -z --ignored --exclude-standard | xargs -0 git rm -r --cached from @JonBrave's answer instead."]},{"answer":"Move it out, commit, and then move it back in.\n\nThis has worked for me in the past, but there is probably a 'gittier' way to accomplish this.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 21:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 13 '09 at 19:27\nJoel Hooks\n6,0793\n3 gold badges\n31\n31 silver badges\n37\n37 bronze badges","comments":["This worked great if you want to ignore a bunch of files that weren't previously ignored. Though like you said, there is probably a better way for this.","This is exactly what I did. Simply move the files to a folder outside of git, then do \"git add .\", \"git commit\". (This removed the files) then add the gitignore, referencing the files/folders, commit again to add the gitignore file to git, then copy/move back in the folders, and they should be ignored. NB: it will appear that the files were deleted from GIT, so would probably remove them from other checkouts/pulls, as mentioned in above solutions, but since you are making copies of them initially, this isnt as much of an issue IMHO. just let the rest of the team know...","This is the easiest way to get rid of wrongly committed folders.","Seems to be the only way, that I can see. It's a massive bug (not 'feature') in git that as soon as you add a file/folder to .gitignore, it doesn't just ignore that file from that point on - forever - everywhere.","This worked after I had them added, and then after the fact added them to .gitignore"]},{"answer":"Use this when:\nYou want to untrack a lot of files, or\nYou updated your .gitignore file\n\nSource: Untrack files already added to Git repository based on .gitignore\n\nLet’s say you have already added/committed some files to your Git repository and you then add them to your .gitignore file; these files will still be present in your repository index. This article we will see how to get rid of them.\n\nStep 1: Commit all your changes\n\nBefore proceeding, make sure all your changes are committed, including your .gitignore file.\n\nStep 2: Remove everything from the repository\n\nTo clear your repository, use:\n\ngit rm -r --cached .\n\nrm is the remove command\n-r will allow recursive removal\n–cached will only remove files from the index. Your files will still be there.\n\nThe rm command can be unforgiving. If you wish to try what it does beforehand, add the -n or --dry-run flag to test things out.\n\nStep 3: Readd everything\ngit add .\n\nStep 4: Commit\ngit commit -m \".gitignore fix\"\n\n\nYour repository is clean :)\n\nPush the changes to your remote to see the changes effective there as well.\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 7:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 22 '18 at 18:11\nDheeraj Bhaskar\n17.3k9\n9 gold badges\n58\n58 silver badges\n65\n65 bronze badges","comments":["It won't delete the files from the remote repository? What if I want to keep the files both in local repo and remote repo but make git \"forget\" about them?","AFAIK this won't delete files from history because we're not using any history changing commands (correct me if I\"m wrong). This only adds a new commit by deleting files ignored in gitignore from git. Those files will be there in the historical commits"]},{"answer":"If you cannot git rm a tracked file because other people might need it (warning, even if you git rm --cached, when someone else gets this change, their files will be deleted in their filesystem). These are often done due to config file overrides, authentication credentials, etc. Please look at https://gist.github.com/1423106 for ways people have worked around the problem.\n\nTo summarize:\n\nHave your application look for an ignored file config-overide.ini and use that over the committed file config.ini (or alternately, look for ~/.config/myapp.ini, or $MYCONFIGFILE)\nCommit file config-sample.ini and ignore file config.ini, have a script or similar copy the file as necessary if necessary.\nTry to use gitattributes clean/smudge magic to apply and remove the changes for you, for instance smudge the config file as a checkout from an alternate branch and clean the config file as a checkout from HEAD. This is tricky stuff, I don't recommend it for the novice user.\nKeep the config file on a deploy branch dedicated to it that is never merged to master. When you want to deploy/compile/test you merge to that branch and get that file. This is essentially the smudge/clean approach except using human merge policies and extra-git modules.\nAnti-recommentation: Don't use assume-unchanged, it will only end in tears (because having git lie to itself will cause bad things to happen, like your change being lost forever).\nShare\nImprove this answer\nFollow\nedited Nov 24 '18 at 4:17\nanswered Jul 19 '12 at 0:08\nSeth Robertson\n28.2k6\n6 gold badges\n56\n56 silver badges\n52\n52 bronze badges","comments":["git wouldn't remove the file, if it were dirty at the time of deletion. And if it's not dirty, retrieving the file would be as easy as git checkout <oldref> -- <filename> - but then it would be checked out and ignored.","Concerning your last note (about --assume-unchanged) : either this is cargo cult and should be dismissed, or you can explain why (which I'm convinced of) and it becomes useful.","@RomainValeri: “Git will fail (gracefully) in case it needs to modify this file in the index e.g. when merging in a commit; thus, in case the assumed-untracked file is changed upstream, you will need to handle the situation manually.”—git-scm.com/docs/git-update-index. You commit to: (1) backup the file out of the tree; (2) reset the a.-u. bit; (3) reset the file to its original content git checkout -- file; (4) git pull or merge, which will now succeed; (5) copy the file back and examine changes; (6) set the a.-u. bit again. That's a definition of PITA in my book, but YMMV. :)"]},{"answer":"I accomplished this by using git filter-branch. The exact command I used was taken from the man page:\n\nWARNING: this will delete the file from your entire history\n\ngit filter-branch --index-filter 'git rm --cached --ignore-unmatch filename' HEAD\n\n\nThis command will recreate the entire commit history, executing git rm before each commit and so will get rid of the specified file. Don't forget to back it up before running the command as it will be lost.\n\nShare\nImprove this answer\nFollow\nedited Apr 25 '17 at 14:50\nbolov\n59.9k13\n13 gold badges\n114\n114 silver badges\n185\n185 bronze badges\nanswered Aug 13 '09 at 19:35\ndrrlvn\n7,6142\n2 gold badges\n39\n39 silver badges\n56\n56 bronze badges","comments":["This will change all commit IDs, thus breaking merges from branches outside of your copy of the repository.","WARNING: this will delete the file from your entire history. This was what I was looking for though, to remove a completely unnecessary and oversized file (output that should never have been committed) that was committed a long time ago in the version history."]},{"answer":"What didn't work for me\n\n(Under Linux), I wanted to use the posts here suggesting the ls-files --ignored --exclude-standard | xargs git rm -r --cached approach. However, (some of) the files to be removed had an embedded newline/LF/\\n in their names. Neither of the solutions:\n\ngit ls-files --ignored --exclude-standard | xargs -d\"\\n\" git rm --cached\ngit ls-files --ignored --exclude-standard | sed 's/.*/\"&\"/' | xargs git rm -r --cached\n\n\ncope with this situation (get errors about files not found).\n\nSo I offer\ngit ls-files -z --ignored --exclude-standard | xargs -0 git rm -r --cached\ngit commit -am \"Remove ignored files\"\n\n\nThis uses the -z argument to ls-files, and the -0 argument to xargs to cater safely/correctly for \"nasty\" characters in filenames.\n\nIn the manual page git-ls-files(1), it states:\n\nWhen -z option is not used, TAB, LF, and backslash characters in pathnames are represented as \\t, \\n, and \\\\, respectively.\n\nso I think my solution is needed if filenames have any of these characters in them.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Dec 29 '15 at 12:50\nJonBrave\n3,2092\n2 gold badges\n29\n29 silver badges\n89\n89 bronze badges","comments":["For me this is the best solution. It has much better performance than a git add .. It also contains the best improvements from some comments above.","Can you add thSoft's git commit -am \"Remove ignored files\" afterward to your answer? Your answers combined got me through things : j","I don't understand the purpose of git commit -a. For me git rm --cached affect exactly the index so no need to stage the files after..."]},{"answer":"Update your .gitignore file – for instance, add a folder you don't want to track to .gitignore.\n\ngit rm -r --cached . – Remove all tracked files, including wanted and unwanted. Your code will be safe as long as you have saved locally.\n\ngit add . – All files will be added back in, except those in .gitignore.\n\nHat tip to @AkiraYamamoto for pointing us in the right direction.\n\nShare\nImprove this answer\nFollow\nedited Oct 4 '16 at 0:58\nChris Nolet\n8,1297\n7 gold badges\n59\n59 silver badges\n91\n91 bronze badges\nanswered Apr 4 '16 at 4:09\nChen_Wayne\n4935\n5 silver badges\n4\n4 bronze badges","comments":["How about downvoted due to the fact that it won't actually work as you need a -r to run rm recursively anyway :) (Someone didn't copy correctly)","Warning: This technique doesn't actually cause git to ignore the file, instead it actually causes git to delete the file. That means if you use this solution, any time anyone else does a git pull, the file will get deleted. So it isn't actually ignored. See the solution suggesting git update-index --assume-unchanged instead for a solution to the original question.","Tks for the reference to my comment. I find it weird that my original comment was deleted from stackoverflow.com/a/1274447/475876"]},{"answer":"Do the following steps serially, and you will be fine.\n\nRemove the mistakenly added files from the directory/storage. You can use the \"rm -r\" (for Linux) command or delete them by browsing the directories. Or move them to another location on your PC. (You maybe need to close the IDE if running for moving/removing.)\n\nAdd the files / directories to the .gitignore file now and save it.\n\nNow remove them from the Git cache by using these commands (if there is more than one directory, remove them one by one by repeatedly issuing this command)\n\n git rm -r --cached path-to-those-files\n\n\nNow do a commit and push by using the following commands. This will remove those files from Git remote and make Git stop tracking those files.\n\n git add .\n git commit -m \"removed unnecessary files from Git\"\n git push origin\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 7:29\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 20 '18 at 10:52\nShamsul Arefin Sajib\n1,44515\n15 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"I think, that maybe Git can't totally forget about a file because of its conception (section \"Snapshots, Not Differences\").\n\nThis problem is absent, for example, when using CVS. CVS stores information as a list of file-based changes. Information for CVS is a set of files and the changes made to each file over time.\n\nBut in Git every time you commit, or save the state of your project, it basically takes a picture of what all your files look like at that moment and stores a reference to that snapshot. So, if you added file once, it will always be present in that snapshot.\n\nThese two articles were helpful for me:\n\ngit assume-unchanged vs skip-worktree and How to ignore changes in tracked files with Git\n\nBasing on it I do the following, if the file is already tracked:\n\ngit update-index --skip-worktree <file>\n\n\nFrom this moment all local changes in this file will be ignored and will not go to remote. If the file is changed on remote, conflict will occur, when git pull. Stash won't work. To resolve it, copy the file content to the safe place and follow these steps:\n\ngit update-index --no-skip-worktree <file>\ngit stash\ngit pull\n\n\nThe file content will be replaced by the remote content. Paste your changes from the safe place to the file and perform again:\n\ngit update-index --skip-worktree <file>\n\n\nIf everyone, who works with the project, will perform git update-index --skip-worktree <file>, problems with pull should be absent. This solution is OK for configurations files, when every developer has their own project configuration.\n\nIt is not very convenient to do this every time, when the file has been changed on remote, but it can protect it from overwriting by remote content.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 22:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 21 '17 at 15:12\nBoolean_Type\n9532\n2 gold badges\n12\n12 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"The copy/paste answer is git rm --cached -r .; git add .; git status;\n\nThis command will NOT change the content of the .gitignore file. It will just ignore the files that have already been committed to a Git repository but now we have added them to .gitignore.\n\nThe last part of the command (git status;) is just to review the changes and could be ignored.\n\nShare\nImprove this answer\nFollow\nedited Aug 2 at 14:19\nanswered Nov 19 '18 at 11:21\nyouhans\n3,8002\n2 gold badges\n22\n22 silver badges\n35\n35 bronze badges","comments":["It can be read as if the command lines will change the content of file .gitignore. Can you make it clear that is not the case (without \"Edit:\", \"Update:\", or similar - the answer should appear as if it was written today). That is, not a direct clarification, but by changing the way it is written."]},{"answer":"Do the following steps for a file/folder:\n\nRemove a File:\n\nneed to add that file to .gitignore.\nneed to remove that file using the command (git rm --cached file name).\nneed to run (git add .).\nneed to (commit -m) \"file removed\".\nand finally, (git push).\n\nFor example:\n\nI want to delete the test.txt file. I accidentally pushed to GitHub and want to remove it. Commands will be as follows:\n\nFirst, add \"test.txt\" in file .gitignore\n\ngit rm --cached test.txt\ngit add .\ngit commit -m \"test.txt removed\"\ngit push\n\n\nRemove Folder:\n\nneed to add that folder to file .gitignore.\nneed to remove that folder using the command (git rm -r --cached folder name).\nneed to run (git add .).\nneed to (commit -m) \"folder removed\".\nand finally, (git push).\n\nFor example:\n\nI want to delete the .idea folder/directory. I accidentally pushed to GitHub and want to remove it. The commands will be as follows:\n\nFirst, add .idea in file .gitignore\n\ngit rm -r --cached .idea\ngit add .\ngit commit -m \".idea removed\"\ngit push\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 8:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 9 '20 at 2:09\nArslan Ahmad khan\n3,8781\n1 gold badge\n22\n22 silver badges\n31\n31 bronze badges","comments":["You Sir are the real MVP!"]},{"answer":"The answer from Matt Frear was the most effective IMHO. The following is just a PowerShell script for those on Windows to only remove files from their Git repository that matches their exclusion list.\n\n# Get files matching exclusionsfrom .gitignore\n# Excluding comments and empty lines\n$ignoreFiles =  gc .gitignore | ?{$_ -notmatch  \"#\"} |  ?{$_ -match  \"\\S\"} | % {\n                    $ignore = \"*\" + $_ + \"*\"\n                    (gci -r -i $ignore).FullName\n                }\n$ignoreFiles = $ignoreFiles| ?{$_ -match  \"\\S\"}\n\n# Remove each of these file from Git\n$ignoreFiles | % { git rm $_}\n\ngit add .\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 22:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 25 '13 at 0:51\nAmeer Deen\n6688\n8 silver badges\n19\n19 bronze badges","comments":["In what situation won't this list of files be equal to the recursive --cached?"]},{"answer":"Using the git rm --cached command does not answer the original question:\n\nHow do you force git to completely forget about [a file]?\n\nIn fact, this solution will cause the file to be deleted in every other instance of the repository when executing a git pull!\n\nThe correct way to force Git to forget about a file is documented by GitHub here.\n\nI recommend reading the documentation, but basically:\n\ngit fetch --all\ngit filter-branch --force --index-filter 'git rm --cached --ignore-unmatch full/path/to/file' --prune-empty --tag-name-filter cat -- --all\ngit push origin --force --all\ngit push origin --force --tags\ngit for-each-ref --format='delete %(refname)' refs/original | git update-ref --stdin\ngit reflog expire --expire=now --all\ngit gc --prune=now\n\n\nJust replace full/path/to/file with the full path of the file. Make sure you've added the file to your .gitignore file.\n\nYou'll also need to (temporarily) allow non-fast-forward pushes to your repository, since you're changing your Git history.\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 7:42\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 9 '19 at 2:27\nSkeets\n3,39933\n33 silver badges\n55\n55 bronze badges","comments":[]},{"answer":"Move or copy the file to a safe location, so you don't lose it. Then 'git rm' the file and commit.\n\nThe file will still show up if you revert to one of those earlier commits, or another branch where it has not been removed. However, in all future commits, you will not see the file again. If the file is in the Git ignore, then you can move it back into the folder, and Git won't see it.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 21:56\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 13 '09 at 19:27\nApreche\n24.5k8\n8 gold badges\n37\n37 silver badges\n46\n46 bronze badges","comments":["git rm --cached will remove the file from the index without deleting it from disk, so no need to move/copy it away"]},{"answer":"The BFG is specifically designed for removing unwanted data like big files or passwords from Git repositories, so it has a simple flag that will remove any large historical (not-in-your-current-commit) files: '--strip-blobs-bigger-than'\n\njava -jar bfg.jar --strip-blobs-bigger-than 100M\n\n\nIf you'd like to specify files by name, you can do that too:\n\njava -jar bfg.jar --delete-files *.mp4\n\n\nThe BFG is 10-1000x faster than git filter-branch and is generally much easier to use - check the full usage instructions and examples for more details.\n\nSource: Reduce repository size\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 22:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 3 '17 at 12:37\nMeir Gerenstadt\n3,5091\n1 gold badge\n21\n21 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"If you don't want to use the CLI and are working on Windows, a very simple solution is to use TortoiseGit. It has the \"Delete (keep local)\" Action in the menu which works fine.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 22:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 15 '18 at 11:04\nPeter T.\n2,2735\n5 gold badges\n26\n26 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"I liked JonBrave's answer, but I have messy enough working directories that commit -a scares me a bit, so here's what I've done:\n\ngit config --global alias.exclude-ignored '!git ls-files -z --ignored --exclude-standard | xargs -0 git rm -r --cached &&  git ls-files -z --ignored --exclude-standard | xargs -0 git stage &&  git stage .gitignore && git commit -m \"new gitignore and remove ignored files from index\"'\n\n\nBreaking it down:\n\ngit ls-files -z --ignored --exclude-standard | xargs -0 git rm -r --cached\ngit ls-files -z --ignored --exclude-standard | xargs -0 git stage\ngit stage .gitignore\ngit commit -m \"new gitignore and remove ignored files from index\"\n\nremove ignored files from the index\nstage .gitignore and the files you just removed\ncommit\nShare\nImprove this answer\nFollow\nedited Jul 21 at 7:21\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 8 '18 at 20:49\nJay Irvine\n1852\n2 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"This is no longer an issue in the latest Git (v2.17.1 at the time of writing).\n\nThe .gitignore file finally ignores tracked-but-deleted files. You can test this for yourself by running the following script. The final git status statement should report \"nothing to commit\".\n\n# Create an empty repository\nmkdir gitignore-test\ncd gitignore-test\ngit init\n\n# Create a file and commit it\necho \"hello\" > file\ngit add file\ngit commit -m initial\n\n# Add the file to gitignore and commit\necho \"file\" > .gitignore\ngit add .gitignore\ngit commit -m gitignore\n\n# Remove the file and commit\ngit rm file\ngit commit -m \"removed file\"\n\n# Reintroduce the file and check status.\n# .gitignore is now respected - status reports \"nothing to commit\".\necho \"hello\" > file\ngit status\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 7:16\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 13 '18 at 16:21\nLloyd\n7,5542\n2 gold badges\n31\n31 silver badges\n52\n52 bronze badges","comments":["I'm glad git now does this. However, the OP was asking about not tracking modifications in files present in the .gitignore, not deleted files still showing a status."]},{"answer":"The accepted answer does not \"make Git \"forget\" about a file...\" (historically). It only makes Git ignore the file in the present/future.\n\nThis method makes Git completely forget ignored files (past/present/future), but it does not delete anything from the working directory (even when re-pulled from remote).\n\nThis method requires usage of file /.git/info/exclude (preferred) or a pre-existing .gitignore in all the commits that have files to be ignored/forgotten. 1\n\nAll methods of enforcing Git ignore behavior after-the-fact effectively rewrite history and thus have significant ramifications for any public/shared/collaborative repositories that might be pulled after this process. 2\n\nGeneral advice: start with a clean repository - everything committed, nothing pending in working directory or index, and make a backup!\n\nAlso, the comments/revision history of this answer (and revision history of this question) may be useful/enlightening.\n\n#Commit up-to-date .gitignore (if not already existing)\n#This command must be run on each branch\n\ngit add .gitignore\ngit commit -m \"Create .gitignore\"\n\n#Apply standard Git ignore behavior only to the current index, not the working directory (--cached)\n#If this command returns nothing, ensure /.git/info/exclude AND/OR .gitignore exist\n#This command must be run on each branch\n\ngit ls-files -z --ignored --exclude-standard | xargs -0 git rm --cached\n\n#Commit to prevent working directory data loss!\n#This commit will be automatically deleted by the --prune-empty flag in the following command\n#This command must be run on each branch\n\ngit commit -m \"ignored index\"\n\n#Apply standard git ignore behavior RETROACTIVELY to all commits from all branches (--all)\n#This step WILL delete ignored files from working directory UNLESS they have been dereferenced from the index by the commit above\n#This step will also delete any \"empty\" commits.  If deliberate \"empty\" commits should be kept, remove --prune-empty and instead run git reset HEAD^ immediately after this command\n\ngit filter-branch --tree-filter 'git ls-files -z --ignored --exclude-standard | xargs -0 git rm -f --ignore-unmatch' --prune-empty --tag-name-filter cat -- --all\n\n#List all still-existing files that are now ignored properly\n#If this command returns nothing, it's time to restore from backup and start over\n#This command must be run on each branch\n\ngit ls-files --other --ignored --exclude-standard\n\n\nFinally, follow the rest of this GitHub guide (starting at step 6) which includes important warnings/information about the commands below.\n\ngit push origin --force --all\ngit push origin --force --tags\ngit for-each-ref --format=\"delete %(refname)\" refs/original | git update-ref --stdin\ngit reflog expire --expire=now --all\ngit gc --prune=now\n\n\nOther developers that pull from the now-modified remote repository should make a backup and then:\n\n#fetch modified remote\n\ngit fetch --all\n\n#\"Pull\" changes WITHOUT deleting newly-ignored files from working directory\n#This will overwrite local tracked files with remote - ensure any local modifications are backed-up/stashed\n\ngit reset FETCH_HEAD\n\nFootnotes\n\n1 Because /.git/info/exclude can be applied to all historical commits using the instructions above, perhaps details about getting a .gitignore file into the historical commit(s) that need it is beyond the scope of this answer. I wanted a proper .gitignore file to be in the root commit, as if it was the first thing I did. Others may not care since /.git/info/exclude can accomplish the same thing regardless where the .gitignore file exists in the commit history, and clearly rewriting history is a very touchy subject, even when aware of the ramifications.\n\nFWIW, potential methods may include git rebase or a git filter-branch that copies an external .gitignore into each commit, like the answers to this question.\n\n2 Enforcing Git ignore behavior after-the-fact by committing the results of a stand-alone git rm --cached command may result in newly-ignored file deletion in future pulls from the force-pushed remote. The --prune-empty flag in the following git filter-branch command avoids this problem by automatically removing the previous \"delete all ignored files\" index-only commit. Rewriting Git history also changes commit hashes, which will wreak havoc on future pulls from public/shared/collaborative repositories. Please understand the ramifications fully before doing this to such a repository. This GitHub guide specifies the following:\n\nTell your collaborators to rebase, not merge, any branches they created off of your old (tainted) repository history. One merge commit could reintroduce some or all of the tainted history that you just went to the trouble of purging.\n\nAlternative solutions that do not affect the remote repository are git update-index --assume-unchanged </path/file> or git update-index --skip-worktree <file>, examples of which can be found here.\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 7:53\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 14 '19 at 2:38\ngoofology\n6652\n2 gold badges\n8\n8 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"In case of already committed DS_Store:\n\nfind . -name .DS_Store -print0 | xargs -0 git rm --ignore-unmatch\n\n\nIgnore them by:\n\necho \".DS_Store\" >> ~/.gitignore_global\necho \"._.DS_Store\" >> ~/.gitignore_global\necho \"**/.DS_Store\" >> ~/.gitignore_global\necho \"**/._.DS_Store\" >> ~/.gitignore_global\ngit config --global core.excludesfile ~/.gitignore_global\n\n\nFinally, make a commit!\n\nShare\nImprove this answer\nFollow\nanswered Apr 22 '18 at 21:14\nuser7718859","comments":["What is \"DS_Store\" (or \".DS_Store\"?)? A Mac-specific file?"]},{"answer":"Especially for the IDE-based files, I use this:\n\nFor instance, for the slnx.sqlite file, I just got rid off it completely like the following:\n\ngit rm {PATH_OF_THE_FILE}/slnx.sqlite -f\ngit commit -m \"remove slnx.sqlite\"\n\n\nJust keep that in mind that some of those files store some local user settings and preferences for projects (like what files you had open). So every time you navigate or do some changes in your IDE, that file is changed and therefore it checks it out and show as uncommitted changes.\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 7:40\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 5 '19 at 18:48\ncuriousBoy\n4,9134\n4 gold badges\n39\n39 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"In my case I needed to put \".envrc\" in the .gitignore file.\n\nAnd then I used:\n\ngit update-index --skip-worktree .envrc\ngit rm --cached .envrc\n\n\nAnd the file was removed.\n\nThen I committed again, telling that the file was removed.\n\nBut when I used the command git log -p, the content of the file (which was secret credentials of the Amazon S3) was showing the content which was removed and I don't want to show this content ever on the history of the Git repository.\n\nThen I used this command:\n\ngit filter-branch --index-filter 'git rm --cached --ignore-unmatch .envrc' HEAD\n\n\nAnd I don't see the content again.\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 8:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 16 at 20:37\nrld\n1,6851\n1 gold badge\n19\n19 silver badges\n32\n32 bronze badges","comments":["git update-index --skip-worktree .idea/ git rm -r --cached .idea/ did the trick after I accidentally hit add . with newly generated IDE folder"]},{"answer":"This is how I solved my issue:\n\ngit filter-branch --tree-filter 'rm -rf path/to/your/file' HEAD\ngit push\n\nIn this, we are basically trying to rewrite the history of that particular file in previous commits also.\n\nFor more information, you can refer to the man page of filter-branch here.\n\nSource: Removing sensitive data from a repository - using filter-branch\n\nSource: Git: How to remove a big file wrongly committed\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 8:05\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 12 at 12:59\nKhushhalm\n3825\n5 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"In my case here, I had several .lock files in several directories that I needed to remove. I ran the following and it worked without having to go into each directory to remove them:\n\ngit rm -r --cached **/*.lock\n\n\nDoing this went into each folder under the 'root' of where I was at and excluded all files that matched the pattern.\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 7:57\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 27 '19 at 22:05\nDC.Skells\n5704\n4 silver badges\n14\n14 bronze badges","comments":["Where did the .lock files come from? What created them?"]},{"answer":"If anyone is having a hard time on Windows and you want to ignore the entire folder, go to the desired 'folder' on file explorer, right click and do 'Git Bash Here' (Git for Windows should have been installed).\n\nRun this command:\n\ngit ls-files -z | xargs -0 git update-index --assume-unchanged\n\nShare\nImprove this answer\nFollow\nedited Jul 22 at 8:09\nanswered Dec 14 '19 at 4:36\nRajVimalC\n1111\n1 silver badge\n5\n5 bronze badges","comments":["What do you mean by \"do Git Bash Here\"? How is it connected to the command-line? Please respond by editing (changing) your answer, not here in comments (without \"Edit:\", \"Update:\", or similar - the answer should appear as if it was written today)."]},{"answer":"if you created gitignore file using command like echo node_modules >> .gitignore, It won't work.\n\nThe windows terminal saves the file in UCS-2 LE BOM and git doesn't seem to accept that.\n\nYou can fix this by opening in Notepad and resave it with UTF-8 encoding\n\nIt Works now.\n\nI think they need to fix this since doing echo \"filetoignore\" >> .gitignore actually seems very handy\n\nShare\nImprove this answer\nFollow\nanswered Jul 28 at 13:49\nAbraham\n1,0965\n5 silver badges\n17\n17 bronze badges","comments":[]}]},{"id":"100003","href":"https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python","title":"What are metaclasses in Python?","description":"\n                \nIn Python, what are metaclasses and what do we use them for?\n    ","questionComments":[],"answers":[{"answer":"A metaclass is the class of a class. A class defines how an instance of the class (i.e. an object) behaves while a metaclass defines how a class behaves. A class is an instance of a metaclass.\n\nWhile in Python you can use arbitrary callables for metaclasses (like Jerub shows), the better approach is to make it an actual class itself. type is the usual metaclass in Python. type is itself a class, and it is its own type. You won't be able to recreate something like type purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass type.\n\nA metaclass is most commonly used as a class-factory. When you create an object by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal __init__ and __new__ methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.\n\nWhen the class statement is executed, Python first executes the body of the class statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the __metaclass__ attribute of the class-to-be (if any) or the __metaclass__ global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.\n\nHowever, metaclasses actually define the type of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. type.__subclasses__() is an example of a method on the type metaclass. You can also define the normal 'magic' methods, like __add__, __iter__ and __getattr__, to implement or change how the class behaves.\n\nHere's an aggregated example of the bits and pieces:\n\ndef make_hook(f):\n    \"\"\"Decorator to turn 'foo' method into '__foo__'\"\"\"\n    f.is_hook = 1\n    return f\n\nclass MyType(type):\n    def __new__(mcls, name, bases, attrs):\n\n        if name.startswith('None'):\n            return None\n\n        # Go over attributes and see if they should be renamed.\n        newattrs = {}\n        for attrname, attrvalue in attrs.iteritems():\n            if getattr(attrvalue, 'is_hook', 0):\n                newattrs['__%s__' % attrname] = attrvalue\n            else:\n                newattrs[attrname] = attrvalue\n\n        return super(MyType, mcls).__new__(mcls, name, bases, newattrs)\n\n    def __init__(self, name, bases, attrs):\n        super(MyType, self).__init__(name, bases, attrs)\n\n        # classregistry.register(self, self.interfaces)\n        print \"Would register class %s now.\" % self\n\n    def __add__(self, other):\n        class AutoClass(self, other):\n            pass\n        return AutoClass\n        # Alternatively, to autogenerate the classname as well as the class:\n        # return type(self.__name__ + other.__name__, (self, other), {})\n\n    def unregister(self):\n        # classregistry.unregister(self)\n        print \"Would unregister class %s now.\" % self\n\nclass MyObject:\n    __metaclass__ = MyType\n\n\nclass NoneSample(MyObject):\n    pass\n\n# Will print \"NoneType None\"\nprint type(NoneSample), repr(NoneSample)\n\nclass Example(MyObject):\n    def __init__(self, value):\n        self.value = value\n    @make_hook\n    def add(self, other):\n        return self.__class__(self.value + other.value)\n\n# Will unregister the class\nExample.unregister()\n\ninst = Example(10)\n# Will fail with an AttributeError\n#inst.unregister()\n\nprint inst + inst\nclass Sibling(MyObject):\n    pass\n\nExampleSibling = Example + Sibling\n# ExampleSibling is now a subclass of both Example and Sibling (with no\n# content of its own) although it will believe it's called 'AutoClass'\nprint ExampleSibling\nprint ExampleSibling.__mro__\n\nShare\nImprove this answer\nFollow\nedited Mar 4 '19 at 21:34\nCameron Savage\n72\n2 bronze badges\nanswered Sep 19 '08 at 7:01\nThomas Wouters\n120k21\n21 gold badges\n139\n139 silver badges\n118\n118 bronze badges","comments":["class A(type):pass<NEWLINE>class B(type,metaclass=A):pass<NEWLINE>b.__class__ = b","ppperry he obviously meant you can't recreate type without using type itself as a metaclass. Which is fair enough to say.","Shouldn't unregister() be called by instance of Example class ?","Note that __metaclass__ is not supported in Python 3. In Python 3 use class MyObject(metaclass=MyType), see python.org/dev/peps/pep-3115 and the answer below.","The documentation describes how the metaclass is chosen. The metaclass isn't inherited so much as it is derived. If you specify a metaclass, it has to be a subtype of each base class metaclass; otherwise, you'll use the a base class metaclass that is a subtype of each other base class metaclass. Note that it is possible that no valid metaclass can be found, and the definition will fail."]},{"answer":"Classes as objects\n\nBefore understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.\n\nIn most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:\n\n>>> class ObjectCreator(object):\n...       pass\n...\n\n>>> my_object = ObjectCreator()\n>>> print(my_object)\n<__main__.ObjectCreator object at 0x8974f2c>\n\n\nBut classes are more than that in Python. Classes are objects too.\n\nYes, objects.\n\nAs soon as you use the keyword class, Python executes it and creates an object. The instruction\n\n>>> class ObjectCreator(object):\n...       pass\n...\n\n\ncreates in memory an object with the name ObjectCreator.\n\nThis object (the class) is itself capable of creating objects (the instances), and this is why it's a class.\n\nBut still, it's an object, and therefore:\n\nyou can assign it to a variable\nyou can copy it\nyou can add attributes to it\nyou can pass it as a function parameter\n\ne.g.:\n\n>>> print(ObjectCreator) # you can print a class because it's an object\n<class '__main__.ObjectCreator'>\n>>> def echo(o):\n...       print(o)\n...\n>>> echo(ObjectCreator) # you can pass a class as a parameter\n<class '__main__.ObjectCreator'>\n>>> print(hasattr(ObjectCreator, 'new_attribute'))\nFalse\n>>> ObjectCreator.new_attribute = 'foo' # you can add attributes to a class\n>>> print(hasattr(ObjectCreator, 'new_attribute'))\nTrue\n>>> print(ObjectCreator.new_attribute)\nfoo\n>>> ObjectCreatorMirror = ObjectCreator # you can assign a class to a variable\n>>> print(ObjectCreatorMirror.new_attribute)\nfoo\n>>> print(ObjectCreatorMirror())\n<__main__.ObjectCreator object at 0x8997b4c>\n\nCreating classes dynamically\n\nSince classes are objects, you can create them on the fly, like any object.\n\nFirst, you can create a class in a function using class:\n\n>>> def choose_class(name):\n...     if name == 'foo':\n...         class Foo(object):\n...             pass\n...         return Foo # return the class, not an instance\n...     else:\n...         class Bar(object):\n...             pass\n...         return Bar\n...\n>>> MyClass = choose_class('foo')\n>>> print(MyClass) # the function returns a class, not an instance\n<class '__main__.Foo'>\n>>> print(MyClass()) # you can create an object from this class\n<__main__.Foo object at 0x89c6d4c>\n\n\nBut it's not so dynamic, since you still have to write the whole class yourself.\n\nSince classes are objects, they must be generated by something.\n\nWhen you use the class keyword, Python creates this object automatically. But as with most things in Python, it gives you a way to do it manually.\n\nRemember the function type? The good old function that lets you know what type an object is:\n\n>>> print(type(1))\n<type 'int'>\n>>> print(type(\"1\"))\n<type 'str'>\n>>> print(type(ObjectCreator))\n<type 'type'>\n>>> print(type(ObjectCreator()))\n<class '__main__.ObjectCreator'>\n\n\nWell, type has a completely different ability, it can also create classes on the fly. type can take the description of a class as parameters, and return a class.\n\n(I know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backward compatibility in Python)\n\ntype works this way:\n\ntype(name, bases, attrs)\n\n\nWhere:\n\nname: name of the class\nbases: tuple of the parent class (for inheritance, can be empty)\nattrs: dictionary containing attributes names and values\n\ne.g.:\n\n>>> class MyShinyClass(object):\n...       pass\n\n\ncan be created manually this way:\n\n>>> MyShinyClass = type('MyShinyClass', (), {}) # returns a class object\n>>> print(MyShinyClass)\n<class '__main__.MyShinyClass'>\n>>> print(MyShinyClass()) # create an instance with the class\n<__main__.MyShinyClass object at 0x8997cec>\n\n\nYou'll notice that we use MyShinyClass as the name of the class and as the variable to hold the class reference. They can be different, but there is no reason to complicate things.\n\ntype accepts a dictionary to define the attributes of the class. So:\n\n>>> class Foo(object):\n...       bar = True\n\n\nCan be translated to:\n\n>>> Foo = type('Foo', (), {'bar':True})\n\n\nAnd used as a normal class:\n\n>>> print(Foo)\n<class '__main__.Foo'>\n>>> print(Foo.bar)\nTrue\n>>> f = Foo()\n>>> print(f)\n<__main__.Foo object at 0x8a9b84c>\n>>> print(f.bar)\nTrue\n\n\nAnd of course, you can inherit from it, so:\n\n>>>   class FooChild(Foo):\n...         pass\n\n\nwould be:\n\n>>> FooChild = type('FooChild', (Foo,), {})\n>>> print(FooChild)\n<class '__main__.FooChild'>\n>>> print(FooChild.bar) # bar is inherited from Foo\nTrue\n\n\nEventually, you'll want to add methods to your class. Just define a function with the proper signature and assign it as an attribute.\n\n>>> def echo_bar(self):\n...       print(self.bar)\n...\n>>> FooChild = type('FooChild', (Foo,), {'echo_bar': echo_bar})\n>>> hasattr(Foo, 'echo_bar')\nFalse\n>>> hasattr(FooChild, 'echo_bar')\nTrue\n>>> my_foo = FooChild()\n>>> my_foo.echo_bar()\nTrue\n\n\nAnd you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.\n\n>>> def echo_bar_more(self):\n...       print('yet another method')\n...\n>>> FooChild.echo_bar_more = echo_bar_more\n>>> hasattr(FooChild, 'echo_bar_more')\nTrue\n\n\nYou see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.\n\nThis is what Python does when you use the keyword class, and it does so by using a metaclass.\n\nWhat are metaclasses (finally)\n\nMetaclasses are the 'stuff' that creates classes.\n\nYou define classes in order to create objects, right?\n\nBut we learned that Python classes are objects.\n\nWell, metaclasses are what create these objects. They are the classes' classes, you can picture them this way:\n\nMyClass = MetaClass()\nmy_object = MyClass()\n\n\nYou've seen that type lets you do something like this:\n\nMyClass = type('MyClass', (), {})\n\n\nIt's because the function type is in fact a metaclass. type is the metaclass Python uses to create all classes behind the scenes.\n\nNow you wonder \"why the heck is it written in lowercase, and not Type?\"\n\nWell, I guess it's a matter of consistency with str, the class that creates strings objects, and int the class that creates integer objects. type is just the class that creates class objects.\n\nYou see that by checking the __class__ attribute.\n\nEverything, and I mean everything, is an object in Python. That includes integers, strings, functions and classes. All of them are objects. And all of them have been created from a class:\n\n>>> age = 35\n>>> age.__class__\n<type 'int'>\n>>> name = 'bob'\n>>> name.__class__\n<type 'str'>\n>>> def foo(): pass\n>>> foo.__class__\n<type 'function'>\n>>> class Bar(object): pass\n>>> b = Bar()\n>>> b.__class__\n<class '__main__.Bar'>\n\n\nNow, what is the __class__ of any __class__ ?\n\n>>> age.__class__.__class__\n<type 'type'>\n>>> name.__class__.__class__\n<type 'type'>\n>>> foo.__class__.__class__\n<type 'type'>\n>>> b.__class__.__class__\n<type 'type'>\n\n\nSo, a metaclass is just the stuff that creates class objects.\n\nYou can call it a 'class factory' if you wish.\n\ntype is the built-in metaclass Python uses, but of course, you can create your own metaclass.\n\nThe __metaclass__ attribute\n\nIn Python 2, you can add a __metaclass__ attribute when you write a class (see next section for the Python 3 syntax):\n\nclass Foo(object):\n    __metaclass__ = something...\n    [...]\n\n\nIf you do so, Python will use the metaclass to create the class Foo.\n\nCareful, it's tricky.\n\nYou write class Foo(object) first, but the class object Foo is not created in memory yet.\n\nPython will look for __metaclass__ in the class definition. If it finds it, it will use it to create the object class Foo. If it doesn't, it will use type to create the class.\n\nRead that several times.\n\nWhen you do:\n\nclass Foo(Bar):\n    pass\n\n\nPython does the following:\n\nIs there a __metaclass__ attribute in Foo?\n\nIf yes, create in-memory a class object (I said a class object, stay with me here), with the name Foo by using what is in __metaclass__.\n\nIf Python can't find __metaclass__, it will look for a __metaclass__ at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes).\n\nThen if it can't find any __metaclass__ at all, it will use the Bar's (the first parent) own metaclass (which might be the default type) to create the class object.\n\nBe careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.\n\nNow the big question is, what can you put in __metaclass__?\n\nThe answer is something that can create a class.\n\nAnd what can create a class? type, or anything that subclasses or uses it.\n\nMetaclasses in Python 3\n\nThe syntax to set the metaclass has been changed in Python 3:\n\nclass Foo(object, metaclass=something):\n    ...\n\n\ni.e. the __metaclass__ attribute is no longer used, in favor of a keyword argument in the list of base classes.\n\nThe behavior of metaclasses however stays largely the same.\n\nOne thing added to metaclasses in Python 3 is that you can also pass attributes as keyword-arguments into a metaclass, like so:\n\nclass Foo(object, metaclass=something, kwarg1=value1, kwarg2=value2):\n    ...\n\n\nRead the section below for how Python handles this.\n\nCustom metaclasses\n\nThe main purpose of a metaclass is to change the class automatically, when it's created.\n\nYou usually do this for APIs, where you want to create classes matching the current context.\n\nImagine a stupid example, where you decide that all classes in your module should have their attributes written in uppercase. There are several ways to do this, but one way is to set __metaclass__ at the module level.\n\nThis way, all classes of this module will be created using this metaclass, and we just have to tell the metaclass to turn all attributes to uppercase.\n\nLuckily, __metaclass__ can actually be any callable, it doesn't need to be a formal class (I know, something with 'class' in its name doesn't need to be a class, go figure... but it's helpful).\n\nSo we will start with a simple example, by using a function.\n\n# the metaclass will automatically get passed the same argument\n# that you usually pass to `type`\ndef upper_attr(future_class_name, future_class_parents, future_class_attrs):\n    \"\"\"\n      Return a class object, with the list of its attribute turned\n      into uppercase.\n    \"\"\"\n    # pick up any attribute that doesn't start with '__' and uppercase it\n    uppercase_attrs = {\n        attr if attr.startswith(\"__\") else attr.upper(): v\n        for attr, v in future_class_attrs.items()\n    }\n\n    # let `type` do the class creation\n    return type(future_class_name, future_class_parents, uppercase_attrs)\n\n__metaclass__ = upper_attr # this will affect all classes in the module\n\nclass Foo(): # global __metaclass__ won't work with \"object\" though\n    # but we can define __metaclass__ here instead to affect only this class\n    # and this will work with \"object\" children\n    bar = 'bip'\n\n\nLet's check:\n\n>>> hasattr(Foo, 'bar')\nFalse\n>>> hasattr(Foo, 'BAR')\nTrue\n>>> Foo.BAR\n'bip'\n\n\nNow, let's do exactly the same, but using a real class for a metaclass:\n\n# remember that `type` is actually a class like `str` and `int`\n# so you can inherit from it\nclass UpperAttrMetaclass(type):\n    # __new__ is the method called before __init__\n    # it's the method that creates the object and returns it\n    # while __init__ just initializes the object passed as parameter\n    # you rarely use __new__, except when you want to control how the object\n    # is created.\n    # here the created object is the class, and we want to customize it\n    # so we override __new__\n    # you can do some stuff in __init__ too if you wish\n    # some advanced use involves overriding __call__ as well, but we won't\n    # see this\n    def __new__(upperattr_metaclass, future_class_name,\n                future_class_parents, future_class_attrs):\n        uppercase_attrs = {\n            attr if attr.startswith(\"__\") else attr.upper(): v\n            for attr, v in future_class_attrs.items()\n        }\n        return type(future_class_name, future_class_parents, uppercase_attrs)\n\n\nLet's rewrite the above, but with shorter and more realistic variable names now that we know what they mean:\n\nclass UpperAttrMetaclass(type):\n    def __new__(cls, clsname, bases, attrs):\n        uppercase_attrs = {\n            attr if attr.startswith(\"__\") else attr.upper(): v\n            for attr, v in attrs.items()\n        }\n        return type(clsname, bases, uppercase_attrs)\n\n\nYou may have noticed the extra argument cls. There is nothing special about it: __new__ always receives the class it's defined in, as the first parameter. Just like you have self for ordinary methods which receive the instance as the first parameter, or the defining class for class methods.\n\nBut this is not proper OOP. We are calling type directly and we aren't overriding or calling the parent's __new__. Let's do that instead:\n\nclass UpperAttrMetaclass(type):\n    def __new__(cls, clsname, bases, attrs):\n        uppercase_attrs = {\n            attr if attr.startswith(\"__\") else attr.upper(): v\n            for attr, v in attrs.items()\n        }\n        return type.__new__(cls, clsname, bases, uppercase_attrs)\n\n\nWe can make it even cleaner by using super, which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):\n\nclass UpperAttrMetaclass(type):\n    def __new__(cls, clsname, bases, attrs):\n        uppercase_attrs = {\n            attr if attr.startswith(\"__\") else attr.upper(): v\n            for attr, v in attrs.items()\n        }\n        return super(UpperAttrMetaclass, cls).__new__(\n            cls, clsname, bases, uppercase_attrs)\n\n\nOh, and in Python 3 if you do this call with keyword arguments, like this:\n\nclass Foo(object, metaclass=MyMetaclass, kwarg1=value1):\n    ...\n\n\nIt translates to this in the metaclass to use it:\n\nclass MyMetaclass(type):\n    def __new__(cls, clsname, bases, dct, kwargs1=default):\n        ...\n\n\nThat's it. There is really nothing more about metaclasses.\n\nThe reason behind the complexity of the code using metaclasses is not because of metaclasses, it's because you usually use metaclasses to do twisted stuff relying on introspection, manipulating inheritance, vars such as __dict__, etc.\n\nIndeed, metaclasses are especially useful to do black magic, and therefore complicated stuff. But by themselves, they are simple:\n\nintercept a class creation\nmodify the class\nreturn the modified class\nWhy would you use metaclasses classes instead of functions?\n\nSince __metaclass__ can accept any callable, why would you use a class since it's obviously more complicated?\n\nThere are several reasons to do so:\n\nThe intention is clear. When you read UpperAttrMetaclass(type), you know what's going to follow\nYou can use OOP. Metaclass can inherit from metaclass, override parent methods. Metaclasses can even use metaclasses.\nSubclasses of a class will be instances of its metaclass if you specified a metaclass-class, but not with a metaclass-function.\nYou can structure your code better. You never use metaclasses for something as trivial as the above example. It's usually for something complicated. Having the ability to make several methods and group them in one class is very useful to make the code easier to read.\nYou can hook on __new__, __init__ and __call__. Which will allow you to do different stuff, Even if usually you can do it all in __new__, some people are just more comfortable using __init__.\nThese are called metaclasses, damn it! It must mean something!\nWhy would you use metaclasses?\n\nNow the big question. Why would you use some obscure error-prone feature?\n\nWell, usually you don't:\n\nMetaclasses are deeper magic that 99% of users should never worry about it. If you wonder whether you need them, you don't (the people who actually need them to know with certainty that they need them and don't need an explanation about why).\n\nPython Guru Tim Peters\n\nThe main use case for a metaclass is creating an API. A typical example of this is the Django ORM. It allows you to define something like this:\n\nclass Person(models.Model):\n    name = models.CharField(max_length=30)\n    age = models.IntegerField()\n\n\nBut if you do this:\n\nperson = Person(name='bob', age='35')\nprint(person.age)\n\n\nIt won't return an IntegerField object. It will return an int, and can even take it directly from the database.\n\nThis is possible because models.Model defines __metaclass__ and it uses some magic that will turn the Person you just defined with simple statements into a complex hook to a database field.\n\nDjango makes something complex look simple by exposing a simple API and using metaclasses, recreating code from this API to do the real job behind the scenes.\n\nThe last word\n\nFirst, you know that classes are objects that can create instances.\n\nWell, in fact, classes are themselves instances. Of metaclasses.\n\n>>> class Foo(object): pass\n>>> id(Foo)\n142630324\n\n\nEverything is an object in Python, and they are all either instance of classes or instances of metaclasses.\n\nExcept for type.\n\ntype is actually its own metaclass. This is not something you could reproduce in pure Python, and is done by cheating a little bit at the implementation level.\n\nSecondly, metaclasses are complicated. You may not want to use them for very simple class alterations. You can change classes by using two different techniques:\n\nmonkey patching\nclass decorators\n\n99% of the time you need class alteration, you are better off using these.\n\nBut 98% of the time, you don't need class alteration at all.\n\nShare\nImprove this answer\nFollow\nedited Jul 20 at 18:45\ncommunity wiki\n\n\n61 revs, 46 users 68%\ne-satis","comments":["It appears that in Django models.Model it does not use __metaclass__ but rather class Model(metaclass=ModelBase): to reference a ModelBase class which then does the aforementioned metaclass magic. Great post! Here's the Django source: github.com/django/django/blob/master/django/db/models/…","<<Be careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.>> -- Could you/someone please explain a bit deeper this passage?","@MaxGoodridge That's the Python 3 syntax for metaclasses. See Python 3.6 Data model VS Python 2.7 Data model","Now you wonder why the heck is it written in lowercase, and not Type? - well because it's implemented in C - it's the same reason defaultdict is lowercase while OrderedDict (in python 2) is normal CamelCase","It's a community wiki answer (so, those who commented with corrections/improvements might consider editing their comments into the answer, if they're sure they are correct)."]},{"answer":"Note, this answer is for Python 2.x as it was written in 2008, metaclasses are slightly different in 3.x.\n\nMetaclasses are the secret sauce that make 'class' work. The default metaclass for a new style object is called 'type'.\n\nclass type(object)\n  |  type(object) -> the object's type\n  |  type(name, bases, dict) -> a new type\n\n\nMetaclasses take 3 args. 'name', 'bases' and 'dict'\n\nHere is where the secret starts. Look for where name, bases and the dict come from in this example class definition.\n\nclass ThisIsTheName(Bases, Are, Here):\n    All_the_code_here\n    def doesIs(create, a):\n        dict\n\n\nLets define a metaclass that will demonstrate how 'class:' calls it.\n\ndef test_metaclass(name, bases, dict):\n    print 'The Class Name is', name\n    print 'The Class Bases are', bases\n    print 'The dict has', len(dict), 'elems, the keys are', dict.keys()\n\n    return \"yellow\"\n\nclass TestName(object, None, int, 1):\n    __metaclass__ = test_metaclass\n    foo = 1\n    def baz(self, arr):\n        pass\n\nprint 'TestName = ', repr(TestName)\n\n# output => \nThe Class Name is TestName\nThe Class Bases are (<type 'object'>, None, <type 'int'>, 1)\nThe dict has 4 elems, the keys are ['baz', '__module__', 'foo', '__metaclass__']\nTestName =  'yellow'\n\n\nAnd now, an example that actually means something, this will automatically make the variables in the list \"attributes\" set on the class, and set to None.\n\ndef init_attributes(name, bases, dict):\n    if 'attributes' in dict:\n        for attr in dict['attributes']:\n            dict[attr] = None\n\n    return type(name, bases, dict)\n\nclass Initialised(object):\n    __metaclass__ = init_attributes\n    attributes = ['foo', 'bar', 'baz']\n\nprint 'foo =>', Initialised.foo\n# output=>\nfoo => None\n\n\nNote that the magic behaviour that Initialised gains by having the metaclass init_attributes is not passed onto a subclass of Initialised.\n\nHere is an even more concrete example, showing how you can subclass 'type' to make a metaclass that performs an action when the class is created. This is quite tricky:\n\nclass MetaSingleton(type):\n    instance = None\n    def __call__(cls, *args, **kw):\n        if cls.instance is None:\n            cls.instance = super(MetaSingleton, cls).__call__(*args, **kw)\n        return cls.instance\n\nclass Foo(object):\n    __metaclass__ = MetaSingleton\n\na = Foo()\nb = Foo()\nassert a is b\n\nShare\nImprove this answer\nFollow\nedited Nov 6 '19 at 7:57\nralh\n2,3341\n1 gold badge\n11\n11 silver badges\n18\n18 bronze badges\nanswered Sep 19 '08 at 6:26\nJerub\n38.9k14\n14 gold badges\n69\n69 silver badges\n90\n90 bronze badges","comments":[]},{"answer":"Others have explained how metaclasses work and how they fit into the Python type system. Here's an example of what they can be used for. In a testing framework I wrote, I wanted to keep track of the order in which classes were defined, so that I could later instantiate them in this order. I found it easiest to do this using a metaclass.\n\nclass MyMeta(type):\n\n    counter = 0\n\n    def __init__(cls, name, bases, dic):\n        type.__init__(cls, name, bases, dic)\n        cls._order = MyMeta.counter\n        MyMeta.counter += 1\n\nclass MyType(object):              # Python 2\n    __metaclass__ = MyMeta\n\nclass MyType(metaclass=MyMeta):    # Python 3\n    pass\n\n\nAnything that's a subclass of MyType then gets a class attribute _order that records the order in which the classes were defined.\n\nShare\nImprove this answer\nFollow\nedited Nov 28 '16 at 18:04\nanswered Jun 21 '11 at 16:30\nkindall\n160k31\n31 gold badges\n251\n251 silver badges\n290\n290 bronze badges","comments":["Thanks for the example. Why did you find this easier than inheriting from MyBase, whose __init__(self) says type(self)._order = MyBase.counter; MyBase.counter += 1 ?","I wanted the classes themselves, not their instances, to be numbered.","Right, duh. Thanks. My code would reset MyType's attribute on every instantiation, and would never set the attribute if an instance of MyType was never created. Oops. (And a class property could also work, but unlike the metaclass it offers no obvious place to store the counter.)","This is a jolly interesting example, not least because one can genuinely see why a metaclass could be neeeded with this, to supply a solution to a specific difficulty. OTOH I struggle to be convinced that anyone would really need to instantiate objects in the order in which their classes were defined: I guess we just have to take your word for that :).","It was a documentation testing framework and the classes were declarative descriptions of the specific files to be tested, tests to be run, and so forth. The framework reported the results of these in a nicely formatted report grouped by product, document, and test. The report was more useful if it the tests were run in a predictable order. :-)"]},{"answer":"One use for metaclasses is adding new properties and methods to an instance automatically.\n\nFor example, if you look at Django models, their definition looks a bit confusing. It looks as if you are only defining class properties:\n\nclass Person(models.Model):\n    first_name = models.CharField(max_length=30)\n    last_name = models.CharField(max_length=30)\n\n\nHowever, at runtime the Person objects are filled with all sorts of useful methods. See the source for some amazing metaclassery.\n\nShare\nImprove this answer\nFollow\nanswered Sep 19 '08 at 6:45\nAntti Rasinen\n9,1582\n2 gold badges\n20\n20 silver badges\n18\n18 bronze badges","comments":["Isn't the use of meta classes adding new properties and methods to a class and not an instance? As far as i understood it the meta class alters the class itself and as a result the instances can be constructed differently by the altered class. Could be a bit misleading to people who try to get the nature of a meta class. Having useful methods on instances can be achieved by normal inherence. The reference to Django code as an example is good, though."]},{"answer":"I think the ONLamp introduction to metaclass programming is well written and gives a really good introduction to the topic despite being several years old already.\n\nhttp://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html (archived at https://web.archive.org/web/20080206005253/http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html)\n\nIn short: A class is a blueprint for the creation of an instance, a metaclass is a blueprint for the creation of a class. It can be easily seen that in Python classes need to be first-class objects too to enable this behavior.\n\nI've never written one myself, but I think one of the nicest uses of metaclasses can be seen in the Django framework. The model classes use a metaclass approach to enable a declarative style of writing new models or form classes. While the metaclass is creating the class, all members get the possibility to customize the class itself.\n\nCreating a new model\nThe metaclass enabling this\n\nThe thing that's left to say is: If you don't know what metaclasses are, the probability that you will not need them is 99%.\n\nShare\nImprove this answer\nFollow\nedited Aug 13 '18 at 4:53\nYet Another User\n2,1272\n2 gold badges\n14\n14 silver badges\n27\n27 bronze badges\nanswered Sep 19 '08 at 6:32\nMatthias Kestenholz\n2,9701\n1 gold badge\n18\n18 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"What are metaclasses? What do you use them for?\n\nTLDR: A metaclass instantiates and defines behavior for a class just like a class instantiates and defines behavior for an instance.\n\nPseudocode:\n\n>>> Class(...)\ninstance\n\n\nThe above should look familiar. Well, where does Class come from? It's an instance of a metaclass (also pseudocode):\n\n>>> Metaclass(...)\nClass\n\n\nIn real code, we can pass the default metaclass, type, everything we need to instantiate a class and we get a class:\n\n>>> type('Foo', (object,), {}) # requires a name, bases, and a namespace\n<class '__main__.Foo'>\n\nPutting it differently\n\nA class is to an instance as a metaclass is to a class.\n\nWhen we instantiate an object, we get an instance:\n\n>>> object()                          # instantiation of class\n<object object at 0x7f9069b4e0b0>     # instance\n\n\nLikewise, when we define a class explicitly with the default metaclass, type, we instantiate it:\n\n>>> type('Object', (object,), {})     # instantiation of metaclass\n<class '__main__.Object'>             # instance\n\n\nPut another way, a class is an instance of a metaclass:\n\n>>> isinstance(object, type)\nTrue\n\n\nPut a third way, a metaclass is a class's class.\n\n>>> type(object) == type\nTrue\n>>> object.__class__\n<class 'type'>\n\n\nWhen you write a class definition and Python executes it, it uses a metaclass to instantiate the class object (which will, in turn, be used to instantiate instances of that class).\n\nJust as we can use class definitions to change how custom object instances behave, we can use a metaclass class definition to change the way a class object behaves.\n\nWhat can they be used for? From the docs:\n\nThe potential uses for metaclasses are boundless. Some ideas that have been explored include logging, interface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource locking/synchronization.\n\nNevertheless, it is usually encouraged for users to avoid using metaclasses unless absolutely necessary.\n\nYou use a metaclass every time you create a class:\n\nWhen you write a class definition, for example, like this,\n\nclass Foo(object): \n    'demo'\n\n\nYou instantiate a class object.\n\n>>> Foo\n<class '__main__.Foo'>\n>>> isinstance(Foo, type), isinstance(Foo, object)\n(True, True)\n\n\nIt is the same as functionally calling type with the appropriate arguments and assigning the result to a variable of that name:\n\nname = 'Foo'\nbases = (object,)\nnamespace = {'__doc__': 'demo'}\nFoo = type(name, bases, namespace)\n\n\nNote, some things automatically get added to the __dict__, i.e., the namespace:\n\n>>> Foo.__dict__\ndict_proxy({'__dict__': <attribute '__dict__' of 'Foo' objects>, \n'__module__': '__main__', '__weakref__': <attribute '__weakref__' \nof 'Foo' objects>, '__doc__': 'demo'})\n\n\nThe metaclass of the object we created, in both cases, is type.\n\n(A side-note on the contents of the class __dict__: __module__ is there because classes must know where they are defined, and __dict__ and __weakref__ are there because we don't define __slots__ - if we define __slots__ we'll save a bit of space in the instances, as we can disallow __dict__ and __weakref__ by excluding them. For example:\n\n>>> Baz = type('Bar', (object,), {'__doc__': 'demo', '__slots__': ()})\n>>> Baz.__dict__\nmappingproxy({'__doc__': 'demo', '__slots__': (), '__module__': '__main__'})\n\n\n... but I digress.)\n\nWe can extend type just like any other class definition:\n\nHere's the default __repr__ of classes:\n\n>>> Foo\n<class '__main__.Foo'>\n\n\nOne of the most valuable things we can do by default in writing a Python object is to provide it with a good __repr__. When we call help(repr) we learn that there's a good test for a __repr__ that also requires a test for equality - obj == eval(repr(obj)). The following simple implementation of __repr__ and __eq__ for class instances of our type class provides us with a demonstration that may improve on the default __repr__ of classes:\n\nclass Type(type):\n    def __repr__(cls):\n        \"\"\"\n        >>> Baz\n        Type('Baz', (Foo, Bar,), {'__module__': '__main__', '__doc__': None})\n        >>> eval(repr(Baz))\n        Type('Baz', (Foo, Bar,), {'__module__': '__main__', '__doc__': None})\n        \"\"\"\n        metaname = type(cls).__name__\n        name = cls.__name__\n        parents = ', '.join(b.__name__ for b in cls.__bases__)\n        if parents:\n            parents += ','\n        namespace = ', '.join(': '.join(\n          (repr(k), repr(v) if not isinstance(v, type) else v.__name__))\n               for k, v in cls.__dict__.items())\n        return '{0}(\\'{1}\\', ({2}), {{{3}}})'.format(metaname, name, parents, namespace)\n    def __eq__(cls, other):\n        \"\"\"\n        >>> Baz == eval(repr(Baz))\n        True            \n        \"\"\"\n        return (cls.__name__, cls.__bases__, cls.__dict__) == (\n                other.__name__, other.__bases__, other.__dict__)\n\n\nSo now when we create an object with this metaclass, the __repr__ echoed on the command line provides a much less ugly sight than the default:\n\n>>> class Bar(object): pass\n>>> Baz = Type('Baz', (Foo, Bar,), {'__module__': '__main__', '__doc__': None})\n>>> Baz\nType('Baz', (Foo, Bar,), {'__module__': '__main__', '__doc__': None})\n\n\nWith a nice __repr__ defined for the class instance, we have a stronger ability to debug our code. However, much further checking with eval(repr(Class)) is unlikely (as functions would be rather impossible to eval from their default __repr__'s).\n\nAn expected usage: __prepare__ a namespace\n\nIf, for example, we want to know in what order a class's methods are created in, we could provide an ordered dict as the namespace of the class. We would do this with __prepare__ which returns the namespace dict for the class if it is implemented in Python 3:\n\nfrom collections import OrderedDict\n\nclass OrderedType(Type):\n    @classmethod\n    def __prepare__(metacls, name, bases, **kwargs):\n        return OrderedDict()\n    def __new__(cls, name, bases, namespace, **kwargs):\n        result = Type.__new__(cls, name, bases, dict(namespace))\n        result.members = tuple(namespace)\n        return result\n\n\nAnd usage:\n\nclass OrderedMethodsObject(object, metaclass=OrderedType):\n    def method1(self): pass\n    def method2(self): pass\n    def method3(self): pass\n    def method4(self): pass\n\n\nAnd now we have a record of the order in which these methods (and other class attributes) were created:\n\n>>> OrderedMethodsObject.members\n('__module__', '__qualname__', 'method1', 'method2', 'method3', 'method4')\n\n\nNote, this example was adapted from the documentation - the new enum in the standard library does this.\n\nSo what we did was instantiate a metaclass by creating a class. We can also treat the metaclass as we would any other class. It has a method resolution order:\n\n>>> inspect.getmro(OrderedType)\n(<class '__main__.OrderedType'>, <class '__main__.Type'>, <class 'type'>, <class 'object'>)\n\n\nAnd it has approximately the correct repr (which we can no longer eval unless we can find a way to represent our functions.):\n\n>>> OrderedMethodsObject\nOrderedType('OrderedMethodsObject', (object,), {'method1': <function OrderedMethodsObject.method1 at 0x0000000002DB01E0>, 'members': ('__module__', '__qualname__', 'method1', 'method2', 'method3', 'method4'), 'method3': <function OrderedMet\nhodsObject.method3 at 0x0000000002DB02F0>, 'method2': <function OrderedMethodsObject.method2 at 0x0000000002DB0268>, '__module__': '__main__', '__weakref__': <attribute '__weakref__' of 'OrderedMethodsObject' objects>, '__doc__': None, '__d\nict__': <attribute '__dict__' of 'OrderedMethodsObject' objects>, 'method4': <function OrderedMethodsObject.method4 at 0x0000000002DB0378>})\n\nShare\nImprove this answer\nFollow\nedited Aug 30 '17 at 3:19\nanswered Aug 10 '15 at 23:28\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":[]},{"answer":"Python 3 update\n\nThere are (at this point) two key methods in a metaclass:\n\n__prepare__, and\n__new__\n\n__prepare__ lets you supply a custom mapping (such as an OrderedDict) to be used as the namespace while the class is being created. You must return an instance of whatever namespace you choose. If you don't implement __prepare__ a normal dict is used.\n\n__new__ is responsible for the actual creation/modification of the final class.\n\nA bare-bones, do-nothing-extra metaclass would like:\n\nclass Meta(type):\n\n    def __prepare__(metaclass, cls, bases):\n        return dict()\n\n    def __new__(metacls, cls, bases, clsdict):\n        return super().__new__(metacls, cls, bases, clsdict)\n\n\nA simple example:\n\nSay you want some simple validation code to run on your attributes -- like it must always be an int or a str. Without a metaclass, your class would look something like:\n\nclass Person:\n    weight = ValidateType('weight', int)\n    age = ValidateType('age', int)\n    name = ValidateType('name', str)\n\n\nAs you can see, you have to repeat the name of the attribute twice. This makes typos possible along with irritating bugs.\n\nA simple metaclass can address that problem:\n\nclass Person(metaclass=Validator):\n    weight = ValidateType(int)\n    age = ValidateType(int)\n    name = ValidateType(str)\n\n\nThis is what the metaclass would look like (not using __prepare__ since it is not needed):\n\nclass Validator(type):\n    def __new__(metacls, cls, bases, clsdict):\n        # search clsdict looking for ValidateType descriptors\n        for name, attr in clsdict.items():\n            if isinstance(attr, ValidateType):\n                attr.name = name\n                attr.attr = '_' + name\n        # create final class and return it\n        return super().__new__(metacls, cls, bases, clsdict)\n\n\nA sample run of:\n\np = Person()\np.weight = 9\nprint(p.weight)\np.weight = '9'\n\n\nproduces:\n\n9\nTraceback (most recent call last):\n  File \"simple_meta.py\", line 36, in <module>\n    p.weight = '9'\n  File \"simple_meta.py\", line 24, in __set__\n    (self.name, self.type, value))\nTypeError: weight must be of type(s) <class 'int'> (got '9')\n\n\nNote: This example is simple enough it could have also been accomplished with a class decorator, but presumably an actual metaclass would be doing much more.\n\nThe 'ValidateType' class for reference:\n\nclass ValidateType:\n    def __init__(self, type):\n        self.name = None  # will be set by metaclass\n        self.attr = None  # will be set by metaclass\n        self.type = type\n    def __get__(self, inst, cls):\n        if inst is None:\n            return self\n        else:\n            return inst.__dict__[self.attr]\n    def __set__(self, inst, value):\n        if not isinstance(value, self.type):\n            raise TypeError('%s must be of type(s) %s (got %r)' %\n                    (self.name, self.type, value))\n        else:\n            inst.__dict__[self.attr] = value\n\nShare\nImprove this answer\nFollow\nanswered Mar 1 '16 at 19:48\nEthan Furman\n53.3k16\n16 gold badges\n131\n131 silver badges\n206\n206 bronze badges","comments":["Note that since python 3.6, you can use __set_name__(cls, name) in the descriptor (ValidateType) to set the name in the descriptor (self.name and in this case also self.attr). This was added to not have to dive into metaclasses for this specific common use case (see PEP 487)."]},{"answer":"Role of a metaclass' __call__() method when creating a class instance\n\nIf you've done Python programming for more than a few months you'll eventually stumble upon code that looks like this:\n\n# define a class\nclass SomeClass(object):\n    # ...\n    # some definition here ...\n    # ...\n\n# create an instance of it\ninstance = SomeClass()\n\n# then call the object as if it's a function\nresult = instance('foo', 'bar')\n\n\nThe latter is possible when you implement the __call__() magic method on the class.\n\nclass SomeClass(object):\n    # ...\n    # some definition here ...\n    # ...\n\n    def __call__(self, foo, bar):\n        return bar + foo\n\n\nThe __call__() method is invoked when an instance of a class is used as a callable. But as we've seen from previous answers a class itself is an instance of a metaclass, so when we use the class as a callable (i.e. when we create an instance of it) we're actually calling its metaclass' __call__() method. At this point most Python programmers are a bit confused because they've been told that when creating an instance like this instance = SomeClass() you're calling its __init__() method. Some who've dug a bit deeper know that before __init__() there's __new__(). Well, today another layer of truth is being revealed, before __new__() there's the metaclass' __call__().\n\nLet's study the method call chain from specifically the perspective of creating an instance of a class.\n\nThis is a metaclass that logs exactly the moment before an instance is created and the moment it's about to return it.\n\nclass Meta_1(type):\n    def __call__(cls):\n        print \"Meta_1.__call__() before creating an instance of \", cls\n        instance = super(Meta_1, cls).__call__()\n        print \"Meta_1.__call__() about to return instance.\"\n        return instance\n\n\nThis is a class that uses that metaclass\n\nclass Class_1(object):\n\n    __metaclass__ = Meta_1\n\n    def __new__(cls):\n        print \"Class_1.__new__() before creating an instance.\"\n        instance = super(Class_1, cls).__new__(cls)\n        print \"Class_1.__new__() about to return instance.\"\n        return instance\n\n    def __init__(self):\n        print \"entering Class_1.__init__() for instance initialization.\"\n        super(Class_1,self).__init__()\n        print \"exiting Class_1.__init__().\"\n\n\nAnd now let's create an instance of Class_1\n\ninstance = Class_1()\n# Meta_1.__call__() before creating an instance of <class '__main__.Class_1'>.\n# Class_1.__new__() before creating an instance.\n# Class_1.__new__() about to return instance.\n# entering Class_1.__init__() for instance initialization.\n# exiting Class_1.__init__().\n# Meta_1.__call__() about to return instance.\n\n\nObserve that the code above doesn't actually do anything more than logging the tasks. Each method delegates the actual work to its parent's implementation, thus keeping the default behavior. Since type is Meta_1's parent class (type being the default parent metaclass) and considering the ordering sequence of the output above, we now have a clue as to what would be the pseudo implementation of type.__call__():\n\nclass type:\n    def __call__(cls, *args, **kwarg):\n\n        # ... maybe a few things done to cls here\n\n        # then we call __new__() on the class to create an instance\n        instance = cls.__new__(cls, *args, **kwargs)\n\n        # ... maybe a few things done to the instance here\n\n        # then we initialize the instance with its __init__() method\n        instance.__init__(*args, **kwargs)\n\n        # ... maybe a few more things done to instance here\n\n        # then we return it\n        return instance\n\n\nWe can see that the metaclass' __call__() method is the one that's called first. It then delegates creation of the instance to the class's __new__() method and initialization to the instance's __init__(). It's also the one that ultimately returns the instance.\n\nFrom the above it stems that the metaclass' __call__() is also given the opportunity to decide whether or not a call to Class_1.__new__() or Class_1.__init__() will eventually be made. Over the course of its execution it could actually return an object that hasn't been touched by either of these methods. Take for example this approach to the singleton pattern:\n\nclass Meta_2(type):\n    singletons = {}\n\n    def __call__(cls, *args, **kwargs):\n        if cls in Meta_2.singletons:\n            # we return the only instance and skip a call to __new__()\n            # and __init__()\n            print (\"{} singleton returning from Meta_2.__call__(), \"\n                   \"skipping creation of new instance.\".format(cls))\n            return Meta_2.singletons[cls]\n\n        # else if the singleton isn't present we proceed as usual\n        print \"Meta_2.__call__() before creating an instance.\"\n        instance = super(Meta_2, cls).__call__(*args, **kwargs)\n        Meta_2.singletons[cls] = instance\n        print \"Meta_2.__call__() returning new instance.\"\n        return instance\n\nclass Class_2(object):\n\n    __metaclass__ = Meta_2\n\n    def __new__(cls, *args, **kwargs):\n        print \"Class_2.__new__() before creating instance.\"\n        instance = super(Class_2, cls).__new__(cls)\n        print \"Class_2.__new__() returning instance.\"\n        return instance\n\n    def __init__(self, *args, **kwargs):\n        print \"entering Class_2.__init__() for initialization.\"\n        super(Class_2, self).__init__()\n        print \"exiting Class_2.__init__().\"\n\n\nLet's observe what happens when repeatedly trying to create an object of type Class_2\n\na = Class_2()\n# Meta_2.__call__() before creating an instance.\n# Class_2.__new__() before creating instance.\n# Class_2.__new__() returning instance.\n# entering Class_2.__init__() for initialization.\n# exiting Class_2.__init__().\n# Meta_2.__call__() returning new instance.\n\nb = Class_2()\n# <class '__main__.Class_2'> singleton returning from Meta_2.__call__(), skipping creation of new instance.\n\nc = Class_2()\n# <class '__main__.Class_2'> singleton returning from Meta_2.__call__(), skipping creation of new instance.\n\na is b is c # True\n\nShare\nImprove this answer\nFollow\nedited Aug 27 '18 at 17:21\nanswered Oct 13 '16 at 9:21\nMichael Ekoka\n16.3k9\n9 gold badges\n67\n67 silver badges\n76\n76 bronze badges","comments":["This is a good addition to the previously upvoted \"accepted answer\". It provides examples for intermediate coders to chew on."]},{"answer":"A metaclass is a class that tells how (some) other class should be created.\n\nThis is a case where I saw metaclass as a solution to my problem: I had a really complicated problem, that probably could have been solved differently, but I chose to solve it using a metaclass. Because of the complexity, it is one of the few modules I have written where the comments in the module surpass the amount of code that has been written. Here it is...\n\n#!/usr/bin/env python\n\n# Copyright (C) 2013-2014 Craig Phillips.  All rights reserved.\n\n# This requires some explaining.  The point of this metaclass excercise is to\n# create a static abstract class that is in one way or another, dormant until\n# queried.  I experimented with creating a singlton on import, but that did\n# not quite behave how I wanted it to.  See now here, we are creating a class\n# called GsyncOptions, that on import, will do nothing except state that its\n# class creator is GsyncOptionsType.  This means, docopt doesn't parse any\n# of the help document, nor does it start processing command line options.\n# So importing this module becomes really efficient.  The complicated bit\n# comes from requiring the GsyncOptions class to be static.  By that, I mean\n# any property on it, may or may not exist, since they are not statically\n# defined; so I can't simply just define the class with a whole bunch of\n# properties that are @property @staticmethods.\n#\n# So here's how it works:\n#\n# Executing 'from libgsync.options import GsyncOptions' does nothing more\n# than load up this module, define the Type and the Class and import them\n# into the callers namespace.  Simple.\n#\n# Invoking 'GsyncOptions.debug' for the first time, or any other property\n# causes the __metaclass__ __getattr__ method to be called, since the class\n# is not instantiated as a class instance yet.  The __getattr__ method on\n# the type then initialises the class (GsyncOptions) via the __initialiseClass\n# method.  This is the first and only time the class will actually have its\n# dictionary statically populated.  The docopt module is invoked to parse the\n# usage document and generate command line options from it.  These are then\n# paired with their defaults and what's in sys.argv.  After all that, we\n# setup some dynamic properties that could not be defined by their name in\n# the usage, before everything is then transplanted onto the actual class\n# object (or static class GsyncOptions).\n#\n# Another piece of magic, is to allow command line options to be set in\n# in their native form and be translated into argparse style properties.\n#\n# Finally, the GsyncListOptions class is actually where the options are\n# stored.  This only acts as a mechanism for storing options as lists, to\n# allow aggregation of duplicate options or options that can be specified\n# multiple times.  The __getattr__ call hides this by default, returning the\n# last item in a property's list.  However, if the entire list is required,\n# calling the 'list()' method on the GsyncOptions class, returns a reference\n# to the GsyncListOptions class, which contains all of the same properties\n# but as lists and without the duplication of having them as both lists and\n# static singlton values.\n#\n# So this actually means that GsyncOptions is actually a static proxy class...\n#\n# ...And all this is neatly hidden within a closure for safe keeping.\ndef GetGsyncOptionsType():\n    class GsyncListOptions(object):\n        __initialised = False\n\n    class GsyncOptionsType(type):\n        def __initialiseClass(cls):\n            if GsyncListOptions._GsyncListOptions__initialised: return\n\n            from docopt import docopt\n            from libgsync.options import doc\n            from libgsync import __version__\n\n            options = docopt(\n                doc.__doc__ % __version__,\n                version = __version__,\n                options_first = True\n            )\n\n            paths = options.pop('<path>', None)\n            setattr(cls, \"destination_path\", paths.pop() if paths else None)\n            setattr(cls, \"source_paths\", paths)\n            setattr(cls, \"options\", options)\n\n            for k, v in options.iteritems():\n                setattr(cls, k, v)\n\n            GsyncListOptions._GsyncListOptions__initialised = True\n\n        def list(cls):\n            return GsyncListOptions\n\n        def __getattr__(cls, name):\n            cls.__initialiseClass()\n            return getattr(GsyncListOptions, name)[-1]\n\n        def __setattr__(cls, name, value):\n            # Substitut option names: --an-option-name for an_option_name\n            import re\n            name = re.sub(r'^__', \"\", re.sub(r'-', \"_\", name))\n            listvalue = []\n\n            # Ensure value is converted to a list type for GsyncListOptions\n            if isinstance(value, list):\n                if value:\n                    listvalue = [] + value\n                else:\n                    listvalue = [ None ]\n            else:\n                listvalue = [ value ]\n\n            type.__setattr__(GsyncListOptions, name, listvalue)\n\n    # Cleanup this module to prevent tinkering.\n    import sys\n    module = sys.modules[__name__]\n    del module.__dict__['GetGsyncOptionsType']\n\n    return GsyncOptionsType\n\n# Our singlton abstract proxy class.\nclass GsyncOptions(object):\n    __metaclass__ = GetGsyncOptionsType()\n\nShare\nImprove this answer\nFollow\nedited Jan 25 '16 at 20:08\ncommunity wiki\n\n\n3 revs, 2 users 99%\nCraig","comments":[]},{"answer":"The tl;dr version\n\nThe type(obj) function gets you the type of an object.\n\nThe type() of a class is its metaclass.\n\nTo use a metaclass:\n\nclass Foo(object):\n    __metaclass__ = MyMetaClass\n\n\ntype is its own metaclass. The class of a class is a metaclass-- the body of a class is the arguments passed to the metaclass that is used to construct the class.\n\nHere you can read about how to use metaclasses to customize class construction.\n\nShare\nImprove this answer\nFollow\nedited Dec 5 '19 at 16:27\nanswered Dec 27 '16 at 2:21\nnoɥʇʎԀʎzɐɹƆ\n6,9532\n2 gold badges\n40\n40 silver badges\n64\n64 bronze badges","comments":[]},{"answer":"type is actually a metaclass -- a class that creates another classes. Most metaclass are the subclasses of type. The metaclass receives the new class as its first argument and provide access to class object with details as mentioned below:\n\n>>> class MetaClass(type):\n...     def __init__(cls, name, bases, attrs):\n...         print ('class name: %s' %name )\n...         print ('Defining class %s' %cls)\n...         print('Bases %s: ' %bases)\n...         print('Attributes')\n...         for (name, value) in attrs.items():\n...             print ('%s :%r' %(name, value))\n... \n\n>>> class NewClass(object, metaclass=MetaClass):\n...    get_choch='dairy'\n... \nclass name: NewClass\nBases <class 'object'>: \nDefining class <class 'NewClass'>\nget_choch :'dairy'\n__module__ :'builtins'\n__qualname__ :'NewClass'\n\n\nNote:\n\nNotice that the class was not instantiated at any time; the simple act of creating the class triggered execution of the metaclass.\n\nShare\nImprove this answer\nFollow\nedited Aug 29 '17 at 5:23\nChankey Pathak\n19.5k10\n10 gold badges\n74\n74 silver badges\n120\n120 bronze badges\nanswered Aug 9 '16 at 18:49\nMushahid Khan\n2,6791\n1 gold badge\n17\n17 silver badges\n30\n30 bronze badges","comments":[]},{"answer":"Python classes are themselves objects - as in instance - of their meta-class.\n\nThe default metaclass, which is applied when when you determine classes as:\n\nclass foo:\n    ...\n\n\nmeta class are used to apply some rule to an entire set of classes. For example, suppose you're building an ORM to access a database, and you want records from each table to be of a class mapped to that table (based on fields, business rules, etc..,), a possible use of metaclass is for instance, connection pool logic, which is share by all classes of record from all tables. Another use is logic to to support foreign keys, which involves multiple classes of records.\n\nwhen you define metaclass, you subclass type, and can overrided the following magic methods to insert your logic.\n\nclass somemeta(type):\n    __new__(mcs, name, bases, clsdict):\n      \"\"\"\n  mcs: is the base metaclass, in this case type.\n  name: name of the new class, as provided by the user.\n  bases: tuple of base classes \n  clsdict: a dictionary containing all methods and attributes defined on class\n\n  you must return a class object by invoking the __new__ constructor on the base metaclass. \n ie: \n    return type.__call__(mcs, name, bases, clsdict).\n\n  in the following case:\n\n  class foo(baseclass):\n        __metaclass__ = somemeta\n\n  an_attr = 12\n\n  def bar(self):\n      ...\n\n  @classmethod\n  def foo(cls):\n      ...\n\n      arguments would be : ( somemeta, \"foo\", (baseclass, baseofbase,..., object), {\"an_attr\":12, \"bar\": <function>, \"foo\": <bound class method>}\n\n      you can modify any of these values before passing on to type\n      \"\"\"\n      return type.__call__(mcs, name, bases, clsdict)\n\n\n    def __init__(self, name, bases, clsdict):\n      \"\"\" \n      called after type has been created. unlike in standard classes, __init__ method cannot modify the instance (cls) - and should be used for class validaton.\n      \"\"\"\n      pass\n\n\n    def __prepare__():\n        \"\"\"\n        returns a dict or something that can be used as a namespace.\n        the type will then attach methods and attributes from class definition to it.\n\n        call order :\n\n        somemeta.__new__ ->  type.__new__ -> type.__init__ -> somemeta.__init__ \n        \"\"\"\n        return dict()\n\n    def mymethod(cls):\n        \"\"\" works like a classmethod, but for class objects. Also, my method will not be visible to instances of cls.\n        \"\"\"\n        pass\n\n\nanyhow, those two are the most commonly used hooks. metaclassing is powerful, and above is nowhere near and exhaustive list of uses for metaclassing.\n\nShare\nImprove this answer\nFollow\nedited Jul 13 '17 at 8:18\nanswered Jul 13 '17 at 7:58\nXingzhou Liu\n1,2856\n6 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"The type() function can return the type of an object or create a new type,\n\nfor example, we can create a Hi class with the type() function and do not need to use this way with class Hi(object):\n\ndef func(self, name='mike'):\n    print('Hi, %s.' % name)\n\nHi = type('Hi', (object,), dict(hi=func))\nh = Hi()\nh.hi()\nHi, mike.\n\ntype(Hi)\ntype\n\ntype(h)\n__main__.Hi\n\n\nIn addition to using type() to create classes dynamically, you can control creation behavior of class and use metaclass.\n\nAccording to the Python object model, the class is the object, so the class must be an instance of another certain class. By default, a Python class is instance of the type class. That is, type is metaclass of most of the built-in classes and metaclass of user-defined classes.\n\nclass ListMetaclass(type):\n    def __new__(cls, name, bases, attrs):\n        attrs['add'] = lambda self, value: self.append(value)\n        return type.__new__(cls, name, bases, attrs)\n\nclass CustomList(list, metaclass=ListMetaclass):\n    pass\n\nlst = CustomList()\nlst.add('custom_list_1')\nlst.add('custom_list_2')\n\nlst\n['custom_list_1', 'custom_list_2']\n\n\nMagic will take effect when we passed keyword arguments in metaclass, it indicates the Python interpreter to create the CustomList through ListMetaclass. new (), at this point, we can modify the class definition, for example, and add a new method and then return the revised definition.\n\nShare\nImprove this answer\nFollow\nedited Jan 12 '18 at 9:30\nanswered Jan 12 '18 at 9:16\nbinbjz\n5816\n6 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"In addition to the published answers I can say that a metaclass defines the behaviour for a class. So, you can explicitly set your metaclass. Whenever Python gets a keyword class then it starts searching for the metaclass. If it's not found – the default metaclass type is used to create the class's object. Using the __metaclass__ attribute, you can set metaclass of your class:\n\nclass MyClass:\n   __metaclass__ = type\n   # write here other method\n   # write here one more method\n\nprint(MyClass.__metaclass__)\n\n\nIt'll produce the output like this:\n\nclass 'type'\n\n\nAnd, of course, you can create your own metaclass to define the behaviour of any class that are created using your class.\n\nFor doing that, your default metaclass type class must be inherited as this is the main metaclass:\n\nclass MyMetaClass(type):\n   __metaclass__ = type\n   # you can write here any behaviour you want\n\nclass MyTestClass:\n   __metaclass__ = MyMetaClass\n\nObj = MyTestClass()\nprint(Obj.__metaclass__)\nprint(MyMetaClass.__metaclass__)\n\n\nThe output will be:\n\nclass '__main__.MyMetaClass'\nclass 'type'\n\nShare\nImprove this answer\nFollow\nedited Sep 15 '18 at 13:17\nanswered Sep 15 '18 at 12:41\nAndy Fedoroff\n29.2k10\n10 gold badges\n94\n94 silver badges\n146\n146 bronze badges","comments":[]},{"answer":"Note that in python 3.6 a new dunder method __init_subclass__(cls, **kwargs) was introduced to replace a lot of common use cases for metaclasses. Is is called when a subclass of the defining class is created. See python docs.\n\nShare\nImprove this answer\nFollow\nanswered Mar 3 '20 at 10:06\nLars\n1,3802\n2 gold badges\n10\n10 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"In object-oriented programming, a metaclass is a class whose instances are classes. Just as an ordinary class defines the behavior of certain objects, a metaclass defines the behavior of certain class and their instances The term metaclass simply means something used to create classes. In other words, it is the class of a class. The metaclass is used to create the class so like the object being an instance of a class, a class is an instance of a metaclass. In python classes are also considered objects.\n\nShare\nImprove this answer\nFollow\nedited Jul 9 '19 at 5:45\nanswered Jul 9 '19 at 5:37\nVenu Gopal Tewari\n4,66836\n36 silver badges\n38\n38 bronze badges","comments":["Rather than giving bookish definitions, would have been better if you had added some examples. The first line of your answer seems to have been copied from the Wikipedia entry of Metaclasses.","@verisimilitude I am also learning can you help me improving this answer by providing some practical examples from your experience ??"]},{"answer":"Here's another example of what it can be used for:\n\nYou can use the metaclass to change the function of its instance (the class).\nclass MetaMemberControl(type):\n    __slots__ = ()\n\n    @classmethod\n    def __prepare__(mcs, f_cls_name, f_cls_parents,  # f_cls means: future class\n                    meta_args=None, meta_options=None):  # meta_args and meta_options is not necessarily needed, just so you know.\n        f_cls_attr = dict()\n        if not \"do something or if you want to define your cool stuff of dict...\":\n            return dict(make_your_special_dict=None)\n        else:\n            return f_cls_attr\n\n    def __new__(mcs, f_cls_name, f_cls_parents, f_cls_attr,\n                meta_args=None, meta_options=None):\n\n        original_getattr = f_cls_attr.get('__getattribute__')\n        original_setattr = f_cls_attr.get('__setattr__')\n\n        def init_getattr(self, item):\n            if not item.startswith('_'):  # you can set break points at here\n                alias_name = '_' + item\n                if alias_name in f_cls_attr['__slots__']:\n                    item = alias_name\n            if original_getattr is not None:\n                return original_getattr(self, item)\n            else:\n                return super(eval(f_cls_name), self).__getattribute__(item)\n\n        def init_setattr(self, key, value):\n            if not key.startswith('_') and ('_' + key) in f_cls_attr['__slots__']:\n                raise AttributeError(f\"you can't modify private members:_{key}\")\n            if original_setattr is not None:\n                original_setattr(self, key, value)\n            else:\n                super(eval(f_cls_name), self).__setattr__(key, value)\n\n        f_cls_attr['__getattribute__'] = init_getattr\n        f_cls_attr['__setattr__'] = init_setattr\n\n        cls = super().__new__(mcs, f_cls_name, f_cls_parents, f_cls_attr)\n        return cls\n\n\nclass Human(metaclass=MetaMemberControl):\n    __slots__ = ('_age', '_name')\n\n    def __init__(self, name, age):\n        self._name = name\n        self._age = age\n\n    def __getattribute__(self, item):\n        \"\"\"\n        is just for IDE recognize.\n        \"\"\"\n        return super().__getattribute__(item)\n\n    \"\"\" with MetaMemberControl then you don't have to write as following\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def age(self):\n        return self._age\n    \"\"\"\n\n\ndef test_demo():\n    human = Human('Carson', 27)\n    # human.age = 18  # you can't modify private members:_age  <-- this is defined by yourself.\n    # human.k = 18  # 'Human' object has no attribute 'k'  <-- system error.\n    age1 = human._age  # It's OK, although the IDE will show some warnings. (Access to a protected member _age of a class)\n\n    age2 = human.age  # It's OK! see below:\n    \"\"\"\n    if you do not define `__getattribute__` at the class of Human,\n    the IDE will show you: Unresolved attribute reference 'age' for class 'Human'\n    but it's ok on running since the MetaMemberControl will help you.\n    \"\"\"\n\n\nif __name__ == '__main__':\n    test_demo()\n\n\n\nThe metaclass is powerful, there are many things (such as monkey magic) you can do with it, but be careful this may only be known to you.\n\nShare\nImprove this answer\nFollow\nanswered Dec 20 '19 at 11:03\nCarson\n2,1031\n1 gold badge\n13\n13 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"A class, in Python, is an object, and just like any other object, it is an instance of \"something\". This \"something\" is what is termed as a Metaclass. This metaclass is a special type of class that creates other class's objects. Hence, metaclass is responsible for making new classes. This allows the programmer to customize the way classes are generated.\n\nTo create a metaclass, overriding of new() and init() methods is usually done. new() can be overridden to change the way objects are created, while init() can be overridden to change the way of initializing the object. Metaclass can be created by a number of ways. One of the ways is to use type() function. type() function, when called with 3 parameters, creates a metaclass. The parameters are :-\n\nClass Name\nTuple having base classes inherited by class\nA dictionary having all class methods and class variables\n\nAnother way of creating a metaclass comprises of 'metaclass' keyword. Define the metaclass as a simple class. In the parameters of inherited class, pass metaclass=metaclass_name\n\nMetaclass can be specifically used in the following situations :-\n\nwhen a particular effect has to be applied to all the subclasses\nAutomatic change of class (on creation) is required\nBy API developers\nShare\nImprove this answer\nFollow\nanswered Jan 20 '20 at 6:59\nSwati Srivastava\n8531\n1 gold badge\n9\n9 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"In Python, a metaclass is a subclass of a subclass that determines how a subclass behaves. A class is an instance of another metaclass. In Python, a class specifies how the class's instance will behave.\n\nSince metaclasses are in charge of class generation, you can write your own custom metaclasses to change how classes are created by performing additional actions or injecting code. Custom metaclasses aren't always important, but they can be.\n\nShare\nImprove this answer\nFollow\nanswered Apr 21 at 18:41\nDrosnickX\n1398\n8 bronze badges","comments":[]},{"answer":"I saw an interesting use case for metaclasses in a package called classutilities. It checks if all class variables are in upper case format (it is convenient to have unified logic for configuration classes), and checks if there are no instance level methods in class. Another interesting example for metaclases was deactivation of unittests based on complex conditions (checking values of multiple environmental variables).\n\nShare\nImprove this answer\nFollow\nedited Jul 12 at 22:53\nArthur MacMillan\n257\n7 bronze badges\nanswered Jul 12 at 22:51\nEmma Brown\n757\n7 bronze badges","comments":[]},{"answer":"Metaclasses are nothing but a simple inner class of your model class for example: In Django or python\n\nclass Author(models.Model):\n    name = models.CharField(max_length=50)\n    email = models.EmailField()\n\n    class Meta:\n        abstract = True\n\n\nHere, If abstract = True, this model will be an abstract base class. Metaclass will change the behaviour of your base class.\n\nShare\nImprove this answer\nFollow\nanswered Jul 17 at 5:18\nManukumar\n252\n2 bronze badges","comments":[]},{"answer":"Metaclass is a kind of class which defines how the class will behave like or we can say that A class is itself an instance of a metaclass.\n\nShare\nImprove this answer\nFollow\nanswered Mar 29 '20 at 9:25\nTechnical A.D.\n15\n5 bronze badges","comments":["Please add relevant information ..your comments are confusing"]}]},{"id":"82831","href":"https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists-without-exceptions","title":"How do I check whether a file exists without exceptions?","description":"\n                \nHow do I check whether a file exists or not, without using the try statement?\n    ","questionComments":["To check whether a Path object exists independently of whether is it a file or directory, use my_path.exists()."],"answers":[{"answer":"If the reason you're checking is so you can do something like if file_exists: open_it(), it's safer to use a try around the attempt to open it. Checking and then opening risks the file being deleted or moved or something between when you check and when you try to open it.\n\nIf you're not planning to open the file immediately, you can use os.path.isfile\n\nReturn True if path is an existing regular file. This follows symbolic links, so both islink() and isfile() can be true for the same path.\n\nimport os.path\nos.path.isfile(fname) \n\n\nif you need to be sure it's a file.\n\nStarting with Python 3.4, the pathlib module offers an object-oriented approach (backported to pathlib2 in Python 2.7):\n\nfrom pathlib import Path\n\nmy_file = Path(\"/path/to/file\")\nif my_file.is_file():\n    # file exists\n\n\nTo check a directory, do:\n\nif my_file.is_dir():\n    # directory exists\n\n\nTo check whether a Path object exists independently of whether is it a file or directory, use exists():\n\nif my_file.exists():\n    # path exists\n\n\nYou can also use resolve(strict=True) in a try block:\n\ntry:\n    my_abs_path = my_file.resolve(strict=True)\nexcept FileNotFoundError:\n    # doesn't exist\nelse:\n    # exists\n\nShare\nImprove this answer\nFollow\nedited May 13 '19 at 10:40\nGeorgy\n6,8417\n7 gold badges\n49\n49 silver badges\n59\n59 bronze badges\nanswered Sep 17 '08 at 12:57\nrslite\n74.6k4\n4 gold badges\n40\n40 silver badges\n46\n46 bronze badges","comments":["concerning the first remark (use \"try\" if check before open) unfortunately this will not work if you want to open for appending being sure it exists before since 'a' mode will create if not exists.","Note that FileNotFoundError was introduced in Python 3. If you also need to support Python 2.7 as well as Python 3, you can use IOError instead (which FileNotFoundError subclasses) stackoverflow.com/a/21368457/1960959","@makapuf You can open it for \"updating\" (open('file', 'r+')) and then seek to the end.","Wait, so pathlib2 < pathlib? pathlib is for python3, right? I've been using pathlib2 thinking it was superior.","@kyrill: Opening a file for appending is not the same as opening it for writing and seeking to the end: When you have concurrent writers, they will overwrite each other without 'a'."]},{"answer":"You have the os.path.exists function:\n\nimport os.path\nos.path.exists(file_path)\n\n\nThis returns True for both files and directories but you can instead use\n\nos.path.isfile(file_path)\n\n\nto test if it's a file specifically. It follows symlinks.\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '18 at 8:58\nCommunity♦\n11\n1 silver badge\nanswered Sep 17 '08 at 12:57\nPierreBdR\n38.7k9\n9 gold badges\n41\n41 silver badges\n60\n60 bronze badges","comments":[]},{"answer":"Unlike isfile(), exists() will return True for directories. So depending on if you want only plain files or also directories, you'll use isfile() or exists(). Here is some simple REPL output:\n\n>>> os.path.isfile(\"/etc/password.txt\")\nTrue\n>>> os.path.isfile(\"/etc\")\nFalse\n>>> os.path.isfile(\"/does/not/exist\")\nFalse\n>>> os.path.exists(\"/etc/password.txt\")\nTrue\n>>> os.path.exists(\"/etc\")\nTrue\n>>> os.path.exists(\"/does/not/exist\")\nFalse\n\nShare\nImprove this answer\nFollow\nedited Mar 3 '20 at 17:45\nBoris\n7,6557\n7 gold badges\n66\n66 silver badges\n67\n67 bronze badges\nanswered Sep 17 '08 at 15:01\nbortzmeyer\n31.1k10\n10 gold badges\n61\n61 silver badges\n89\n89 bronze badges","comments":[]},{"answer":"import os.path\n\nif os.path.isfile(filepath):\n   print(\"File exists\")\n\nShare\nImprove this answer\nFollow\nedited Dec 29 '20 at 5:11\nMohammed H\n6,38613\n13 gold badges\n72\n72 silver badges\n120\n120 bronze badges\nanswered Sep 17 '08 at 12:55\nPaul\n16.8k7\n7 gold badges\n47\n47 silver badges\n56\n56 bronze badges","comments":[]},{"answer":"Use os.path.isfile() with os.access():\n\nimport os\n\nPATH = './file.txt'\nif os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n    print(\"File exists and is readable\")\nelse:\n    print(\"Either the file is missing or not readable\")\n\nShare\nImprove this answer\nFollow\nedited Mar 26 '20 at 11:35\nnull\n1,41310\n10 silver badges\n18\n18 bronze badges\nanswered Jan 16 '12 at 5:57\nYugal Jindle\n40k40\n40 gold badges\n122\n122 silver badges\n191\n191 bronze badges","comments":["having multiple conditions, some of which are superfluous, is less clear and explicit.","It is also redundant. If the file doesn't exist, os.access() will return false.","@EJP In linux files can exist but not accesible.","since you import os, you do not need to import os.path again as it is already part of os. You just need to import os.path if you are only going to use functions from os.path and not from os itself, to import a smaller thing, but as you use os.access and os.R_OK, the second import is not needed.","Checking if the user has access rights to read the file is very professional. Often data is on local drive during dev, and on network share in prod. Then this might lead to such a situation. Also, the code is perfectly clear and readable and explicit."]},{"answer":"import os\nos.path.exists(path) # Returns whether the path (directory or file) exists or not\nos.path.isfile(path) # Returns whether the file exists or not\n\nShare\nImprove this answer\nFollow\nedited Jun 2 '18 at 20:52\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 17 '08 at 12:56\nbenefactual\n6,7515\n5 gold badges\n21\n21 silver badges\n16\n16 bronze badges","comments":["Generally, not good practise to name variables the same as method names."]},{"answer":"Although almost every possible way has been listed in (at least one of) the existing answers (e.g. Python 3.4 specific stuff was added), I'll try to group everything together.\n\nNote: every piece of Python standard library code that I'm going to post, belongs to version 3.5.3.\n\nProblem statement:\n\nCheck file (arguable: also folder (\"special\" file) ?) existence\nDon't use try / except / else / finally blocks\n\nPossible solutions:\n\n[Python 3]: os.path.exists(path) (also check other function family members like os.path.isfile, os.path.isdir, os.path.lexists for slightly different behaviors)\n\nos.path.exists(path)\n\n\nReturn True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic links. On some platforms, this function may return False if permission is not granted to execute os.stat() on the requested file, even if the path physically exists.\n\nAll good, but if following the import tree:\n\nos.path - posixpath.py (ntpath.py)\n\ngenericpath.py, line ~#20+\n\ndef exists(path):\n    \"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\n    try:\n        st = os.stat(path)\n    except os.error:\n        return False\n    return True\n\n\nit's just a try / except block around [Python 3]: os.stat(path, *, dir_fd=None, follow_symlinks=True). So, your code is try / except free, but lower in the framestack there's (at least) one such block. This also applies to other funcs (including os.path.isfile).\n\n1.1. [Python 3]: Path.is_file()\n\nIt's a fancier (and more pythonic) way of handling paths, but\n\nUnder the hood, it does exactly the same thing (pathlib.py, line ~#1330):\n\ndef is_file(self):\n    \"\"\"\n    Whether this path is a regular file (also True for symlinks pointing\n    to regular files).\n    \"\"\"\n    try:\n        return S_ISREG(self.stat().st_mode)\n    except OSError as e:\n        if e.errno not in (ENOENT, ENOTDIR):\n            raise\n        # Path doesn't exist or is a broken symlink\n        # (see https://bitbucket.org/pitrou/pathlib/issue/12/)\n        return False\n\n\n[Python 3]: With Statement Context Managers. Either:\n\nCreate one:\n\nclass Swallow:  # Dummy example\n    swallowed_exceptions = (FileNotFoundError,)\n\n    def __enter__(self):\n        print(\"Entering...\")\n\n    def __exit__(self, exc_type, exc_value, exc_traceback):\n        print(\"Exiting:\", exc_type, exc_value, exc_traceback)\n        return exc_type in Swallow.swallowed_exceptions  # only swallow FileNotFoundError (not e.g. TypeError - if the user passes a wrong argument like None or float or ...)\n\n\nAnd its usage - I'll replicate the os.path.isfile behavior (note that this is just for demonstrating purposes, do not attempt to write such code for production):\n\nimport os\nimport stat\n\n\ndef isfile_seaman(path):  # Dummy func\n    result = False\n    with Swallow():\n        result = stat.S_ISREG(os.stat(path).st_mode)\n    return result\n\n\nUse [Python 3]: contextlib.suppress(*exceptions) - which was specifically designed for selectively suppressing exceptions\n\n\nBut, they seem to be wrappers over try / except / else / finally blocks, as [Python 3]: The with statement states:\n\nThis allows common try...except...finally usage patterns to be encapsulated for convenient reuse.\n\nFilesystem traversal functions (and search the results for matching item(s))\n\n[Python 3]: os.listdir(path='.') (or [Python 3]: os.scandir(path='.') on Python v3.5+, backport: [PyPI]: scandir)\n\nUnder the hood, both use:\n\nNix: [man7]: OPENDIR(3) / [man7]: READDIR(3) / [man7]: CLOSEDIR(3)\nWin: [MS.Docs]: FindFirstFileW function / [MS.Docs]: FindNextFileW function / [MS.Docs]: FindClose function\n\nvia [GitHub]: python/cpython - (master) cpython/Modules/posixmodule.c\n\nUsing scandir() instead of listdir() can significantly increase the performance of code that also needs file type or file attribute information, because os.DirEntry objects expose this information if the operating system provides it when scanning a directory. All os.DirEntry methods may perform a system call, but is_dir() and is_file() usually only require a system call for symbolic links; os.DirEntry.stat() always requires a system call on Unix but only requires one for symbolic links on Windows.\n\n[Python 3]: os.walk(top, topdown=True, onerror=None, followlinks=False)\nIt uses os.listdir (os.scandir when available)\n[Python 3]: glob.iglob(pathname, *, recursive=False) (or its predecessor: glob.glob)\nDoesn't seem a traversing function per se (at least in some cases), but it still uses os.listdir\n\n\nSince these iterate over folders, (in most of the cases) they are inefficient for our problem (there are exceptions, like non wildcarded globbing - as @ShadowRanger pointed out), so I'm not going to insist on them. Not to mention that in some cases, filename processing might be required.\n\n[Python 3]: os.access(path, mode, *, dir_fd=None, effective_ids=False, follow_symlinks=True) whose behavior is close to os.path.exists (actually it's wider, mainly because of the 2nd argument)\n\nuser permissions might restrict the file \"visibility\" as the doc states:\n\n...test if the invoking user has the specified access to path. mode should be F_OK to test the existence of path...\n\nos.access(\"/tmp\", os.F_OK)\n\nSince I also work in C, I use this method as well because under the hood, it calls native APIs (again, via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants. So, as @AaronHall rightly pointed out, don't use it unless you know what you're doing:\n\nNix: [man7]: ACCESS(2) (!!! pay attention to the note about the security hole its usage might introduce !!!)\nWin: [MS.Docs]: GetFileAttributesW function\n\nNote: calling native APIs is also possible via [Python 3]: ctypes - A foreign function library for Python, but in most cases it's more complicated.\n\n(Win specific): Since vcruntime* (msvcr*) .dll exports a [MS.Docs]: _access, _waccess function family as well, here's an example:\n\nPython 3.5.3 (v3.5.3:1880cb95a742, Jan 16 2017, 16:02:32) [MSC v.1900 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import os, ctypes\n>>> ctypes.CDLL(\"msvcrt\")._waccess(u\"C:\\\\Windows\\\\System32\\\\cmd.exe\", os.F_OK)\n0\n>>> ctypes.CDLL(\"msvcrt\")._waccess(u\"C:\\\\Windows\\\\System32\\\\cmd.exe.notexist\", os.F_OK)\n-1\n\n\nNotes:\n\nAlthough it's not a good practice, I'm using os.F_OK in the call, but that's just for clarity (its value is 0)\nI'm using _waccess so that the same code works on Python3 and Python2 (in spite of unicode related differences between them)\nAlthough this targets a very specific area, it was not mentioned in any of the previous answers\n\n\nThe Lnx (Ubtu (16 x64)) counterpart as well:\n\nPython 3.5.2 (default, Nov 17 2016, 17:05:23)\n[GCC 5.4.0 20160609] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import os, ctypes\n>>> ctypes.CDLL(\"/lib/x86_64-linux-gnu/libc.so.6\").access(b\"/tmp\", os.F_OK)\n0\n>>> ctypes.CDLL(\"/lib/x86_64-linux-gnu/libc.so.6\").access(b\"/tmp.notexist\", os.F_OK)\n-1\n\n\nNotes:\n\nInstead hardcoding libc's path (\"/lib/x86_64-linux-gnu/libc.so.6\") which may (and most likely, will) vary across systems, None (or the empty string) can be passed to CDLL constructor (ctypes.CDLL(None).access(b\"/tmp\", os.F_OK)). According to [man7]: DLOPEN(3):\n\nIf filename is NULL, then the returned handle is for the main program. When given to dlsym(), this handle causes a search for a symbol in the main program, followed by all shared objects loaded at program startup, and then all shared objects loaded by dlopen() with the flag RTLD_GLOBAL.\n\nMain (current) program (python) is linked against libc, so its symbols (including access) will be loaded\nThis has to be handled with care, since functions like main, Py_Main and (all the) others are available; calling them could have disastrous effects (on the current program)\nThis doesn't also apply to Win (but that's not such a big deal, since msvcrt.dll is located in \"%SystemRoot%\\System32\" which is in %PATH% by default). I wanted to take things further and replicate this behavior on Win (and submit a patch), but as it turns out, [MS.Docs]: GetProcAddress function only \"sees\" exported symbols, so unless someone declares the functions in the main executable as __declspec(dllexport) (why on Earth the regular person would do that?), the main program is loadable but pretty much unusable\n\nInstall some third-party module with filesystem capabilities\n\nMost likely, will rely on one of the ways above (maybe with slight customizations).\nOne example would be (again, Win specific) [GitHub]: mhammond/pywin32 - Python for Windows (pywin32) Extensions, which is a Python wrapper over WINAPIs.\n\nBut, since this is more like a workaround, I'm stopping here.\n\nAnother (lame) workaround (gainarie) is (as I like to call it,) the sysadmin approach: use Python as a wrapper to execute shell commands\n\nWin:\n\n(py35x64_test) e:\\Work\\Dev\\StackOverflow\\q000082831>\"e:\\Work\\Dev\\VEnvs\\py35x64_test\\Scripts\\python.exe\" -c \"import os; print(os.system('dir /b \\\"C:\\\\Windows\\\\System32\\\\cmd.exe\\\" > nul 2>&1'))\"\n0\n\n(py35x64_test) e:\\Work\\Dev\\StackOverflow\\q000082831>\"e:\\Work\\Dev\\VEnvs\\py35x64_test\\Scripts\\python.exe\" -c \"import os; print(os.system('dir /b \\\"C:\\\\Windows\\\\System32\\\\cmd.exe.notexist\\\" > nul 2>&1'))\"\n1\n\n\nNix (Lnx (Ubtu)):\n\n[cfati@cfati-ubtu16x64-0:~]> python3 -c \"import os; print(os.system('ls \\\"/tmp\\\" > /dev/null 2>&1'))\"\n0\n[cfati@cfati-ubtu16x64-0:~]> python3 -c \"import os; print(os.system('ls \\\"/tmp.notexist\\\" > /dev/null 2>&1'))\"\n512\n\n\nBottom line:\n\nDo use try / except / else / finally blocks, because they can prevent you running into a series of nasty problems. A counter-example that I can think of, is performance: such blocks are costly, so try not to place them in code that it's supposed to run hundreds of thousands times per second (but since (in most cases) it involves disk access, it won't be the case).\n\nFinal note(s):\n\nI will try to keep it up to date, any suggestions are welcome, I will incorporate anything useful that will come up into the answer\nShare\nImprove this answer\nFollow\nedited Feb 8 '19 at 9:36\nanswered Jun 20 '17 at 19:28\nCristiFati\n29.5k9\n9 gold badges\n41\n41 silver badges\n66\n66 bronze badges","comments":["Can you elaborate on this statement? \"Although it's not a good practice, I'm using os.F_OK in the call, but that's just for clarity (its value is 0)\"","@sk8asd123: Kind of hard to doo it in a comment: generally, it's best to use constants with functions that they come together with. That applies when working with multiple modules that define the same constant, because some might not be up to date, and it's best for the functions and constants to be in sync. When working with ctypes (calling the functions directly) I should have defined the constant (from MSDN), or not use a constant at all. It's just a guideline that I use, in 99.9% it probably makes no difference (functionally).","@CristiFati: As of 3.6, glob.iglob (and glob.glob as well) are based on os.scandir, so it's lazy now; to get the first hit in a directory of 10M files, you only scan until you reach the first hit. And even pre-3.6, if you use glob methods w/o any wildcards, the function is smart: It knows you can only have one hit, so it simplifies the globbing to just os.path.isdir or os.path.lexists (depending on whether path ends in /).","That second part of my comment (non-wildcarded globbing doesn't actually iterate the folder, and never has) does mean it's a perfectly efficient solution to the problem (slower than directly calling os.path.isdir or os.path.lexist since it's a bunch of Python level function calls and string operations before it decides the efficient path is viable, but no additional system call or I/O work, which is orders of magnitude slower)."]},{"answer":"Python 3.4+ has an object-oriented path module: pathlib. Using this new module, you can check whether a file exists like this:\n\nimport pathlib\np = pathlib.Path('path/to/file')\nif p.is_file():  # or p.is_dir() to see if it is a directory\n    # do stuff\n\n\nYou can (and usually should) still use a try/except block when opening files:\n\ntry:\n    with p.open() as f:\n        # do awesome stuff\nexcept OSError:\n    print('Well darn.')\n\n\nThe pathlib module has lots of cool stuff in it: convenient globbing, checking file's owner, easier path joining, etc. It's worth checking out. If you're on an older Python (version 2.6 or later), you can still install pathlib with pip:\n\n# installs pathlib2 on older Python versions\n# the original third-party module, pathlib, is no longer maintained.\npip install pathlib2\n\n\nThen import it as follows:\n\n# Older Python versions\nimport pathlib2 as pathlib\n\nShare\nImprove this answer\nFollow\nedited Sep 12 '20 at 4:42\nHonest Abe\n7,5544\n4 gold badges\n46\n46 silver badges\n59\n59 bronze badges\nanswered Feb 8 '14 at 2:38\nCody Piersall\n7,2892\n2 gold badges\n37\n37 silver badges\n52\n52 bronze badges","comments":["You can use pathlib.Path.exists, which covers more cases than is_file"]},{"answer":"This is the simplest way to check if a file exists. Just because the file existed when you checked doesn't guarantee that it will be there when you need to open it.\n\nimport os\nfname = \"foo.txt\"\nif os.path.isfile(fname):\n    print(\"file does exist at this time\")\nelse:\n    print(\"no such file exists at this time\")\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '18 at 4:07\nMrWonderful\n2,23814\n14 silver badges\n22\n22 bronze badges\nanswered Jun 27 '13 at 13:38\nun33k\n15.6k13\n13 gold badges\n59\n59 silver badges\n64\n64 bronze badges","comments":["As long as you intend to access the file, the race condition does exist, regardless of how your program is constructed. Your program cannot guarantee that another process on the computer has not modified the file. It's what Eric Lippert refers to as an exogenous exception. You cannot avoid it by checking for the file's existence beforehand.","@IsaacSupeene Best practice is to make the window of (file) operation as small as possible followed by a proper exception handling"]},{"answer":"Prefer the try statement. It's considered better style and avoids race conditions.\n\nDon't take my word for it. There's plenty of support for this theory. Here's a couple:\n\nStyle: Section \"Handling unusual conditions\" of http://allendowney.com/sd/notes/notes11.txt\nAvoiding Race Conditions\nShare\nImprove this answer\nFollow\nedited Apr 28 '14 at 1:01\nHonest Abe\n7,5544\n4 gold badges\n46\n46 silver badges\n59\n59 bronze badges\nanswered Nov 4 '09 at 0:48\npkoch\n2,5291\n1 gold badge\n17\n17 silver badges\n16\n16 bronze badges","comments":["Please add better sources to support your statement.","The cited Avoiding Race Conditions (apple dev support) link does not support your answer. It concerns only using temporary files that contain sensitive information on poorly designed operating systems that don't properly sandbox temporary files / directories via restricted permissions. Using try...except doesn't help resolve that problem anyway.","The problem with this method, is that if you have an important piece of code depending on the file not existing, putting it in the except: clause will make that an exception arising in this part of your code will raise a confusing message (second error raised during the processing of the first one.)"]},{"answer":"How do I check whether a file exists, using Python, without using a try statement?\n\nNow available since Python 3.4, import and instantiate a Path object with the file name, and check the is_file method (note that this returns True for symlinks pointing to regular files as well):\n\n>>> from pathlib import Path\n>>> Path('/').is_file()\nFalse\n>>> Path('/initrd.img').is_file()\nTrue\n>>> Path('/doesnotexist').is_file()\nFalse\n\n\nIf you're on Python 2, you can backport the pathlib module from pypi, pathlib2, or otherwise check isfile from the os.path module:\n\n>>> import os\n>>> os.path.isfile('/')\nFalse\n>>> os.path.isfile('/initrd.img')\nTrue\n>>> os.path.isfile('/doesnotexist')\nFalse\n\n\nNow the above is probably the best pragmatic direct answer here, but there's the possibility of a race condition (depending on what you're trying to accomplish), and the fact that the underlying implementation uses a try, but Python uses try everywhere in its implementation.\n\nBecause Python uses try everywhere, there's really no reason to avoid an implementation that uses it.\n\nBut the rest of this answer attempts to consider these caveats.\n\nLonger, much more pedantic answer\n\nAvailable since Python 3.4, use the new Path object in pathlib. Note that .exists is not quite right, because directories are not files (except in the unix sense that everything is a file).\n\n>>> from pathlib import Path\n>>> root = Path('/')\n>>> root.exists()\nTrue\n\n\nSo we need to use is_file:\n\n>>> root.is_file()\nFalse\n\n\nHere's the help on is_file:\n\nis_file(self)\n    Whether this path is a regular file (also True for symlinks pointing\n    to regular files).\n\n\nSo let's get a file that we know is a file:\n\n>>> import tempfile\n>>> file = tempfile.NamedTemporaryFile()\n>>> filepathobj = Path(file.name)\n>>> filepathobj.is_file()\nTrue\n>>> filepathobj.exists()\nTrue\n\n\nBy default, NamedTemporaryFile deletes the file when closed (and will automatically close when no more references exist to it).\n\n>>> del file\n>>> filepathobj.exists()\nFalse\n>>> filepathobj.is_file()\nFalse\n\n\nIf you dig into the implementation, though, you'll see that is_file uses try:\n\ndef is_file(self):\n    \"\"\"\n    Whether this path is a regular file (also True for symlinks pointing\n    to regular files).\n    \"\"\"\n    try:\n        return S_ISREG(self.stat().st_mode)\n    except OSError as e:\n        if e.errno not in (ENOENT, ENOTDIR):\n            raise\n        # Path doesn't exist or is a broken symlink\n        # (see https://bitbucket.org/pitrou/pathlib/issue/12/)\n        return False\n\nRace Conditions: Why we like try\n\nWe like try because it avoids race conditions. With try, you simply attempt to read your file, expecting it to be there, and if not, you catch the exception and perform whatever fallback behavior makes sense.\n\nIf you want to check that a file exists before you attempt to read it, and you might be deleting it and then you might be using multiple threads or processes, or another program knows about that file and could delete it - you risk the chance of a race condition if you check it exists, because you are then racing to open it before its condition (its existence) changes.\n\nRace conditions are very hard to debug because there's a very small window in which they can cause your program to fail.\n\nBut if this is your motivation, you can get the value of a try statement by using the suppress context manager.\n\nAvoiding race conditions without a try statement: suppress\n\nPython 3.4 gives us the suppress context manager (previously the ignore context manager), which does semantically exactly the same thing in fewer lines, while also (at least superficially) meeting the original ask to avoid a try statement:\n\nfrom contextlib import suppress\nfrom pathlib import Path\n\n\nUsage:\n\n>>> with suppress(OSError), Path('doesnotexist').open() as f:\n...     for line in f:\n...         print(line)\n... \n>>>\n>>> with suppress(OSError):\n...     Path('doesnotexist').unlink()\n... \n>>> \n\n\nFor earlier Pythons, you could roll your own suppress, but without a try will be more verbose than with. I do believe this actually is the only answer that doesn't use try at any level in the Python that can be applied to prior to Python 3.4 because it uses a context manager instead:\n\nclass suppress(object):\n    def __init__(self, *exceptions):\n        self.exceptions = exceptions\n    def __enter__(self):\n        return self\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_type is not None:\n            return issubclass(exc_type, self.exceptions)\n\n\nPerhaps easier with a try:\n\nfrom contextlib import contextmanager\n\n@contextmanager\ndef suppress(*exceptions):\n    try:\n        yield\n    except exceptions:\n        pass\n\nOther options that don't meet the ask for \"without try\":\n\nisfile\n\nimport os\nos.path.isfile(path)\n\n\nfrom the docs:\n\nos.path.isfile(path)\n\nReturn True if path is an existing regular file. This follows symbolic links, so both islink() and isfile() can be true for the same path.\n\nBut if you examine the source of this function, you'll see it actually does use a try statement:\n\n# This follows symbolic links, so both islink() and isdir() can be true\n# for the same path on systems that support symlinks\ndef isfile(path):\n    \"\"\"Test whether a path is a regular file\"\"\"\n    try:\n        st = os.stat(path)\n    except os.error:\n        return False\n    return stat.S_ISREG(st.st_mode)\n\n>>> OSError is os.error\nTrue\n\n\nAll it's doing is using the given path to see if it can get stats on it, catching OSError and then checking if it's a file if it didn't raise the exception.\n\nIf you intend to do something with the file, I would suggest directly attempting it with a try-except to avoid a race condition:\n\ntry:\n    with open(path) as f:\n        f.read()\nexcept OSError:\n    pass\n\n\nos.access\n\nAvailable for Unix and Windows is os.access, but to use you must pass flags, and it does not differentiate between files and directories. This is more used to test if the real invoking user has access in an elevated privilege environment:\n\nimport os\nos.access(path, os.F_OK)\n\n\nIt also suffers from the same race condition problems as isfile. From the docs:\n\nNote: Using access() to check if a user is authorized to e.g. open a file before actually doing so using open() creates a security hole, because the user might exploit the short time interval between checking and opening the file to manipulate it. It’s preferable to use EAFP techniques. For example:\n\nif os.access(\"myfile\", os.R_OK):\n    with open(\"myfile\") as fp:\n        return fp.read()\nreturn \"some default data\"\n\n\nis better written as:\n\ntry:\n    fp = open(\"myfile\")\nexcept IOError as e:\n    if e.errno == errno.EACCES:\n        return \"some default data\"\n    # Not a permission error.\n    raise\nelse:\n    with fp:\n        return fp.read()\n\n\nAvoid using os.access. It is a low level function that has more opportunities for user error than the higher level objects and functions discussed above.\n\nCriticism of another answer:\n\nAnother answer says this about os.access:\n\nPersonally, I prefer this one because under the hood, it calls native APIs (via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants:\n\nThis answer says it prefers a non-Pythonic, error-prone method, with no justification. It seems to encourage users to use low-level APIs without understanding them.\n\nIt also creates a context manager which, by unconditionally returning True, allows all Exceptions (including KeyboardInterrupt and SystemExit!) to pass silently, which is a good way to hide bugs.\n\nThis seems to encourage users to adopt poor practices.\n\nShare\nImprove this answer\nFollow\nedited Feb 25 '18 at 20:45\nanswered Aug 11 '15 at 3:54\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":[]},{"answer":"Testing for files and folders with os.path.isfile(), os.path.isdir() and os.path.exists()\n\nAssuming that the \"path\" is a valid path, this table shows what is returned by each function for files and folders:\n\nYou can also test if a file is a certain type of file using os.path.splitext() to get the extension (if you don't already know it)\n\n>>> import os\n>>> path = \"path to a word document\"\n>>> os.path.isfile(path)\nTrue\n>>> os.path.splitext(path)[1] == \".docx\" # test if the extension is .docx\nTrue\n\nShare\nImprove this answer\nFollow\nanswered Oct 8 '16 at 12:43\nTom Fuller\n4,6986\n6 gold badges\n31\n31 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"import os\n#Your path here e.g. \"C:\\Program Files\\text.txt\"\n#For access purposes: \"C:\\\\Program Files\\\\text.txt\"\nif os.path.exists(\"C:\\...\"):   \n    print \"File found!\"\nelse:\n    print \"File not found!\"\n\n\nImporting os makes it easier to navigate and perform standard actions with your operating system.\n\nFor reference also see How to check whether a file exists using Python?\n\nIf you need high-level operations, use shutil.\n\nShare\nImprove this answer\nFollow\nedited May 16 '17 at 16:36\nanswered May 25 '15 at 18:29\nloxsat\n2,7251\n1 gold badge\n22\n22 silver badges\n28\n28 bronze badges","comments":["This answer is wrong. os.path.exists returns true for things that aren't files, such as directories. This gives false positives. See the other answers that recommend os.path.isfile."]},{"answer":"In 2016 the best way is still using os.path.isfile:\n\n>>> os.path.isfile('/path/to/some/file.txt')\n\n\nOr in Python 3 you can use pathlib:\n\nimport pathlib\npath = pathlib.Path('/path/to/some/file.txt')\nif path.is_file():\n    ...\n\nShare\nImprove this answer\nFollow\nedited May 27 '17 at 1:00\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 24 '16 at 12:44\nKaiBuxe\n8287\n7 silver badges\n8\n8 bronze badges","comments":["May I ask: What's the advantage of using the module 'pathlib' instead of the module 'os' in python3 for this checking?","pathlib is python's OOP solution for paths. You can do a lot more with it. If you just need to check existance, the advantage is not so big."]},{"answer":"It doesn't seem like there's a meaningful functional difference between try/except and isfile(), so you should use which one makes sense.\n\nIf you want to read a file, if it exists, do\n\ntry:\n    f = open(filepath)\nexcept IOError:\n    print 'Oh dear.'\n\n\nBut if you just wanted to rename a file if it exists, and therefore don't need to open it, do\n\nif os.path.isfile(filepath):\n    os.rename(filepath, filepath + '.old')\n\n\nIf you want to write to a file, if it doesn't exist, do\n\n# python 2\nif not os.path.isfile(filepath):\n    f = open(filepath, 'w')\n\n# python 3, x opens for exclusive creation, failing if the file already exists\ntry:\n    f = open(filepath, 'wx')\nexcept IOError:\n    print 'file already exists'\n\n\nIf you need file locking, that's a different matter.\n\nShare\nImprove this answer\nFollow\nedited Aug 25 '15 at 3:12\nanswered Sep 25 '13 at 1:52\nchad\n1,23912\n12 silver badges\n10\n10 bronze badges","comments":["This answer is wrong. os.path.exists returns true for things that aren't files, such as directories. This gives false positives. See the other answers that recommend os.path.isfile.","On your third example, I create a link named filepath with the right timing, and BAM, you overwrite the target file. You should do open(filepath, 'wx') in a try...except block to avoid the issue.","In your second example, at least in Windows, you will get an OSError if filepath + '.old' already exists: \"On Windows, if dst already exists, OSError will be raised even if it is a file; there may be no way to implement an atomic rename when dst names an existing file.\"","@TomMyddeltyn: As of Python 3.3, os.replace portably performs silent replacement of the destination file (it's identical to os.rename's Linux behavior) (it only errors if the destination name exists and is a directory). So you're stuck on 2.x, but Py3 users have had a good option for several years now.","On the rename example: It should still be done with try/except. os.rename (or os.replace on modern Python) is atomic; making it check then rename introduces an unnecessary race and additional system calls. Just do try: os.replace(filepath, filepath + '.old') except OSError: pass"]},{"answer":"You could try this (safer):\n\ntry:\n    # http://effbot.org/zone/python-with-statement.htm\n    # 'with' is safer to open a file\n    with open('whatever.txt') as fh:\n        # Do something with 'fh'\nexcept IOError as e:\n    print(\"({})\".format(e))\n\n\nThe ouput would be:\n\n([Errno 2] No such file or directory: 'whatever.txt')\n\nThen, depending on the result, your program can just keep running from there or you can code to stop it if you want.\n\nShare\nImprove this answer\nFollow\nedited May 27 '17 at 0:43\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 25 '11 at 23:00\nphilberndt\n1,0522\n2 gold badges\n11\n11 silver badges\n14\n14 bronze badges","comments":["The original question asked for a solution that does not use try","This answer misses the point of the OP. Checking is a file exists is not the same as checking if you can open it. There will be cases where a file does exist but for a variety of reasons, you can't open it."]},{"answer":"Date:2017-12-04\n\nEvery possible solution has been listed in other answers.\n\nAn intuitive and arguable way to check if a file exists is the following:\n\nimport os\nos.path.isfile('~/file.md')  # Returns True if exists, else False\n# additionaly check a dir\nos.path.isdir('~/folder')  # Returns True if the folder exists, else False\n# check either a dir or a file\nos.path.exists('~/file')\n\n\nI made an exhaustive cheatsheet for your reference:\n\n#os.path methods in exhaustive cheatsheet\n{'definition': ['dirname',\n               'basename',\n               'abspath',\n               'relpath',\n               'commonpath',\n               'normpath',\n               'realpath'],\n'operation': ['split', 'splitdrive', 'splitext',\n               'join', 'normcase'],\n'compare': ['samefile', 'sameopenfile', 'samestat'],\n'condition': ['isdir',\n              'isfile',\n              'exists',\n              'lexists'\n              'islink',\n              'isabs',\n              'ismount',],\n 'expand': ['expanduser',\n            'expandvars'],\n 'stat': ['getatime', 'getctime', 'getmtime',\n          'getsize']}\n\nShare\nImprove this answer\nFollow\nedited Dec 23 '18 at 10:46\nAzat Ibrakov\n7,5198\n8 gold badges\n32\n32 silver badges\n40\n40 bronze badges\nanswered Dec 4 '17 at 8:51\nAbstProcDo\n15k14\n14 gold badges\n54\n54 silver badges\n99\n99 bronze badges","comments":[]},{"answer":"Although I always recommend using try and except statements, here are a few possibilities for you (my personal favourite is using os.access):\n\nTry opening the file:\n\nOpening the file will always verify the existence of the file. You can make a function just like so:\n\ndef File_Existence(filepath):\n    f = open(filepath)\n    return True\n\n\nIf it's False, it will stop execution with an unhanded IOError or OSError in later versions of Python. To catch the exception, you have to use a try except clause. Of course, you can always use a try except` statement like so (thanks to hsandt for making me think):\n\ndef File_Existence(filepath):\n    try:\n        f = open(filepath)\n    except IOError, OSError: # Note OSError is for later versions of Python\n        return False\n\n    return True\n\n\nUse os.path.exists(path):\n\nThis will check the existence of what you specify. However, it checks for files and directories so beware about how you use it.\n\nimport os.path\n>>> os.path.exists(\"this/is/a/directory\")\nTrue\n>>> os.path.exists(\"this/is/a/file.txt\")\nTrue\n>>> os.path.exists(\"not/a/directory\")\nFalse\n\n\nUse os.access(path, mode):\n\nThis will check whether you have access to the file. It will check for permissions. Based on the os.py documentation, typing in os.F_OK, it will check the existence of the path. However, using this will create a security hole, as someone can attack your file using the time between checking the permissions and opening the file. You should instead go directly to opening the file instead of checking its permissions. (EAFP vs LBYP). If you're not going to open the file afterwards, and only checking its existence, then you can use this.\n\nAnyway, here:\n\n>>> import os\n>>> os.access(\"/is/a/file.txt\", os.F_OK)\nTrue\n\n\nI should also mention that there are two ways that you will not be able to verify the existence of a file. Either the issue will be permission denied or no such file or directory. If you catch an IOError, set the IOError as e (like my first option), and then type in print(e.args) so that you can hopefully determine your issue. I hope it helps! :)\n\nShare\nImprove this answer\nFollow\nedited May 27 '17 at 0:52\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 26 '14 at 20:05\nZizouz212\n4,6285\n5 gold badges\n36\n36 silver badges\n62\n62 bronze badges","comments":[]},{"answer":"Additionally, os.access():\n\nif os.access(\"myfile\", os.R_OK):\n    with open(\"myfile\") as fp:\n        return fp.read()\n\n\nBeing R_OK, W_OK, and X_OK the flags to test for permissions (doc).\n\nShare\nImprove this answer\nFollow\nedited May 4 '16 at 15:24\narmatita\n10.5k7\n7 gold badges\n43\n43 silver badges\n44\n44 bronze badges\nanswered Sep 17 '08 at 13:13\nzgoda\n12.5k4\n4 gold badges\n35\n35 silver badges\n43\n43 bronze badges","comments":[]},{"answer":"If the file is for opening you could use one of the following techniques:\n\nwith open('somefile', 'xt') as f: #Using the x-flag, Python3.3 and above\n    f.write('Hello\\n')\n\nif not os.path.exists('somefile'): \n    with open('somefile', 'wt') as f:\n        f.write(\"Hello\\n\")\nelse:\n    print('File already exists!')\n\n\nUPDATE\n\nJust to avoid confusion and based on the answers I got, current answer finds either a file or a directory with the given name.\n\nShare\nImprove this answer\nFollow\nedited Feb 21 '20 at 13:28\nTshilidzi Mudau\n5,6626\n6 gold badges\n32\n32 silver badges\n44\n44 bronze badges\nanswered Oct 13 '14 at 7:45\nbergercookie\n2,06524\n24 silver badges\n34\n34 bronze badges","comments":["This answer is wrong. os.path.exists returns true for things that aren't files, such as directories. This gives false positives. See the other answers that recommend os.path.isfile.","got the false positive problem also.","docs.python.org/3/library/os.path.html#os.path.exists To the above statement from chris >>os.path.exists(path) > Return True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic links. On some platforms, this function may return False if permission is not granted to execute os.stat() on the requested file, even if the path physically exists. Changed in version 3.3: path can now be an integer: True is returned if it is an open file descriptor, False otherwise. Changed in version 3.6: Accepts a path-like object."]},{"answer":"The easiest way to do this is with\n\nimport os\n\nif os.path.exists(FILE):\n  # file exists\n  pass\nelse:\n  # file does not exists\n  pass\n\n\nfrom the os library, while FILE is the relative path. In Windows this may or many not work and you may have to use the absolution path by doing os.path.exists(os.path.join(os.path.abspath('./'), FILE)), where FILE is still the relative path plus file name\n\nShare\nImprove this answer\nFollow\nanswered May 10 at 16:42\nAndrew\n7404\n4 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"TL;DR use the pathlib module which is probably the most modern and convenient way for almost all of the file operations. For the existence of a file or a folder a single line of code is enough.\n\nfrom pathlib import Path\n\nif Path(\"myfile.txt\").exists(): # works for both file and folders\n    # do your cool stuff...\n\n\nThe pathlib module was introduced in Python 3.4, so you need to have Python 3.4+, this lib makes your life much easier while working with files and folders and it is pretty to use, here is more doc about it (https://docs.python.org/3/library/pathlib.html).\n\nBTW, if you are going to reuse the path, then it is better to assign it to a variable\n\nso will become\n\nfrom pathlib import Path\n\np = Path(\"loc/of/myfile.txt\")\nif p.exists(): # works for both file and folders\n    # do stuffs...\n#reuse 'p' if needed.\n\nShare\nImprove this answer\nFollow\nedited Aug 18 at 10:24\nanswered Jan 23 at 9:48\nMemin\n2,25621\n21 silver badges\n24\n24 bronze badges","comments":["Be aware that this returns True if the file is not present but path to file exists. If you are really interested in asking whether the file exists or not you should be using p.is_file()"]},{"answer":"You Can Use os.path.exists() :\n\nimport os\nprint(os.path.exists(\"file\"))\n\n\nHope It Helps :D\n\nShare\nImprove this answer\nFollow\nanswered Apr 16 at 5:21\nAbhimanyu Sharma\n3561\n1 silver badge\n10\n10 bronze badges","comments":[]},{"answer":"if os.path.isfile(path_to_file):\n    try: \n        open(path_to_file)\n            pass\n    except IOError as e:\n        print \"Unable to open file\"\n\n\nRaising exceptions is considered to be an acceptable, and Pythonic, approach for flow control in your program. Consider handling missing files with IOErrors. In this situation, an IOError exception will be raised if the file exists but the user does not have read permissions.\n\nSRC: http://www.pfinn.net/python-check-if-file-exists.html\n\nShare\nImprove this answer\nFollow\nedited Jul 18 '15 at 17:41\nanswered Apr 28 '15 at 2:45\nPedro Lobito\n78k26\n26 gold badges\n210\n210 silver badges\n228\n228 bronze badges","comments":["The OP asked how to check if a file exists. It's possible for a file to exist but for you to not be able to open it. Therefore using opening a file as a proxy for checking if the file exists is not correct: will have false negatives."]},{"answer":"If you imported NumPy already for other purposes then there is no need to import other libraries like pathlib, os, paths, etc.\n\nimport numpy as np\nnp.DataSource().exists(\"path/to/your/file\")\n\n\nThis will return true or false based on its existence.\n\nShare\nImprove this answer\nFollow\nedited Sep 1 '18 at 1:00\nJayRizzo\n2,1323\n3 gold badges\n25\n25 silver badges\n40\n40 bronze badges\nanswered Aug 10 '17 at 5:50\ndurjoy\n1,45111\n11 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"You can write Brian's suggestion without the try:.\n\nfrom contextlib import suppress\n\nwith suppress(IOError), open('filename'):\n    process()\n\n\nsuppress is part of Python 3.4. In older releases you can quickly write your own suppress:\n\nfrom contextlib import contextmanager\n\n@contextmanager\ndef suppress(*exceptions):\n    try:\n        yield\n    except exceptions:\n        pass\n\nShare\nImprove this answer\nFollow\nedited May 27 '17 at 0:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 10 '14 at 21:30\nChris\n1,39812\n12 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"Check file or directory exists\n\nYou can follow these three ways:\n\nNote1: The os.path.isfile used only for files\n\nimport os.path\nos.path.isfile(filename) # True if file exists\nos.path.isfile(dirname) # False if directory exists\n\n\nNote2: The os.path.exists used for both files and directories\n\nimport os.path\nos.path.exists(filename) # True if file exists\nos.path.exists(dirname) #True if directory exists\n\n\nThe pathlib.Path method (included in Python 3+, installable with pip for Python 2)\n\nfrom pathlib import Path\nPath(filename).exists()\n\nShare\nImprove this answer\nFollow\nanswered Mar 4 '18 at 6:24\nAli Hallaji\n1,8481\n1 gold badge\n18\n18 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"Adding one more slight variation which isn't exactly reflected in the other answers.\n\nThis will handle the case of the file_path being None or empty string.\n\ndef file_exists(file_path):\n    if not file_path:\n        return False\n    elif not os.path.isfile(file_path):\n        return False\n    else:\n        return True\n\n\nAdding a variant based on suggestion from Shahbaz\n\ndef file_exists(file_path):\n    if not file_path:\n        return False\n    else:\n        return os.path.isfile(file_path)\n\n\nAdding a variant based on suggestion from Peter Wood\n\ndef file_exists(file_path):\n    return file_path and os.path.isfile(file_path):\n\nShare\nImprove this answer\nFollow\nedited Apr 7 '17 at 16:10\nanswered Aug 5 '16 at 15:54\nMarcel Wilson\n2,99921\n21 silver badges\n43\n43 bronze badges","comments":["if (x) return true; else return false; is really just return x. Your last four lines can become return os.path.isfile(file_path). While we're at it, the whole function can be simplified as return file_path and os.path.isfile(file_path).","You have to be careful with return x in the case of if (x). Python will consider an empty string False in which case we would be returning an empty string instead of a bool. The purpose of this function is to always return bool.","True. In this case however, x is os.path.isfile(..) so it's already bool.","os.path.isfile(None) raises an exception which is why I added the if check. I could probably just wrap it in a try/except instead but I felt it was more explicit this way.","return file_path and os.path.isfile(file_path)"]},{"answer":"I'm the author of a package that's been around for about 10 years, and it has a function that addresses this question directly. Basically, if you are on a non-Windows system, it uses Popen to access find. However, if you are on Windows, it replicates find with an efficient filesystem walker.\n\nThe code itself does not use a try block… except in determining the operating system and thus steering you to the \"Unix\"-style find or the hand-buillt find. Timing tests showed that the try was faster in determining the OS, so I did use one there (but nowhere else).\n\n>>> import pox\n>>> pox.find('*python*', type='file', root=pox.homedir(), recurse=False)\n['/Users/mmckerns/.python']\n\n\nAnd the doc…\n\n>>> print pox.find.__doc__\nfind(patterns[,root,recurse,type]); Get path to a file or directory\n\n    patterns: name or partial name string of items to search for\n    root: path string of top-level directory to search\n    recurse: if True, recurse down from root directory\n    type: item filter; one of {None, file, dir, link, socket, block, char}\n    verbose: if True, be a little verbose about the search\n\n    On some OS, recursion can be specified by recursion depth (an integer).\n    patterns can be specified with basic pattern matching. Additionally,\n    multiple patterns can be specified by splitting patterns with a ';'\n    For example:\n        >>> find('pox*', root='..')\n        ['/Users/foo/pox/pox', '/Users/foo/pox/scripts/pox_launcher.py']\n\n        >>> find('*shutils*;*init*')\n        ['/Users/foo/pox/pox/shutils.py', '/Users/foo/pox/pox/__init__.py']\n\n>>>\n\n\nThe implementation, if you care to look, is here: https://github.com/uqfoundation/pox/blob/89f90fb308f285ca7a62eabe2c38acb87e89dad9/pox/shutils.py#L190\n\nShare\nImprove this answer\nFollow\nedited May 27 '17 at 0:59\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 5 '16 at 12:00\nMike McKerns\n28.1k7\n7 gold badges\n105\n105 silver badges\n127\n127 bronze badges","comments":[]},{"answer":"Here's a 1 line Python command for the Linux command line environment. I find this VERY HANDY since I'm not such a hot Bash guy.\n\npython -c \"import os.path; print os.path.isfile('/path_to/file.xxx')\"\n\n\nI hope this is helpful.\n\nShare\nImprove this answer\nFollow\nanswered Aug 29 '15 at 16:15\nLove and peace - Joe Codeswell\n2,4212\n2 gold badges\n33\n33 silver badges\n43\n43 bronze badges","comments":["One-line check in bash: [ -f \"${file}\" ] && echo \"file found\" || echo \"file not found\" (which is the same as if [ ... ]; then ...; else ...; fi)."]}]},{"id":"16956810","href":"https://stackoverflow.com/questions/16956810/how-do-i-find-all-files-containing-specific-text-on-linux","title":"How do I find all files containing specific text on Linux?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        Want to improve this post? Provide detailed answers to this question, including citations and an explanation of why your answer is correct. Answers without enough detail may be edited or deleted.\n                        \n                    \n                \n            \n        \n\n\n    \n\nI'm trying to find a way to scan my entire Linux system for all files containing a specific string of text. Just to clarify, I'm looking for text within the file, not in the file name.\n\nWhen I was looking up how to do this, I came across this solution twice:\n\nfind / -type f -exec grep -H 'text-to-find-here' {} \\;\n\n\nHowever, it doesn't work. It seems to display every single file in the system.\n\nIs this close to the proper way to do it? If not, how should I? This ability to find text strings in files would be extraordinarily useful for some programming projects I'm doing.\n    ","questionComments":["remember that grep will interpret any . as a single-character wildcard, among others. My advice is to alway use either fgrep or egrep.","anyway, you were almost there! Just replace -H with -l (and maybe grep with fgrep). To exclude files with certain patterns of names you would use find in a more advanced way. It's worthwile to learn to use find, though. Just man find.","find … -exec <cmd> + is easier to type and faster than find … -exec <cmd> \\;. It works only if <cmd> accepts any number of file name arguments. The saving in execution time is especially big if <cmd> is slow to start like Python or Ruby scripts.","To search non-recursively in a given path the command is `grep --include=*.txt -snw \"pattern\" thepath/*.","@StéphaneLaurent I think you are complicating it too much. Just say grep \"pattern\" path/*.txt"],"answers":[{"answer":"Do the following:\n\ngrep -rnw '/path/to/somewhere/' -e 'pattern'\n\n-r or -R is recursive,\n-n is line number, and\n-w stands for match the whole word.\n-l (lower-case L) can be added to just give the file name of matching files.\n-e is the pattern used during the search\n\nAlong with these, --exclude, --include, --exclude-dir flags could be used for efficient searching:\n\nThis will only search through those files which have .c or .h extensions:\ngrep --include=\\*.{c,h} -rnw '/path/to/somewhere/' -e \"pattern\"\n\nThis will exclude searching all the files ending with .o extension:\ngrep --exclude=\\*.o -rnw '/path/to/somewhere/' -e \"pattern\"\n\nFor directories it's possible to exclude one or more directories using the --exclude-dir parameter. For example, this will exclude the dirs dir1/, dir2/ and all of them matching *.dst/:\ngrep --exclude-dir={dir1,dir2,*.dst} -rnw '/path/to/somewhere/' -e \"pattern\"\n\n\nThis works very well for me, to achieve almost the same purpose like yours.\n\nFor more options check man grep.\n\nShare\nImprove this answer\nFollow\nedited Jan 26 at 21:27\nIntrastellar Explorer\n9233\n3 gold badges\n17\n17 silver badges\n53\n53 bronze badges\nanswered Jun 6 '13 at 8:21\nrakib_\n117k3\n3 gold badges\n15\n15 silver badges\n25\n25 bronze badges","comments":["use --exclude. like \"grep -rnw --exclude=*.o 'directory' -e \"pattern\"","it's worth noting: it seems the r option is lazy (traverses depth-first, than stops after the first directory), while R is greedy (will traverse the entire tree correctly).","grep -rnw \"String I was looking for\" done what I needed. Thanks!","Note(especially for newbies): The quotation marks in the above command are important.","@Eliran Malka R en r will both traverse directories correctly, but R will follow symbolic links."]},{"answer":"You can use grep -ilR:\n\ngrep -Ril \"text-to-find-here\" /\n\ni stands for ignore case (optional in your case).\nR stands for recursive.\nl stands for \"show the file name, not the result itself\".\n/ stands for starting at the root of your machine.\nShare\nImprove this answer\nFollow\nedited Feb 23 '16 at 10:02\nanswered Jun 6 '13 at 8:08\nfedorqui 'SO stop harming'\n234k82\n82 gold badges\n477\n477 silver badges\n531\n531 bronze badges","comments":["Based on my experience, the -i makes it slow down a lot, so don't use it if not necessary. Test it in a certain dir and then generalise. It should be completed within few minutes. I think a regular expression would make it slower. But my comments are based on suppositions, I suggest you to test it with time in front of the line.","Yes, /* stands for that. Anyway I just tested it and noticed that just / works.","If you are not searching using a regex you can use fgrep in place of grep on most systems.","Yes @markle976, in fact from man grep: fgrep is the same as grep -F -> Interpret PATTERN as a list of fixed strings.","You can replace / with path to directory grep -Ril \"text-to-find-here\" ~/sites/ or use . for current directory grep -Ril \"text-to-find-here\" ."]},{"answer":"You can use ack. It is like grep for source code. You can scan your entire file system with it.\n\nJust do:\n\nack 'text-to-find-here'\n\n\nIn your root directory.\n\nYou can also use regular expressions, specify the filetype, etc.\n\nUPDATE\n\nI just discovered The Silver Searcher, which is like ack but 3-5x faster than it and even ignores patterns from a .gitignore file.\n\nShare\nImprove this answer\nFollow\nedited Mar 12 '15 at 12:31\nRAJ\n9,4031\n1 gold badge\n29\n29 silver badges\n61\n61 bronze badges\nanswered Jun 6 '13 at 8:26\nStephan\n13.1k6\n6 gold badges\n46\n46 silver badges\n56\n56 bronze badges","comments":["Very useful, simple and fast. Warning: \"On Debian-derived distros, ack is packaged as \"ack-grep\" because \"ack\" already existed\" (from beyondgrep.com/install). You may end up running a Kanji code converter on those Linuxes...","ack or ack-grep has nice highlights, but find+grep when proper used is much better in performance","Note that ripgrep is faster than anything else mentioned here, including The Silver Searcher and plain 'ol grep. See this blog post for proof."]},{"answer":"You can use:\n\ngrep -r \"string to be searched\"  /path/to/dir\n\n\nThe r stands for recursive and so will search in the path specified and also its sub-directories. This will tell you the file name as well as print out the line in the file where the string appears.\n\nOr a command similar to the one you are trying (example: ) for searching in all javascript files (*.js):\n\nfind . -name '*.js' -exec grep -i 'string to search for' {} \\; -print\n\n\nThis will print the lines in the files where the text appears, but it does not print the file name.\n\nIn addition to this command, we can write this too: grep -rn \"String to search\" /path/to/directory/or/file -r: recursive search n: line number will be shown for matches\n\nShare\nImprove this answer\nFollow\nedited Apr 2 '18 at 8:35\nVivek Ranjan\n557\n7 bronze badges\nanswered Mar 14 '14 at 23:29\nlearner_19\n3,2711\n1 gold badge\n17\n17 silver badges\n8\n8 bronze badges","comments":["Thanx for the find version. My grep version (busybox for NAS) hasn't the -r option, i really needed another solution!","Thank you for the 'find' version! It is so important to be able to filter by '.js' or '.txt', etc. Nobody wants to spend hours waiting for grep to finish searching all the multi-gigabyte videos from the last family vacation, even if the command is easier to type.","better grep than accepted version, because accepted do not search half words"]},{"answer":"You can use this:\n\ngrep -inr \"Text\" folder/to/be/searched/\n\nShare\nImprove this answer\nFollow\nedited Jul 31 '13 at 14:09\nSudipta\n4,2972\n2 gold badges\n22\n22 silver badges\n41\n41 bronze badges\nanswered Jul 31 '13 at 13:44\nA R\n2,2673\n3 gold badges\n17\n17 silver badges\n34\n34 bronze badges","comments":["easiest, verbose, recursive and case insensitive. thumbs up.","if you add -A3 is even better"]},{"answer":"grep (GNU or BSD)\n\nYou can use grep tool to search recursively the current folder, like:\n\ngrep -r \"class foo\" .\n\n\nNote: -r - Recursively search subdirectories.\n\nYou can also use globbing syntax to search within specific files such as:\n\ngrep \"class foo\" **/*.c\n\n\nNote: By using globbing option (**), it scans all the files recursively with specific extension or pattern. To enable this syntax, run: shopt -s globstar. You may also use **/*.* for all files (excluding hidden and without extension) or any other pattern.\n\nIf you've the error that your argument is too long, consider narrowing down your search, or use find syntax instead such as:\n\nfind . -name \"*.php\" -execdir grep -nH --color=auto foo {} ';'\n\n\nAlternatively, use ripgrep.\n\nripgrep\n\nIf you're working on larger projects or big files, you should use ripgrep instead, like:\n\nrg \"class foo\" .\n\n\nCheckout the docs, installation steps or source code on the GitHub project page.\n\nIt's much quicker than any other tool like GNU/BSD grep, ucg, ag, sift, ack, pt or similar, since it is built on top of Rust's regex engine which uses finite automata, SIMD and aggressive literal optimizations to make searching very fast.\n\nIt supports ignore patterns specified in .gitignore files, so a single file path can be matched against multiple glob patterns simultaneously.\n\nYou can use common parameters such as:\n\n-i - Insensitive searching.\n-I - Ignore the binary files.\n-w - Search for the whole words (in the opposite of partial word matching).\n-n - Show the line of your match.\n-C/--context (e.g. -C5) - Increases context, so you see the surrounding code.\n--color=auto - Mark up the matching text.\n-H - Displays filename where the text is found.\n-c - Displays count of matching lines. Can be combined with -H.\nShare\nImprove this answer\nFollow\nedited Aug 4 '20 at 0:48\nHasidul Islam\n33\n3 bronze badges\nanswered May 9 '15 at 10:11\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges","comments":["I also find extended globbing useful. But keep in mind that if there are really huge number of files, you can get a \"Argument list too long\" error. (Simple globbing is also prone to this kind of error).","For inhaling a whole file system, rg is gonna be far less painful than almost any other tool.","lol i'm sorry I downvoted this answer yesterday by mistake and now I can't change it ;_; here's 10 robot parts for apologies <3","it could use a better name, though... i don't use it everyday and it's get hard to remember this name when i want to use it!"]},{"answer":"List of file names containing a given text\n\nFirst of all, I believe you have used -H instead of -l. Also you can try adding the text inside quotes followed by {} \\.\n\nfind / -type f -exec grep -l \"text-to-find-here\" {} \\; \n\nExample\n\nLet's say you are searching for files containing specific text \"Apache License\" inside your directory. It will display results somewhat similar to below (output will be different based on your directory content).\n\nbash-4.1$ find . -type f -exec grep -l \"Apache License\" {} \\; \n./net/java/jvnet-parent/5/jvnet-parent-5.pom\n./commons-cli/commons-cli/1.3.1/commons-cli-1.3.1.pom\n./io/swagger/swagger-project/1.5.10/swagger-project-1.5.10.pom\n./io/netty/netty-transport/4.1.7.Final/netty-transport-4.1.7.Final.pom\n./commons-codec/commons-codec/1.9/commons-codec-1.9.pom\n./commons-io/commons-io/2.4/commons-io-2.4.pom\nbash-4.1$ \n\nRemove case sensitiveness\n\nEven if you are not use about the case like \"text\" vs \"TEXT\", you can use the -i switch to ignore case. You can read further details here.\n\nHope this helps you.\n\nShare\nImprove this answer\nFollow\nedited Oct 7 '17 at 5:54\nanswered Nov 9 '13 at 13:18\nlkamal\n3,23015\n15 silver badges\n28\n28 bronze badges","comments":["Which is what this command does: find will pass all the paths it finds to the command grep -l \"text-to-find-here\" <file found>\". You may add restrictions to the file name, e.g. find / -iname \"*.txt\" to search only in files which name ends in .txt","@Auxiliary - included a sample output to avoid any confusion for the readers.","@Mene It's a truly sad state that Auxiliary's comment has more votes than yours...even if their comment is from 2014 and yours is 2017 that their comment has 6 when it should have exactly 0 and yours only had one (now two) isn't something I'd like to believe.","@Mene That being said -iname is case-insensitive which means it would also find .TXT files, for example, as well as TxT and TXt and so on."]},{"answer":"If your grep doesn't support recursive search, you can combine find with xargs:\n\nfind / -type f | xargs grep 'text-to-find-here'\n\n\nI find this easier to remember than the format for find -exec.\n\nThis will output the filename and the content of the matched line, e.g.\n\n/home/rob/file:text-to-find-here\n\n\nOptional flags you may want to add to grep:\n\n-i - case insensitive search\n-l - only output the filename where the match was found\n-h - only output the line which matched (not the filename)\nShare\nImprove this answer\nFollow\nedited Aug 12 '15 at 9:19\nanswered Jun 20 '14 at 8:49\nRobEarl\n7,5566\n6 gold badges\n31\n31 silver badges\n48\n48 bronze badges","comments":["This is equivalent to grep 'text-to-find-here' without file name if find does not find anything. This will hang and wait for user input! Add --no-run-if-empty as an option to xargs.","This combination of find and xargs does not work as intended if file or directory names contain spaces (characters that xargs interprets as separators). Use find … -exec grep … +. If you insist on using find together with xargs, use -print0 and -0."]},{"answer":"grep -insr \"pattern\" *\n\ni: Ignore case distinctions in both the PATTERN and the input files.\nn: Prefix each line of output with the 1-based line number within its input file.\ns: Suppress error messages about nonexistent or unreadable files.\nr: Read all files under each directory, recursively.\nShare\nImprove this answer\nFollow\nedited Mar 8 '16 at 7:39\nFabio Poloni\n7,6233\n3 gold badges\n40\n40 silver badges\n72\n72 bronze badges\nanswered Feb 26 '16 at 5:47\nenfinet\n7306\n6 silver badges\n16\n16 bronze badges","comments":["Can you explain how your answer improves upon the other answers, or how it is sufficiently different from them?","not much complex to remember, will cover all patterns(case-senstivity -> off, includes file-names and line number and will do recursively search etc) and using \"*\" in the end will search all directories (no need to specify any path or directory name).","Sorry, I should've been clearer: it would be great if you could include that explanation in your answer. As it stands, especially with so many other similar answers already, it is hard to see from such a short answer what the benefit of trying it over the accepted answer or one of the upvoted ones would be.","@AmosM.Carpenter One thing I love about this answer is pointing out the suppress argument, which can help filter out noise that doesn't matter to getting the results we actually want. Grep prints errors like, \"Function not implemented\", \"Invalid Argument\", \"Resource unavailable\", etc. etc on certain \"files\".","@leetNightshade: I'm assuming you're addressing your comment to me because I asked for an explanation on the sparse original post. Please see Fabio's great revision for my previous comments to make sense."]},{"answer":"There's a new utility called The Silversearcher\n\nsudo apt install silversearcher-ag\n\n\nIt works closely with Git and other VCS. So you won't get anything in a .git or another directory.\n\nYou can simply use\n\nag \"Search query\"\n\n\nAnd it will do the task for you!\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '19 at 17:01\nanswered Nov 3 '16 at 21:30\nNeil Agarwal\n7391\n1 gold badge\n7\n7 silver badges\n10\n10 bronze badges","comments":["Good call!. I downloaded it and used it first time. The output results are very informative and colourful and very helpfull. This prog will stay in my machine for ever. I have also put it on my \"Install a new computer\" list of programs. Cheers!!"]},{"answer":"How do I find all files containing specific text on Linux? (...)\n\nI came across this solution twice:\n\nfind / -type f -exec grep -H 'text-to-find-here' {} \\;\n\nIf using find like in your example, better add -s (--no-messages) to grep, and 2>/dev/null at the end of the command to avoid lots of Permission denied messages issued by grep and find:\n\nfind / -type f -exec grep -sH 'text-to-find-here' {} \\; 2>/dev/null\n\n\nfind is the standard tool for searching files - combined with grep when looking for specific text - on Unix-like platforms. The find command is often combined with xargs, by the way.\n\nFaster and easier tools exist for the same purpose - see below. Better try them, provided they're available on your platform, of course:\n\nFaster and easier alternatives\n\nRipGrep - fastest search tool around:\n\nrg 'text-to-find-here' / -l\n\n\nThe Silver Searcher:\n\nag 'text-to-find-here' / -l\n\n\nack:\n\nack 'text-to-find-here' / -l\n\n\nNote: You can add 2>/dev/null to these commands as well, to hide many error messages.\n\nWarning: unless you really can't avoid it, don't search from '/' (the root directory) to avoid a long and inefficient search! So in the examples above, you'd better replace '/' by a sub-directory name, e.g. \"/home\" depending where you actually want to search...\n\nShare\nImprove this answer\nFollow\nedited Jun 2 '18 at 17:21\nanswered Nov 25 '15 at 14:16\nBludzee\n2,4405\n5 gold badges\n30\n30 silver badges\n39\n39 bronze badges","comments":["'find is the standard tool for searching files containing specific text on Unix-like platforms' seems rather ambiguous to me. Even besides recursive grep find doesn't directly search the inside of files for text. And maybe those additional tools are useful to some but old timers and those whoa are well accustomed to e.g. grep wouldn't give them any time at all (well I certainly won't). Not saying they're useless though.","\"....containing specific text...\" : this part of the sentence was not accurate (because it's not find itself that deals with this part of the search). Edited. Thanks.","Glad to be of help! The only thing else at a very very quick glance is changing the word folder to directory but I know that’s a crusade of mine I will never win completely. Not giving up though...","Why not \"directory\" instead of \"folder\", but why ? Please share your \"crusade\" !","I'm saying use directory instead! Referring to: you'd better replace '/' by a sub-folder name And it's a pet peeve of mine.. esp since even Windows used to call it 'directory'. Ah..maybe you got that. Why? Well because that's what it's called. It's also called that at the file system level. And look at it this way: was it ever called (for DOS) fol? No of course not; it was called dir (and I believe it still is). Folder is a thing contrived for (I guess) user friendliness though in this case it's maybe dumbing it down for less 'advanced' users?"]},{"answer":"Try:\n\nfind . -name \"*.txt\" | xargs grep -i \"text_pattern\"\n\nShare\nImprove this answer\nFollow\nedited Apr 17 '15 at 15:33\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges\nanswered Dec 10 '14 at 5:47\nvenkat\n3493\n3 silver badges\n2\n2 bronze badges","comments":["This is actually a prime example of when NOT to use xargs like that .. consider this. echo \"file bar.txt has bar\" > bar.txt; echo \"file foo bar.txt has foo bar\" > \"foo bar.txt\"; echo \"You should never see this foo\" > foo; find . -name \"*.txt\" | xargs grep -i foo #  ./foo:You should never see this foo . The xargs here matched the WRONG file and did NOT match the intended file. Either use a find .. -print0 | xargs -0 ... but that's a useless use of a pipe or better find ... -exec grep ... {} +"]},{"answer":"Use pwd to search from any directory you are in, recursing downward\n\ngrep -rnw `pwd` -e \"pattern\"\n\n\nUpdate Depending on the version of grep you are using, you can omit pwd. On newer versions . seems to be the default case for grep if no directory is given thus:\n\ngrep -rnw -e \"pattern\"\n\nor\n\ngrep -rnw \"pattern\"\n\nwill do the same thing as above!\n\nShare\nImprove this answer\nFollow\nedited Feb 2 '17 at 12:29\nanswered May 28 '16 at 12:47\nmahatmanich\n9,5855\n5 gold badges\n51\n51 silver badges\n72\n72 bronze badges","comments":["using pwd is not necessary at all, since it is the default. grep -rnw \"pattern\" suffices.","and in fact the grep -rnw and similar is what was answered like three years ago, I don't see how this answer is adding value.","The selected answer does not show the default pattern, and 5 peoples seemed to have found it useful","What do you mean with \"default pattern\"? The accepted answer contains grep -rnw '/path/to/somewhere/' -e \"pattern\" which is what you have here. 5 votes after 2.3M visits does not mean that much.","I agree :-) what I was missing in the original answer is the use case that you don't have to give a path at all or to search the current directory recursively which is not reflected in the accepted answer. Thus it was a good learning experience about grep to dig a bit deeper."]},{"answer":"grep can be used even if we're not looking for a string.\n\nSimply running,\n\ngrep -RIl \"\" .\n\n\nwill print out the path to all text files, i.e. those containing only printable characters.\n\nShare\nImprove this answer\nFollow\nedited May 25 '17 at 0:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 9 '14 at 19:51\nAlex Jasmin\n37.4k6\n6 gold badges\n72\n72 silver badges\n63\n63 bronze badges","comments":["I don't see how this is better than using a mere ls or find (for the recursive)"]},{"answer":"Silver Searcher is a terrific tool, but ripgrep may be even better.\n\nIt works on Linux, Mac and Windows, and was written up on Hacker News a couple of months ago (this has a link to Andrew Gallant's Blog which has a GitHub link):\n\nRipgrep – A new command line search tool\n\nShare\nImprove this answer\nFollow\nedited May 25 '17 at 0:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 13 '16 at 5:48\nAAAfarmclub\n1,8381\n1 gold badge\n16\n16 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"If you strictly want to use find then use find + grep:\n\nfind /path/to/somewhere/ -type f -exec grep -nw 'textPattern' {} \\;\n\nSteps:\n\nUse find to search files,\nExecute grep on all of them.\n\nThis gives you the power of find to find files.\n\nUse -name Pattern if you want to grep only certain files:\n\nfind /path/to/somewhere/ -type f -name \\*.cpp -exec grep -nw 'textPattern' {} \\;\n\nYou can use different options of find to improve your file search.\n\nShare\nImprove this answer\nFollow\nedited Nov 21 '20 at 13:37\nJMP\n2,60917\n17 gold badges\n26\n26 silver badges\n34\n34 bronze badges\nanswered Jun 25 '18 at 12:11\nBreakBadSP\n7168\n8 silver badges\n20\n20 bronze badges","comments":["What is the difference? Will it work with spaces in the file path?"]},{"answer":"Here are the several list of commands that can be used to search file.\n\ngrep \"text string to search” directory-path\n\ngrep [option] \"text string to search” directory-path\n\ngrep -r \"text string to search” directory-path\n\ngrep -r -H \"text string to search” directory-path\n\negrep -R \"word-1|word-2” directory-path\n\negrep -w -R \"word-1|word-2” directory-path\n\nShare\nImprove this answer\nFollow\nanswered Feb 1 '14 at 5:47\nAtul Arvind\n14.2k5\n5 gold badges\n44\n44 silver badges\n54\n54 bronze badges","comments":["what is this adding to the existing answers?","@fedorqui egrep is equivalent to grep -E and it means --extended-regexp you can find details here unix.stackexchange.com/a/17951/196072"]},{"answer":"I am fascinated by how simple grep makes it with 'rl':\n\ngrep -rl 'pattern_to_find' /path/where/to/find\n\n-r to recursively find a file / directory inside directories..\n-l to list files matching the 'pattern'\n\n\nUse '-r' without 'l' to see the file names followed by text in which the pattern is found!\n\ngrep -r 'pattern_to_find' /path/where/to/find\n\n\nIt works just perfect...\n\nShare\nImprove this answer\nFollow\nedited Mar 27 '20 at 1:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 8 '17 at 9:38\nnitinr708\n1,2752\n2 gold badges\n19\n19 silver badges\n27\n27 bronze badges","comments":["This also works in Git Bash (Windows).","But it implies every file must searched (no filter on the file name or file extension level, like .txt). Or is there a way to do that?"]},{"answer":"find /path -type f -exec grep -l \"string\" {} \\;\n\n\nExplanation from comments\n\nfind is a command that lets you find files and other objects like directories and links in subdirectories of a given path. If you don't specify a mask that filesnames should meet, it enumerates all directory objects.\n\n-type f specifies that it should proceed only files, not directories etc.\n-exec grep specifies that for every found file, it should run grep command, passing its filename as an argument to it, by replacing {} with the filename\n\nShare\nImprove this answer\nFollow\nedited Nov 26 '14 at 13:12\nJuanZe\n7,66341\n41 silver badges\n57\n57 bronze badges\nanswered Jul 2 '14 at 7:18\nVinod Joshi\n7,14246\n46 silver badges\n49\n49 bronze badges","comments":[]},{"answer":"Hope this is of assistance...\n\nExpanding the grep a bit to give more information in the output, for example, to get the line number in the file where the text is can be done as follows:\n\nfind . -type f -name \"*.*\" -print0 | xargs --null grep --with-filename --line-number --no-messages --color --ignore-case \"searthtext\"\n\n\nAnd if you have an idea what the file type is you can narrow your search down by specifying file type extensions to search for, in this case .pas OR .dfm files:\n\nfind . -type f \\( -name \"*.pas\" -o -name \"*.dfm\" \\) -print0 | xargs --null grep --with-filename --line-number --no-messages --color --ignore-case \"searchtext\"\n\n\nShort explanation of the options:\n\n. in the find specifies from the current directory.\n-name \"*.*\" : for all files ( -name \"*.pas\" -o -name \"*.dfm\" ) : Only the *.pas OR *.dfm files, OR specified with -o\n-type f specifies that you are looking for files\n-print0 and --null on the other side of the | (pipe) are the crucial ones, passing the filename from the find to the grep embedded in the xargs, allowing for the passing of filenames WITH spaces in the filenames, allowing grep to treat the path and filename as one string, and not break it up on each space.\nShare\nImprove this answer\nFollow\nedited May 25 '17 at 0:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 28 '15 at 6:42\nGert van Biljon\n3313\n3 silver badges\n6\n6 bronze badges","comments":["-name '*.*' isn't what you say; it wouldn't pick up on a file called 'file' because the pattern doesn't equate to that (no .ext); * would however (well . files aside). But there's another thing: if you want all files why bother specifying a file name in the first place? No other comment - except that it's nice to know that there still are people who don't use the MS terminology 'folder' (which really after saying it enough I wouldn't add but I wanted to point out the slightly incorrect statement you made with file names - as well as the redundancy/uselessness in the case of 'all')."]},{"answer":"A Simple find can work handy. alias it in your ~/.bashrc file:\n\nalias ffind find / -type f | xargs grep\n\n\nStart a new terminal and issue:\n\nffind 'text-to-find-here'\n\nShare\nImprove this answer\nFollow\nedited May 25 '17 at 0:15\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 22 '17 at 12:30\ndanglingpointer\n4,1193\n3 gold badges\n20\n20 silver badges\n37\n37 bronze badges","comments":[]},{"answer":"grep is your good friend to achieve this.\n\ngrep -r <text_fo_find> <directory>\n\n\nIf you don't care about the case of the text to find, then use:\n\ngrep -ir <text_to_find> <directory>\n\nShare\nImprove this answer\nFollow\nedited Mar 27 '20 at 1:00\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 24 '17 at 3:07\nPrash\n4984\n4 silver badges\n8\n8 bronze badges","comments":["In my case it looks like it searches everywhere even if I do specify the directory","@Pathros Probably to do with recursion enabled and what directory you specify. Put another way recursion does change things in that way.","@Pathros Oh and if there are any - s in the search string you'll want to pass in -- to grep first; that can cause interesting side effects otherwise!"]},{"answer":"I wrote a Python script which does something similar. This is how one should use this script.\n\n./sniff.py path pattern_to_search [file_pattern]\n\n\nThe first argument, path, is the directory in which we will search recursively. The second argument, pattern_to_search, is a regular expression which we want to search in a file. We use the regular expression format defined in the Python re library. In this script, the . also matches newline.\n\nThe third argument, file_pattern, is optional. This is another regular expression which works on a filename. Only those files which matches this regular expression will be considered.\n\nFor example, if I want to search Python files with the extension py containing Pool( followed by word Adaptor, I do the following,\n\n./sniff.py . \"Pool(.*?Adaptor\"  .*py\n./Demos/snippets/cubeMeshSigNeur.py:146 \n./Demos/snippets/testSigNeur.py:259 \n./python/moose/multiscale/core/mumbl.py:206 \n./Demos/snippets/multiComptSigNeur.py:268 \n\n\nAnd voila, it generates the path of matched files and line number at which the match was found. If more than one match was found, then each line number will be appended to the filename.\n\nShare\nImprove this answer\nFollow\nedited Jun 30 '14 at 17:59\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 6 '14 at 12:56\nDilawar\n4,9189\n9 gold badges\n38\n38 silver badges\n56\n56 bronze badges","comments":[]},{"answer":"Try:\n\nfind / -type f -exec grep -H 'text-to-find-here' {} \\;\n\n\nwhich will search all file systems, because / is the root folder.\n\nFor home folder use:\n\nfind ~/ -type f -exec grep -H 'text-to-find-here' {} \\;\n\n\nFor current folder use:\n\nfind ./ -type f -exec grep -H 'text-to-find-here' {} \\;\n\nShare\nImprove this answer\nFollow\nedited May 9 '15 at 9:49\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges\nanswered May 4 '15 at 19:11\nuser4863663\n1791\n1 silver badge\n2\n2 bronze badges","comments":["Perhaps the details on differences of folders are obvious to many ...but also very helpful for newbies. +1","what is this adding to the existing answers?","Call it my crusade but the word is 'directory'. This isn't Windows (which used to use 'directory' anyway - pre 9x). Please stop saying 'folder'. As for your last command you don't even need the '/' just FYI."]},{"answer":"There is an ack tool that would do exactly what you are looking for.\n\nhttp://linux.die.net/man/1/ack\n\nack -i search_string folder_path/*\n\n\nYou may ignore -i for case sensitive search\n\nShare\nImprove this answer\nFollow\nedited Jul 13 '17 at 0:17\nDaniel\n3,4582\n2 gold badges\n32\n32 silver badges\n41\n41 bronze badges\nanswered Aug 17 '16 at 3:31\nPal\n8259\n9 silver badges\n21\n21 bronze badges","comments":["What is this adding to the existing answers? This was suggested more than three years ago already.","@fedorqui 1)no piping! 2)Use regular expressions 3)Get line numbers, file name with relative path, highlighted text etc. useful for editing after the search e.g \"vim +lineno path/file.cpp\" will get you right at the line no of interest. See the output of the command \"ack include\\|hpp\" that searches \"include\" or \"hpp\" keywords under my search folder and subfolders. I hope the point is clear. Here is the sample output(Can't show the keyword highlights with simple text) process/child.hpp 11:boost/process/child.hpp process/all.hpp 21:#include <boost/process/execute.hpp>"]},{"answer":"Use:\n\ngrep -c Your_Pattern *\n\n\nThis will report how many copies of your pattern are there in each of the files in the current directory.\n\nShare\nImprove this answer\nFollow\nedited May 25 '17 at 0:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 7 '17 at 7:59\nDr_Hope\n1,64414\n14 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"To search for the string and output just that line with the search string:\n\nfor i in $(find /path/of/target/directory -type f); do grep -i \"the string to look for\" \"$i\"; done\n\n\ne.g.:\n\nfor i in $(find /usr/share/applications -type f); \\\ndo grep -i \"web browser\" \"$i\"; done\n\n\nTo display filename containing the search string:\n\nfor i in $(find /path/of/target/directory -type f); do if grep -i \"the string to look for\" \"$i\" > /dev/null; then echo \"$i\"; fi; done;\n\n\ne.g.:\n\nfor i in $(find /usr/share/applications -type f); \\\ndo if grep -i \"web browser\" \"$i\" > /dev/null; then echo \"$i\"; \\\nfi; done;\n\nShare\nImprove this answer\nFollow\nanswered Jan 25 '14 at 11:08\nuser3124504","comments":["I see only downside compared to using find … -exec grep 'str' {} \\; (if you have to use find at all).","This would break horribly if any of the files found by find contained spaces .. you could end up grepping the wrong files and/or missing the right files altogether. Just use find ... -exec grep ... if you have a need to use find .. but in this case a grep -r ... suffices.","what is the point of using a loop over the results of find to then grep? This gets unnecessarily complicated."]},{"answer":"All previous answers suggest grep and find. But there is another way: Use Midnight Commander\n\nIt is a free utility (30 years old, proven by time) which is visual without being GUI. It has tons of functions, and finding files is just one of them.\n\nShare\nImprove this answer\nFollow\nedited Apr 24 '19 at 15:28\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 22 '17 at 16:27\nPeter M. - stands for Monica\n97811\n11 silver badges\n18\n18 bronze badges","comments":["ranger would be in the same idea"]},{"answer":"The below command will work fine for this approach:\n\nfind ./ -name \"file_pattern_name\"  -exec grep -r \"pattern\" {} \\;\n\nShare\nImprove this answer\nFollow\nedited Feb 16 '16 at 23:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 12 '15 at 6:14\nPradeep Goswami\n1,3861\n1 gold badge\n13\n13 silver badges\n21\n21 bronze badges","comments":["what is the point of using find and then grep -r? They are meant for the same, so this is redundant.","ohh!! corrected , Actually find is for running grep on filtered files and not all, thanks","still, this does not make any sense, you can filter with find."]},{"answer":"You can use below command as you don't want file name but you want to search from all the files. Here are i am capturing \"TEXT\" form All the log files making sure that file name is not printed\n\ngrep -e TEXT *.log | cut -d' ' --complement -s -f1\n\n\ngrep with -e option is quite quick compared to other option as it is for PATTERN match\n\nShare\nImprove this answer\nFollow\nedited Jul 10 '18 at 8:52\nanswered Jun 26 '15 at 11:31\nMitul Patel\n1992\n2 silver badges\n5\n5 bronze badges","comments":["Personally I think you should remove the # because other than comments that typically implies something - and you shouldn't be root unless you absolutely have to be. Even so you needn't have the prompt surely? Call this petty but I have seen people many times over the years simply copy and paste and do things without truly understanding it. Not saying any will here but still.. Just a thought.","Better way use find + grep stackoverflow.com/a/51023211/7918560"]}]},{"id":"14220321","href":"https://stackoverflow.com/questions/14220321/how-to-return-the-response-from-an-asynchronous-call","title":"How to return the response from an asynchronous call","description":"\n                \nI have a function foo which makes an asynchronous request. How can I return the response/result from foo?\nI am trying to return the value from the callback, as well as assigning the result to a local variable inside the function and returning that one, but none of those ways actually return the response (they all return undefined or whatever the initial value of the variable result is).\nExample using jQuery's ajax function:\nfunction foo() {\n    var result;\n\n    $.ajax({\n        url: '...',\n        success: function(response) {\n            result = response;\n            // return response; // <- I tried that one as well\n        }\n    });\n\n    return result; // It always returns `undefined`\n}\n\nExample using Node.js:\nfunction foo() {\n    var result;\n\n    fs.readFile(\"path/to/file\", function(err, data) {\n        result = data;\n        // return data; // <- I tried that one as well\n    });\n\n    return result; // It always returns `undefined`\n}\n\nExample using the then block of a promise:\nfunction foo() {\n    var result;\n\n    fetch(url).then(function(response) {\n        result = response;\n        // return response; // <- I tried that one as well\n    });\n\n    return result; // It always returns `undefined`\n}\n\n    ","questionComments":[],"answers":[{"answer":"→ For a more general explanation of asynchronous behaviour with different examples, see Why is my variable unaltered after I modify it inside of a function? - Asynchronous code reference\n\n→ If you already understand the problem, skip to the possible solutions below.\n\nThe problem\n\nThe A in Ajax stands for asynchronous. That means sending the request (or rather receiving the response) is taken out of the normal execution flow. In your example, $.ajax returns immediately and the next statement, return result;, is executed before the function you passed as success callback was even called.\n\nHere is an analogy which hopefully makes the difference between synchronous and asynchronous flow clearer:\n\nSynchronous\n\nImagine you make a phone call to a friend and ask him to look something up for you. Although it might take a while, you wait on the phone and stare into space, until your friend gives you the answer that you needed.\n\nThe same is happening when you make a function call containing \"normal\" code:\n\nfunction findItem() {\n    var item;\n    while(item_not_found) {\n        // search\n    }\n    return item;\n}\n\nvar item = findItem();\n\n// Do something with item\ndoSomethingElse();\n\n\nEven though findItem might take a long time to execute, any code coming after var item = findItem(); has to wait until the function returns the result.\n\nAsynchronous\n\nYou call your friend again for the same reason. But this time you tell him that you are in a hurry and he should call you back on your mobile phone. You hang up, leave the house, and do whatever you planned to do. Once your friend calls you back, you are dealing with the information he gave to you.\n\nThat's exactly what's happening when you do an Ajax request.\n\nfindItem(function(item) {\n    // Do something with the item\n});\ndoSomethingElse();\n\n\nInstead of waiting for the response, the execution continues immediately and the statement after the Ajax call is executed. To get the response eventually, you provide a function to be called once the response was received, a callback (notice something? call back ?). Any statement coming after that call is executed before the callback is called.\n\nSolution(s)\n\nEmbrace the asynchronous nature of JavaScript! While certain asynchronous operations provide synchronous counterparts (so does \"Ajax\"), it's generally discouraged to use them, especially in a browser context.\n\nWhy is it bad do you ask?\n\nJavaScript runs in the UI thread of the browser and any long-running process will lock the UI, making it unresponsive. Additionally, there is an upper limit on the execution time for JavaScript and the browser will ask the user whether to continue the execution or not.\n\nAll of this results in a really bad user experience. The user won't be able to tell whether everything is working fine or not. Furthermore, the effect will be worse for users with a slow connection.\n\nIn the following we will look at three different solutions that are all building on top of each other:\n\nPromises with async/await (ES2017+, available in older browsers if you use a transpiler or regenerator)\nCallbacks (popular in node)\nPromises with then() (ES2015+, available in older browsers if you use one of the many promise libraries)\n\nAll three are available in current browsers, and node 7+.\n\nES2017+: Promises with async/await\n\nThe ECMAScript version released in 2017 introduced syntax-level support for asynchronous functions. With the help of async and await, you can write asynchronous in a \"synchronous style\". The code is still asynchronous, but it's easier to read/understand.\n\nasync/await builds on top of promises: an async function always returns a promise. await \"unwraps\" a promise and either result in the value the promise was resolved with or throws an error if the promise was rejected.\n\nImportant: You can only use await inside an async function. Right now, top-level await isn't yet supported, so you might have to make an async IIFE (Immediately Invoked Function Expression) to start an async context.\n\nYou can read more about async and await on MDN.\n\nHere is an example that elaborates the delay function findItem() above:\n\n// Using 'superagent' which will return a promise.\nvar superagent = require('superagent')\n\n// This is isn't declared as `async` because it already returns a promise\nfunction delay() {\n  // `delay` returns a promise\n  return new Promise(function(resolve, reject) {\n    // Only `delay` is able to resolve or reject the promise\n    setTimeout(function() {\n      resolve(42); // After 3 seconds, resolve the promise with value 42\n    }, 3000);\n  });\n}\n\nasync function getAllBooks() {\n  try {\n    // GET a list of book IDs of the current user\n    var bookIDs = await superagent.get('/user/books');\n    // wait for 3 seconds (just for the sake of this example)\n    await delay();\n    // GET information about each book\n    return await superagent.get('/books/ids='+JSON.stringify(bookIDs));\n  } catch(error) {\n    // If any of the awaited promises was rejected, this catch block\n    // would catch the rejection reason\n    return null;\n  }\n}\n\n// Start an IIFE to use `await` at the top level\n(async function(){\n  let books = await getAllBooks();\n  console.log(books);\n})();\n\n\nCurrent browser and node versions support async/await. You can also support older environments by transforming your code to ES5 with the help of regenerator (or tools that use regenerator, such as Babel).\n\nLet functions accept callbacks\n\nA callback is when function 1 is passed to function 2. Function 2 can call function 1 whenever it is ready. In the context of an asynchronous process, the callback will be called whenever the asynchronous process is done. Usually, the result is passed to the callback.\n\nIn the example of the question, you can make foo accept a callback and use it as success callback. So this\n\nvar result = foo();\n// Code that depends on 'result'\n\n\nbecomes\n\nfoo(function(result) {\n    // Code that depends on 'result'\n});\n\n\nHere we defined the function \"inline\" but you can pass any function reference:\n\nfunction myCallback(result) {\n    // Code that depends on 'result'\n}\n\nfoo(myCallback);\n\n\nfoo itself is defined as follows:\n\nfunction foo(callback) {\n    $.ajax({\n        // ...\n        success: callback\n    });\n}\n\n\ncallback will refer to the function we pass to foo when we call it and we pass it on to success. I.e. once the Ajax request is successful, $.ajax will call callback and pass the response to the callback (which can be referred to with result, since this is how we defined the callback).\n\nYou can also process the response before passing it to the callback:\n\nfunction foo(callback) {\n    $.ajax({\n        // ...\n        success: function(response) {\n            // For example, filter the response\n            callback(filtered_response);\n        }\n    });\n}\n\n\nIt's easier to write code using callbacks than it may seem. After all, JavaScript in the browser is heavily event-driven (DOM events). Receiving the Ajax response is nothing else but an event. Difficulties could arise when you have to work with third-party code, but most problems can be solved by just thinking through the application flow.\n\nES2015+: Promises with then()\n\nThe Promise API is a new feature of ECMAScript 6 (ES2015), but it has good browser support already. There are also many libraries which implement the standard Promises API and provide additional methods to ease the use and composition of asynchronous functions (e.g., bluebird).\n\nPromises are containers for future values. When the promise receives the value (it is resolved) or when it is canceled (rejected), it notifies all of its \"listeners\" who want to access this value.\n\nThe advantage over plain callbacks is that they allow you to decouple your code and they are easier to compose.\n\nHere is an example of using a promise:\n\nfunction delay() {\n  // `delay` returns a promise\n  return new Promise(function(resolve, reject) {\n    // Only `delay` is able to resolve or reject the promise\n    setTimeout(function() {\n      resolve(42); // After 3 seconds, resolve the promise with value 42\n    }, 3000);\n  });\n}\n\ndelay()\n  .then(function(v) { // `delay` returns a promise\n    console.log(v); // Log the value once it is resolved\n  })\n  .catch(function(v) {\n    // Or do something else if it is rejected\n    // (it would not happen in this example, since `reject` is not called).\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }\n Run code snippetExpand snippet\n\nApplied to our Ajax call we could use promises like this:\n\nfunction ajax(url) {\n  return new Promise(function(resolve, reject) {\n    var xhr = new XMLHttpRequest();\n    xhr.onload = function() {\n      resolve(this.responseText);\n    };\n    xhr.onerror = reject;\n    xhr.open('GET', url);\n    xhr.send();\n  });\n}\n\najax(\"https://jsonplaceholder.typicode.com/todos/1\")\n  .then(function(result) {\n    console.log(result); // Code depending on result\n  })\n  .catch(function() {\n    // An error occurred\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }\n Run code snippetExpand snippet\n\nDescribing all the advantages that promise offer is beyond the scope of this answer, but if you write new code, you should seriously consider them. They provide a great abstraction and separation of your code.\n\nMore information about promises: HTML5 rocks - JavaScript Promises.\n\nSide note: jQuery's deferred objects\n\nDeferred objects are jQuery's custom implementation of promises (before the Promise API was standardized). They behave almost like promises but expose a slightly different API.\n\nEvery Ajax method of jQuery already returns a \"deferred object\" (actually a promise of a deferred object) which you can just return from your function:\n\nfunction ajax() {\n    return $.ajax(...);\n}\n\najax().done(function(result) {\n    // Code depending on result\n}).fail(function() {\n    // An error occurred\n});\n\nSide note: Promise gotchas\n\nKeep in mind that promises and deferred objects are just containers for a future value, they are not the value itself. For example, suppose you had the following:\n\nfunction checkPassword() {\n    return $.ajax({\n        url: '/password',\n        data: {\n            username: $('#username').val(),\n            password: $('#password').val()\n        },\n        type: 'POST',\n        dataType: 'json'\n    });\n}\n\nif (checkPassword()) {\n    // Tell the user they're logged in\n}\n\n\nThis code misunderstands the above asynchronous issues. Specifically, $.ajax() doesn't freeze the code while it checks the '/password' page on your server - it sends a request to the server and while it waits, it immediately returns a jQuery Ajax Deferred object, not the response from the server. That means the if statement is going to always get this Deferred object, treat it as true, and proceed as though the user is logged in. Not good.\n\nBut the fix is easy:\n\ncheckPassword()\n.done(function(r) {\n    if (r) {\n        // Tell the user they're logged in\n    } else {\n        // Tell the user their password was bad\n    }\n})\n.fail(function(x) {\n    // Tell the user something bad happened\n});\n\nNot recommended: Synchronous \"Ajax\" calls\n\nAs I mentioned, some(!) asynchronous operations have synchronous counterparts. I don't advocate their use, but for completeness' sake, here is how you would perform a synchronous call:\n\nWithout jQuery\n\nIf you directly use a XMLHttpRequest object, pass false as third argument to .open.\n\njQuery\n\nIf you use jQuery, you can set the async option to false. Note that this option is deprecated since jQuery 1.8. You can then either still use a success callback or access the responseText property of the jqXHR object:\n\nfunction foo() {\n    var jqXHR = $.ajax({\n        //...\n        async: false\n    });\n    return jqXHR.responseText;\n}\n\n\nIf you use any other jQuery Ajax method, such as $.get, $.getJSON, etc., you have to change it to $.ajax (since you can only pass configuration parameters to $.ajax).\n\nHeads up! It is not possible to make a synchronous JSONP request. JSONP by its very nature is always asynchronous (one more reason to not even consider this option).\n\nShare\nImprove this answer\nFollow\nedited May 7 at 10:09\nHenke\n1,8342\n2 gold badges\n11\n11 silver badges\n23\n23 bronze badges\nanswered Jan 8 '13 at 17:06\nFelix Kling\n718k163\n163 gold badges\n1015\n1015 silver badges\n1081\n1081 bronze badges","comments":["@Pommy: If you want to use jQuery, you have to include it. Please refer to docs.jquery.com/Tutorials:Getting_Started_with_jQuery.","In Solution 1, sub jQuery, I could not understand this line: If you use any other jQuery AJAX method, such as $.get, $.getJSON, etc., you have them to $.ajax. (Yes, I realize my nick is a tad ironic in this case)","@gibberish: Mmmh, I don't know how it can be made clearer. Do you see how foo is called and a function is passed to it (foo(function(result) {....});)? result is used inside this function and is the response of the Ajax request. To refer to this function, the first parameter of foo is called callback and assigned to success instead of an anonymous function. So, $.ajax will call callback when the request was successful. I tried to explain it a bit more.","The Chat for this question is dead so I'm not sure where to propose outlined changes, but I propose: 1) Change the synchronous part to a simple discussion of why it's bad with no code example of how to do it. 2) Remove/merge the callback examples to only show the more flexible Deferred approach, which I think may also be a little easier to follow for those learning Javascript.","@Jessi: I think you misunderstood that part of the answer. You cannot use $.getJSON if you want the Ajax request to be synchronous. However, you should not event want the request to be synchronous, so that doesn't apply. You should be using callbacks or promises to handle the response, as it is explained earlier in the answer."]},{"answer":"If you're not using jQuery in your code, this answer is for you\n\nYour code should be something along the lines of this:\n\nfunction foo() {\n    var httpRequest = new XMLHttpRequest();\n    httpRequest.open('GET', \"/echo/json\");\n    httpRequest.send();\n    return httpRequest.responseText;\n}\n\nvar result = foo(); // Always ends up being 'undefined'\n\n\nFelix Kling did a fine job writing an answer for people using jQuery for AJAX, but I've decided to provide an alternative for people who aren't.\n\n(Note, for those using the new fetch API, Angular or promises I've added another answer below)\n\nWhat you're facing\n\nThis is a short summary of \"Explanation of the problem\" from the other answer, if you're not sure after reading this, read that.\n\nThe A in AJAX stands for asynchronous. That means sending the request (or rather receiving the response) is taken out of the normal execution flow. In your example, .send returns immediately and the next statement, return result;, is executed before the function you passed as success callback was even called.\n\nThis means when you're returning, the listener you've defined did not execute yet, which means the value you're returning has not been defined.\n\nHere is a simple analogy:\n\nfunction getFive(){\n    var a;\n    setTimeout(function(){\n         a=5;\n    },10);\n    return a;\n}\n\n\n(Fiddle)\n\nThe value of a returned is undefined since the a=5 part has not executed yet. AJAX acts like this, you're returning the value before the server got the chance to tell your browser what that value is.\n\nOne possible solution to this problem is to code re-actively , telling your program what to do when the calculation completed.\n\nfunction onComplete(a){ // When the code completes, do this\n    alert(a);\n}\n\nfunction getFive(whenDone){\n    var a;\n    setTimeout(function(){\n         a=5;\n         whenDone(a);\n    },10);\n}\n\n\nThis is called CPS. Basically, we're passing getFive an action to perform when it completes, we're telling our code how to react when an event completes (like our AJAX call, or in this case the timeout).\n\nUsage would be:\n\ngetFive(onComplete);\n\n\nWhich should alert \"5\" to the screen. (Fiddle).\n\nPossible solutions\n\nThere are basically two ways how to solve this:\n\nMake the AJAX call synchronous (let’s call it SJAX).\nRestructure your code to work properly with callbacks.\n1. Synchronous AJAX - Don't do it!!\n\nAs for synchronous AJAX, don't do it! Felix's answer raises some compelling arguments about why it's a bad idea. To sum it up, it'll freeze the user's browser until the server returns the response and create a very bad user experience. Here is another short summary taken from MDN on why:\n\nXMLHttpRequest supports both synchronous and asynchronous communications. In general, however, asynchronous requests should be preferred to synchronous requests for performance reasons.\n\nIn short, synchronous requests block the execution of code... ...this can cause serious issues...\n\nIf you have to do it, you can pass a flag. Here is how:\n\nvar request = new XMLHttpRequest();\nrequest.open('GET', 'yourURL', false);  // `false` makes the request synchronous\nrequest.send(null);\n\nif (request.status === 200) {// That's HTTP for 'ok'\n  console.log(request.responseText);\n}\n\n2. Restructure code\n\nLet your function accept a callback. In the example code foo can be made to accept a callback. We'll be telling our code how to react when foo completes.\n\nSo:\n\nvar result = foo();\n// Code that depends on `result` goes here\n\n\nBecomes:\n\nfoo(function(result) {\n    // Code that depends on `result`\n});\n\n\nHere we passed an anonymous function, but we could just as easily pass a reference to an existing function, making it look like:\n\nfunction myHandler(result) {\n    // Code that depends on `result`\n}\nfoo(myHandler);\n\n\nFor more details on how this sort of callback design is done, check Felix's answer.\n\nNow, let's define foo itself to act accordingly\n\nfunction foo(callback) {\n    var httpRequest = new XMLHttpRequest();\n    httpRequest.onload = function(){ // When the request is loaded\n       callback(httpRequest.responseText);// We're calling our method\n    };\n    httpRequest.open('GET', \"/echo/json\");\n    httpRequest.send();\n}\n\n\n(fiddle)\n\nWe have now made our foo function accept an action to run when the AJAX completes successfully. We can extend this further by checking if the response status is not 200 and acting accordingly (create a fail handler and such). Effectively it is solving our issue.\n\nIf you're still having a hard time understanding this, read the AJAX getting started guide at MDN.\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 11:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 29 '13 at 23:30\nBenjamin Gruenbaum\n250k80\n80 gold badges\n477\n477 silver badges\n479\n479 bronze badges","comments":["\"synchronous requests block the execution of code and can leak memory and events\" how can a synchronous request leak memory?","@MatthewG I've added a bounty on it in this question, I'll see what I can fish out. I'm removing the quote from the answer in the mean time.","Just for the reference, XHR 2 allows us to use the onload handler, which only fires when readyState is 4. Of course, it's not supported in IE8. (iirc, may need confirmation.)","Your explanation of how to pass an anonymous function as a callback is valid but misleading. The example var bar = foo(); is asking for a variable to be defined, whereas your suggested foo(functim() {}); doesn't define bar","I can see why this might be a little misleading, but after months of not knowing the answer to this question, I finally understand what's going on and how to avoid it (you just want to make your async functions not use any public variables and pass their return data to functions with their own private variables). I have no idea why this answer lead me to this/my solution, but it definitely did. Thanks man! I also realize this question may not be exactly asking what I'm describing, but it's at least related/similar."]},{"answer":"XMLHttpRequest 2 (first of all, read the answers from Benjamin Gruenbaum and Felix Kling)\n\nIf you don't use jQuery and want a nice short XMLHttpRequest 2 which works in the modern browsers and also in the mobile browsers, I suggest to use it this way:\n\nfunction ajax(a, b, c){ // URL, callback, just a placeholder\n  c = new XMLHttpRequest;\n  c.open('GET', a);\n  c.onload = b;\n  c.send()\n}\n\n\nAs you can see:\n\nIt's shorter than all other functions Listed.\nThe callback is set directly (so no extra unnecessary closures).\nIt uses the new onload (so you don't have to check for readystate && status)\nThere are some other situations, which I don't remember, that make the XMLHttpRequest 1 annoying.\n\nThere are two ways to get the response of this Ajax call (three using the XMLHttpRequest var name):\n\nThe simplest:\n\nthis.response\n\n\nOr if for some reason you bind() the callback to a class:\n\ne.target.response\n\n\nExample:\n\nfunction callback(e){\n  console.log(this.response);\n}\najax('URL', callback);\n\n\nOr (the above one is better anonymous functions are always a problem):\n\najax('URL', function(e){console.log(this.response)});\n\n\nNothing easier.\n\nNow some people will probably say that it's better to use onreadystatechange or the even the XMLHttpRequest variable name. That's wrong.\n\nCheck out XMLHttpRequest advanced features.\n\nIt supported all *modern browsers. And I can confirm as I have been using this approach since XMLHttpRequest 2 was created. I never had any type of problem in any browsers I used.\n\nonreadystatechange is only useful if you want to get the headers on state 2.\n\nUsing the XMLHttpRequest variable name is another big error as you need to execute the callback inside the onload/oreadystatechange closures, or else you lost it.\n\nNow if you want something more complex using POST and FormData you can easily extend this function:\n\nfunction x(a, b, e, d, c){ // URL, callback, method, formdata or {key:val},placeholder\n  c = new XMLHttpRequest;\n  c.open(e||'get', a);\n  c.onload = b;\n  c.send(d||null)\n}\n\n\nAgain ... it's a very short function, but it does GET and POST.\n\nExamples of usage:\n\nx(url, callback); // By default it's GET so no need to set\nx(url, callback, 'post', {'key': 'val'}); // No need to set POST data\n\n\nOr pass a full form element (document.getElementsByTagName('form')[0]):\n\nvar fd = new FormData(form);\nx(url, callback, 'post', fd);\n\n\nOr set some custom values:\n\nvar fd = new FormData();\nfd.append('key', 'val')\nx(url, callback, 'post', fd);\n\n\nAs you can see, I didn't implement sync... it's a bad thing.\n\nHaving said that ... why don't we do it the easy way?\n\nAs mentioned in the comment, the use of error && synchronous does completely break the point of the answer. Which is a nice short way to use Ajax in the proper way?\n\nError handler\n\nfunction x(a, b, e, d, c){ // URL, callback, method, formdata or {key:val}, placeholder\n  c = new XMLHttpRequest;\n  c.open(e||'get', a);\n  c.onload = b;\n  c.onerror = error;\n  c.send(d||null)\n}\n\nfunction error(e){\n  console.log('--Error--', this.type);\n  console.log('this: ', this);\n  console.log('Event: ', e)\n}\nfunction displayAjax(e){\n  console.log(e, this);\n}\nx('WRONGURL', displayAjax);\n\n\nIn the above script, you have an error handler which is statically defined, so it does not compromise the function. The error handler can be used for other functions too.\n\nBut to really get out an error, the only way is to write a wrong URL in which case every browser throws an error.\n\nError handlers are maybe useful if you set custom headers, set the responseType to blob array buffer, or whatever...\n\nEven if you pass 'POSTAPAPAP' as the method it won't throw an error.\n\nEven if you pass 'fdggdgilfdghfldj' as formdata it won't throw an error.\n\nIn the first case the error is inside the displayAjax() under this.statusText as Method not Allowed.\n\nIn the second case, it simply works. You have to check at the server side if you passed the right post data.\n\nCross-domain not allowed throws an error automatically.\n\nIn the error response, there aren't any error codes.\n\nThere is only the this.type which is set to error.\n\nWhy add an error handler if you totally don't have any control over errors? Most of the errors are returned inside this in the callback function displayAjax().\n\nSo: There isn't any need for error checks if you're able to copy and paste the URL properly. ;)\n\nPS: As the first test I wrote x('x', displayAjax)..., and it totally got a response...??? So I checked the folder where the HTML is located, and there was a file called 'x.xml'. So even if you forget the extension of your file XMLHttpRequest 2 WILL FIND IT. I LOL'd\n\nRead a file synchronous\n\nDon't do that.\n\nIf you want to block the browser for a while load a nice big .txt file synchronous.\n\nfunction omg(a, c){ // URL\n  c = new XMLHttpRequest;\n  c.open('GET', a, true);\n  c.send();\n  return c; // Or c.response\n}\n\n\nNow you can do\n\n var res = omg('thisIsGonnaBlockThePage.txt');\n\n\nThere is no other way to do this in a non-asynchronous way. (Yeah, with setTimeout loop... but seriously?)\n\nAnother point is... if you work with APIs or just your own list's files or whatever you always use different functions for each request...\n\nOnly if you have a page where you load always the same XML/JSON or whatever you need only one function. In that case, modify a little the Ajax function and replace b with your special function.\n\nThe functions above are for basic use.\n\nIf you want to extend the function...\n\nYes, you can.\n\nI'm using a lot of APIs and one of the first functions I integrate into every HTML page is the first Ajax function in this answer, with GET only...\n\nBut you can do a lot of stuff with XMLHttpRequest 2:\n\nI made a download manager (using ranges on both sides with resume, filereader, and filesystem), various image resizers converters using canvas, populate web SQL databases with base64images and much more...\n\nBut in these cases you should create a function only for that purpose... sometimes you need a blob, array buffers, you can set headers, override mimetype and there is a lot more...\n\nBut the question here is how to return an Ajax response... (I added an easy way.)\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 11:57\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 19 '13 at 8:06\ncocco\n15.4k6\n6 gold badges\n54\n54 silver badges\n73\n73 bronze badges","comments":["While this answer is nice (And we all love XHR2 and posting file data and multipart data is totally awesome) - this shows syntactic sugar for posting XHR with JavaScript - you might want to put this in a blog post (I'd like it) or even in a library (not sure about the name x, ajax or xhr might be nicer :)). I don't see how it addresses returning the response from an AJAX call. (someone could still do var res = x(\"url\") and not understand why it doesn't work ;)). On a side note - it would be cool if you returned c from the method so users can hook on error etc.","2.ajax is meant to be async.. so NO var res=x('url').. That's the entire point of this question and answers :)","why is there a 'c' parameter in the functions, if on the first line you're overwriting whatever value it had? am i missing something?","You can use parameters as a placeholder to avoid writing multiple times \"var\"","@cocco So you wrote misleading, unreadable code in a SO answer in order to save a few keystrokes? Please don't do that."]},{"answer":"If you're using promises, this answer is for you.\n\nThis means AngularJS, jQuery (with deferred), native XHR's replacement (fetch), Ember.js, Backbone.js's save or any Node.js library that returns promises.\n\nYour code should be something along the lines of this:\n\nfunction foo() {\n    var data;\n    // Or $.get(...).then, or request(...).then, or query(...).then\n    fetch(\"/echo/json\").then(function(response){\n        data = response.json();\n    });\n    return data;\n}\n\nvar result = foo(); // 'result' is always undefined no matter what.\n\n\nFelix Kling did a fine job writing an answer for people using jQuery with callbacks for Ajax. I have an answer for native XHR. This answer is for generic usage of promises either on the frontend or backend.\n\nThe core issue\n\nThe JavaScript concurrency model in the browser and on the server with Node.js/io.js is asynchronous and reactive.\n\nWhenever you call a method that returns a promise, the then handlers are always executed asynchronously - that is, after the code below them that is not in a .then handler.\n\nThis means when you're returning data the then handler you've defined did not execute yet. This in turn means that the value you're returning has not been set to the correct value in time.\n\nHere is a simple analogy for the issue:\n\n    function getFive(){\n        var data;\n        setTimeout(function(){ // Set a timer for one second in the future\n           data = 5; // After a second, do this\n        }, 1000);\n        return data;\n    }\n    document.body.innerHTML = getFive(); // `undefined` here and not 5\n Run code snippetExpand snippet\n\nThe value of data is undefined since the data = 5 part has not executed yet. It will likely execute in a second, but by that time it is irrelevant to the returned value.\n\nSince the operation did not happen yet (Ajax, server call, I/O, and timer) you're returning the value before the request got the chance to tell your code what that value is.\n\nOne possible solution to this problem is to code re-actively, telling your program what to do when the calculation completed. Promises actively enable this by being temporal (time-sensitive) in nature.\n\nQuick recap on promises\n\nA Promise is a value over time. Promises have state. They start as pending with no value and can settle to:\n\nfulfilled meaning that the computation completed successfully.\nrejected meaning that the computation failed.\n\nA promise can only change states once after which it will always stay at the same state forever. You can attach then handlers to promises to extract their value and handle errors. then handlers allow chaining of calls. Promises are created by using APIs that return them. For example, the more modern Ajax replacement fetch or jQuery's $.get return promises.\n\nWhen we call .then on a promise and return something from it - we get a promise for the processed value. If we return another promise we'll get amazing things, but let's hold our horses.\n\nWith promises\n\nLet's see how we can solve the above issue with promises. First, let's demonstrate our understanding of promise states from above by using the Promise constructor for creating a delay function:\n\nfunction delay(ms){ // Takes amount of milliseconds\n    // Returns a new promise\n    return new Promise(function(resolve, reject){\n        setTimeout(function(){ // When the time is up,\n            resolve(); // change the promise to the fulfilled state\n        }, ms);\n    });\n}\n\n\nNow, after we converted setTimeout to use promises, we can use then to make it count:\n\nfunction delay(ms){ // Takes amount of milliseconds\n  // Returns a new promise\n  return new Promise(function(resolve, reject){\n    setTimeout(function(){ // When the time is up,\n      resolve(); // change the promise to the fulfilled state\n    }, ms);\n  });\n}\n\nfunction getFive(){\n  // We're RETURNING the promise. Remember, a promise is a wrapper over our value\n  return delay(100).then(function(){ // When the promise is ready,\n      return 5; // return the value 5. Promises are all about return values\n  })\n}\n// We _have_ to wrap it like this in the call site, and we can't access the plain value\ngetFive().then(function(five){\n   document.body.innerHTML = five;\n});\n Run code snippetExpand snippet\n\nBasically, instead of returning a value which we can't do because of the concurrency model - we're returning a wrapper for a value that we can unwrap with then. It's like a box you can open with then.\n\nApplying this\n\nThis stands the same for your original API call, you can:\n\nfunction foo() {\n    // RETURN the promise\n    return fetch(\"/echo/json\").then(function(response){\n        return response.json(); // Process it inside the `then`\n    });\n}\n\nfoo().then(function(response){\n    // Access the value inside the `then`\n})\n\n\nSo this works just as well. We've learned we can't return values from already asynchronous calls, but we can use promises and chain them to perform processing. We now know how to return the response from an asynchronous call.\n\nES2015 (ES6)\n\nES6 introduces generators which are functions that can return in the middle and then resume the point they were at. This is typically useful for sequences, for example:\n\nfunction* foo(){ // Notice the star. This is ES6, so new browsers, Nodes.js, and io.js only\n    yield 1;\n    yield 2;\n    while(true) yield 3;\n}\n\n\nIs a function that returns an iterator over the sequence 1,2,3,3,3,3,.... which can be iterated. While this is interesting on its own and opens room for a lot of possibility, there is one particular interesting case.\n\nIf the sequence we're producing is a sequence of actions rather than numbers - we can pause the function whenever an action is yielded and wait for it before we resume the function. So instead of a sequence of numbers, we need a sequence of future values - that is: promises.\n\nThis somewhat a tricky, but very powerful trick let’s us write asynchronous code in a synchronous manner. There are several \"runners\" that do this for you. Writing one is a short few lines of code, but it is beyond the scope of this answer. I'll be using Bluebird's Promise.coroutine here, but there are other wrappers like co or Q.async.\n\nvar foo = coroutine(function*(){\n    var data = yield fetch(\"/echo/json\"); // Notice the yield\n    // The code here only executes _after_ the request is done\n    return data.json(); // 'data' is defined\n});\n\n\nThis method returns a promise itself, which we can consume from other coroutines. For example:\n\nvar main = coroutine(function*(){\n   var bar = yield foo(); // Wait our earlier coroutine. It returns a promise\n   // The server call is done here, and the code below executes when done\n   var baz = yield fetch(\"/api/users/\" + bar.userid); // Depends on foo's result\n   console.log(baz); // Runs after both requests are done\n});\nmain();\n\nES2016 (ES7)\n\nIn ES7, this is further standardized. There are several proposals right now, but in all of them you can await promise. This is just \"sugar\" (nicer syntax) for the ES6 proposal above by adding the async and await keywords. Making the above example:\n\nasync function foo(){\n    var data = await fetch(\"/echo/json\"); // Notice the await\n    // code here only executes _after_ the request is done\n    return data.json(); // 'data' is defined\n}\n\n\nIt still returns a promise just the same :)\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 13:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 12 '15 at 2:22\nBenjamin Gruenbaum\n250k80\n80 gold badges\n477\n477 silver badges\n479\n479 bronze badges","comments":["This should be the accepted answer. +1 for async/await (although should we not return await data.json();?)","Such a great explanation.. Thank you sir"]},{"answer":"You are using Ajax incorrectly. The idea is not to have it return anything, but instead hand off the data to something called a callback function, which handles the data.\n\nThat is:\n\nfunction handleData( responseData ) {\n\n    // Do what you want with the data\n    console.log(responseData);\n}\n\n$.ajax({\n    url: \"hi.php\",\n    ...\n    success: function ( data, status, XHR ) {\n        handleData(data);\n    }\n});\n\n\nReturning anything in the submit handler will not do anything. You must instead either hand off the data, or do what you want with it directly inside the success function.\n\nShare\nImprove this answer\nFollow\nedited Nov 21 '15 at 14:07\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 23 '14 at 2:05\nNic\n2,6231\n1 gold badge\n11\n11 silver badges\n12\n12 bronze badges","comments":["This answer is completely semantic... your success method is just a callback within a callback. You could just have success: handleData and it would work.","And what if you want to return the \"responseData\" outside of \"handleData\" ... :) ... how will you do it ... ? ... cause a simple return will return it to the \"success\" callback of the ajax ... and not outside of \"handleData\" ...","@Jacques & @pesho hristov You missed this point. Submit handler is not the success method, it's the surrounding scope of $.ajax.","@travnik I didn't miss that. If you took the contents of handleData and put it in the success method it would act exactly the same...","This answer is SO clear and simple and saved my (hours!). Thank you. Would upvote 100 times if I could."]},{"answer":"I will answer with a horrible-looking, hand-drawn comic. The second image is the reason why result is undefined in your code example.\n\nShare\nImprove this answer\nFollow\nedited Aug 11 '16 at 17:12\nanswered Aug 11 '16 at 14:17\nJohannes Fahrenkrug\n38.9k18\n18 gold badges\n115\n115 silver badges\n155\n155 bronze badges","comments":["A picture is worth a thousand words, Person A - Ask's person B details to fix his car, in turn Person B - Makes Ajax Call and waits for response from server for car fixing details, when response is received, Ajax Success function calls the Person B function and passes the response as argument to it, Person A receives the answer.","Would be great if you added lines of code with each image to illustrate the concepts.","Meanwhile, the guy with the car is stuck on the side of the road. He requires the car is fixed before continuing. He is now alone on the side of the road waiting... He would rather be on the phone waiting for status changes but the mechanic would not do it... The mechanic said he has to get on with his job and can't simply hang out on the phone. Mechanic promised he would call him back as soon as he could. After about 4 hours, the guy gives up and calls Uber. - Example of timeout.","@barrypicker :-D Brilliant!","@FingLixon It's not a perfect comic by any stretch :-D. The 2nd image should illustrate what happens when you try to read a value too early (before a callback has occurred). The 3rd image illustrates setting up a callback method: The guy on the left basically IS the callback handler: He will be called with the information once it's available and can then do with it whatever he wants. I now think it was a bad idea to have TWO phone calls in this comic: The call to the shop and the call to the guy on the left. I should have simplified that, sorry about that."]},{"answer":"The simplest solution is to create a JavaScript function and call it for the Ajax success callback.\n\nfunction callServerAsync(){\n    $.ajax({\n        url: '...',\n        success: function(response) {\n\n            successCallback(response);\n        }\n    });\n}\n\nfunction successCallback(responseObj){\n    // Do something like read the response and show data\n    alert(JSON.stringify(responseObj)); // Only applicable to a JSON response\n}\n\nfunction foo(callback) {\n\n    $.ajax({\n        url: '...',\n        success: function(response) {\n           return callback(null, response);\n        }\n    });\n}\n\nvar result = foo(function(err, result){\n          if (!err)\n           console.log(result);\n});\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 12:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 18 '14 at 18:58\nHemant Bavle\n3,1371\n1 gold badge\n22\n22 silver badges\n28\n28 bronze badges","comments":["I don't know who voted it negative. But this is a work around which has worked in fact i used this approach to create a whole application. The jquery.ajax don't return data so its better to use the above approach. If it's wrong then please explain and suggest better way to do it.","Sorry, I forgot to leave a comment (I usually do!). I downvoted it. Downvotes don't indicate factual correctness or lack of, they indicate usefulness in the context or lack of. I don't find your answer useful given Felix's which already explains this only in much more detail. On a side note, why would you stringify the response if it's JSON?","ok.. @Benjamin i used stringify, to convert a JSON Object to string. And thanks for clarifying your point. Will keep in mind to post more elaborate answers.","And what if you want to return the \"responseObj\" outside of \"successCallback\" ... :) ... how will you do it ... ? ... cause a simple return will return it to the \"success\" callback of the ajax ... and not outside of \"successCallback\" ..."]},{"answer":"Angular 1\n\nPeople who are using AngularJS, can handle this situation using promises.\n\nHere it says,\n\nPromises can be used to unnest asynchronous functions and allows one to chain multiple functions together.\n\nYou can find a nice explanation here also.\n\nAn example found in documentation mentioned below.\n\n  promiseB = promiseA.then(\n    function onSuccess(result) {\n      return result + 1;\n    }\n    ,function onError(err) {\n      // Handle error\n    }\n  );\n\n // promiseB will be resolved immediately after promiseA is resolved\n // and its value will be the result of promiseA incremented by 1.\n\nAngular 2 and later\n\nIn Angular 2 with look at the following example, but its recommended to use observables with Angular 2.\n\n search(term: string) {\n     return this.http\n       .get(`https://api.spotify.com/v1/search?q=${term}&type=artist`)\n       .map((response) => response.json())\n       .toPromise();\n}\n\n\nYou can consume that in this way,\n\nsearch() {\n    this.searchService.search(this.searchField.value)\n      .then((result) => {\n    this.result = result.artists.items;\n  })\n  .catch((error) => console.error(error));\n}\n\n\nSee the original post here. But TypeScript does not support native ES6 Promises, if you want to use it, you might need plugin for that.\n\nAdditionally, here is the promises specification.\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 12:33\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 26 '14 at 8:11\nMaleen Abewardana\n11.5k3\n3 gold badges\n37\n37 silver badges\n38\n38 bronze badges","comments":["This does not explain how promises would solve this issue at all though.","jQuery and fetch methods both return promises as well. I would suggest revising your answer. Though jQuery's isn't quite the same (then is there, but catch isn't)."]},{"answer":"Most of the answers here give useful suggestions for when you have a single async operation, but sometimes, this comes up when you need to do an asynchronous operation for each entry in an array or other list-like structure. The temptation is to do this:\n\n// WRONG\nvar results = [];\ntheArray.forEach(function(entry) {\n    doSomethingAsync(entry, function(result) {\n        results.push(result);\n    });\n});\nconsole.log(results); // E.g., using them, returning them, etc.\n\n\nExample:\n\nShow code snippet\n\nThe reason that doesn't work is that the callbacks from doSomethingAsync haven't run yet by the time you're trying to use the results.\n\nSo, if you have an array (or list of some kind) and want to do async operations for each entry, you have two options: Do the operations in parallel (overlapping), or in series (one after another in sequence).\n\nParallel\n\nYou can start all of them and keep track of how many callbacks you're expecting, and then use the results when you've gotten that many callbacks:\n\nvar results = [];\nvar expecting = theArray.length;\ntheArray.forEach(function(entry, index) {\n    doSomethingAsync(entry, function(result) {\n        results[index] = result;\n        if (--expecting === 0) {\n            // Done!\n            console.log(\"Results:\", results); // E.g., using the results\n        }\n    });\n});\n\n\nExample:\n\nShow code snippet\n\n(We could do away with expecting and just use results.length === theArray.length, but that leaves us open to the possibility that theArray is changed while the calls are outstanding...)\n\nNotice how we use the index from forEach to save the result in results in the same position as the entry it relates to, even if the results arrive out of order (since async calls don't necessarily complete in the order in which they were started).\n\nBut what if you need to return those results from a function? As the other answers have pointed out, you can't; you have to have your function accept and call a callback (or return a Promise). Here's a callback version:\n\nfunction doSomethingWith(theArray, callback) {\n    var results = [];\n    var expecting = theArray.length;\n    theArray.forEach(function(entry, index) {\n        doSomethingAsync(entry, function(result) {\n            results[index] = result;\n            if (--expecting === 0) {\n                // Done!\n                callback(results);\n            }\n        });\n    });\n}\ndoSomethingWith(theArray, function(results) {\n    console.log(\"Results:\", results);\n});\n\n\nExample:\n\nShow code snippet\n\nOr here's a version returning a Promise instead:\n\nfunction doSomethingWith(theArray) {\n    return new Promise(function(resolve) {\n        var results = [];\n        var expecting = theArray.length;\n        theArray.forEach(function(entry, index) {\n            doSomethingAsync(entry, function(result) {\n                results[index] = result;\n                if (--expecting === 0) {\n                    // Done!\n                    resolve(results);\n                }\n            });\n        });\n    });\n}\ndoSomethingWith(theArray).then(function(results) {\n    console.log(\"Results:\", results);\n});\n\n\nOf course, if doSomethingAsync passed us errors, we'd use reject to reject the promise when we got an error.)\n\nExample:\n\nShow code snippet\n\n(Or alternately, you could make a wrapper for doSomethingAsync that returns a promise, and then do the below...)\n\nIf doSomethingAsync gives you a Promise, you can use Promise.all:\n\nfunction doSomethingWith(theArray) {\n    return Promise.all(theArray.map(function(entry) {\n        return doSomethingAsync(entry);\n    }));\n}\ndoSomethingWith(theArray).then(function(results) {\n    console.log(\"Results:\", results);\n});\n\n\nIf you know that doSomethingAsync will ignore a second and third argument, you can just pass it directly to map (map calls its callback with three arguments, but most people only use the first most of the time):\n\nfunction doSomethingWith(theArray) {\n    return Promise.all(theArray.map(doSomethingAsync));\n}\ndoSomethingWith(theArray).then(function(results) {\n    console.log(\"Results:\", results);\n});\n\n\nExample:\n\nShow code snippet\n\nNote that Promise.all resolves its promise with an array of the results of all of the promises you give it when they are all resolved, or rejects its promise when the first of the promises you give it rejects.\n\nSeries\n\nSuppose you don't want the operations to be in parallel? If you want to run them one after another, you need to wait for each operation to complete before you start the next. Here's an example of a function that does that and calls a callback with the result:\n\nfunction doSomethingWith(theArray, callback) {\n    var results = [];\n    doOne(0);\n    function doOne(index) {\n        if (index < theArray.length) {\n            doSomethingAsync(theArray[index], function(result) {\n                results.push(result);\n                doOne(index + 1);\n            });\n        } else {\n            // Done!\n            callback(results);\n        }\n    }\n}\ndoSomethingWith(theArray, function(results) {\n    console.log(\"Results:\", results);\n});\n\n\n(Since we're doing the work in series, we can just use results.push(result) since we know we won't get results out of order. In the above we could have used results[index] = result;, but in some of the following examples we don't have an index to use.)\n\nExample:\n\nShow code snippet\n\n(Or, again, build a wrapper for doSomethingAsync that gives you a promise and do the below...)\n\nIf doSomethingAsync gives you a Promise, if you can use ES2017+ syntax (perhaps with a transpiler like Babel), you can use an async function with for-of and await:\n\nasync function doSomethingWith(theArray) {\n    const results = [];\n    for (const entry of theArray) {\n        results.push(await doSomethingAsync(entry));\n    }\n    return results;\n}\ndoSomethingWith(theArray).then(results => {\n    console.log(\"Results:\", results);\n});\n\n\nExample:\n\nShow code snippet\n\nIf you can't use ES2017+ syntax (yet), you can use a variation on the \"Promise reduce\" pattern (this is more complex than the usual Promise reduce because we're not passing the result from one into the next, but instead gathering up their results in an array):\n\nfunction doSomethingWith(theArray) {\n    return theArray.reduce(function(p, entry) {\n        return p.then(function(results) {\n            return doSomethingAsync(entry).then(function(result) {\n                results.push(result);\n                return results;\n            });\n        });\n    }, Promise.resolve([]));\n}\ndoSomethingWith(theArray).then(function(results) {\n    console.log(\"Results:\", results);\n});\n\n\nExample:\n\nShow code snippet\n\n...which is less cumbersome with ES2015+ arrow functions:\n\nfunction doSomethingWith(theArray) {\n    return theArray.reduce((p, entry) => p.then(results => doSomethingAsync(entry).then(result => {\n        results.push(result);\n        return results;\n    })), Promise.resolve([]));\n}\ndoSomethingWith(theArray).then(results => {\n    console.log(\"Results:\", results);\n});\n\n\nExample:\n\nShow code snippet\n\nShare\nImprove this answer\nFollow\nedited May 6 at 11:25\nHenke\n1,8342\n2 gold badges\n11\n11 silver badges\n23\n23 bronze badges\nanswered May 3 '17 at 16:59\nT.J. Crowder\n897k166\n166 gold badges\n1650\n1650 silver badges\n1666\n1666 bronze badges","comments":["Could you explain how the if (--expecting === 0) part of the code works please? The callback version of your solution is working great for me, I just don't understand how, with that statement, you are checking the number of responses completed. Appreciate it's just lack of knowledge on my part. Is there an alternative way that check could be written?","@Sarah: expecting starts out with the value of array.length, which is how many requests we're going to make. We know the callback won't be called until all of those requests are started. In the callback, if (--expecting === 0) does this: 1. Decrements expecting (we've received a response, so we're expecting one fewer response) and if the value after the decrement is 0 (we're not expecting any more responses), we're done!","@Henke - I think it is indeed personal preference, and while normally I'd prefer to log raw data and let the console handle it, in this specific case I think you're right about the change. Thanks! :-)","Out of convenience for myself (and others?), adding a link to a related answer: How to make many asynchronous calls and wait for them all."]},{"answer":"Have a look at this example:\n\nvar app = angular.module('plunker', []);\n\napp.controller('MainCtrl', function($scope,$http) {\n\n    var getJoke = function(){\n        return $http.get('http://api.icndb.com/jokes/random').then(function(res){\n            return res.data.value;  \n        });\n    }\n\n    getJoke().then(function(res) {\n        console.log(res.joke);\n    });\n});\n\n\nAs you can see getJoke is returning a resolved promise (it is resolved when returning res.data.value). So you wait until the $http.get request is completed and then console.log(res.joke) is executed (as a normal asynchronous flow).\n\nThis is the plnkr:\n\nhttp://embed.plnkr.co/XlNR7HpCaIhJxskMJfSg/\n\nES6 way (async - await)\n\n(function(){\n  async function getJoke(){\n    let response = await fetch('http://api.icndb.com/jokes/random');\n    let data = await response.json();\n    return data.value;\n  }\n\n  getJoke().then((joke) => {\n    console.log(joke);\n  });\n})();\n\nShare\nImprove this answer\nFollow\nedited Nov 23 '18 at 12:19\nanswered Jun 2 '16 at 8:31\nFrancisco Carmona\n1,5711\n1 gold badge\n7\n7 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"This is one of the places which two-way data binding or store concept that's used in many new JavaScript frameworks will work great for you...\n\nSo if you are using Angular, React, or any other frameworks which do two-way data binding or store concept, this issue is simply fixed for you, so in easy words, your result is undefined at the first stage, so you have got result = undefined before you receive the data, then as soon as you get the result, it will be updated and get assigned to the new value which response of your Ajax call...\n\nBut how you can do it in pure JavaScript or jQuery for example as you asked in this question?\n\nYou can use a callback, promise and recently observable to handle it for you. For example, in promises we have some function like success() or then() which will be executed when your data is ready for you. The same with callback or the subscribe function on an observable.\n\nFor example, in your case which you are using jQuery, you can do something like this:\n\n$(document).ready(function(){\n    function foo() {\n        $.ajax({url: \"api/data\", success: function(data){\n            fooDone(data); // After we have data, we pass it to fooDone\n        }});\n    };\n\n    function fooDone(data) {\n        console.log(data); // fooDone has the data and console.log it\n    };\n\n    foo(); // The call happens here\n});\n\n\nFor more information, study promises and observables which are newer ways to do this async stuff.\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 13:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 24 '17 at 9:38\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":["This is fine at global scope, but in some module context you probably want to ensure right context for the callback e.g. $.ajax({url: \"api/data\", success: fooDone.bind(this)});","This is actually incorrect as React is one-way data binding","@MatthewBrent you are not wrong, but not right also, React props are object and if changed, they change throughout the application, but its not a way that React developer recommend to use it..."]},{"answer":"It's a very common issue we face while struggling with the 'mysteries' of JavaScript. Let me try demystifying this mystery today.\n\nLet's start with a simple JavaScript function:\n\nfunction foo(){\n    // Do something\n    return 'wohoo';\n}\n\nlet bar = foo(); // 'bar' is 'wohoo' here\n\n\nThat's a simple synchronous function call (where each line of code is 'finished with its job' before the next one in sequence), and the result is same as expected.\n\nNow let's add a bit of twist, by introducing a little delay in our function, so that all lines of code are not 'finished' in sequence. Thus, it will emulate the asynchronous behavior of the function:\n\nfunction foo(){\n    setTimeout( ()=> {\n        return 'wohoo';\n   }, 1000)\n}\n\nlet bar = foo() // 'bar' is undefined here\n\n\nSo there you go; that delay just broke the functionality we expected! But what exactly happened? Well, it's actually pretty logical if you look at the code.\n\nThe function foo(), upon execution, returns nothing (thus returned value is undefined), but it does start a timer, which executes a function after 1 second to return 'wohoo'. But as you can see, the value that's assigned to bar is the immediately returned stuff from foo(), which is nothing, i.e., just undefined.\n\nSo, how do we tackle this issue?\n\nLet's ask our function for a promise. Promise is really about what it means: it means that the function guarantees you to provide with any output it gets in future. So let's see it in action for our little problem above:\n\nfunction foo(){\n   return new Promise((resolve, reject) => { // I want foo() to PROMISE me something\n    setTimeout ( function(){\n      // Promise is RESOLVED, when the execution reaches this line of code\n       resolve('wohoo') // After 1 second, RESOLVE the promise with value 'wohoo'\n    }, 1000 )\n  })\n}\n\nlet bar;\nfoo().then( res => {\n    bar = res;\n    console.log(bar) // Will print 'wohoo'\n});\n\n\nThus, the summary is - to tackle the asynchronous functions like Ajax-based calls, etc., you can use a promise to resolve the value (which you intend to return). Thus, in short you resolve value instead of returning, in asynchronous functions.\n\nUPDATE (Promises with async/await)\n\nApart from using then/catch to work with promises, there exists one more approach. The idea is to recognize an asynchronous function and then wait for the promises to resolve, before moving to the next line of code. It's still just the promises under the hood, but with a different syntactical approach. To make things clearer, you can find a comparison below:\n\nthen/catch version:\nfunction saveUsers(){\n     getUsers()\n      .then(users => {\n         saveSomewhere(users);\n      })\n      .catch(err => {\n          console.error(err);\n       })\n }\n\nasync/await version:\n  async function saveUsers(){\n     try{\n        let users = await getUsers()\n        saveSomewhere(users);\n     }\n     catch(err){\n        console.error(err);\n     }\n  }\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 14:05\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 31 '17 at 20:12\nAnish K.\n1,9423\n3 gold badges\n14\n14 silver badges\n23\n23 bronze badges","comments":["is this still considered the best way to return a value from a promise or async/await?","@edwardsmarkf Personally I don't think there's a best way as such. I use promises with then/catch , async/await as well as generators for async portions of my code. It largely depends on the context of usage."]},{"answer":"Another approach to return a value from an asynchronous function, is to pass in an object that will store the result from the asynchronous function.\n\nHere is an example of the same:\n\nvar async = require(\"async\");\n\n// This wires up result back to the caller\nvar result = {};\nvar asyncTasks = [];\nasyncTasks.push(function(_callback){\n    // some asynchronous operation\n    $.ajax({\n        url: '...',\n        success: function(response) {\n            result.response = response;\n            _callback();\n        }\n    });\n});\n\nasync.parallel(asyncTasks, function(){\n    // result is available after performing asynchronous operation\n    console.log(result)\n    console.log('Done');\n});\n\n\nI am using the result object to store the value during the asynchronous operation. This allows the result be available even after the asynchronous job.\n\nI use this approach a lot. I would be interested to know how well this approach works where wiring the result back through consecutive modules is involved.\n\nShare\nImprove this answer\nFollow\nedited Dec 17 '16 at 12:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 2 '15 at 12:54\njsbisht\n7,2417\n7 gold badges\n42\n42 silver badges\n52\n52 bronze badges","comments":["There is nothing special about using an object here. It would work as well if you assigned he response directly to result. It works because you are reading the variable after the async function is complete."]},{"answer":"While promises and callbacks work fine in many situations, it is a pain in the rear to express something like:\n\nif (!name) {\n  name = async1();\n}\nasync2(name);\n\n\nYou'd end up going through async1; check if name is undefined or not and call the callback accordingly.\n\nasync1(name, callback) {\n  if (name)\n    callback(name)\n  else {\n    doSomething(callback)\n  }\n}\n\nasync1(name, async2)\n\n\nWhile it is okay in small examples it gets annoying when you have a lot of similar cases and error handling involved.\n\nFibers helps in solving the issue.\n\nvar Fiber = require('fibers')\n\nfunction async1(container) {\n  var current = Fiber.current\n  var result\n  doSomething(function(name) {\n    result = name\n    fiber.run()\n  })\n  Fiber.yield()\n  return result\n}\n\nFiber(function() {\n  var name\n  if (!name) {\n    name = async1()\n  }\n  async2(name)\n  // Make any number of async calls from here\n}\n\n\nYou can checkout the project here.\n\nShare\nImprove this answer\nFollow\nedited May 9 '16 at 13:02\nanswered Jan 25 '16 at 17:43\nrohithpr\n4,9972\n2 gold badges\n28\n28 silver badges\n55\n55 bronze badges","comments":["@recurf - It's not my project. You could try using their issue tracker.","is this similar to generator functions? developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/…*","Is this still relevant?","You can make use of async-await if you're using some of the newest versions of node. If someone is stuck with older versions they can use this method."]},{"answer":"The following example I have written shows how to\n\nHandle asynchronous HTTP calls;\nWait for response from each API call;\nUse Promise pattern;\nUse Promise.all pattern to join multiple HTTP calls;\n\nThis working example is self-contained. It will define a simple request object that uses the window XMLHttpRequest object to make calls. It will define a simple function to wait for a bunch of promises to be completed.\n\nContext. The example is querying the Spotify Web API endpoint in order to search for playlist objects for a given set of query strings:\n\n[\n \"search?type=playlist&q=%22doom%20metal%22\",\n \"search?type=playlist&q=Adele\"\n]\n\n\nFor each item, a new Promise will fire a block - ExecutionBlock, parse the result, schedule a new set of promises based on the result array, that is a list of Spotify user objects and execute the new HTTP call within the ExecutionProfileBlock asynchronously.\n\nYou can then see a nested Promise structure, that lets you spawn multiple and completely asynchronous nested HTTP calls, and join the results from each subset of calls through Promise.all.\n\nNOTE Recent Spotify search APIs will require an access token to be specified in the request headers:\n\n-H \"Authorization: Bearer {your access token}\" \n\n\nSo, you to run the following example you need to put your access token in the request headers:\n\nvar spotifyAccessToken = \"YourSpotifyAccessToken\";\nvar console = {\n    log: function(s) {\n        document.getElementById(\"console\").innerHTML += s + \"<br/>\"\n    }\n}\n\n// Simple XMLHttpRequest\n// based on https://davidwalsh.name/xmlhttprequest\nSimpleRequest = {\n    call: function(what, response) {\n        var request;\n        if (window.XMLHttpRequest) { // Mozilla, Safari, ...\n            request = new XMLHttpRequest();\n        } else if (window.ActiveXObject) { // Internet Explorer\n            try {\n                request = new ActiveXObject('Msxml2.XMLHTTP');\n            }\n            catch (e) {\n                try {\n                  request = new ActiveXObject('Microsoft.XMLHTTP');\n                } catch (e) {}\n            }\n        }\n\n        // State changes\n        request.onreadystatechange = function() {\n            if (request.readyState === 4) { // Done\n                if (request.status === 200) { // Complete\n                    response(request.responseText)\n                }\n                else\n                    response();\n            }\n        }\n        request.open('GET', what, true);\n        request.setRequestHeader(\"Authorization\", \"Bearer \" + spotifyAccessToken);\n        request.send(null);\n    }\n}\n\n//PromiseAll\nvar promiseAll = function(items, block, done, fail) {\n    var self = this;\n    var promises = [],\n                   index = 0;\n    items.forEach(function(item) {\n        promises.push(function(item, i) {\n            return new Promise(function(resolve, reject) {\n                if (block) {\n                    block.apply(this, [item, index, resolve, reject]);\n                }\n            });\n        }(item, ++index))\n    });\n    Promise.all(promises).then(function AcceptHandler(results) {\n        if (done) done(results);\n    }, function ErrorHandler(error) {\n        if (fail) fail(error);\n    });\n}; //promiseAll\n\n// LP: deferred execution block\nvar ExecutionBlock = function(item, index, resolve, reject) {\n    var url = \"https://api.spotify.com/v1/\"\n    url += item;\n    console.log( url )\n    SimpleRequest.call(url, function(result) {\n        if (result) {\n\n            var profileUrls = JSON.parse(result).playlists.items.map(function(item, index) {\n                return item.owner.href;\n            })\n            resolve(profileUrls);\n        }\n        else {\n            reject(new Error(\"call error\"));\n        }\n    })\n}\n\narr = [\n    \"search?type=playlist&q=%22doom%20metal%22\",\n    \"search?type=playlist&q=Adele\"\n]\n\npromiseAll(arr, function(item, index, resolve, reject) {\n    console.log(\"Making request [\" + index + \"]\")\n    ExecutionBlock(item, index, resolve, reject);\n}, function(results) { // Aggregated results\n\n    console.log(\"All profiles received \" + results.length);\n    //console.log(JSON.stringify(results[0], null, 2));\n\n    ///// promiseall again\n\n    var ExecutionProfileBlock = function(item, index, resolve, reject) {\n        SimpleRequest.call(item, function(result) {\n            if (result) {\n                var obj = JSON.parse(result);\n                resolve({\n                    name: obj.display_name,\n                    followers: obj.followers.total,\n                    url: obj.href\n                });\n            } //result\n        })\n    } //ExecutionProfileBlock\n\n    promiseAll(results[0], function(item, index, resolve, reject) {\n        //console.log(\"Making request [\" + index + \"] \" + item)\n        ExecutionProfileBlock(item, index, resolve, reject);\n    }, function(results) { // aggregated results\n        console.log(\"All response received \" + results.length);\n        console.log(JSON.stringify(results, null, 2));\n    }\n\n    , function(error) { // Error\n        console.log(error);\n    })\n\n    /////\n\n  },\n  function(error) { // Error\n      console.log(error);\n  });\n<div id=\"console\" />\n Run code snippetExpand snippet\n\nI have extensively discussed this solution here.\n\nShare\nImprove this answer\nFollow\nedited Nov 28 '18 at 16:42\nanswered Apr 12 '16 at 22:55\nloretoparisi\n13.3k10\n10 gold badges\n82\n82 silver badges\n112\n112 bronze badges","comments":[]},{"answer":"The short answer is, you have to implement a callback like this:\n\nfunction callback(response) {\n    // Here you can do what ever you want with the response object.\n    console.log(response);\n}\n\n$.ajax({\n    url: \"...\",\n    success: callback\n});\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 13:31\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 22 '16 at 14:47\nPablo Matias Gomez\n5,6826\n6 gold badges\n34\n34 silver badges\n69\n69 bronze badges","comments":[]},{"answer":"JavaScript is single threaded.\n\nThe browser can be divided into three parts:\n\nEvent Loop\n\nWeb API\n\nEvent Queue\n\nThe event loop runs for forever, i.e., kind of an infinite loop. The event queue is where all your functions are pushed on some event (example: click).\n\nThis is one by one carried out of queue and put into the event loop which executes this function and prepares itself for the next one after the first one is executed. This means execution of one function doesn't start until the function before it in the queue is executed in the event loop.\n\nNow let us think we pushed two functions in a queue. One is for getting a data from the server and another utilises that data. We pushed the serverRequest() function in the queue first and then the utiliseData() function. The serverRequest function goes in the event loop and makes a call to server as we never know how much time it will take to get data from server, so this process is expected to take time and so we busy our event loop thus hanging our page.\n\nThat's where Web API come into the role. It takes this function from the event loop and deals with the server making the event loop free, so that we can execute the next function from the queue.\n\nThe next function in the queue is utiliseData() which goes in the loop, but because of no data available, it goes to waste and execution of the next function continues until the end of the queue. (This is called Async calling, i.e., we can do something else until we get data.)\n\nLet us suppose our serverRequest() function had a return statement in code. When we get back data from the server Web API, it will push it in the queue at the end of queue.\n\nAs it gets pushed at the end of the queue, we cannot utilise its data as there isn't any function left in our queue to utilise this data. Thus it is not possible to return something from the async call.\n\nThus the solution to this is callback or promise.\n\nAn image from one of the answers here correctly explains callback use...*\n\nWe give our function (function utilising data returned from the server) to a function calling the server.\n\nfunction doAjax(callbackFunc, method, url) {\n    var xmlHttpReq = new XMLHttpRequest();\n    xmlHttpReq.open(method, url);\n    xmlHttpReq.onreadystatechange = function() {\n\n        if (xmlHttpReq.readyState == 4 && xmlHttpReq.status == 200) {\n            callbackFunc(xmlHttpReq.responseText);\n        }\n    }\n    xmlHttpReq.send(null);\n}\n\n\nIn my code it is called as:\n\nfunction loadMyJson(categoryValue){\n    if(categoryValue === \"veg\")\n        doAjax(print, \"GET\", \"http://localhost:3004/vegetables\");\n    else if(categoryValue === \"fruits\")\n        doAjax(print, \"GET\", \"http://localhost:3004/fruits\");\n    else\n      console.log(\"Data not found\");\n}\n\n\nJavaScript.info callback\n\nShare\nImprove this answer\nFollow\nedited Apr 21 at 12:46\n404\n5,9231\n1 gold badge\n23\n23 silver badges\n42\n42 bronze badges\nanswered Feb 3 '18 at 6:06\nAniket Jha\n1,5499\n9 silver badges\n12\n12 bronze badges","comments":["well explained. also add promise related information"]},{"answer":"2017 answer: you can now do exactly what you want in every current browser and Node.js\n\nThis is quite simple:\n\nReturn a Promise\nUse the 'await', which will tell JavaScript to await the promise to be resolved into a value (like the HTTP response)\nAdd the 'async' keyword to the parent function\n\nHere's a working version of your code:\n\n(async function(){\n\n    var response = await superagent.get('...')\n    console.log(response)\n\n})()\n\n\nawait is supported in all current browsers and Node.js 8\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 13:50\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 2 '17 at 9:51\nmikemaccana\n84.5k77\n77 gold badges\n327\n327 silver badges\n402\n402 bronze badges","comments":["Unfortunately, this works only with functions that return promises – for example it doesn't work with Node.js API, which uses callbacks. And I wouldn't recommend using it without Babel, because not everyone uses \"current browsers\".","@MichałPerłakowski node 8 includes nodejs.org/api/util.html#util_util_promisify_original which can be used to make the node.js API return promises. Whether you have the time and money to support non-current browsers obviously depends on your situation.","IE 11 is still a current browser in 2018, sadly and it doesn't support await/async","IE11 is not a current browser. It was released 5 years ago, has a worldwide market share of 2.5% according to caniuse, and unless someone is doubling your budget to ignore all current tech then it's not worth most people's time."]},{"answer":"You can use this custom library (written using Promise) to make a remote call.\n\nfunction $http(apiConfig) {\n    return new Promise(function (resolve, reject) {\n        var client = new XMLHttpRequest();\n        client.open(apiConfig.method, apiConfig.url);\n        client.send();\n        client.onload = function () {\n            if (this.status >= 200 && this.status < 300) {\n                // Performs the function \"resolve\" when this.status is equal to 2xx.\n                // Your logic here.\n                resolve(this.response);\n            }\n            else {\n                // Performs the function \"reject\" when this.status is different than 2xx.\n                reject(this.statusText);\n            }\n        };\n        client.onerror = function () {\n            reject(this.statusText);\n        };\n    });\n}\n\n\nSimple usage example:\n\n$http({\n    method: 'get',\n    url: 'google.com'\n}).then(function(response) {\n    console.log(response);\n}, function(error) {\n    console.log(error)\n});\n\nShare\nImprove this answer\nFollow\nedited Dec 17 '16 at 10:59\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 26 '16 at 13:26\nVinoth Rajendran\n1,1211\n1 gold badge\n12\n12 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"Another solution is to execute code via the sequential executor nsynjs.\n\nIf the underlying function is promisified\n\nnsynjs will evaluate all promises sequentially, and put the promise result into the data property:\n\nfunction synchronousCode() {\n\n    var getURL = function(url) {\n        return window.fetch(url).data.text().data;\n    };\n    \n    var url = 'https://ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min.js';\n    console.log('received bytes:',getURL(url).length);\n    \n};\n\nnsynjs.run(synchronousCode,{},function(){\n    console.log('synchronousCode done');\n});\n<script src=\"https://rawgit.com/amaksr/nsynjs/master/nsynjs.js\"></script>\n Run code snippetExpand snippet\n\nIf the underlying function is not promisified\n\nStep 1. Wrap the function with a callback into the nsynjs-aware wrapper (if it has a promisified version, you can skip this step):\n\nvar ajaxGet = function (ctx,url) {\n    var res = {};\n    var ex;\n    $.ajax(url)\n    .done(function (data) {\n        res.data = data;\n    })\n    .fail(function(e) {\n        ex = e;\n    })\n    .always(function() {\n        ctx.resume(ex);\n    });\n    return res;\n};\najaxGet.nsynjsHasCallback = true;\n\n\nStep 2. Put synchronous logic into function:\n\nfunction process() {\n    console.log('got data:', ajaxGet(nsynjsCtx, \"data/file1.json\").data);\n}\n\n\nStep 3. Run function in synchronous manner via nsynjs:\n\nnsynjs.run(process,this,function () {\n    console.log(\"synchronous function finished\");\n});\n\n\nNsynjs will evaluate all operators and expressions step-by-step, pausing execution in case if the result of some slow function is not ready.\n\nMore examples are here.\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 13:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 27 '17 at 2:47\namaksr\n6,8032\n2 gold badges\n14\n14 silver badges\n16\n16 bronze badges","comments":["This is interesting. I like how it allows to code async calls the way you'd do it in other languages. But technically it's not real JavaScript?"]},{"answer":"ECMAScript 6 has 'generators' which allow you to easily program in an asynchronous style.\n\nfunction* myGenerator() {\n    const callback = yield;\n    let [response] = yield $.ajax(\"https://stackoverflow.com\", {complete: callback});\n    console.log(\"response is:\", response);\n\n    // examples of other things you can do\n    yield setTimeout(callback, 1000);\n    console.log(\"it delayed for 1000ms\");\n    while (response.statusText === \"error\") {\n        [response] = yield* anotherGenerator();\n    }\n}\n\n\nTo run the above code you do this:\n\nconst gen = myGenerator(); // Create generator\ngen.next(); // Start it\ngen.next((...args) => gen.next([...args])); // Set its callback function\n\n\nIf you need to target browsers that don't support ES6 you can run the code through Babel or closure-compiler to generate ECMAScript 5.\n\nThe callback ...args are wrapped in an array and destructured when you read them so that the pattern can cope with callbacks that have multiple arguments. For example with node fs:\n\nconst [err, data] = yield fs.readFile(filePath, \"utf-8\", callback);\n\nShare\nImprove this answer\nFollow\nedited Jul 31 '18 at 10:35\nanswered Feb 17 '18 at 15:26\nJames\n4,6971\n1 gold badge\n30\n30 silver badges\n39\n39 bronze badges","comments":["Do you consider generators / async generators to be an async API solution alone ? Or you would use generators to wrap another asynchronous API like promise/deffered ? I agree it is another strong addition to the async universe but still haven't found the right usage of generators that would make me adopt them."]},{"answer":"We find ourselves in a universe which appears to progress along a dimension we call \"time\". We don't really understand what time is, but we have developed abstractions and vocabulary that let us reason and talk about it: \"past\", \"present\", \"future\", \"before\", \"after\".\n\nThe computer systems we build--more and more--have time as an important dimension. Certain things are set up to happen in the future. Then other things need to happen after those first things eventually occur. This is the basic notion called \"asynchronicity\". In our increasingly networked world, the most common case of asynchronicity is waiting for some remote system to respond to some request.\n\nConsider an example. You call the milkman and order some milk. When it comes, you want to put it in your coffee. You can't put the milk in your coffee right now, because it is not here yet. You have to wait for it to come before putting it in your coffee. In other words, the following won't work:\n\nvar milk = order_milk();\nput_in_coffee(milk);\n\n\nBecause JavaScript has no way to know that it needs to wait for order_milk to finish before it executes put_in_coffee. In other words, it does not know that order_milk is asynchronous--is something that is not going to result in milk until some future time. JavaScript, and other declarative languages execute one statement after another without waiting.\n\nThe classic JavaScript approach to this problem, taking advantage of the fact that JavaScript supports functions as first-class objects which can be passed around, is to pass a function as a parameter to the asynchronous request, which it will then invoke when it has completed its task sometime in the future. That is the \"callback\" approach. It looks like this:\n\norder_milk(put_in_coffee);\n\n\norder_milk kicks off, orders the milk, then, when and only when it arrives, it invokes put_in_coffee.\n\nThe problem with this callback approach is that it pollutes the normal semantics of a function reporting its result with return; instead, functions must not reports their results by calling a callback given as a parameter. Also, this approach can rapidly become unwieldy when dealing with longer sequences of events. For example, let's say that I want to wait for the milk to be put in the coffee, and then and only then perform a third step, namely drinking the coffee. I end up needing to write something like this:\n\norder_milk(function(milk) { put_in_coffee(milk, drink_coffee); }\n\n\nwhere I am passing to put_in_coffee both the milk to put in it, and also the action (drink_coffee) to execute once the milk has been put in. Such code becomes hard to write, and read, and debug.\n\nIn this case, we could rewrite the code in the question as:\n\nvar answer;\n$.ajax('/foo.json') . done(function(response) {\n  callback(response.data);\n});\n\nfunction callback(data) {\n  console.log(data);\n}\n\nEnter promises\n\nThis was the motivation for the notion of a \"promise\", which is a particular type of value which represents a future or asynchronous outcome of some sort. It can represent something that already happened, or that is going to happen in the future, or might never happen at all. Promises have a single method, named then, to which you pass an action to be executed when the outcome the promise represents has been realized.\n\nIn the case of our milk and coffee, we design order_milk to return a promise for the milk arriving, then specify put_in_coffee as a then action, as follows:\n\norder_milk() . then(put_in_coffee)\n\n\nOne advantage of this is that we can string these together to create sequences of future occurrences (\"chaining\"):\n\norder_milk() . then(put_in_coffee) . then(drink_coffee)\n\n\nLet's apply promises to your particular problem. We will wrap our request logic inside a function, which returns a promise:\n\nfunction get_data() {\n  return $.ajax('/foo.json');\n}\n\n\nActually, all we've done is added a return to the call to $.ajax. This works because jQuery's $.ajax already returns a kind of promise-like thing. (In practice, without getting into details, we would prefer to wrap this call so as for return a real promise, or use some alternative to $.ajax that does so.) Now, if we want to load the file and wait for it to finish and then do something, we can simply say\n\nget_data() . then(do_something)\n\n\nfor instance,\n\nget_data() .\n  then(function(data) { console.log(data); });\n\n\nWhen using promises, we end up passing lots of functions into then, so it's often helpful to use the more compact ES6-style arrow functions:\n\nget_data() .\n  then(data => console.log(data));\n\nThe async keyword\n\nBut there's still something vaguely dissatisfying about having to write code one way if synchronous and a quite different way if asynchronous. For synchronous, we write\n\na();\nb();\n\n\nbut if a is asynchronous, with promises we have to write\n\na() . then(b);\n\n\nAbove, we said, \"JavaScript has no way to know that it needs to wait for the first call to finish before it executes the second\". Wouldn't it be nice if there was some way to tell JavaScript that? It turns out that there is--the await keyword, used inside a special type of function called an \"async\" function. This feature is part of the upcoming version of ECMAScript (ES), but it is already available in transpilers such as Babel given the right presets. This allows us to simply write\n\nasync function morning_routine() {\n  var milk   = await order_milk();\n  var coffee = await put_in_coffee(milk);\n  await drink(coffee);\n}\n\n\nIn your case, you would be able to write something like\n\nasync function foo() {\n  data = await get_data();\n  console.log(data);\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 13:20\ncommunity wiki\n\n\n5 revs, 4 users 87%\nuser663031","comments":[]},{"answer":"Short answer: Your foo() method returns immediately, while the $ajax() call executes asynchronously after the function returns. The problem is then how or where to store the results retrieved by the async call once it returns.\n\nSeveral solutions have been given in this thread. Perhaps the easiest way is to pass an object to the foo() method, and to store the results in a member of that object after the async call completes.\n\nfunction foo(result) {\n    $.ajax({\n        url: '...',\n        success: function(response) {\n            result.response = response;   // Store the async result\n        }\n    });\n}\n\nvar result = { response: null };   // Object to hold the async result\nfoo(result);                       // Returns before the async completes\n\n\nNote that the call to foo() will still return nothing useful. However, the result of the async call will now be stored in result.response.\n\nShare\nImprove this answer\nFollow\nanswered Sep 23 '15 at 22:52\nDavid R Tribble\n10.8k4\n4 gold badges\n39\n39 silver badges\n50\n50 bronze badges","comments":["While this works, it's not really better than assigning to a global variable."]},{"answer":"Here are some approaches to work with asynchronous requests:\nBrowser Promise object\nQ - A promise library for JavaScript\nA+ Promises.js\njQuery deferred\nXMLHttpRequest API\nUsing callback concept - As implementation in first answer\nExample: jQuery deferred implementation to work with multiple requests\n\nvar App = App || {};\n\nApp = {\n    getDataFromServer: function(){\n\n      var self = this,\n                 deferred = $.Deferred(),\n                 requests = [];\n\n      requests.push($.getJSON('request/ajax/url/1'));\n      requests.push($.getJSON('request/ajax/url/2'));\n\n      $.when.apply(jQuery, requests).done(function(xhrResponse) {\n        return deferred.resolve(xhrResponse.result);\n      });\n      return deferred;\n    },\n\n    init: function(){\n\n        this.getDataFromServer().done(_.bind(function(resp1, resp2) {\n\n           // Do the operations which you wanted to do when you\n           // get a response from Ajax, for example, log response.\n        }, this));\n    }\n};\nApp.init();\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Aug 13 '16 at 9:36\nMohan Dere\n3,8571\n1 gold badge\n20\n20 silver badges\n20\n20 bronze badges","comments":["Why include a Stack Snippet that outputs an error?"]},{"answer":"Use a callback() function inside the foo() success. Try it in this way. It is simple and easy to understand.\n\nvar lat = \"\";\nvar lon = \"\";\n\nfunction callback(data) {\n    lat = data.lat;\n    lon = data.lon;\n}\n\nfunction getLoc() {\n    var url = \"http://ip-api.com/json\"\n    $.getJSON(url, function(data) {\n        callback(data);\n    });\n}\n\ngetLoc();\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 13:40\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 24 '17 at 8:09\nMahfuzur Rahman\n1,29215\n15 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"Using Promise\n\nThe most perfect answer to this question is using Promise.\n\nfunction ajax(method, url, params) {\n  return new Promise(function(resolve, reject) {\n    var xhr = new XMLHttpRequest();\n    xhr.onload = function() {\n      resolve(this.responseText);\n    };\n    xhr.onerror = reject;\n    xhr.open(method, url);\n    xhr.send(params);\n  });\n}\n\nUsage\najax(\"GET\", \"/test\", \"acrive=1\").then(function(result) {\n    // Code depending on result\n})\n.catch(function() {\n    // An error occurred\n});\n\nBut wait...!\n\nThere is a problem with using promises!\n\nWhy should we use our own custom Promise?\n\nI was using this solution for a while until I figured out there is an error in old browsers:\n\nUncaught ReferenceError: Promise is not defined\n\nSo I decided to implement my own Promise class for ES3 to below JavaScript compilers if it's not defined. Just add this code before your main code and then safely use Promise!\n\nif(typeof Promise === \"undefined\"){\n    function _classCallCheck(instance, Constructor) {\n        if (!(instance instanceof Constructor)) {\n            throw new TypeError(\"Cannot call a class as a function\");\n        }\n    }\n    var Promise = function () {\n        function Promise(main) {\n            var _this = this;\n            _classCallCheck(this, Promise);\n            this.value = undefined;\n            this.callbacks = [];\n            var resolve = function resolve(resolveValue) {\n                _this.value = resolveValue;\n                _this.triggerCallbacks();\n            };\n            var reject = function reject(rejectValue) {\n                _this.value = rejectValue;\n                _this.triggerCallbacks();\n            };\n            main(resolve, reject);\n        }\n        Promise.prototype.then = function then(cb) {\n            var _this2 = this;\n            var next = new Promise(function (resolve) {\n                _this2.callbacks.push(function (x) {\n                    return resolve(cb(x));\n                });\n            });\n            return next;\n        };\n        Promise.prototype.catch = function catch_(cb) {\n            var _this2 = this;\n            var next = new Promise(function (reject) {\n                _this2.callbacks.push(function (x) {\n                    return reject(cb(x));\n                });\n            });\n            return next;\n        };\n        Promise.prototype.triggerCallbacks = function triggerCallbacks() {\n            var _this3 = this;\n            this.callbacks.forEach(function (cb) {\n                cb(_this3.value);\n            });\n        };\n        return Promise;\n    }();\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 14:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 7 '18 at 14:10\nAmir Fo\n3,3711\n1 gold badge\n28\n28 silver badges\n38\n38 bronze badges","comments":[]},{"answer":"The question was:\n\nHow do I return the response from an asynchronous call?\n\nwhich can be interpreted as:\n\nHow to make asynchronous code look synchronous?\n\nThe solution will be to avoid callbacks, and use a combination of Promises and async/await.\n\nI would like to give an example for an Ajax request.\n\n(Although it can be written in JavaScript, I prefer to write it in Python, and compile it to JavaScript using Transcrypt. It will be clear enough.)\n\nLet’s first enable jQuery usage, to have $ available as S:\n\n__pragma__ ('alias', 'S', '$')\n\n\nDefine a function which returns a Promise, in this case an Ajax call:\n\ndef read(url: str):\n    deferred = S.Deferred()\n    S.ajax({'type': \"POST\", 'url': url, 'data': { },\n        'success': lambda d: deferred.resolve(d),\n        'error': lambda e: deferred.reject(e)\n    })\n    return deferred.promise()\n\n\nUse the asynchronous code as if it were synchronous:\n\nasync def readALot():\n    try:\n        result1 = await read(\"url_1\")\n        result2 = await read(\"url_2\")\n    except Exception:\n        console.warn(\"Reading a lot failed\")\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 14:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 13 '18 at 19:13\nPieter Jan Bonestroo\n5135\n5 silver badges\n10\n10 bronze badges","comments":["Anyone interested in using async / await will likely also want to read this answer (and possibly my comment below it :-)."]},{"answer":"Of course there are many approaches like synchronous request, promise, but from my experience I think you should use the callback approach. It's natural to asynchronous behavior of JavaScript.\n\nSo, your code snippet can be rewritten to be a little different:\n\nfunction foo() {\n    var result;\n\n    $.ajax({\n        url: '...',\n        success: function(response) {\n            myCallback(response);\n        }\n    });\n\n    return result;\n}\n\nfunction myCallback(response) {\n    // Does something.\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 13:53\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 5 '17 at 20:28\nKhoa Bui\n6637\n7 silver badges\n14\n14 bronze badges","comments":["There's nothing inherently asynchronous about callbacks or JavaScript.","Why keep var result; and return result;? The latter will still always return undefined!"]},{"answer":"Rather than throwing code at you, there are two concepts that are key to understanding how JavaScript handles callbacks and asynchronicity (is that even a word?)\n\nThe Event Loop and Concurrency Model\n\nThere are three things you need to be aware of; The queue; the event loop and the stack\n\nIn broad, simplistic terms, the event loop is like the project manager, it is constantly listening for any functions that want to run and communicates between the queue and the stack.\n\nwhile (queue.waitForMessage()) {\n  queue.processNextMessage();\n}\n\n\nOnce it receives a message to run something it adds it to the queue. The queue is the list of things that are waiting to execute (like your AJAX request). imagine it like this:\n\ncall foo.com/api/bar using foobarFunc\nGo perform an infinite loop ... and so on\n\nWhen one of these messages is going to execute it pops the message from the queue and creates a stack, the stack is everything JavaScript needs to execute to perform the instruction in the message. So in our example it's being told to call foobarFunc\n\nfunction foobarFunc (var) {\n  console.log(anotherFunction(var));\n}\n\n\nSo anything that foobarFunc needs to execute (in our case anotherFunction) will get pushed onto the stack. executed, and then forgotten about - the event loop will then move onto the next thing in the queue (or listen for messages)\n\nThe key thing here is the order of execution. That is\n\nWHEN is something going to run\n\nWhen you make a call using AJAX to an external party or run any asynchronous code (a setTimeout for example), JavaScript is dependant upon a response before it can proceed.\n\nThe big question is when will it get the response? The answer is we don't know - so the event loop is waiting for that message to say \"hey run me\". If JavaScript just waited around for that message synchronously your app would freeze and it will suck. So JavaScript carries on executing the next item in the queue whilst waiting for the message to get added back to the queue.\n\nThat's why with asynchronous functionality we use things called callbacks. - A function or handler that, when passed into another function, will be executed at a later date. A promise uses callbacks (functions passed to .then() for example) as a way to reason about this asynchronous behaviour in a more linear way. The promise is a way of saying \"I promise to return something at some point\" and the callback is how we handle that value that is eventually returned. jQuery uses specific callbacks called deffered.done deffered.fail and deffered.always (amongst others). You can see them all here\n\nSo what you need to do is pass a function that is promised to execute at some point with data that is passed to it.\n\nBecause a callback is not executed immediately but at a later time it's important to pass the reference to the function not it executed. so\n\nfunction foo(bla) {\n  console.log(bla)\n}\n\n\nso most of the time (but not always) you'll pass foo not foo()\n\nHopefully that will make some sense. When you encounter things like this that seem confusing - i highly recommend reading the documentation fully to at least get an understanding of it. It will make you a much better developer.\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 14:43\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 4 '18 at 15:56\nMatthew Brent\n1,22611\n11 silver badges\n21\n21 bronze badges","comments":["I am struggling to accept \"callbacks are kind of like promises\". it's like saying \"flour is kind of like bread\" but it is not. you use flour, water and other incredients, mix them and eventually after a process, bread is the results.","This is true - I think I was try to say something that doesnt quite read what I was meaning. A promise in JS evidently represents something different to a callback, however when programming any kind asynchronous functionality you are going to be executing a callback. A promise represents the value but the callback is what we need to do something with that value, at some point in the future, when it returns.","A promise is mostly useless (but not always) without a callback to do something with the resolved value"]},{"answer":"After reading all the responses here and with my experiences, I would like to resume the detail of callback, promise and async/await for the asynchronous programming in JavaScript.\n\n1) Callback: The fundamental reason for a callback is to run code in response of an event (see the example below). We use callback in JavaScript every time.\n\nconst body = document.getElementsByTagName('body')[0];\nfunction callback() {\n  console.log('Hello');\n}\nbody.addEventListener('click', callback);\n\n\nBut if you must use many nested callbacks in the example below, it will be fairy terrible for the code refactoring.\n\nasyncCallOne(function callback1() {\n  asyncCallTwo(function callback2() {\n    asyncCallThree(function callback3() {\n        ...\n    })\n  })\n})\n\n\n2) Promise: a syntax ES6 - Promise resolves the callback hell issue!\n\nconst myFirstPromise = new Promise((resolve, reject) => {\n  // We call resolve(...) when what we were doing asynchronously was successful, and reject(...) when it failed.\n  // In this example, we use setTimeout(...) to simulate async code.\n  // In reality, you will probably be using something like XHR request or an HTML5 API.\n  setTimeout(() => {\n    resolve(\"Success!\")  // Yay! Everything went well!\n  }, 250)\n})\n\nmyFirstPromise\n  .then((res) => {\n    return res.json();\n  })\n  .then((data) => {\n    console.log(data);\n  })\n  .catch((e) => {\n    console.log(e);\n  });\n\n\nmyFirstPromise is a Promise instance that represents the process of async codes. The resolve function signals that the Promise instance has finished. Afterwards, we can call .then() (a chain of .then as you want) and .catch() on the promise instance:\n\nthen — Runs a callback you pass to it when the promise has fulfilled.\ncatch — Runs a callback you pass to it when something went wrong.\n\n\n3) Async/Await: a new syntax ES6 - Await is basically syntactic sugar for Promise!\n\nThe Async function provides us with a clean and concise syntax that enables us to write less code to accomplish the same outcome we would get with promises. Async/Await looks similar to synchronous code, and synchronous code is much easier to read and write. To catch errors with Async/Await, we can use the block try...catch. In here, you don't need to write a chain of .then() of Promise syntax.\n\nconst getExchangeRate = async () => {\n  try {\n    const res = await fetch('https://getExchangeRateData');\n    const data = await res.json();\n    console.log(data);\n  } catch (err) {\n    console.error(err);\n  }\n}\n\ngetExchangeRate();\n\n\nConclusion: These are totally the three syntaxes for asynchronous programming in JavaScript that you should well understand. So if possible, I recommend that you should use \"promise\" or \"async/await\" for refactoring your asynchronous codes (mostly for XHR requests) !\n\nShare\nImprove this answer\nFollow\nedited Apr 9 at 15:11\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 19 '20 at 22:23\nSanjiMika\n2,33916\n16 silver badges\n18\n18 bronze badges","comments":["Hi, although this answer's contents are accurate, it really doesn't answer OP's question (which is how to return something from an asynchronous call?)"]}]},{"id":"2025282","href":"https://stackoverflow.com/questions/2025282/what-is-the-difference-between-px-dip-dp-and-sp","title":"What is the difference between “px”, “dip”, “dp” and “sp”?","description":"\n                \nWhat is the difference between Android units of measure?\n\n\npx\ndip\ndp\nsp\n\n    ","questionComments":["this is use full difference between px, dip, dp and sp in android [ developer.android.com/guide/topics/resources/…","This nifty converter demonstrates it best, in my opinion. It's also extremely useful for exporting sprites from Photoshop or designing your layout for a physical dimension.","How to programmatically convert between px, dp, and sp","from android developers site developer.android.com/guide/practices/screens_support.html","Material design with pixel-density material.io/design/layout/…"],"answers":[{"answer":"From the Android Developer Documentation:\n\npx\n> Pixels - corresponds to actual pixels on the screen.\n\nin\n> Inches - based on the physical size of the screen.\n> 1 Inch = 2.54 centimeters\n\nmm\n> Millimeters - based on the physical size of the screen.\n\npt\n> Points - 1/72 of an inch based on the physical size of the screen.\n\ndp or dip\n> Density-independent Pixels - an abstract unit that is based on the physical density of the screen. These units are relative to a 160 dpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both \"dip\" and \"dp\", though \"dp\" is more consistent with \"sp\".\n\nsp\n> Scaleable Pixels OR scale-independent pixels - this is like the dp unit, but it is also scaled by the user's font size preference. It is recommended you use this unit when specifying font sizes, so they will be adjusted for both the screen density and user's preference. Note, the Android documentation is inconsistent on what sp actually stands for, one doc says \"scale-independent pixels\", the other says \"scaleable pixels\".\n\nFrom Understanding Density Independence In Android:\n\nDensity Bucket\tScreen Density\tPhysical Size\tPixel Size\nldpi\t120 dpi\t0.5 x 0.5 in\t0.5 in * 120 dpi = 60x60 px\nmdpi\t160 dpi\t0.5 x 0.5 in\t0.5 in * 160 dpi = 80x80 px\nhdpi\t240 dpi\t0.5 x 0.5 in\t0.5 in * 240 dpi = 120x120 px\nxhdpi\t320 dpi\t0.5 x 0.5 in\t0.5 in * 320 dpi = 160x160 px\nxxhdpi\t480 dpi\t0.5 x 0.5 in\t0.5 in * 480 dpi = 240x240 px\nxxxhdpi\t640 dpi\t0.5 x 0.5 in\t0.5 in * 640 dpi = 320x320 px\nUnit\tDescription\tUnits Per Physical Inch\tDensity Independent?\tSame Physical Size On Every Screen?\npx\tPixels\tVaries\tNo\tNo\nin\tInches\t1\tYes\tYes\nmm\tMillimeters\t25.4\tYes\tYes\npt\tPoints\t72\tYes\tYes\ndp\tDensity Independent Pixels\t~160\tYes\tNo\nsp\tScale Independent Pixels\t~160\tYes\tNo\n\nMore info can be also be found in the Google Design Documentation.\n\nShare\nImprove this answer\nFollow\nedited Dec 22 '20 at 11:12\ncommunity wiki\n\n\n32 revs, 29 users 17%\nSteven Byle","comments":[]},{"answer":"Pretty much everything about this and how to achieve the best support for multiple screens of different sizes and densities is very well documented here:\n\nSupporting Multiple Screens\n\nScreen size\nActual physical size, measured as the screen's diagonal. For simplicity, Android groups all actual screen sizes into four generalized sizes: small, normal, large, and extra-large.\n\nScreen density\nThe number of pixels within a physical area of the screen; usually referred to as dpi (dots per inch). For example, a \"low\" density screen has fewer pixels within a given physical area, compared to a \"normal\" or \"high\" density screen. For simplicity, Android groups all actual screen densities into six generalized densities: low, medium, high, extra-high, extra-extra-high, and extra-extra-extra-high.\n\nOrientation\nThe orientation of the screen from the user's point of view. This is either landscape or portrait, meaning that the screen's aspect ratio is either wide or tall, respectively. Be aware that not only do different devices operate in different orientations by default, but the orientation can change at runtime when the user rotates the device.\n\nResolution\nThe total number of physical pixels on a screen. When adding support for multiple screens, applications do not work directly with resolution; applications should be concerned only with screen size and density, as specified by the generalized size and density groups.\n\nDensity-independent pixel (dp)\nA virtual pixel unit that you should use when defining UI layout, to express layout dimensions or position in a density-independent way. The density-independent pixel is equivalent to one physical pixel on a 160 dpi screen, which is the baseline density assumed by the system for a \"medium\" density screen. At runtime, the system transparently handles any scaling of the dp units, as necessary, based on the actual density of the screen in use. The conversion of dp units to screen pixels is simple: px = dp * (dpi / 160). For example, on a 240 dpi screen, 1 dp equals 1.5 physical pixels. You should always use dp units when defining your application's UI, to ensure proper display of your UI on screens with different densities.\n\nIf you are at all serious about developing an Android app for more than one type of device, you should have read the screens support development document at least once. In addition to that, it is always a good thing to know the actual number of active devices that have a particular screen configuration.\n\nScreen Sizes and Densities\nShare\nImprove this answer\nFollow\nedited Jul 31 at 16:08\nauspicious99\n2,7471\n1 gold badge\n32\n32 silver badges\n43\n43 bronze badges\nanswered Feb 25 '11 at 12:56\nBruiser\n11.4k5\n5 gold badges\n32\n32 silver badges\n44\n44 bronze badges","comments":[]},{"answer":"I will elaborate more on how exactly does dp convert to px:\n\nIf running on an mdpi device, a 150 x 150 px image will take up 150 * 150 dp of screen space.\nIf running on an hdpi device, a 150 x 150 px image will take up 100 * 100 dp of screen space.\nIf running on an xhdpi device, a 150x150 px image will take up 75 * 75 dp of screen space.\n\nThe other way around: say, you want to add an image to your application and you need it to fill a 100 * 100 dp control. You'll need to create different size images for supported screen sizes:\n\n100 * 100 px image for mdpi\n150 * 150 px image for hdpi\n200 * 200 px image for xhdpi\nShare\nImprove this answer\nFollow\nedited Apr 6 '18 at 19:03\nVishal Yadav\n3,4213\n3 gold badges\n20\n20 silver badges\n40\n40 bronze badges\nanswered Aug 2 '12 at 14:15\ndevmiles.com\n9,5525\n5 gold badges\n30\n30 silver badges\n45\n45 bronze badges","comments":["How the fontsize is represened? in dp or sp? I have an app the text shows bigger in some modal. So it comes to the next line or fully occupying the spaces. How does this fontsize will be set to show as good in android"]},{"answer":"px - Pixels - point per scale corresponds to actual pixels on the screen.\n\ni - Inches - based on the physical size of the screen.\n\nmm - Millimeters - based on the physical size of the screen.\n\npt - Points - 1/72 of an inch based on the physical size of the screen.\n\ndp - Density-independent Pixels - an abstract unit that is based on the physical density of the screen. These units are relative to a 160 dpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both dip and dp, though dp is more consistent with sp.\n\nsp - scalable pixels - this is like the dp unit, but it is also scaled by the user's font size preference. It is recommended that you use this unit when specifying font sizes, so they will be adjusted for both the screen density and user's preference.\n\nTake the example of two screens that are the same size but one has a screen density of 160 dpi (dots per inch, i.e. pixels per inch) and the other is 240 dpi.\n\n                          Lower resolution screen     Higher resolution, same size\nPhysical Width                      1.5 inches                        1.5 inches\nDots Per Inch (“dpi”)               160                               240\nPixels (=width*dpi)                 240                               360\nDensity (factor of baseline 160)    1.0                               1.5\n\nDensity-independent pixels          240                               240\n(“dip” or “dp” or “dps”)\n\nScale-independent pixels \n (“sip” or “sp”)                  Depends on user font size settings    same\n\nShare\nImprove this answer\nFollow\nedited Oct 2 '20 at 17:39\nBen Butterworth\n7,8152\n2 gold badges\n34\n34 silver badges\n56\n56 bronze badges\nanswered Oct 30 '12 at 9:43\nAmit Gajera\n3,1791\n1 gold badge\n12\n12 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"Moreover you should have clear understanding about the following concepts:\n\nScreen size:\n\nActual physical size, measured as the screen's diagonal. For simplicity, Android groups all actual screen sizes into four generalized sizes: small, normal, large, and extra large.\n\nScreen density:\n\nThe quantity of pixels within a physical area of the screen; usually referred to as dpi (dots per inch). For example, a \"low\" density screen has fewer pixels within a given physical area, compared to a \"normal\" or \"high\" density screen. For simplicity, Android groups all actual screen densities into four generalized densities: low, medium, high, and extra high.\n\nOrientation:\n\nThe orientation of the screen from the user's point of view. This is either landscape or portrait, meaning that the screen's aspect ratio is either wide or tall, respectively. Be aware that not only do different devices operate in different orientations by default, but the orientation can change at runtime when the user rotates the device.\n\nResolution:\n\nThe total number of physical pixels on a screen. When adding support for multiple screens, applications do not work directly with resolution; applications should be concerned only with screen size and density, as specified by the generalized size and density groups.\n\nDensity-independent pixel (dp):\n\nA virtual pixel unit that you should use when defining UI layout, to express layout dimensions or position in a density-independent way. The density-independent pixel is equivalent to one physical pixel on a 160 dpi screen, which is the baseline density assumed by the system for a \"medium\" density screen. At runtime, the system transparently handles any scaling of the dp units, as necessary, based on the actual density of the screen in use. The conversion of dp units to screen pixels is simple: px = dp * (dpi / 160). For example, on a 240 dpi screen, 1 dp equals 1.5 physical pixels. You should always use dp units when defining your application's UI, to ensure proper display of your UI on screens with different densities.\n\nReference: Android developers site\n\nShare\nImprove this answer\nFollow\nedited Nov 27 '18 at 13:10\nanswered Jul 26 '13 at 21:19\nSazzad Hissain Khan\n30.5k21\n21 gold badges\n138\n138 silver badges\n201\n201 bronze badges","comments":[]},{"answer":"dp is dip. Use it for everything (margin, padding, etc.).\n\nUse sp for {text-size} only.\n\nTo get the same size on different screen densities, Android translates these units into pixels at runtime, so there is no tricky math for you to do.\n\nSee the difference between px, dp and sp on different screen sizes.\n\nSource: Android Programming: The Big Nerd Ranch Guide\n\nShare\nImprove this answer\nFollow\nedited Aug 11 '15 at 20:53\nanswered Oct 17 '14 at 12:47\nMina Gabriel\n17.7k23\n23 gold badges\n89\n89 silver badges\n120\n120 bronze badges","comments":[]},{"answer":"Definitions\n\npx or dot is a pixel on the physical screen.\n\ndpi are pixels per inch on the physical screen and represent the density of the display.\n\nAndroid gives alias names to several densities\n\nldpi (low) ~120dpi\nmdpi (medium) ~160dpi\nhdpi (high) ~240dpi\nmost devices in 2015 are here\nxhdpi (extra-high) ~320dpi\nApple iPhone 4/5/6, Nexus 4\nxxhdpi (extra-extra-high) ~480dpi\nNexus 5\nxxxhdpi (extra-extra-extra-high) ~640dpi\n\ndip or dp are density-indenpendant pixels, i.e. they correspond to more or less pixels depending on the physical density.\n\n1dp = 1px on mdpi\n\nsp or sip is a scale-independant pixel. They are scaled when the Large Text option is turned on in Settings > Accessibility\n\n1sp = 1dp\n1sp = 1.2dp with accessibility Large Text\nWhat to use?\n\nUse sp for Text size.\n\nUse dp for everything else.\n\nShare\nImprove this answer\nFollow\nedited Mar 2 '16 at 9:39\nanswered Jan 10 '16 at 19:13\nrds\n24.5k16\n16 gold badges\n98\n98 silver badges\n124\n124 bronze badges","comments":[]},{"answer":"I have calculated the formula below to make the conversions dpi to dp and sp \n\nShare\nImprove this answer\nFollow\nedited Apr 6 '17 at 10:24\ncommunity wiki\n\n\n4 revs, 4 users 50%\nchaitanya","comments":["It should be ppi instead of dpi"]},{"answer":"Source 1\n\nSource 2\n\nSource 3: (data from source 3 is given below)\n\nThese are dimension values defined in XML. A dimension is specified with a number followed by a unit of measure. For example: 10px, 2in, 5sp. The following units of measure are supported by Android:\n\ndp\n\nDensity-independent Pixels - An abstract unit that is based on the physical density of the screen. These units are relative to a 160 dpi (dots per inch) screen, on which 1dp is roughly equal to 1px. When running on a higher density screen, the number of pixels used to draw 1dp is scaled up by a factor appropriate for the screen's dpi. Likewise, when on a lower density screen, the number of pixels used for 1dp is scaled down. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Using dp units (instead of px units) is a simple solution to making the view dimensions in your layout resize properly for different screen densities. In other words, it provides consistency for the real-world sizes of your UI elements across different devices.\n\nsp\n\nScale-independent Pixels - This is like the dp unit, but it is also scaled by the user's font size preference. It is recommended that you use this unit when specifying font sizes, so they will be adjusted for both the screen density and the user's preference.\n\npt\n\nPoints - 1/72 of an inch based on the physical size of the screen.\n\npx\n\nPixels - Corresponds to actual pixels on the screen. This unit of measure is not recommended because the actual representation can vary across devices; each devices may have a different number of pixels per inch and may have more or fewer total pixels available on the screen.\n\nmm\n\nMillimeters - Based on the physical size of the screen.\n\nin\n\nInches - Based on the physical size of the screen.\n\nNote: A dimension is a simple resource that is referenced using the value provided in the name attribute (not the name of the XML file). As such, you can combine dimension resources with other simple resources in the one XML file, under one element.\n\nShare\nImprove this answer\nFollow\nedited Nov 27 '18 at 9:15\nSayed Mohd Ali\n2,0193\n3 gold badges\n9\n9 silver badges\n25\n25 bronze badges\nanswered Dec 27 '13 at 9:21\nsms247\n4,1064\n4 gold badges\n30\n30 silver badges\n44\n44 bronze badges","comments":["Also: what is the added value of this answer? There doesn't seem to be anything that hasn't already been mentioned in other answers."]},{"answer":"Basically the only time where px applies is one px, and that's if you want exactly one pixel on the screen like in the case of a divider:\n\nOn >160 dpi, you may get 2-3 pixels,\n\nOn >120 dpi, it rounds to 0.\n\nShare\nImprove this answer\nFollow\nedited Mar 31 '18 at 10:05\nRKRK\n1,3545\n5 gold badges\n14\n14 silver badges\n17\n17 bronze badges\nanswered Sep 20 '12 at 21:34\nJoe Plante\n6,0222\n2 gold badges\n28\n28 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"px\n\nPixels - corresponds to actual pixels on the screen.\n\ndp or dip\n\nDensity-independent Pixels - an abstract unit that is based on the physical density of the screen. These units are relative to a 160 dpi screen, so one dp is one pixel on a 160 dpi screen.\n\nUse of dp:\n\nDensity independence - Your application achieves “density independence” when it preserves the physical size (from the user’s point of view) of user interface elements when displayed on screens with different densities. (ie) The image should look the same size (not enlarged or shrinked) in different types of screens.\n\nsp\n\nScale-independent Pixels - this is like the dp unit, but it is also scaled by the user's font size preference.\n\nhttp://developer.android.com/guide/topics/resources/more-resources.html#Dimension\n\nShare\nImprove this answer\nFollow\nanswered Apr 2 '13 at 6:35\nNirav Ranpara\n15.4k4\n4 gold badges\n40\n40 silver badges\n57\n57 bronze badges","comments":[]},{"answer":"Where to use what & relationship between px & dp?\nDensity-independent pixel (dp)\n\nA virtual pixel unit that you should use when defining UI layout, to express layout dimensions or position in a density-independent way. As described above, the density-independent pixel is equivalent to one physical pixel on a 160 dpi screen, which is the baseline density assumed by the system for a \"medium\" density screen. At runtime, the system transparently handles any scaling of the dp units, as necessary, based on the actual density of the screen in use. The conversion of dp units to screen pixels is simple:\n\npx = dp * (dpi / 160).\n\nFor example, on a 240 dpi screen, 1 dp equals 1.5 physical pixels. You should always use dp units when defining your application's UI, to ensure proper display of your UI on screens with different densities.\n\nUnderstanding pixel to dp and vice versa is very essential (especially for giving exact dp values to creative team)\n\ndp = px * 160 / dpi\n\nMDPI = 160 dpi || Therefore, on MDPI 1 px = 1 dp\nFor example, if you want to convert 20 pixel to dp, use the above formula,\ndp = 20 * 160 / 160 = 20.\nSo, 20 pixel = 20 dp.\n\nHDPI = 240 dpi - So, on HDPI 1.5 px = 1 dp\nXHDPI = 320 dpi - So, on XHDPI 2 px = 1 dp\nXXHDPI = 480 dpi - So, on XXHDPI 3 px = 1 dp\n\nFor example, let us consider Nexus 4.\nIf 24 pixels to be converted to dp and if it is a Nexus 4 screen, developers can\nconvert it to dp easily by the following calculation :\ndp = 24 * 160 / 320 = 12 dp\nScreen dimension:\n768 x 1280 pixel resolution (320 ppi or 320dpi)\nOptional (screen size):\n 4.7\" diagonal\n\nTry to get all pixel values in even numbers from the creative team. Otherwise precision lose will happen while multiplying with 0.5.\npx\n\nIt is explained above. Try to avoid in layout files. But there are some cases, where px is required. for example, ListView divider line. px is better here for giving a one-pixel line as a divider for all across screen resolutions.\n\nsp\n\nUse sp for font sizes. Then only the font inside the application will change while device fonts size changes (that is, Display -> Fonts on Device). If you want to keep a static sized font inside the app, you can give the font dimension in dp. In such a case, it will never change. Developers may get such a requirement for some specific screens, for that, developers can use dp instead of sp. In all other cases, sp is recommended.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jul 9 '14 at 5:46\nArunjyothis\n1,4061\n1 gold badge\n10\n10 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"You can see the difference between px and dp from the below picture, and you can also find that the px and dp could not guarantee the same physical sizes on the different screens.\n\nShare\nImprove this answer\nFollow\nanswered Feb 13 '15 at 18:50\nZephyr\n5,51832\n32 silver badges\n32\n32 bronze badges","comments":["@EnesBattal, I think because the dp isn't an acute physical size, it is a approximate value. Quoting from CapTech : \"dp - This is a density independent unit, however the physical size of a single “dp” is only approximately the same on every screen density. There are approximately 160 “dp” in an inch. A scaling factor, depending on the density bucket of the device, is applied to convert “dp” to the number of pixels at 160 dpi. The number of pixels a single “dp” translates to varies depending on the pixel on screen density and the density bucket the device falls into.\"","@RuchirBaronia, I think the DP or DIP is still there inside apk, because the apk doesn't know which kind of screen density it will run with yet, so the device independence should be still kept."]},{"answer":"Anything related with the size of text and appearance must use sp or pt. Whereas, anything related to the size of the controls, the layouts, etc. must be used with dp.\n\nYou can use both dp and dip at its places.\n\nShare\nImprove this answer\nFollow\nedited Jul 1 '15 at 14:30\nanswered Aug 9 '13 at 13:38\nAtish Agrawal\n2,8251\n1 gold badge\n18\n18 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"I would only use dp.\n\nThere is a lot of talk about using \"sp\" for font sizes, and while I appreciate the point, I don't think that it is the right thing to do from a design point of view. You can end up breaking your design if the user has some wonky font size selection, and the user will end up blaming the app, and not their own life choices.\n\nAlso, if you take an sp-font app on a 160 dpi tablet, you will find that everything scales up... but your font, which is going to look tiny in comparison. It isn't a good look.\n\nWhile the idea of \"sp\" fonts has a good heart, it is a poor idea. Stick with dp for everything.\n\nShare\nImprove this answer\nFollow\nedited Jun 6 '15 at 14:42\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 22 '14 at 16:56\nbharal\n14.3k31\n31 gold badges\n110\n110 silver badges\n183\n183 bronze badges","comments":["You know that the font scale factor applied to sp is a factor, right? Anything that affects dp will also affect sp. That said, it's still preferable to specify font sizes using dp instead of sp if your layout is very tight and the larger sizes won't fit - better to have text smaller than what the user wants that a completely messed up layout. But in the first instance you should always strive to respect the user's font size preference - even the biggest setting is not THAT big."]},{"answer":"sp = scale independent pixel\n\ndp = dip = density independent pixels\n\ndpi = dots per inch\n\nWe should avoid to use sp.\n\nWe should use dp to support multiple screens.\n\nAndroid supports different screen resolutions\n\nldpi (low) ~120 dpi\nmdpi (medium) ~160 dpi\nhdpi (high) ~240 dpi\nxhdpi (extra-high) ~320 dpi\nxxhdpi (extra-extra-high) ~480 dpi\nxxxhdpi (extra-extra-extra-high) ~640 dpi\n\nAn 120 dp ldpi device has 120 pixels in 1 inch size.\n\nThe same for other densities...\n\nWe as software engineers should use this conversion formula:\n\npixel = dp * (density / 160)\n\nSo 240 dpi device's 1 dp will have = 1 * (240/160) = 3/2 = 1.5 pixels.\n\nAnd 480 dpi device's 1 dp will have = 1 * (480/160) = 3 pixels.\n\nUsing this 1.5 and 3 pixels knowledge, a software engineer can design layouts for different densities.\n\nTo check screen parameters of any device:\n\nDisplayMetrics metrics = new DisplayMetrics();\ngetWindowManager().getDefaultDisplay().getMetrics(metrics);\n\nToast.makeText(\n    this,\n    \"4:\" + metrics.heightPixels + \",\" + metrics.density + \",\"\n    + metrics.densityDpi, Toast.LENGTH_LONG).show();\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Mar 11 '15 at 6:33\nKushal\n6,8496\n6 gold badges\n48\n48 silver badges\n73\n73 bronze badges","comments":["Very good tutorial for understanding is : http:/vinsol.com/blog/2014/11/20/tips-for-designers-from-a-developer","\"We should avoid to use sp\" Why is that? You should use sp when dealing with font sizes because it takes into account the user's preferred text size, developer.android.com/training/multiscreen/screendensities.html","I have answered relative to layout perspective.. Please read on link you provided \"so you should use this measurement unit when defining text size (but never for layout sizes).\"","The question was \"Difference between px, dp, dip and sp in Android?\" your answer said \"We should avoid to use sp\". There was no mention of \"layout perspective\" anywhere.","Yes.. dp and dip are same... used interchangeably... Is my answer solve your query?"]},{"answer":"Difference between dp and sp units mentioned as \"user's font size preference\" by the answers copied from official documentation can be seen at run time by changing Settings->Accessibility->Large Text option.\n\nLarge Text option forces text to become 1.3 times bigger.\n\nprivate static final float LARGE_FONT_SCALE = 1.3f;\n\n\nThis might be well of course vendor dependent since it lies in packages/apps/Settings.\n\nShare\nImprove this answer\nFollow\nanswered Oct 14 '13 at 8:44\nauselen\n25.9k4\n4 gold badges\n68\n68 silver badges\n107\n107 bronze badges","comments":[]},{"answer":"dpi -\n\nDots per inches\nMeasuring the pixel density of the screen.\n\npx - pixel\n\nFor mapping screen pixels\n\npt - points\n\nAbout 1/72 of an inch, with respect to physical screen size.\n\nin - inch - with respect to physical screen size(1 inch = 2.54 cm).\n\nmm- milimeter - with respect to physical screen size.\n\nsp - scale-independent pixel.\n\nBased on user`s font size preference.\nFont should be in 'sp'.\n\ndip -\n\ndip == dp\nDensity independent pixel.\nIt varies based on Screen Density.\nIn 160 dpi screen, 1 dp = 1 pixel.\nUse dp except the text font size.\n\nIn standard, dp and sp are used. sp for font size and dp for everything else.\n\nFormula for conversion of units:\n\npx = dp * ( dpi / 160 );\n\nDensity Bucket -> Screen Display => Physical Size        => Pixel Size                   \n\nldpi         -> 120 dpi          => 0.5 x 0.5 in         => 0.5 in * 120 dpi = 60x60 px   \n\nmdpi         -> 160 dpi          => 0.5 x 0.5 in         => 0.5 in * 160 dpi = 80x80 px   \n\nhdpi         -> 240 dpi          => 0.5 x 0.5 in         => 0.5 in * 240 dpi = 120x120 px  \n\nxhdpi        -> 320 dpi          => 0.5 x 0.5 in         => 0.5 in * 320 dpi = 160x160 px  \n\nxxhdpi       -> 480 dpi          => 0.5 x 0.5 in         => 0.5 in * 480 dpi = 240x240 px \n\nxxxhdpi      -> 640 dpi          => 0.5 x 0.5 in         => 0.5 in * 640 dpi = 320x320 px  \n\nShare\nImprove this answer\nFollow\nedited Nov 24 '15 at 8:32\nanswered Jan 16 '15 at 7:44\nArunendra\n1,82622\n22 silver badges\n21\n21 bronze badges","comments":["As per the documentation The compiler accepts both \"dip\" and \"dp\", though \"dp\" is more consistent with \"sp”."]},{"answer":"Please read the answer from community wiki. Below mentioned are some information to be considered in addition to the above answers. Most Android developers miss this while developing apps, so I am adding these points.\n\nsp = scale independent pixel\n\ndp = density independent pixels\n\ndpi = density pixels\n\nI have gone through the above answers...not finding them exactly correct. sp for text size, dp for layout bounds - standard. But sp for text size will break the layout if used carelessly in most of the devices.\n\nsp take the textsize of the device, whereas dp take that of device density standard( never change in a device) Say 100sp text can occupies 80% of screen or 100% of screen depending on the font size set in device\n\nYou can use sp for layout bounds also, it will work :) No standard app use sp for whole text\n\nUse sp and dp for text size considering UX.\n\nDont use sp for text in toolbar( can use android dimens available for different screen sizes with dp)\nDont use sp for text in small bounded buttons, very smaller text, etc\n\nSome people use huge FONT size in their phone for more readability, giving them small hardcoded sized text will be an UX issue. Put sp for text where necessary, but make sure it won't break the layout when user changes his settings.\n\nSimilarly if you have a single app supporting all dimensions, adding xxxhdpi assets increases the app size a lot. But now xxxhdpi phones are common so we have to include xxxhdpi assets atleast for icons in side bar, toolbar and bottom bar. Its better to move to vector images to have a uniform and better quality images for all screen sizes.\n\nAlso note that people use custom font in their phone. So lack of a font can cause problems regarding spacing and all. Say text size 12sp for a custom font may take some pixels extra than default font.\n\nRefer google developer site for screendensities and basedensity details for android. https://developer.android.com/training/multiscreen/screendensities\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '19 at 11:36\nanswered May 26 '16 at 5:32\nshijin\n2,5661\n1 gold badge\n19\n19 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"Screen Size in Android is grouped into categories small, medium, large, extra large, double-extra and triple-extra. Screen density is the amount of pixels within an area (like inch) of the screen. Generally it is measured in dots-per-inch (dpi). Screen density is grouped as low, medium, high and extra high. Resolution is the total number of pixels in the screen.\n\ndp: Density Independent Pixel, it varies based on screen density . In 160 dpi screen, 1 dp = 1 pixel. Except for font size, use dp always.\ndip: dip == dp. In earlier Android versions dip was used and later changed to dp.\nsp: Scale Independent Pixel, scaled based on user’s font size preference. Fonts should use sp.\npx: our usual standard pixel which maps to the screen pixel.\nin: inches, with respect to the physical screen size.\nmm: millimeters, with respect to the physical screen size.\npt: 1/72 of an inch, with respect to the physical screen size.\n\nFormula for Conversion between Units\n\n px = dp * (dpi / 160)\n\n\ndp to px in device\n\nFollowing example may help understand better. The scaling occurs based on bucket size of 120(ldpi), 160(mdpi), 240(hdpi), 320(xhdpi), 480(xxhdpi) and 640(xxxhdpi). The Google suggested ratio for designing is 3:4:6:8:12 for ldpi:mdpi:hdpi:xhdpi:xxhdpi\n\nA 150px X 150px image will occupy,\n\n150 dp X 150 dp screen space in mdpi\n100 dp X 100 dp screen space in hdpi\n75 dp X 75 dp screen space in xhdpi\n\nYou may use the following DPI calculator to fix your image sizes and other dimensions when you wish to have an uniform UI design in all Android devices.\n\nDPI Calculator in Java\n\n/*\nProgram output\nLDPI: 165.0 X 60.0\nMDPI: 220.0 X 80.0\nHDPI: 330.0 X 120.0\nXHDPI: 440.0 X 160.0\nXXHDPI: 660.0 X 240.0\nXXXHDPI: 880.0 X 320.0\n*/\n\n\npublic class DPICalculator {\n\nprivate final float LDPI = 120;\nprivate final float MDPI = 160;\nprivate final float HDPI = 240;\nprivate final float XHDPI = 320;\nprivate final float XXHDPI = 480;\nprivate final float XXXHDPI = 640;    \n\nprivate float forDeviceDensity;\nprivate float width;\nprivate float height;\n\npublic DPICalculator(float forDeviceDensity, float width, float height){\n    this.forDeviceDensity = forDeviceDensity;\n    this.width = width;\n    this.height = height;\n}\n\npublic static void main(String... args) {\n    DPICalculator dpiCalculator = new DPICalculator(240,330,120);\n    dpiCalculator.calculateDPI();\n}\n\n\nprivate float getPx(float dp, float value) {\n    float px = dp * (value / forDeviceDensity );        \n    return px;\n}\n\nprivate void calculateDPI() {\n\n    float ldpiW = getPx(LDPI,width);        \n    float ldpiH =  getPx(LDPI,height);\n    float mdpiW = getPx(MDPI,width);        \n    float mdpiH =  getPx(MDPI,height);        \n    float hdpiW = getPx(HDPI,width);        \n    float hdpiH =  getPx(HDPI,height);       \n    float xdpiW = getPx(XHDPI,width);        \n    float xdpiH =  getPx(XHDPI,height);\n    float xxdpiW = getPx(XXHDPI,width);        \n    float xxdpiH =  getPx(XXHDPI,height);\n    float xxxdpiW = getPx(XXXHDPI,width);        \n    float xxxdpiH =  getPx(XXXHDPI,height);\n\n    System.out.println(\"LDPI: \" + ldpiW + \" X \" + ldpiH);\n    System.out.println(\"MDPI: \" + mdpiW + \" X \" + mdpiH);\n    System.out.println(\"HDPI: \" + hdpiW + \" X \" + hdpiH);\n    System.out.println(\"XHDPI: \" + xdpiW + \" X \" + xdpiH);\n    System.out.println(\"XXHDPI: \" + xxdpiW + \" X \" + xxdpiH);\n    System.out.println(\"XXXHDPI: \" + xxxdpiW + \" X \" + xxxdpiH);        \n   }\n}\n\n\nMore Information refer following link.\n\nhttp://javapapers.com/android/difference-between-dp-dip-sp-px-in-mm-pt-in-android/\n\nShare\nImprove this answer\nFollow\nedited Mar 28 '18 at 10:24\nanswered Mar 4 '16 at 5:36\nRavi Vaghela\n3,3162\n2 gold badges\n20\n20 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"Here's the formula used by Android:\n\npx = dp * (dpi / 160)\n\nWhere dpi is one of the following screen densities. For a list of all possible densities go here\n\nIt defines the \"DENSITY_*\" constants.\n\nldpi (low) ~120dpi\nmdpi (medium) ~160dpi\nhdpi (high) ~240dpi\nxhdpi (extra-high) ~320dpi\nxxhdpi (extra-extra-high) ~480dpi\nxxxhdpi (extra-extra-extra-high) ~640dpi\n\nTaken from here.\n\nThis will sort out a lot of the confusion when translating between px and dp, if you know your screen dpi.\n\nSo, let's say you want an image of 60 dp for an hdpi screen then the physical pixel size of 60 dp is:\n\npx = 60 * (240 / 160)\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '18 at 6:24\nRohit Sharma\n1,0064\n4 gold badges\n15\n15 silver badges\n32\n32 bronze badges\nanswered Apr 30 '15 at 4:14\nDan Borza\n3,0413\n3 gold badges\n20\n20 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"px - one pixel, same as to what is used in CSS, JavaScript, etc.\nsp - scale-independent pixels\ndip - density-independent pixels\n\nNormally sp is used for font sizes, while dip is used (also called dp) for others.\n\nShare\nImprove this answer\nFollow\nedited Jun 6 '15 at 14:41\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 13 '14 at 16:53\nDPC\n5964\n4 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"I've come across a good article about designing Android apps UI for different screen resolutions, and I'd like to leave it here just for somebody searching in this area. Yes, I know that it's somehow described in Google docs (and mentioned in the posts above), I read that but it was not good for me (yeah, I may be too stupid)). It remained unclear for me how to design layouts capable to handle different screen size. I hate DP concept and so on, when I need to implement a \"flexible\" UI layout for different screens. (Hey iOS developers - yes, you're right it's Storyboard concept).\n\nAndroid has not bad UI concept, but lacks iOS Storyboard features, unfortunately. Designing flexible UI in Android is not easy thing (at the best).\n\nHere goes the article that helped me to understand what to do in Android to make layouts for different screen sizes:\n\nJMSTUDIO Blog :- Decide Android App Screen Size\n\nHow to Design UI for Android Apps for Different Screen Size\n\nTo design an app UI for different screen sizes, our initial design has to meet a minimum required space for each screen size. Android defines a minimum size (in dp) for each generalized screen type. Here is an Android screen size guideline.  When we get the screen size in dp, it is not enough for us to design the Android app UI. For each screen size, we need to prepare graphics and bitmap images for each density. Here is an Android screen density guideline. \n\nFor easy calculation, we can follow the 3:4:6:8 scaling ratio between the four generalized densities. If we create a 36×36 pixel picture for ldpi device, the rest densities pictures size will be 48×48 for mdpi, 72×72 for hdpi, and 96×96 for xhdpi.\n\nHow to Design Android Apps UI in Photoshop\n\nMany designers have problems for designing Android app UI in photoshop or other pixel based graphic design tools because of density-independent unit, dp. Designers don’t know how to map dp to pixel. Google also doesn’t give a clear Android UI design guide for them, though they give a basic formula for dp and pixel translation.\n\nAs Android’s definition, 1pd equal to 1px under 160 dpi device (mdpi). So we want to design an Android app for xlarge Android device with mdpi density, we can define our UI size in pixel as 960 pixel in width and 720px in height; Follow the same mapping rule, we can get following Android App screen size UI design guideline:\n\nADDED: If you interested in \"flexible\" UI too, have a look at this library: An Android SDK that provides a new size unit - sdp (scalable dp). This size unit scales with the screen size (this also mentioned in an answer here, about SDP library)\n\nADDED2 Google has finally understood usefulness of iOS Storeboard UI concept, and here goes ConstraintLayout for Android world: Build a Responsive UI with ConstraintLayout\n\nShare\nImprove this answer\nFollow\nedited Sep 14 '18 at 15:03\nanswered May 17 '16 at 19:59\nMixaz\n3,80925\n25 silver badges\n54\n54 bronze badges","comments":[]},{"answer":"1) dp: (density independent pixels)\n\nThe number of pixels represented in one unit of dp will increase as the screen resolution increases (when you have more dots/pixels per inch). Conversely on devices with lower resolution, the number of pixels represented in on unit of dp will decrease. Since this is a relative unit, it needs to have a baseline to be compared with. This baseline is a 160 dpi screen. This is the equation: px = dp * (dpi / 160).\n\n\n2) sp: (scale independent pixels)\n\nThis unit scales according to the screen dpi (similar to dp) as well as the user’s font size preference.\n\n\n3) px: (pixels)\n\nActual pixels or dots on the screen.\n\n\n\n\nFor more details you can visit\n\nAndroid Developer Guide > Dimension\nAndroid Developer Guide > Screens\n\nShare\nImprove this answer\nFollow\nedited Apr 2 '18 at 13:58\nRKRK\n1,3545\n5 gold badges\n14\n14 silver badges\n17\n17 bronze badges\nanswered May 10 '15 at 12:59\nIntelliJ Amiya\n71.1k14\n14 gold badges\n155\n155 silver badges\n187\n187 bronze badges","comments":[]},{"answer":"Screen size in Android is grouped into categories ldpi, mdpi, hdpi, xhdpi, xxhdpi and xxxhdpi. Screen density is the amount of pixels within an area (like inch) of the screen. Generally it is measured in dots-per-inch (dpi).\n\nPX(Pixels):\n\nour usual standard pixel which maps to the screen pixel. px is meant for absolute pixels. This is used if you want to give in terms of absolute pixels for width or height. Not recommended.\n\nDP/DIP(Density pixels / Density independent pixels):\n\ndip == dp. In earlier Android versions dip was used and later changed to dp. This is alternative of px.\n\nGenerally we never use px because it is absolute value. If you use px to set width or height, and if that application is being downloaded into different screen sized devices, then that view will not stretch as per the screen original size.\n\ndp is highly recommended to use in place of px. Use dp if you want to mention width and height to grow & shrink dynamically based on screen sizes.\n\nif we give dp/dip, android will automatically calculate the pixel size on the basis of 160 pixel sized screen.\n\nSP(Scale independent pixels):\n\nscaled based on user’s font size preference. Fonts should use sp.\n\nwhen mentioning the font sizes to fit for various screen sizes, use sp. This is similar to dp.Use sp especially for font sizes to grow & shrink dynamically based on screen sizes\n\nAndroid Documentation says:\n\nwhen specifying dimensions, always use either dp or sp units. A dp is a density-independent pixel that corresponds to the physical size of a pixel at 160 dpi. An sp is the same base unit, but is scaled by the user's preferred text size (it’s a scale-independent pixel), so you should use this measurement unit when defining text size\n\nShare\nImprove this answer\nFollow\nanswered Oct 7 '15 at 8:47\nRajesh\n12.5k4\n4 gold badges\n48\n48 silver badges\n76\n76 bronze badges","comments":[]},{"answer":"The screen of a mobile phone is made up of thousands of tiny dots known as pixels (px). A pixel is the smallest element which goes to make the picture. The more the number of pixels to make a picture or wording, the sharper it becomes and makes the smartphone screen more easily readable.\n\nScreen resolution is measured in terms of number of pixels on the screen. Screen resolution is a commonly-used specification when buying a device, but it's actually not that useful when designing for Android because thinking of screens in terms of pixels ignores the notion of physical size, which for a touch device is really really important.\n\nDensity independent pixel (dp or dip) allow the designer to create assets that appear in a expected way, no matter the resolution or density of target device.\n\nA density independent pixel (dp or dip) is equal to one pixel at the baseline density or 160 dpi (dots per inch).\n\n1 px/1dp = 160 dpi/160 dpi\n\n2 px/1dp = 320 dpi(2x)/160 dpi\n\nwhere,\n\ndpi is dots per inch\n\nSo, at 320 dpi, 1 dp is equal to 2 px.\n\nFormula\n\npx/dp = dpi/160dpi\n\nDots per inch (dpi) is a measure of the sharpness (that is, the density of illuminated points) on a display screen. The dots per inch for a given picture resolution will differ based on the overall screen size since the same number of pixels are being spread out over a different space.\n\nWorking with density independent pixels help us to deal with a situation like where you have two devices with same pixel resolution, but differing amount of space. Suppose in a case, a tablet and phone has the same pixel resolution 1280 by 800 pixels (160 dpi) and 800 by 1280 pixels (320 dpi) respectively.\n\nNow because a tablet is at baseline density (160 dpi) its physical and density independent pixels sizes are the same, 1280 by 800. The phone on the other hand has a higher pixel density, so it has half as many density independent pixels as physical pixels. So a phone has 400 by 640 density independent pixels. So using a density-independent pixel makes it easier to mentally picture that tablet has much more space than the phone.\n\nSimilarly, if you have two devices with similar screen size, but different pixel density, say one is 800 by 1280 pixels (320 dpi), and the other is 400 by 640 pixels (160 dpi), we don't need to define totally different layouts for these two devices as we can measure assets in terms of density independent pixel which is same for both devices.\n\n800 by 1280 pixels (320dpi)=400 by 640 density independent pixel (dp)\n\n400 by 640 pixels (160 dpi)=400 by 640 density independent pixel (dp)\n\nScale independent pixels(sp) is the preferred unit for font size. For accessibility purposes, Android allows users to customize their device's font size. Users that have trouble reading text can increase their device's font size. You can normally find this option in the display setting on your phone or tablet under font size. It's often also available through the accessibility settings.\n\nWith scale independent pixels, 16 sp is exactly the same as 16 dp when the device's font size is normal or 100%. But when device's font size is large, for example 125%, 16 sp will translate to 20 dp or 1.25 times 16.\n\nIf you use dp as the unit for font size, then that piece of text has a specific physical size no matter if the user has customize device's font size. Using sp units will make a better experience for people with impaired eyesight.\n\nReference: Udacity, Google\n\nShare\nImprove this answer\nFollow\nedited Oct 18 '17 at 5:31\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 29 '17 at 10:00\nAndroid Developer\n7,10116\n16 gold badges\n64\n64 silver badges\n116\n116 bronze badges","comments":[]},{"answer":"Pixel density\n\nScreen pixel density and resolution vary depending on the platform. Device-independent pixels and scalable pixels are units that provide a flexible way to accommodate a design across platforms.\n\nCalculating pixel density\n\nThe number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones....\n\nThe number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones. As a result, UI elements of the same pixel dimensions appear larger on low-density screens, and smaller on high-density screens.\n\nTo calculate screen density, you can use this equation:\n\nScreen density = Screen width (or height) in pixels / Screen width (or height) in inches\n\nDensity independence\n\nScreen pixel density and resolution vary depending on the platform. Device-independent pixels and scalable pixels are units that provide a flexible way to accommodate a design across platforms.\n\nCalculating pixel density The number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones....\n\nDensity independence refers to the uniform display of UI elements on screens with different densities.\n\nDensity-independent pixels, written as dp (pronounced “dips”), are flexible units that scale to have uniform dimensions on any screen. Material UIs use density-independent pixels to display elements consistently on screens with different densities.\n\nLow-density screen displayed with density independence\nHigh-density screen displayed with density independence\n\nRead full text https://material.io/design/layout/pixel-density.html\n\nShare\nImprove this answer\nFollow\nedited Jul 24 '19 at 11:31\nHBG\n1,4021\n1 gold badge\n22\n22 silver badges\n31\n31 bronze badges\nanswered Aug 31 '18 at 8:20\nlava-lava\n9118\n8 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"sp: scale independent pixel\n\nYou should use it with texts because it is automatically scaled according to the font size that is being used by the user in his device.\n\npx: pixel or picture element is the single point on the screen\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '18 at 8:59\nRohit Sharma\n1,0064\n4 gold badges\n15\n15 silver badges\n32\n32 bronze badges\nanswered Jul 1 '16 at 16:37\nA.Saini\n2092\n2 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"Before answering this question let me decrease the number of units first. So here you go: dp or dip are both the same and are known as Density-independent pixels.\n\n1. px - stands for pixels. Pixels are a single dot, point on a screen. Generally in the mobile industry it is measured in ppi (pixels per inch). Screen resolution is directly proportional to ppi, the larger the number of pixels per inch the higher the screen resolution.\n\nFor example, if you draw an image of a size 200 px * 200 px, then its appearance must be different on a high-resolution device versus a low-resolution device. The reason is a 200 px image on a low-resolution phone will be look larger than on a high-resolution device.\n\nBelow images are showing a resolution of the same image on different phones -\n\nPhone with High screen resolution\n\nPhone with Low screen resolution\n\n2. dip or dp - an abstract unit that is based on the physical density of the screen. These units are relative to a 160 dpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. \"Density independence\" refers to the uniform display of UI elements on screens with different densities.\n\nImage which is showing 80px (left side image) and 80 dp (right-side image). Checkout difference.\n\nA dp is equal to one physical pixel on a screen with a density of 160. To calculate dp:\n\ndp = (width in pixels * 160) / screen density\n\n3. sp - stands for scalable pixels. Generally sp is used for texts on the UI, and sp preserves the font settings. For example, if a user selected a larger font than 30 sp it will auto scale to appear large according to a user preference.\n\nShare\nImprove this answer\nFollow\nedited Dec 7 '17 at 17:58\nanswered Jul 21 '17 at 18:28\nRahul\n9,7394\n4 gold badges\n32\n32 silver badges\n53\n53 bronze badges","comments":["you confused with the Phone with low screen resolution to the appropriate image"]},{"answer":"Pixels(px) – corresponds to actual pixels on the screen. This is used if you want to give in terms of absolute pixels for width or height.\n\nDensity-independent Pixels (dp or dip) – an abstract unit that is based on the physical density of the screen. These units are relative to a 160 dpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both “dip” and “dp”, though “dp” is more consistent with “sp”.\n\nScale-independent Pixels(sp) – this is like the dp unit, but it is also scaled by the user’s font size preference. It is recommend you use this unit when specifying font sizes, so they will be adjusted for both the screen density and user’s preference.\n\nAlways use dp and sp only. sp for font sizes and dp for everything else. It will make UI compatible for Android devices with different densities. You can learn more about pixel and dp from https://www.google.com/design/spec/layout/units-measurements.html#units-measurements-density-independent-pixels-dp-\n\nSource url:- http://www.androidtutorialshub.com/what-is-the-difference-between-px-dp-dip-sp-on-android/\n\nShare\nImprove this answer\nFollow\nedited Oct 8 '18 at 6:22\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered May 10 '17 at 7:37\nlalit vasan\n4323\n3 silver badges\n6\n6 bronze badges","comments":[]}]},{"id":"38987","href":"https://stackoverflow.com/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression-taking-union-of-dictiona","title":"How do I merge two dictionaries in a single expression (taking union of dictionaries)?","description":"\n                \nI have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged (i.e. taking the union).  The update() method would be what I need, if it returned its result instead of modifying a dictionary in-place.\n>>> x = {'a': 1, 'b': 2}\n>>> y = {'b': 10, 'c': 11}\n>>> z = x.update(y)\n>>> print(z)\nNone\n>>> x\n{'a': 1, 'b': 10, 'c': 11}\n\nHow can I get that final merged dictionary in z, not x?\n(To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)\n    ","questionComments":[],"answers":[{"answer":"How can I merge two Python dictionaries in a single expression?\n\nFor dictionaries x and y, z becomes a shallowly-merged dictionary with values from y replacing those from x.\n\nIn Python 3.9.0 or greater (released 17 October 2020): PEP-584, discussed here, was implemented and provides the simplest method:\n\nz = x | y          # NOTE: 3.9+ ONLY\n\n\nIn Python 3.5 or greater:\n\nz = {**x, **y}\n\n\nIn Python 2, (or 3.4 or lower) write a function:\n\ndef merge_two_dicts(x, y):\n    z = x.copy()   # start with keys and values of x\n    z.update(y)    # modifies z with keys and values of y\n    return z\n\n\nand now:\n\nz = merge_two_dicts(x, y)\n\nExplanation\n\nSay you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:\n\nx = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\n\n\nThe desired result is to get a new dictionary (z) with the values merged, and the second dictionary's values overwriting those from the first.\n\n>>> z\n{'a': 1, 'b': 3, 'c': 4}\n\n\nA new syntax for this, proposed in PEP 448 and available as of Python 3.5, is\n\nz = {**x, **y}\n\n\nAnd it is indeed a single expression.\n\nNote that we can merge in with literal notation as well:\n\nz = {**x, 'foo': 1, 'bar': 2, **y}\n\n\nand now:\n\n>>> z\n{'a': 1, 'b': 3, 'foo': 1, 'bar': 2, 'c': 4}\n\n\nIt is now showing as implemented in the release schedule for 3.5, PEP 478, and it has now made its way into the What's New in Python 3.5 document.\n\nHowever, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:\n\nz = x.copy()\nz.update(y) # which returns None since it mutates z\n\n\nIn both approaches, y will come second and its values will replace x's values, thus b will point to 3 in our final result.\n\nNot yet on Python 3.5, but want a single expression\n\nIf you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a single expression, the most performant while the correct approach is to put it in a function:\n\ndef merge_two_dicts(x, y):\n    \"\"\"Given two dictionaries, merge them into a new dict as a shallow copy.\"\"\"\n    z = x.copy()\n    z.update(y)\n    return z\n\n\nand then you have a single expression:\n\nz = merge_two_dicts(x, y)\n\n\nYou can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:\n\ndef merge_dicts(*dict_args):\n    \"\"\"\n    Given any number of dictionaries, shallow copy and merge into a new dict,\n    precedence goes to key-value pairs in latter dictionaries.\n    \"\"\"\n    result = {}\n    for dictionary in dict_args:\n        result.update(dictionary)\n    return result\n\n\nThis function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries a to g:\n\nz = merge_dicts(a, b, c, d, e, f, g) \n\n\nand key-value pairs in g will take precedence over dictionaries a to f, and so on.\n\nCritiques of Other Answers\n\nDon't use what you see in the formerly accepted answer:\n\nz = dict(x.items() + y.items())\n\n\nIn Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. In Python 3, this will fail because you're adding two dict_items objects together, not two lists -\n\n>>> c = dict(a.items() + b.items())\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'\n\n\nand you would have to explicitly create them as lists, e.g. z = dict(list(x.items()) + list(y.items())). This is a waste of resources and computation power.\n\nSimilarly, taking the union of items() in Python 3 (viewitems() in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:\n\n>>> c = dict(a.items() | b.items())\n\n\nThis example demonstrates what happens when values are unhashable:\n\n>>> x = {'a': []}\n>>> y = {'b': []}\n>>> dict(x.items() | y.items())\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: unhashable type: 'list'\n\n\nHere's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:\n\n>>> x = {'a': 2}\n>>> y = {'a': 1}\n>>> dict(x.items() | y.items())\n{'a': 2}\n\n\nAnother hack you should not use:\n\nz = dict(x, **y)\n\n\nThis uses the dict constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.\n\nHere's an example of the usage being remediated in django.\n\nDictionaries are intended to take hashable keys (e.g. frozensets or tuples), but this method fails in Python 3 when keys are not strings.\n\n>>> c = dict(a, **b)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: keyword arguments must be strings\n\n\nFrom the mailing list, Guido van Rossum, the creator of the language, wrote:\n\nI am fine with declaring dict({}, **{1:3}) illegal, since after all it is abuse of the ** mechanism.\n\nand\n\nApparently dict(x, **y) is going around as \"cool hack\" for \"call x.update(y) and return x\". Personally, I find it more despicable than cool.\n\nIt is my understanding (as well as the understanding of the creator of the language) that the intended usage for dict(**y) is for creating dictionaries for readability purposes, e.g.:\n\ndict(a=1, b=10, c=11)\n\n\ninstead of\n\n{'a': 1, 'b': 10, 'c': 11}\n\nResponse to comments\n\nDespite what Guido says, dict(x, **y) is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.\n\nAgain, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. dict broke this consistency in Python 2:\n\n>>> foo(**{('a', 'b'): None})\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() keywords must be strings\n>>> dict(**{('a', 'b'): None})\n{('a', 'b'): None}\n\n\nThis inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.\n\nI submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.\n\nMore comments:\n\ndict(x.items() + y.items()) is still the most readable solution for Python 2. Readability counts.\n\nMy response: merge_two_dicts(x, y) actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.\n\n{**x, **y} does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word \"merging\" these answers describe \"updating one dict with another\", and not merging.\n\nYes. I must refer you back to the question, which is asking for a shallow merge of two dictionaries, with the first's values being overwritten by the second's - in a single expression.\n\nAssuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:\n\nfrom copy import deepcopy\n\ndef dict_of_dicts_merge(x, y):\n    z = {}\n    overlapping_keys = x.keys() & y.keys()\n    for key in overlapping_keys:\n        z[key] = dict_of_dicts_merge(x[key], y[key])\n    for key in x.keys() - overlapping_keys:\n        z[key] = deepcopy(x[key])\n    for key in y.keys() - overlapping_keys:\n        z[key] = deepcopy(y[key])\n    return z\n\n\nUsage:\n\n>>> x = {'a':{1:{}}, 'b': {2:{}}}\n>>> y = {'b':{10:{}}, 'c': {11:{}}}\n>>> dict_of_dicts_merge(x, y)\n{'b': {2: {}, 10: {}}, 'a': {1: {}}, 'c': {11: {}}}\n\n\nComing up with contingencies for other value types is far beyond the scope of this question, so I will point you at my answer to the canonical question on a \"Dictionaries of dictionaries merge\".\n\nLess Performant But Correct Ad-hocs\n\nThese approaches are less performant, but they will provide correct behavior. They will be much less performant than copy and update or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they do respect the order of precedence (latter dictionaries have precedence)\n\nYou can also chain the dictionaries manually inside a dict comprehension:\n\n{k: v for d in dicts for k, v in d.items()} # iteritems in Python 2.7\n\n\nor in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):\n\ndict((k, v) for d in dicts for k, v in d.items()) # iteritems in Python 2\n\n\nitertools.chain will chain the iterators over the key-value pairs in the correct order:\n\nfrom itertools import chain\nz = dict(chain(x.items(), y.items())) # iteritems in Python 2\n\nPerformance Analysis\n\nI'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)\n\nfrom timeit import repeat\nfrom itertools import chain\n\nx = dict.fromkeys('abcdefg')\ny = dict.fromkeys('efghijk')\n\ndef merge_two_dicts(x, y):\n    z = x.copy()\n    z.update(y)\n    return z\n\nmin(repeat(lambda: {**x, **y}))\nmin(repeat(lambda: merge_two_dicts(x, y)))\nmin(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))\nmin(repeat(lambda: dict(chain(x.items(), y.items()))))\nmin(repeat(lambda: dict(item for d in (x, y) for item in d.items())))\n\n\nIn Python 3.8.1, NixOS:\n\n>>> min(repeat(lambda: {**x, **y}))\n1.0804965235292912\n>>> min(repeat(lambda: merge_two_dicts(x, y)))\n1.636518670246005\n>>> min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))\n3.1779992282390594\n>>> min(repeat(lambda: dict(chain(x.items(), y.items()))))\n2.740647904574871\n>>> min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))\n4.266070580109954\n\n$ uname -a\nLinux nixos 4.19.113 #1-NixOS SMP Wed Mar 25 07:06:15 UTC 2020 x86_64 GNU/Linux\n\nResources on Dictionaries\nMy explanation of Python's dictionary implementation, updated for 3.6.\nAnswer on how to add new keys to a dictionary\nMapping two lists into a dictionary\nThe official Python docs on dictionaries\nThe Dictionary Even Mightier - talk by Brandon Rhodes at Pycon 2017\nModern Python Dictionaries, A Confluence of Great Ideas - talk by Raymond Hettinger at Pycon 2017\nShare\nImprove this answer\nFollow\nedited Jul 20 at 9:33\nuser16442705\nanswered Nov 10 '14 at 22:11\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":["@MohammadAzim \"strings only\" only applies to keyword argument expansion in callables, not generalized unpacking syntax. To demonstrate that this works: {**{(0, 1):2}} -> {(0, 1): 2}","This may be changed when PEP-0584 is accepted. A new union operator will be implemented with the following syntax: x | y","@cal97g yes, I addressed that in my answer about 10 days ago: stackoverflow.com/posts/26853961/revisions","Hi, the top is a summary, yes. Up to you. The whole thing would be a great blog post. Note Py 3.4 and below are EOL, 3.5 approaching EOL in 2020-09.","I agree with the eagerness to leave the old way behind, but sometimes people have to work in environments where they only have the older technology available to them. People also have to update code, and seeing the old way next to the new way allows them to confidently replace the old code with equivalent new code. I am open to suggestions on reorganizing the material, but I think we need to keep the older information."]},{"answer":"In your case, what you can do is:\n\nz = dict(list(x.items()) + list(y.items()))\n\n\nThis will, as you want it, put the final dict in z, and make the value for key b be properly overridden by the second (y) dict's value:\n\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = dict(list(x.items()) + list(y.items()))\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n\n\n\nIf you use Python 2, you can even remove the list() calls. To create z:\n\n>>> z = dict(x.items() + y.items())\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n\n\nIf you use Python version 3.9.0a4 or greater, then you can directly use:\n\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz = x | y\nprint(z)\n\n{'a': 1, 'c': 11, 'b': 10}\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '20 at 21:08\nNikita Vlasenko\n2,9664\n4 gold badges\n34\n34 silver badges\n65\n65 bronze badges\nanswered Sep 2 '08 at 7:50\nThomas Vander Stichele\n34.3k13\n13 gold badges\n51\n51 silver badges\n59\n59 bronze badges","comments":["Don't use this as it is very inefficient. (See the timeit results below.) It may have been necessary in the Py2 days if a wrapper function was not an option, but those days are now past."]},{"answer":"An alternative:\n\nz = x.copy()\nz.update(y)\n\nShare\nImprove this answer\nFollow\nanswered Sep 2 '08 at 13:00\nMatthew Schinckel\n32.7k6\n6 gold badges\n74\n74 silver badges\n110\n110 bronze badges","comments":["To clarify why this doesn't meet the critera provided by the question: it's not a single expression and it doesn't return z.","Put it this way: if you need to put two lines of comments explaining your one line of code to the people you hand your code off to...have you really done it in one line? :) I fully agree Python is not good for this: there should be a much easier way. While this answer is more pythonic, is it really all that explicit or clear? Update is not one of the \"core\" functions that people tend to use a lot.","Well, if people insist on making it a oneliner, you can always do (lambda z: z.update(y) or z)(x.copy()) :P","@AlexanderOh The single-line requirement should give way to clarity."]},{"answer":"Another, more concise, option:\n\nz = dict(x, **y)\n\n\nNote: this has become a popular answer, but it is important to point out that if y has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also, Guido is not a fan. So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely.\n\nShare\nImprove this answer\nFollow\nedited Jan 21 '16 at 6:43\nanswered Sep 2 '08 at 15:52\nCarl Meyer\n108k18\n18 gold badges\n102\n102 silver badges\n113\n113 bronze badges","comments":["Works fine in Python 3 and PyPy and PyPy 3, can't speak to Jython or Iron. Given this pattern is explicitly documented (see the third constructor form in this documentation) I'd argue it's not an \"implementation detail\" but intentional feature use.","@amcgregor You missed the key phrase \"if y has any non-string keys.\" That's what doesn't work in Python3; the fact that it works in CPython 2 is an implementation detail that can't be relied on. IFF all your keys are guaranteed to be strings, this is a fully supported option."]},{"answer":"This probably won't be a popular answer, but you almost certainly do not want to do this. If you want a copy that's a merge, then use copy (or deepcopy, depending on what you want) and then update. The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items(). Explicit is better than implicit.\n\nIn addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict. If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created). update() can work more efficiently, because it can run through the second dict item-by-item.\n\nIn terms of time:\n\n>>> timeit.Timer(\"dict(x, **y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n15.52571702003479\n>>> timeit.Timer(\"temp = x.copy()\\ntemp.update(y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n15.694622993469238\n>>> timeit.Timer(\"dict(x.items() + y.items())\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n41.484580039978027\n\n\nIMO the tiny slowdown between the first two is worth it for the readability. In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions.\n\nShare\nImprove this answer\nFollow\nedited Aug 5 '14 at 23:56\ntwasbrillig\n12.9k8\n8 gold badges\n37\n37 silver badges\n61\n61 bronze badges\nanswered Sep 8 '08 at 11:16\nTony Meyer\n9,4415\n5 gold badges\n40\n40 silver badges\n47\n47 bronze badges","comments":[]},{"answer":"In a follow-up answer, you asked about the relative performance of these two alternatives:\n\nz1 = dict(x.items() + y.items())\nz2 = dict(x, **y)\n\n\nOn my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative z2 is not only shorter and simpler but also significantly faster. You can verify this for yourself using the timeit module that comes with Python.\n\nExample 1: identical dictionaries mapping 20 consecutive integers to themselves:\n\n% python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z1=dict(x.items() + y.items())'\n100000 loops, best of 3: 5.67 usec per loop\n% python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z2=dict(x, **y)' \n100000 loops, best of 3: 1.53 usec per loop\n\n\nz2 wins by a factor of 3.5 or so. Different dictionaries seem to yield quite different results, but z2 always seems to come out ahead. (If you get inconsistent results for the same test, try passing in -r with a number larger than the default 3.)\n\nExample 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa:\n\n% python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z1=dict(x.items() + y.items())'\n1000 loops, best of 3: 260 usec per loop\n% python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z2=dict(x, **y)'               \n10000 loops, best of 3: 26.9 usec per loop\n\n\nz2 wins by about a factor of 10. That's a pretty big win in my book!\n\nAfter comparing those two, I wondered if z1's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better:\n\nfrom itertools import chain\nz3 = dict(chain(x.iteritems(), y.iteritems()))\n\n\nA few quick tests, e.g.\n\n% python -m timeit -s 'from itertools import chain; from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z3=dict(chain(x.iteritems(), y.iteritems()))'\n10000 loops, best of 3: 66 usec per loop\n\n\nlead me to conclude that z3 is somewhat faster than z1, but not nearly as fast as z2. Definitely not worth all the extra typing.\n\nThis discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the update method. To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows:\n\nz0 = dict(x)\nz0.update(y)\n\n\nA typical result:\n\n% python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z0=dict(x); z0.update(y)'\n10000 loops, best of 3: 26.9 usec per loop\n\n\nIn other words, z0 and z2 seem to have essentially identical performance. Do you think this might be a coincidence? I don't....\n\nIn fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this. And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core. Python uses dict in lots of places; optimizing its operations is a big deal.\n\nYou could also write this as\n\nz0 = x.copy()\nz0.update(y)\n\n\nas Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance. Use whichever looks right to you. Of course, he's absolutely correct to point out that the two-statement version is much easier to understand.\n\nShare\nImprove this answer\nFollow\nedited Jan 10 '15 at 2:32\nthe Tin Man\n152k39\n39 gold badges\n199\n199 silver badges\n279\n279 bronze badges\nanswered Oct 23 '08 at 2:38\nzaphod\n4,1983\n3 gold badges\n21\n21 silver badges\n25\n25 bronze badges","comments":["This does not work in Python 3; items() is not catenable, and iteritems does not exist."]},{"answer":"In Python 3.0 and later, you can use collections.ChainMap which groups multiple dicts or other mappings together to create a single, updateable view:\n\n>>> from collections import ChainMap\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = dict(ChainMap({}, y, x))\n>>> for k, v in z.items():\n        print(k, '-->', v)\n    \na --> 1\nb --> 10\nc --> 11\n\n\nUpdate for Python 3.5 and later: You can use PEP 448 extended dictionary packing and unpacking. This is fast and easy:\n\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> {**x, **y}\n{'a': 1, 'b': 10, 'c': 11}\n\n\nUpdate for Python 3.9 and later: You can use the PEP 584 union operator:\n\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> x | y\n{'a': 1, 'b': 10, 'c': 11}\n\nShare\nImprove this answer\nFollow\nedited Dec 11 '20 at 6:43\nanswered Apr 28 '13 at 3:15\nRaymond Hettinger\n187k55\n55 gold badges\n325\n325 silver badges\n424\n424 bronze badges","comments":["But one should be cautious while using ChainMap there's a catch that if you have duplicate keys the values from first mapping get used and when you call a del on say a ChainMap c will delete the first mapping of that key.","@Prerit What else would you expect it to do? That's the normal way chained namespaces work. Consider how $PATH works in bash. Deleting an executable on the path doesn't preclude another executable with the same name further upstream.","@Raymond Hettinger I agree, just added a caution. Most people may not know about it. :D","@Prerit You could cast to dict to avoid that, i.e.: dict(ChainMap({}, y, x))","Suggested Edit Queue is full, but someone put the modification from @wjandrea into the answer, which is wrong - it's no longer a a single, updateable view. This edit should be reverted."]},{"answer":"I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it). Obviously this is not a single expression, but it is a single function call.\n\ndef merge(d1, d2, merge_fn=lambda x,y:y):\n    \"\"\"\n    Merges two dictionaries, non-destructively, combining \n    values on duplicate keys as defined by the optional merge\n    function.  The default behavior replaces the values in d1\n    with corresponding values in d2.  (There is no other generally\n    applicable merge strategy, but often you'll have homogeneous \n    types in your dicts, so specifying a merge technique can be \n    valuable.)\n\n    Examples:\n\n    >>> d1\n    {'a': 1, 'c': 3, 'b': 2}\n    >>> merge(d1, d1)\n    {'a': 1, 'c': 3, 'b': 2}\n    >>> merge(d1, d1, lambda x,y: x+y)\n    {'a': 2, 'c': 6, 'b': 4}\n\n    \"\"\"\n    result = dict(d1)\n    for k,v in d2.iteritems():\n        if k in result:\n            result[k] = merge_fn(result[k], v)\n        else:\n            result[k] = v\n    return result\n\nShare\nImprove this answer\nFollow\nedited Sep 13 '14 at 19:56\nRainy\n9377\n7 silver badges\n13\n13 bronze badges\nanswered Sep 4 '08 at 19:08\nrcreswick\n15.6k15\n15 gold badges\n56\n56 silver badges\n69\n69 bronze badges","comments":["Handy solution when the default behaviour of the shorter and simpler solutions (replacement of values of common keys by the second dictionary) is not wished. For Python 3, iteritems() is not available anymore in dicts, and one can simply use items() instead."]},{"answer":"Recursively/deep update a dict\ndef deepupdate(original, update):\n    \"\"\"\n    Recursively update a dict.\n    Subdict's won't be overwritten but also updated.\n    \"\"\"\n    for key, value in original.iteritems(): \n        if key not in update:\n            update[key] = value\n        elif isinstance(value, dict):\n            deepupdate(value, update[key]) \n    return update\n\nDemonstration:\n\npluto_original = {\n    'name': 'Pluto',\n    'details': {\n        'tail': True,\n        'color': 'orange'\n    }\n}\n\npluto_update = {\n    'name': 'Pluutoo',\n    'details': {\n        'color': 'blue'\n    }\n}\n\nprint deepupdate(pluto_original, pluto_update)\n\nOutputs:\n\n{\n    'name': 'Pluutoo',\n    'details': {\n        'color': 'blue',\n        'tail': True\n    }\n}\n\nThanks rednaw for edits.\n\nShare\nImprove this answer\nFollow\nedited Dec 18 '15 at 11:19\nDawid Gosławski\n1,77916\n16 silver badges\n24\n24 bronze badges\nanswered Nov 29 '11 at 11:52\nStan\n3,8092\n2 gold badges\n28\n28 silver badges\n37\n37 bronze badges","comments":["This does not answer the question. The question clearly asks for a new dictionary, z, from original dictionaries, x and y, with values from y replacing those of x - not an updated dictionary. This answer modifies y in-place by adding values from x. Worse, it does not copy these values, so one could further modify the modified dictionary, y, and modifications could be reflected in dictionary x. @Jérôme I hope this code is not causing any bugs for your application - at least consider using deepcopy to copy the values.","@AaronHall agreed this does not answer the question. But it answers my need. I understand those limitations, but that's not an issue in my case. Thinking of it, maybe the name is misleading, as it might evoke a deepcopy, which it does not provide. But it addresses deep nesting. Here's another implementation from the Martellibot: stackoverflow.com/questions/3232943/…."]},{"answer":"Python 3.5 (PEP 448) allows a nicer syntax option:\n\nx = {'a': 1, 'b': 1}\ny = {'a': 2, 'c': 2}\nfinal = {**x, **y} \nfinal\n# {'a': 2, 'b': 1, 'c': 2}\n\n\nOr even\n\nfinal = {'a': 1, 'b': 1, **x, **y}\n\n\nIn Python 3.9 you also use | and |= with the below example from PEP 584\n\nd = {'spam': 1, 'eggs': 2, 'cheese': 3}\ne = {'cheese': 'cheddar', 'aardvark': 'Ethel'}\nd | e\n# {'spam': 1, 'eggs': 2, 'cheese': 'cheddar', 'aardvark': 'Ethel'}\n\nShare\nImprove this answer\nFollow\nedited May 3 '20 at 21:16\nanswered Feb 26 '15 at 21:27\nBilal Syed Hussain\n6,9848\n8 gold badges\n32\n32 silver badges\n41\n41 bronze badges","comments":["In what way is this solution better than the dict(x, **y)-solution? As you (@CarlMeyer) mentioned within the note of your own answer (stackoverflow.com/a/39858/2798610) Guido considers that solution illegal.","Guido dislikes dict(x, **y) for the (very good) reason that it relies on y only having keys which are valid keyword argument names (unless you are using CPython 2.7, where the dict constructor cheats). This objection/restriction does not apply to PEP 448, which generalizes the ** unpacking syntax to dict literals. So this solution has the same concision as dict(x, **y), without the downside."]},{"answer":"The best version I could think while not using copy would be:\n\nfrom itertools import chain\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\ndict(chain(x.iteritems(), y.iteritems()))\n\n\nIt's faster than dict(x.items() + y.items()) but not as fast as n = copy(a); n.update(b), at least on CPython. This version also works in Python 3 if you change iteritems() to items(), which is automatically done by the 2to3 tool.\n\nPersonally I like this version best because it describes fairly good what I want in a single functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out.\n\nShare\nImprove this answer\nFollow\nanswered Oct 14 '10 at 18:55\ndriax\n2,2781\n1 gold badge\n22\n22 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz = dict(x.items() + y.items())\nprint z\n\n\nFor items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last.\n\nShare\nImprove this answer\nFollow\nanswered Sep 2 '08 at 7:49\nGreg Hewgill\n843k170\n170 gold badges\n1107\n1107 silver badges\n1243\n1243 bronze badges","comments":["In python 3 you would get TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items' ... you should encapsulate each dict with list() like: dict(list(x.items()) + list(y.items()))"]},{"answer":"While the question has already been answered several times, this simple solution to the problem has not been listed yet.\n\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz4 = {}\nz4.update(x)\nz4.update(y)\n\n\nIt is as fast as z0 and the evil z2 mentioned above, but easy to understand and change.\n\nShare\nImprove this answer\nFollow\nanswered Oct 14 '11 at 16:12\nphobie\n2,2361\n1 gold badge\n18\n18 silver badges\n21\n21 bronze badges","comments":["but it's three statements rather than one expression","Yes! The mentioned one-expression-solutions are either slow or evil. Good code is readable and maintainable. So the problem is the question not the answer. We should ask for the best solution of a problem not for a one-line-solution.","Lose the z4 = {} and change the next line to z4 = x.copy() -- better than just good code doesn't do unnecessary things (which makes it even more readable and maintainable).","Your suggestion would change this to Matthews answer. While his answer is fine, I think mine is more readable and better maintainable. The extra line would only be bad if it would cost execution time.","I suggest you put this into a function"]},{"answer":"def dict_merge(a, b):\n  c = a.copy()\n  c.update(b)\n  return c\n\nnew = dict_merge(old, extras)\n\n\nAmong such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life Guido van Rossum himself! Someone else suggested half of this, but did not put it in a function.\n\nprint dict_merge(\n      {'color':'red', 'model':'Mini'},\n      {'model':'Ferrari', 'owner':'Carl'})\n\n\ngives:\n\n{'color': 'red', 'owner': 'Carl', 'model': 'Ferrari'}\n\nShare\nImprove this answer\nFollow\nedited Aug 6 '12 at 9:30\nanswered Aug 6 '12 at 9:24\nSam Watkins\n6,6503\n3 gold badges\n34\n34 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"If you think lambdas are evil then read no further. As requested, you can write the fast and memory-efficient solution with one expression:\n\nx = {'a':1, 'b':2}\ny = {'b':10, 'c':11}\nz = (lambda a, b: (lambda a_copy: a_copy.update(b) or a_copy)(a.copy()))(x, y)\nprint z\n{'a': 1, 'c': 11, 'b': 10}\nprint x\n{'a': 1, 'b': 2}\n\n\nAs suggested above, using two lines or writing a function is probably a better way to go.\n\nShare\nImprove this answer\nFollow\nedited Nov 23 '11 at 18:20\nanswered Nov 23 '11 at 18:08\nEMS\n9431\n1 gold badge\n8\n8 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"Be pythonic. Use a comprehension:\n\nz={i:d[i] for d in [x,y] for i in d}\n\n>>> print z\n{'a': 1, 'c': 11, 'b': 10}\n\nShare\nImprove this answer\nFollow\nedited Sep 29 '16 at 10:45\nanswered Jan 20 '16 at 11:46\nRobino\n3,5042\n2 gold badges\n28\n28 silver badges\n36\n36 bronze badges","comments":["As a function: def dictmerge(*args):   return {i:d[i] for d in args for i in d}","Save a lookup by iterating the key/value pairs directly: z={k: v for d in (x, y) for k, v in d.items()}"]},{"answer":"In python3, the items method no longer returns a list, but rather a view, which acts like a set. In this case you'll need to take the set union since concatenating with + won't work:\n\ndict(x.items() | y.items())\n\n\nFor python3-like behavior in version 2.7, the viewitems method should work in place of items:\n\ndict(x.viewitems() | y.viewitems())\n\n\nI prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows).\n\nEdit:\n\nA couple more points for python 3. First, note that the dict(x, **y) trick won't work in python 3 unless the keys in y are strings.\n\nAlso, Raymond Hettinger's Chainmap answer is pretty elegant, since it can take an arbitrary number of dicts as arguments, but from the docs it looks like it sequentially looks through a list of all the dicts for each lookup:\n\nLookups search the underlying mappings successively until a key is found.\n\nThis can slow you down if you have a lot of lookups in your application:\n\nIn [1]: from collections import ChainMap\nIn [2]: from string import ascii_uppercase as up, ascii_lowercase as lo; x = dict(zip(lo, up)); y = dict(zip(up, lo))\nIn [3]: chainmap_dict = ChainMap(y, x)\nIn [4]: union_dict = dict(x.items() | y.items())\nIn [5]: timeit for k in union_dict: union_dict[k]\n100000 loops, best of 3: 2.15 µs per loop\nIn [6]: timeit for k in chainmap_dict: chainmap_dict[k]\n10000 loops, best of 3: 27.1 µs per loop\n\n\nSo about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Oct 9 '13 at 18:09\nbeardc\n17.4k16\n16 gold badges\n68\n68 silver badges\n90\n90 bronze badges","comments":[]},{"answer":"Two dictionaries\n\ndef union2(dict1, dict2):\n    return dict(list(dict1.items()) + list(dict2.items()))\n\n\nn dictionaries\n\ndef union(*dicts):\n    return dict(itertools.chain.from_iterable(dct.items() for dct in dicts))\n\n\nsum has bad performance. See https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python/\n\nShare\nImprove this answer\nFollow\nedited Oct 2 '16 at 18:16\nanswered Oct 17 '12 at 2:09\nMathieu Larose\n1,1201\n1 gold badge\n12\n12 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"Simple solution using itertools that preserves order (latter dicts have precedence)\n\n# py2\nfrom itertools import chain, imap\nmerge = lambda *args: dict(chain.from_iterable(imap(dict.iteritems, args)))\n\n# py3\nfrom itertools import chain\nmerge = lambda *args: dict(chain.from_iterable(map(dict.items, args)))\n\n\nAnd it's usage:\n\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> merge(x, y)\n{'a': 1, 'b': 10, 'c': 11}\n\n>>> z = {'c': 3, 'd': 4}\n>>> merge(x, y, z)\n{'a': 1, 'b': 10, 'c': 3, 'd': 4}\n\nShare\nImprove this answer\nFollow\nedited Sep 29 '20 at 19:45\nanswered Aug 4 '15 at 14:54\nreubano\n4,01833\n33 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"Abuse leading to a one-expression solution for Matthew's answer:\n\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = (lambda f=x.copy(): (f.update(y), f)[1])()\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n\n\nYou said you wanted one expression, so I abused lambda to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe.\n\nYou could also do this of course if you don't care about copying it:\n\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = (x.update(y), x)[1]\n>>> z\n{'a': 1, 'b': 10, 'c': 11}\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Aug 7 '13 at 21:23\nClaudiu\n209k155\n155 gold badges\n451\n451 silver badges\n657\n657 bronze badges","comments":[]},{"answer":"Even though the answers were good for this shallow dictionary, none of the methods defined here actually do a deep dictionary merge.\n\nExamples follow:\n\na = { 'one': { 'depth_2': True }, 'two': True }\nb = { 'one': { 'extra': False } }\nprint dict(a.items() + b.items())\n\n\nOne would expect a result of something like this:\n\n{ 'one': { 'extra': False', 'depth_2': True }, 'two': True }\n\n\nInstead, we get this:\n\n{'two': True, 'one': {'extra': False}}\n\n\nThe 'one' entry should have had 'depth_2' and 'extra' as items inside its dictionary if it truly was a merge.\n\nUsing chain also, does not work:\n\nfrom itertools import chain\nprint dict(chain(a.iteritems(), b.iteritems()))\n\n\nResults in:\n\n{'two': True, 'one': {'extra': False}}\n\n\nThe deep merge that rcwesick gave also creates the same result.\n\nYes, it will work to merge the sample dictionaries, but none of them are a generic mechanism to merge. I'll update this later once I write a method that does a true merge.\n\nShare\nImprove this answer\nFollow\nanswered Aug 3 '12 at 23:36\nThanh Lim\n2652\n2 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"If you don't mind mutating x,\n\nx.update(y) or x\n\n\nSimple, readable, performant. You know update() always returns None, which is a false value. So the above expression will always evaluate to x, after updating it.\n\nMost mutating methods in the standard library (like .update()) return None by convention, so this kind of pattern will work on those too. However, if you're using a dict subclass or some other method that doesn't follow this convention, then or may return its left operand, which may not be what you want. Instead, you can use a tuple display and index, which works regardless of what the first element evaluates to (although it's not quite as pretty):\n\n(x.update(y), x)[-1]\n\n\nIf you don't have x in a variable yet, you can use lambda to make a local without using an assignment statement. This amounts to using lambda as a let expression, which is a common technique in functional languages, but is maybe unpythonic.\n\n(lambda x: x.update(y) or x)({'a': 1, 'b': 2})\n\n\nAlthough it's not that different from the following use of the new walrus operator (Python 3.8+ only),\n\n(x := {'a': 1, 'b': 2}).update(y) or x\n\n\nespecially if you use a default argument:\n\n(lambda x={'a': 1, 'b': 2}: x.update(y) or x)()\n\n\nIf you do want a copy, PEP 584 style x | y is the most Pythonic on 3.9+. If you must support older versions, PEP 448 style {**x, **y} is easiest for 3.5+. But if that's not available in your (even older) Python version, the let expression pattern works here too.\n\n(lambda z=x.copy(): z.update(y) or z)()\n\n\n(That is, of course, nearly equivalent to (z := x.copy()).update(y) or z, but if your Python version is new enough for that, then the PEP 448 style will be available.)\n\nShare\nImprove this answer\nFollow\nedited May 29 at 6:33\nanswered Sep 22 '17 at 2:57\ngilch\n8,8841\n1 gold badge\n17\n17 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"New in Python 3.9: Use the union operator (|) to merge dicts similar to sets:\n\n>>> d = {'a': 1, 'b': 2}\n>>> e = {'a': 9, 'c': 3}\n>>> d | e\n{'a': 9, 'b': 2, 'c': 3}\n\n\nFor matching keys, the right dict takes precedence.\n\nThis also works for |= to modify a dict in-place:\n\n>>> e |= d    # e = e | d\n>>> e\n{'a': 1, 'c': 3, 'b': 2}\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '20 at 21:49\nanswered Jun 1 '20 at 21:23\nxjcl\n6,4213\n3 gold badges\n36\n36 silver badges\n46\n46 bronze badges","comments":[]},{"answer":"It's so silly that .update returns nothing.\nI just use a simple helper function to solve the problem:\n\ndef merge(dict1,*dicts):\n    for dict2 in dicts:\n        dict1.update(dict2)\n    return dict1\n\n\nExamples:\n\nmerge(dict1,dict2)\nmerge(dict1,dict2,dict3)\nmerge(dict1,dict2,dict3,dict4)\nmerge({},dict1,dict2)  # this one returns a new copy\n\nShare\nImprove this answer\nFollow\nanswered Mar 2 '14 at 1:44\nGetFree\n34.6k17\n17 gold badges\n70\n70 silver badges\n101\n101 bronze badges","comments":[]},{"answer":"(For Python2.7* only; there are simpler solutions for Python3*.)\n\nIf you're not averse to importing a standard library module, you can do\n\nfrom functools import reduce\n\ndef merge_dicts(*dicts):\n    return reduce(lambda a, d: a.update(d) or a, dicts, {})\n\n\n(The or a bit in the lambda is necessary because dict.update always returns None on success.)\n\nShare\nImprove this answer\nFollow\nanswered Mar 28 '16 at 13:13\nkjo\n28.3k42\n42 gold badges\n126\n126 silver badges\n231\n231 bronze badges","comments":[]},{"answer":"Drawing on ideas here and elsewhere I've comprehended a function:\n\ndef merge(*dicts, **kv): \n      return { k:v for d in list(dicts) + [kv] for k,v in d.items() }\n\n\nUsage (tested in python 3):\n\nassert (merge({1:11,'a':'aaa'},{1:99, 'b':'bbb'},foo='bar')==\\\n    {1: 99, 'foo': 'bar', 'b': 'bbb', 'a': 'aaa'})\n\nassert (merge(foo='bar')=={'foo': 'bar'})\n\nassert (merge({1:11},{1:99},foo='bar',baz='quux')==\\\n    {1: 99, 'foo': 'bar', 'baz':'quux'})\n\nassert (merge({1:11},{1:99})=={1: 99})\n\n\nYou could use a lambda instead.\n\nShare\nImprove this answer\nFollow\nanswered Jul 19 '13 at 5:49\nBijou Trouvaille\n6,9844\n4 gold badges\n35\n35 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12. In that light, I present the following:\n\nimport timeit\n\nn=100000\nsu = \"\"\"\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\n\"\"\"\n\ndef timeMerge(f,su,niter):\n    print \"{:4f} sec for: {:30s}\".format(timeit.Timer(f,setup=su).timeit(n),f)\n\ntimeMerge(\"dict(x, **y)\",su,n)\ntimeMerge(\"x.update(y)\",su,n)\ntimeMerge(\"dict(x.items() + y.items())\",su,n)\ntimeMerge(\"for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k] \",su,n)\n\n#confirm for loop adds b entries together\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nfor k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k]\nprint \"confirm b elements are added:\",x\n\nResults:\n0.049465 sec for: dict(x, **y)\n0.033729 sec for: x.update(y)                   \n0.150380 sec for: dict(x.items() + y.items())   \n0.083120 sec for: for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k]\n\nconfirm b elements are added: {'a': 1, 'c': 11, 'b': 12}\n\nShare\nImprove this answer\nFollow\nanswered Dec 3 '13 at 18:11\nupandacross\n3872\n2 silver badges\n7\n7 bronze badges","comments":["You might be interested in cytoolz.merge_with (toolz.readthedocs.io/en/latest/…)"]},{"answer":"from collections import Counter\ndict1 = {'a':1, 'b': 2}\ndict2 = {'b':10, 'c': 11}\nresult = dict(Counter(dict1) + Counter(dict2))\n\n\nThis should solve your problem.\n\nShare\nImprove this answer\nFollow\nanswered Nov 30 '15 at 13:04\nreetesh11\n5836\n6 silver badges\n16\n16 bronze badges","comments":["I will recommend using the Counter's .update() instead of +. This is because, if the sum results to a value of 0 for any of the keys, Counter will delete it."]},{"answer":"There will be a new option when Python 3.8 releases (scheduled for 20 October, 2019), thanks to PEP 572: Assignment Expressions. The new assignment expression operator := allows you to assign the result of the copy and still use it to call update, leaving the combined code a single expression, rather than two statements, changing:\n\nnewdict = dict1.copy()\nnewdict.update(dict2)\n\n\nto:\n\n(newdict := dict1.copy()).update(dict2)\n\n\nwhile behaving identically in every way. If you must also return the resulting dict (you asked for an expression returning the dict; the above creates and assigns to newdict, but doesn't return it, so you couldn't use it to pass an argument to a function as is, a la myfunc((newdict := dict1.copy()).update(dict2))), then just add or newdict to the end (since update returns None, which is falsy, it will then evaluate and return newdict as the result of the expression):\n\n(newdict := dict1.copy()).update(dict2) or newdict\n\n\nImportant caveat: In general, I'd discourage this approach in favor of:\n\nnewdict = {**dict1, **dict2}\n\n\nThe unpacking approach is clearer (to anyone who knows about generalized unpacking in the first place, which you should), doesn't require a name for the result at all (so it's much more concise when constructing a temporary that is immediately passed to a function or included in a list/tuple literal or the like), and is almost certainly faster as well, being (on CPython) roughly equivalent to:\n\nnewdict = {}\nnewdict.update(dict1)\nnewdict.update(dict2)\n\n\nbut done at the C layer, using the concrete dict API, so no dynamic method lookup/binding or function call dispatch overhead is involved (where (newdict := dict1.copy()).update(dict2) is unavoidably identical to the original two-liner in behavior, performing the work in discrete steps, with dynamic lookup/binding/invocation of methods.\n\nIt's also more extensible, as merging three dicts is obvious:\n\n newdict = {**dict1, **dict2, **dict3}\n\n\nwhere using assignment expressions won't scale like that; the closest you could get would be:\n\n (newdict := dict1.copy()).update(dict2), newdict.update(dict3)\n\n\nor without the temporary tuple of Nones, but with truthiness testing of each None result:\n\n (newdict := dict1.copy()).update(dict2) or newdict.update(dict3)\n\n\neither of which is obviously much uglier, and includes further inefficiencies (either a wasted temporary tuple of Nones for comma separation, or pointless truthiness testing of each update's None return for or separation).\n\nThe only real advantage to the assignment expression approach occurs if:\n\nYou have generic code that needs handle both sets and dicts (both of them support copy and update, so the code works roughly as you'd expect it to)\nYou expect to receive arbitrary dict-like objects, not just dict itself, and must preserve the type and semantics of the left hand side (rather than ending up with a plain dict). While myspecialdict({**speciala, **specialb}) might work, it would involve an extra temporary dict, and if myspecialdict has features plain dict can't preserve (e.g. regular dicts now preserve order based on the first appearance of a key, and value based on the last appearance of a key; you might want one that preserves order based on the last appearance of a key so updating a value also moves it to the end), then the semantics would be wrong. Since the assignment expression version uses the named methods (which are presumably overloaded to behave appropriately), it never creates a dict at all (unless dict1 was already a dict), preserving the original type (and original type's semantics), all while avoiding any temporaries.\nShare\nImprove this answer\nFollow\nedited Feb 28 '19 at 17:49\nanswered Feb 28 '19 at 17:16\nShadowRanger\n111k10\n10 gold badges\n134\n134 silver badges\n196\n196 bronze badges","comments":[]},{"answer":"This can be done with a single dict comprehension:\n\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> { key: y[key] if key in y else x[key]\n      for key in set(x) + set(y)\n    }\n\n\nIn my view the best answer for the 'single expression' part as no extra functions are needed, and it is short.\n\nShare\nImprove this answer\nFollow\nanswered Jul 17 '15 at 14:47\nRemcoGerlich\n27.5k4\n4 gold badges\n58\n58 silver badges\n75\n75 bronze badges","comments":["I suspect performance will not be very good though; creating a set out of each dict then only iterating through the keys means another lookup for the value each time (though relatively fast, still increases the order of the function for scaling)","it all depends on the version of the python we are using. In 3.5 and above {**x,**y} gives the concatenated dictionary"]}]},{"id":"630453","href":"https://stackoverflow.com/questions/630453/what-is-the-difference-between-post-and-put-in-http","title":"What is the difference between POST and PUT in HTTP?","description":"\n                \nAccording to RFC 2616, § 9.5, POST is used to create a resource:\n\nThe POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the resource identified by the Request-URI in the Request-Line.\n\nAccording to RFC 2616, § 9.6, PUT is used to create or replace a resource:\n\nThe PUT method requests that the enclosed entity be stored under the supplied Request-URI. If the Request-URI refers to an already existing resource, the enclosed entity SHOULD be considered as a modified version of the one residing on the origin server. If the Request-URI does not point to an existing resource, and that URI is capable of being defined as a new resource by the requesting user agent, the origin server can create the resource with that URI.\n\nSo which HTTP method should be used to create a resource? Or should both be supported?\n    ","questionComments":["It may be helpful to use the definitions in HTTPbis - Roy put a fair amount of work into clarifying them. See: tools.ietf.org/html/…","Just to bring @MarkNottingham's comment to the latest revision, here's POST and PUT, as defined on HTTPbis.","It seems to me that this debate has arisen from the common practice of oversimplifying REST by describing the HTTP Methods in terms of CRUD operations.","Unfortunally the first answers are wrong about POST. Check my answer for a better explanation of the differences: stackoverflow.com/a/18243587/2458234","PUT and POST are both unsafe methods. However, PUT is idempotent, while POST is not. - See more at: restcookbook.com/HTTP%20Methods/put-vs-post/…"],"answers":[{"answer":"Overall:\n\nBoth PUT and POST can be used for creating.\n\nYou have to ask, \"what are you performing the action upon?\", to distinguish what you should be using. Let's assume you're designing an API for asking questions. If you want to use POST, then you would do that to a list of questions. If you want to use PUT, then you would do that to a particular question.\n\nGreat, both can be used, so which one should I use in my RESTful design:\n\nYou do not need to support both PUT and POST.\n\nWhich you use is up to you. But just remember to use the right one depending on what object you are referencing in the request.\n\nSome considerations:\n\nDo you name the URL objects you create explicitly, or let the server decide? If you name them then use PUT. If you let the server decide then use POST.\nPUT is defined to assume idempotency, so if you PUT an object twice, it should have no additional effect. This is a nice property, so I would use PUT when possible. Just make sure that the PUT-idempotency actually is implemented correctly in the server.\nYou can update or create a resource with PUT with the same object URL\nWith POST you can have 2 requests coming in at the same time making modifications to a URL, and they may update different parts of the object.\n\nAn example:\n\nI wrote the following as part of another answer on SO regarding this:\n\nPOST:\n\nUsed to modify and update a resource\n\nPOST /questions/<existing_question> HTTP/1.1\nHost: www.example.com/\n\n\nNote that the following is an error:\n\nPOST /questions/<new_question> HTTP/1.1\nHost: www.example.com/\n\n\nIf the URL is not yet created, you should not be using POST to create it while specifying the name. This should result in a 'resource not found' error because <new_question> does not exist yet. You should PUT the <new_question> resource on the server first.\n\nYou could though do something like this to create a resources using POST:\n\nPOST /questions HTTP/1.1\nHost: www.example.com/\n\n\nNote that in this case the resource name is not specified, the new objects URL path would be returned to you.\n\nPUT:\n\nUsed to create a resource, or overwrite it. While you specify the resources new URL.\n\nFor a new resource:\n\nPUT /questions/<new_question> HTTP/1.1\nHost: www.example.com/\n\n\nTo overwrite an existing resource:\n\nPUT /questions/<existing_question> HTTP/1.1\nHost: www.example.com/\n\n\nAdditionally, and a bit more concisely, RFC 7231 Section 4.3.4 PUT states (emphasis added),\n\n4.3.4. PUT\n\nThe PUT method requests that the state of the target resource be created or replaced with the state defined by the representation enclosed in the request message payload.\n\nShare\nImprove this answer\nFollow\nedited Apr 8 at 9:47\nAlex\n12.4k10\n10 gold badges\n50\n50 silver badges\n74\n74 bronze badges\nanswered Mar 10 '09 at 14:29\nBrian R. Bondy\n317k116\n116 gold badges\n577\n577 silver badges\n621\n621 bronze badges","comments":["I think one cannot stress enough the fact that PUT is idempotent: if the network is botched and the client is not sure whether his request made it through, it can just send it a second (or 100th) time, and it is guaranteed by the HTTP spec that this has exactly the same effect as sending once.","@Jörg W Mittag: Not necessary. The second time could return 409 Conflict or something if the request has been modified in meantime (by some other user or the first request itself, which got through).","If I'm not mistaken, what we should be stressing is that PUT is defined to be idempotent. You still have to write your server in such a way that PUT behaves correctly, yes? Perhaps it's better to say \"PUT causes the transport to assume idempotence, which may affect behavior of the transport, e.g. caching.\"","@JörgWMittag Idempotence catchphrase? How about \"Send and send and send my friend, it makes no difference in the end.\"","Thinks of them as: PUT = insert or update; POST = insert. So when you make two PUT - you get the one new record, when you do two POSTs - you get two new records."]},{"answer":"You can find assertions on the web that say\n\nPOST should be used to create a resource, and PUT should be used to modify one\nPUT should be used to create a resource, and POST should be used to modify one\n\nNeither is quite right.\n\nBetter is to choose between PUT and POST based on idempotence of the action.\n\nPUT implies putting a resource - completely replacing whatever is available at the given URL with a different thing. By definition, a PUT is idempotent. Do it as many times as you like, and the result is the same. x=5 is idempotent. You can PUT a resource whether it previously exists, or not (eg, to Create, or to Update)!\n\nPOST updates a resource, adds a subsidiary resource, or causes a change. A POST is not idempotent, in the way that x++ is not idempotent.\n\nBy this argument, PUT is for creating when you know the URL of the thing you will create. POST can be used to create when you know the URL of the \"factory\" or manager for the category of things you want to create.\n\nso:\n\nPOST /expense-report\n\n\nor:\n\nPUT  /expense-report/10929\n\nShare\nImprove this answer\nFollow\nedited May 22 '13 at 5:56\nthe Tin Man\n152k39\n39 gold badges\n199\n199 silver badges\n279\n279 bronze badges\nanswered Apr 22 '10 at 14:55\nCheeso\n181k93\n93 gold badges\n448\n448 silver badges\n688\n688 bronze badges","comments":["I agree, wherever idempotence is concerned it should trump any other concerns since getting that wrong can cause many many unexpected bugs.","If POST can update a resource, how is that not idempotent? If I change a students age using PUT and do that 10x times the students age is the same if I did it once.","@Schneider, in this case your server is making an extra effort to guarantee idempotence, but it is not advertising it. Browsers will still warn the user if they try to reload such a POST request.","@Schneider POST may create a subsidiary resource; hence you can POST to collection, like POST /expense-reports and it would create as many entities (expense reports) on your server as the quantity of requests you've sent, even if they are completely similar. Think of it as inserting the same row in the DB table (/expense-reports) with auto-incremented primary key. Data remains the same, key (URI in this case) is generated by server and is different for every other insert (request). So, POST effect can be idempotent, but also may not. Hence, POST is not idempotent.","Let's say we have entities which may have two properties - name and date. If we have an entity with an existing name and date, but then make requests to it specifying only a name, the proper behavior of PUT would be to obliterate the date of the entity, whereas POST may update only the properties specified, leaving the unspecified properties as they were before the request was made. Does that sound correct/reasonable, or is it an improper use of PUT (I saw references to PATCH, which it seems would be more appropriate, but doesn't exist yet)?"]},{"answer":"POST to a URL creates a child resource at a server defined URL.\nPUT to a URL creates/replaces the resource in its entirety at the client defined URL.\nPATCH to a URL updates part of the resource at that client defined URL.\n\nThe relevant specification for PUT and POST is RFC 2616 §9.5ff.\n\nPOST creates a child resource, so POST to /items creates a resources that lives under the /items resource. Eg. /items/1. Sending the same post packet twice will create two resources.\n\nPUT is for creating or replacing a resource at a URL known by the client.\n\nTherefore: PUT is only a candidate for CREATE where the client already knows the url before the resource is created. Eg. /blogs/nigel/entry/when_to_use_post_vs_put as the title is used as the resource key\n\nPUT replaces the resource at the known url if it already exists, so sending the same request twice has no effect. In other words, calls to PUT are idempotent.\n\nThe RFC reads like this:\n\nThe fundamental difference between the POST and PUT requests is reflected in the different meaning of the Request-URI. The URI in a POST request identifies the resource that will handle the enclosed entity. That resource might be a data-accepting process, a gateway to some other protocol, or a separate entity that accepts annotations. In contrast, the URI in a PUT request identifies the entity enclosed with the request -- the user agent knows what URI is intended and the server MUST NOT attempt to apply the request to some other resource. If the server desires that the request be applied to a different URI,\n\nNote: PUT has mostly been used to update resources (by replacing them in their entireties), but recently there is movement towards using PATCH for updating existing resources, as PUT specifies that it replaces the whole resource. RFC 5789.\n\nUpdate 2018: There is a case that can be made to avoid PUT. See \"REST without PUT\"\n\nWith “REST without PUT” technique, the idea is that consumers are forced to post new 'nounified' request resources. As discussed earlier, changing a customer’s mailing address is a POST to a new “ChangeOfAddress” resource, not a PUT of a “Customer” resource with a different mailing address field value.\n\ntaken from REST API Design - Resource Modeling by Prakash Subramaniam of Thoughtworks\n\nThis forces the API to avoid state transition problems with multiple clients updating a single resource, and matches more nicely with event sourcing and CQRS. When the work is done asynchronously, POSTing the transformation and waiting for it to be applied seems appropriate.\n\nShare\nImprove this answer\nFollow\nedited Nov 26 '18 at 1:52\nanswered Apr 7 '10 at 5:52\nNigel Thorne\n19.6k3\n3 gold badges\n30\n30 silver badges\n50\n50 bronze badges","comments":["Or from the other side of the fence: PUT if the client determines the resulting resource's address, POST if the server does it.","I think that this answer should be edited to make it more clear what @DanMan pointed in a very simple way. What I find the most valuable here is the note at the end, stating that a PUT should be used only for replacing the whole resource.","PATCH isn't a realistic option for at least a few years, but I agree with the ideology.","I'm trying to understand, but using PUT to create something would only make sense if the client knows for sure that the resource doesn't exist yet, right? Following the blog example, say you have created hundreds of blog posts in a couple of years, then accidentally pick the same title as you did for a post two years ago. Now you have gone and replaced that post, which wasn't intended. So using PUT to create would require the client to track what is taken and what is not, and could lead to accidents and unintended side effects, as well as having routes that do two entirely different things?","You are correct. PUTting a blog post at the same url as an existing one would cause an update to that existing post (although you could obviously check first with a GET). This indicates why it would be a bad idea to use just the title as the URL. It would however work anywhere there was a natural key in the data... which in my experience is rare. Or if you used GUIDs"]},{"answer":"Summary:\nCreate:\n\nCan be performed with both PUT or POST in the following way:\n\nPUT\n\nCreates THE new resource with newResourceId as the identifier, under the /resources URI, or collection.\n\nPUT /resources/<newResourceId> HTTP/1.1 \n\nPOST\n\nCreates A new resource under the /resources URI, or collection. Usually the identifier is returned by the server.\n\nPOST /resources HTTP/1.1\n\nUpdate:\n\nCan only be performed with PUT in the following way:\n\nPUT\n\nUpdates the resource with existingResourceId as the identifier, under the /resources URI, or collection.\n\nPUT /resources/<existingResourceId> HTTP/1.1\n\nExplanation:\n\nWhen dealing with REST and URI as general, you have generic on the left and specific on the right. The generics are usually called collections and the more specific items can be called resource. Note that a resource can contain a collection.\n\nExamples:\n\n<-- generic -- specific -->\n\nURI: website.com/users/john\nwebsite.com  - whole site\nusers        - collection of users\njohn         - item of the collection, or a resource\n\nURI:website.com/users/john/posts/23\nwebsite.com  - whole site\nusers        - collection of users\njohn         - item of the collection, or a resource\nposts        - collection of posts from john\n23           - post from john with identifier 23, also a resource\n\n\nWhen you use POST you are always refering to a collection, so whenever you say:\n\nPOST /users HTTP/1.1\n\n\nyou are posting a new user to the users collection.\n\nIf you go on and try something like this:\n\nPOST /users/john HTTP/1.1\n\n\nit will work, but semantically you are saying that you want to add a resource to the john collection under the users collection.\n\nOnce you are using PUT you are refering to a resource or single item, possibly inside a collection. So when you say:\n\nPUT /users/john HTTP/1.1\n\n\nyou are telling to the server update, or create if it doesn't exist, the john resource under the users collection.\n\nSpec:\n\nLet me highlight some important parts of the spec:\n\nPOST\n\nThe POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the resource identified by the Request-URI in the Request-Line\n\nHence, creates a new resource on a collection.\n\nPUT\n\nThe PUT method requests that the enclosed entity be stored under the supplied Request-URI. If the Request-URI refers to an already existing resource, the enclosed entity SHOULD be considered as a modified version of the one residing on the origin server. If the Request-URI does not point to an existing resource, and that URI is capable of being defined as a new resource by the requesting user agent, the origin server can create the resource with that URI.\"\n\nHence, create or update based on existence of the resource.\n\nReference:\nHTTP/1.1 Spec\nWikipedia - REST\nUniform Resource Identifiers (URI): Generic Syntax and Semantics\nShare\nImprove this answer\nFollow\nedited Feb 9 '16 at 18:25\nKobayashi\n1,9971\n1 gold badge\n13\n13 silver badges\n20\n20 bronze badges\nanswered Aug 14 '13 at 22:47\n7hi4g0\n3,3793\n3 gold badges\n20\n20 silver badges\n32\n32 bronze badges","comments":["This post was helpful to me in understanding that POST adds \"something\" as a child to the given collection (URI), whereas PUT explicitly defines the \"something\" at the given URI location.","This is the best answer, here, I think: none of this \"POST can update a resource\" nonsense. I like your statement, \"Update can only be performed with PUT\".","No, PUT is not for update or create. It is for replacing. Note that you can replace nothing with something for the effect of creating.","@7hi4g0 PUT is for for updating with a complete replacement, in other words, it replaces. You replace nothing with something, or something with a completely new something. PUT is not for making a minor change (unless you have the client make that minor change and provide the entire new version, even what is remaining the same). For partial modification, PATCH is the method of choice.","@thecoshman You could, but it wouldn't be too clear that create is also covered in there. In this case, it is better to be explicit."]},{"answer":"POST means \"create new\" as in \"Here is the input for creating a user, create it for me\".\n\nPUT means \"insert, replace if already exists\" as in \"Here is the data for user 5\".\n\nYou POST to example.com/users since you don't know the URL of the user yet, you want the server to create it.\n\nYou PUT to example.com/users/id since you want to replace/create a specific user.\n\nPOSTing twice with the same data means create two identical users with different ids. PUTing twice with the same data creates the user the first and updates him to the same state the second time (no changes). Since you end up with the same state after a PUT no matter how many times you perform it, it is said to be \"equally potent\" every time - idempotent. This is useful for automatically retrying requests. No more 'are you sure you want to resend' when you push the back button on the browser.\n\nA general advice is to use POST when you need the server to be in control of URL generation of your resources. Use PUT otherwise. Prefer PUT over POST.\n\nShare\nImprove this answer\nFollow\nedited Dec 20 '19 at 8:22\nAshwini Chougale\n1,04310\n10 silver badges\n25\n25 bronze badges\nanswered Oct 23 '11 at 14:27\nAlexander Torstling\n16.9k6\n6 gold badges\n55\n55 silver badges\n70\n70 bronze badges","comments":["Sloppiness may have cause it to be commonly taught that there are only two verbs you need: GET and POST. GET to obtain, POST to change. Even PUT and DELETE were performed using POST. Asking what PUT really means 25 years later maybe a sign we learned it wrong at first. REST popularity drove people back to the basics where we must now unlearn past bad mistakes. POST was overused and now commonly taught incorrectly. Best part: \"POSTing twice with the same data means create two identical [resources]\". Great point!","How can you use PUT to create a record by the ID, like in your example user 5 if it doesn't exist yet? Don't you mean update, replace if already exists? or something","@Coulton: I meant what I wrote. You insert user 5 if you PUT to /users/5 and #5 does not exist yet.","\"Prefer PUT over POST\"... care to justify that?","@thecoshman: Sure. I wrote that as a general advise. My reasoning is that PUT is idempotent, hence better from a network perspective. POST is also more general, so by recommending PUT you avoid POST being used for situations where PUT would have sufficed. POST is also heavily overused due to browser restrictions, and so a recommendation against it will have positive effects for REST as a concept. There are also some positive effects in the URL scheme when the clients are in control of the URL construction IMO, but I cannot fit that into a comment here."]},{"answer":"I'd like to add my \"pragmatic\" advice. Use PUT when you know the \"id\" by which the object you are saving can be retrieved. Using PUT won't work too well if you need, say, a database generated id to be returned for you to do future lookups or updates.\n\nSo: To save an existing user, or one where the client generates the id and it's been verified that the id is unique:\n\nPUT /user/12345 HTTP/1.1  <-- create the user providing the id 12345\nHost: mydomain.com\n\nGET /user/12345 HTTP/1.1  <-- return that user\nHost: mydomain.com\n\n\nOtherwise, use POST to initially create the object, and PUT to update the object:\n\nPOST /user HTTP/1.1   <--- create the user, server returns 12345\nHost: mydomain.com\n\nPUT /user/12345 HTTP/1.1  <--- update the user\nHost: mydomain.com\n\nShare\nImprove this answer\nFollow\nedited May 25 '11 at 3:43\nanswered Jan 15 '11 at 19:59\nThaDon\n7,2909\n9 gold badges\n46\n46 silver badges\n79\n79 bronze badges","comments":["Actually, it should be POST /users. (Note that /users is plural.) This has the affect of creating a new user and making it a child resource of the /users collection.","@DavidRR to be fair, how to handle groups is another debate altogether. GET /users makes sense, it reads as you want, but I'd be ok with GET /user/<id> or POST /user (with payload for said new user) because it reads correctly 'get me users 5' is odd, but 'get me user 5' is more natural. I'd probably still fall down on the side of pluralisation though :)","@thecoshman You can read it like 'from users get me id 5' ;)","@xuiqzy hmm, I quite like this way of thinking about it really, and expands nicely GET /users/5/documents/4/title would be like 'get the users, from there get me user 5, from there get me the documents, from there get me document 4, from there get me the title'"]},{"answer":"Both are used for data transmission between client to server, but there are subtle differences between them, which are:\n\nPUT\tPOST\nReplacing existing resource or creating if resource is not exist. www.example.com/com/customer/{customerId} www.example.com/com/customer/123/order/{orderId} Identifier is chosen by the client.\tCreating new resources and subordinate resources, e.g. a file is subordinate to a directory containing it or a row is subordinate to a database table. www.example.com/com/customer/ www.example.com/com/customer/123/order/ identifier is returned by server\nIdempotent i.e. if you PUT a resource twice, it has no effect. Example: Do it as many times as you want, the result will be same. x=1;\tPOST is neither safe nor idempotent. Example: x++;\nWorks as specific\tWorks as abstractive\nIf you create or update a resource using PUT and then make that same call again, the resource is still there and still has the same state as it did with the first call.\tMaking two identical POST requests will most likely result in two resources containing the same information.\n\nAnalogy:\n\nPUT i.e. take and put where it was.\nPOST as send mail in post office.\n\nSocial Media/Network Analogy:\n\nPost on social media: when we post message, it creates new post.\nPut(i.e. edit) for the message we already Posted.\nShare\nImprove this answer\nFollow\nedited Jul 2 at 14:13\nanswered Sep 11 '15 at 13:12\nPremraj\n59k24\n24 gold badges\n216\n216 silver badges\n163\n163 bronze badges","comments":["@MobileMon No, REST methods are not CRUD.","I'd say PUT for UPSERTS","@MobileMon no : POST when you create a new resource and you don't know the final endpoint to get it. PUT for other cases."]},{"answer":"Use POST to create, and PUT to update. That's how Ruby on Rails is doing it, anyway.\n\nPUT    /items/1      #=> update\nPOST   /items        #=> create\n\nShare\nImprove this answer\nFollow\nedited Sep 16 '17 at 20:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 10 '09 at 14:28\nTim Sullivan\n16.4k11\n11 gold badges\n73\n73 silver badges\n116\n116 bronze badges","comments":["POST /items adds a new item to an already defined resource ('item'). It does not, as the answer says, \"create a group.\" I don't understand why this has 12 votes.","Out of the box, Rails does not support 'creating a group' via REST. To 'create a group' by which I mean 'create a resource' you have to do it via the source code.","This is a fair guideline, but an oversimplification. As the other answers mention, either method could be used for both create and update.","I agree with the answer with a slight modification. Use POST to create and PUT to update the resource completely. For partial updates, we can use PUT or PATCH. Lets say we want to update the status of a group. We can use PUT /groups/1/status with the status is the request payload or PATCH /groups/1 with the details about the action in the payload","It should also be made clear that PUT /items/42 is also valid for creating a resource, but only if the client has the privilege of naming the resource. (Does Rails allow a client this naming privilege?)"]},{"answer":"REST is a very high-level concept. In fact, it doesn't even mention HTTP at all!\n\nIf you have any doubts about how to implement REST in HTTP, you can always take a look at the Atom Publication Protocol (AtomPub) specification. AtomPub is a standard for writing RESTful webservices with HTTP that was developed by many HTTP and REST luminaries, with some input from Roy Fielding, the inventor of REST and (co-)inventor of HTTP himself.\n\nIn fact, you might even be able to use AtomPub directly. While it came out of the blogging community, it is in no way restricted to blogging: it is a generic protocol for RESTfully interacting with arbitrary (nested) collections of arbitrary resources via HTTP. If you can represent your application as a nested collection of resources, then you can just use AtomPub and not worry about whether to use PUT or POST, what HTTP Status Codes to return and all those details.\n\nThis is what AtomPub has to say about resource creation (section 9.2):\n\nTo add members to a Collection, clients send POST requests to the URI of the Collection.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Mar 10 '09 at 15:27\nJörg W Mittag\n340k72\n72 gold badges\n416\n416 silver badges\n617\n617 bronze badges","comments":["There's nothing wrong with allowing PUT to create resources. Just be aware that it means that the client provides the URL.","There's something very wrong with allowing PUT to create resources: the client provides the URL. That's the server's job!","@Joshcodes It is not always the case that it is the server's job to create client ids. I have increasingly seen designs that let clients generate some sort of UUID as the resource id. This design lends itself in particular to increase scale.","@JustinOhms I agree with your point about client generated IDs (side note: all systems designed by me since circa 2008 require the client to create the ID as a UUID/Guid). That does not mean the client should specify the URL.","Yes, if the resource already exists, use PUT. However, in nearly all cases, the resources should be created with POST and the client should not provide the URL. Roy Fielding agrees with this statement FWIW: roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven"]},{"answer":"The decision of whether to use PUT or POST to create a resource on a server with an HTTP + REST API is based on who owns the URL structure. Having the client know, or participate in defining, the URL struct is an unnecessary coupling akin to the undesirable couplings that arose from SOA. Escaping types of couplings is the reason REST is so popular. Therefore, the proper method to use is POST. There are exceptions to this rule and they occur when the client wishes to retain control over the location structure of the resources it deploys. This is rare and likely means something else is wrong.\n\nAt this point some people will argue that if RESTful-URL's are used, the client does knows the URL of the resource and therefore a PUT is acceptable. After all, this is why canonical, normalized, Ruby on Rails, Django URLs are important, look at the Twitter API … blah blah blah. Those people need to understand there is no such thing as a Restful-URL and that Roy Fielding himself states that:\n\nA REST API must not define fixed resource names or hierarchies (an obvious coupling of client and server). Servers must have the freedom to control their own namespace. Instead, allow servers to instruct clients on how to construct appropriate URIs, such as is done in HTML forms and URI templates, by defining those instructions within media types and link relations. [Failure here implies that clients are assuming a resource structure due to out-of band information, such as a domain-specific standard, which is the data-oriented equivalent to RPC's functional coupling].\n\nhttp://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven\n\nThe idea of a RESTful-URL is actually a violation of REST as the server is in charge of the URL structure and should be free to decide how to use it to avoid coupling. If this confuses you read about the significance of self discovery on API design.\n\nUsing POST to create resources comes with a design consideration because POST is not idempotent. This means that repeating a POST several times does not guarantee the same behavior each time. This scares people into using PUT to create resources when they should not. They know it's wrong (POST is for CREATE) but they do it anyway because they don't know how to solve this problem. This concern is demonstrated in the following situation:\n\nThe client POST a new resource to the server.\nThe server processes the request and sends a response.\nThe client never receives the response.\nThe server is unaware the client has not received the response.\nThe client does not have a URL for the resource (therefore PUT is not an option) and repeats the POST.\nPOST is not idempotent and the server …\n\nStep 6 is where people commonly get confused about what to do. However, there is no reason to create a kludge to solve this issue. Instead, HTTP can be used as specified in RFC 2616 and the server replies:\n\n10.4.10 409 Conflict\n\nThe request could not be completed due to a conflict with the current state of the resource. This code is only allowed in situations where it is expected that the user might be able to resolve the conflict and resubmit the request. The response body SHOULD include enough\n\ninformation for the user to recognize the source of the conflict. Ideally, the response entity would include enough information for the user or user agent to fix the problem; however, that might not be possible and is not required.\n\nConflicts are most likely to occur in response to a PUT request. For example, if versioning were being used and the entity being PUT included changes to a resource which conflict with those made by an earlier (third-party) request, the server might use the 409 response to indicate that it can’t complete the request. In this case, the response entity would likely contain a list of the differences between the two versions in a format defined by the response Content-Type.\n\nReplying with a status code of 409 Conflict is the correct recourse because:\n\nPerforming a POST of data which has an ID which matches a resource already in the system is “a conflict with the current state of the resource.”\nSince the important part is for the client to understand the server has the resource and to take appropriate action. This is a “situation(s) where it is expected that the user might be able to resolve the conflict and resubmit the request.”\nA response which contains the URL of the resource with the conflicting ID and the appropriate preconditions for the resource would provide “enough information for the user or user agent to fix the problem” which is the ideal case per RFC 2616.\n\nUpdate based on release of RFC 7231 to Replace 2616\n\nRFC 7231 is designed to replace 2616 and in Section 4.3.3 describes the follow possible response for a POST\n\nIf the result of processing a POST would be equivalent to a representation of an existing resource, an origin server MAY redirect the user agent to that resource by sending a 303 (See Other) response with the existing resource's identifier in the Location field. This has the benefits of providing the user agent a resource identifier and transferring the representation via a method more amenable to shared caching, though at the cost of an extra request if the user agent does not already have the representation cached.\n\nIt now may be tempting to simply return a 303 in the event that a POST is repeated. However, the opposite is true. Returning a 303 would only make sense if multiple create requests (creating different resources) return the same content. An example would be a \"thank you for submitting your request message\" that the client need not re-download each time. RFC 7231 still maintains in section 4.2.2 that POST is not to be idempotent and continues to maintain that POST should be used for create.\n\nFor more information about this, read this article.\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '17 at 12:39\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 29 '13 at 23:00\nJoshcodes\n7,6035\n5 gold badges\n38\n38 silver badges\n44\n44 bronze badges","comments":["Would a 409 Conflict response be the appropriate code for something like trying to create a new account with a username that already exists? I've been using 409 for versioning conflicts specifically, but after reading your answer, I wonder if it shouldn't be used for any \"duplicate\" requests.","@EricB. Yes, in the situation you describe \"due to a conflict with the current state of the resource\" the operation fails. Additionally, it is reasonable to expect that the user can resolve the conflict and the message body only needs to inform the user that the username already exists.","@Joshcodes can you say more about the conflict resolution process? In this case, if the username already exists is the client expected to prompt the end user for a different username? What if the client is actually trying to use POST to change the username? Should PUT requests still be used for updating parameters, while POST is used for creating objects whether it be one at a time or several? Thanks.","@BFar2 if the username already exists then the client should prompt the user. To change the username, assuming the username is part of an already created resource which needs modified, PUT would be used because you are correct, POST is used for create, always and PUT for updates.","explaining things using short and effective language is also a desirable skill"]},{"answer":"I like this advice, from RFC 2616's definition of PUT:\n\nThe fundamental difference between the POST and PUT requests is reflected in the different meaning of the Request-URI. The URI in a POST request identifies the resource that will handle the enclosed entity. That resource might be a data-accepting process, a gateway to some other protocol, or a separate entity that accepts annotations. In contrast, the URI in a PUT request identifies the entity enclosed with the request -- the user agent knows what URI is intended and the server MUST NOT attempt to apply the request to some other resource.\n\nThis jibes with the other advice here, that PUT is best applied to resources that already have a name, and POST is good for creating a new object under an existing resource (and letting the server name it).\n\nI interpret this, and the idempotency requirements on PUT, to mean that:\n\nPOST is good for creating new objects under a collection (and create does not need to be idempotent)\nPUT is good for updating existing objects (and update needs to be idempotent)\nPOST can also be used for non-idempotent updates to existing objects (especially, changing part of an object without specifying the whole thing -- if you think about it, creating a new member of a collection is actually a special case of this kind of update, from the collection's perspective)\nPUT can also be used for create if and only if you allow the client to name the resource. But since REST clients aren't supposed to make assumptions about URL structure, this is less in the intended spirit of things.\nShare\nImprove this answer\nFollow\nanswered Jan 11 '12 at 17:18\nmetamatt\n12.5k7\n7 gold badges\n42\n42 silver badges\n55\n55 bronze badges","comments":["\"POST can also be used for non-idempotent updates to existing objects (especially, changing part of an object without specifying the whole thing\" That's what PATCH is for"]},{"answer":"In short:\n\nPUT is idempotent, where the resource state will be the same if the same operation is executed one time or multiple times.\n\nPOST is non-idempotent, where the resource state may become different if the operation is executed multiple times as compared to executing a single time.\n\nAnalogy with database query\n\nPUT You can think of similar to \"UPDATE STUDENT SET address = \"abc\" where id=\"123\";\n\nPOST You can think of something like \"INSERT INTO STUDENT(name, address) VALUES (\"abc\", \"xyzzz\");\n\nStudent Id is auto generated.\n\nWith PUT, if the same query is executed multiple times or one time, the STUDENT table state remains the same.\n\nIn case of POST, if the same query is executed multiple times then multiple Student records get created in the database and the database state changes on each execution of an \"INSERT\" query.\n\nNOTE: PUT needs a resource location (already-resource) on which update needs to happen, whereas POST doesn't require that. Therefore intuitively POST is meant for creation of a new resource, whereas PUT is needed for updating the already existing resource.\n\nSome may come up with that updates can be performed with POST. There is no hard rule which one to use for updates or which one to use for create. Again these are conventions, and intuitively I'm inclined with the above mentioned reasoning and follow it.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jul 29 '16 at 11:11\nbharatj\n1,8611\n1 gold badge\n20\n20 silver badges\n24\n24 bronze badges","comments":["for PUT is similar to INSERT or UPDATE query","actually PUT You can think of similar to \"UPDATE STUDENT SET address = \"abc\" where id=\"123\"; would be a statement for PATCH. \"UPDATE STUDENT SET address = \"abc\", name=\"newname\" where id=\"123\" would be a correct analogy for PUT","Put could also be used for INSERT. For example if you server detected you were trying to upload the same file multiple times, it would make your request idempotent. (No new file uploads are done)."]},{"answer":"POST is like posting a letter to a mailbox or posting an email to an email queue. PUT is like when you put an object in a cubby hole or a place on a shelf (it has a known address).\n\nWith POST, you're posting to the address of the QUEUE or COLLECTION. With PUT, you're putting to the address of the ITEM.\n\nPUT is idempotent. You can send the request 100 times and it will not matter. POST is not idempotent. If you send the request 100 times, you'll get 100 emails or 100 letters in your postal box.\n\nA general rule: if you know the id or name of the item, use PUT. If you want the id or name of the item to be assigned by the receiving party, use POST.\n\nShare\nImprove this answer\nFollow\nedited Jul 10 '13 at 19:52\nanswered Jun 14 '13 at 18:10\nHomer6\n14.1k10\n10 gold badges\n53\n53 silver badges\n78\n78 bronze badges","comments":["No, PUT implies that you know the URL. If you only know the ID then POST with that ID to get the URL.","The id is part of the URL, so yes, use PUT if you know the URL (which includes the id).","No, the URL is determined by the server and the ID is not necessarily part of the URL. Roy Fielding would tell you the same or you could just read his thesis.","@Joshcodes, is that assuming REST? In a RESTful architecture, the item id is most definitely part of the URL, as in: /people/123. I like this site for REST: microformats.org/wiki/rest/urls","@Beez the mircoformats link suggests a good way for servers to structure their URLs but the server determines the URL. The client next-to-never does. See my answer or associated article if you don't understand this."]},{"answer":"Short Answer:\n\nSimple rule of thumb: Use POST to create, use PUT to update.\n\nLong Answer:\n\nPOST:\n\nPOST is used to send data to server.\nUseful when the resource's URL is unknown\n\nPUT:\n\nPUT is used to transfer state to the server\nUseful when a resource's URL is known\n\nLonger Answer:\n\nTo understand it we need to question why PUT was required, what were the problems PUT was trying to solve that POST couldn't.\n\nFrom a REST architecture's point of view there is none that matters. We could have lived without PUT as well. But from a client developer's point of view it made his/her life a lot simpler.\n\nPrior to PUT, clients couldn't directly know the URL that the server generated or if all it had generated any or whether the data to be sent to the server is already updated or not. PUT relieved the developer of all these headaches. PUT is idempotent, PUT handles race conditions, and PUT lets the client choose the URL.\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '17 at 13:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 15 '17 at 2:33\nishandutta2007\n13.2k12\n12 gold badges\n79\n79 silver badges\n104\n104 bronze badges","comments":["Your short answer might be VERY wrong. HTTP PUT is free to be repeated by HTTP proxies. And so, if PUT is actually doing SQL INSERT it might fail second time, which means it would return different result and so it would not be IDEMPOTENT (which is the difference between PUT and POST)"]},{"answer":"New answer (now that I understand REST better):\n\nPUT is merely a statement of what content the service should, from now on, use to render representations of the resource identified by the client; POST is a statement of what content the service should, from now on, contain (possibly duplicated) but it's up to the server how to identify that content.\n\nPUT x (if x identifies a resource): \"Replace the content of the resource identified by x with my content.\"\n\nPUT x (if x does not identify a resource): \"Create a new resource containing my content and use x to identify it.\"\n\nPOST x: \"Store my content and give me an identifier that I can use to identify a resource (old or new) containing said content (possibly mixed with other content). Said resource should be identical or subordinate to that which x identifies.\" \"y's resource is subordinate to x's resource\" is typically but not necessarily implemented by making y a subpath of x (e.g. x = /foo and y = /foo/bar) and modifying the representation(s) of x's resource to reflect the existence of a new resource, e.g. with a hyperlink to y's resource and some metadata. Only the latter is really essential to good design, as URLs are opaque in REST -- you're supposed to use hypermedia instead of client-side URL construction to traverse the service anyways.\n\nIn REST, there's no such thing as a resource containing \"content\". I refer as \"content\" to data that the service uses to render representations consistently. It typically consists of some related rows in a database or a file (e.g. an image file). It's up to the service to convert the user's content into something the service can use, e.g. converting a JSON payload into SQL statements.\n\nOriginal answer (might be easier to read):\n\nPUT /something (if /something already exists): \"Take whatever you have at /something and replace it with what I give you.\"\n\nPUT /something (if /something does not already exist): \"Take what I give you and put it at /something.\"\n\nPOST /something: \"Take what I give you and put it anywhere you want under /something as long as you give me its URL when you're done.\"\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:55\nCommunity♦\n11\n1 silver badge\nanswered Aug 1 '12 at 20:10\nJordan\n4,2304\n4 gold badges\n30\n30 silver badges\n40\n40 bronze badges","comments":["But how can you use PUT to create a new resource if it doesn't exist, while your ID generation method is on Auto Increment ? Usually ORM's does auto generate the ID for you, like the way you want it to be in a POST for example. Does it mean that if you want to implement PUT the right way you have to change your id auto generation ? This is awkward if the answer is yes.","@RoniAxelrad : PUT is like a database \"INSERT OR UPDATE\" statement where you are including the key in the statement, so only applicable where you can guarente no collisions. eg. your domain has a 'natural key' or you use a guid. POST is like inserting into a table with an auto incrementing key. You have to be told by the database what ID it got after it has been inserted. Note your \"INSERT OR UPDATE\" will replace any previous data if it existed.","@NigelThorne Thanks for your answer. So if for example I'm trying to PUT a book id 10 with a URI: PUT books/10. If book id 10 does not exists, I should create a book with id 10 right? but I cannot control the creation ID numerator, because it's auto increment. what should I do in that situation ?","@RoniAxelrad REST PUT to an ID that doesn't exist is a request to the server to create a resource. It's still up to the server to decide if it wants to allow that. The server is in charge. It can respond with \"No. I'm not going to do that\". You already do that if the user doesn't have enough permissions...etc. It's okay for the server to say \"No\". REST is a convention that lets us define the meaning of various types of request ... your server decides what to do with those requests based on your business logic :) Even if it says \"no\" it's still following REST :)"]},{"answer":"Ruby on Rails 4.0 will use the 'PATCH' method instead of PUT to do partial updates.\n\nRFC 5789 says about PATCH (since 1995):\n\nA new method is necessary to improve interoperability and prevent errors. The PUT method is already defined to overwrite a resource with a complete new body, and cannot be reused to do partial changes. Otherwise, proxies and caches, and even clients and servers, may get confused as to the result of the operation. POST is already used but without broad interoperability (for one, there is no standard way to discover patch format support). PATCH was mentioned in earlier HTTP specifications, but not completely defined.\n\n\"Edge Rails: PATCH is the new primary HTTP method for updates\" explains it.\n\nShare\nImprove this answer\nFollow\nedited Sep 16 '17 at 20:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 26 '12 at 9:21\ngermanlinux\n2,3931\n1 gold badge\n18\n18 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"At the risk of restating what has already been said, it seems important to remember that PUT implies that the client controls what the URL is going to end up being, when creating a resource. So part of the choice between PUT and POST is going to be about how much you can trust the client to provide correct, normalized URL that are coherent with whatever your URL scheme is.\n\nWhen you can't fully trust the client to do the right thing, it would be more appropriate to use POST to create a new item and then send the URL back to the client in the response.\n\nShare\nImprove this answer\nFollow\nedited Aug 28 '14 at 9:17\nbeginer\n18811\n11 bronze badges\nanswered Mar 25 '11 at 10:17\nskillet-thief\n4994\n4 silver badges\n8\n8 bronze badges","comments":["I'm a bit late to this - but someone saying something similar on another website got it to click for me. If you're creating a resource and using an auto-incremented ID as it's \"identifier\" instead of a user assigned name, it should be a POST.","This isn't quite right - PUT can still create a resource by referring to it with a non-canonical name, as long as in the response, the server returns a Location header that does contain the canonical resource name.","@Joshcodes don't forget that you can have many URIs referencing the same underlying resource. So what Ether said is sound advice, the client can PUT to a URL (that might be more semantic, like PUT /X-files/series/4/episodes/max) and the server respond with a URI that provides a short canonical unique link to that new resource (ie /X-Ffiles/episodes/91)","@thecoshman the issue is the concern for the URL structure does not belong to the client. Reading about self-discovery (also part of REST) may help make this clear.","@Joshcodes then by that logic, a client should never use PUT to create as they shouldn't be concerned with with providing the URL. Well... unless the server provided a URL to PUT to if the client wants to put to it... something like \"PUT /comments/new\" and the server might respond \"204 /comments/234532\" but that seems a bit RPC to me, the client should just POST to /comments..."]},{"answer":"In a very simple way I'm taking the example of the Facebook timeline.\n\nCase 1: When you post something on your timeline, it's a fresh new entry. So in this case they use the POST method because the POST method is non-idempotent.\n\nCase 2: If your friend comment on your post the first time, that also will create a new entry in the database so the POST method used.\n\nCase 3: If your friend edits his comment, in this case, they had a comment id, so they will update an existing comment instead of creating a new entry in the database. Therefore for this type of operation use the PUT method because it is idempotent.*\n\nIn a single line, use POST to add a new entry in the database and PUT to update something in the database.\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '17 at 12:49\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 14 '17 at 6:55\nUniCoder\n2,31322\n22 silver badges\n23\n23 bronze badges","comments":["If the comment is an object with property like user id, created date, comment-message, etc. and at the time of edit only comment-message is getting updated, PATCH should be done here?","PUT is used by FB to update the comment because an existing resource is being updated, and that is what PUT does (updates a resource). PUT happens to be idempotent, in contrast to POST. An HTTP verb being idempotent affects the error handling but does not dictate usage. See my answer for a more detail explanation: stackoverflow.com/questions/630453/put-vs-post-in-rest/…"]},{"answer":"The most important consideration is reliability. If a POST message gets lost the state of the system is undefined. Automatic recovery is impossible. For PUT messages, the state is undefined only until the first successful retry.\n\nFor instance, it may not be a good idea to create credit card transactions with POST.\n\nIf you happen to have auto generated URI's on your resource you can still use PUT by passing a generated URI (pointing to an empty resource) to the client.\n\nSome other considerations:\n\nPOST invalidates cached copies of the entire containing resource (better consistency)\nPUT responses are not cacheable while POST ones are (Require Content-Location and expiration)\nPUT is less supported by e.g. Java ME, older browsers, firewalls\nShare\nImprove this answer\nFollow\nedited Feb 10 '12 at 5:53\nanswered Feb 8 '12 at 16:31\nHans Malherbe\n2,86220\n20 silver badges\n18\n18 bronze badges","comments":["This is incorrect. For POST, the state is also undefined only until the first successful retry. Then, either the server accepts the POST (message never arrived), throws a 409 conflict for a duplicate ID (message arrived, response was lost), or any other valid response.","In general a useragent would not able to safely retry the POST operation since the POST operation gives no that guarantee that two operations would have the same effect as one. The term \"ID\" has nothing to do with HTTP. The URI identifies the resource.","A useragent can \"safely\" retry a POST operation as many times as it wants. It will just receive a duplicate ID error (assuming the resource has an ID) or a duplicate data error (assuming that's an issue and the resource does not have IDs).","Bangs head against wall. HTTP has no solution to the problem of reliability, and this is not well understood, not much discussed, and simply not catered for in the vast majority of web applications. @Joshcodes I have an answer to this question. I essentially agree with Hans. There's a problem.","@bbsimonbb, HTTP has a robust and well documented set of error responses. My answer to this question (stackoverflow.com/questions/630453/put-vs-post-in-rest/…) covers how to use http according to specification to achieve consistency."]},{"answer":"In addition to differences suggested by others, I want to add one more.\n\nIn POST method you can send body params in form-data\n\nIn PUT method you have to send body params in x-www-form-urlencoded\n\nHeader Content-Type:application/x-www-form-urlencoded\n\nAccording to this, you cannot send files or multipart data in the PUT method\n\nEDIT\n\nThe content type \"application/x-www-form-urlencoded\" is inefficient for sending large quantities of binary data or text containing non-ASCII characters. The content type \"multipart/form-data\" should be used for submitting forms that contain files, non-ASCII data, and binary data.\n\nWhich means if you have to submit\n\nfiles, non-ASCII data, and binary data\n\nyou should use POST method\n\nShare\nImprove this answer\nFollow\nedited Oct 1 '18 at 9:33\nanswered Sep 25 '18 at 8:28\nRohit Dhiman\n2,40313\n13 silver badges\n32\n32 bronze badges","comments":["Why was this not upvoted? If true, this is a critical distinction is it not?","I faced it when implementing API for the profile update, which includes user profile pic upload. Then I tested it with the postman, Ajax, PHP curl and laravel 5.6 as backend."]},{"answer":"Readers new to this topic will be struck by the endless discussion about what you should do, and the relative absence of lessons from experience. The fact that REST is \"preferred\" over SOAP is, I suppose, a high-level learning from experience, but goodness we must have progressed from there? It's 2016. Roy's dissertation was in 2000. What have we developed? Was it fun? Was it easy to integrate with? To support? Will it handle the rise of smartphones and flaky mobile connections?\n\nAccording to ME, real-life networks are unreliable. Requests timeout. Connections are reset. Networks go down for hours or days at a time. Trains go into tunnels with mobile users aboard. For any given request (as occasionally acknowledged in all this discussion) the request can fall in the water on its way, or the response can fall in the water on its way back. In these conditions, issuing PUT, POST and DELETE requests directly against substantive resources has always struck me as a little brutal and naive.\n\nHTTP does nothing to ensure reliable completion of the request-response, and that's just fine because this is properly the job of network-aware applications. Developing such an application, you can jump through hoops to use PUT instead of POST, then more hoops to give a certain kind of error on the server if you detect duplicate requests. Back at the client, you then have to jump through hoops to interpret these errors, refetch, revalidate and repost.\n\nOr you can do this: consider your unsafe requests as ephemeral single-user resources (let's call them actions). Clients request a new \"action\" on a substantive resource with an empty POST to the resource. POST will be used only for this. Once safely in possession of the URI of the freshly minted action, the client PUTs the unsafe request to the action URI, not the target resource. Resolving the action and updating the \"real\" resource is properly the job of your API, and is here decoupled from the unreliable network.\n\nThe server does the business, returns the response and stores it against the agreed action URI. If anything goes wrong, the client repeats the request (natural behaviour!), and if the server has already seen it, it repeats the stored response and does nothing else.\n\nYou will quickly spot the similarity with promises: we create and return the placeholder for the result before doing anything. Also like a promise, an action can succeed or fail one time, but its result can be fetched repeatedly.\n\nBest of all, we give sending and receiving applications a chance to link the uniquely identified action to uniqueness in their respective environments. And we can start to demand, and enforce!, responsible behaviour from clients: repeat your requests as much as you like, but don't go generating a new action until you're in possession of a definitive result from the existing one.\n\nAs such, numerous thorny problems go away. Repeated insert requests won't create duplicates, and we don't create the real resource until we're in possession of the data. (database columns can stay not-nullable). Repeated update requests won't hit incompatible states and won't overwrite subsequent changes. Clients can (re)fetch and seamlessy process the original confirmation for whatever reason (client crashed, response went missing, etc.).\n\nSuccessive delete requests can see and process the original confirmation, without hitting a 404 error. If things take longer than expected, we can respond provisionally, and we have a place where the client can check back for the definitive result. The nicest part of this pattern is its Kung-Fu (Panda) property. We take a weakness, the propensity for clients to repeat a request any time they don't understand the response, and turn it into a strength :-)\n\nBefore telling me this is not RESTful, please consider the numerous ways in which REST principles are respected. Clients don't construct URLs. The API stays discoverable, albeit with a little change in semantics. HTTP verbs are used appropriately. If you think this is a huge change to implement, I can tell you from experience that it's not.\n\nIf you think you'll have huge amounts of data to store, let's talk volumes: a typical update confirmation is a fraction of a kilobyte. HTTP currently gives you a minute or two to respond definitively. Even if you only store actions for a week, clients have ample chance to catch up. If you have very high volumes, you may want a dedicated acid-compliant key value store, or an in-memory solution.\n\nShare\nImprove this answer\nFollow\nedited May 23 '18 at 14:06\nanswered Feb 18 '16 at 11:45\nbbsimonbb\n21.2k10\n10 gold badges\n60\n60 silver badges\n94\n94 bronze badges","comments":["Wont storing response be like maintaining a session? Which would cause (horizontal) scaling issues."]},{"answer":"There seems to always be some confusion as to when to use the HTTP POST versus the HTTP PUT method for REST services. Most developers will try to associate CRUD operations directly to HTTP methods. I will argue that this is not correct and one can not simply associate the CRUD concepts to the HTTP methods. That is:\n\nCreate => HTTP PUT\nRetrieve => HTTP GET\nUpdate => HTTP POST\nDelete => HTTP DELETE\n\n\nIt is true that the R(etrieve) and D(elete) of the CRUD operations can be mapped directly to the HTTP methods GET and DELETE respectively. However, the confusion lies in the C(reate) and U(update) operations. In some cases, one can use the PUT for a create while in other cases a POST will be required. The ambiguity lies in the definition of an HTTP PUT method versus an HTTP POST method.\n\nAccording to the HTTP 1.1 specifications the GET, HEAD, DELETE, and PUT methods must be idempotent, and the POST method is not idempotent. That is to say that an operation is idempotent if it can be performed on a resource once or many times and always return the same state of that resource. Whereas a non idempotent operation can return a modified state of the resource from one request to another. Hence, in a non idempotent operation, there is no guarantee that one will receive the same state of a resource.\n\nBased on the above idempotent definition, my take on using the HTTP PUT method versus using the HTTP POST method for REST services is: Use the HTTP PUT method when:\n\nThe client includes all aspect of the resource including the unique identifier to uniquely identify the resource. Example: creating a new employee.\nThe client provides all the information for a resource to be able to modify that resource.This implies that the server side does not update any aspect of the resource (such as an update date).\n\n\nIn both cases, these operations can be performed multiple times with the same results. That is the resource will not be changed by requesting the operation more than once. Hence, a true idempotent operation. Use the HTTP POST method when:\n\nThe server will provide some information concerning the newly created resource. For example, take a logging system. A new entry in the log will most likely have a numbering scheme which is determined on the server side. Upon creating a new log entry, the new sequence number will be determined by the server and not by the client.\nOn a modification of a resource, the server will provide such information as a resource state or an update date. Again in this case not all information was provided by the client and the resource will be changing from one modification request to the next. Hence a non idempotent operation.\n\n\nConclusion\n\nDo not directly correlate and map CRUD operations to HTTP methods for REST services. The use of an HTTP PUT method versus an HTTP POST method should be based on the idempotent aspect of that operation. That is, if the operation is idempotent, then use the HTTP PUT method. If the operation is non idempotent, then use the HTTP POST method.\n\nShare\nImprove this answer\nFollow\nanswered Oct 10 '13 at 4:18\nBurhan\n2134\n4 silver badges\n9\n9 bronze badges","comments":["Update => HTTP POST : POST is not for updating","@premraj You made the assumption that Burhan is telling you not to make; namely, you are conflating CRUD, REST, and HTTP. If you read RFC 7231, where these things are defined, you will find that in HTTP protocol, the definition of POST certainly allows updating. It is only the constraints of REST that say otherwise."]},{"answer":"the origin server can create the resource with that URI\n\nSo you use POST and probably, but not necessary PUT for resource creation. You don't have to support both. For me POST is perfectly enough. So it is a design decision.\n\nAs your quote mentioned, you use PUT for creation of there is no resource assigned to an IRI, and you want to create a resource anyway. For example, PUT /users/123/password usually replaces the old password with a new one, but you can use it to create a password if it does not exist already (for example, by freshly registered users or by restoring banned users).\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '17 at 12:41\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 16 '14 at 7:58\ninf3rno\n21.1k9\n9 gold badges\n98\n98 silver badges\n173\n173 bronze badges","comments":["I think you've managed to provide one of the few good examples of how to use PUT, well done."]},{"answer":"I'm going to land with the following:\n\nPUT refers to a resource, identified by the URI. In this case, you are updating it. It is the part of the three verbs referring to resources -- delete and get being the other two.\n\nPOST is basically a free form message, with its meaning being defined 'out of band'. If the message can be interpreted as adding a resource to a directory, that would be OK, but basically you need to understand the message you are sending (posting) to know what will happen with the resource.\n\nBecause PUT and GET and DELETE refer to a resource, they are also by definition idempotent.\n\nPOST can perform the other three functions, but then the semantics of the request will be lost on the intermediaries such as caches and proxies. This also applies to providing security on the resource, since a post's URI doesn't necessarily indicate the resource it is applying to (it can though).\n\nA PUT doesn't need to be a create; the service could error if the resource isn't already created, but otherwise update it. Or vice versa -- it may create the resource, but not allow updates. The only thing required about PUT is that it points to a specific resource, and its payload is the representation of that resource. A successful PUT means (barring interference) that a GET would retrieve the same resource.\n\nEdit: One more thing -- a PUT can create, but if it does then the ID has to be a natural ID -- AKA an email address. That way when you PUT twice, the second put is an update of the first. This makes it idempotent.\n\nIf the ID is generated (a new employee ID, for example), then the second PUT with the same URL would create a new record, which violates the idempotent rule. In this case the verb would be POST, and the message (not resource) would be to create a resource using the values defined in this message.\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '17 at 12:32\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 21 '13 at 21:16\nGerard ONeill\n3,23332\n32 silver badges\n22\n22 bronze badges","comments":[]},{"answer":"The semantics are supposed be different, in that \"PUT\", like \"GET\" is supposed to be idempotent -- meaning, you can the same exact PUT request multiple times and the result will be as if you executed it only once.\n\nI will describe the conventions which I think are most widely used and are most useful:\n\nWhen you PUT a resource at a particular URL what happens is that it should get saved at that URL, or something along those lines.\n\nWhen you POST to a resource at a particular URL, often you are posting a related piece of information to that URL. This implies that the resource at the URL already exists.\n\nFor example, when you want to create a new stream, you can PUT it to some URL. But when you want to POST a message to an existing stream, you POST to its URL.\n\nAs for modifying the properties of the stream, you can do that with either PUT or POST. Basically, only use \"PUT\" when the operation is idempotent - otherwise use POST.\n\nNote, however, that not all modern browsers support HTTP verbs other than GET or POST.\n\nShare\nImprove this answer\nFollow\nanswered Oct 23 '11 at 20:07\nGregory Magarshak\n1,6772\n2 gold badges\n21\n21 silver badges\n32\n32 bronze badges","comments":["What you describe POST as is actually how PATCH should behave. POST is supposed to mean something more akin to \"append\" as in \"post to mailing list\"."]},{"answer":"Most of the time, you will use them like this:\n\nPOST a resource into a collection\nPUT a resource identified by collection/:id\n\nFor example:\n\nPOST /items\nPUT /items/1234\n\nIn both cases, the request body contains the data for the resource to be created or updated. It should be obvious from the route names that POST is not idempotent (if you call it 3 times it will create 3 objects), but PUT is idempotent (if you call it 3 times the result is the same). PUT is often used for \"upsert\" operation (create or update), but you can always return a 404 error if you only want to use it to modify.\n\nNote that POST \"creates\" a new element in the collection, and PUT \"replaces\" an element at a given URL, but it is a very common practice to use PUT for partial modifications, that is, use it only to update existing resources and only modify the included fields in the body (ignoring the other fields). This is technically incorrect, if you want to be REST-purist, PUT should replace the whole resource and you should use PATCH for the partial update. I personally don't care much as far as the behavior is clear and consistent across all your API endpoints.\n\nRemember, REST is a set of conventions and guidelines to keep your API simple. If you end up with a complicated work-around just to check the \"RESTfull\" box then you are defeating the purpose ;)\n\nShare\nImprove this answer\nFollow\nanswered Jun 21 '17 at 17:38\ntothemario\n4,7352\n2 gold badges\n37\n37 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"Here's a simple rule:\n\nPUT to a URL should be used to update or create the resource that can be located at that URL.\n\nPOST to a URL should be used to update or create a resource which is located at some other (\"subordinate\") URL, or is not locatable via HTTP.\n\nShare\nImprove this answer\nFollow\nedited Sep 16 '17 at 20:24\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 11 '13 at 22:15\nAdam Griffiths\n1,4861\n1 gold badge\n12\n12 silver badges\n10\n10 bronze badges","comments":["PUT is not for update, it is for replace, note that to create you are replacing nothing with something. POST is absolutely not for update in any shape of form.","Does the http spec say that? Or are you basing your comment on something else?","It's just common sense, how you update something when you don't know what it is you are updating? POST is for creating a new resource.","thecoshman -- you are abusing semantics here -- a replace can be an update if it is the same resource with a few differences. A replace is only valid for put if replace is used to change the same resource. Replacing with a new and different resource is invalid (remove old and add new?), especially if the 'new' resource doesn't have a natural ID. POST, OTOH, is something that can create, update, replace, and delete -- using post depends on whether or not there is a message to interpret, such as 'apply the discount', which may or may not change the resource depending on logic.","As for your second comment -- how about you 'get' the resource, modify the fields you need to, and then put it back? Or how about if the resource comes from a different source but uses a natural ID (the external ID) -- put would naturally update the resource at the URL when the original data changed."]},{"answer":"If you are familiar with database operations, there are\n\nSelect\nInsert\nUpdate\nDelete\nMerge (Update if already existing, else insert)\n\nI use PUT for Merge and update like operations and use POST for Insertions.\n\nShare\nImprove this answer\nFollow\nanswered Jun 29 '16 at 21:13\nRajan\n1,3533\n3 gold badges\n20\n20 silver badges\n31\n31 bronze badges","comments":[]},{"answer":"While there is probably an agnostic way to describe these, it does seem to be conflicting with various statements from answers to websites.\n\nLet's be very clear and direct here. If you are a .NET developer working with Web API, the facts are (from the Microsoft API documentation), http://www.asp.net/web-api/overview/creating-web-apis/creating-a-web-api-that-supports-crud-operations:\n\n1. PUT = UPDATE (/api/products/id)\n2. MCSD Exams 2014 -  UPDATE = PUT, there are **NO** multiple answers for that question period.\n\n\nSure you \"can\" use \"POST\" to update, but just follow the conventions laid out for you with your given framework. In my case it is .NET / Web API, so PUT is for UPDATE there is no debate.\n\nI hope this helps any Microsoft developers that read all comments with Amazon and Sun/Java website links.\n\nShare\nImprove this answer\nFollow\nedited Jul 22 '17 at 11:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 21 '14 at 20:02\nTom Stickel\n17k6\n6 gold badges\n102\n102 silver badges\n109\n109 bronze badges","comments":[]},{"answer":"In practice, POST works well for creating resources. The URL of the newly created resource should be returned in the Location response header. PUT should be used for updating a resource completely. Please understand that these are the best practices when designing a RESTful API. HTTP specification as such does not restrict using PUT/POST with a few restrictions for creating/updating resources. Take a look at http://techoctave.com/c7/posts/71-twitter-rest-api-dissected that summarizes the best practices.\n\nShare\nImprove this answer\nFollow\nedited Oct 13 '14 at 9:59\nanswered Oct 6 '14 at 6:51\njava_geek\n16.1k29\n29 gold badges\n82\n82 silver badges\n106\n106 bronze badges","comments":["For the most part, from reading through all this noise, you seem on the ball. I would say though, we should refer to PUT as the replace method, rather than the create/update. I think it better describes in one what it does."]}]},{"id":"950087","href":"https://stackoverflow.com/questions/950087/how-do-i-include-a-javascript-file-in-another-javascript-file","title":"How do I include a JavaScript file in another JavaScript file?","description":"\n                \nIs there something in JavaScript similar to @import in CSS that allows you to include a JavaScript file inside another JavaScript file?\n    ","questionComments":[],"answers":[{"answer":"The old versions of JavaScript had no import, include, or require, so many different approaches to this problem have been developed.\n\nBut since 2015 (ES6), JavaScript has had the ES6 modules standard to import modules in Node.js, which is also supported by most modern browsers.\n\nFor compatibility with older browsers, build tools like Webpack and Rollup and/or transpilation tools like Babel can be used.\n\nES6 Modules\n\nECMAScript (ES6) modules have been supported in Node.js since v8.5, with the --experimental-modules flag, and since at least Node.js v13.8.0 without the flag. To enable \"ESM\" (vs. Node.js's previous CommonJS-style module system [\"CJS\"]) you either use \"type\": \"module\" in package.json or give the files the extension .mjs. (Similarly, modules written with Node.js's previous CJS module can be named .cjs if your default is ESM.)\n\nUsing package.json:\n\n{\n    \"type\": \"module\"\n}\n\n\nThen module.js:\n\nexport function hello() {\n  return \"Hello\";\n}\n\n\nThen main.js:\n\nimport { hello } from './module.js';\nlet val = hello();  // val is \"Hello\";\n\n\nUsing .mjs, you'd have module.mjs:\n\nexport function hello() {\n  return \"Hello\";\n}\n\n\nThen main.mjs:\n\nimport { hello } from './module.mjs';\nlet val = hello();  // val is \"Hello\";\n\nECMAScript modules in browsers\n\nBrowsers have had support for loading ECMAScript modules directly (no tools like Webpack required) since Safari 10.1, Chrome 61, Firefox 60, and Edge 16. Check the current support at caniuse. There is no need to use Node.js' .mjs extension; browsers completely ignore file extensions on modules/scripts.\n\n<script type=\"module\">\n  import { hello } from './hello.mjs'; // Or it could be simply `hello.js`\n  hello('world');\n</script>\n\n// hello.mjs -- or it could be simply `hello.js`\nexport function hello(text) {\n  const div = document.createElement('div');\n  div.textContent = `Hello ${text}`;\n  document.body.appendChild(div);\n}\n\n\nRead more at https://jakearchibald.com/2017/es-modules-in-browsers/\n\nDynamic imports in browsers\n\nDynamic imports let the script load other scripts as needed:\n\n<script type=\"module\">\n  import('hello.mjs').then(module => {\n      module.hello('world');\n    });\n</script>\n\n\nRead more at https://developers.google.com/web/updates/2017/11/dynamic-import\n\nNode.js require\n\nThe older CJS module style, still widely used in Node.js, is the module.exports/require system.\n\n// mymodule.js\nmodule.exports = {\n   hello: function() {\n      return \"Hello\";\n   }\n}\n\n// server.js\nconst myModule = require('./mymodule');\nlet val = myModule.hello(); // val is \"Hello\"   \n\n\nThere are other ways for JavaScript to include external JavaScript contents in browsers that do not require preprocessing.\n\nAJAX Loading\n\nYou could load an additional script with an AJAX call and then use eval to run it. This is the most straightforward way, but it is limited to your domain because of the JavaScript sandbox security model. Using eval also opens the door to bugs, hacks and security issues.\n\nFetch Loading\n\nLike Dynamic Imports you can load one or many scripts with a fetch call using promises to control order of execution for script dependencies using the Fetch Inject library:\n\nfetchInject([\n  'https://cdn.jsdelivr.net/momentjs/2.17.1/moment.min.js'\n]).then(() => {\n  console.log(`Finish in less than ${moment().endOf('year').fromNow(true)}`)\n})\n\njQuery Loading\n\nThe jQuery library provides loading functionality in one line:\n\n$.getScript(\"my_lovely_script.js\", function() {\n   alert(\"Script loaded but not necessarily executed.\");\n});\n\nDynamic Script Loading\n\nYou could add a script tag with the script URL into the HTML. To avoid the overhead of jQuery, this is an ideal solution.\n\nThe script can even reside on a different server. Furthermore, the browser evaluates the code. The <script> tag can be injected into either the web page <head>, or inserted just before the closing </body> tag.\n\nHere is an example of how this could work:\n\nfunction dynamicallyLoadScript(url) {\n    var script = document.createElement(\"script\");  // create a script DOM node\n    script.src = url;  // set its src to the provided URL\n\n    document.head.appendChild(script);  // add it to the end of the head section of the page (could change 'head' to 'body' to add it to the end of the body section instead)\n}\n\n\nThis function will add a new <script> tag to the end of the head section of the page, where the src attribute is set to the URL which is given to the function as the first parameter.\n\nBoth of these solutions are discussed and illustrated in JavaScript Madness: Dynamic Script Loading.\n\nDetecting when the script has been executed\n\nNow, there is a big issue you must know about. Doing that implies that you remotely load the code. Modern web browsers will load the file and keep executing your current script because they load everything asynchronously to improve performance. (This applies to both the jQuery method and the manual dynamic script loading method.)\n\nIt means that if you use these tricks directly, you won't be able to use your newly loaded code the next line after you asked it to be loaded, because it will be still loading.\n\nFor example: my_lovely_script.js contains MySuperObject:\n\nvar js = document.createElement(\"script\");\n\njs.type = \"text/javascript\";\njs.src = jsFilePath;\n\ndocument.body.appendChild(js);\n\nvar s = new MySuperObject();\n\nError : MySuperObject is undefined\n\n\nThen you reload the page hitting F5. And it works! Confusing...\n\nSo what to do about it ?\n\nWell, you can use the hack the author suggests in the link I gave you. In summary, for people in a hurry, he uses an event to run a callback function when the script is loaded. So you can put all the code using the remote library in the callback function. For example:\n\nfunction loadScript(url, callback)\n{\n    // Adding the script tag to the head as suggested before\n    var head = document.head;\n    var script = document.createElement('script');\n    script.type = 'text/javascript';\n    script.src = url;\n\n    // Then bind the event to the callback function.\n    // There are several events for cross browser compatibility.\n    script.onreadystatechange = callback;\n    script.onload = callback;\n\n    // Fire the loading\n    head.appendChild(script);\n}\n\n\nThen you write the code you want to use AFTER the script is loaded in a lambda function:\n\nvar myPrettyCode = function() {\n   // Here, do whatever you want\n};\n\n\nThen you run all that:\n\nloadScript(\"my_lovely_script.js\", myPrettyCode);\n\n\nNote that the script may execute after the DOM has loaded, or before, depending on the browser and whether you included the line script.async = false;. There's a great article on Javascript loading in general which discusses this.\n\nSource Code Merge/Preprocessing\n\nAs mentioned at the top of this answer, many developers use build/transpilation tool(s) like Parcel, Webpack, or Babel in their projects, allowing them to use upcoming JavaScript syntax, provide backward compatibility for older browsers, combine files, minify, perform code splitting etc.\n\nShare\nImprove this answer\nFollow\nedited Mar 21 '20 at 9:09\nT.J. Crowder\n897k166\n166 gold badges\n1650\n1650 silver badges\n1666\n1666 bronze badges\nanswered Jun 4 '09 at 12:13\ne-satis\n525k103\n103 gold badges\n284\n284 silver badges\n322\n322 bronze badges","comments":["I have loaded div dynamically by clicking menu without page loading by using URL hash. My problem is when i click same page 2/3 times js loading 2/3 times. thats why every event occurs multiple time. I want to check js file already loaded into footer/head before appending in that code: var js = document.createElement(\"script\"); js.type = \"text/javascript\"; js.src = jsFilePath; document.body.appendChild(js);","Thank you for your input. Is there anyway to insert the script in the beginning of the head?","You can also use something like Gulp (gulpjs.com) to preprocess them with the output being a single file that's called. For example: a) concatenate several JavaScript files together into one, b) use Babel to make it backwards compatible, c) minify/uglify to remove comments, whitespace, etc. Then, you've not only organized those files but also optimized them as well by initiating a pipeline with the potential of doing the same for other file formats (such as css and images.)","jakearchibald.com/2017/es-modules-in-browsers seems to be a dead link."]},{"answer":"If anyone is looking for something more advanced, try out RequireJS. You'll get added benefits such as dependency management, better concurrency, and avoid duplication (that is, retrieving a script more than once).\n\nYou can write your JavaScript files in \"modules\" and then reference them as dependencies in other scripts. Or you can use RequireJS as a simple \"go get this script\" solution.\n\nExample:\n\nDefine dependencies as modules:\n\nsome-dependency.js\n\ndefine(['lib/dependency1', 'lib/dependency2'], function (d1, d2) {\n\n     //Your actual script goes here.   \n     //The dependent scripts will be fetched if necessary.\n\n     return libraryObject;  //For example, jQuery object\n});\n\n\nimplementation.js is your \"main\" JavaScript file that depends on some-dependency.js\n\nrequire(['some-dependency'], function(dependency) {\n\n    //Your script goes here\n    //some-dependency.js is fetched.   \n    //Then your script is executed\n});\n\n\nExcerpt from the GitHub README:\n\nRequireJS loads plain JavaScript files as well as more defined modules. It is optimized for in-browser use, including in a Web Worker, but it can be used in other JavaScript environments, like Rhino and Node. It implements the Asynchronous Module API.\n\nRequireJS uses plain script tags to load modules/files, so it should allow for easy debugging. It can be used simply to load existing JavaScript files, so you can add it to your existing project without having to re-write your JavaScript files.\n\n...\n\nShare\nImprove this answer\nFollow\nedited Sep 28 '13 at 13:11\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 7 '12 at 20:55\nJohn Strickler\n24k4\n4 gold badges\n49\n49 silver badges\n67\n67 bronze badges","comments":[]},{"answer":"There actually is a way to load a JavaScript file not asynchronously, so you could use the functions included in your newly loaded file right after loading it, and I think it works in all browsers.\n\nYou need to use jQuery.append() on the <head> element of your page, that is:\n\n$(\"head\").append($(\"<script></script>\").attr(\"src\", url));\n\n/* Note that following line of code is incorrect because it doesn't escape the\n * HTML attribute src correctly and will fail if `url` contains special characters:\n * $(\"head\").append('<script src=\"' + url + '\"></script>');\n */\n\n\nHowever, this method also has a problem: if an error happens in the imported JavaScript file, Firebug (and also Firefox Error Console and Chrome Developer Tools as well) will report its place incorrectly, which is a big problem if you use Firebug to track JavaScript errors down a lot (I do). Firebug simply doesn't know about the newly loaded file for some reason, so if an error occurs in that file, it reports that it occurred in your main HTML file, and you will have trouble finding out the real reason for the error.\n\nBut if that is not a problem for you, then this method should work.\n\nI have actually written a jQuery plugin called $.import_js() which uses this method:\n\n(function($)\n{\n    /*\n     * $.import_js() helper (for JavaScript importing within JavaScript code).\n     */\n    var import_js_imported = [];\n    \n    $.extend(true,\n    {\n        import_js : function(script)\n        {\n            var found = false;\n            for (var i = 0; i < import_js_imported.length; i++)\n                if (import_js_imported[i] == script) {\n                    found = true;\n                    break;\n                }\n            \n            if (found == false) {\n                $(\"head\").append($('<script></script').attr('src', script));\n                import_js_imported.push(script);\n            }\n        }\n    });\n    \n})(jQuery);\n\n\nSo all you would need to do to import JavaScript is:\n\n$.import_js('/path_to_project/scripts/somefunctions.js');\n\n\nI also made a simple test for this at Example.\n\nIt includes a main.js file in the main HTML and then the script in main.js uses $.import_js() to import an additional file called included.js, which defines this function:\n\nfunction hello()\n{\n    alert(\"Hello world!\");\n}\n\n\nAnd right after including included.js, the hello() function is called, and you get the alert.\n\n(This answer is in response to e-satis' comment).\n\nShare\nImprove this answer\nFollow\nedited May 12 at 12:57\nFlimm\n102k33\n33 gold badges\n206\n206 silver badges\n223\n223 bronze badges\nanswered Apr 28 '11 at 15:25\nKipras\n2,4771\n1 gold badge\n14\n14 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"Another way, that in my opinion is much cleaner, is to make a synchronous Ajax request instead of using a <script> tag. Which is also how Node.js handles includes.\n\nHere's an example using jQuery:\n\nfunction require(script) {\n    $.ajax({\n        url: script,\n        dataType: \"script\",\n        async: false,           // <-- This is the key\n        success: function () {\n            // all good...\n        },\n        error: function () {\n            throw new Error(\"Could not load script \" + script);\n        }\n    });\n}\n\n\nYou can then use it in your code as you'd usually use an include:\n\nrequire(\"/scripts/subscript.js\");\n\n\nAnd be able to call a function from the required script in the next line:\n\nsubscript.doSomethingCool(); \n\nShare\nImprove this answer\nFollow\nedited Sep 28 '13 at 12:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 8 '11 at 18:22\nAriel\n4,4182\n2 gold badges\n19\n19 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"It is possible to dynamically generate a JavaScript tag and append it to HTML document from inside other JavaScript code. This will load targeted JavaScript file.\n\nfunction includeJs(jsFilePath) {\n    var js = document.createElement(\"script\");\n\n    js.type = \"text/javascript\";\n    js.src = jsFilePath;\n\n    document.body.appendChild(js);\n}\n\nincludeJs(\"/path/to/some/file.js\");\n\nShare\nImprove this answer\nFollow\nedited Sep 28 '13 at 12:44\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 4 '09 at 12:02\nSvitlana Maksymchuk\n4,0422\n2 gold badges\n14\n14 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"There is a good news for you. Very soon you will be able to load JavaScript code easily. It will become a standard way of importing modules of JavaScript code and will be part of core JavaScript itself.\n\nYou simply have to write import cond from 'cond.js'; to load a macro named cond from a file cond.js.\n\nSo you don't have to rely upon any JavaScript framework nor do you have to explicitly make Ajax calls.\n\nRefer to:\n\nStatic module resolution\n\nModule loaders\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 18:05\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 3 '12 at 13:32\nImdad\n5,7354\n4 gold badges\n31\n31 silver badges\n53\n53 bronze badges","comments":["Seven years later, this answer doesn't work: \"SyntaxError: import declarations may only appear at top level of a module\".","Share your code what you are trying to do.","Okay, here is code that works nicely: function Include(jsFilePath) { var js = d.createElement(\"script\"); js.type = \"text/javascript\"; js.src = jsFilePath; d.body.appendChild(js); } // Include"]},{"answer":"Statement import is in ECMAScript 6.\n\nSyntax\n\nimport name from \"module-name\";\nimport { member } from \"module-name\";\nimport { member as alias } from \"module-name\";\nimport { member1 , member2 } from \"module-name\";\nimport { member1 , member2 as alias2 , [...] } from \"module-name\";\nimport name , { member [ , [...] ] } from \"module-name\";\nimport \"module-name\" as name;\n\nShare\nImprove this answer\nFollow\nedited Dec 11 '16 at 9:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 17 '15 at 1:56\ndraupnie\n1,0307\n7 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"Maybe you can use this function that I found on this page How do I include a JavaScript file in a JavaScript file?:\n\nfunction include(filename)\n{\n    var head = document.getElementsByTagName('head')[0];\n\n    var script = document.createElement('script');\n    script.src = filename;\n    script.type = 'text/javascript';\n\n    head.appendChild(script)\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 15 '14 at 17:01\nAjeet Lakhani\n3,3082\n2 gold badges\n19\n19 silver badges\n36\n36 bronze badges\nanswered Jun 4 '09 at 12:04\nArnaud Gouder de Beauregard\n1,4791\n1 gold badge\n13\n13 silver badges\n22\n22 bronze badges","comments":[]},{"answer":"Here is a synchronous version without jQuery:\n\nfunction myRequire( url ) {\n    var ajax = new XMLHttpRequest();\n    ajax.open( 'GET', url, false ); // <-- the 'false' makes it synchronous\n    ajax.onreadystatechange = function () {\n        var script = ajax.response || ajax.responseText;\n        if (ajax.readyState === 4) {\n            switch( ajax.status) {\n                case 200:\n                    eval.apply( window, [script] );\n                    console.log(\"script loaded: \", url);\n                    break;\n                default:\n                    console.log(\"ERROR: script not loaded: \", url);\n            }\n        }\n    };\n    ajax.send(null);\n}\n\n\nNote that to get this working cross-domain, the server will need to set allow-origin header in its response.\n\nShare\nImprove this answer\nFollow\nedited Jun 18 '15 at 14:44\nFlimm\n102k33\n33 gold badges\n206\n206 silver badges\n223\n223 bronze badges\nanswered Dec 11 '13 at 11:54\nheinob\n17.7k3\n3 gold badges\n35\n35 silver badges\n58\n58 bronze badges","comments":[]},{"answer":"I just wrote this JavaScript code (using Prototype for DOM manipulation):\n\nvar require = (function() {\n    var _required = {};\n    return (function(url, callback) {\n        if (typeof url == 'object') {\n            // We've (hopefully) got an array: time to chain!\n            if (url.length > 1) {\n                // Load the nth file as soon as everything up to the\n                // n-1th one is done.\n                require(url.slice(0, url.length - 1), function() {\n                    require(url[url.length - 1], callback);\n                });\n            } else if (url.length == 1) {\n                require(url[0], callback);\n            }\n            return;\n        }\n        if (typeof _required[url] == 'undefined') {\n            // Haven't loaded this URL yet; gogogo!\n            _required[url] = [];\n\n            var script = new Element('script', {\n                src: url,\n                type: 'text/javascript'\n            });\n            script.observe('load', function() {\n                console.log(\"script \" + url + \" loaded.\");\n                _required[url].each(function(cb) {\n                    cb.call(); // TODO: does this execute in the right context?\n                });\n                _required[url] = true;\n            });\n\n            $$('head')[0].insert(script);\n        } else if (typeof _required[url] == 'boolean') {\n            // We already loaded the thing, so go ahead.\n            if (callback) {\n                callback.call();\n            }\n            return;\n        }\n\n        if (callback) {\n            _required[url].push(callback);\n        }\n    });\n})();\n\n\nUsage:\n\n<script src=\"prototype.js\"></script>\n<script src=\"require.js\"></script>\n<script>\n    require(['foo.js','bar.js'], function () {\n        /* Use foo.js and bar.js here */\n    });\n</script>\n\n\nGist: http://gist.github.com/284442.\n\nShare\nImprove this answer\nFollow\nedited Jun 25 '17 at 21:04\nTalha Awan\n4,1584\n4 gold badges\n22\n22 silver badges\n39\n39 bronze badges\nanswered Jan 23 '10 at 5:20\nnornagon\n14.1k17\n17 gold badges\n68\n68 silver badges\n84\n84 bronze badges","comments":[]},{"answer":"Here's the generalized version of how Facebook does it for their ubiquitous Like button:\n\n<script>\n  var firstScript = document.getElementsByTagName('script')[0],\n      js = document.createElement('script');\n  js.src = 'https://cdnjs.cloudflare.com/ajax/libs/Snowstorm/20131208/snowstorm-min.js';\n  js.onload = function () {\n    // do stuff with your dynamically loaded script\n    snowStorm.snowColor = '#99ccff';\n  };\n  firstScript.parentNode.insertBefore(js, firstScript);\n</script>\n Run code snippetExpand snippet\n\nIf it works for Facebook, it will work for you.\n\nThe reason why we look for the first script element instead of head or body is because some browsers don't create one if missing, but we're guaranteed to have a script element - this one. Read more at http://www.jspatterns.com/the-ridiculous-case-of-adding-a-script-element/.\n\nShare\nImprove this answer\nFollow\nedited Jul 8 '15 at 2:48\nanswered Jul 8 '15 at 2:41\nDan Dascalescu\n115k41\n41 gold badges\n283\n283 silver badges\n367\n367 bronze badges","comments":[]},{"answer":"If you want it in pure JavaScript, you can use document.write.\n\ndocument.write('<script src=\"myscript.js\" type=\"text/javascript\"></script>');\n\n\nIf you use the jQuery library, you can use the $.getScript method.\n\n$.getScript(\"another_script.js\");\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '20 at 20:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 13 '13 at 9:18\nVenu immadi\n1,57311\n11 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"You can also assemble your scripts using PHP:\n\nFile main.js.php:\n\n<?php\n    header('Content-type:text/javascript; charset=utf-8');\n    include_once(\"foo.js.php\");\n    include_once(\"bar.js.php\");\n?>\n\n// Main JavaScript code goes here\n\nShare\nImprove this answer\nFollow\nedited Sep 28 '13 at 12:50\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 27 '10 at 21:03\nCalmarius\n16.4k15\n15 gold badges\n96\n96 silver badges\n137\n137 bronze badges","comments":[]},{"answer":"Most of solutions shown here imply dynamical loading. I was searching instead for a compiler which assemble all the depended files into a single output file. The same as Less/Sass preprocessors deal with the CSS @import at-rule. Since I didn't find anything decent of this sort, I wrote a simple tool solving the issue.\n\nSo here is the compiler, https://github.com/dsheiko/jsic, which replaces $import(\"file-path\") with the requested file content securely. Here is the corresponding Grunt plugin: https://github.com/dsheiko/grunt-jsic.\n\nOn the jQuery master branch, they simply concatenate atomic source files into a single one starting with intro.js and ending with outtro.js. That doesn't suits me as it provides no flexibility on the source code design. Check out how it works with jsic:\n\nsrc/main.js\n\nvar foo = $import(\"./Form/Input/Tel\");\n\n\nsrc/Form/Input/Tel.js\n\nfunction() {\n    return {\n          prop: \"\",\n          method: function(){}\n    }\n}\n\n\nNow we can run the compiler:\n\nnode jsic.js src/main.js build/mail.js\n\n\nAnd get the combined file\n\nbuild/main.js\n\nvar foo = function() {\n    return {\n          prop: \"\",\n          method: function(){}\n    }\n};\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 18:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 13 '13 at 21:44\nDmitry Sheiko\n1,9121\n1 gold badge\n21\n21 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"If your intention to load the JavaScript file is using the functions from the imported/included file, you can also define a global object and set the functions as object items. For instance:\n\nglobal.js\nA = {};\n\nfile1.js\nA.func1 = function() {\n  console.log(\"func1\");\n}\n\nfile2.js\nA.func2 = function() {\n  console.log(\"func2\");\n}\n\nmain.js\nA.func1();\nA.func2();\n\n\nYou just need to be careful when you are including scripts in an HTML file. The order should be as in below:\n\n<head>\n  <script type=\"text/javascript\" src=\"global.js\"></script>\n  <script type=\"text/javascript\" src=\"file1.js\"></script>\n  <script type=\"text/javascript\" src=\"file2.js\"></script>\n  <script type=\"text/javascript\" src=\"main.js\"></script>\n</head>\n\nShare\nImprove this answer\nFollow\nedited Dec 11 '16 at 9:42\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 24 '15 at 6:53\nAdem İlhan\n1,3702\n2 gold badges\n15\n15 silver badges\n26\n26 bronze badges","comments":["This is not a good idea when you have a lot of separate files; the more files you create, the more requests will to be sent from the client, which makes the loading longer and also might affect the page SEO."]},{"answer":"Or rather than including at run time, use a script to concatenate prior to upload.\n\nI use Sprockets (I don't know if there are others). You build your JavaScript code in separate files and include comments that are processed by the Sprockets engine as includes. For development you can include files sequentially, then for production to merge them...\n\nSee also:\n\nIntroducing Sprockets: JavaScript dependency management and concatenation\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 18:02\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 7 '12 at 20:48\nJMawer\n2593\n3 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"This should do:\n\nxhr = new XMLHttpRequest();\nxhr.open(\"GET\", \"/soap/ajax/11.0/connection.js\", false);\nxhr.send();\neval(xhr.responseText);\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '14 at 13:50\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 24 '13 at 19:32\ntggagne\n2,7351\n1 gold badge\n18\n18 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"I had a simple issue, but I was baffled by responses to this question.\n\nI had to use a variable (myVar1) defined in one JavaScript file (myvariables.js) in another JavaScript file (main.js).\n\nFor this I did as below:\n\nLoaded the JavaScript code in the HTML file, in the correct order, myvariables.js first, then main.js:\n\n<html>\n    <body onload=\"bodyReady();\" >\n\n        <script src=\"myvariables.js\" > </script>\n        <script src=\"main.js\" > </script>\n\n        <!-- Some other code -->\n    </body>\n</html>\n\n\nFile: myvariables.js\n\nvar myVar1 = \"I am variable from myvariables.js\";\n\n\nFile: main.js\n\n// ...\nfunction bodyReady() {\n    // ...\n    alert (myVar1);    // This shows \"I am variable from myvariables.js\", which I needed\n    // ...\n}\n// ...\n\n\nAs you saw, I had use a variable in one JavaScript file in another JavaScript file, but I didn't need to include one in another. I just needed to ensure that the first JavaScript file loaded before the second JavaScript file, and, the first JavaScript file's variables are accessible in the second JavaScript file, automatically.\n\nThis saved my day. I hope this helps.\n\nShare\nImprove this answer\nFollow\nedited Dec 11 '16 at 9:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 22 '15 at 2:15\nManohar Reddy Poreddy\n17.5k7\n7 gold badges\n117\n117 silver badges\n102\n102 bronze badges","comments":[]},{"answer":"In a modern language with the check if script has already been loaded, it would be:\n\nfunction loadJs( url ){\n  return new Promise(( resolve, reject ) => {\n    if (document.querySelector( `head > script[ src = \"${url}\" ]`) !== null ){\n        console.warn( `script already loaded: ${url}` );\n        resolve();\n    }\n    const script = document.createElement( \"script\" );\n    script.src = url;\n    script.onload = resolve;\n    script.onerror = function( reason ){\n        // This can be useful for your error-handling code\n        reason.message = `error trying to load script ${url}`;\n        reject( reason );\n    };\n    document.head.appendChild( script );\n  });\n}\n\n\nUsage (async/await):\n\ntry { await loadJs(\"https://.../script.js\"); }\ncatch(error) { console.log(error); }\n\n\nor\n\nawait loadJs( \"https://.../script.js\" ).catch( err => {} );\n\n\nUsage (Promise):\n\nloadJs( \"https://.../script.js\" ).then( res => {} ).catch( err => {} );\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '20 at 19:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 20 '17 at 15:15\nDmitry Sheiko\n1,9121\n1 gold badge\n21\n21 silver badges\n25\n25 bronze badges","comments":["This is very good if you want to avoid having to get involved in modules, and don't want to use a callback function, but do want to use async / await.","url needs to be properly escaped here: `head > script[ src = \"${url}\" ]`"]},{"answer":"The @import syntax for achieving CSS-like JavaScript importing is possible using a tool such as Mixture via their special .mix file type (see here). I assume the application does this via one of above-mentioned methods.\n\nFrom the Mixture documentation on .mix files:\n\nMix files are simply .js or .css files with .mix. in the file name. A mix file simply extends the functionality of a normal style or script file and allows you to import and combine.\n\nHere's an example .mix file that combines multiple .js files into one:\n\n// scripts-global.mix.js\n// Plugins - Global\n\n@import \"global-plugins/headroom.js\";\n@import \"global-plugins/retina-1.1.0.js\";\n@import \"global-plugins/isotope.js\";\n@import \"global-plugins/jquery.fitvids.js\";\n\n\nMixture outputs this as scripts-global.js and also as a minified version (scripts-global.min.js).\n\nNote: I'm not in any way affiliated with Mixture, other than using it as a front-end development tool. I came across this question upon seeing a .mix JavaScript file in action (in one of the Mixture boilerplates) and being a bit confused by it (\"you can do this?\" I thought to myself). Then I realized that it was an application-specific file type (somewhat disappointing, agreed). Nevertheless, figured the knowledge might be helpful for others.\n\nNote: Mixture was discontinued on 2016/07/26 (after being open sourced on 2015/04/12).\n\nShare\nImprove this answer\nFollow\nedited Oct 5 '20 at 17:34\nanswered Mar 14 '14 at 4:40\nIsaac Gregson\n1,3951\n1 gold badge\n14\n14 silver badges\n27\n27 bronze badges","comments":["It is better to avoid \"Update\" (meta information that belongs in the revision history to this post). Instead apply it to the content (not this post), e.g. \"Mixture was open sourced on 2015-04-12, and it was discontinued on 2016-07-26.\""]},{"answer":"In case you are using Web Workers and want to include additional scripts in the scope of the worker, the other answers provided about adding scripts to the head tag, etc. will not work for you.\n\nFortunately, Web Workers have their own importScripts function which is a global function in the scope of the Web Worker, native to the browser itself as it is part of the specification.\n\nAlternatively, as the second highest voted answer to your question highlights, RequireJS can also handle including scripts inside a Web Worker (likely calling importScripts itself, but with a few other useful features).\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Jan 1 '15 at 8:58\nTurnerj\n4,0935\n5 gold badges\n33\n33 silver badges\n49\n49 bronze badges","comments":[]},{"answer":"var js = document.createElement(\"script\");\n\njs.type = \"text/javascript\";\njs.src = jsFilePath;\n\ndocument.body.appendChild(js);\n\nShare\nImprove this answer\nFollow\nedited Aug 22 '12 at 6:44\nSpudley\n158k39\n39 gold badges\n223\n223 silver badges\n296\n296 bronze badges\nanswered Aug 22 '12 at 4:33\nSam4Code\n5115\n5 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"Although these answers are great, there is a simple \"solution\" that has been around since script loading existed, and it will cover 99.999% of most people's use cases. Just include the script you need before the script that requires it. For most projects it does not take long to determine which scripts are needed and in what order.\n\n<!DOCTYPE HTML>\n<html>\n    <head>\n        <script src=\"script1.js\"></script>\n        <script src=\"script2.js\"></script>\n    </head>\n    <body></body>\n</html>\n\n\nIf script2 requires script1, this really is the absolute easiest way to do something like this. I'm very surprised no-one has brought this up, as it's the most obvious and simplest answer that will apply in nearly every single case.\n\nShare\nImprove this answer\nFollow\nanswered Apr 12 '18 at 19:38\nKthProg\n1,8101\n1 gold badge\n20\n20 silver badges\n29\n29 bronze badges","comments":["This is a good answer. It may have been missed because it does not directly answer the question, but it's also important to understand that 'you usually don't need to do that'. Especially since the other solutions are so messy.","But this only works in a web browser? What about offline unit testing (say, under Node.js)?"]},{"answer":"My usual method is:\n\nvar require = function (src, cb) {\n    cb = cb || function () {};\n\n    var newScriptTag = document.createElement('script'),\n        firstScriptTag = document.getElementsByTagName('script')[0];\n    newScriptTag.src = src;\n    newScriptTag.async = true;\n    newScriptTag.onload = newScriptTag.onreadystatechange = function () {\n        (!this.readyState || this.readyState === 'loaded' || this.readyState === 'complete') && (cb());\n    };\n    firstScriptTag.parentNode.insertBefore(newScriptTag, firstScriptTag);\n}\n\n\nIt works great and uses no page-reloads for me. I've tried the AJAX method (one of the other answers) but it doesn't seem to work as nicely for me.\n\nHere's an explanation of how the code works for those that are curious: essentially, it creates a new script tag (after the first one) of the URL. It sets it to asynchronous mode so it doesn't block the rest of the code, but calls a callback when the readyState (the state of the content to be loaded) changes to 'loaded'.\n\nShare\nImprove this answer\nFollow\nedited Aug 26 '17 at 17:02\nanswered May 31 '13 at 19:31\nChristopher Dumas\n1,26011\n11 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"ES6 Modules\n\nYes, use type=\"module\" in a script tag (support):\n\n<script type=\"module\" src=\"script.js\"></script>\n\n\nAnd in a script.js file include another file like this:\n\nimport { hello } from './module.js';\n...\n// alert(hello());\n\n\nIn 'module.js' you must export the function/class that you will import:\n\nexport function hello() {\n    return \"Hello World\";\n}\n\n\nA working example is here.\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '20 at 20:06\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 10 '19 at 16:12\nKamil Kiełczewski\n57.6k22\n22 gold badges\n275\n275 silver badges\n253\n253 bronze badges","comments":[]},{"answer":"I wrote a simple module that automates the job of importing/including module scripts in JavaScript. For detailed explanation of the code, refer to the blog post JavaScript require / import / include modules.\n\n// ----- USAGE -----\n\nrequire('ivar.util.string');\nrequire('ivar.net.*');\nrequire('ivar/util/array.js');\nrequire('http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js');\n\nready(function(){\n    //Do something when required scripts are loaded\n});\n\n    //--------------------\n\nvar _rmod = _rmod || {}; //Require module namespace\n_rmod.LOADED = false;\n_rmod.on_ready_fn_stack = [];\n_rmod.libpath = '';\n_rmod.imported = {};\n_rmod.loading = {\n    scripts: {},\n    length: 0\n};\n\n_rmod.findScriptPath = function(script_name) {\n    var script_elems = document.getElementsByTagName('script');\n    for (var i = 0; i < script_elems.length; i++) {\n        if (script_elems[i].src.endsWith(script_name)) {\n            var href = window.location.href;\n            href = href.substring(0, href.lastIndexOf('/'));\n            var url = script_elems[i].src.substring(0, script_elems[i].length - script_name.length);\n            return url.substring(href.length+1, url.length);\n        }\n    }\n    return '';\n};\n\n_rmod.libpath = _rmod.findScriptPath('script.js'); //Path of your main script used to mark\n                                                   //the root directory of your library, any library.\n\n\n_rmod.injectScript = function(script_name, uri, callback, prepare) {\n\n    if(!prepare)\n        prepare(script_name, uri);\n\n    var script_elem = document.createElement('script');\n    script_elem.type = 'text/javascript';\n    script_elem.title = script_name;\n    script_elem.src = uri;\n    script_elem.async = true;\n    script_elem.defer = false;\n\n    if(!callback)\n        script_elem.onload = function() {\n            callback(script_name, uri);\n        };\n    document.getElementsByTagName('head')[0].appendChild(script_elem);\n};\n\n_rmod.requirePrepare = function(script_name, uri) {\n    _rmod.loading.scripts[script_name] = uri;\n    _rmod.loading.length++;\n};\n\n_rmod.requireCallback = function(script_name, uri) {\n    _rmod.loading.length--;\n    delete _rmod.loading.scripts[script_name];\n    _rmod.imported[script_name] = uri;\n\n    if(_rmod.loading.length == 0)\n        _rmod.onReady();\n};\n\n_rmod.onReady = function() {\n    if (!_rmod.LOADED) {\n        for (var i = 0; i < _rmod.on_ready_fn_stack.length; i++){\n            _rmod.on_ready_fn_stack[i]();\n        });\n        _rmod.LOADED = true;\n    }\n};\n\n_.rmod = namespaceToUri = function(script_name, url) {\n    var np = script_name.split('.');\n    if (np.getLast() === '*') {\n        np.pop();\n        np.push('_all');\n    }\n\n    if(!url)\n        url = '';\n\n    script_name = np.join('.');\n    return  url + np.join('/')+'.js';\n};\n\n//You can rename based on your liking. I chose require, but it\n//can be called include or anything else that is easy for you\n//to remember or write, except \"import\", because it is reserved\n//for future use.\nvar require = function(script_name) {\n    var uri = '';\n    if (script_name.indexOf('/') > -1) {\n        uri = script_name;\n        var lastSlash = uri.lastIndexOf('/');\n        script_name = uri.substring(lastSlash+1, uri.length);\n    } \n    else {\n        uri = _rmod.namespaceToUri(script_name, ivar._private.libpath);\n    }\n\n    if (!_rmod.loading.scripts.hasOwnProperty(script_name)\n     && !_rmod.imported.hasOwnProperty(script_name)) {\n        _rmod.injectScript(script_name, uri,\n            _rmod.requireCallback,\n                _rmod.requirePrepare);\n    }\n};\n\nvar ready = function(fn) {\n    _rmod.on_ready_fn_stack.push(fn);\n};\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 18:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 12 '13 at 16:34\nstamat\n1,57917\n17 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"This script will add a JavaScript file to the top of any other <script> tag:\n\n(function () {\n    var li = document.createElement('script'); \n    li.type = 'text/javascript'; \n    li.src = \"http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js\"; \n    li.async = true; \n    var s = document.getElementsByTagName('script')[0]; \n    s.parentNode.insertBefore(li, s);\n})();\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '20 at 20:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 26 '13 at 3:42\nVicky Gonsalves\n10.8k2\n2 gold badges\n35\n35 silver badges\n55\n55 bronze badges","comments":[]},{"answer":"Keep it nice, short, simple, and maintainable! :]\n\n// Third-party plugins / script (don't forget the full path is necessary)\nvar FULL_PATH = '', s =\n[\n    FULL_PATH + 'plugins/script.js'      // Script example\n    FULL_PATH + 'plugins/jquery.1.2.js', // jQuery Library\n    FULL_PATH + 'plugins/crypto-js/hmac-sha1.js',      // CryptoJS\n    FULL_PATH + 'plugins/crypto-js/enc-base64-min.js'  // CryptoJS\n];\n\nfunction load(url)\n{\n    var ajax = new XMLHttpRequest();\n    ajax.open('GET', url, false);\n    ajax.onreadystatechange = function ()\n    {\n        var script = ajax.response || ajax.responseText;\n        if (ajax.readyState === 4)\n        {\n            switch(ajax.status)\n            {\n                case 200:\n                    eval.apply( window, [script] );\n                    console.log(\"library loaded: \", url);\n                    break;\n                default:\n                    console.log(\"ERROR: library not loaded: \", url);\n            }\n        }\n    };\n    ajax.send(null);\n}\n\n// Initialize a single load\nload('plugins/script.js');\n\n// Initialize a full load of scripts\nif (s.length > 0)\n{\n    for (i = 0; i < s.length; i++)\n    {\n        load(s[i]);\n    }\n}\n\n\nThis code is simply a short functional example that could require additional feature functionality for full support on any (or given) platform.\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '20 at 20:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 8 '15 at 1:19\ntfont\n9,7225\n5 gold badges\n48\n48 silver badges\n51\n51 bronze badges","comments":["An explanation would be in order. E.g. what is the idea (principle of operation) and how does it work?"]},{"answer":"I came to this question because I was looking for a simple way to maintain a collection of useful JavaScript plugins. After seeing some of the solutions here, I came up with this:\n\nSet up a file called \"plugins.js\" (or extensions.js or whatever you want). Keep your plugin files together with that one master file.\n\nplugins.js will have an array called pluginNames[] that we will iterate over each(), then append a <script> tag to the head for each plugin\n\n//set array to be updated when we add or remove plugin files\nvar pluginNames = [\"lettering\", \"fittext\", \"butterjam\", etc.];\n\n//one script tag for each plugin\n$.each(pluginNames, function(){\n    $('head').append('<script src=\"js/plugins/' + this + '.js\"></script>');\n});\n\nManually call just the one file in your head:\n<script src=\"js/plugins/plugins.js\"></script>\n\nBUT:\n\nEven though all of the plugins get dropped into the head tag the way they ought to, they don't always get run by the browser when you click into the page or refresh.\n\nI've found it's more reliable to just write the script tags in a PHP include. You only have to write it once and that's just as much work as calling the plugin using JavaScript.\n\nShare\nImprove this answer\nFollow\nedited Jan 10 '20 at 5:03\nanswered Dec 1 '11 at 5:36\nrgb_life\n3433\n3 silver badges\n10\n10 bronze badges","comments":["Note that if pluginNames contains special characters, this won't work, and might even lead to a security vulnerability. You need to use proper escaping here: $('head').append('<script src=\"js/plugins/' + this + '.js\"></script>');"]},{"answer":"There are several ways to implement modules in JavaScript. Here are the two most popular ones:\n\nES6 Modules\n\nBrowsers do not support this moduling system yet, so in order for you to use this syntax you must use a bundler like Webpack. Using a bundler is better anyway because this can combine all of your different files into a single (or a couple of related) files. This will serve the files from the server to the client faster because each HTTP request has some associated overhead accompanied with it. Thus by reducing the overall HTTP request we improve the performance. Here is an example of ES6 modules:\n\n// main.js file\n\nexport function add (a, b) {\n  return a + b;\n}\n\nexport default function multiply (a, b) {\n  return a * b;\n}\n\n\n// test.js file\n\nimport {add}, multiply from './main';   // For named exports between curly braces {export1, export2}\n                                        // For default exports without {}\n\nconsole.log(multiply(2, 2));  // logs 4\n\nconsole.log(add(1, 2));  // logs 3\n\nCommonJS (used in Node.js)\n\nThis moduling system is used in Node.js. You basically add your exports to an object which is called module.exports. You then can access this object via a require('modulePath'). Important here is to realize that these modules are being cached, so if you require() a certain module twice it will return the already created module.\n\n// main.js file\n\nfunction add (a, b) {\n  return a + b;\n}\n\nmodule.exports = add;  // Here we add our 'add' function to the exports object\n\n\n// test.js file\n\nconst add = require('./main');\n\nconsole.log(add(1,2));  // logs 3\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '20 at 20:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 10 '18 at 17:11\nWillem van der Veen\n21.2k11\n11 gold badges\n121\n121 silver badges\n116\n116 bronze badges","comments":[]}]},{"id":"359494","href":"https://stackoverflow.com/questions/359494/which-equals-operator-vs-should-be-used-in-javascript-comparisons","title":"Which equals operator (== vs ===) should be used in JavaScript comparisons?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nI'm using JSLint to go through JavaScript, and it's returning many suggestions to replace == (two equals signs) with === (three equals signs) when doing things like comparing idSele_UNVEHtype.value.length == 0 inside of an if statement.\n\nIs there a performance benefit to replacing == with ===? \n\nAny performance improvement would be welcomed as many comparison operators exist.\n\nIf no type conversion takes place, would there be a performance gain over ==?\n    ","questionComments":[],"answers":[{"answer":"The strict equality operator (===) behaves identically to the abstract equality operator (==) except no type conversion is done, and the types must be the same to be considered equal.\n\nReference: Javascript Tutorial: Comparison Operators\n\nThe == operator will compare for equality after doing any necessary type conversions. The === operator will not do the conversion, so if two values are not the same type === will simply return false. Both are equally quick.\n\nTo quote Douglas Crockford's excellent JavaScript: The Good Parts,\n\nJavaScript has two sets of equality operators: === and !==, and their evil twins == and !=. The good ones work the way you would expect. If the two operands are of the same type and have the same value, then === produces true and !== produces false. The evil twins do the right thing when the operands are of the same type, but if they are of different types, they attempt to coerce the values. the rules by which they do that are complicated and unmemorable. These are some of the interesting cases:\n\n'' == '0'           // false\n0 == ''             // true\n0 == '0'            // true\n\nfalse == 'false'    // false\nfalse == '0'        // true\n\nfalse == undefined  // false\nfalse == null       // false\nnull == undefined   // true\n\n' \\t\\r\\n ' == 0     // true\n\n\nThe lack of transitivity is alarming. My advice is to never use the evil twins. Instead, always use === and !==. All of the comparisons just shown produce false with the === operator.\n\nUpdate:\n\nA good point was brought up by @Casebash in the comments and in @Phillipe Laybaert's answer concerning objects. For objects, == and === act consistently with one another (except in a special case).\n\nvar a = [1,2,3];\nvar b = [1,2,3];\n\nvar c = { x: 1, y: 2 };\nvar d = { x: 1, y: 2 };\n\nvar e = \"text\";\nvar f = \"te\" + \"xt\";\n\na == b            // false\na === b           // false\n\nc == d            // false\nc === d           // false\n\ne == f            // true\ne === f           // true\n\n\nThe special case is when you compare a primitive with an object that evaluates to the same primitive, due to its toString or valueOf method. For example, consider the comparison of a string primitive with a string object created using the String constructor.\n\n\"abc\" == new String(\"abc\")    // true\n\"abc\" === new String(\"abc\")   // false\n\n\nHere the == operator is checking the values of the two objects and returning true, but the === is seeing that they're not the same type and returning false. Which one is correct? That really depends on what you're trying to compare. My advice is to bypass the question entirely and just don't use the String constructor to create string objects from string literals.\n\nReference\nhttp://www.ecma-international.org/ecma-262/5.1/#sec-11.9.3\n\nShare\nImprove this answer\nFollow\nedited May 24 '20 at 17:49\nanswered Dec 11 '08 at 14:25\nBill the Lizard\n374k202\n202 gold badges\n548\n548 silver badges\n845\n845 bronze badges","comments":["I'd also point out that 0 === -0 and NaN !== NaN, which can be confusing sometimes. If you want to differentiate ±0 and consider NaNs equal, use Object.is (ES2015)","Soft typing is a feature. Obviously Crockford is pointing out some of the \"artifacts\" of the design decision, but soft typing is still a feature. If used correctly, it's absolutely fine to use. Don't throw the baby away with the bathwater."]},{"answer":"Using the == operator (Equality)\n\ntrue == 1; //true, because 'true' is converted to 1 and then compared\n\"2\" == 2;  //true, because \"2\" is converted to 2 and then compared\n\n\nUsing the === operator (Identity)\n\ntrue === 1; //false\n\"2\" === 2;  //false\n\n\nThis is because the equality operator == does type coercion, meaning that the interpreter implicitly tries to convert the values before comparing.\n\nOn the other hand, the identity operator === does not do type coercion, and thus does not convert the values when comparing, and is therefore faster (as according to This JS benchmark test) as it skips one step.\n\nShare\nImprove this answer\nFollow\nedited Apr 29 '19 at 1:53\ncommunity wiki\n\n\n13 revs, 8 users 32%\nKalpesh Rajai","comments":[]},{"answer":"An interesting pictorial representation of the equality comparison between == and ===.\n\nSource: http://dorey.github.io/JavaScript-Equality-Table/\n\nvar1 === var2\n\nWhen using === for JavaScript equality testing, everything is as is. Nothing gets converted before being evaluated.\n\nvar1 == var2\n\nWhen using == for JavaScript equality testing, some funky conversions take place.\n\nConclusion:\n\nAlways use ===.\n\n(Unless you fully understand the conversions that take place with ==.)\n\nShare\nImprove this answer\nFollow\nedited May 8 at 7:54\nMateen Ulhaq\n18.9k13\n13 gold badges\n77\n77 silver badges\n113\n113 bronze badges\nanswered May 5 '14 at 5:21\nSNag\n15.8k10\n10 gold badges\n45\n45 silver badges\n63\n63 bronze badges","comments":["A better '==' table: algassert.com/visualization/2014/03/27/…"]},{"answer":"In the answers here, I didn't read anything about what equal means. Some will say that === means equal and of the same type, but that's not really true. It actually means that both operands reference the same object, or in case of value types, have the same value.\n\nSo, let's take the following code:\n\nvar a = [1,2,3];\nvar b = [1,2,3];\nvar c = a;\n\nvar ab_eq = (a === b); // false (even though a and b are the same type)\nvar ac_eq = (a === c); // true\n\n\nThe same here:\n\nvar a = { x: 1, y: 2 };\nvar b = { x: 1, y: 2 };\nvar c = a;\n\nvar ab_eq = (a === b); // false (even though a and b are the same type)\nvar ac_eq = (a === c); // true\n\n\nOr even:\n\nvar a = { };\nvar b = { };\nvar c = a;\n\nvar ab_eq = (a === b); // false (even though a and b are the same type)\nvar ac_eq = (a === c); // true\n\n\nThis behavior is not always obvious. There's more to the story than being equal and being of the same type.\n\nThe rule is:\n\nFor value types (numbers):\na === b returns true if a and b have the same value and are of the same type\n\nFor reference types:\na === b returns true if a and b reference the exact same object\n\nFor strings:\na === b returns true if a and b are both strings and contain the exact same characters\n\nStrings: the special case...\n\nStrings are not value types, but in Javascript they behave like value types, so they will be \"equal\" when the characters in the string are the same and when they are of the same length (as explained in the third rule)\n\nNow it becomes interesting:\n\nvar a = \"12\" + \"3\";\nvar b = \"123\";\n\nalert(a === b); // returns true, because strings behave like value types\n\n\nBut how about this?:\n\nvar a = new String(\"123\");\nvar b = \"123\";\n\nalert(a === b); // returns false !! (but they are equal and of the same type)\n\n\nI thought strings behave like value types? Well, it depends who you ask... In this case a and b are not the same type. a is of type Object, while b is of type string. Just remember that creating a string object using the String constructor creates something of type Object that behaves as a string most of the time.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jun 5 '09 at 19:11\nPhilippe Leybaert\n158k30\n30 gold badges\n201\n201 silver badges\n218\n218 bronze badges","comments":[]},{"answer":"Let me add this counsel:\n\nIf in doubt, read the specification!\n\nECMA-262 is the specification for a scripting language of which JavaScript is a dialect. Of course in practice it matters more how the most important browsers behave than an esoteric definition of how something is supposed to be handled. But it is helpful to understand why new String(\"a\") !== \"a\".\n\nPlease let me explain how to read the specification to clarify this question. I see that in this very old topic nobody had an answer for the very strange effect. So, if you can read a specification, this will help you in your profession tremendously. It is an acquired skill. So, let's continue.\n\nSearching the PDF file for === brings me to page 56 of the specification: 11.9.4. The Strict Equals Operator ( === ), and after wading through the specificationalese I find:\n\n11.9.6 The Strict Equality Comparison Algorithm\nThe comparison x === y, where x and y are values, produces true or false. Such a comparison is performed as follows:\n  1. If Type(x) is different from Type(y), return false.\n  2. If Type(x) is Undefined, return true.\n  3. If Type(x) is Null, return true.\n  4. If Type(x) is not Number, go to step 11.\n  5. If x is NaN, return false.\n  6. If y is NaN, return false.\n  7. If x is the same number value as y, return true.\n  8. If x is +0 and y is −0, return true.\n  9. If x is −0 and y is +0, return true.\n  10. Return false.\n  11. If Type(x) is String, then return true if x and y are exactly the same sequence of characters (same length and same characters in corresponding positions); otherwise, return false.\n  12. If Type(x) is Boolean, return true if x and y are both true or both false; otherwise, return false.\n  13. Return true if x and y refer to the same object or if they refer to objects joined to each other (see 13.1.2). Otherwise, return false.\n\nInteresting is step 11. Yes, strings are treated as value types. But this does not explain why new String(\"a\") !== \"a\". Do we have a browser not conforming to ECMA-262?\n\nNot so fast!\n\nLet's check the types of the operands. Try it out for yourself by wrapping them in typeof(). I find that new String(\"a\") is an object, and step 1 is used: return false if the types are different.\n\nIf you wonder why new String(\"a\") does not return a string, how about some exercise reading a specification? Have fun!\n\nAidiakapi wrote this in a comment below:\n\nFrom the specification\n\n11.2.2 The new Operator:\n\nIf Type(constructor) is not Object, throw a TypeError exception.\n\nWith other words, if String wouldn't be of type Object it couldn't be used with the new operator.\n\nnew always returns an Object, even for String constructors, too. And alas! The value semantics for strings (see step 11) is lost.\n\nAnd this finally means: new String(\"a\") !== \"a\".\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Nov 28 '09 at 18:18\nnalply\n21.4k12\n12 gold badges\n75\n75 silver badges\n93\n93 bronze badges","comments":[]},{"answer":"I tested this in Firefox with Firebug using code like this:\n\nconsole.time(\"testEquality\");\nvar n = 0;\nwhile (true) {\n  n++;\n  if (n == 100000)\n    break;\n}\nconsole.timeEnd(\"testEquality\");\n Run code snippetExpand snippet\n\nand\n\nconsole.time(\"testTypeEquality\");\nvar n = 0;\nwhile (true) {\n  n++;\n  if (n === 100000)\n    break;\n}\nconsole.timeEnd(\"testTypeEquality\");\n Run code snippetExpand snippet\n\nMy results (tested five times each and averaged):\n\n==: 115.2\n===: 114.4\n\n\nSo I'd say that the miniscule difference (this is over 100000 iterations, remember) is negligible. Performance isn't a reason to do ===. Type safety (well, as safe as you're going to get in JavaScript), and code quality is.\n\nShare\nImprove this answer\nFollow\nedited Nov 11 '20 at 14:14\nkabirbaidhya\n2,7002\n2 gold badges\n30\n30 silver badges\n52\n52 bronze badges\nanswered Dec 25 '08 at 11:17\nSimon Scarfe\n8,7123\n3 gold badges\n26\n26 silver badges\n31\n31 bronze badges","comments":["Now, how do these compare when there is an actual type coersion for == operator? Remember, that's when there's a performance boost.","MAJOR difference when tested properly for the aforementioned reasons of quicker to only check type inequality. jsfiddle.net/4jhuxkb2"]},{"answer":"In PHP and JavaScript, it is a strict equality operator. Which means, it will compare both type and values.\n\nShare\nImprove this answer\nFollow\nanswered May 12 '10 at 12:58\nShiki\n16.4k7\n7 gold badges\n30\n30 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"In JavaScript it means of the same value and type.\n\nFor example,\n\n4 == \"4\" // will return true\n\n\nbut\n\n4 === \"4\" // will return false \n\nShare\nImprove this answer\nFollow\nedited Oct 26 '14 at 11:11\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 12 '10 at 12:58\nDimitar\n2,3342\n2 gold badges\n19\n19 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"The === operator is called a strict comparison operator, it does differ from the == operator.\n\nLets take 2 vars a and b.\n\nFor \"a == b\" to evaluate to true a and b need to be the same value.\n\nIn the case of \"a === b\" a and b must be the same value and also the same type for it to evaluate to true.\n\nTake the following example\n\nvar a = 1;\nvar b = \"1\";\n\nif (a == b) //evaluates to true as a and b are both 1\n{\n    alert(\"a == b\");\n}\n\nif (a === b) //evaluates to false as a is not the same type as b\n{\n    alert(\"a === b\");\n}\n\n\nIn summary; using the == operator might evaluate to true in situations where you do not want it to so using the === operator would be safer.\n\nIn the 90% usage scenario it won't matter which one you use, but it is handy to know the difference when you get some unexpected behaviour one day.\n\nShare\nImprove this answer\nFollow\nedited Aug 21 '13 at 8:39\nanswered Dec 11 '08 at 14:58\nDoctor Jones\n20.2k12\n12 gold badges\n72\n72 silver badges\n96\n96 bronze badges","comments":[]},{"answer":"Why == is so unpredictable?\n\nWhat do you get when you compare an empty string \"\" with the number zero 0?\n\ntrue\n\nYep, that's right according to == an empty string and the number zero are the same time.\n\nAnd it doesn't end there, here's another one:\n\n'0' == false // true\n\n\nThings get really weird with arrays.\n\n[1] == true // true\n[] == false // true\n[[]] == false // true\n[0] == false // true\n\n\nThen weirder with strings\n\n[1,2,3] == '1,2,3' // true - REALLY?!\n'\\r\\n\\t' == 0 // true - Come on!\n\n\nIt get's worse:\n\nWhen is equal not equal?\n\nlet A = ''  // empty string\nlet B = 0   // zero\nlet C = '0' // zero string\n\nA == B // true - ok... \nB == C // true - so far so good...\nA == C // **FALSE** - Plot twist!\n\n\nLet me say that again:\n\n(A == B) && (B == C) // true\n(A == C) // **FALSE**\n\n\nAnd this is just the crazy stuff you get with primitives.\n\nIt's a whole new level of crazy when you use == with objects.\n\nAt this point your probably wondering...\n\nWhy does this happen?\n\nWell it's because unlike \"triple equals\" (===) which just checks if two values are the same.\n\n== does a whole bunch of other stuff.\n\nIt has special handling for functions, special handling for nulls, undefined, strings, you name it.\n\nIt get's pretty wacky.\n\nIn fact, if you tried to write a function that does what == does it would look something like this:\n\nfunction isEqual(x, y) { // if `==` were a function\n    if(typeof y === typeof x) return y === x;\n    // treat null and undefined the same\n    var xIsNothing = (y === undefined) || (y === null);\n    var yIsNothing = (x === undefined) || (x === null);\n\n    if(xIsNothing || yIsNothing) return (xIsNothing && yIsNothing);\n\n    if(typeof y === \"function\" || typeof x === \"function\") {\n        // if either value is a string \n        // convert the function into a string and compare\n        if(typeof x === \"string\") {\n            return x === y.toString();\n        } else if(typeof y === \"string\") {\n            return x.toString() === y;\n        } \n        return false;\n    }\n\n    if(typeof x === \"object\") x = toPrimitive(x);\n    if(typeof y === \"object\") y = toPrimitive(y);\n    if(typeof y === typeof x) return y === x;\n\n    // convert x and y into numbers if they are not already use the \"+\" trick\n    if(typeof x !== \"number\") x = +x;\n    if(typeof y !== \"number\") y = +y;\n    // actually the real `==` is even more complicated than this, especially in ES6\n    return x === y;\n}\n\nfunction toPrimitive(obj) {\n    var value = obj.valueOf();\n    if(obj !== value) return value;\n    return obj.toString();\n}\n\n\nSo what does this mean?\n\nIt means == is complicated.\n\nBecause it's complicated it's hard to know what's going to happen when you use it.\n\nWhich means you could end up with bugs.\n\nSo the moral of the story is...\n\nMake your life less complicated.\n\nUse === instead of ==.\n\nThe End.\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '18 at 15:39\nanswered Aug 9 '16 at 16:50\nLuis Perez\n26.4k10\n10 gold badges\n76\n76 silver badges\n77\n77 bronze badges","comments":[]},{"answer":"=== checks same sides are equal in type as well as value.\nExample:\n'1' === 1 // will return \"false\" because `string` is not a `number`\n\nCommon example:\n0 == ''  // will be \"true\", but it's very common to want this check to be \"false\"\n\nAnother common example:\nnull == undefined // returns \"true\", but in most cases a distinction is necessary\n\n\nMany times an untyped check would be handy because you do not care if the value is either undefined, null, 0 or \"\"\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered May 12 '10 at 12:58\nvsync\n91.5k47\n47 gold badges\n255\n255 silver badges\n331\n331 bronze badges","comments":[]},{"answer":"Javascript execution flow diagram for strict equality / Comparison '==='\n\nJavascript execution flow diagram for non strict equality / comparison '=='\n\nShare\nImprove this answer\nFollow\nanswered Sep 5 '15 at 13:53\nSamar Panda\n3,6963\n3 gold badges\n23\n23 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"JavaScript === vs == .\n\n0==false   // true\n0===false  // false, because they are of a different type\n1==\"1\"     // true, auto type coercion\n1===\"1\"    // false, because they are of a different type\n\nShare\nImprove this answer\nFollow\nedited Nov 12 '15 at 3:18\nAnik Islam Abhi\n24.5k8\n8 gold badges\n52\n52 silver badges\n76\n76 bronze badges\nanswered Jul 3 '13 at 4:08\nuser2496033","comments":[]},{"answer":"It means equality without type coercion type coercion means JavaScript do not automatically convert any other data types to string data types\n\n0==false   // true,although they are different types\n\n0===false  // false,as they are different types\n\n2=='2'    //true,different types,one is string and another is integer but \n            javaScript convert 2 to string by using == operator \n\n2==='2'  //false because by using === operator ,javaScript do not convert \n           integer to string \n\n2===2   //true because both have same value and same types \n\nShare\nImprove this answer\nFollow\nedited Jul 30 '17 at 21:40\nMd Nakibul Hassan\n2,1961\n1 gold badge\n13\n13 silver badges\n18\n18 bronze badges\nanswered May 12 '10 at 12:59\nPop Catalin\n57.9k22\n22 gold badges\n86\n86 silver badges\n111\n111 bronze badges","comments":[]},{"answer":"In a typical script there will be no performance difference. More important may be the fact that thousand \"===\" is 1 KB heavier than thousand \"==\" :) JavaScript profilers can tell you if there is a performance difference in your case.\n\nBut personally I would do what JSLint suggests. This recommendation is there not because of performance issues, but because type coercion means ('\\t\\r\\n' == 0) is true.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:02\nCommunity♦\n11\n1 silver badge\nanswered Dec 16 '08 at 14:29\nConstantin\n25.9k10\n10 gold badges\n57\n57 silver badges\n79\n79 bronze badges","comments":[]},{"answer":"The equal comparison operator == is confusing and should be avoided.\n\nIf you HAVE TO live with it, then remember the following 3 things:\n\nIt is not transitive: (a == b) and (b == c) does not lead to (a == c)\nIt's mutually exclusive to its negation: (a == b) and (a != b) always hold opposite Boolean values, with all a and b.\nIn case of doubt, learn by heart the following truth table:\n\nEQUAL OPERATOR TRUTH TABLE IN JAVASCRIPT\n\nEach row in the table is a set of 3 mutually \"equal\" values, meaning that any 2 values among them are equal using the equal == sign*\n\n** STRANGE: note that any two values on the first column are not equal in that sense.**\n\n''       == 0 == false   // Any two values among these 3 ones are equal with the == operator\n'0'      == 0 == false   // Also a set of 3 equal values, note that only 0 and false are repeated\n'\\t'     == 0 == false   // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n'\\r'     == 0 == false   // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n'\\n'     == 0 == false   // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n'\\t\\r\\n' == 0 == false   // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\nnull == undefined  // These two \"default\" values are not-equal to any of the listed values above\nNaN                // NaN is not equal to any thing, even to itself.\n\nShare\nImprove this answer\nFollow\nedited Feb 19 '14 at 15:01\nanswered Sep 16 '11 at 14:25\nCuongHuyTo\n1,26313\n13 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"There is unlikely to be any performance difference between the two operations in your usage. There is no type-conversion to be done because both parameters are already the same type. Both operations will have a type comparison followed by a value comparison.\n\nShare\nImprove this answer\nFollow\nanswered Dec 11 '08 at 14:44\nSean\n1,5961\n1 gold badge\n13\n13 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"Yes! It does matter.\n\n=== operator in javascript checks value as well as type where as == operator just checks the value (does type conversion if required).\n\nYou can easily test it. Paste following code in an HTML file and open it in browser\n\n<script>\n\nfunction onPageLoad()\n{\n    var x = \"5\";\n    var y = 5;\n    alert(x === 5);\n};\n\n</script>\n\n</head>\n\n<body onload='onPageLoad();'>\n\n\nYou will get 'false' in alert. Now modify the onPageLoad() method to alert(x == 5); you will get true.\n\nShare\nImprove this answer\nFollow\nedited Jan 10 '15 at 14:34\nanswered Nov 14 '14 at 6:02\nAniket Thakur\n60k35\n35 gold badges\n255\n255 silver badges\n270\n270 bronze badges","comments":[]},{"answer":"It's a strict check test.\n\nIt's a good thing especially if you're checking between 0 and false and null.\n\nFor example, if you have:\n\n$a = 0;\n\n\nThen:\n\n$a==0; \n$a==NULL;\n$a==false;\n\n\nAll returns true and you may not want this. Let's suppose you have a function that can return the 0th index of an array or false on failure. If you check with \"==\" false, you can get a confusing result.\n\nSo with the same thing as above, but a strict test:\n\n$a = 0;\n\n$a===0; // returns true\n$a===NULL; // returns false\n$a===false; // returns false\n\nShare\nImprove this answer\nFollow\nedited Apr 27 '15 at 8:26\nPraxis Ashelin\n4,9892\n2 gold badges\n17\n17 silver badges\n43\n43 bronze badges\nanswered May 12 '10 at 13:19\nDaniel\n8406\n6 silver badges\n5\n5 bronze badges","comments":["In JavaScript, this is completely wrong and wrongly incomplete. 0 != null. -1"]},{"answer":"=== operator checks the values as well as the types of the variables for equality.\n\n== operator just checks the value of the variables for equality.\n\nShare\nImprove this answer\nFollow\nedited Nov 20 '17 at 12:05\nAlex Weitz\n2,5202\n2 gold badges\n24\n24 silver badges\n42\n42 bronze badges\nanswered May 12 '10 at 13:03\nNiraj CHoubey\n4675\n5 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"Simply\n\n== means comparison between operands with type coercion\n\nand\n\n=== means comparison between operands without type coercion.\n\nType coercion in JavaScript means automatically converting data types to other data types.\n\nFor example:\n\n123 == \"123\"  // Returns true, because JS coerces string \"123\" to number 123\n              // and then goes on to compare `123 == 123`.\n\n123 === \"123\" // Returns false, because JS does not coerce values of different types here.\n\nShare\nImprove this answer\nFollow\nedited Mar 15 at 9:08\nSebastian Simon\n14.7k6\n6 gold badges\n44\n44 silver badges\n61\n61 bronze badges\nanswered Mar 20 '15 at 5:05\nAmit\n7359\n9 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"JSLint sometimes gives you unrealistic reasons to modify stuff. === has exactly the same performance as == if the types are already the same.\n\nIt is faster only when the types are not the same, in which case it does not try to convert types but directly returns a false.\n\nSo, IMHO, JSLint maybe used to write new code, but useless over-optimizing should be avoided at all costs.\n\nMeaning, there is no reason to change == to === in a check like if (a == 'test') when you know it for a fact that a can only be a String.\n\nModifying a lot of code that way wastes developers' and reviewers' time and achieves nothing.\n\nShare\nImprove this answer\nFollow\nedited Nov 20 '17 at 12:11\nAlex Weitz\n2,5202\n2 gold badges\n24\n24 silver badges\n42\n42 bronze badges\nanswered Jun 5 '12 at 7:53\nashes\n5911\n1 gold badge\n5\n5 silver badges\n9\n9 bronze badges","comments":["Interestingly, a.length===4 is actually slower in Firefox than a.length==4. It is, by all means, a micro-optimization anyway, but this is contrary to what people claim."]},{"answer":"A simple example is\n\n2 == '2'  -> true, values are SAME because of type conversion.\n\n2 === '2'  -> false, values are NOT SAME because of no type conversion.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 '15 at 3:56\nTamil Selvan C\n18.6k12\n12 gold badges\n45\n45 silver badges\n64\n64 bronze badges\nanswered May 14 '15 at 14:45\nVikas\n3,9851\n1 gold badge\n31\n31 silver badges\n37\n37 bronze badges","comments":[]},{"answer":"As a rule of thumb, I would generally use === instead of == (and !== instead of !=).\n\nReasons are explained in in the answers above and also Douglas Crockford is pretty clear about it (JavaScript: The Good Parts).\n\nHowever there is one single exception: == null is an efficient way to check for 'is null or undefined':\n\nif( value == null ){\n    // value is either null or undefined\n}\n\n\nFor example jQuery 1.9.1 uses this pattern 43 times, and the JSHint syntax checker even provides the eqnull relaxing option for this reason.\n\nFrom the jQuery style guide:\n\nStrict equality checks (===) should be used in favor of ==. The only exception is when checking for undefined and null by way of null.\n\n// Check for both undefined and null values, for some important reason. \nundefOrNull == null;\n\n\nEDIT 2021-03:\n\nNowadays most browsers support the Nullish coalescing operator (??) and the Logical nullish assignment (??=), which allows a more concise way to assign a default value if a variable is null or undefined, for example:\n\nif (a.speed == null) {\n  // Set default if null or undefined\n  a.speed = 42;\n}\n\n\ncan be written as any of these forms\n\na.speed ??= 42;\na.speed ?? a.speed = 42;\na.speed = a.speed ?? 42;\n\nShare\nImprove this answer\nFollow\nedited Mar 29 at 18:51\nanswered Apr 27 '13 at 14:15\nmar10\n12.2k5\n5 gold badges\n36\n36 silver badges\n58\n58 bronze badges","comments":["“== null is an efficient way to check for ‘is null or undefined’” … or document.all."]},{"answer":"The top 2 answers both mentioned == means equality and === means identity. Unfortunately, this statement is incorrect.\n\nIf both operands of == are objects, then they are compared to see if they are the same object. If both operands point to the same object, then the equal operator returns true. Otherwise, the two are not equal.\n\nvar a = [1, 2, 3];  \nvar b = [1, 2, 3];  \nconsole.log(a == b)  // false  \nconsole.log(a === b) // false  \n\n\nIn the code above, both == and === get false because a and b are not the same objects.\n\nThat's to say: if both operands of == are objects, == behaves same as ===, which also means identity. The essential difference of this two operators is about type conversion. == has conversion before it checks equality, but === does not.\n\nShare\nImprove this answer\nFollow\nanswered Sep 9 '13 at 8:31\nHarry He\n1,54514\n14 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"The problem is that you might easily get into trouble since JavaScript have a lot of implicit conversions meaning...\n\nvar x = 0;\nvar isTrue = x == null;\nvar isFalse = x === null;\n\n\nWhich pretty soon becomes a problem. The best sample of why implicit conversion is \"evil\" can be taken from this code in MFC / C++ which actually will compile due to an implicit conversion from CString to HANDLE which is a pointer typedef type...\n\nCString x;\ndelete x;\n\n\nWhich obviously during runtime does very undefined things...\n\nGoogle for implicit conversions in C++ and STL to get some of the arguments against it...\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '14 at 11:08\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 29 '08 at 11:54\nThomas Hansen\n5,4531\n1 gold badge\n21\n21 silver badges\n28\n28 bronze badges","comments":["0 == null is false."]},{"answer":"From the core javascript reference\n\n=== Returns true if the operands are strictly equal (see above) with no type conversion.\n\nShare\nImprove this answer\nFollow\nedited Nov 12 '15 at 3:17\nAnik Islam Abhi\n24.5k8\n8 gold badges\n52\n52 silver badges\n76\n76 bronze badges\nanswered May 12 '10 at 12:59\nPaul Butcher\n6,71626\n26 silver badges\n39\n39 bronze badges","comments":[]},{"answer":"Equality comparison:\n\nOperator ==\n\nReturns true, when both operands are equal. The operands are converted to the same type before being compared.\n\n>>> 1 == 1\ntrue\n>>> 1 == 2\nfalse\n>>> 1 == '1'\ntrue\n\n\nEquality and type comparison:\n\nOperator ===\n\nReturns true if both operands are equal and of the same type. It's generally better and safer if you compare this way, because there's no behind-the-scenes type conversions.\n\n>>> 1 === '1'\nfalse\n>>> 1 === 1\ntrue\n\nShare\nImprove this answer\nFollow\nanswered Oct 2 '13 at 21:54\nuser2601995\n5,5178\n8 gold badges\n35\n35 silver badges\n38\n38 bronze badges","comments":[]},{"answer":"Here is a handy comparison table that shows the conversions that happen and the differences between == and ===.\n\nAs the conclusion states:\n\n\"Use three equals unless you fully understand the conversions that take place for two-equals.\"\n\nhttp://dorey.github.io/JavaScript-Equality-Table/\n\nShare\nImprove this answer\nFollow\nedited Mar 27 '14 at 11:41\nBonifacio2\n2,7564\n4 gold badges\n30\n30 silver badges\n45\n45 bronze badges\nanswered Mar 27 '14 at 0:18\nChristian Hagelid\n7,8294\n4 gold badges\n38\n38 silver badges\n63\n63 bronze badges","comments":[]},{"answer":"null and undefined are nothingness, that is,\n\nvar a;\nvar b = null;\n\n\nHere a and b do not have values. Whereas, 0, false and '' are all values. One thing common beween all these are that they are all falsy values, which means they all satisfy falsy conditions.\n\nSo, the 0, false and '' together form a sub-group. And on other hand, null & undefined form the second sub-group. Check the comparisons in the below image. null and undefined would equal. The other three would equal to each other. But, they all are treated as falsy conditions in JavaScript.\n\nThis is same as any object (like {}, arrays, etc.), non-empty string & Boolean true are all truthy conditions. But, they are all not equal.\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '14 at 11:15\ncommunity wiki\n\n\n2 revs, 2 users 69%\nvivek_nk","comments":[]}]},{"id":"1628563","href":"https://stackoverflow.com/questions/1628563/move-the-most-recent-commits-to-a-new-branch-with-git","title":"Move the most recent commit(s) to a new branch with Git","description":"\n                \nI'd like to move the last several commits I've committed to master to a new branch and take master back to before those commits were made. Unfortunately, my Git-fu is not strong enough yet, any help?\n\nI.e. How can I go from this\n\nmaster A - B - C - D - E\n\n\nto this?\n\nnewbranch     C - D - E\n             /\nmaster A - B \n\n    ","questionComments":["Note: I asked the opposite question here","eddmann.com/posts/… this one works","Were the comments here purged? I ask because during my bimonthly visit to this question, I always scroll by that comment.","Side-comment: The question is about a very simple case. Reading the answers and all the \"don't do this because...\" and \"a better solution is...\" and \"warning with version n+...\" just after the answers (possibly when it's too late), it seems to me even very simple operations have no straight solutions in git. A graphical version manager where you would just add a tag for the new branch without dealing with what seems to me obscure and archaic syntax would be such a relief. My kingdom and my gold badges to the first one who \"forks\" git and starts a new approach ;-) it's urgent.","@mins Perhaps TortoiseGit is one step nearer to what you're asking for. The beauty of Git is that you have full control at your fingertips, but this requires a deeper understanding and a need for the user to be comfortable using a command line interface. I've been using Git for some years now, yet I still rely upon making references to the documentation and/or stackoverflow when I need to do less frequent operations. I like operating with the git CLI (I use GitBash) as I can get things done quickly. However, I turn to TortoiseGit to resolve conflicts as I find this easier."],"answers":[{"answer":"Moving to an existing branch\n\nIf you want to move your commits to an existing branch, it will look like this:\n\ngit checkout existingbranch\ngit merge master\ngit checkout master\ngit reset --hard HEAD~3 # Go back 3 commits. You *will* lose uncommitted work.\ngit checkout existingbranch\n\n\nYou can store uncommitted edits to your stash before doing this, using git stash. Once complete, you can retrieve the stashed uncommitted edits with git stash pop\n\nMoving to a new branch\n\nWARNING: This method works because you are creating a new branch with the first command: git branch newbranch. If you want to move commits to an existing branch you need to merge your changes into the existing branch before executing git reset --hard HEAD~3 (see Moving to an existing branch above). If you don't merge your changes first, they will be lost.\n\nUnless there are other circumstances involved, this can be easily done by branching and rolling back.\n\n# Note: Any changes not committed will be lost.\ngit branch newbranch      # Create a new branch, saving the desired commits\ngit reset --hard HEAD~3   # Move master back by 3 commits (Make sure you know how many commits you need to go back)\ngit checkout newbranch    # Go to the new branch that still has the desired commits\n\n\nBut do make sure how many commits to go back. Alternatively, you can instead of HEAD~3, simply provide the hash of the commit (or the reference like origin/master) you want to \"revert back to\" on the master (/current) branch, e.g:\n\ngit reset --hard a1b2c3d4\n\n\n*1 You will only be \"losing\" commits from the master branch, but don't worry, you'll have those commits in newbranch!\n\nWARNING: With Git version 2.0 and later, if you later git rebase the new branch upon the original (master) branch, you may need an explicit --no-fork-point option during the rebase to avoid losing the carried-over commits. Having branch.autosetuprebase always set makes this more likely. See John Mellor's answer for details.\n\nShare\nImprove this answer\nFollow\nedited Feb 15 at 12:40\ncommunity wiki\n\n\n23 revs, 21 users 18%\nDuc Filan","comments":["And in particular, don't try to go back further than the point where you last pushed commits to another repository from which somebody else might have pulled.","Wondering if you can explain WHY this works. To me you're creating a new branch, removing 3 commits from the old branch you are still on, and then checking out the branch you made. So how do the commits you removed magically show up in the new branch?","@Jonathan Dumaine: Because I created the new branch before removing the commits from the old branch. They're still there in the new branch.","branches in git are just markers which point to commits in history, there is nothing being cloned, created or deleted (except the markers)","Also note: Don't do this with uncommitted changes in your working copy! This just bit me! :("]},{"answer":"For those wondering why it works (as I was at first):\n\nYou want to go back to C, and move D and E to the new branch. Here's what it looks like at first:\n\nA-B-C-D-E (HEAD)\n        ↑\n      master\n\n\nAfter git branch newBranch:\n\n    newBranch\n        ↓\nA-B-C-D-E (HEAD)\n        ↑\n      master\n\n\nAfter git reset --hard HEAD~2:\n\n    newBranch\n        ↓\nA-B-C-D-E (HEAD)\n    ↑\n  master\n\n\nSince a branch is just a pointer, master pointed to the last commit. When you made newBranch, you simply made a new pointer to the last commit. Then using git reset you moved the master pointer back two commits. But since you didn't move newBranch, it still points to the commit it originally did.\n\nShare\nImprove this answer\nFollow\nedited Dec 31 '15 at 0:29\nanswered Jul 22 '11 at 22:37\nRyan Lundy\n189k36\n36 gold badges\n174\n174 silver badges\n206\n206 bronze badges","comments":["I also needed to do a git push origin master --force for the change to show up in main repository.","This answer causes commits to be lost: next time you git rebase, the 3 commits will be silently discarded from newbranch. See my answer for details and safer alternatives.","@John, that's nonsense. Rebasing without knowing what you're doing causes commits to be lost. If you lost commits, I'm sorry for you, but this answer didn't lose your commits. Note that origin/master doesn't appear in the above diagram. If you pushed to origin/master and then made the changes above, sure, things would go funny. But that's a \"Doctor, it hurts when I do this\" kind of problem. And it's out of scope for what the original question asked. I suggest you write your own question to explore your scenario instead of hijacking this one.","@John, in your answer, you said \"Don't do this! git branch -t newbranch\". Go back and read the answers again. Nobody suggested doing that.","@Kyralessa, sure, but if you look at the diagram in the question, it's clear that they want newbranch to be based off their existing local master branch. After performing the accepted answer, when the user gets around to running git rebase in newbranch, git will remind them that they forgot to set the upstream branch, so they'll run git branch --set-upstream-to=master then git rebase and have the same problem. They may as well use git branch -t newbranch in the first place."]},{"answer":"In General...\n\nThe method exposed by sykora is the best option in this case. But sometimes is not the easiest and it's not a general method. For a general method use git cherry-pick:\n\nTo achieve what OP wants, its a 2-step process:\n\nStep 1 - Note which commits from master you want on a newbranch\n\nExecute\n\ngit checkout master\ngit log\n\n\nNote the hashes of (say 3) commits you want on newbranch. Here I shall use:\nC commit: 9aa1233\nD commit: 453ac3d\nE commit: 612ecb3\n\nNote: You can use the first seven characters or the whole commit hash\n\nStep 2 - Put them on the newbranch\ngit checkout newbranch\ngit cherry-pick 612ecb3\ngit cherry-pick 453ac3d\ngit cherry-pick 9aa1233\n\nOR (on Git 1.7.2+, use ranges)\ngit checkout newbranch\ngit cherry-pick 612ecb3~1..9aa1233\n\n\ngit cherry-pick applies those three commits to newbranch.\n\nShare\nImprove this answer\nFollow\nedited Feb 28 '18 at 18:13\nanswered Feb 7 '12 at 16:58\nIvan\n12.6k13\n13 gold badges\n55\n55 silver badges\n89\n89 bronze badges","comments":["This works very well if you accidentally commit the wrong, non-master branch, when you should have created a new feature branch.","The information on git cherry-pick is nice, but the commands in this post don't work. 1) the 'git checkout newbranch' should be 'git checkout -b newbranch' since newbranch doesn't already exist; 2) if you checkout newbranch from the existing master branch it ALREADY has those three commits included in it, so there's no use in picking them. At the end of the day to get what the OP wanted, you'll still have to do some form of reset --hard HEAD.","+1 for a useful approach in some situations. This is good if you only want to pull your own commits (which are interspersed with others) into a new branch.","It's better answer. This way you can move commits to any branch.","Is the order of cherry picking important?"]},{"answer":"Most previous answers are dangerously wrong!\n\nDo NOT do this:\n\ngit branch -t newbranch\ngit reset --hard HEAD~3\ngit checkout newbranch\n\n\nAs the next time you run git rebase (or git pull --rebase) those 3 commits would be silently discarded from newbranch! (see explanation below)\n\nInstead do this:\n\ngit reset --keep HEAD~3\ngit checkout -t -b newbranch\ngit cherry-pick ..HEAD@{2}\n\nFirst it discards the 3 most recent commits (--keep is like --hard, but safer, as fails rather than throw away uncommitted changes).\nThen it forks off newbranch.\nThen it cherry-picks those 3 commits back onto newbranch. Since they're no longer referenced by a branch, it does that by using git's reflog: HEAD@{2} is the commit that HEAD used to refer to 2 operations ago, i.e. before we 1. checked out newbranch and 2. used git reset to discard the 3 commits.\n\nWarning: the reflog is enabled by default, but if you've manually disabled it (e.g. by using a \"bare\" git repository), you won't be able to get the 3 commits back after running git reset --keep HEAD~3.\n\nAn alternative that doesn't rely on the reflog is:\n\n# newbranch will omit the 3 most recent commits.\ngit checkout -b newbranch HEAD~3\ngit branch --set-upstream-to=oldbranch\n# Cherry-picks the extra commits from oldbranch.\ngit cherry-pick ..oldbranch\n# Discards the 3 most recent commits from oldbranch.\ngit branch --force oldbranch oldbranch~3\n\n\n(if you prefer you can write @{-1} - the previously checked out branch - instead of oldbranch).\n\nTechnical explanation\n\nWhy would git rebase discard the 3 commits after the first example? It's because git rebase with no arguments enables the --fork-point option by default, which uses the local reflog to try to be robust against the upstream branch being force-pushed.\n\nSuppose you branched off origin/master when it contained commits M1, M2, M3, then made three commits yourself:\n\nM1--M2--M3  <-- origin/master\n         \\\n          T1--T2--T3  <-- topic\n\n\nbut then someone rewrites history by force-pushing origin/master to remove M2:\n\nM1--M3'  <-- origin/master\n \\\n  M2--M3--T1--T2--T3  <-- topic\n\n\nUsing your local reflog, git rebase can see that you forked from an earlier incarnation of the origin/master branch, and hence that the M2 and M3 commits are not really part of your topic branch. Hence it reasonably assumes that since M2 was removed from the upstream branch, you no longer want it in your topic branch either once the topic branch is rebased:\n\nM1--M3'  <-- origin/master\n     \\\n      T1'--T2'--T3'  <-- topic (rebased)\n\n\nThis behavior makes sense, and is generally the right thing to do when rebasing.\n\nSo the reason that the following commands fail:\n\ngit branch -t newbranch\ngit reset --hard HEAD~3\ngit checkout newbranch\n\n\nis because they leave the reflog in the wrong state. Git sees newbranch as having forked off the upstream branch at a revision that includes the 3 commits, then the reset --hard rewrites the upstream's history to remove the commits, and so next time you run git rebase it discards them like any other commit that has been removed from the upstream.\n\nBut in this particular case we want those 3 commits to be considered as part of the topic branch. To achieve that, we need to fork off the upstream at the earlier revision that doesn't include the 3 commits. That's what my suggested solutions do, hence they both leave the reflog in the correct state.\n\nFor more details, see the definition of --fork-point in the git rebase and git merge-base docs.\n\nShare\nImprove this answer\nFollow\nedited Sep 16 '16 at 1:34\nanswered Apr 6 '16 at 22:38\nJohn Mellor\n11.3k4\n4 gold badges\n41\n41 silver badges\n33\n33 bronze badges","comments":["This answer says \"Do NOT do this!\" above something that no one suggested doing.","Most people don't rewrite published history, especially on master. So no, they are not dangerously wrong.","@Kyralessa, the -t you are referring to in git branch happens implicitly if you have git config --global branch.autosetuprebase always set. Even if you don't, I already explained to you that the same problem occurs if you setup tracking after performing these commands, as the OP likely intends to do given their question.","@RockLee, yes, the general the way to fix such situations is to create a fresh branch (newbranch2) from a safe starting point then cherry-pick all the commits you want to keep (from badnewbranch to newbranch2). Cherry-picking will give the commits new hashes, so you'll be able to safely rebase newbranch2 (and can now delete badnewbranch).","@Walf, you misunderstood: git rebase is designed to be robust against upstreams having their history rewritten. Unfortunately, the side-effects of that robustness affect everyone, even if neither they nor their upstream ever rewrite history."]},{"answer":"Yet another way to do this, using just 2 commands. Also keeps your current working tree intact.\n\ngit checkout -b newbranch # switch to a new branch\ngit branch -f master HEAD~3 # make master point to some older commit\n\n\nOld version - before I learned about git branch -f\n\ngit checkout -b newbranch # switch to a new branch\ngit push . +HEAD~3:master # make master point to some older commit \n\n\nBeing able to push to . is a nice trick to know.\n\nShare\nImprove this answer\nFollow\nedited Jun 21 '18 at 14:17\nanswered Mar 26 '14 at 8:13\naragaer\n15.6k4\n4 gold badges\n44\n44 silver badges\n46\n46 bronze badges","comments":["Current directory. I guess this would work only if you are in a top directory.","The local push is grin-inducing, but on reflection, how is it different to git branch -f here?","@GerardSexton . is current director. git can push to REMOTES or GIT URLs. path to local directory is supported Git URLs syntax. See the GIT URLS section in git help clone.","I don't know why this is not rated higher. Dead simple, and without the small but potential danger of git reset --hard.","@Godsmith My guess is people prefer three simple commands to two slightly more obscure commands. Also, top voted answers get more upvotes by nature of being displayed first."]},{"answer":"Much simpler solution using git stash\n\nHere's a far simpler solution for commits to the wrong branch. Starting on branch master that has three mistaken commits:\n\ngit reset HEAD~3\ngit stash\ngit checkout newbranch\ngit stash pop\n\nWhen to use this?\nIf your primary purpose is to roll back master\nYou want to keep file changes\nYou don't care about the messages on the mistaken commits\nYou haven't pushed yet\nYou want this to be easy to memorize\nYou don't want complications like temporary/new branches, finding and copying commit hashes, and other headaches\nWhat this does, by line number\nUndoes the last three commits (and their messages) to master, yet leaves all working files intact\nStashes away all the working file changes, making the master working tree exactly equal to the HEAD~3 state\nSwitches to an existing branch newbranch\nApplies the stashed changes to your working directory and clears the stash\n\nYou can now use git add and git commit as you normally would. All new commits will be added to newbranch.\n\nWhat this doesn't do\nIt doesn't leave random temporary branches cluttering your tree\nIt doesn't preserve the mistaken commit messages, so you'll need to add a new commit message to this new commit\nUpdate! Use up-arrow to scroll through your command buffer to reapply the prior commit with its commit message (thanks @ARK)\nGoals\n\nThe OP stated the goal was to \"take master back to before those commits were made\" without losing changes and this solution does that.\n\nI do this at least once a week when I accidentally make new commits to master instead of develop. Usually I have only one commit to rollback in which case using git reset HEAD^ on line 1 is a simpler way to rollback just one commit.\n\nDon't do this if you pushed master's changes upstream\n\nSomeone else may have pulled those changes. If you are only rewriting your local master there's no impact when it's pushed upstream, but pushing a rewritten history to collaborators can cause headaches.\n\nShare\nImprove this answer\nFollow\nedited Feb 27 '20 at 4:48\nanswered May 1 '18 at 7:50\nSlam\n2,5691\n1 gold badge\n12\n12 silver badges\n20\n20 bronze badges","comments":["Thanks, am so glad I read past/through so much to get to here, cause it's a pretty common use case for me as well. Are we so atypical?","I think we're totally typical and \"oops I commited to master by mistake\" is the most common use-case for need to revert a handful or less of commits. Lucky this solution is so simple I have it memorized now.","This should be the accepted answer. It's straightforward, easy to understand and easy to remember","I don't event think the stashing is necessary. I just did it without and worked well.","You can easily get your commit messages back, too, if you happen have them in your CLI (command line) history. I happened to have both the git add and git commit commands that I used so all I had to do was hit up arrow and enter a few times and boom! Everything was back, but on the right branch now."]},{"answer":"This doesn't \"move\" them in the technical sense but it has the same effect:\n\nA--B--C  (branch-foo)\n \\    ^-- I wanted them here!\n  \\\n   D--E--F--G  (branch-bar)\n      ^--^--^-- Opps wrong branch!\n\nWhile on branch-bar:\n$ git reset --hard D # remember the SHAs for E, F, G (or E and G for a range)\n\nA--B--C  (branch-foo)\n \\\n  \\\n   D-(E--F--G) detached\n   ^-- (branch-bar)\n\nSwitch to branch-foo\n$ git cherry-pick E..G\n\nA--B--C--E'--F'--G' (branch-foo)\n \\   E--F--G detached (This can be ignored)\n  \\ /\n   D--H--I (branch-bar)\n\nNow you won't need to worry about the detached branch because it is basically\nlike they are in the trash can waiting for the day it gets garbage collected.\nEventually some time in the far future it will look like:\n\nA--B--C--E'--F'--G'--L--M--N--... (branch-foo)\n \\\n  \\\n   D--H--I--J--K--.... (branch-bar)\n\nShare\nImprove this answer\nFollow\nedited Aug 17 '14 at 10:23\nhamdiakoguz\n14.3k9\n9 gold badges\n30\n30 silver badges\n27\n27 bronze badges\nanswered Oct 19 '13 at 14:12\nSukima\n9,6673\n3 gold badges\n42\n42 silver badges\n58\n58 bronze badges","comments":["Can't you use rebase for the same thing?","Yes you could alternatively use rebase on the detached branch in the scenario above."]},{"answer":"To do this without rewriting history (i.e. if you've already pushed the commits):\n\ngit checkout master\ngit revert <commitID(s)>\ngit checkout -b new-branch\ngit cherry-pick <commitID(s)>\n\n\nBoth branches can then be pushed without force!\n\nShare\nImprove this answer\nFollow\nanswered Jan 21 '16 at 16:10\nteh_senaus\n1,31916\n16 silver badges\n21\n21 bronze badges","comments":["But then you have to deal with the revert scenario, which, depending on your circumstance, can be a lot trickier. If you revert a commit on the branch, Git will still see those commits as have taken place, so in order to undo that, you have to revert the revert. This burns quite a few people, especially when they revert a merge and try to merge the branch back, only to find that Git believes that it's already merged that branch in (which is entirely true).","That's why I cherry-pick the commits at the end, onto a new branch. That way git sees them as new commits, which solves your issue.","This is more dangerous than it first seems, since you're changing the state of the repository's history without really understanding the implications of this state.","I don't follow your argument - the point of this answer is that you're not changing history, simply adding new commits (which effectively undo the redo the changes). These new commits can be pushed and merged as normal."]},{"answer":"Simplest way to do this:\n\n1. Rename master branch to your newbranch (assuming you are on master branch):\n\ngit branch -m newbranch\n\n\n2. Create master branch from the commit that you wish:\n\ngit checkout -b master <seven_char_commit_id>\n\n\ne.g. git checkout -b master a34bc22\n\nShare\nImprove this answer\nFollow\nedited Nov 21 '20 at 9:21\nanswered Mar 21 '20 at 7:24\nSaikat\n8,66213\n13 gold badges\n75\n75 silver badges\n99\n99 bronze badges","comments":["Love this solution, because you do not have to rewrite the git commit title/description.","Doesn't this mess up the remote upstream branches? Isn't newbranch now pointing to origin/master?"]},{"answer":"Had just this situation:\n\nBranch one: A B C D E F     J   L M  \n                       \\ (Merge)\nBranch two:             G I   K     N\n\n\nI performed:\n\ngit branch newbranch \ngit reset --hard HEAD~8 \ngit checkout newbranch\n\n\nI expected that commit I would be the HEAD, but commit L is it now...\n\nTo be sure to land on the right spot in the history its easier to work with the hash of the commit\n\ngit branch newbranch \ngit reset --hard #########\ngit checkout newbranch\n\nShare\nImprove this answer\nFollow\nanswered Sep 20 '13 at 10:17\nDarkglow\n5932\n2 gold badges\n7\n7 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"How can I go from this\n\nA - B - C - D - E \n                |\n                master\n\n\nto this?\n\nA - B - C - D - E \n    |           |\n    master      newbranch\n\n\nWith two commands\n\ngit branch -m master newbranch\n\ngiving\n\nA - B - C - D - E \n                |\n                newbranch\n\n\nand\n\ngit branch master B\n\ngiving\n\nA - B - C - D - E\n    |           |\n    master      newbranch\n\nShare\nImprove this answer\nFollow\nanswered May 16 '19 at 12:00\nIvan\n3,64328\n28 silver badges\n26\n26 bronze badges","comments":["Yep, this works and is quite easy. Sourcetree GUI is a little confused about the changes made in the git shell, but after a fetch it's all right again.","Yes, they are as in the question. The first couple of diagrams are intended to be equivalent to those in the question, just redrawn the way I would like for the purpose of illustration in the answer. Basically rename the master branch as newbranch and create a new master branch where you want it."]},{"answer":"If you just need to move all your unpushed commits to a new branch, then you just need to,\n\ncreate a new branch from the current one :git branch new-branch-name\n\npush your new branch: git push origin new-branch-name\n\nrevert your old(current) branch to the last pushed/stable state: git reset --hard origin/old-branch-name\n\nSome people also have other upstreams rather than origin, they should use appropriate upstream\n\nShare\nImprove this answer\nFollow\nanswered Jun 17 '19 at 7:38\nShamsul Arefin Sajib\n1,44515\n15 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"You can do this is just 3 simple step that i used.\n\n1) make new branch where you want to commit you recent update.\n\ngit branch <branch name>\n\n2) Find Recent Commit Id for commit on new branch.\n\ngit log\n\n3) Copy that commit id note that Most Recent commit list take place on top. so you can find your commit. you also find this via message.\n\ngit cherry-pick d34bcef232f6c...\n\nyou can also provide some rang of commit id.\n\ngit cherry-pick d34bcef...86d2aec\n\nNow your job done. If you picked correct id and correct branch then you will success. So before do this be careful. else another problem can occur.\n\nNow you can push your code\n\ngit push\n\nShare\nImprove this answer\nFollow\nanswered May 25 '18 at 14:14\npankaj\n4255\n5 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"1) Create a new branch, which moves all your changes to new_branch.\n\ngit checkout -b new_branch\n\n\n2) Then go back to old branch.\n\ngit checkout master\n\n\n3) Do git rebase\n\ngit rebase -i <short-hash-of-B-commit>\n\n\n4) Then the opened editor contains last 3 commit information.\n\n...\npick <C's hash> C\npick <D's hash> D\npick <E's hash> E\n...\n\n\n5) Change pick to drop in all those 3 commits. Then save and close the editor.\n\n...\ndrop <C's hash> C\ndrop <D's hash> D\ndrop <E's hash> E\n...\n\n\n6) Now last 3 commits are removed from current branch (master). Now push the branch forcefully, with + sign before branch name.\n\ngit push origin +master\n\nShare\nImprove this answer\nFollow\nanswered Jun 1 '18 at 5:40\nrashok\n10.8k11\n11 gold badges\n78\n78 silver badges\n90\n90 bronze badges","comments":[]},{"answer":"Most of the solutions here count the amount of commits you'd like to go back. I think this is an error prone methodology. Counting would require recounting.\n\nYou can simply pass the commit hash of the commit you want to be at HEAD or in other words, the commit you'd like to be the last commit via:\n\n(Notice see commit hash)\n\nTo avoid this:\n\n1) git checkout master\n\n2) git branch <feature branch> master\n\n3) git reset --hard <commit hash>\n\n4) git push -f origin master\n\nShare\nImprove this answer\nFollow\nanswered Nov 24 '20 at 21:49\nQuesofat\n1,3502\n2 gold badges\n16\n16 silver badges\n39\n39 bronze badges","comments":[]}]},{"id":"826782","href":"https://stackoverflow.com/questions/826782/how-to-disable-text-selection-highlighting","title":"How to disable text selection highlighting","description":"\n                \nFor anchors that act like buttons (for example Questions, Tags, Users, etc. which are located on the top of the Stack Overflow page) or tabs, is there a CSS standard way to disable the highlighting effect if the user accidentally selects the text?\nI realize that this could be done with JavaScript and a little googling yielded the Mozilla-only -moz-user-select option.\nIs there a standard-compliant way to accomplish this with CSS, and if not, what is the \"best practice\" approach?\n    ","questionComments":["can elements within the element witch has highlighting disabled, have highlighting enabled with in css in the style or class attribute? or in other words, are there other values for -webkit-user-select ect. other than just none?","Related: stackoverflow.com/questions/16600479/… = how to allow only some of the child elements to be selected","There a bug in some browsers where doing \"Select All\" (CTRL+A and CMD+A) still selects things. This can be fought with a transparent selection color: ::selection { background: transparent; } ::-moz-selection { background: transparent; }","Can I just say: please don't do this. From my experience, I more often than not acctually want to select some text that also serves as a button, to copy-paste it somewhere else. It would be unimaginably infuriating not to be able to do that because some web developer went out of their way to purpousely disable this feature for me. So please don't do this unless you have a very, very good reason.","In year 2017, it is better way to use postcss and autoprefixer and set browser version, then postcss make everything cool."],"answers":[{"answer":"UPDATE January, 2017:\n\nAccording to Can I use, the user-select is currently supported in all browsers except Internet Explorer 9 and its earlier versions (but sadly still needs a vendor prefix).\n\nThese are all of the available correct CSS variations:\n\n.noselect {\n  -webkit-touch-callout: none; /* iOS Safari */\n    -webkit-user-select: none; /* Safari */\n     -khtml-user-select: none; /* Konqueror HTML */\n       -moz-user-select: none; /* Old versions of Firefox */\n        -ms-user-select: none; /* Internet Explorer/Edge */\n            user-select: none; /* Non-prefixed version, currently\n                                  supported by Chrome, Edge, Opera and Firefox */\n}\n<p>\n  Selectable text.\n</p>\n<p class=\"noselect\">\n  Unselectable text.\n</p>\n Run code snippetExpand snippet\n\nNote that user-select is in standardization process (currently in a W3C working draft). It is not guaranteed to work everywhere and there might be differences in implementation among browsers. Also, browsers can drop support for it in the future.\n\nMore information can be found in Mozilla Developer Network documentation.\n\nThe values of this attribute are none, text, toggle, element, elements, all and inherit.\n\nShare\nImprove this answer\nFollow\nedited Aug 5 at 15:29\ncommunity wiki\n\n\n38 revs, 23 users 20%\nBlowsie","comments":["nice code molokoloco :D , although I personally would stay well away from using it, as sometimes you may need the values different for different browsers, and it relys on JavaScript. Making a class and adding it to your element or applying the css to your type of element in your style-sheet is pretty bullet proof.","'user-select'- Values: none | text | toggle | element | elements | all | inherit - w3.org/TR/2000/WD-css3-userint-20000216","this is ridiculous! so many different ways to do the same thing. let's make a new standard for user selects. we will call it standard-user-select. then we won't have these problems. although for backwards compatibility we should include the others as well. so now the code becomes -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; standard-user-select: none;. ah, much better.","According to caniuse it seems that it doesn't need those prefixes anymore."]},{"answer":"In most browsers, this can be achieved using proprietary variations on the CSS user-select property, originally proposed and then abandoned in CSS 3 and now proposed in CSS UI Level 4:\n\n*.unselectable {\n   -moz-user-select: none;\n   -khtml-user-select: none;\n   -webkit-user-select: none;\n\n   /*\n     Introduced in Internet Explorer 10.\n     See http://ie.microsoft.com/testdrive/HTML5/msUserSelect/\n   */\n   -ms-user-select: none;\n   user-select: none;\n}\n\n\nFor Internet Explorer < 10 and Opera < 15, you will need to use the unselectable attribute of the element you wish to be unselectable. You can set this using an attribute in HTML:\n\n<div id=\"foo\" unselectable=\"on\" class=\"unselectable\">...</div>\n\n\nSadly this property isn't inherited, meaning you have to put an attribute in the start tag of every element inside the <div>. If this is a problem, you could instead use JavaScript to do this recursively for an element's descendants:\n\nfunction makeUnselectable(node) {\n    if (node.nodeType == 1) {\n        node.setAttribute(\"unselectable\", \"on\");\n    }\n    var child = node.firstChild;\n    while (child) {\n        makeUnselectable(child);\n        child = child.nextSibling;\n    }\n}\n\nmakeUnselectable(document.getElementById(\"foo\"));\n\n\nUpdate 30 April 2014: This tree traversal needs to be rerun whenever a new element is added to the tree, but it seems from a comment by @Han that it is possible to avoid this by adding a mousedown event handler that sets unselectable on the target of the event. See http://jsbin.com/yagekiji/1 for details.\n\nThis still doesn't cover all possibilities. While it is impossible to initiate selections in unselectable elements, in some browsers (Internet Explorer and Firefox, for example) it's still impossible to prevent selections that start before and end after the unselectable element without making the whole document unselectable.\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 12:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 5 '10 at 11:45\nTim Down\n296k68\n68 gold badges\n433\n433 silver badges\n511\n511 bronze badges","comments":["you should remove the * selector from your example, its really in-efficient and there really isnt any need to use it in your example is there?","@Blowsie: I don't think so: the CSS 2 spec states that *.foo and .foo are precisely equivalent (in the second case, the universal selector (*) is implied), so barring browser quirks, I can't see that including the * will harm performance. It's a long-standing habit of mine to include the *, which I originally started doing for readability: it explicitly states at a glance that the author intends to match all elements.","oooh after some further reading, it seems * is only un-effiecient when using it as the key (the righmost selector) ie .unselectable * . Further info here code.google.com/speed/page-speed/docs/…","Instead of using the class=\"unselectable\", just use the attribute selector [unselectable=\"on\"] { … }"]},{"answer":"Until CSS 3's user-select property becomes available, Gecko-based browsers support the -moz-user-select property you already found. WebKit and Blink-based browsers support the -webkit-user-select property.\n\nThis of course is not supported in browsers that do not use the Gecko rendering engine.\n\nThere is no \"standards\" compliant quick-and-easy way to do it; using JavaScript is an option.\n\nThe real question is, why do you want users to not be able to highlight and presumably copy and paste certain elements? I have not come across a single time that I wanted to not let users highlight a certain portion of my website. Several of my friends, after spending many hours reading and writing code will use the highlight feature as a way to remember where on the page they were, or providing a marker so that their eyes know where to look next.\n\nThe only place I could see this being useful is if you have buttons for forms that should not be copy and pasted if a user copy and pasted the website.\n\nShare\nImprove this answer\nFollow\nedited Apr 17 '16 at 5:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 5 '09 at 20:37\nX-Istence\n15.5k6\n6 gold badges\n52\n52 silver badges\n73\n73 bronze badges","comments":["The buttons thing would be exactly my motivation.","This may be necessary for embedded devices. i.e. a device where a browser is used for rendering the UI.","Another reason this is needed is Shift-clicking to select multiple rows in a grid or table. You don't want to to highlight the text, you want it to select the rows.","Highly interactive web app with a lot of drag & drop... accidental highlighting is a big usability problem."]},{"answer":"A JavaScript solution for Internet Explorer is:\n\nonselectstart=\"return false;\"\n\nShare\nImprove this answer\nFollow\nedited Jul 31 '19 at 19:30\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 13 '09 at 16:05\nPekka\n422k131\n131 gold badges\n938\n938 silver badges\n1060\n1060 bronze badges","comments":["Don’t forget about ondragstart!"]},{"answer":"If you want to disable text selection on everything except on <p> elements, you can do this in CSS (watch out for the -moz-none which allows override in sub-elements, which is allowed in other browsers with none):\n\n* {\n    -webkit-user-select: none;\n    -khtml-user-select: none;\n    -moz-user-select: -moz-none;\n    -o-user-select: none;\n    user-select: none;\n}\n\np {\n    -webkit-user-select: text;\n    -khtml-user-select: text;\n    -moz-user-select: text;\n    -o-user-select: text;\n    user-select: text;\n}\n\nShare\nImprove this answer\nFollow\nedited Oct 29 '13 at 17:09\nJames Donnelly\n119k31\n31 gold badges\n194\n194 silver badges\n200\n200 bronze badges\nanswered May 24 '11 at 21:24\nBenjamin Crouzier\n35.6k37\n37 gold badges\n155\n155 silver badges\n219\n219 bronze badges","comments":["Make sure you also make input fields selectable: p, input { -webkit-user-select: text; -khtml-user-select: text; -moz-user-select: text; -o-user-select: text; user-select: text; }","Be very wary about turning off browser UI expectations on ALL code except for one item. What about list items <li /> text, for example?","Just an update... according to MDN since Firefox 21 -moz-none and none are the same.","For this you may add cursor:default and cursor:text respectively : )","THE bomb. That is to say. THE END. ul>* {     -webkit-user-select: none;     -khtml-user-select: none;     -moz-user-select: -moz-none;     -o-user-select: none;     user-select: none; } [selects everything in an unordered list, and makes it un-selectable, rather than trashing the whole view tree.] Thanks for the lesson. My button list is looking great, and responding correctly to screen tapping and pressing, rather than launching an IME (android clipboard widgets)."]},{"answer":"In the solutions in previous answers selection is stopped, but the user still thinks you can select text because the cursor still changes. To keep it static, you'll have to set your CSS cursor:\n\n.noselect {\n    cursor: default;\n    -webkit-touch-callout: none;\n    -webkit-user-select: none;\n    -khtml-user-select: none;\n    -moz-user-select: none;\n    -ms-user-select: none;\n    user-select: none;\n}\n<p>\n  Selectable text.\n</p>\n<p class=\"noselect\">\n  Unselectable text.\n</p>\n Run code snippetExpand snippet\n\nThis will make your text totally flat, like it would be in a desktop application.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 14:23\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 30 '15 at 18:32\nZECTBynmo\n2,8782\n2 gold badges\n20\n20 silver badges\n35\n35 bronze badges","comments":["\"Flat\" as opposed to what?","@kojow7 As opposed to \"layered\". Instead of text floating on top of the other elements. It is similar to the difference between SVG and PNG images.","Was surprised to discover that Firefox still requires the vendor prefix in 2019. I disregardfully used only user-select: none;, thinking the standard would be adopted by now, but sadly it has not. Makes you wonder what the people on the standards committee could still be debating. \"No, you guys... I really think it should be user-select: cant; because it's like more descriptive, you know?\" \"We've been over this, Mike. We would have to omit the apostrophe, and that's bad form!\" \"Enough, everyone! We will deliberate on this matter again next month. Standards Committee meeting adjourned!\""]},{"answer":"You can do so in Firefox and Safari (Chrome also?)\n\n::selection { background: transparent; }\n::-moz-selection { background: transparent; }\n\nShare\nImprove this answer\nFollow\nedited Oct 29 '13 at 17:09\nJames Donnelly\n119k31\n31 gold badges\n194\n194 silver badges\n200\n200 bronze badges\nanswered May 5 '09 at 20:46\nseanmonstar\n10.9k2\n2 gold badges\n19\n19 silver badges\n25\n25 bronze badges","comments":["I wouldn't recommend doing this, because it doesn't actually fix the issue; disabling text selection - it merely hides it. This can lead to bad usability, because if I drag my cursor around the page I could be selecting any arbitrary text without knowing it. This can cause all kinds of weird usability \"bugs\".","Doesn't work on PNG-images with transparent areas: The will always select in a light blue… Any workaround?"]},{"answer":"Workaround for WebKit:\n\n/* Disable tap highlighting */\n-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\n\n\nI found it in a CardFlip example.\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 12:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 21 '11 at 7:09\nAlex\n8496\n6 silver badges\n3\n3 bronze badges","comments":["Using transparent in lieu of rgba also works in Chrome 42 on Android."]},{"answer":"I like the hybrid CSS + jQuery solution.\n\nTo make all elements inside <div class=\"draggable\"></div> unselectable, use this CSS:\n\n.draggable {\n    -webkit-user-select: none;\n     -khtml-user-select: none;\n       -moz-user-select: none;\n        -ms-user-select: none;\n         -o-user-select: none;\n            user-select: none;\n}\n\n.draggable input {\n    -webkit-user-select: text;\n     -khtml-user-select: text;\n       -moz-user-select: text;\n         -o-user-select: text;\n            user-select: text;\n }\n\n\nAnd then, if you're using jQuery, add this inside a $(document).ready() block:\n\nif (($.browser.msie && $.browser.version < 10) || $.browser.opera) $('.draggable').find(':not(input)').attr('unselectable', 'on');\n\n\nI figure you still want any input elements to be interactable, hence the :not() pseudo-selector. You could use '*' instead if you don't care.\n\nCaveat: Internet Explorer 9 may not need this extra jQuery piece, so you may want to add a version check in there.\n\nShare\nImprove this answer\nFollow\nedited Apr 15 '20 at 20:54\njohannchopin\n9,5046\n6 gold badges\n26\n26 silver badges\n68\n68 bronze badges\nanswered Nov 11 '11 at 19:53\nTom Auger\n18.5k22\n22 gold badges\n75\n75 silver badges\n100\n100 bronze badges","comments":["Use -ms-user-select: none; (for IE10) and your jQuery \"if\" should be this: if (($.browser.msie && $.browser.version < 10) || $.browser.opera)","Be careful man !!! To make it selectable in firefox you must use -moz-user-select: Normal;","@mhenry1384 jQuery.browser has been deprecated as of version 1.3 and has been removed in version 1.9 - api.jquery.com/jQuery.browser","@Wynand Good point. But what sort of \"feature detection\" exists to determine which CSS property to use?","@TomAuger You could use jQuery.support, it allows you to check for single features : Link"]},{"answer":".hidden:after {\n    content: attr(data-txt);\n}\n<p class=\"hidden\" data-txt=\"Some text you don't want to be selected\"></p>\n Run code snippetExpand snippet\n\nIt's not the best way, though.\n\nShare\nImprove this answer\nFollow\nedited Jun 16 '17 at 2:37\nFred Gandt\n3,7311\n1 gold badge\n29\n29 silver badges\n37\n37 bronze badges\nanswered May 1 '13 at 11:36\nAle\n1,92018\n18 silver badges\n27\n27 bronze badges","comments":["You could also use title as the attribute.","That is a very creative solution. Especially if it used the title attribute because that would probably be better for screen readers.","I tried it (JSBin) and it doesn't work in IE. Unfortunately older IEs are the only ones that user-select doesn't work for.","This is a great non-JS alternative that works in Chrome! Awesome!"]},{"answer":"You can use CSS or JavaScript for that.\n\nThe JavaScript way is supported in older browsers, like old versions of Internet Explorer as well, but if it's not your case, use the CSS way then:\n\nHTML/JavaScript:\n\n<html onselectstart='return false;'>\n  <body>\n    <h1>This is the Heading!</h1>\n    <p>And I'm the text, I won't be selected if you select me.</p>\n  </body>\n</html>\n Run code snippetExpand snippet\n\nHTML/CSS:\n\n.not-selectable {\n  -webkit-touch-callout: none;\n  -webkit-user-select: none;\n  -khtml-user-select: none;\n  -moz-user-select: none;\n  -ms-user-select: none;\n  user-select: none;\n}\n<body class=\"not-selectable\">\n  <h1>This is the Heading!</h1>\n  <p>And I'm the text, I won't be selected if you select me.</p>\n</body>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 14:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 5 '17 at 14:03\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"For Internet Explorer in addition, you need to add pseudo class focus (.ClassName:focus) and outline-style: none.\n\n.ClassName,\n.ClassName:focus {\n    -webkit-touch-callout: none;\n    -webkit-user-select: none;\n    -khtml-user-select: none;\n    -moz-user-select: none;\n    -ms-user-select: none;\n    user-select: none;\n    outline-style: none; /* Internet Explorer  */\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 13:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 23 '13 at 14:05\nElad Shechter\n3,32917\n17 silver badges\n21\n21 bronze badges","comments":["This does work in IE so long as the selection starts on an element with the className class. See this JSBin."]},{"answer":"Try to insert these rows into the CSS and call the \"disHighlight\" at class property:\n\n.disHighlight {\n    user-select: none;\n    -webkit-user-select: none;\n    -ms-user-select: none;\n    -webkit-touch-callout: none;\n    -o-user-select: none;\n    -moz-user-select: none;\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 13:58\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 28 '16 at 7:13\nuser1012506\n1,85120\n20 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"A Quick Hack Update\n\nIf you use the value none for all the CSS user-select properties (including browser prefixes of it), there is a problem which can be still occurred by this.\n\n.div {\n    -webkit-user-select: none; /* Chrome all / Safari all */\n    -moz-user-select: none;    /* Firefox all             */\n    -ms-user-select: none;     /* Internet Explorer  10+  */\n     user-select: none;        /* Likely future           */\n}\n\n\nAs CSS-Tricks says, the problem is:\n\nWebKit still allows the text to be copied, if you select elements around it.\n\nYou can also use the below one to enforce that an entire element gets selected which means if you click on an element, all the text wrapped in that element will get selected. For this all you have to do is changing the value none to all.\n\n.force-select {\n    -webkit-user-select: all;  /* Chrome 49+     */\n    -moz-user-select: all;     /* Firefox 43+    */\n    -ms-user-select: all;      /* No support yet */\n    user-select: all;          /* Likely future  */\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 14:11\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 31 '18 at 11:32\nKaz\n1,0367\n7 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"With SASS (SCSS syntax)\n\nYou can do this with a mixin:\n\n// Disable selection\n@mixin disable-selection {\n    -webkit-touch-callout: none; /* iOS Safari */\n    -webkit-user-select: none;   /* Safari */\n    -khtml-user-select: none;    /* Konqueror HTML */\n    -moz-user-select: none;      /* Firefox */\n    -ms-user-select: none;       /* Internet Explorer/Edge */\n    user-select: none;           /* Non-prefixed version, currently supported by Chrome and Opera */\n}\n\n// No selectable element\n.no-selectable {\n    @include disable-selection;\n}\n\n\nIn an HTML tag:\n\n<div class=\"no-selectable\">TRY TO HIGHLIGHT</div>\n\n\nTry it in this CodePen.\n\nIf you are using an autoprefixer you can remove other prefixes.\n\nBrowser compatibility here.\n\nShare\nImprove this answer\nFollow\nedited May 8 '20 at 8:35\nanswered Oct 11 '19 at 10:27\nAlessandro_russo\n1,45612\n12 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"For those who have trouble achieving the same in the Android browser with the touch event, use:\n\nhtml, body {\n    -webkit-touch-callout: none;\n    -webkit-user-select: none;\n    -webkit-tap-highlight-color: rgba(0, 0, 0, 0);\n    -webkit-tap-highlight-color: transparent;\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 13:37\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 19 '14 at 5:30\nBeep.exe\n1,34012\n12 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"If you are using Less and Bootstrap you could write:\n\n.user-select(none);\n\nShare\nImprove this answer\nFollow\nedited Apr 17 '16 at 5:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 18 '12 at 8:34\nCodler\n9,6716\n6 gold badges\n48\n48 silver badges\n62\n62 bronze badges","comments":[]},{"answer":"-webkit-user-select: none;\n-khtml-user-select: none;\n-moz-user-select: none;\n-o-user-select: none;\nuser-select: none;\n\n*.unselectable {\n   -moz-user-select: -moz-none;\n   -khtml-user-select: none;\n   -webkit-user-select: none;\n   user-select: none;\n}\n\n<div id=\"foo\" unselectable=\"on\" class=\"unselectable\">...</div>\n\nfunction makeUnselectable(node) {\n    if (node.nodeType == 1) {\n        node.unselectable = true;\n    }\n    var child = node.firstChild;\n    while (child) {\n        makeUnselectable(child);\n        child = child.nextSibling;\n    }\n}\n\nmakeUnselectable(document.getElementById(\"foo\"));\n\n-webkit-user-select: none;\n-moz-user-select: none;\n\nonselectstart=\"return false;\"\n\n::selection { \n    background: transparent; \n}\n\n::-moz-selection { \n    background: transparent; \n}\n\n* {\n    -webkit-user-select: none;\n    -khtml-user-select: none;\n    -moz-user-select: -moz-none;\n    -o-user-select: none;\n    user-select: none;\n}\n\np {\n    -webkit-user-select: text;\n    -khtml-user-select: text;\n    -moz-user-select: text;\n    -o-user-select: text;\n    user-select: text;\n}\n\n<div class=\"draggable\"></div>\n\n.draggable {\n    -webkit-user-select: none;\n    -khtml-user-select: none;\n    -moz-user-select: none;\n    -o-user-select: none;\n    user-select: none;\n}\n\n.draggable input {\n    -webkit-user-select: text;\n    -khtml-user-select: text;\n    -moz-user-select: text;\n    -o-user-select: text;\n    user-select: text;\n }\n\nif ($.browser.msie)\n    $('.draggable').find(':not(input)').attr('unselectable', 'on');\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 13:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 26 '12 at 5:44\nGaurang\n1,89818\n18 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"Working\n\nCSS:\n\n-khtml-user-select: none;\n-moz-user-select: none;\n-ms-user-select: none;\nuser-select: none;\n-webkit-touch-callout: none;\n-webkit-user-select: none;\n\n\nThis should work, but it won't work for the old browsers. There is a browser compatibility issue.\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 13:34\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 27 '14 at 9:01\nsuraj rawat\n3,35919\n19 silver badges\n30\n30 bronze badges","comments":["The unprefixed CSS property must be strictly at the end of list of prefixed versions of the property. It is good right practice, other is bad practice making an \"new IE\" from Chrome/Webkit and leading to so much UGLY THINGS as introducing -webkit prefix support in not webkit browsers. Look, this was already in 2012: dev.opera.com/articles/…","And I quote: This is because through our site compatibility work, we have experienced that many authors of (especially mobile) sites only use -webkit- prefixed CSS, thereby ignoring other vendor prefixes and not even including an unprefixed equivalent. This leads to a reduced user experience on Opera and Firefox, which don’t receive the same shiny effects such as transitions, gradients and the like, even if the browser supported those effects."]},{"answer":"Aside from the Mozilla-only property, no, there is no way to disable text selection with just standard CSS (as of now).\n\nIf you notice, Stack Overflow doesn't disable text selection for their navigation buttons, and I would recommend against doing so in most cases, since it modifies normal selection behavior and makes it conflict with a user's expectations.\n\nShare\nImprove this answer\nFollow\nanswered May 5 '09 at 20:38\nhbw\n15k5\n5 gold badges\n48\n48 silver badges\n56\n56 bronze badges","comments":["While I agree that it changes behaviour the user expects, it would make sense for things like the \"Add Comment\" button that is sitting next to this form field ...","But doesn't that expose needless implementation details? An input or button's text can't be selected.","@anon: Most users will probably not try to select the text of your button, so in practice, it shouldn't really matter much. Besides, in order to do so, they will have to start selecting outside of the button—if they click inside the button itself, the onclick handler will activate instead. Plus, certain browsers (e.g. Safari) actually let you select the text of normal buttons…","If you're selecting a set of comments from a chat thread and each comment has an upvote/downvote button next to it, then it would be nice to select the text without the other stuff. That's what the user expects or wants. He doesn't want to copy/paste the button labels with every comment.","And what if you for example double click a button which instead of redirecting you to another page opens a div? then the text for the button will be selected due to the double-click!"]},{"answer":"This works in some browsers:\n\n::selection{ background-color: transparent;}\n::moz-selection{ background-color: transparent;}\n::webkit-selection{ background-color: transparent;}\n\n\nSimply add your desired elements/ids in front of the selectors separated by commas without spaces, like so:\n\nh1::selection,h2::selection,h3::selection,p::selection{ background-color: transparent;}\nh1::moz-selection,h2::moz-selection,h3::moz-selection,p::moz-selection{ background-color: transparent;}\nh1::webkit-selection,h2::webkit-selection,h3::webkit-selection,p::webkit-selection{ background-color: transparent;}\n\n\nThe other answers are better; this should probably be seen as a last resort/catchall.\n\nShare\nImprove this answer\nFollow\nedited Apr 17 '16 at 4:54\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 9 '14 at 22:56\nr3wt\n4,3202\n2 gold badges\n29\n29 silver badges\n52\n52 bronze badges","comments":["There are few things that can be known for sure, but this solution definitely doesn't work in all browsers."]},{"answer":"Suppose there are two divs like this:\n\n.second {\n  cursor: default;\n  user-select: none;\n  -webkit-user-select: none;\n  /* Chrome/Safari/Opera */\n  -moz-user-select: none;\n  /* Firefox */\n  -ms-user-select: none;\n  /* Internet Explorer/Edge */\n  -webkit-touch-callout: none;\n  /* iOS Safari */\n}\n<div class=\"first\">\n  This is my first div\n</div>\n\n<div class=\"second\">\n  This is my second div\n</div>\n Run code snippetExpand snippet\n\nSet cursor to default so that it will give a unselectable feel to the user.\n\nPrefix need to be used to support it in all browsers. Without a prefix this may not work in all the answers.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 14:24\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 28 '16 at 9:42\nGaurav Aggarwal\n9,0315\n5 gold badges\n30\n30 silver badges\n67\n67 bronze badges","comments":[]},{"answer":"This will be useful if color selection is also not needed:\n\n::-moz-selection { background:none; color:none; }\n::selection { background:none; color:none; }\n\n\n...all other browser fixes. It will work in Internet Explorer 9 or later.\n\nShare\nImprove this answer\nFollow\nedited Apr 17 '16 at 5:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 3 '13 at 8:31\nkarthipan raj\n7278\n8 silver badges\n14\n14 bronze badges","comments":["Make that color: inherit; maybe.","yeah I love it. It's css selector level 3 according to Mozilla docs"]},{"answer":"Add this to the first div in which you want to disable the selection for text:\n\nonmousedown='return false;' \nonselectstart='return false;'\n\nShare\nImprove this answer\nFollow\nedited Mar 10 '13 at 19:58\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 30 '12 at 6:56\nJIT1986\n6736\n6 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"NOTE:\n\nThe correct answer is correct in that it prevents you from being able to select the text. However, it does not prevent you from being able to copy the text, as I'll show with the next couple of screenshots (as of 7th Nov 2014).\n\nAs you can see, we were unable to select the numbers, but we were able to copy them.\n\nTested on: Ubuntu, Google Chrome 38.0.2125.111.\n\nShare\nImprove this answer\nFollow\nedited Apr 17 '16 at 4:52\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 7 '14 at 13:22\nLuke Madhanga\n4,3001\n1 gold badge\n36\n36 silver badges\n40\n40 bronze badges","comments":["I've had the same problem. On Mac Chrome 48.0.2564.116 and on Mac Safari 9.0.3. Notably, Mac Firefox 43.0 doesn't copy the character, but sticks extra endlines between them. What should be done about this?"]},{"answer":"To get the result I needed, I found I had to use both ::selection and user-select\n\ninput.no-select:focus {\n    -webkit-touch-callout: none;\n    -webkit-user-select: none;\n    -khtml-user-select: none;\n    -moz-user-select: none;\n    -ms-user-select: none;\n    user-select: none;\n}\n\ninput.no-select::selection {\n    background: transparent;\n}\n\ninput.no-select::-moz-selection {\n    background: transparent;\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 13:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 14 '15 at 0:13\nSemanticZen\n1,09113\n13 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"It is easily done with:\n\n-webkit-user-select: none;\n-moz-user-select: none;\n-ms-user-select: none;\n-o-user-select: none;\nuser-select: none;\n\n\nAlternatively:\n\nLet's say you have a <h1 id=\"example\">Hello, World!</h1>. You will have to remove the innerHTML of that h1, in this case Hello, World. Then you will have to go to CSS and do this:\n\n#example::before // You can of course use **::after** as well.\n{\n    content: 'Hello, World!'; // Both single-quotes and double-quotes can be used here.\n\n    display: block; // To make sure it works fine in every browser.\n}\n\n\nNow it simply thinks it is a block-element, and not text.\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 14:16\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 8 '18 at 9:17\ncodeWithMe\n7568\n8 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"This is not CSS, but it is worth a mention:\n\njQuery UI Disable Selection:\n\n$(\"your.selector\").disableSelection();\n\nShare\nImprove this answer\nFollow\nanswered Apr 9 '13 at 16:42\nAutomatico\n11k7\n7 gold badges\n69\n69 silver badges\n106\n106 bronze badges","comments":[]},{"answer":"Check my solution without JavaScript:\n\njsFiddle\n\nli:hover {\n    background-color: silver;\n}\n#id1:before {\n    content: \"File\";\n}\n#id2:before {\n    content: \"Edit\";\n}\n#id3:before {\n    content: \"View\";\n}\n<ul>\n    <li><a id=\"id1\" href=\"www.w1.com\"></a>\n    <li><a id=\"id2\" href=\"www.w2.com\"></a>\n    <li><a id=\"id3\" href=\"www.w3.com\"></a>\n</ul>\n Run code snippetExpand snippet\n\nPopup menu with my technique applied: http://jsfiddle.net/y4Lac/2/\n\nShare\nImprove this answer\nFollow\nedited Apr 17 '16 at 5:00\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 22 '14 at 22:06\napocalypse\n5,3418\n8 gold badges\n41\n41 silver badges\n86\n86 bronze badges","comments":[]},{"answer":"Though this pseudo-element was in drafts of CSS Selectors Level 3, it was removed during the Candidate Recommendation phase, as it appeared that its behavior was under-specified, especially with nested elements, and interoperability wasn't achieved.\n\nIt's being discussed in How ::selection works on nested elements.\n\nDespite it is being implemented in browsers, you can make an illusion of text not being selected by using the same color and background color on selection as of the tab design (in your case).\n\nNormal CSS Design\np { color: white;  background: black; }\n\nOn selection\np::-moz-selection { color: white;  background: black; }\np::selection      { color: white;  background: black; }\n\n\nDisallowing users to select the text will raise usability issues.\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '19 at 13:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 21 '14 at 13:53\nSuraj Naik\n5034\n4 silver badges\n7\n7 bronze badges","comments":["This must be why Netbeans auto-completion has no idea what I am talking about!"]}]},{"id":"549","href":"https://stackoverflow.com/questions/549/the-definitive-guide-to-form-based-website-authentication","title":"The definitive guide to form-based website authentication [closed]","description":"\n                    \n            \n        \n            \n                \n                    \n                        Closed. This question needs to be more focused. It is not currently accepting answers.\n                        \n                    \n                \n            \n        \n            \n        \n                \n                    \n                \n            \n                \n                    Want to improve this question? Update the question so it focuses on one problem only by editing this post.\n                \n                    Closed 5 years ago.\n            \n        \n            \n                    \n                        Improve this question\n                    \n            \n\n\n    \n\nForm-based authentication for websites\n\nWe believe that Stack Overflow should not just be a resource for very specific technical questions, but also for general guidelines on how to solve variations on common problems. \"Form based authentication for websites\" should be a fine topic for such an experiment.\n\nIt should include topics such as:\n\n\nHow to log in\nHow to log out\nHow to remain logged in\nManaging cookies (including recommended settings)\nSSL/HTTPS encryption\nHow to store passwords\nUsing secret questions\nForgotten username/password functionality\nUse of nonces to prevent cross-site request forgeries (CSRF)\nOpenID\n\"Remember me\" checkbox\nBrowser autocompletion of usernames and passwords\nSecret URLs (public URL protected by digest)\nChecking password strength\nE-mail validation\nand much more about form based authentication...\n\n\nIt should not include things like:\n\n\nRoles and authorization\nHTTP basic authentication\n\n\nPlease help us by:\n\n\nSuggesting subtopics\nSubmitting good articles about this subject\nEditing the official answer\n\n    ","questionComments":["Why exclude HTTP Basic Authentication? It can work in HTML Forms via Ajax: peej.co.uk/articles/http-auth-with-html-forms.html","HTTP Basic Auth has the property of being (comparatively) difficult to make a browser forget. It's also horribly insecure if you don't use it with SSL to secure the connection (i.e., HTTPS).","I think it'd be worth talking about sessions (including fixation and hijacking) cookies (the secure and http only flags) HTTP based SSO","The super-useful HttpOnly cookie flag, which prevents JavaScript-based cookie theft (a subset of XSS attacks), should be mentioned somewhere too.","Wow. Lengthy answers, dozens of upvotes for some of them, yet nobody mentions the common mistake of serving login forms over HTTP. I've even argued with people who said \"but it submits to https://...\" and only got blank stares when I asked if they were sure an attacker didn't rewrite the non-encrypted page the form was served over."],"answers":[{"answer":"PART I: How To Log In\n\nWe'll assume you already know how to build a login+password HTML form which POSTs the values to a script on the server side for authentication. The sections below will deal with patterns for sound practical auth, and how to avoid the most common security pitfalls.\n\nTo HTTPS or not to HTTPS?\n\nUnless the connection is already secure (that is, tunneled through HTTPS using SSL/TLS), your login form values (gasp! including your password) will be sent in cleartext, which allows anyone eavesdropping on the line between browser and web server will be able to read logins as they pass through. This type of wiretapping is done routinely by governments, but in general, we won't address 'owned' wires other than to say this: Just use HTTPS.\n\nIn essence, the only practical way to protect against wiretapping/packet sniffing during login is by using HTTPS or another certificate-based encryption scheme (for example, TLS) or a proven & tested challenge-response scheme (for example, the Diffie-Hellman-based SRP). Any other method can be easily circumvented by an eavesdropping attacker.\n\nOf course, if you are willing to get a little bit impractical, you could also employ some form of two-factor authentication scheme (e.g. the Google Authenticator app, a physical 'cold war style' codebook, or an RSA key generator dongle). If applied correctly, this could work even with an unsecured connection, but it's hard to imagine that a dev would be willing to implement two-factor auth but not SSL.\n\n(Do not) Roll-your-own JavaScript encryption/hashing\n\nGiven the perceived (though now avoidable) cost and technical difficulty of setting up an SSL certificate on your website, some developers are tempted to roll their own in-browser hashing or encryption schemes in order to avoid passing cleartext logins over an unsecured wire.\n\nWhile this is a noble thought, it is essentially useless (and can be a security flaw) unless it is combined with one of the above - that is, either securing the line with strong encryption or using a tried-and-tested challenge-response mechanism (if you don't know what that is, just know that it is one of the most difficult to prove, most difficult to design, and most difficult to implement concepts in digital security).\n\nWhile it is true that hashing the password can be effective against password disclosure, it is vulnerable to replay attacks, Man-In-The-Middle attacks / hijackings (if an attacker can inject a few bytes into your unsecured HTML page before it reaches your browser, they can simply comment out the hashing in the JavaScript), or brute-force attacks (since you are handing the attacker both username, salt and hashed password).\n\nCAPTCHAS against humanity\n\nCAPTCHA is meant to thwart one specific category of attack: automated dictionary/brute force trial-and-error with no human operator. There is no doubt that this is a real threat, however, there are ways of dealing with it seamlessly that don't require a CAPTCHA, specifically properly designed server-side login throttling schemes - we'll discuss those later.\n\nKnow that CAPTCHA implementations are not created alike; they often aren't human-solvable, most of them are actually ineffective against bots, all of them are ineffective against cheap third-world labor (according to OWASP, the current sweatshop rate is $12 per 500 tests), and some implementations may be technically illegal in some countries (see OWASP Authentication Cheat Sheet).\n\nCAPTCHAs are bad for the visually impaired. The traditional copy was almost impossible to complete even for humans with perfect 20/20 vision on the first try. So don't use a traditional CAPTCHA!\n\nIf you must use a CAPTCHA, use Google's reCAPTCHA, since it is OCR-hard by definition (since it uses already OCR-misclassified book scans) and tries very hard to be user-friendly.\n\nPersonally, I tend to find CAPTCHAS annoying, and use them only as a last resort when a user has failed to log in a number of times and throttling delays are maxed out. This will happen rarely enough to be acceptable, and it strengthens the system as a whole.\n\nStoring Passwords / Verifying logins\n\nThis may finally be common knowledge after all the highly-publicized hacks and user data leaks we've seen in recent years, but it has to be said: Do not store passwords in cleartext in your database. User databases are routinely hacked, leaked or gleaned through SQL injection, and if you are storing raw, plaintext passwords, that is instant game over for your login security.\n\nSo if you can't store the password, how do you check that the login+password combination POSTed from the login form is correct? The answer is hashing using a key derivation function. Whenever a new user is created or a password is changed, you take the password and run it through a KDF, such as Argon2, bcrypt, scrypt or PBKDF2, turning the cleartext password (\"correcthorsebatterystaple\") into a long, random-looking string, which is a lot safer to store in your database. To verify a login, you run the same hash function on the entered password, this time passing in the salt and compare the resulting hash string to the value stored in your database. Argon2, bcrypt and scrypt store the salt with the hash already. Check out this article on sec.stackexchange for more detailed information.\n\nThe reason a salt is used is that hashing in itself is not sufficient -- you'll want to add a so-called 'salt' to protect the hash against rainbow tables. A salt effectively prevents two passwords that exactly match from being stored as the same hash value, preventing the whole database being scanned in one run if an attacker is executing a password guessing attack.\n\nA cryptographic hash should not be used for password storage because user-selected passwords are not strong enough (i.e. do not usually contain enough entropy) and a password guessing attack could be completed in a relatively short time by an attacker with access to the hashes. This is why KDFs are used - these effectively \"stretch the key\", which means that every password guess an attacker makes causes multiple repetitions of the hash algorithm, for example 10,000 times, which causes the attacker to guess the password 10,000 times slower.\n\nSession data - \"You are logged in as Spiderman69\"\n\nOnce the server has verified the login and password against your user database and found a match, the system needs a way to remember that the browser has been authenticated. This fact should only ever be stored server side in the session data.\n\nIf you are unfamiliar with session data, here's how it works: A single randomly-generated string is stored in an expiring cookie and used to reference a collection of data - the session data - which is stored on the server. If you are using an MVC framework, this is undoubtedly handled already.\n\nIf at all possible, make sure the session cookie has the secure and HTTP Only flags set when sent to the browser. The HttpOnly flag provides some protection against the cookie being read through XSS attack. The secure flag ensures that the cookie is only sent back via HTTPS, and therefore protects against network sniffing attacks. The value of the cookie should not be predictable. Where a cookie referencing a non-existent session is presented, its value should be replaced immediately to prevent session fixation.\n\nSession state can also be maintained on the client side. This is achieved by using techniques like JWT (JSON Web Token).\n\nPART II: How To Remain Logged In - The Infamous \"Remember Me\" Checkbox\n\nPersistent Login Cookies (\"remember me\" functionality) are a danger zone; on the one hand, they are entirely as safe as conventional logins when users understand how to handle them; and on the other hand, they are an enormous security risk in the hands of careless users, who may use them on public computers and forget to log out, and who may not know what browser cookies are or how to delete them.\n\nPersonally, I like persistent logins for the websites I visit on a regular basis, but I know how to handle them safely. If you are positive that your users know the same, you can use persistent logins with a clean conscience. If not - well, then you may subscribe to the philosophy that users who are careless with their login credentials brought it upon themselves if they get hacked. It's not like we go to our user's houses and tear off all those facepalm-inducing Post-It notes with passwords they have lined up on the edge of their monitors, either.\n\nOf course, some systems can't afford to have any accounts hacked; for such systems, there is no way you can justify having persistent logins.\n\nIf you DO decide to implement persistent login cookies, this is how you do it:\n\nFirst, take some time to read Paragon Initiative's article on the subject. You'll need to get a bunch of elements right, and the article does a great job of explaining each.\n\nAnd just to reiterate one of the most common pitfalls, DO NOT STORE THE PERSISTENT LOGIN COOKIE (TOKEN) IN YOUR DATABASE, ONLY A HASH OF IT! The login token is Password Equivalent, so if an attacker got their hands on your database, they could use the tokens to log in to any account, just as if they were cleartext login-password combinations. Therefore, use hashing (according to https://security.stackexchange.com/a/63438/5002 a weak hash will do just fine for this purpose) when storing persistent login tokens.\n\nPART III: Using Secret Questions\n\nDon't implement 'secret questions'. The 'secret questions' feature is a security anti-pattern. Read the paper from link number 4 from the MUST-READ list. You can ask Sarah Palin about that one, after her Yahoo! email account got hacked during a previous presidential campaign because the answer to her security question was... \"Wasilla High School\"!\n\nEven with user-specified questions, it is highly likely that most users will choose either:\n\nA 'standard' secret question like mother's maiden name or favorite pet\n\nA simple piece of trivia that anyone could lift from their blog, LinkedIn profile, or similar\n\nAny question that is easier to answer than guessing their password. Which, for any decent password, is every question you can imagine\n\nIn conclusion, security questions are inherently insecure in virtually all their forms and variations, and should not be employed in an authentication scheme for any reason.\n\nThe true reason why security questions even exist in the wild is that they conveniently save the cost of a few support calls from users who can't access their email to get to a reactivation code. This at the expense of security and Sarah Palin's reputation. Worth it? Probably not.\n\nPART IV: Forgotten Password Functionality\n\nI already mentioned why you should never use security questions for handling forgotten/lost user passwords; it also goes without saying that you should never e-mail users their actual passwords. There are at least two more all-too-common pitfalls to avoid in this field:\n\nDon't reset a forgotten password to an autogenerated strong password - such passwords are notoriously hard to remember, which means the user must either change it or write it down - say, on a bright yellow Post-It on the edge of their monitor. Instead of setting a new password, just let users pick a new one right away - which is what they want to do anyway. (An exception to this might be if the users are universally using a password manager to store/manage passwords that would normally be impossible to remember without writing it down).\n\nAlways hash the lost password code/token in the database. AGAIN, this code is another example of a Password Equivalent, so it MUST be hashed in case an attacker got their hands on your database. When a lost password code is requested, send the plaintext code to the user's email address, then hash it, save the hash in your database -- and throw away the original. Just like a password or a persistent login token.\n\nA final note: always make sure your interface for entering the 'lost password code' is at least as secure as your login form itself, or an attacker will simply use this to gain access instead. Making sure you generate very long 'lost password codes' (for example, 16 case-sensitive alphanumeric characters) is a good start, but consider adding the same throttling scheme that you do for the login form itself.\n\nPART V: Checking Password Strength\n\nFirst, you'll want to read this small article for a reality check: The 500 most common passwords\n\nOkay, so maybe the list isn't the canonical list of most common passwords on any system anywhere ever, but it's a good indication of how poorly people will choose their passwords when there is no enforced policy in place. Plus, the list looks frighteningly close to home when you compare it to publicly available analyses of recently stolen passwords.\n\nSo: With no minimum password strength requirements, 2% of users use one of the top 20 most common passwords. Meaning: if an attacker gets just 20 attempts, 1 in 50 accounts on your website will be crackable.\n\nThwarting this requires calculating the entropy of a password and then applying a threshold. The National Institute of Standards and Technology (NIST) Special Publication 800-63 has a set of very good suggestions. That, when combined with a dictionary and keyboard layout analysis (for example, 'qwertyuiop' is a bad password), can reject 99% of all poorly selected passwords at a level of 18 bits of entropy. Simply calculating password strength and showing a visual strength meter to a user is good, but insufficient. Unless it is enforced, a lot of users will most likely ignore it.\n\nAnd for a refreshing take on user-friendliness of high-entropy passwords, Randall Munroe's Password Strength xkcd is highly recommended.\n\nUtilize Troy Hunt's Have I Been Pwned API to check users passwords against passwords compromised in public data breaches.\n\nPART VI: Much More - Or: Preventing Rapid-Fire Login Attempts\n\nFirst, have a look at the numbers: Password Recovery Speeds - How long will your password stand up\n\nIf you don't have the time to look through the tables in that link, here's the list of them:\n\nIt takes virtually no time to crack a weak password, even if you're cracking it with an abacus\n\nIt takes virtually no time to crack an alphanumeric 9-character password if it is case insensitive\n\nIt takes virtually no time to crack an intricate, symbols-and-letters-and-numbers, upper-and-lowercase password if it is less than 8 characters long (a desktop PC can search the entire keyspace up to 7 characters in a matter of days or even hours)\n\nIt would, however, take an inordinate amount of time to crack even a 6-character password, if you were limited to one attempt per second!\n\nSo what can we learn from these numbers? Well, lots, but we can focus on the most important part: the fact that preventing large numbers of rapid-fire successive login attempts (ie. the brute force attack) really isn't that difficult. But preventing it right isn't as easy as it seems.\n\nGenerally speaking, you have three choices that are all effective against brute-force attacks (and dictionary attacks, but since you are already employing a strong passwords policy, they shouldn't be an issue):\n\nPresent a CAPTCHA after N failed attempts (annoying as hell and often ineffective -- but I'm repeating myself here)\n\nLocking accounts and requiring email verification after N failed attempts (this is a DoS attack waiting to happen)\n\nAnd finally, login throttling: that is, setting a time delay between attempts after N failed attempts (yes, DoS attacks are still possible, but at least they are far less likely and a lot more complicated to pull off).\n\nBest practice #1: A short time delay that increases with the number of failed attempts, like:\n\n1 failed attempt = no delay\n2 failed attempts = 2 sec delay\n3 failed attempts = 4 sec delay\n4 failed attempts = 8 sec delay\n5 failed attempts = 16 sec delay\netc.\n\nDoS attacking this scheme would be very impractical, since the resulting lockout time is slightly larger than the sum of the previous lockout times.\n\nTo clarify: The delay is not a delay before returning the response to the browser. It is more like a timeout or refractory period during which login attempts to a specific account or from a specific IP address will not be accepted or evaluated at all. That is, correct credentials will not return in a successful login, and incorrect credentials will not trigger a delay increase.\n\nBest practice #2: A medium length time delay that goes into effect after N failed attempts, like:\n\n1-4 failed attempts = no delay\n5 failed attempts = 15-30 min delay\n\nDoS attacking this scheme would be quite impractical, but certainly doable. Also, it might be relevant to note that such a long delay can be very annoying for a legitimate user. Forgetful users will dislike you.\n\nBest practice #3: Combining the two approaches - either a fixed, short time delay that goes into effect after N failed attempts, like:\n\n1-4 failed attempts = no delay\n5+ failed attempts = 20 sec delay\n\nOr, an increasing delay with a fixed upper bound, like:\n\n1 failed attempt = 5 sec delay\n2 failed attempts = 15 sec delay\n3+ failed attempts = 45 sec delay\n\nThis final scheme was taken from the OWASP best-practices suggestions (link 1 from the MUST-READ list) and should be considered best practice, even if it is admittedly on the restrictive side.\n\nAs a rule of thumb, however, I would say: the stronger your password policy is, the less you have to bug users with delays. If you require strong (case-sensitive alphanumerics + required numbers and symbols) 9+ character passwords, you could give the users 2-4 non-delayed password attempts before activating the throttling.\n\nDoS attacking this final login throttling scheme would be very impractical. And as a final touch, always allow persistent (cookie) logins (and/or a CAPTCHA-verified login form) to pass through, so legitimate users won't even be delayed while the attack is in progress. That way, the very impractical DoS attack becomes an extremely impractical attack.\n\nAdditionally, it makes sense to do more aggressive throttling on admin accounts, since those are the most attractive entry points\n\nPART VII: Distributed Brute Force Attacks\n\nJust as an aside, more advanced attackers will try to circumvent login throttling by 'spreading their activities':\n\nDistributing the attempts on a botnet to prevent IP address flagging\n\nRather than picking one user and trying the 50.000 most common passwords (which they can't, because of our throttling), they will pick THE most common password and try it against 50.000 users instead. That way, not only do they get around maximum-attempts measures like CAPTCHAs and login throttling, their chance of success increases as well, since the number 1 most common password is far more likely than number 49.995\n\nSpacing the login requests for each user account, say, 30 seconds apart, to sneak under the radar\n\nHere, the best practice would be logging the number of failed logins, system-wide, and using a running average of your site's bad-login frequency as the basis for an upper limit that you then impose on all users.\n\nToo abstract? Let me rephrase:\n\nSay your site has had an average of 120 bad logins per day over the past 3 months. Using that (running average), your system might set the global limit to 3 times that -- ie. 360 failed attempts over a 24 hour period. Then, if the total number of failed attempts across all accounts exceeds that number within one day (or even better, monitor the rate of acceleration and trigger on a calculated threshold), it activates system-wide login throttling - meaning short delays for ALL users (still, with the exception of cookie logins and/or backup CAPTCHA logins).\n\nI also posted a question with more details and a really good discussion of how to avoid tricky pitfals in fending off distributed brute force attacks\n\nPART VIII: Two-Factor Authentication and Authentication Providers\n\nCredentials can be compromised, whether by exploits, passwords being written down and lost, laptops with keys being stolen, or users entering logins into phishing sites. Logins can be further protected with two-factor authentication, which uses out-of-band factors such as single-use codes received from a phone call, SMS message, app, or dongle. Several providers offer two-factor authentication services.\n\nAuthentication can be completely delegated to a single-sign-on service, where another provider handles collecting credentials. This pushes the problem to a trusted third party. Google and Twitter both provide standards-based SSO services, while Facebook provides a similar proprietary solution.\n\nMUST-READ LINKS About Web Authentication\nOWASP Guide To Authentication / OWASP Authentication Cheat Sheet\nDos and Don’ts of Client Authentication on the Web (very readable MIT research paper)\nWikipedia: HTTP cookie\nPersonal knowledge questions for fallback authentication: Security questions in the era of Facebook (very readable Berkeley research paper)\nShare\nImprove this answer\nFollow\nedited Jul 22 at 2:48\ncommunity wiki\n\n\n53 revs, 38 users 29%\nJens Roland","comments":["Well, I don't really agree with the Captcha part, yes Captchas are annoying and they can be broken (except recaptcha but this is barely solvable by humans!) but this is exactly like saying don't use a spam filter because it has less than 0.1% false negatives .. this very site uses Captchas, they are not perfect but they cut a considerable amount of spam and there's simply no good alternative to them","@Jeff: I'm sorry to hear that you have issues with my reply. I didn't know there was a debate on Meta about this answer, I would have gladly edited it myself if you'd asked me to. And deleting my posts just deleted 1200 reputation from my account, which hurts :(","\"After sending the authentication tokens, the system needs a way to remember that you have been authenticated - this fact should only ever be stored serverside in the session data. A cookie can be used to reference the session data.\" Not quite. You can (and should, for stateless servers!) use a cryptographically signed cookie. That's impossible to forge, doesn't tie up server resources, and doesn't need sticky sessions or other shenanigans.","\"a desktop PC can search the FULL KEYSPACE up to 7 characters in less than 90 days\" A machine with a recent GPU can search the full 7 char keyspace in less than 1 day. A top of the line GPU can manage 1 billion hashes per second. golubev.com/hashgpu.htm This leads to some conclusions about password storage which aren't directly addressed.","I'm surprised CSRF protection hasn't been mentioned..."]},{"answer":"Definitive Article\nSending credentials\n\nThe only practical way to send credentials 100% securely is by using SSL. Using JavaScript to hash the password is not safe. Common pitfalls for client-side password hashing:\n\nIf the connection between the client and server is unencrypted, everything you do is vulnerable to man-in-the-middle attacks. An attacker could replace the incoming javascript to break the hashing or send all credentials to their server, they could listen to client responses and impersonate the users perfectly, etc. etc. SSL with trusted Certificate Authorities is designed to prevent MitM attacks.\nThe hashed password received by the server is less secure if you don't do additional, redundant work on the server.\n\nThere's another secure method called SRP, but it's patented (although it is freely licensed) and there are few good implementations available.\n\nStoring passwords\n\nDon't ever store passwords as plaintext in the database. Not even if you don't care about the security of your own site. Assume that some of your users will reuse the password of their online bank account. So, store the hashed password, and throw away the original. And make sure the password doesn't show up in access logs or application logs. OWASP recommends the use of Argon2 as your first choice for new applications. If this is not available, PBKDF2 or scrypt should be used instead. And finally if none of the above are available, use bcrypt.\n\nHashes by themselves are also insecure. For instance, identical passwords mean identical hashes--this makes hash lookup tables an effective way of cracking lots of passwords at once. Instead, store the salted hash. A salt is a string appended to the password prior to hashing - use a different (random) salt per user. The salt is a public value, so you can store them with the hash in the database. See here for more on this.\n\nThis means that you can't send the user their forgotten passwords (because you only have the hash). Don't reset the user's password unless you have authenticated the user (users must prove that they are able to read emails sent to the stored (and validated) email address.)\n\nSecurity questions\n\nSecurity questions are insecure - avoid using them. Why? Anything a security question does, a password does better. Read PART III: Using Secret Questions in @Jens Roland answer here in this wiki.\n\nSession cookies\n\nAfter the user logs in, the server sends the user a session cookie. The server can retrieve the username or id from the cookie, but nobody else can generate such a cookie (TODO explain mechanisms).\n\nCookies can be hijacked: they are only as secure as the rest of the client's machine and other communications. They can be read from disk, sniffed in network traffic, lifted by a cross-site scripting attack, phished from a poisoned DNS so the client sends their cookies to the wrong servers. Don't send persistent cookies. Cookies should expire at the end of the client session (browser close or leaving your domain).\n\nIf you want to autologin your users, you can set a persistent cookie, but it should be distinct from a full-session cookie. You can set an additional flag that the user has auto-logged in, and needs to log in for real for sensitive operations. This is popular with shopping sites that want to provide you with a seamless, personalized shopping experience but still protect your financial details. For example, when you return to visit Amazon, they show you a page that looks like you're logged in, but when you go to place an order (or change your shipping address, credit card etc.), they ask you to confirm your password.\n\nFinancial websites such as banks and credit cards, on the other hand, only have sensitive data and should not allow auto-login or a low-security mode.\n\nList of external resources\nDos and Don'ts of Client Authentication on the Web (PDF)\n21 page academic article with many great tips.\nAsk YC: Best Practices for User Authentication\nForum discussion on the subject\nYou're Probably Storing Passwords Incorrectly\nIntroductory article about storing passwords\nDiscussion: Coding Horror: You're Probably Storing Passwords Incorrectly\nForum discussion about a Coding Horror article.\nNever store passwords in a database!\nAnother warning about storing passwords in the database.\nPassword cracking\nWikipedia article on weaknesses of several password hashing schemes.\nEnough With The Rainbow Tables: What You Need To Know About Secure Password Schemes\nDiscussion about rainbow tables and how to defend against them, and against other threads. Includes extensive discussion.\nShare\nImprove this answer\nFollow\nedited Nov 19 '18 at 13:54\ncommunity wiki\n\n\n21 revs, 14 users 35%\nMichiel de Mare","comments":["Given the recent MITM vulnerability surrounding signed SSL certificates (blog.startcom.org/?p=145) so a combination of SSL and some kind of Challenge response authentication (There are alternatives to SRP) is probably a better solution.","a lot of this stuff is situational. i tend not to use session cookies at all. cookies getting hijacked is almost always the servers fault. man in the middle / packet sniffing arent that common","BCrypt Nuget package : nuget.org/List/Packages/BCrypt","Note 1 about this answer: it is a draft, to be edited as a wiki. If you can edit this, you're welcome to.","SRP is specific to the presence of several parties if I understand well"]},{"answer":"First, a strong caveat that this answer is not the best fit for this exact question. It should definitely not be the top answer!\n\nI will go ahead and mention Mozilla’s proposed BrowserID (or perhaps more precisely, the Verified Email Protocol) in the spirit of finding an upgrade path to better approaches to authentication in the future.\n\nI’ll summarize it this way:\n\nMozilla is a nonprofit with values that align well with finding good solutions to this problem.\nThe reality today is that most websites use form-based authentication\nForm-based authentication has a big drawback, which is an increased risk of phishing. Users are asked to enter sensitive information into an area controlled by a remote entity, rather than an area controlled by their User Agent (browser).\nSince browsers are implicitly trusted (the whole idea of a User Agent is to act on behalf of the User), they can help improve this situation.\nThe primary force holding back progress here is deployment deadlock. Solutions must be decomposed into steps which provide some incremental benefit on their own.\nThe simplest decentralized method for expressing an identity that is built into the internet infrastructure is the domain name.\nAs a second level of expressing identity, each domain manages its own set of accounts.\nThe form “account@domain” is concise and supported by a wide range of protocols and URI schemes. Such an identifier is, of course, most universally recognized as an email address.\nEmail providers are already the de-facto primary identity providers online. Current password reset flows usually let you take control of an account if you can prove that you control that account’s associated email address.\nThe Verified Email Protocol was proposed to provide a secure method, based on public key cryptography, for streamlining the process of proving to domain B that you have an account on domain A.\nFor browsers that don’t support the Verified Email Protocol (currently all of them), Mozilla provides a shim which implements the protocol in client-side JavaScript code.\nFor email services that don’t support the Verified Email Protocol, the protocol allows third parties to act as a trusted intermediary, asserting that they’ve verified a user’s ownership of an account. It is not desirable to have a large number of such third parties; this capability is intended only to allow an upgrade path, and it is much preferred that email services provide these assertions themselves.\nMozilla offers their own service to act like such a trusted third party. Service Providers (that is, Relying Parties) implementing the Verified Email Protocol may choose to trust Mozilla's assertions or not. Mozilla’s service verifies users’ account ownership using the conventional means of sending an email with a confirmation link.\nService Providers may, of course, offer this protocol as an option in addition to any other method(s) of authentication they might wish to offer.\nA big user interface benefit being sought here is the “identity selector”. When a user visits a site and chooses to authenticate, their browser shows them a selection of email addresses (“personal”, “work”, “political activism”, etc.) they may use to identify themselves to the site.\nAnother big user interface benefit being sought as part of this effort is helping the browser know more about the user’s session – who they’re signed in as currently, primarily – so it may display that in the browser chrome.\nBecause of the distributed nature of this system, it avoids lock-in to major sites like Facebook, Twitter, Google, etc. Any individual can own their own domain and therefore act as their own identity provider.\n\nThis is not strictly “form-based authentication for websites”. But it is an effort to transition from the current norm of form-based authentication to something more secure: browser-supported authentication.\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '18 at 14:02\ncommunity wiki\n\n\n9 revs, 4 users 75%\nCharlie","comments":["BrowserID link is dead","The project seems to have been mothballed.... see en.wikipedia.org/wiki/Mozilla_Persona"]},{"answer":"I just thought I'd share this solution that I found to be working just fine.\n\nI call it the Dummy Field (though I haven't invented this so don't credit me).\n\nIn short: you just have to insert this into your <form> and check for it to be empty at when validating:\n\n<input type=\"text\" name=\"email\" style=\"display:none\" />\n\n\nThe trick is to fool a bot into thinking it has to insert data into a required field, that's why I named the input \"email\". If you already have a field called email that you're using you should try naming the dummy field something else like \"company\", \"phone\" or \"emailaddress\". Just pick something you know you don't need and what sounds like something people would normally find logical to fill in into a web form. Now hide the input field using CSS or JavaScript/jQuery - whatever fits you best - just don't set the input type to hidden or else the bot won't fall for it.\n\nOur form now looks like this:\n\nlabel[for=\"telephone\"], input[type=\"tel\"] {\n  visibility: visible; /* to fool others */\n  color:white;\n  width: 0;\n  height: 0;\n  position: absolute;\n  top: -50px;\n  left: -120px;\n}\n<h1>Log In</h1>\n<p>Can you see a field called 'telephone number'?</p>\n<form action=\"/\" method=\"post\">\n<label>username: <input type=\"text\" name=\"username\" /></label>\n<label>password: <input type=\"password\" name=\"password\" /></label>\n<!-- ta da. a label for it to seem even more realistic. aria-hidden=\"true\" so screen readers will not be fooled.-->\n<label for=\"telephone\" aria-hidden=\"true\">telephone number</label>\n<input type=\"tel\" name=\"telephone\" id=\"telephone\" title=\"enter your telephone number\" />\n<br />\n<input type=\"submit\" value=\"log in\" />\n</form>\n Run code snippetExpand snippet\n\nWhen you are validating the form (either client or server side) check if your dummy field has been filled to determine if it was sent by a human or a bot.\n\nYour processing:\n\n$fakefield = $_POST['telephone_number'];\nif (!$fakefield) {\n  // log in\n  // password_verify(...);\n  // ...\n} else {\n  echo 'no bots allowed';\n}\n\n\nExample:\n\nIn case of a human: The user will not see the dummy field (in my case named \"email\") and will not attempt to fill it. So the value of the dummy field should still be empty when the form has been sent.\n\nIn case of a bot: The bot will see a field whose type is text and a name email (or whatever it is you called it) and will logically attempt to fill it with appropriate data. It doesn't care if you styled the input form with some fancy CSS, web-developers do it all the time. Whatever the value in the dummy field is, we don't care as long as it's larger than 0 characters.\n\nI used this method on a guestbook in combination with CAPTCHA, and I haven't seen a single spam post since. I had used a CAPTCHA-only solution before, but eventually, it resulted in about five spam posts every hour. Adding the dummy field in the form has stopped (at least until now) all the spam from appearing.\n\nI believe this can also be used just fine with a login/authentication form.\n\nWarning: Of course this method is not 100% foolproof. Bots can be programmed to ignore input fields with the style display:none applied to it. You also have to think about people who use some form of auto-completion (like most browsers have built-in!) to auto-fill all form fields for them. They might just as well pick up a dummy field.\n\nYou can also vary this up a little by leaving the dummy field visible but outside the boundaries of the screen, but this is totally up to you.\n\nNote: Browser based autofill will not fill it in! The user cannot enter\n\nBe creative!\n\nShare\nImprove this answer\nFollow\nedited Jul 24 at 4:22\ncommunity wiki\n\n\n6 revs, 5 users 47%\nPieter888","comments":["This is a useful anti-spam trick, but I would suggest using a field name other than 'email', or you may find that browser auto-fill's fill it in, inadvertently blocking genuine users of your site.","I also have several more of these using visibility:hidden and also position:absolute;top:-9000px you can also do text-indent and also z-index on a few of these elements and place them in compressed CSS file names with awkward names - since bots can detect 1display:none` and they now check for a range of combinations - I actually use these methods and they're old tricks of the trade. +1","What happens when a user with a vision impairment is using a screenreader to navigate the form?","This technique has a name: the honeypot en.wikipedia.org/wiki/Honeypot_(computing)","No need for inline styling. Just add a class to the field (maybe use a weird word that could never mean anything to a bot), and hide it via the site's CSS file. Like: <input type=\"text\" name=\"email\" class=\"cucaracha\"> and in your CSS: .cucaracha { display:none; }."]},{"answer":"I do not think the above answer is \"wrong\" but there are large areas of authentication that are not touched upon (or rather the emphasis is on \"how to implement cookie sessions\", not on \"what options are available and what are the trade-offs\".\n\nMy suggested edits/answers are\n\nThe problem lies more in account setup than in password checking.\nThe use of two-factor authentication is much more secure than more clever means of password encryption\n\nDo NOT try to implement your own login form or database storage of passwords, unless the data being stored is valueless at account creation and self-generated (that is, web 2.0 style like Facebook, Flickr, etc.)\n\nDigest Authentication is a standards-based approach supported in all major browsers and servers, that will not send a password even over a secure channel.\n\nThis avoids any need to have \"sessions\" or cookies as the browser itself will re-encrypt the communication each time. It is the most \"lightweight\" development approach.\n\nHowever, I do not recommend this, except for public, low-value services. This is an issue with some of the other answers above - do not try an re-implement server-side authentication mechanisms - this problem has been solved and is supported by most major browsers. Do not use cookies. Do not store anything in your own hand-rolled database. Just ask, per request, if the request is authenticated. Everything else should be supported by configuration and third-party trusted software.\n\nSo ...\n\nFirst, we are confusing the initial creation of an account (with a password) with the re-checking of the password subsequently. If I am Flickr and creating your site for the first time, the new user has access to zero value (blank web space). I truly do not care if the person creating the account is lying about their name. If I am creating an account of the hospital intranet/extranet, the value lies in all the medical records, and so I do care about the identity (*) of the account creator.\n\nThis is the very very hard part. The only decent solution is a web of trust. For example, you join the hospital as a doctor. You create a web page hosted somewhere with your photo, your passport number, and a public key, and hash them all with the private key. You then visit the hospital and the system administrator looks at your passport, sees if the photo matches you, and then hashes the web page/photo hash with the hospital private key. From now on we can securely exchange keys and tokens. As can anyone who trusts the hospital (there is the secret sauce BTW). The system administrator can also give you an RSA dongle or other two-factor authentication.\n\nBut this is a lot of a hassle, and not very web 2.0. However, it is the only secure way to create new accounts that have access to valuable information that is not self-created.\n\nKerberos and SPNEGO - single sign-on mechanisms with a trusted third party - basically the user verifies against a trusted third party. (NB this is not in any way the not to be trusted OAuth)\n\nSRP - sort of clever password authentication without a trusted third party. But here we are getting into the realms of \"it's safer to use two-factor authentication, even if that's costlier\"\n\nSSL client side - give the clients a public key certificate (support in all major browsers - but raises questions over client machine security).\n\nIn the end, it's a tradeoff - what is the cost of a security breach vs the cost of implementing more secure approaches. One day, we may see a proper PKI widely accepted and so no more own rolled authentication forms and databases. One day...\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '18 at 14:04\ncommunity wiki\n\n\n5 revs, 4 users 67%\nyou cad sir - take that","comments":["Hard to tell which answer you are talking about in 'I do not think the above answer is \"wrong\"'"]},{"answer":"When hashing, don't use fast hash algorithms such as MD5 (many hardware implementations exist). Use something like SHA-512. For passwords, slower hashes are better.\n\nThe faster you can create hashes, the faster any brute force checker can work. Slower hashes will therefore slow down brute forcing. A slow hash algorithm will make brute forcing impractical for longer passwords (8 digits +)\n\nShare\nImprove this answer\nFollow\nedited Aug 4 '13 at 18:09\ncommunity wiki\n\n\n2 revs, 2 users 50%\njosh","comments":["SHA-512 is also fast, so you need thousands of iterations.","More like something like bcrypt which is designed to hash slowly.","As mentioned in another answer, \"OWASP recommends the use of Argon2 as your first choice for new applications. If this is not available, PBKDF2 or scrypt should be used instead. And finally if none of the above are available, use bcrypt.\" Neither MD5 nor any of the SHA hashing functions should ever be used for hashing passwords. This answer is bad advice."]},{"answer":"My favourite rule in regards to authentication systems: use passphrases, not passwords. Easy to remember, hard to crack.\n\nSuch as:\n\nvar inputs = document.querySelectorAll('input:not([value=\"\"])');\nfor (var $i = 0; $i < inputs.length; $i++) {\n  inputs[$i].setAttribute('onkeydown', 'function space(e){if(\"Space\"==e.code){e.preventDefault();document.getElementById(\"pass'+($i+1)+'\").focus();}if(\"Backspace\"==e.code){e.preventDefault();document.getElementById(\"pass'+($i - 1)+'\").focus();}} space(event);');\n}\n<h1>Sign Up for An Account</h1>\n<label for=\"username\">Type username: <input type=\"text\" id=\"username\" /></label><br />\n<label for=\"passphrase\">Type passphrase:</label>\n<input type=\"text\" id=\"pass1\" placeholder=\"The\" />\n<input type=\"text\" id=\"pass2\" placeholder=\"quick\" />\n<input type=\"text\" id=\"pass3\" placeholder=\"brown\" />\n<input type=\"text\" id=\"pass4\" placeholder=\"fox\" />\n<input type=\"text\" id=\"pass5\" placeholder=\"jumped\" />\n<input type=\"text\" id=\"pass6\" placeholder=\"over\" />\n<input type=\"text\" id=\"pass7\" placeholder=\"the\" />\n<input type=\"text\" id=\"pass8\" placeholder=\"lazy\" />\n<input type=\"text\" id=\"pass9\" placeholder=\"dog\" />\n Run code snippetExpand snippet\n\nMore info: Coding Horror: Passwords vs. Pass Phrases\n\nShare\nImprove this answer\nFollow\nedited Jul 22 at 3:14\ncommunity wiki\n\n\n4 revs, 4 users 76%\nSomeone_who_likes_SE","comments":["even better - hard to remember, hard to guess: Password managers ... linking to article from 2005 where that likely meant an excel spreadsheet :)"]},{"answer":"I'd like to add one suggestion I've used, based on defense in depth. You don't need to have the same auth&auth system for admins as regular users. You can have a separate login form on a separate url executing separate code for requests that will grant high privileges. This one can make choices that would be a total pain to regular users. One such that I've used is to actually scramble the login URL for admin access and email the admin the new URL. Stops any brute force attack right away as your new URL can be arbitrarily difficult (very long random string) but your admin user's only inconvenience is following a link in their email. The attacker no longer knows where to even POST to.\n\nShare\nImprove this answer\nFollow\nanswered Jul 18 '15 at 1:18\ncommunity wiki\n\n\nIain Duncan","comments":["A simple link in an email isn't actually secure, since email is not secure.","It is as secure as any other token based password reset system that is not two-factor though. Which is almost all of them."]},{"answer":"I dont't know whether it was best to answer this as an answer or as a comment. I opted for the first option.\n\nRegarding the poing PART IV: Forgotten Password Functionality in the first answer, I would make a point about Timing Attacks.\n\nIn the Remember your password forms, an attacker could potentially check a full list of emails and detect which are registered to the system (see link below).\n\nRegarding the Forgotten Password Form, I would add that it is a good idea to equal times between successful and unsucessful queries with some delay function.\n\nhttps://crypto.stanford.edu/~dabo/papers/webtiming.pdf\n\nShare\nImprove this answer\nFollow\nanswered Aug 16 '15 at 17:31\ncommunity wiki\n\n\nuser9869932","comments":[]},{"answer":"I would like to add one very important comment: -\n\n\"In a corporate, intra- net setting,\" most if not all of the foregoing might not apply!\n\nMany corporations deploy \"internal use only\" websites which are, effectively, \"corporate applications\" that happen to have been implemented through URLs. These URLs can (supposedly ...) only be resolved within \"the company's internal network.\" (Which network magically includes all VPN-connected 'road warriors.')\n\nWhen a user is dutifully-connected to the aforesaid network, their identity (\"authentication\") is [already ...] \"conclusively known,\" as is their permission (\"authorization\") to do certain things ... such as ... \"to access this website.\"\n\nThis \"authentication + authorization\" service can be provided by several different technologies, such as LDAP (Microsoft OpenDirectory), or Kerberos.\n\nFrom your point-of-view, you simply know this: that anyone who legitimately winds-up at your website must be accompanied by [an environment-variable magically containing ...] a \"token.\" (i.e. The absence of such a token must be immediate grounds for 404 Not Found.)\n\nThe token's value makes no sense to you, but, should the need arise, \"appropriate means exist\" by which your website can \"[authoritatively] ask someone who knows (LDAP... etc.)\" about any and every(!) question that you may have. In other words, you do not avail yourself of any \"home-grown logic.\" Instead, you inquire of The Authority and implicitly trust its verdict.\n\nUh huh ... it's quite a mental-switch from the \"wild-and-wooly Internet.\"\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '18 at 14:05\ncommunity wiki\n\n\n3 revs, 3 users 90%\nMike Robinson","comments":["Did you fell in the punctuation well as a child? :) I've read it three times and I am still lost at what point you are trying to make. But if you are saying \"Sometimes you do not need form based authentication\" then you are right. But considering we are discussing when we do need it, I dont see why this is very important to note?","My point is that the world outside a corporation is entirely different from the world inside. If you are building an app that is accessible to the \"wooly wide web,\" and for general consumption by the public, then you have no choice but to roll your own authentication and authorization methods. But, inside a corporation, where the only way to get there is to be there or to use VPN, then it is very likely that the application will not have – must not have – \"its own\" methods for doing these things. The app must use these methods instead, to provide consistent, centralized management.","Even intranets require a minimum amount of security in the building. Sales has confidential profit and loss numbers, while engineering has confidential intellectual property. Many companies restrict data across departmental or divisional lines."]},{"answer":"Use OpenID Connect or User-Managed Access.\n\nAs nothing is more efficient than not doing it at all.\n\nShare\nImprove this answer\nFollow\nanswered Aug 10 '16 at 13:27\ncommunity wiki\n\n\njwilleke","comments":[]}]},{"id":"59895","href":"https://stackoverflow.com/questions/59895/how-can-i-get-the-source-directory-of-a-bash-script-from-within-the-script-itsel","title":"How can I get the source directory of a Bash script from within the script itself?","description":"\n                \nHow do I get the path of the directory in which a Bash script is located, inside that script?\nI want to use a Bash script as a launcher for another application. I want to change the working directory to the one where the Bash script is located, so I can operate on the files in that directory, like so:\n$ ./application\n\n    ","questionComments":["None of the current solutions work if there are any newlines at the end of the directory name - They will be stripped by the command substitution. To work around this you can append a non-newline character inside the command substitution - DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd && echo x)\" - and remove it without a command substitution - DIR=\"${DIR%x}\".","@jpmc26 There are two very common situations: Accidents and sabotage. A script shouldn't fail in unpredictable ways just because someone, somewhere, did a mkdir $'\\n'.","anyone who lets people sabotage their system in that way shouldn't leave it up to bash to detect such problems... much less hire people capable of making that kind of mistake. I have never had, in the 25 years of using bash, seen this kind of thing happen anywhere.... this is why we have things like perl and practices such as taint checking (i will probably be flamed for saying that :)","@l0b0 Consider that you'd need the same protection on dirname, and that the directory could start with a - (e.g. --help). DIR=$(reldir=$(dirname -- \"$0\"; echo x); reldir=${reldir%?x}; cd -- \"$reldir\" && pwd && echo x); DIR=${DIR%?x}. Perhaps this is overkill?","I stronly suggest to read this Bash FAQ about the subject."],"answers":[{"answer":"#!/usr/bin/env bash\n\nSCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\"\n\n\nis a useful one-liner which will give you the full directory name of the script no matter where it is being called from.\n\nIt will work as long as the last component of the path used to find the script is not a symlink (directory links are OK). If you also want to resolve any links to the script itself, you need a multi-line solution:\n\n#!/usr/bin/env bash\n\nSOURCE=\"${BASH_SOURCE[0]}\"\nwhile [ -h \"$SOURCE\" ]; do # resolve $SOURCE until the file is no longer a symlink\n  DIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" >/dev/null 2>&1 && pwd )\"\n  SOURCE=\"$(readlink \"$SOURCE\")\"\n  [[ $SOURCE != /* ]] && SOURCE=\"$DIR/$SOURCE\" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located\ndone\nDIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" >/dev/null 2>&1 && pwd )\"\n\n\nThis last one will work with any combination of aliases, source, bash -c, symlinks, etc.\n\nBeware: if you cd to a different directory before running this snippet, the result may be incorrect!\n\nAlso, watch out for $CDPATH gotchas, and stderr output side effects if the user has smartly overridden cd to redirect output to stderr instead (including escape sequences, such as when calling update_terminal_cwd >&2 on Mac). Adding >/dev/null 2>&1 at the end of your cd command will take care of both possibilities.\n\nTo understand how it works, try running this more verbose form:\n\n#!/usr/bin/env bash\n\nSOURCE=\"${BASH_SOURCE[0]}\"\nwhile [ -h \"$SOURCE\" ]; do # resolve $SOURCE until the file is no longer a symlink\n  TARGET=\"$(readlink \"$SOURCE\")\"\n  if [[ $TARGET == /* ]]; then\n    echo \"SOURCE '$SOURCE' is an absolute symlink to '$TARGET'\"\n    SOURCE=\"$TARGET\"\n  else\n    DIR=\"$( dirname \"$SOURCE\" )\"\n    echo \"SOURCE '$SOURCE' is a relative symlink to '$TARGET' (relative to '$DIR')\"\n    SOURCE=\"$DIR/$TARGET\" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located\n  fi\ndone\necho \"SOURCE is '$SOURCE'\"\nRDIR=\"$( dirname \"$SOURCE\" )\"\nDIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" >/dev/null 2>&1 && pwd )\"\nif [ \"$DIR\" != \"$RDIR\" ]; then\n  echo \"DIR '$RDIR' resolves to '$DIR'\"\nfi\necho \"DIR is '$DIR'\"\n\n\nAnd it will print something like:\n\nSOURCE './scriptdir.sh' is a relative symlink to 'sym2/scriptdir.sh' (relative to '.')\nSOURCE is './sym2/scriptdir.sh'\nDIR './sym2' resolves to '/home/ubuntu/dotfiles/fo fo/real/real1/real2'\nDIR is '/home/ubuntu/dotfiles/fo fo/real/real1/real2'\n\nShare\nImprove this answer\nFollow\nedited Aug 4 at 12:37\ncommunity wiki\n\n\n28 revs, 22 users 32%\nDave Dopson","comments":["You can fuse this approach with the answer by user25866 to arrive at a solution that works with source <script> and bash <script>: DIR=\"$(cd -P \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\".","Sometimes cd prints something to STDOUT! E.g., if your $CDPATH has .. To cover this case, use DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" > /dev/null && pwd )\"","This accepted answer is not ok, it doesn't work with symlinks and is overly complex. dirname $(readlink -f $0) is the right command. See gist.github.com/tvlooy/cbfbdb111a4ebad8b93e for a testcase","@tvlooy IMO your answer isn't exactly OK as-is either, because it fails when there is a space in the path. In contrast to a newline character, this isn't unlikely or even uncommon. dirname \"$(readlink -f \"$0\")\" doesn't add complexity and is fair measure more robust for the minimal amount of trouble.","@tvlooy your comment is not macOS (or probably BSD in general) compatible, while the accepted answer is. readlink -f $0 gives readlink: illegal option -- f."]},{"answer":"Use dirname \"$0\":\n\n#!/bin/bash\necho \"The script you are running has basename `basename \"$0\"`, dirname `dirname \"$0\"`\"\necho \"The present working directory is `pwd`\"\n\n\nUsing pwd alone will not work if you are not running the script from the directory it is contained in.\n\n[matt@server1 ~]$ pwd\n/home/matt\n[matt@server1 ~]$ ./test2.sh\nThe script you are running has basename test2.sh, dirname .\nThe present working directory is /home/matt\n[matt@server1 ~]$ cd /tmp\n[matt@server1 tmp]$ ~/test2.sh\nThe script you are running has basename test2.sh, dirname /home/matt\nThe present working directory is /tmp\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 2:08\ncommunity wiki\n\n\n5 revs, 5 users 72%\nmatt b","comments":["For portability beyond bash, $0 may not always be enough. You may need to substitute \"type -p $0\" to make this work if the command was found on the path.","@Darron: you can only use type -p if the script is executable. This can also open a subtle hole if the script is executed using bash test2.sh and there is another script with the same name executable somewhere else.","@Darron: but since the question is tagged bash and the hash-bang line explicitly mentions /bin/bash I'd say it's pretty safe to depend on bashisms.","+1, but the problem with using dirname $0 is that if the directory is the current directory, you'll get .. That's fine unless you're going to change directories in the script and expect to use the path you got from dirname $0 as though it were absolute. To get the absolute path: pushd `dirname $0` > /dev/null, SCRIPTPATH=`pwd`, popd > /dev/null: pastie.org/1489386 (But surely there's a better way to expand that path?)","@T.J. Crowder I'm not sure sure dirname $0 is a problem if you assign it to a variable and then use it to launch a script like $dir/script.sh; I would imagine this is the use case for this type of thing 90% of the time. ./script.sh would work fine."]},{"answer":"The dirname command is the most basic, simply parsing the path up to the filename off of the $0 (script name) variable:\n\ndirname \"$0\"\n\n\nBut, as matt b pointed out, the path returned is different depending on how the script is called. pwd doesn't do the job because that only tells you what the current directory is, not what directory the script resides in. Additionally, if a symbolic link to a script is executed, you're going to get a (probably relative) path to where the link resides, not the actual script.\n\nSome others have mentioned the readlink command, but at its simplest, you can use:\n\ndirname \"$(readlink -f \"$0\")\"\n\n\nreadlink will resolve the script path to an absolute path from the root of the filesystem. So, any paths containing single or double dots, tildes and/or symbolic links will be resolved to a full path.\n\nHere's a script demonstrating each of these, whatdir.sh:\n\n#!/bin/bash\necho \"pwd: `pwd`\"\necho \"\\$0: $0\"\necho \"basename: `basename $0`\"\necho \"dirname: `dirname $0`\"\necho \"dirname/readlink: $(dirname $(readlink -f $0))\"\n\n\nRunning this script in my home dir, using a relative path:\n\n>>>$ ./whatdir.sh\npwd: /Users/phatblat\n$0: ./whatdir.sh\nbasename: whatdir.sh\ndirname: .\ndirname/readlink: /Users/phatblat\n\n\nAgain, but using the full path to the script:\n\n>>>$ /Users/phatblat/whatdir.sh\npwd: /Users/phatblat\n$0: /Users/phatblat/whatdir.sh\nbasename: whatdir.sh\ndirname: /Users/phatblat\ndirname/readlink: /Users/phatblat\n\n\nNow changing directories:\n\n>>>$ cd /tmp\n>>>$ ~/whatdir.sh\npwd: /tmp\n$0: /Users/phatblat/whatdir.sh\nbasename: whatdir.sh\ndirname: /Users/phatblat\ndirname/readlink: /Users/phatblat\n\n\nAnd finally using a symbolic link to execute the script:\n\n>>>$ ln -s ~/whatdir.sh whatdirlink.sh\n>>>$ ./whatdirlink.sh\npwd: /tmp\n$0: ./whatdirlink.sh\nbasename: whatdirlink.sh\ndirname: .\ndirname/readlink: /Users/phatblat\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 3:36\ncommunity wiki\n\n\n7 revs, 6 users 81%\nphatblat","comments":["readlink will not availabe in some platform in default installation. Try to avoid using it if you can","be careful to quote everything to avoid whitespace issues: export SCRIPT_DIR=\"$(dirname \"$(readlink -f \"$0\")\")\"","In OSX Yosemite 10.10.1 -f is not recognised as an option to readlink. Using stat -f instead does the job. Thanks","In OSX, there is greadlink, which is basically the readlink we are all familiar. Here is a platform independent version: dir=`greadlink -f ${BASH_SOURCE[0]} || readlink -f ${BASH_SOURCE[0]}`","Good call, @robert. FYI, greadlink can easily be installed through homebrew: brew install coreutils"]},{"answer":"pushd . > /dev/null\nSCRIPT_PATH=\"${BASH_SOURCE[0]}\"\nif ([ -h \"${SCRIPT_PATH}\" ]); then\n  while([ -h \"${SCRIPT_PATH}\" ]); do cd `dirname \"$SCRIPT_PATH\"`;\n  SCRIPT_PATH=`readlink \"${SCRIPT_PATH}\"`; done\nfi\ncd `dirname ${SCRIPT_PATH}` > /dev/null\nSCRIPT_PATH=`pwd`;\npopd  > /dev/null\n\n\nIt works for all versions, including\n\nwhen called via multiple depth soft link,\nwhen the file it\nwhen script called by command \"source\" aka . (dot) operator.\nwhen arg $0 is modified from caller.\n\"./script\"\n\"/full/path/to/script\"\n\"/some/path/../../another/path/script\"\n\"./some/folder/script\"\n\nAlternatively, if the Bash script itself is a relative symlink you want to follow it and return the full path of the linked-to script:\n\npushd . > /dev/null\nSCRIPT_PATH=\"${BASH_SOURCE[0]}\";\nif ([ -h \"${SCRIPT_PATH}\" ]) then\n  while([ -h \"${SCRIPT_PATH}\" ]) do cd `dirname \"$SCRIPT_PATH\"`; SCRIPT_PATH=`readlink \"${SCRIPT_PATH}\"`; done\nfi\ncd `dirname ${SCRIPT_PATH}` > /dev/null\nSCRIPT_PATH=`pwd`;\npopd  > /dev/null\n\n\nSCRIPT_PATH is given in full path, no matter how it is called.\n\nJust make sure you locate this at start of the script.\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 2:27\ncommunity wiki\n\n\n10 revs, 8 users 47%\nuser25866","comments":["Nice! Could be made shorter replacing \"pushd[...] popd /dev/null\" by SCRIPT_PATH=readlink -f $(dirname \"${VIRTUAL_ENV}\");","And instead of using pushd ...; would not it be better to use $(cd dirname \"${SCRIPT_PATH}\" && pwd)? But anyway great script!","It's dangerous for a script to cd out of its current directory in the hope of cding back again later: The script may not have permission to change directory back to the directory that was current when it was invoked. (Same goes for pushd/popd)","readlink -f is GNU-specific. BSD readlink does not have that option.","What's with all the unnecessary subshells? ([ ... ]) is less efficient than [ ... ], and there's no advantage taken of the isolation offered in return for that performance hit here."]},{"answer":"Short answer:\n\n`dirname $0`\n\n\nor (preferably):\n\n$(dirname \"$0\")\n\nShare\nImprove this answer\nFollow\nedited Apr 19 '17 at 6:59\ncommunity wiki\n\n\n7 revs, 7 users 37%\nFabien","comments":["It won't work if you source the script. \"source my/script.sh\"","I use this all the time in my bash scripts that automate stuff and often invoke other scripts in the same dir. I'd never use source on these and cd $(dirname $0) is easy to remember.","@vidstige: ${BASH_SOURCE[0]} instead of $0 will work with source my/script.sh","@TimothyJones that will fail 100% of the time if sourced from any other shell than bash. ${BASH_SOURCE[0]} is not satisfactory at all. ${BASH_SOURCE:-0} is much better."]},{"answer":"You can use $BASH_SOURCE:\n\n#!/bin/bash\n\nscriptdir=`dirname \"$BASH_SOURCE\"`\n\n\nNote that you need to use #!/bin/bash and not #!/bin/sh since it's a Bash extension.\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '20 at 18:33\ncommunity wiki\n\n\n3 revs, 2 users 87%\nMr Shark","comments":["When I do ./foo/script, then $(dirname $BASH_SOURCE) is ./foo.","@Till, In this case we can use realpath command to get full path of ./foo/script. So dirname $(realpath ./foo/script)  will give the path of script."]},{"answer":"This should do it:\n\nDIR=\"$(dirname \"$(readlink -f \"$0\")\")\"\n\n\nThis works with symlinks and spaces in path.\n\nSee the man pages for dirname and readlink.\n\nFrom the comment track it seems not to work with Mac OS. I have no idea why that is. Any suggestions?\n\nShare\nImprove this answer\nFollow\nedited Mar 19 '20 at 20:15\ncommunity wiki\n\n\n9 revs, 3 users 85%\nSimon Rigét","comments":["with your solution, invoking the script like ./script.sh shows . instead of the full directory path","There's no -f option for readlink on MacOS. Use stat instead. But still, it shows . if you are in 'this' dir.","You need to install coreutils from Homebrew and use greadlink to get the -f option on MacOS because it is *BSD under the covers and not Linux.","You should add double quotes surrounding all the right hand side: DIR=\"$(dirname \"$(readlink -f \"$0\")\")\""]},{"answer":"Here is an easy-to-remember script:\n\nDIR=\"$(dirname \"${BASH_SOURCE[0]}\")\"  # Get the directory name\nDIR=\"$(realpath \"${DIR}\")\"    # Resolve its full path if need be\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 4:54\ncommunity wiki\n\n\n3 revs, 3 users 67%\nThamme Gowda","comments":["Or, more obscurely, on one line: DIR=$(realpath \"$(dirname \"${BASH_SOURCE[0]}\")\")","Why isn't this the accepted answer? Is there any difference using realpath from resolving \"manually\" with a loop of readlink? Even the readlink man page says Note realpath(1) is the preferred command to use for canonicalization functionality.","And by the way shouldn't we apply realpath before dirname, not after? If the script file itself is a symlink... It would give something like DIR=\"$(dirname \"$(realpath \"${BASH_SOURCE[0]}\")\")\". Actually very close to the answer proposed by Simon.","@User9123 I think the accept one is try to be compatible with all popular shell/distro. More over, depending on what you are trying to do, in most cases people want to obtain the directory where the symlink located instead of the directory of the actual source.","The only reason is missing coreutils on mac. I am using SCRIPT=$(realpath \"${BASH_SOURCE[0]}\") + DIR=$(dirname \"$SCRIPT\")."]},{"answer":"pwd can be used to find the current working directory, and dirname to find the directory of a particular file (command that was run, is $0, so dirname $0 should give you the directory of the current script).\n\nHowever, dirname gives precisely the directory portion of the filename, which more likely than not is going to be relative to the current working directory. If your script needs to change directory for some reason, then the output from dirname becomes meaningless.\n\nI suggest the following:\n\n#!/bin/bash\n\nreldir=`dirname $0`\ncd $reldir\ndirectory=`pwd`\n\necho \"Directory is $directory\"\n\n\nThis way, you get an absolute, rather than a relative directory.\n\nSince the script will be run in a separate Bash instance, there isn't any need to restore the working directory afterwards, but if you do want to change back in your script for some reason, you can easily assign the value of pwd to a variable before you change directory, for future use.\n\nAlthough just\n\ncd `dirname $0`\n\n\nsolves the specific scenario in the question, I find having the absolute path to more more useful generally.\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 2:15\ncommunity wiki\n\n\n4 revs, 3 users 87%\nSpoonMeiser","comments":["You can do it all in one line like this: DIRECTORY=$(cd dirname $0 && pwd)","This doesn't work if the script sources another script and you want to know the name of the latter."]},{"answer":"I don't think this is as easy as others have made it out to be. pwd doesn't work, as the current directory is not necessarily the directory with the script. $0 doesn't always have the information either. Consider the following three ways to invoke a script:\n\n./script\n\n/usr/bin/script\n\nscript\n\n\nIn the first and third ways $0 doesn't have the full path information. In the second and third, pwd does not work. The only way to get the directory in the third way would be to run through the path and find the file with the correct match. Basically the code would have to redo what the OS does.\n\nOne way to do what you are asking would be to just hardcode the data in the /usr/share directory, and reference it by its full path. Data shoudn't be in the /usr/bin directory anyway, so this is probably the thing to do.\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '20 at 18:36\ncommunity wiki\n\n\n3 revs, 3 users 73%\nJim","comments":["If you intend to disprove his comment, PROVE that a script CAN access where it's stored with a code example."]},{"answer":"SCRIPT_DIR=$( cd ${0%/*} && pwd -P )\n\nShare\nImprove this answer\nFollow\nedited May 30 '13 at 11:28\ncommunity wiki\n\n\n2 revs, 2 users 67%\nP M","comments":["This is way shorter than the chosen answer. And appears to work just as well. This deserves 1000 votes just so people do not overlook it.","As many of the previous answers explain in detail, neither $0 nor pwd are guaranteed to have the right information, depending on how the script is invoked."]},{"answer":"$(dirname \"$(readlink -f \"$BASH_SOURCE\")\")\n\nShare\nImprove this answer\nFollow\nedited May 13 '18 at 4:36\ncommunity wiki\n\n\n3 revs, 3 users 55%\ntest11","comments":["I prefer, $BASH_SOURCE over $0 , because it's explicit even for readers not well-versed in bash. $(dirname -- \"$(readlink -f -- \"$BASH_SOURCE\")\")"]},{"answer":"This gets the current working directory on Mac OS X v10.6.6 (Snow Leopard):\n\nDIR=$(cd \"$(dirname \"$0\")\"; pwd)\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 3:43\ncommunity wiki\n\n\n3 revs, 3 users 73%\nPubguy","comments":[]},{"answer":"This is Linux specific, but you could use:\n\nSELF=$(readlink /proc/$$/fd/255)\n\nShare\nImprove this answer\nFollow\nedited Dec 22 '13 at 0:07\ncommunity wiki\n\n\n3 revs, 3 users 75%\nSteve Baker","comments":["It's also bash specific, but perhaps bash's behavior has changed? /proc/fd/$$/255 seems to point to the tty, not to a directory. For example, in my current login shell, file descriptors 0, 1, 2, and 255 all refer to /dev/pts/4. In any case, the bash manual doesn't mention fd 255, so it's probably unwise to depend on this behavior.\\","Interactive shell != script. Anyway realpath ${BASH_SOURCE[0]}; would seem to be the best way to go."]},{"answer":"Here is a POSIX compliant one-liner:\n\nSCRIPT_PATH=`dirname \"$0\"`; SCRIPT_PATH=`eval \"cd \\\"$SCRIPT_PATH\\\" && pwd\"`\n\n# test\necho $SCRIPT_PATH\n\nShare\nImprove this answer\nFollow\nedited Apr 15 '13 at 7:28\ncommunity wiki\n\n\n2 revs, 2 users 91%\nlamawithonel","comments":["I had success with this when running a script by itself or by using sudo, but not when calling source ./script.sh","And it fails when cd is configured to print the new path name."]},{"answer":"The shortest and most elegant way to do this is:\n\n#!/bin/bash\nDIRECTORY=$(cd `dirname $0` && pwd)\necho $DIRECTORY\n\n\nThis would work on all platforms and is super clean.\n\nMore details can be found in \"Which directory is that bash script in?\".\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '20 at 18:41\ncommunity wiki\n\n\n2 revs, 2 users 83%\nAtul","comments":["great clean solution, but this will not work if the file is symlinked."]},{"answer":"Here is the simple, correct way:\n\nactual_path=$(readlink -f \"${BASH_SOURCE[0]}\")\nscript_dir=$(dirname \"$actual_path\")\n\n\nExplanation:\n\n${BASH_SOURCE[0]} - the full path to the script. The value of this will be correct even when the script is being sourced, e.g. source <(echo 'echo $0') prints bash, while replacing it with ${BASH_SOURCE[0]} will print the full path of the script. (Of course, this assumes you're OK taking a dependency on Bash.)\n\nreadlink -f - Recursively resolves any symlinks in the specified path. This is a GNU extension, and not available on (for example) BSD systems. If you're running a Mac, you can use Homebrew to install GNU coreutils and supplant this with greadlink -f.\n\nAnd of course dirname gets the parent directory of the path.\n\nShare\nImprove this answer\nFollow\nedited Feb 20 '16 at 7:53\ncommunity wiki\n\n\n2 revs\nJames Ko","comments":["greadlink -f unfortunately doesn't work effectively when sourceing the script on Mac :("]},{"answer":"I tried all of these and none worked. One was very close, but it had a tiny bug that broke it badly; they forgot to wrap the path in quotation marks.\n\nAlso a lot of people assume you're running the script from a shell, so they forget when you open a new script it defaults to your home.\n\nTry this directory on for size:\n\n/var/No one/Thought/About Spaces Being/In a Directory/Name/And Here's your file.text\n\n\nThis gets it right regardless how or where you run it:\n\n#!/bin/bash\necho \"pwd: `pwd`\"\necho \"\\$0: $0\"\necho \"basename: `basename \"$0\"`\"\necho \"dirname: `dirname \"$0\"`\"\n\n\nSo to make it actually useful, here's how to change to the directory of the running script:\n\ncd \"`dirname \"$0\"`\"\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 3:39\ncommunity wiki\n\n\n6 revs, 3 users 73%\nMike Bethany","comments":["Doesn't work if the script is being sourced from another script.","This does not work if the last part of $0 is a symbolic link pointing to an entry of another directory (ln -s ../bin64/foo /usr/bin/foo)."]},{"answer":"#!/bin/sh\nPRG=\"$0\"\n\n# need this for relative symlinks\nwhile [ -h \"$PRG\" ] ; do\n   PRG=`readlink \"$PRG\"`\ndone\n\nscriptdir=`dirname \"$PRG\"`\n\nShare\nImprove this answer\nFollow\nanswered Sep 13 '08 at 1:28\ncommunity wiki\n\n\nMonkeyboy","comments":["I haven't tested it across different systems. But this solution is the one that works right away at least on Ubuntu, for me!"]},{"answer":"This is a slight revision to the solution e-satis and 3bcdnlklvc04a pointed out in their answer:\n\nSCRIPT_DIR=''\npushd \"$(dirname \"$(readlink -f \"$BASH_SOURCE\")\")\" > /dev/null && {\n    SCRIPT_DIR=\"$PWD\"\n    popd > /dev/null\n}\n\n\nThis should still work in all the cases they listed.\n\nThis will prevent popd after a failed pushd. Thanks to konsolebox.\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 3:38\ncommunity wiki\n\n\n5 revs, 4 users 75%\nFuwjax","comments":["This works perfectly to get the \"real\" dirname, rather than just the name of a symlink. Thank you!","Better SCRIPT_DIR=''; pushd \"$(dirname \"$(readlink -f \"$BASH_SOURCE\")\")\" > /dev/null && { SCRIPT_DIR=$PWD; popd > /dev/null; }","@konsolebox, what are you trying to defend against? I'm generally a fan of inlining logical conditionals, but what was the specific error that you were seeing in the pushd? I'd match rather find a way to handle it directly instead of returning an empty SCRIPT_DIR.","@Fuwjax Natural practice to avoid doing popd in cases (even when rare) where pushd fails. And in case pushd fails, what do you think should be the value of SCRIPT_DIR? The action may vary depending on what may seem logical or what one user could prefer but certainly, doing popd is wrong.","All those pushd popd dangers could be avoided simply by dropping them and using cd + pwd enclosed in a command substitution instead. SCRIPT_DIR=$(...)"]},{"answer":"I would use something like this:\n\n# Retrieve the full pathname of the called script\nscriptPath=$(which $0)\n\n# Check whether the path is a link or not\nif [ -L $scriptPath ]; then\n\n    # It is a link then retrieve the target path and get the directory name\n    sourceDir=$(dirname $(readlink -f $scriptPath))\n\nelse\n\n    # Otherwise just get the directory name of the script path\n    sourceDir=$(dirname $scriptPath)\n\nfi\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 4:10\ncommunity wiki\n\n\n2 revs, 2 users 82%\nNicolas","comments":["This is the real one! Works with simple sh too! Problem with simple dirname \"$0\" based solutions: If the script is in the $PATH and is invoked without path, they will give wrong result.","@Notinlist Not so. If the script is found via the PATH, $0 will contain the absolute filename. If the script is invoked with a relative or absolute filename containing a /, $0 will contain that."]},{"answer":"For systems having GNU coreutils readlink (for example, Linux):\n\n$(readlink -f \"$(dirname \"$0\")\")\n\n\nThere's no need to use BASH_SOURCE when $0 contains the script filename.\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 4:39\ncommunity wiki\n\n\n4 revs, 3 users 64%\nuser1338062","comments":["unless the script was sourced with . or 'source' in which case it will still be whatever script sourced it, or, if from the command line, '-bash' (tty login) or 'bash' (invoked via 'bash -l') or '/bin/bash' (invoked as an interactive non-login shell)","I added second pair of quotes around dirname call. Needed if the directory path contains spaces."]},{"answer":"$_ is worth mentioning as an alternative to $0. If you're running a script from Bash, the accepted answer can be shortened to:\n\nDIR=\"$( dirname \"$_\" )\"\n\n\nNote that this has to be the first statement in your script.\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '20 at 18:45\ncommunity wiki\n\n\n2 revs, 2 users 86%\nhurrymaplelad","comments":["It breaks if you source or . the script. In those situations, $_ would contain the last parameter of the last command you ran before the .. $BASH_SOURCE works every time.","This is Perl-like! A coincidence?"]},{"answer":"These are short ways to get script information:\n\nFolders and files:\n\n    Script: \"/tmp/src dir/test.sh\"\n    Calling folder: \"/tmp/src dir/other\"\n\n\nUsing these commands:\n\n    echo Script-Dir : `dirname \"$(realpath $0)\"`\n    echo Script-Dir : $( cd ${0%/*} && pwd -P )\n    echo Script-Dir : $(dirname \"$(readlink -f \"$0\")\")\n    echo\n    echo Script-Name : `basename \"$(realpath $0)\"`\n    echo Script-Name : `basename $0`\n    echo\n    echo Script-Dir-Relative : `dirname \"$BASH_SOURCE\"`\n    echo Script-Dir-Relative : `dirname $0`\n    echo\n    echo Calling-Dir : `pwd`\n\n\nAnd I got this output:\n\n     Script-Dir : /tmp/src dir\n     Script-Dir : /tmp/src dir\n     Script-Dir : /tmp/src dir\n\n     Script-Name : test.sh\n     Script-Name : test.sh\n\n     Script-Dir-Relative : ..\n     Script-Dir-Relative : ..\n\n     Calling-Dir : /tmp/src dir/other\n\n\nAlso see: https://pastebin.com/J8KjxrPF\n\nShare\nImprove this answer\nFollow\nedited May 15 '20 at 0:32\ncommunity wiki\n\n\n3 revs, 2 users 89%\nUser8461","comments":["\"Are answers which merely summarize other answers acceptable?\"","I think my answer is ok because it is hard to find a simple working edition. Here you can take the code you like e.g. cd + pwd, dirname + realpath or dirname + readlink. I am not sure that all parts exist before and most answers are complex and overloaded. Here you can pike out the code you like to use. At least please do not remove it as I need in the future :D"]},{"answer":"This works in Bash 3.2:\n\npath=\"$( dirname \"$( which \"$0\" )\" )\"\n\n\nIf you have a ~/bin directory in your $PATH, you have A inside this directory. It sources the script ~/bin/lib/B. You know where the included script is relative to the original one, in the lib subdirectory, but not where it is relative to the user's current directory.\n\nThis is solved by the following (inside A):\n\nsource \"$( dirname \"$( which \"$0\" )\" )/lib/B\"\n\n\nIt doesn't matter where the user is or how he/she calls the script. This will always work.\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 2:43\ncommunity wiki\n\n\n7 revs, 4 users 73%\nMatt Tardiff","comments":["The point on which is very debatable. type, hash, and other builtins do the same thing better in bash. which is kindof more portable, though it really isn't the same which used in other shells like tcsh, that has it as a builtin.","\"Always\"? Not at all. which being an external tool, you have no reason to believe it behaves identically to the parent shell."]},{"answer":"Try using:\n\nreal=$(realpath $(dirname $0))\n\nShare\nImprove this answer\nFollow\nedited Feb 6 '12 at 11:20\ncommunity wiki\n\n\n2 revs, 2 users 60%\neeerahul","comments":["All I want to know is, why this way is not good? It seemed no bad and correct for me. Could anyone explain why it's downvoted?","realpath is not a standard utility.","On Linux, realpath is a standard utility (part of the GNU coreutils package), but it is not a bash built-in (i.e., a function provided by bash itself). If you're running Linux, this method will probably work, although I'd substitute the $0 for ${BASH_SOURCE[0]} so that this method will work anywhere, including in a function.","The order of the operations in this answer is wrong. You need to first resolve the symlink, then do dirname because the last part of $0 may be a symlink that points to a file that is not in the same directory as the symlink itself. The solution described in this answer just gets the path of the directory where the symlink it stored, not the directory of the target. Furthermore, this solution is missing quoting. It will not work if the path contains special characters.","dir=\"$(realpath \"$(dirname \"${BASH_SOURCE[0]}\")\")\""]},{"answer":"I've compared many of the answers given, and came up with some more compact solutions. These seem to handle all of the crazy edge cases that arise from your favorite combination of:\n\nAbsolute paths or relative paths\nFile and directory soft links\nInvocation as script, bash script, bash -c script, source script, or . script\nSpaces, tabs, newlines, Unicode, etc. in directories and/or filename\nFilenames beginning with a hyphen\n\nIf you're running from Linux, it seems that using the proc handle is the best solution to locate the fully resolved source of the currently running script (in an interactive session, the link points to the respective /dev/pts/X):\n\nresolved=\"$(readlink /proc/$$/fd/255 && echo X)\" && resolved=\"${resolved%$'\\nX'}\"\n\n\nThis has a small bit of ugliness to it, but the fix is compact and easy to understand. We aren't using bash primitives only, but I'm okay with that because readlink simplifies the task considerably. The echo X adds an X to the end of the variable string so that any trailing whitespace in the filename doesn't get eaten, and the parameter substitution ${VAR%X} at the end of the line gets rid of the X. Because readlink adds a newline of its own (which would normally be eaten in the command substitution if not for our previous trickery), we have to get rid of that, too. This is most easily accomplished using the $'' quoting scheme, which lets us use escape sequences such as \\n to represent newlines (this is also how you can easily make deviously named directories and files).\n\nThe above should cover your needs for locating the currently running script on Linux, but if you don't have the proc filesystem at your disposal, or if you're trying to locate the fully resolved path of some other file, then maybe you'll find the below code helpful. It's only a slight modification from the above one-liner. If you're playing around with strange directory/filenames, checking the output with both ls and readlink is informative, as ls will output \"simplified\" paths, substituting ? for things like newlines.\n\nabsolute_path=$(readlink -e -- \"${BASH_SOURCE[0]}\" && echo x) && absolute_path=${absolute_path%?x}\ndir=$(dirname -- \"$absolute_path\" && echo x) && dir=${dir%?x}\nfile=$(basename -- \"$absolute_path\" && echo x) && file=${file%?x}\n\nls -l -- \"$dir/$file\"\nprintf '$absolute_path: \"%s\"\\n' \"$absolute_path\"\n\nShare\nImprove this answer\nFollow\nedited Jan 20 at 4:13\ncommunity wiki\n\n\n4 revs, 3 users 76%\nbillyjmc","comments":["I get /dev/pts/30 with bash on Ubuntu 14.10 Desktop.","@DanDascalescu Using the one-liner? Or the full code snippet at the bottom? And were you feeding it any tricky pathnames?","The one line plus another line to echo $resolved, I saved it as d, chmod +x d, ./d.","@DanDascalescu The first line in your script needs to be #!/bin/bash"]},{"answer":"I believe I've got this one. I'm late to the party, but I think some will appreciate it being here if they come across this thread. The comments should explain:\n\n#!/bin/sh # dash bash ksh # !zsh (issues). G. Nixon, 12/2013. Public domain.\n\n## 'linkread' or 'fullpath' or (you choose) is a little tool to recursively\n## dereference symbolic links (ala 'readlink') until the originating file\n## is found. This is effectively the same function provided in stdlib.h as\n## 'realpath' and on the command line in GNU 'readlink -f'.\n\n## Neither of these tools, however, are particularly accessible on the many\n## systems that do not have the GNU implementation of readlink, nor ship\n## with a system compiler (not to mention the requisite knowledge of C).\n\n## This script is written with portability and (to the extent possible, speed)\n## in mind, hence the use of printf for echo and case statements where they\n## can be substituded for test, though I've had to scale back a bit on that.\n\n## It is (to the best of my knowledge) written in standard POSIX shell, and\n## has been tested with bash-as-bin-sh, dash, and ksh93. zsh seems to have\n## issues with it, though I'm not sure why; so probably best to avoid for now.\n\n## Particularly useful (in fact, the reason I wrote this) is the fact that\n## it can be used within a shell script to find the path of the script itself.\n## (I am sure the shell knows this already; but most likely for the sake of\n## security it is not made readily available. The implementation of \"$0\"\n## specificies that the $0 must be the location of **last** symbolic link in\n## a chain, or wherever it resides in the path.) This can be used for some\n## ...interesting things, like self-duplicating and self-modifiying scripts.\n\n## Currently supported are three errors: whether the file specified exists\n## (ala ENOENT), whether its target exists/is accessible; and the special\n## case of when a sybolic link references itself \"foo -> foo\": a common error\n## for beginners, since 'ln' does not produce an error if the order of link\n## and target are reversed on the command line. (See POSIX signal ELOOP.)\n\n## It would probably be rather simple to write to use this as a basis for\n## a pure shell implementation of the 'symlinks' util included with Linux.\n\n## As an aside, the amount of code below **completely** belies the amount\n## effort it took to get this right -- but I guess that's coding for you.\n\n##===-------------------------------------------------------------------===##\n\nfor argv; do :; done # Last parameter on command line, for options parsing.\n\n## Error messages. Use functions so that we can sub in when the error occurs.\n\nrecurses(){ printf \"Self-referential:\\n\\t$argv ->\\n\\t$argv\\n\" ;}\ndangling(){ printf \"Broken symlink:\\n\\t$argv ->\\n\\t\"$(readlink \"$argv\")\"\\n\" ;}\nerrnoent(){ printf \"No such file: \"$@\"\\n\" ;} # Borrow a horrible signal name.\n\n# Probably best not to install as 'pathfull', if you can avoid it.\n\npathfull(){ cd \"$(dirname \"$@\")\"; link=\"$(readlink \"$(basename \"$@\")\")\"\n\n## 'test and 'ls' report different status for bad symlinks, so we use this.\n\n if [ ! -e \"$@\" ]; then if $(ls -d \"$@\" 2>/dev/null) 2>/dev/null;  then\n    errnoent 1>&2; exit 1; elif [ ! -e \"$@\" -a \"$link\" = \"$@\" ];   then\n    recurses 1>&2; exit 1; elif [ ! -e \"$@\" ] && [ ! -z \"$link\" ]; then\n    dangling 1>&2; exit 1; fi\n fi\n\n## Not a link, but there might be one in the path, so 'cd' and 'pwd'.\n\n if [ -z \"$link\" ]; then if [ \"$(dirname \"$@\" | cut -c1)\" = '/' ]; then\n   printf \"$@\\n\"; exit 0; else printf \"$(pwd)/$(basename \"$@\")\\n\"; fi; exit 0\n fi\n\n## Walk the symlinks back to the origin. Calls itself recursivly as needed.\n\n while [ \"$link\" ]; do\n   cd \"$(dirname \"$link\")\"; newlink=\"$(readlink \"$(basename \"$link\")\")\"\n   case \"$newlink\" in\n    \"$link\") dangling 1>&2 && exit 1                                       ;;\n         '') printf \"$(pwd)/$(basename \"$link\")\\n\"; exit 0                 ;;\n          *) link=\"$newlink\" && pathfull \"$link\"                           ;;\n   esac\n done\n printf \"$(pwd)/$(basename \"$newlink\")\\n\"\n}\n\n## Demo. Install somewhere deep in the filesystem, then symlink somewhere \n## else, symlink again (maybe with a different name) elsewhere, and link\n## back into the directory you started in (or something.) The absolute path\n## of the script will always be reported in the usage, along with \"$0\".\n\nif [ -z \"$argv\" ]; then scriptname=\"$(pathfull \"$0\")\"\n\n# Yay ANSI l33t codes! Fancy.\n printf \"\\n\\033[3mfrom/as: \\033[4m$0\\033[0m\\n\\n\\033[1mUSAGE:\\033[0m   \"\n printf \"\\033[4m$scriptname\\033[24m [ link | file | dir ]\\n\\n         \"\n printf \"Recursive readlink for the authoritative file, symlink after \"\n printf \"symlink.\\n\\n\\n         \\033[4m$scriptname\\033[24m\\n\\n        \"\n printf \" From within an invocation of a script, locate the script's \"\n printf \"own file\\n         (no matter where it has been linked or \"\n printf \"from where it is being called).\\n\\n\"\n\nelse pathfull \"$@\"\nfi\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '20 at 18:47\ncommunity wiki\n\n\n2 revs, 2 users 100%\nGeoff Nixon","comments":[]},{"answer":"How to obtain the full file path, full directory, and base filename of any script being run itself\n\nFor many cases, all you need to acquire is the full path to the script you just called. This can be easily accomplished using realpath. Note that realpath is part of GNU coreutils. If you don't have it already installed (it comes default on Ubuntu), you can install it with sudo apt update && sudo apt install coreutils.\n\nget_script_path.sh:\n\n#!/bin/bash\n\nFULL_PATH_TO_SCRIPT=\"$(realpath \"$0\")\"\n\n# You can then also get the full path to the directory, and the base\n# filename, like this:\nSCRIPT_DIRECTORY=\"$(dirname \"$FULL_PATH_TO_SCRIPT\")\"\nSCRIPT_FILENAME=\"$(basename \"$FULL_PATH_TO_SCRIPT\")\"\n\n# Now print it all out\necho \"FULL_PATH_TO_SCRIPT = \\\"$FULL_PATH_TO_SCRIPT\\\"\"\necho \"SCRIPT_DIRECTORY    = \\\"$SCRIPT_DIRECTORY\\\"\"\necho \"SCRIPT_FILENAME     = \\\"$SCRIPT_FILENAME\\\"\"\n\n\nExample output:\n\n~/GS/dev/eRCaGuy_hello_world/bash$ ./get_script_path.sh \nFULL_PATH_TO_SCRIPT = \"/home/gabriel/GS/dev/eRCaGuy_hello_world/bash/get_script_path.sh\"\nSCRIPT_DIRECTORY    = \"/home/gabriel/GS/dev/eRCaGuy_hello_world/bash\"\nSCRIPT_FILENAME     = \"get_script_path.sh\"\n\n\nNote that realpath also successfully walks down symbolic links to determine and point to their targets rather than pointing to the symbolic link.\n\nThe code above is now part of my eRCaGuy_hello_world repo in this file here: bash/get_script_path.sh.\n\nReferences:\nHow to retrieve absolute path given relative\nShare\nImprove this answer\nFollow\nedited Dec 28 '20 at 5:32\nanswered Feb 10 '20 at 19:46\nGabriel Staples\n13.4k4\n4 gold badges\n84\n84 silver badges\n119\n119 bronze badges","comments":[]},{"answer":"Try the following cross-compatible solution:\n\nCWD=\"$(cd -P -- \"$(dirname -- \"${BASH_SOURCE[0]}\")\" && pwd -P)\"\n\n\nAs the commands such as realpath or readlink could be not available (depending on the operating system).\n\nNote: In Bash, it's recommended to use ${BASH_SOURCE[0]} instead of $0, otherwise path can break when sourcing the file (source/.).\n\nAlternatively you can try the following function in Bash:\n\nrealpath () {\n  [[ $1 = /* ]] && echo \"$1\" || echo \"$PWD/${1#./}\"\n}\n\n\nThis function takes one argument. If argument has already absolute path, print it as it is, otherwise print $PWD variable + filename argument (without ./ prefix).\n\nRelated:\n\nHow can I set the current working directory to the directory of the script in Bash?\nBash script absolute path with OS X\nReliable way for a Bash script to get the full path to itself\nShare\nImprove this answer\nFollow\nedited Jan 20 at 4:34\ncommunity wiki\n\n\n6 revs, 2 users 83%\nkenorb","comments":["Please explain more about the realpath function.","@Chris realpath function takes 1 argument. If argument has already absolute path, print it as it is, otherwise print $PWD + filename (without ./ prefix).","Your cross-compatible solution doesn’t work when the script is symlinked."]}]},{"id":"89228","href":"https://stackoverflow.com/questions/89228/how-to-execute-a-program-or-call-a-system-command","title":"How to execute a program or call a system command?","description":"\n                \nHow do you call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?\n    ","questionComments":[],"answers":[{"answer":"Use the subprocess module in the standard library:\n\nimport subprocess\nsubprocess.run([\"ls\", \"-l\"])\n\n\nThe advantage of subprocess.run over os.system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...).\n\nEven the documentation for os.system recommends using subprocess instead:\n\nThe subprocess module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function. See the Replacing Older Functions with the subprocess Module section in the subprocess documentation for some helpful recipes.\n\nOn Python 3.4 and earlier, use subprocess.call instead of .run:\n\nsubprocess.call([\"ls\", \"-l\"])\n\nShare\nImprove this answer\nFollow\nedited Jun 9 at 18:44\nBoris\n7,6557\n7 gold badges\n66\n66 silver badges\n67\n67 bronze badges\nanswered Sep 18 '08 at 1:39\nDavid Cournapeau\n72.5k8\n8 gold badges\n59\n59 silver badges\n68\n68 bronze badges","comments":["Is there a way to use variable substitution? IE I tried to do echo $PATH by using call([\"echo\", \"$PATH\"]), but it just echoed the literal string $PATH instead of doing any substitution. I know I could get the PATH environment variable, but I'm wondering if there is an easy way to have the command behave exactly as if I had executed it in bash.","@KevinWheeler You'll have to use shell=True for that to work.","@KevinWheeler You should NOT use shell=True, for this purpose Python comes with os.path.expandvars. In your case you can write: os.path.expandvars(\"$PATH\"). @SethMMorton please reconsider your comment -> Why not to use shell=True"]},{"answer":"Here's a summary of the ways to call external programs and the advantages and disadvantages of each:\n\nos.system(\"some_command with args\") passes the command and arguments to your system's shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example:\n\nos.system(\"some_command < input_file | another_command > output_file\")  \n\n\nHowever, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, et cetera. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs. See the documentation.\n\nstream = os.popen(\"some_command with args\") will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don't need to worry about escaping anything. See the documentation.\n\nThe Popen class of the subprocess module. This is intended as a replacement for os.popen, but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you'd say:\n\nprint subprocess.Popen(\"echo Hello World\", shell=True, stdout=subprocess.PIPE).stdout.read()\n\n\ninstead of\n\nprint os.popen(\"echo Hello World\").read()\n\n\nbut it is nice to have all of the options there in one unified class instead of 4 different popen functions. See the documentation.\n\nThe call function from the subprocess module. This is basically just like the Popen class and takes all of the same arguments, but it simply waits until the command completes and gives you the return code. For example:\n\nreturn_code = subprocess.call(\"echo Hello World\", shell=True)\n\n\nSee the documentation.\n\nIf you're on Python 3.5 or later, you can use the new subprocess.run function, which is a lot like the above but even more flexible and returns a CompletedProcess object when the command finishes executing.\n\nThe os module also has all of the fork/exec/spawn functions that you'd have in a C program, but I don't recommend using them directly.\n\nThe subprocess module should probably be what you use.\n\nFinally, please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it. There are serious security implications if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code:\n\nprint subprocess.Popen(\"echo %s \" % user_input, stdout=PIPE).stdout.read()\n\n\nand imagine that the user enters something \"my mama didnt love me && rm -rf /\" which could erase the whole filesystem.\n\nShare\nImprove this answer\nFollow\nedited yesterday\nMC Emperor\n17.8k13\n13 gold badges\n72\n72 silver badges\n107\n107 bronze badges\nanswered Sep 18 '08 at 13:11\nEli Courtwright\n167k63\n63 gold badges\n204\n204 silver badges\n255\n255 bronze badges","comments":["Nice answer/explanation. How is this answer justifying Python's motto as described in this article ? fastcompany.com/3026446/… \"Stylistically, Perl and Python have different philosophies. Perl’s best known mottos is \" There’s More Than One Way to Do It\". Python is designed to have one obvious way to do it\" Seem like it should be the other way! In Perl I know only two ways to execute a command - using back-tick or open.","If using Python 3.5+, use subprocess.run(). docs.python.org/3.5/library/subprocess.html#subprocess.run","What one typically needs to know is what is done with the child process's STDOUT and STDERR, because if they are ignored, under some (quite common) conditions, eventually the child process will issue a system call to write to STDOUT (STDERR too?) that would exceed the output buffer provided for the process by the OS, and the OS will cause it to block until some process reads from that buffer. So, with the currently recommended ways, subprocess.run(..), what exactly does \"This does not capture stdout or stderr by default.\" imply? What about subprocess.check_output(..) and STDERR?","which of the commands you recommended block my script? i.e. if I want to run multiple commands in a for loop how do I do it without it blocking my python script? I don't care about the output of the command I just want to run lots of them.","This is arguably the wrong way around. Most people only need subprocess.run() or its older siblings subprocess.check_call() et al. For cases where these do not suffice, see subprocess.Popen(). os.popen() should perhaps not be mentioned at all, or come even after \"hack your own fork/exec/spawn code\"."]},{"answer":"Typical implementation:\n\nimport subprocess\n\np = subprocess.Popen('ls', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\nfor line in p.stdout.readlines():\n    print line,\nretval = p.wait()\n\n\nYou are free to do what you want with the stdout data in the pipe. In fact, you can simply omit those parameters (stdout= and stderr=) and it'll behave like os.system().\n\nShare\nImprove this answer\nFollow\nedited Jul 25 at 23:37\nBrian\n3,2004\n4 gold badges\n14\n14 silver badges\n25\n25 bronze badges\nanswered Sep 18 '08 at 18:20\nEmmEff\n7,0652\n2 gold badges\n15\n15 silver badges\n18\n18 bronze badges","comments":[".readlines() reads all lines at once i.e., it blocks until the subprocess exits (closes its end of the pipe). To read in real time (if there is no buffering issues) you could: for line in iter(p.stdout.readline, ''): print line,","Could you elaborate on what you mean by \"if there is no buffering issues\"? If the process blocks definitely, the subprocess call also blocks. The same could happen with my original example as well. What else could happen with respect to buffering?","the child process may use block-buffering in non-interactive mode instead of line-buffering so p.stdout.readline() (note: no s at the end) won't see any data until the child fills its buffer. If the child doesn't produce much data then the output won't be in real time. See the second reason in Q: Why not just use a pipe (popen())?. Some workarounds are provided in this answer (pexpect, pty, stdbuf)","the buffering issue only matters if you want output in real time and doesn't apply to your code that doesn't print anything until all data is received","This answer was fine for its time, but we should no longer recommend Popen for simple tasks. This also needlessly specifies shell=True. Try one of the subprocess.run() answers."]},{"answer":"Some hints on detaching the child process from the calling one (starting the child process in background).\n\nSuppose you want to start a long task from a CGI script. That is, the child process should live longer than the CGI script execution process.\n\nThe classical example from the subprocess module documentation is:\n\nimport subprocess\nimport sys\n\n# Some code here\n\npid = subprocess.Popen([sys.executable, \"longtask.py\"]) # Call subprocess\n\n# Some more code here\n\n\nThe idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example.\n\nMy target platform was FreeBSD, but the development was on Windows, so I faced the problem on Windows first.\n\nOn Windows (Windows XP), the parent process will not finish until the longtask.py has finished its work. It is not what you want in a CGI script. The problem is not specific to Python; in the PHP community the problems are the same.\n\nThe solution is to pass DETACHED_PROCESS Process Creation Flag to the underlying CreateProcess function in Windows API. If you happen to have installed pywin32, you can import the flag from the win32process module, otherwise you should define it yourself:\n\nDETACHED_PROCESS = 0x00000008\n\npid = subprocess.Popen([sys.executable, \"longtask.py\"],\n                       creationflags=DETACHED_PROCESS).pid\n\n\n/* UPD 2015.10.27 @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */\n\nOn FreeBSD we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in a CGI script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following:\n\npid = subprocess.Popen([sys.executable, \"longtask.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n\n\nI have not checked the code on other platforms and do not know the reasons of the behaviour on FreeBSD. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet.\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '19 at 21:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 12 '10 at 10:15\nnewtover\n28.6k11\n11 gold badges\n78\n78 silver badges\n86\n86 bronze badges","comments":["you might also need CREATE_NEW_PROCESS_GROUP flag. See Popen waiting for child process even when the immediate child has terminated","I'm seeing import subprocess as sp;sp.Popen('calc') not waiting for the subprocess to complete. It seems the creationflags aren't necessary. What am I missing?","The following is incorrect: \"[o]n windows (win xp), the parent process will not finish until the longtask.py has finished its work\". The parent will exit normally, but the console window (conhost.exe instance) only closes when the last attached process exits, and the child may have inherited the parent's console. Setting DETACHED_PROCESS in creationflags avoids this by preventing the child from inheriting or creating a console. If you instead want a new console, use CREATE_NEW_CONSOLE (0x00000010).","I didn't mean that executing as a detached process is incorrect. That said, you may need to set the standard handles to files, pipes, or os.devnull because some console programs exit with an error otherwise. Create a new console when you want the child process to interact with the user concurrently with the parent process. It would be confusing to try to do both in a single window.","is there not an OS-agnostic way to have the process run in the background?"]},{"answer":"import os\nos.system(\"your command\")\n\n\nNote that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant documentation on the 'os' and 'sys' modules. There are a bunch of functions (exec* and spawn*) that will do similar things.\n\nShare\nImprove this answer\nFollow\nedited Jun 3 '18 at 17:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 18 '08 at 1:37\nnimish\n4,1703\n3 gold badges\n18\n18 silver badges\n33\n33 bronze badges","comments":["No idea what I meant nearly a decade ago (check the date!), but if I had to guess, it would be that there's no validation done.","This should now point to subprocess as a slightly more versatile and portable solution. Running external commands is of course inherently unportable (you have to make sure the command is available on every architecture you need to support) and passing user input as an external command is inherently unsafe.","Note the timestamp on this guy: the \"correct\" answer has 40x the votes and is answer #1.","The one solution that worked for me for running NodeJS stuff."]},{"answer":"I'd recommend using the subprocess module instead of os.system because it does shell escaping for you and is therefore much safer.\n\nsubprocess.call(['ping', 'localhost'])\n\nShare\nImprove this answer\nFollow\nedited Feb 24 '20 at 1:01\nNicolas Gervais\n23.5k11\n11 gold badges\n71\n71 silver badges\n101\n101 bronze badges\nanswered Sep 18 '08 at 1:42\nsirwart\n2,2691\n1 gold badge\n14\n14 silver badges\n7\n7 bronze badges","comments":["If you want to create a list out of a command with parameters, a list which can be used with subprocess when shell=False, then use shlex.split for an easy way to do this docs.python.org/2/library/shlex.html#shlex.split (it's the recommended way according to the docs docs.python.org/2/library/subprocess.html#popen-constructor)","This is incorrect: \"it does shell escaping for you and is therefore much safer\". subprocess doesn't do shell escaping, subprocess doesn't pass your command through the shell, so there's no need to shell escape."]},{"answer":"import os\ncmd = 'ls -al'\nos.system(cmd)\n\n\nIf you want to return the results of the command, you can use os.popen. However, this is deprecated since version 2.6 in favor of the subprocess module, which other answers have covered well.\n\nShare\nImprove this answer\nFollow\nedited Jan 26 '16 at 16:53\nPatrick M\n9,6159\n9 gold badges\n57\n57 silver badges\n98\n98 bronze badges\nanswered Sep 18 '08 at 1:37\nAlexandra Franks\n2,8061\n1 gold badge\n17\n17 silver badges\n22\n22 bronze badges","comments":["popen is deprecated in favor of subprocess.","You can also save your result with the os.system call, since it works like the UNIX shell itself, like for example os.system('ls -l > test2.txt')"]},{"answer":"There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is ls -l (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them.\n\nSources\nsubprocess: https://docs.python.org/3.5/library/subprocess.html\nshlex: https://docs.python.org/3/library/shlex.html\nos: https://docs.python.org/3.5/library/os.html\nsh: https://amoffat.github.io/sh/\nplumbum: https://plumbum.readthedocs.io/en/latest/\npexpect: https://pexpect.readthedocs.io/en/stable/\nfabric: http://www.fabfile.org/\nenvoy: https://github.com/kennethreitz/envoy\ncommands: https://docs.python.org/2/library/commands.html\nThese are all the libraries\n\nHopefully this will help you make a decision on which library to use :)\n\nsubprocess\n\nSubprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better.\n\nsubprocess.run([\"ls\", \"-l\"]) # Run command\nsubprocess.run([\"ls\", \"-l\"], stdout=subprocess.PIPE) # This will run the command and return any output\nsubprocess.run(shlex.split(\"ls -l\")) # You can also use the shlex library to split the command\n\nos\n\nos is used for \"operating system dependent functionality\". It can also be used to call external commands with os.system and os.popen (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use subprocess.run.\n\nos.system(\"ls -l\") # Run command\nos.popen(\"ls -l\").read() # This will run the command and return any output\n\nsh\n\nsh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times.\n\nsh.ls(\"-l\") # Run command normally\nls_cmd = sh.Command(\"ls\") # Save command as a variable\nls_cmd() # Run command as if it were a function\n\nplumbum\n\nplumbum is a library for \"script-like\" Python programs. You can call programs like functions as in sh. Plumbum is useful if you want to run a pipeline without the shell.\n\nls_cmd = plumbum.local(\"ls -l\") # Get command\nls_cmd() # Run command\n\npexpect\n\npexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix.\n\npexpect.run(\"ls -l\") # Run command as normal\nchild = pexpect.spawn('scp foo user@example.com:.') # Spawns child application\nchild.expect('Password:') # When this is the output\nchild.sendline('mypassword')\n\nfabric\n\nfabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH)\n\nfabric.operations.local('ls -l') # Run command as normal\nfabric.operations.local('ls -l', capture = True) # Run command and receive output\n\nenvoy\n\nenvoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the subprocess module.\n\nr = envoy.run(\"ls -l\") # Run command\nr.std_out # Get output\n\ncommands\n\ncommands contains wrapper functions for os.popen, but it has been removed from Python 3 since subprocess is a better alternative.\n\nShare\nImprove this answer\nFollow\nedited Apr 7 at 17:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 29 '16 at 14:02\nTom Fuller\n4,6986\n6 gold badges\n31\n31 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"With the standard library\n\nUse the subprocess module (Python 3):\n\nimport subprocess\nsubprocess.run(['ls', '-l'])\n\n\nIt is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write.\n\nNote on Python version: If you are still using Python 2, subprocess.call works in a similar way.\n\nProTip: shlex.split can help you to parse the command for run, call, and other subprocess functions in case you don't want (or you can't!) provide them in form of lists:\n\nimport shlex\nimport subprocess\nsubprocess.run(shlex.split('ls -l'))\n\nWith external dependencies\n\nIf you do not mind external dependencies, use plumbum:\n\nfrom plumbum.cmd import ifconfig\nprint(ifconfig['wlan0']())\n\n\nIt is the best subprocess wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by pip install plumbum.\n\nAnother popular library is sh:\n\nfrom sh import ifconfig\nprint(ifconfig('wlan0'))\n\n\nHowever, sh dropped Windows support, so it's not as awesome as it used to be. Install by pip install sh.\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '19 at 21:54\ncommunity wiki\n\n\n6 revs, 2 users 79%\nHonza Javorek","comments":[]},{"answer":"I always use fabric for this things like:\n\nfrom fabric.operations import local\nresult = local('ls', capture=True)\nprint \"Content:/n%s\" % (result, )\n\n\nBut this seem to be a good tool: sh (Python subprocess interface).\n\nLook at an example:\n\nfrom sh import vgdisplay\nprint vgdisplay()\nprint vgdisplay('-v')\nprint vgdisplay(v=True)\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '19 at 21:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 13 '12 at 0:12\nJorge E. Cardona\n85.1k3\n3 gold badges\n32\n32 silver badges\n40\n40 bronze badges","comments":[]},{"answer":"Check the \"pexpect\" Python library, too.\n\nIt allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like:\n\nchild = pexpect.spawn('ftp 192.168.0.24')\n\nchild.expect('(?i)name .*: ')\n\nchild.sendline('anonymous')\n\nchild.expect('(?i)password')\n\nShare\nImprove this answer\nFollow\nedited May 28 '17 at 23:02\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 7 '10 at 7:09\nathanassis\n9797\n7 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"If you need the output from the command you are calling, then you can use subprocess.check_output (Python 2.7+).\n\n>>> subprocess.check_output([\"ls\", \"-l\", \"/dev/null\"])\n'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\\n'\n\n\nAlso note the shell parameter.\n\nIf shell is True, the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user’s home directory. However, note that Python itself offers implementations of many shell-like features (in particular, glob, fnmatch, os.walk(), os.path.expandvars(), os.path.expanduser(), and shutil).\n\nShare\nImprove this answer\nFollow\nedited Jun 3 '18 at 20:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 28 '11 at 20:29\nFacundo Casco\n8,9195\n5 gold badges\n41\n41 silver badges\n62\n62 bronze badges","comments":["Note that check_output requires a list rather than a string. If you don't rely on quoted spaces to make your call valid, the simplest, most readable way to do this is subprocess.check_output(\"ls -l /dev/null\".split()).","Like the answer vaguely mentions, and many other answers on this page explain in more detail, you can pass a list, or with shell=True a single string which the shell then takes care of parsing and executing. Using plain .split() is fine under the circumstances you mention, but beginners typically don't understand the nuances; you are probably better off recommending shlex.split() which does handle quoting and backslash escapes correctly."]},{"answer":"Update:\n\nsubprocess.run is the recommended approach as of Python 3.5 if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See this question for how.)\n\nHere's some examples from the documentation.\n\nRun a process:\n\n>>> subprocess.run([\"ls\", \"-l\"])  # Doesn't capture output\nCompletedProcess(args=['ls', '-l'], returncode=0)\n\n\nRaise on failed run:\n\n>>> subprocess.run(\"exit 1\", shell=True, check=True)\nTraceback (most recent call last):\n  ...\nsubprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1\n\n\nCapture output:\n\n>>> subprocess.run([\"ls\", \"-l\", \"/dev/null\"], stdout=subprocess.PIPE)\nCompletedProcess(args=['ls', '-l', '/dev/null'], returncode=0,\nstdout=b'crw-rw-rw- 1 root root 1, 3 Jan 23 16:23 /dev/null\\n')\n\nOriginal answer:\n\nI recommend trying Envoy. It's a wrapper for subprocess, which in turn aims to replace the older modules and functions. Envoy is subprocess for humans.\n\nExample usage from the README:\n\n>>> r = envoy.run('git config', data='data to pipe in', timeout=2)\n\n>>> r.status_code\n129\n>>> r.std_out\n'usage: git config [options]'\n>>> r.std_err\n''\n\n\nPipe stuff around too:\n\n>>> r = envoy.run('uptime | pbcopy')\n\n>>> r.command\n'pbcopy'\n>>> r.status_code\n0\n\n>>> r.history\n[<Response 'uptime'>]\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '19 at 21:52\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 15 '12 at 17:13\nJoe\n15k10\n10 gold badges\n57\n57 silver badges\n69\n69 bronze badges","comments":[]},{"answer":"This is how I run my commands. This code has everything you need pretty much\n\nfrom subprocess import Popen, PIPE\ncmd = \"ls -l ~/\"\np = Popen(cmd , shell=True, stdout=PIPE, stderr=PIPE)\nout, err = p.communicate()\nprint \"Return code: \", p.returncode\nprint out.rstrip(), err.rstrip()\n\nShare\nImprove this answer\nFollow\nedited Oct 28 '12 at 5:44\nanswered Oct 28 '12 at 5:14\nUsman Khan\n6515\n5 silver badges\n3\n3 bronze badges","comments":["I think it's acceptable for hard-coded commands, if it increases readability.","An explanation would be in order. E.g., what is the idea/gist?"]},{"answer":"Use subprocess.\n\n...or for a very simple command:\n\nimport os\nos.system('cat testfile')\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '19 at 21:39\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 18 '08 at 1:43\nBen Hoffstein\n98.7k8\n8 gold badges\n100\n100 silver badges\n119\n119 bronze badges","comments":[]},{"answer":"How to execute a program or call a system command from Python\n\nSimple, use subprocess.run, which returns a CompletedProcess object:\n\n>>> from subprocess import run\n>>> from shlex import split\n>>> completed_process = run(split('python --version'))\nPython 3.8.8\n>>> completed_process\nCompletedProcess(args=['python', '--version'], returncode=0)\n\n\n(run wants a list of lexically parsed shell arguments - this is what you'd type in a shell, separated by spaces, but not where the spaces are quoted, so use a specialized function, split, to split up what you would literally type into your shell)\n\nWhy?\n\nAs of Python 3.5, the documentation recommends subprocess.run:\n\nThe recommended approach to invoking subprocesses is to use the run() function for all use cases it can handle. For more advanced use cases, the underlying Popen interface can be used directly.\n\nHere's an example of the simplest possible usage - and it does exactly as asked:\n\n>>> from subprocess import run\n>>> from shlex import split\n>>> completed_process = run(split('python --version'))\nPython 3.8.8\n>>> completed_process\nCompletedProcess(args=['python', '--version'], returncode=0)\n\n\nrun waits for the command to successfully finish, then returns a CompletedProcess object. It may instead raise TimeoutExpired (if you give it a timeout= argument) or CalledProcessError (if it fails and you pass check=True).\n\nAs you might infer from the above example, stdout and stderr both get piped to your own stdout and stderr by default.\n\nWe can inspect the returned object and see the command that was given and the returncode:\n\n>>> completed_process.args\n['python', '--version']\n>>> completed_process.returncode\n0\n\nCapturing output\n\nIf you want to capture the output, you can pass subprocess.PIPE to the appropriate stderr or stdout:\n\n>>> from subprocess import PIPE\n>>> completed_process = run(shlex.split('python --version'), stdout=PIPE, stderr=PIPE)\n>>> completed_process.stdout\nb'Python 3.8.8\\n'\n>>> completed_process.stderr\nb''\n\n\nAnd those respective attributes return bytes.\n\nPass a command list\n\nOne might easily move from manually providing a command string (like the question suggests) to providing a string built programmatically. Don't build strings programmatically. This is a potential security issue. It's better to assume you don't trust the input.\n\n>>> import textwrap\n>>> args = ['python', textwrap.__file__]\n>>> cp = run(args, stdout=subprocess.PIPE)\n>>> cp.stdout\nb'Hello there.\\n  This is indented.\\n'\n\n\nNote, only args should be passed positionally.\n\nFull Signature\n\nHere's the actual signature in the source and as shown by help(run):\n\ndef run(*popenargs, input=None, timeout=None, check=False, **kwargs):\n\n\nThe popenargs and kwargs are given to the Popen constructor. input can be a string of bytes (or unicode, if specify encoding or universal_newlines=True) that will be piped to the subprocess's stdin.\n\nThe documentation describes timeout= and check=True better than I could:\n\nThe timeout argument is passed to Popen.communicate(). If the timeout expires, the child process will be killed and waited for. The TimeoutExpired exception will be re-raised after the child process has terminated.\n\nIf check is true, and the process exits with a non-zero exit code, a CalledProcessError exception will be raised. Attributes of that exception hold the arguments, the exit code, and stdout and stderr if they were captured.\n\nand this example for check=True is better than one I could come up with:\n\n>>> subprocess.run(\"exit 1\", shell=True, check=True)\nTraceback (most recent call last):\n  ...\nsubprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1\n\nExpanded Signature\n\nHere's an expanded signature, as given in the documentation:\n\nsubprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None, \nshell=False, cwd=None, timeout=None, check=False, encoding=None, \nerrors=None)\n\n\nNote that this indicates that only the args list should be passed positionally. So pass the remaining arguments as keyword arguments.\n\nPopen\n\nWhen use Popen instead? I would struggle to find use-case based on the arguments alone. Direct usage of Popen would, however, give you access to its methods, including poll, 'send_signal', 'terminate', and 'wait'.\n\nHere's the Popen signature as given in the source. I think this is the most precise encapsulation of the information (as opposed to help(Popen)):\n\n\ndef __init__(self, args, bufsize=-1, executable=None,\n             stdin=None, stdout=None, stderr=None,\n             preexec_fn=None, close_fds=True,\n             shell=False, cwd=None, env=None, universal_newlines=None,\n             startupinfo=None, creationflags=0,\n             restore_signals=True, start_new_session=False,\n             pass_fds=(), *, user=None, group=None, extra_groups=None,\n             encoding=None, errors=None, text=None, umask=-1, pipesize=-1):\n\n\n\nBut more informative is the Popen documentation:\n\nsubprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, \nstderr=None, preexec_fn=None, close_fds=True, shell=False, cwd=None,\nenv=None, universal_newlines=None, startupinfo=None, creationflags=0, \nrestore_signals=True, start_new_session=False, pass_fds=(), *, group=None, \nextra_groups=None, user=None, umask=-1, encoding=None, errors=None, \ntext=None)\n\n\nExecute a child program in a new process. On POSIX, the class uses os.execvp()-like behavior to execute the child program. On Windows, the class uses the Windows CreateProcess() function. The arguments to Popen are as follows.\n\nUnderstanding the remaining documentation on Popen will be left as an exercise for the reader.\n\nShare\nImprove this answer\nFollow\nedited Jun 10 at 13:30\nanswered Oct 18 '17 at 16:37\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":["A simple example of two-way communication between a primary process and a subprocess can be found here: stackoverflow.com/a/52841475/1349673"]},{"answer":"os.system is OK, but kind of dated. It's also not very secure. Instead, try subprocess. subprocess does not call sh directly and is therefore more secure than os.system.\n\nGet more information here.\n\nShare\nImprove this answer\nFollow\nedited Dec 10 '16 at 13:25\nDimitris Fasarakis Hilliard\n124k27\n27 gold badges\n231\n231 silver badges\n228\n228 bronze badges\nanswered Sep 18 '08 at 1:53\nMartin W\n1,2897\n7 silver badges\n12\n12 bronze badges","comments":["While I agree with the overall recommendation, subprocess does not remove all of the security problems, and has some pesky issues of its own."]},{"answer":"There is also Plumbum\n\n>>> from plumbum import local\n>>> ls = local[\"ls\"]\n>>> ls\nLocalCommand(<LocalPath /bin/ls>)\n>>> ls()\nu'build.py\\ndist\\ndocs\\nLICENSE\\nplumbum\\nREADME.rst\\nsetup.py\\ntests\\ntodo.txt\\n'\n>>> notepad = local[\"c:\\\\windows\\\\notepad.exe\"]\n>>> notepad()                                   # Notepad window pops up\nu''                                             # Notepad window is closed by user, command returns\n\nShare\nImprove this answer\nFollow\nanswered Oct 10 '14 at 17:41\nstuckintheshuck\n2,3233\n3 gold badges\n26\n26 silver badges\n31\n31 bronze badges","comments":["An explanation would be in order."]},{"answer":"As of Python 3.7.0 released on June 27th 2018 (https://docs.python.org/3/whatsnew/3.7.html), you can achieve your desired result in the most powerful while equally simple way. This answer intends to show you the essential summary of various options in a short manner. For in-depth answers, please see the other ones.\n\nTL;DR in 2021\n\nThe big advantage of os.system(...) was its simplicity. subprocess is better and still easy to use, especially as of Python 3.5.\n\nimport subprocess\nsubprocess.run(\"ls -a\", shell=True)\n\n\nNote: This is the exact answer to your question - running a command\n\nlike in a shell\n\nPreferred Way\n\nIf possible, remove the shell overhead and run the command directly (requires a list).\n\nimport subprocess\nsubprocess.run([\"help\"])\nsubprocess.run([\"ls\", \"-a\"])\n\n\nPass program arguments in a list. Don't include \\\"-escaping for arguments containing spaces.\n\nAdvanced Use Cases\nChecking The Output\n\nThe following code speaks for itself:\n\nimport subprocess\nresult = subprocess.run([\"ls\", \"-a\"], capture_output=True, text=True)\nif \"stackoverflow-logo.png\" in result.stdout:\n    print(\"You're a fan!\")\nelse:\n    print(\"You're not a fan?\")\n\n\nresult.stdout is all normal program output excluding errors. Read result.stderr to get them.\n\ncapture_output=True - turns capturing on. Otherwise result.stderr and result.stdout would be None. Available from Python 3.7.\n\ntext=True - a convenience argument added in Python 3.7 which converts the received binary data to Python strings you can easily work with.\n\nChecking the returncode\n\nDo\n\nif result.returncode == 127: print(\"The program failed for some weird reason\")\nelif result.returncode == 0: print(\"The program succeeded\")\nelse: print(\"The program failed unexpectedly\")\n\n\nIf you just want to check if the program succeeded (returncode == 0) and otherwise throw an Exception, there is a more convenient function:\n\nresult.check_returncode()\n\n\nBut it's Python, so there's an even more convenient argument check which does the same thing automatically for you:\n\nresult = subprocess.run(..., check=True)\n\nstderr should be inside stdout\n\nYou might want to have all program output inside stdout, even errors. To accomplish this, run\n\nresult = subprocess.run(..., stderr=subprocess.STDOUT)\n\n\nresult.stderr will then be None and result.stdout will contain everything.\n\nUsing shell=False with an argument string\n\nshell=False expects a list of arguments. You might however, split an argument string on your own using shlex.\n\nimport subprocess\nimport shlex\nsubprocess.run(shlex.split(\"ls -a\"))\n\n\nThat's it.\n\nCommon Problems\n\nChances are high you just started using Python when you come across this question. Let's look at some common problems.\n\nFileNotFoundError: [Errno 2] No such file or directory: 'ls -a': 'ls -a'\n\nYou're running a subprocess without shell=True . Either use a list ([\"ls\", \"-a\"]) or set shell=True.\n\nTypeError: [...] NoneType [...]\n\nCheck that you've set capture_output=True.\n\nTypeError: a bytes-like object is required, not [...]\n\nYou always receive byte results from your program. If you want to work with it like a normal string, set text=True.\n\nsubprocess.CalledProcessError: Command '[...]' returned non-zero exit status 1.\n\nYour command didn't run successfully. You could disable returncode checking or check your actual program's validity.\n\nTypeError: init() got an unexpected keyword argument [...]\n\nYou're likely using a version of Python older than 3.7.0; update it to the most recent one available. Otherwise there are other answers in this Stack Overflow post showing you older alternative solutions.\n\nShare\nImprove this answer\nFollow\nedited Apr 7 at 17:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 13 '20 at 19:20\nfameman\n1,93712\n12 silver badges\n30\n30 bronze badges","comments":["\"The big advantage of os.system(...) was its simplicity. subprocess is better\" - how subprocess is better? I am happily using os.system, not sure how switching to subprocess and remembering extra shell=True benefits me. What kind of thing is better in subprocess?","You're right in that os.system(...) is a reasonable choice for executing commands in terms of simple \"blind\" execution. However, the use cases are rather limited - as soon as you want to capture the output, you have to use a whole other library and then you start having both - subprocess and os for similar use cases in your code. I prefer to keep the code clean and use only one of them. Second, and I would have put that section at the top but the TL;DR has to answer the question exactly, you should not use shell=True, but instead what I've written in the Preferred Way section.","The problem with os.system(...) and shell=True is that you're spawning a new shell process, just to execute your command. This means, you have to do manual escaping which is not as simple as you might think - especially when targeting both POSIX and Windows. For user-supplied input, this is a no-go (just imagine the user entered something with \" quotes - you'd have to escape them as well). Also, the shell process itself could load code you don't need - not only does it delay the program, but it could also lead to unexpected side effects, ending with a wrong return code.","Summing up, os.system(...) is valid to use, indeed. But as soon as you're writing more than a quick python helper script, I'd recommend you to go for subprocess.run without shell=True. For more information about the drawbacks of os.system, I'd like to propose you a read through this SO answer: stackoverflow.com/a/44731082/6685358","thanks! I wanted to edit \"better\" to include that link, but I got error about full edit queue."]},{"answer":"It can be this simple:\n\nimport os\ncmd = \"your command\"\nos.system(cmd)\n\nShare\nImprove this answer\nFollow\nedited Jun 8 '18 at 12:06\nanswered Apr 30 '18 at 13:47\nSamadi Salahedine\n5075\n5 silver badges\n12\n12 bronze badges","comments":["This fails to point out the drawbacks, which are explained in much more detail in PEP-324. The documentation for os.system explicitly recommends avoiding it in favor of subprocess."]},{"answer":"Use:\n\nimport os\n\ncmd = 'ls -al'\n\nos.system(cmd)\n\n\nos - This module provides a portable way of using operating system-dependent functionality.\n\nFor the more os functions, here is the documentation.\n\nShare\nImprove this answer\nFollow\nedited May 28 '17 at 23:05\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 29 '15 at 11:34\nPriyankara\n73011\n11 silver badges\n21\n21 bronze badges","comments":["it's also deprecated. use subprocess"]},{"answer":"There is another difference here which is not mentioned previously.\n\nsubprocess.Popen executes the <command> as a subprocess. In my case, I need to execute file <a> which needs to communicate with another program, <b>.\n\nI tried subprocess, and execution was successful. However <b> could not communicate with <a>. Everything is normal when I run both from the terminal.\n\nOne more: (NOTE: kwrite behaves different from other applications. If you try the below with Firefox, the results will not be the same.)\n\nIf you try os.system(\"kwrite\"), program flow freezes until the user closes kwrite. To overcome that I tried instead os.system(konsole -e kwrite). This time program continued to flow, but kwrite became the subprocess of the console.\n\nAnyone runs the kwrite not being a subprocess (i.e. in the system monitor it must appear at the leftmost edge of the tree).\n\nShare\nImprove this answer\nFollow\nedited Jun 3 '18 at 20:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 8 '10 at 21:11\nAtinc Delican\n2753\n3 silver badges\n2\n2 bronze badges","comments":["What do you mean by \"Anyone runs the kwrite not being a subprocess\"?","It is baffling indeed that subprocess runs a subprocess."]},{"answer":"os.system does not allow you to store results, so if you want to store results in some list or something, a subprocess.call works.\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '19 at 21:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 11 '12 at 22:28\nSaurabh Bangad\n3673\n3 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"subprocess.check_call is convenient if you don't want to test return values. It throws an exception on any error.\n\nShare\nImprove this answer\nFollow\nanswered Jan 18 '11 at 19:21\ncdunn2001\n15.9k7\n7 gold badges\n51\n51 silver badges\n42\n42 bronze badges","comments":[]},{"answer":"I tend to use subprocess together with shlex (to handle escaping of quoted strings):\n\n>>> import subprocess, shlex\n>>> command = 'ls -l \"/your/path/with spaces/\"'\n>>> call_params = shlex.split(command)\n>>> print call_params\n[\"ls\", \"-l\", \"/your/path/with spaces/\"]\n>>> subprocess.call(call_params)\n\nShare\nImprove this answer\nFollow\nanswered Apr 30 '14 at 14:37\nEmil Stenström\n10.8k8\n8 gold badges\n47\n47 silver badges\n72\n72 bronze badges","comments":[]},{"answer":"I wrote a library for this, shell.py.\n\nIt's basically a wrapper for popen and shlex for now. It also supports piping commands, so you can chain commands easier in Python. So you can do things like:\n\nex('echo hello shell.py') | \"awk '{print $2}'\"\n\nShare\nImprove this answer\nFollow\nedited Apr 7 at 17:28\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 1 '14 at 20:49\nhouqp\n6738\n8 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"In Windows you can just import the subprocess module and run external commands by calling subprocess.Popen(), subprocess.Popen().communicate() and subprocess.Popen().wait() as below:\n\n# Python script to run a command line\nimport subprocess\n\ndef execute(cmd):\n    \"\"\"\n        Purpose  : To execute a command and return exit status\n        Argument : cmd - command to execute\n        Return   : exit_code\n    \"\"\"\n    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    (result, error) = process.communicate()\n\n    rc = process.wait()\n\n    if rc != 0:\n        print \"Error: failed to execute command:\", cmd\n        print error\n    return result\n# def\n\ncommand = \"tasklist | grep python\"\nprint \"This process detail: \\n\", execute(command)\n\n\nOutput:\n\nThis process detail:\npython.exe                     604 RDP-Tcp#0                  4      5,660 K\n\nShare\nImprove this answer\nFollow\nedited May 28 '17 at 23:08\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 17 '16 at 9:14\nSwadhikar\n1,8771\n1 gold badge\n17\n17 silver badges\n30\n30 bronze badges","comments":[]},{"answer":"Under Linux, in case you would like to call an external command that will execute independently (will keep running after the Python script terminates), you can use a simple queue as task spooler or the at command.\n\nAn example with task spooler:\n\nimport os\nos.system('ts <your-command>')\n\n\nNotes about task spooler (ts):\n\nYou could set the number of concurrent processes to be run (\"slots\") with:\n\nts -S <number-of-slots>\n\nInstalling ts doesn't requires admin privileges. You can download and compile it from source with a simple make, add it to your path and you're done.\n\nShare\nImprove this answer\nFollow\nedited Apr 7 at 17:39\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 27 '16 at 0:15\nYuval Atzmon\n4,8252\n2 gold badges\n30\n30 silver badges\n64\n64 bronze badges","comments":["ts is not standard on any distro I know of, though the pointer to at is mildly useful. You should probably also mention batch. As elsewhere, the os.system() recommendation should probably at least mention that subprocess is its recommended replacement."]},{"answer":"You can use Popen, and then you can check the procedure's status:\n\nfrom subprocess import Popen\n\nproc = Popen(['ls', '-l'])\nif proc.poll() is None:\n    proc.kill()\n\n\nCheck out subprocess.Popen.\n\nShare\nImprove this answer\nFollow\nedited May 28 '17 at 23:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 16 '12 at 15:16\nadmire\n3302\n2 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"To fetch the network id from the OpenStack Neutron:\n\n#!/usr/bin/python\nimport os\nnetid = \"nova net-list | awk '/ External / { print $2 }'\"\ntemp = os.popen(netid).read()  /* Here temp also contains new line (\\n) */\nnetworkId = temp.rstrip()\nprint(networkId)\n\n\nOutput of nova net-list\n\n+--------------------------------------+------------+------+\n| ID                                   | Label      | CIDR |\n+--------------------------------------+------------+------+\n| 431c9014-5b5d-4b51-a357-66020ffbb123 | test1      | None |\n| 27a74fcd-37c0-4789-9414-9531b7e3f126 | External   | None |\n| 5a2712e9-70dc-4b0e-9281-17e02f4684c9 | management | None |\n| 7aa697f5-0e60-4c15-b4cc-9cb659698512 | Internal   | None |\n+--------------------------------------+------------+------+\n\n\nOutput of print(networkId)\n\n27a74fcd-37c0-4789-9414-9531b7e3f126\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '19 at 22:05\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 20 '16 at 9:50\nIRSHAD\n2,38226\n26 silver badges\n37\n37 bronze badges","comments":["You should not recommend os.popen() in 2016. The Awk script could easily be replaced with native Python code."]}]},{"id":"52704","href":"https://stackoverflow.com/questions/52704/how-do-i-discard-unstaged-changes-in-git","title":"How do I discard unstaged changes in Git?","description":"\n                \nHow do I discard changes in my working copy that are not in the index?\n    ","questionComments":["git-clean only removes untracked files from the working tree git-scm.com/docs/git-clean","To clarify Asenar's comment above, git-clean -df can be dangerous. It will delete local untracked files (e.g. covered by a .gitignore) Read all below carefully and consider git checkout . instead","'git clean -df ' Be warned! I tried that and lost key folders that are unable to be restored... Ouch!","hitting git status gives a suggestion on how to do that! git checkout -- .","@Paulo: starting in July 2019, git status gives the suggestion: git restore. git restore is a new command exactly for this purpose. See my 2019 update."],"answers":[{"answer":"Another quicker way is:\n\ngit stash save --keep-index --include-untracked\n\n\nYou don't need to include --include-untracked if you don't want to be thorough about it.\n\nAfter that, you can drop that stash with a git stash drop command if you like.\n\nShare\nImprove this answer\nFollow\nedited Sep 11 '18 at 0:14\nBrandon Minnick\n11.5k12\n12 gold badges\n57\n57 silver badges\n108\n108 bronze badges\nanswered Sep 9 '08 at 19:39\nGreg Hewgill\n843k170\n170 gold badges\n1107\n1107 silver badges\n1243\n1243 bronze badges","comments":["And to be thorough about it, you'd want --include-untracked as well.","@KarimSamir: The question specifically asks about changes that are not in the index. The git reset command will discard changes in the index too.","git checkout -- . is much faster","Neither the git stash, nor any variety of git checkout will discard unstaged deletes. According to the output of git status, the actual correct answer here is some flavor git reset HEAD","This pollutes the stash stack. git checkout -- . does the job with one command only."]},{"answer":"For all unstaged files in current working directory use:\n\ngit checkout -- .\n\n\nFor a specific file use:\n\ngit checkout -- path/to/file/to/revert\n\n\n-- here to remove ambiguity (this is known as argument disambiguation).\n\nFor Git 2.23 onwards, one may want to use the more specific\n\ngit restore .\n\n\nresp.\n\ngit restore path/to/file/to/revert\n\n\nthat together with git switch replaces the overloaded git checkout (see here), and thus removes the argument disambiguation.\n\nShare\nImprove this answer\nFollow\nedited Jun 10 at 6:53\nsnatchysquid\n1,1484\n4 silver badges\n21\n21 bronze badges\nanswered Sep 9 '08 at 19:37\nTobi\n66.6k5\n5 gold badges\n29\n29 silver badges\n36\n36 bronze badges","comments":["This seems to be the git canonical way. i.e. exactly what git tells you to do if you type git status","Doesn't work if there are untracked files. Git says error: The following untracked working tree files would be overwritten by checkout: ....","newbie question, what does \"git checkout -- .\" mean semantically?","@Ninjack git checkout -- . means the same thing as git checkout ., except that you're explicit about the fact that you're not specifying the branch name. They both say checkout the HEAD version on the branch I am currently on for '.' or './'. If you do git checkout branch-name directory-or-file-name in general, you get the HEAD version of directory-or-file-name on branch branch-name.","IMO this variant is imperfect, as it doesn't handle situation when your changed repository is not on the HEAD revision at the moment of changes cleaning and you DO NOT want to update it to HEAD, and want to just clean the changes."]},{"answer":"It seems like the complete solution is:\n\ngit clean -df\ngit checkout -- .\n\n\ngit clean removes all untracked files (warning: while it won't delete ignored files mentioned directly in .gitignore, it may delete ignored files residing in folders) and git checkout clears all unstaged changes.\n\nShare\nImprove this answer\nFollow\nedited Mar 29 '17 at 2:32\nHonest Abe\n7,5544\n4 gold badges\n46\n46 silver badges\n59\n59 bronze badges\nanswered Aug 29 '12 at 18:28\nMariusz Nowak\n29k4\n4 gold badges\n32\n32 silver badges\n37\n37 bronze badges","comments":["The other two answers don't actually work, this one did.","@dval this is becues the first command removed the unindexed files and the second one removed the unstaged changes (of indexed files). So if you did not have any staged changes this it is the same as reverting to the last commit with git reset --hard","use -dff if the untracked directory is a git clone.","Be careful running git clean -df. If you don't understand what it does, you might be deleting files you mean to keep, like robots.txt, uploaded files, etc.","As @ctlockey said, the first command also delete directories if they are composed of ignored files only... Lost a whole bunch of configuration files on my project :( Be careful."]},{"answer":"This checks out the current index for the current directory, throwing away all changes in files from the current directory downwards.\n\ngit checkout .\n\n\nor this which checks out all files from the index, overwriting working tree files.\n\ngit checkout-index -a -f\n\nShare\nImprove this answer\nFollow\nanswered Jun 20 '09 at 10:28\nCB Bailey\n661k95\n95 gold badges\n610\n610 silver badges\n639\n639 bronze badges","comments":["+1 This is the RIGHT ANSWER, as it correctly handles the case where some files have both staged and un-staged changes. Note that this solution DISCARDS the unstaged changes; if you wish to retain them, then you should use @greg-hewgill 's answer of git stash save --keep-index.","git checkout -- does not work if you have only one branch. git checkout . always works.","Thank you so much! Finally an answer that ALWAYS works! This may be combined with git clean to also remove untracked files.","Not being funny but this appears to be the only working answer. The higher rated answers appear to do nothing. I'm sure they do something, but they certainly don't \"reset\" the unstaged changes."]},{"answer":"git clean -df\n\n\nCleans the working tree by recursively removing files that are not under version control, starting from the current directory.\n\n-d: Remove untracked directories in addition to untracked files\n\n-f: Force (might be not necessary depending on clean.requireForce setting)\n\nRun git help clean to see the manual\n\nShare\nImprove this answer\nFollow\nedited May 15 '15 at 13:42\nfalsarella\n11.8k8\n8 gold badges\n67\n67 silver badges\n107\n107 bronze badges\nanswered Dec 7 '11 at 13:09\nE Ciotti\n4,3601\n1 gold badge\n22\n22 silver badges\n17\n17 bronze badges","comments":["why this answer doesn't have all the votes? answered back in the 2011 and still correct."]},{"answer":"2019 update\n\nYou can now discard unstaged changes in one tracked file with:\n\ngit restore <file>\n\n\nand in all tracked files in the current directory (recursively) with:\n\ngit restore .\n\n\nIf you run the latter from the root of the repository, it will discard unstaged changes in all tracked files in the project.\n\nNotes\ngit restore was introduced in July 2019 and released in version 2.23 as part of a split of the git checkout command into git restore for files and git switch for branches.\ngit checkout still behaves as it used to and the older answers remain perfectly valid.\nWhen running git status with unstaged changes in the working tree, this is now what Git suggests to use to discard them (instead of git checkout -- <file> as it used to prior to v2.23).\nAs with git checkout -- ., this only discards changes in tracked files. So Mariusz Nowak's answer still applies and if you want to discard all unstaged changes, including untracked files, you could run, as he suggests, an additional git clean -df.\nShare\nImprove this answer\nFollow\nedited Apr 3 at 16:47\nanswered Sep 11 '19 at 1:30\nprosoitos\n5,0215\n5 gold badges\n20\n20 silver badges\n35\n35 bronze badges","comments":["I wanted to revert my unstaged changes only without affecting newly added files so a git restore . worked perfectly. Thanks.","I did git restore <filename> and it worked perfectly.","Worked fine for me.","According to the man page git restore . restores all files in current directory, not in the whole repository.","You are right. Thanks! I just tested it and indeed, that is the case. It is, however, recursive. So when run from the root of the project, it applies to the whole repository. I will edit my answer."]},{"answer":"My favorite is\n\ngit checkout -p\n\n\nThat lets you selectively revert chunks.\n\nSee also:\n\ngit add -p\n\nShare\nImprove this answer\nFollow\nedited Feb 23 '15 at 19:46\nanswered Oct 10 '14 at 12:31\nBen\n6,7131\n1 gold badge\n35\n35 silver badges\n41\n41 bronze badges","comments":["I love the ability to see the actual change before it's discarded.","This is what I use. git checkout -p and then \"a\" to accept all.","I've never thought about. That -p adds a nice extra layer of safety. Combine it with git clean -d to actually answer OP."]},{"answer":"Since no answer suggests the exact option combination that I use, here it is:\n\ngit clean -dxn .  # dry-run to inspect the list of files-to-be-removed\ngit clean -dxf .  # REMOVE ignored/untracked files (in the current directory)\ngit checkout -- . # ERASE changes in tracked files (in the current directory)\n\n\nThis is the online help text for the used git clean options:\n\n-d\n\nRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use -f option twice if you really want to remove such a directory.\n\n-x\n\nDon’t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in conjunction with git reset) to create a pristine working directory to test a clean build.\n\n-n\n\nDon’t actually remove anything, just show what would be done.\n\n-f\n\nIf the Git configuration variable clean.requireForce is not set to false, Git clean will refuse to delete files or directories unless given -f, -n, or -i. Git will refuse to delete directories within the .git subdirectory or file, unless a second -f is given.\n\nShare\nImprove this answer\nFollow\nedited Jul 14 '20 at 21:07\nErikMD\n7,9501\n1 gold badge\n14\n14 silver badges\n41\n41 bronze badges\nanswered Apr 28 '16 at 19:46\nMartin G\n14.6k9\n9 gold badges\n72\n72 silver badges\n84\n84 bronze badges","comments":["+1 for this solution. Regarding your remark that \"git checkout . needs to be done in the root of the repo\", maybe you might mention we can just do git reset --hard instead? (which is actually equivalent to git reset --hard HEAD and should work whichever is the current directory...)","Also regarding the first command git clean -dfx, here is a tip I use to be on the safe side before running it: just run git clean -d -x -n before, to display the list of files-to-be-removed, then confirm the operation by running git clean -d -x -f (I put the argument -n, resp. -f in the end to be able to quickly change it in a terminal)","Quick note that this is unreversable, and if you have files in .gitignore you will lose them. So consider backing up your project before this.","@MartinG I just took the opportunity to incorporate my two suggestions, including the one that adds a \"dry-run\" step (as better safe than sorry!). Anyway, feel free to amend my edit if need be!"]},{"answer":"If you merely wish to remove changes to existing files, use checkout (documented here).\n\ngit checkout -- .\n\nNo branch is specified, so it checks out the current branch.\nThe double-hyphen (--) tells Git that what follows should be taken as its second argument (path), that you skipped specification of a branch.\nThe period (.) indicates all paths.\n\nIf you want to remove files added since your last commit, use clean (documented here):\n\ngit clean -i \n\nThe -i option initiates an interactive clean, to prevent mistaken deletions.\nA handful of other options are available for a quicker execution; see the documentation.\n\nIf you wish to move changes to a holding space for later access, use stash (documented here):\n\ngit stash\n\nAll changes will be moved to Git's Stash, for possible later access.\nA handful of options are available for more nuanced stashing; see the documentation.\nShare\nImprove this answer\nFollow\nanswered Mar 18 '18 at 0:19\n2540625\n9,5026\n6 gold badges\n42\n42 silver badges\n51\n51 bronze badges","comments":["This will exactly convert your changes and discard newly added files from previous commit.","will it remove the newly added files? or just undo the changes in the old unstaged files?"]},{"answer":"I really found this article helpful for explaining when to use what command: http://www.szakmeister.net/blog/2011/oct/12/reverting-changes-git/\n\nThere are a couple different cases:\n\nIf you haven't staged the file, then you use git checkout. Checkout \"updates files in the working tree to match the version in the index\". If the files have not been staged (aka added to the index)... this command will essentially revert the files to what your last commit was.\n\ngit checkout -- foo.txt\n\nIf you have staged the file, then use git reset. Reset changes the index to match a commit.\n\ngit reset -- foo.txt\n\nI suspect that using git stash is a popular choice since it's a little less dangerous. You can always go back to it if you accidently blow too much away when using git reset. Reset is recursive by default.\n\nTake a look at the article above for further advice.\n\nShare\nImprove this answer\nFollow\nedited May 13 '13 at 5:41\nfontno\n6,0844\n4 gold badges\n33\n33 silver badges\n42\n42 bronze badges\nanswered Aug 13 '12 at 21:31\nblak3r\n15.1k14\n14 gold badges\n73\n73 silver badges\n92\n92 bronze badges","comments":[]},{"answer":"The easiest way to do this is by using this command:\n\nThis command is used to discard changes in working directory -\n\ngit checkout -- .\n\n\nhttps://git-scm.com/docs/git-checkout\n\nIn git command, stashing of untracked files is achieved by using:\n\ngit stash -u\n\n\nhttp://git-scm.com/docs/git-stash\n\nShare\nImprove this answer\nFollow\nedited Oct 23 '17 at 9:30\nanswered Apr 12 '17 at 9:27\nA H M Forhadul Islam\n1,25111\n11 silver badges\n11\n11 bronze badges","comments":["Twice I've come here, read this answer, and forgotten the . at the end. To future me: the period is essential!","I needed to get rid of all local changes in a sub directory, without blowing away every other change. This answer helped a lot, thanks","Please describe what the two commands do. It's really unhelpful to have no explanation.","excellent. the checkout does in one command what the most popular one does in two. can also be followed up with git clean -fd to clean files not in the index."]},{"answer":"If you aren't interested in keeping the unstaged changes (especially if the staged changes are new files), I found this handy:\n\ngit diff | git apply --reverse\n\nShare\nImprove this answer\nFollow\nanswered Jul 28 '11 at 5:27\nJoshua Kunzmann\n9108\n8 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"As you type git status, (use \"git checkout -- ...\" to discard changes in working directory) is shown.\n\ne.g. git checkout -- .\n\nShare\nImprove this answer\nFollow\nedited Jan 7 '17 at 1:28\nDorian\n19.3k8\n8 gold badges\n111\n111 silver badges\n111\n111 bronze badges\nanswered May 17 '16 at 11:27\nErdem ÖZDEMİR\n7557\n7 silver badges\n6\n6 bronze badges","comments":["Downvoted because it doesn't help to quickly discard all files. The three dots indicate that you are required to list all the files. This is especially bad if you need to discard tons of files at once, eg. during a large merge after you have staged all the modifications you like to keep","Of course, the correct command is \"git checkout -- .\" a single dot. In the comment, the three dots were a grammatical thing, to indicate there are many other options that could have been used.."]},{"answer":"git checkout -f\n\nman git-checkout:\n\n-f, --force\n\nWhen switching branches, proceed even if the index or the working tree differs from HEAD. This is used to throw away local changes.\n\nWhen checking out paths from the index, do not fail upon unmerged entries; instead, unmerged entries are ignored.\n\nShare\nImprove this answer\nFollow\nanswered May 17 '14 at 2:28\nBijan\n6,1976\n6 gold badges\n30\n30 silver badges\n27\n27 bronze badges","comments":["This would discard changes in the index!! (And the OP requires to leave them as is.)"]},{"answer":"You can use git stash - if something goes wrong, you can still revert from the stash. Similar to some other answer here, but this one also removes all unstaged files and also all unstaged deletes:\n\ngit add .\ngit stash\n\n\nif you check that everything is OK, throw the stash away:\n\ngit stash drop\n\n\nThe answer from Bilal Maqsood with git clean also worked for me, but with the stash I have more control - if I do sth accidentally, I can still get my changes back\n\nUPDATE\n\nI think there is 1 more change (don't know why this worked for me before):\n\ngit add . -A instead of git add .\n\nwithout the -A the removed files will not be staged\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '15 at 8:37\nanswered Sep 11 '15 at 11:59\nAsped\n2,9933\n3 gold badges\n29\n29 silver badges\n51\n51 bronze badges","comments":[]},{"answer":"Instead of discarding changes, I reset my remote to the origin. Note - this method is to completely restore your folder to that of the repo.\n\nSo I do this to make sure they don't sit there when I git reset (later - excludes gitignores on the Origin/branchname)\n\nNOTE: If you want to keep files not yet tracked, but not in GITIGNORE you may wish to skip this step, as it will Wipe these untracked files not found on your remote repository (thanks @XtrmJosh).\n\ngit add --all\n\n\nThen I\n\ngit fetch --all\n\n\nThen I reset to origin\n\ngit reset --hard origin/branchname\n\n\nThat will put it back to square one. Just like RE-Cloning the branch, WHILE keeping all my gitignored files locally and in place.\n\nUpdated per user comment below: Variation to reset the to whatever current branch the user is on.\n\ngit reset --hard @{u}\n\nShare\nImprove this answer\nFollow\nedited Jan 21 '16 at 18:04\nanswered Aug 7 '15 at 21:15\nNick\n1,14110\n10 silver badges\n21\n21 bronze badges","comments":["This is my preferred option, but why do you add all changes first? So far as I'm aware this just modifies the directory listing in Git files, while using git reset --hard, this will be lost anyway while the directories will still be removed.","I dont on mac or linux, github windows powershell sometimes leaves the files there after reset. I think its because git reset sets all files in the repo to its original state. If theyre not added, theyre not touched. The desktop client then will pickup the \"hey this file is in here and needs to be committed\"","Sense made. I don't use Windows so haven't seen that issue (haven't used Windows for the last few months at least, don't remember much before that - it's one huge regrettable blur). Might be worth noting the rationale in your main answer :)","I ran across this issue on a Mac too now. If the file is not tracked in the Repo sometimes git reset doesnt touch it. I cant really isolate the \"WHY\" but when that happens, if I reset, and i still have 1 uncommitted file or two, i add --all and reset --hard again","A nice little variation of this I like is git reset --hard @{u} which resets the branch to wherever the current remote-tracking branch is"]},{"answer":"Tried all the solutions above but still couldn't get rid of new, unstaged files.\n\nUse git clean -f to remove those new files - with caution though! Note the force option.\n\nShare\nImprove this answer\nFollow\nanswered Oct 14 '11 at 21:07\nartur\n8501\n1 gold badge\n9\n9 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"To do a permanent discard: git reset --hard\n\nTo save changes for later: git stash\n\nShare\nImprove this answer\nFollow\nedited Sep 19 '19 at 20:42\nsiddhantsomani\n92411\n11 silver badges\n12\n12 bronze badges\nanswered Jul 3 '19 at 12:41\nSANGEETHA P.H.\n7598\n8 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"Just use:\n\ngit stash -u\n\n\nDone. Easy.\n\nIf you really care about your stash stack then you can follow with git stash drop. But at that point you're better off using (from Mariusz Nowak):\n\ngit checkout -- .\ngit clean -df\n\n\nNonetheless, I like git stash -u the best because it \"discards\" all tracked and untracked changes in just one command. Yet git checkout -- . only discards tracked changes, and git clean -df only discards untracked changes... and typing both commands is far too much work :)\n\nShare\nImprove this answer\nFollow\nanswered Sep 8 '16 at 6:19\nBen Wilde\n5,0442\n2 gold badges\n35\n35 silver badges\n34\n34 bronze badges","comments":["Note: git stash -u will soon (Git 2.14.x/2.15, Q3 2017) evolve a bit: stackoverflow.com/a/46027357/6309","If i get the question of the OP correct the indexed files should be kept. Only unstage changes should be removed. So is should be git stash -k in my opinion."]},{"answer":"simply say\n\ngit stash\n\n\nIt will remove all your local changes. You also can use later by saying\n\ngit stash apply \n\n\nor git stash pop\n\nShare\nImprove this answer\nFollow\nedited Jun 30 '15 at 22:12\nDrB\n1751\n1 gold badge\n2\n2 silver badges\n14\n14 bronze badges\nanswered Apr 24 '15 at 12:19\npiyushmandovra\n3,7232\n2 gold badges\n17\n17 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"you have a very simple git command git checkout .\n\nShare\nImprove this answer\nFollow\nanswered Aug 27 '19 at 7:58\nKhem Raj Regmi\n1,52414\n14 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"This works even in directories that are; outside of normal git permissions.\n\nsudo chmod -R 664 ./* && git checkout -- . && git clean -dfx\n\n\nHappened to me recently\n\nShare\nImprove this answer\nFollow\nedited Sep 28 '15 at 13:29\nanswered Sep 5 '13 at 9:38\nGlassGhost\n13.7k5\n5 gold badges\n27\n27 silver badges\n42\n42 bronze badges","comments":["Beware though, that the git ignored content will not retain it's original permissions! Hence it can cause a security risk.","@twicejr You're wrong, please read git help clean \"-d Remove untracked directories in addition to untracked files.\"","Why did you set all your files to be world read/write? Not good practice.","@Ghoti my bad, 664 is correct? you're also welcome to edit the answer.","Setting all permissions to 664 makes a lot of assumptions about what kind of permissions the project needs. I think using that part of the command will cause issues for some people."]},{"answer":"cd path_to_project_folder  # take you to your project folder/working directory \ngit checkout .             # removes all unstaged changes in working directory\n\nShare\nImprove this answer\nFollow\nedited May 31 '14 at 10:04\nanswered May 30 '14 at 9:26\nvivekporwal04\n4053\n3 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"No matter what state your repo is in you can always reset to any previous commit:\n\ngit reset --hard <commit hash>\n\n\nThis will discard all changes which were made after that commit.\n\nShare\nImprove this answer\nFollow\nedited Jan 29 '18 at 16:29\njdgregson\n1,27714\n14 silver badges\n28\n28 bronze badges\nanswered Feb 5 '16 at 0:59\nmsangel\n8,9283\n3 gold badges\n45\n45 silver badges\n64\n64 bronze badges","comments":["This will also discard everything in the index (not just things not in the index), which is beyond what the OP is asking for."]},{"answer":"In my opinion,\n\ngit clean -df\n\n\nshould do the trick. As per Git documentation on git clean\n\ngit-clean - Remove untracked files from the working tree\n\nDescription\n\nCleans the working tree by recursively removing files that are not under version control, starting from the current directory.\n\nNormally, only files unknown to Git are removed, but if the -x option is specified, ignored files are also removed. This can, for example, be useful to remove all build products.\n\nIf any optional ... arguments are given, only those paths are affected.\n\nOptions\n\n-d Remove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use -f option twice if you really want to remove such a directory.\n\n-f --force If the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or -i.\n\nShare\nImprove this answer\nFollow\nanswered Jul 14 '16 at 7:03\nLahiru\n1,5324\n4 gold badges\n31\n31 silver badges\n30\n30 bronze badges","comments":[]},{"answer":"Another way to get rid of new files that is more specific than git clean -df (it will allow you to get rid of some files not necessarily all), is to add the new files to the index first, then stash, then drop the stash.\n\nThis technique is useful when, for some reason, you can't easily delete all of the untracked files by some ordinary mechanism (like rm).\n\nShare\nImprove this answer\nFollow\nanswered Jun 15 '12 at 8:55\ntjb\n10.6k8\n8 gold badges\n62\n62 silver badges\n86\n86 bronze badges","comments":[]},{"answer":"What follows is really only a solution if you are working with a fork of a repository where you regularly synchronize (e.g. pull request) with another repo. Short answer: delete fork and refork, but read the warnings on github.\n\nI had a similar problem, perhaps not identical, and I'm sad to say my solution is not ideal, but it is ultimately effective.\n\nI would often have git status messages like this (involving at least 2/4 files):\n\n$ git status\n# Not currently on any branch.\n# Changes to be committed:\n#   (use \"git reset HEAD <file>...\" to unstage)\n#\n#       modified:   doc/PROJECT/MEDIUM/ATS-constraint/constraint_s2var.dats\n#       modified:   doc/PROJECT/MEDIUM/ATS-constraint/parsing/parsing_s2var.dats\n#\n# Changes not staged for commit:\n#   (use \"git add <file>...\" to update what will be committed)\n#   (use \"git checkout -- <file>...\" to discard changes in working directory)\n#\n#       modified:   doc/PROJECT/MEDIUM/ATS-constraint/constraint_s2Var.dats\n#       modified:   doc/PROJECT/MEDIUM/ATS-constraint/parsing/parsing_s2Var.dats\n\n\nA keen eye will note that these files have dopplegangers that are a single letter in case off. Somehow, and I have no idea what led me down this path to start with (as I was not working with these files myself from the upstream repo), I had switched these files. Try the many solutions listed on this page (and other pages) did not seem to help.\n\nI was able to fix the problem by deleting my forked repository and all local repositories, and reforking. This alone was not enough; upstream had to rename the files in question to new filenames. As long as you don't have any uncommited work, no wikis, and no issues that diverge from the upstream repository, you should be just fine. Upstream may not be very happy with you, to say the least. As for my problem, it is undoubtedly a user error as I'm not that proficient with git, but the fact that it is far from easy to fix points to an issue with git as well.\n\nShare\nImprove this answer\nFollow\nedited Jan 13 '14 at 16:42\nanswered Jan 5 '14 at 4:53\nbbarker\n8,3135\n5 gold badges\n30\n30 silver badges\n46\n46 bronze badges","comments":[]},{"answer":"I had a weird situation where a file is always unstaged, this helps me to resolve.\n\ngit rm .gitattributes\ngit add -A\ngit reset --hard\n\nShare\nImprove this answer\nFollow\nedited Jul 18 '17 at 12:23\nVadim Kotov\n7,2918\n8 gold badges\n44\n44 silver badges\n59\n59 bronze badges\nanswered Feb 8 '17 at 11:58\nSDV\n2312\n2 silver badges\n8\n8 bronze badges","comments":[]},{"answer":"When you want to transfer a stash to someone else:\n\n# add files\ngit add .  \n# diff all the changes to a file\ngit diff --staged > ~/mijn-fix.diff\n# remove local changes \ngit reset && git checkout .\n# (later you can re-apply the diff:)\ngit apply ~/mijn-fix.diff\n\n\n[edit] as commented, it ís possible to name stashes. Well, use this if you want to share your stash ;)\n\nShare\nImprove this answer\nFollow\nedited Apr 20 '15 at 10:39\nanswered Jul 8 '13 at 15:07\ntwicejr\n1,2593\n3 gold badges\n13\n13 silver badges\n21\n21 bronze badges","comments":["Actually Git stash can have a title. For instance git stash save \"Feature X work in progress\"."]},{"answer":"You could create your own alias which describes how to do it in a descriptive way.\n\nI use the next alias to discard changes.\n\nDiscard changes in a (list of) file(s) in working tree\ndiscard = checkout --\n\n\nThen you can use it as next to discard all changes:\n\ndiscard .\n\n\nOr just a file:\n\ndiscard filename\n\n\nOtherwise, if you want to discard all changes and also the untracked files, I use a mix of checkout and clean:\n\nClean and discard changes and untracked files in working tree\ncleanout = !git clean -df && git checkout -- .\n\n\nSo the use is simple as next:\n\ncleanout\n\n\nNow is available in the next Github repo which contains a lot of aliases:\n\nhttps://github.com/GitAlias/gitalias\nShare\nImprove this answer\nFollow\nedited Jun 5 '17 at 4:51\nanswered Jun 5 '17 at 4:44\nPau\n11.6k11\n11 gold badges\n56\n56 silver badges\n85\n85 bronze badges","comments":[]}]},{"id":"762011","href":"https://stackoverflow.com/questions/762011/whats-the-difference-between-using-let-and-var","title":"What's the difference between using “let” and “var”?","description":"\n                \nECMAScript 6 introduced the let statement.\nI've heard that it's described as a local variable, but I'm still not quite sure how it behaves differently than the var keyword.\nWhat are the differences?. When should let be used instead of var?\n    ","questionComments":["ECMAScript is the standard and let is included in the 6th edition draft and will most likely be in the final specification.","See kangax.github.io/es5-compat-table/es6 for an up to date support matrix of ES6 features (including let). At the time of writing Firefox, Chrome and IE11 all support it (although I believe FF's implementation is not quite standard).","For the longest time I did not know that vars in a for loop were scoped to the function it was wrapped in. I remember figuring this out for the first time and thought it was very stupid. I do see some power though knowing now how the two could be used ffor different reason and how in some cases you might actually want to use a var in a for loop and not have it scoped to the block.","As ES6 feature support improves, the question concerning ES6 adoption shifts focus from feature support to performance differences. As such, here's a site I found benchmarking performance differences between ES6 and ES5. Keep in mind this will likely change over time as engines optimize for ES6 code.","This is a very good reading wesbos.com/javascript-scoping"],"answers":[{"answer":"Scoping rules\n\nThe main difference is scoping rules. Variables declared by var keyword are scoped to the immediate function body (hence the function scope) while let variables are scoped to the immediate enclosing block denoted by { } (hence the block scope).\n\nfunction run() {\n  var foo = \"Foo\";\n  let bar = \"Bar\";\n\n  console.log(foo, bar); // Foo Bar\n\n  {\n    var moo = \"Mooo\"\n    let baz = \"Bazz\";\n    console.log(moo, baz); // Mooo Bazz\n  }\n\n  console.log(moo); // Mooo\n  console.log(baz); // ReferenceError\n}\n\nrun();\n Run code snippetExpand snippet\n\nThe reason why let keyword was introduced to the language was function scope is confusing and was one of the main sources of bugs in JavaScript.\n\nTake a look at this example from another stackoverflow question:\n\nvar funcs = [];\n// let's create 3 functions\nfor (var i = 0; i < 3; i++) {\n  // and store them in funcs\n  funcs[i] = function() {\n    // each should log its value.\n    console.log(\"My value: \" + i);\n  };\n}\nfor (var j = 0; j < 3; j++) {\n  // and now let's run each one to see\n  funcs[j]();\n}\n Run code snippetExpand snippet\n\nMy value: 3 was output to console each time funcs[j](); was invoked since anonymous functions were bound to the same variable.\n\nPeople had to create immediately invoked functions to capture correct values from the loops but that was also hairy.\n\nHoisting\n\nWhile variables declared with var keyword are hoisted (initialized with undefined before the code is run) which means they are accessible in their enclosing scope even before they are declared:\n\nfunction run() {\n  console.log(foo); // undefined\n  var foo = \"Foo\";\n  console.log(foo); // Foo\n}\n\nrun();\n Run code snippetExpand snippet\n\nlet variables are not initialized until their definition is evaluated. Accessing them before the initialization results in a ReferenceError. Variable said to be in \"temporal dead zone\" from the start of the block until the initialization is processed.\n\nfunction checkHoisting() {\n  console.log(foo); // ReferenceError\n  let foo = \"Foo\";\n  console.log(foo); // Foo\n}\n\ncheckHoisting();\n Run code snippetExpand snippet\n\nCreating global object property\n\nAt the top level, let, unlike var, does not create a property on the global object:\n\nvar foo = \"Foo\";  // globally scoped\nlet bar = \"Bar\"; // not allowed to be globally scoped\n\nconsole.log(window.foo); // Foo\nconsole.log(window.bar); // undefined\n Run code snippetExpand snippet\n\nRedeclaration\n\nIn strict mode, var will let you re-declare the same variable in the same scope while let raises a SyntaxError.\n\n'use strict';\nvar foo = \"foo1\";\nvar foo = \"foo2\"; // No problem, 'foo1' is replaced with 'foo2'.\n\nlet bar = \"bar1\"; \nlet bar = \"bar2\"; // SyntaxError: Identifier 'bar' has already been declared\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Aug 9 at 17:38\ncommunity wiki\n\n\n36 revs, 26 users 27%\nThinkingStiff","comments":["Remember you can create block whenever you want. function() { code;{ let inBlock = 5; } code; };","So is the purpose of let statements only to free up memory when not needed in a certain block?","@NoBugs, Yes, and it is encouraged that variables are existent only where they are needed.","let block expression let (variable declaration) statement is non-standard and will be removed in future, bugzilla.mozilla.org/show_bug.cgi?id=1023609.","So, I just cannot think of any case where using var is of any use. Could someone give me an example of a situation where it's preferable to use var?"]},{"answer":"let can also be used to avoid problems with closures. It binds fresh value rather than keeping an old reference as shown in examples below.\n\nfor(var i=1; i<6; i++) {\n  $(\"#div\" + i).click(function () { console.log(i); });\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n<p>Clicking on each number will log to console:</p> \n<div id=\"div1\">1</div>\n<div id=\"div2\">2</div>\n<div id=\"div3\">3</div>\n<div id=\"div4\">4</div>\n<div id=\"div5\">5</div>\n Run code snippetExpand snippet\n\nCode above demonstrates a classic JavaScript closure problem. Reference to the i variable is being stored in the click handler closure, rather than the actual value of i.\n\nEvery single click handler will refer to the same object because there’s only one counter object which holds 6 so you get six on each click.\n\nA general workaround is to wrap this in an anonymous function and pass i as an argument. Such issues can also be avoided now by using let instead var as shown in the code below.\n\n(Tested in Chrome and Firefox 50)\n\nfor(let i=1; i<6; i++) {\n  $(\"#div\" + i).click(function () { console.log(i); });\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n<p>Clicking on each number will log to console:</p> \n<div id=\"div1\">1</div>\n<div id=\"div2\">2</div>\n<div id=\"div3\">3</div>\n<div id=\"div4\">4</div>\n<div id=\"div5\">5</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Oct 29 '19 at 8:47\nNash Bridges\n2,27613\n13 silver badges\n18\n18 bronze badges\nanswered May 27 '15 at 10:16\nGurpreet Singh\n19.4k5\n5 gold badges\n40\n40 silver badges\n56\n56 bronze badges","comments":["That is actually cool. I would expect \"i\" to be defined outside the loop body contains within brackets and to NOT form a \"closure\" around \"i\".Of course your example proves otherwise. I think it is a bit confusing from the syntax point of view but this scenario is so common it makes sense to support it in that way. Many thanks for bringing this up.","IE 11 supports let, but it alerts \"6\" for all the buttons. Do you have any source saying how let is supposed to behave?","Looks like your answer is the correct behavior: developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/…","Indeed this is a common pitfall in Javascript and now I can see why let would be really useful. Setting event listeners in a loop no longer requires an immediatelly invoked function expression for locally scoping i at each iteration.","The use of \"let\" just defers this problem. So each iteration creates a private independent block scope, but the \"i\" variable can still be corrupted by subsequent changes within the block, (granted the iterator variable is not usually changed within the block, but other declared let variables within the block may well be) and any function declared within the block can, when invoked, corrupt the value of \"i\" for other functions declared within the block because they do share the same private block scope hence the same reference to \"i\"."]},{"answer":"What's the difference between let and var?\nA variable defined using a var statement is known throughout the function it is defined in, from the start of the function. (*)\nA variable defined using a let statement is only known in the block it is defined in, from the moment it is defined onward. (**)\n\nTo understand the difference, consider the following code:\n\n// i IS NOT known here\n// j IS NOT known here\n// k IS known here, but undefined\n// l IS NOT known here\n\nfunction loop(arr) {\n    // i IS known here, but undefined\n    // j IS NOT known here\n    // k IS known here, but has a value only the second time loop is called\n    // l IS NOT known here\n\n    for( var i = 0; i < arr.length; i++ ) {\n        // i IS known here, and has a value\n        // j IS NOT known here\n        // k IS known here, but has a value only the second time loop is called\n        // l IS NOT known here\n    };\n\n    // i IS known here, and has a value\n    // j IS NOT known here\n    // k IS known here, but has a value only the second time loop is called\n    // l IS NOT known here\n\n    for( let j = 0; j < arr.length; j++ ) {\n        // i IS known here, and has a value\n        // j IS known here, and has a value\n        // k IS known here, but has a value only the second time loop is called\n        // l IS NOT known here\n    };\n\n    // i IS known here, and has a value\n    // j IS NOT known here\n    // k IS known here, but has a value only the second time loop is called\n    // l IS NOT known here\n}\n\nloop([1,2,3,4]);\n\nfor( var k = 0; k < arr.length; k++ ) {\n    // i IS NOT known here\n    // j IS NOT known here\n    // k IS known here, and has a value\n    // l IS NOT known here\n};\n\nfor( let l = 0; l < arr.length; l++ ) {\n    // i IS NOT known here\n    // j IS NOT known here\n    // k IS known here, and has a value\n    // l IS known here, and has a value\n};\n\nloop([1,2,3,4]);\n\n// i IS NOT known here\n// j IS NOT known here\n// k IS known here, and has a value\n// l IS NOT known here\n\n\nHere, we can see that our variable j is only known in the first for loop, but not before and after. Yet, our variable i is known in the entire function.\n\nAlso, consider that block scoped variables are not known before they are declared because they are not hoisted. You're also not allowed to redeclare the same block scoped variable within the same block. This makes block scoped variables less error prone than globally or functionally scoped variables, which are hoisted and which do not produce any errors in case of multiple declarations.\n\nIs it safe to use let today?\n\nSome people would argue that in the future we'll ONLY use let statements and that var statements will become obsolete. JavaScript guru Kyle Simpson wrote a very elaborate article on why he believes that won't be the case.\n\nToday, however, that is definitely not the case. In fact, we need actually to ask ourselves whether it's safe to use the let statement. The answer to that question depends on your environment:\n\nIf you're writing server-side JavaScript code (Node.js), you can safely use the let statement.\n\nIf you're writing client-side JavaScript code and use a browser based transpiler (like Traceur or babel-standalone), you can safely use the let statement, however your code is likely to be anything but optimal with respect to performance.\n\nIf you're writing client-side JavaScript code and use a Node based transpiler (like the traceur shell script or Babel), you can safely use the let statement. And because your browser will only know about the transpiled code, performance drawbacks should be limited.\n\nIf you're writing client-side JavaScript code and don't use a transpiler, you need to consider browser support.\n\nThere are still some browsers that don't support let at all :\n\nHow to keep track of browser support\n\nFor an up-to-date overview of which browsers support the let statement at the time of your reading this answer, see this Can I Use page.\n\n(*) Globally and functionally scoped variables can be initialized and used before they are declared because JavaScript variables are hoisted. This means that declarations are always much to the top of the scope.\n\n(**) Block scoped variables are not hoisted\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Feb 23 '16 at 18:35\nJohn Slegers\n39.1k17\n17 gold badges\n186\n186 silver badges\n155\n155 bronze badges","comments":["regarding answer v4: i IS known everywhere in the function-block! It starts as undefined (due to hoisting) until you assign a value! ps: let is also hoisted (to the top of it's containing block), but will give a ReferenceError when referenced in the block before first assignment. (ps2: I'm a pro-semicolon kinda guy but you really don't need a semicolon after a block ). That being said, thanks for adding the reality-check regarding support!","@GitaarLAB : According to the Mozilla Developer Network : \"In ECMAScript 2015, let bindings are not subject to Variable Hoisting, which means that let declarations do not move to the top of the current execution context.\" - Anyway, I made a few improvements to my answer that should clarify the difference in hoisting behavior between let and var!","Your answer improved a lot (I thoroughly checked). Note that same link you referenced in your comment also says: \"The (let) variable is in a \"temporal dead zone\" from the start of the block until the initialization is processed.\" That means that the 'identifier' (the text-string 'reserved' to point to 'something') is already reserved in the relevant scope, otherwise it would become part of the root/host/window scope. To me personally, 'hoisting' means nothing more than reserving/linking declared 'identifiers' to their relevant scope; excluding their initialization/assignment/modifyability!","And..+1. That Kyle Simpson article you linked is an excellent read, thank you for that! It is also clear about the \"temporal dead zone\" aka \"TDZ\". One interesting thing I'd like to add: I've read on MDN that let and const were recommended to only use when you actually need their additional functionality, because enforcing/checking these extra features (like write-only const) result in 'more work' (and additional scope-nodes in the scope-tree) for the (current)engine(s) to enforce/check/verify/setup.","Note that MDN says that IE DOES interpret let correctly. Which is it? developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/…"]},{"answer":"Here's an explanation of the let keyword with some examples.\n\nlet works very much like var. The main difference is that the scope of a var variable is the entire enclosing function\n\nThis table on Wikipedia shows which browsers support Javascript 1.7.\n\nNote that only Mozilla and Chrome browsers support it. IE, Safari, and potentially others don't.\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '19 at 2:52\nJack Bashford\n38.9k10\n10 gold badges\n37\n37 silver badges\n68\n68 bronze badges\nanswered Apr 17 '09 at 20:11\nBen S\n65.9k30\n30 gold badges\n165\n165 silver badges\n210\n210 bronze badges","comments":["The key bit of text from the linked document seems to be, \"let works very much like var. The main difference is that the scope of a var variable is the entire enclosing function\".","@olliej, actually Mozilla is just ahead of the game. See page 19 of ecma-international.org/publications/files/ECMA-ST/Ecma-262.pdf","@TylerCrompton that's just the set of words that have been reserved for years. When mozilla added let it was purely a mozilla extension, with no related spec. ES6 should define behaviour for let statements, but that came after mozilla introduced the syntax. Remember moz also has E4X, which is entirely dead and moz only.","IE11 added support for let msdn.microsoft.com/en-us/library/ie/dn342892%28v=vs.85%29.aspx","Now let support all latest browser today except Opera, Blackberry & QQ Browsers."]},{"answer":"The accepted answer is missing a point:\n\n{\n  let a = 123;\n};\n\nconsole.log(a); // ReferenceError: a is not defined\n\nShare\nImprove this answer\nFollow\nedited Jul 14 '16 at 14:13\nWilliam\n3937\n7 silver badges\n20\n20 bronze badges\nanswered Jun 2 '15 at 20:59\nLcf.vs\n1,5691\n1 gold badge\n10\n10 silver badges\n14\n14 bronze badges","comments":["The accepted answer does NOT explain this point in its example. The accepted answer only demonstrated it in a for loop initializer, dramatically narrowing the scope of application of the limitations of let. Upvoted.","@stimpy77 It explicitly states \"let is scoped to the nearest enclosing block\"; does every way that manifests need to be included?","there were a lot of examples and none of them properly demonstrated the matter .. I might've upvoted both the accepted answer and this one?","This contribution demonstrates that a \"block\" can simply be a set of lines enclosed in brackets; i.e. it doesn't need to be associated with any sort of control flow, loop, etc.","Worth +9999 but I can't give it..."]},{"answer":"let\nBlock scope\n\nVariables declared using the let keyword are block-scoped, which means that they are available only in the block in which they were declared.\n\nAt the top level (outside of a function)\n\nAt the top level, variables declared using let don't create properties on the global object.\n\nvar globalVariable = 42;\nlet blockScopedVariable = 43;\n\nconsole.log(globalVariable); // 42\nconsole.log(blockScopedVariable); // 43\n\nconsole.log(this.globalVariable); // 42\nconsole.log(this.blockScopedVariable); // undefined\n\nInside a function\n\nInside a function (but outside of a block), let has the same scope as var.\n\n(() => {\n  var functionScopedVariable = 42;\n  let blockScopedVariable = 43;\n\n  console.log(functionScopedVariable); // 42\n  console.log(blockScopedVariable); // 43\n})();\n\nconsole.log(functionScopedVariable); // ReferenceError: functionScopedVariable is not defined\nconsole.log(blockScopedVariable); // ReferenceError: blockScopedVariable is not defined\n\nInside a block\n\nVariables declared using let inside a block can't be accessed outside that block.\n\n{\n  var globalVariable = 42;\n  let blockScopedVariable = 43;\n  console.log(globalVariable); // 42\n  console.log(blockScopedVariable); // 43\n}\n\nconsole.log(globalVariable); // 42\nconsole.log(blockScopedVariable); // ReferenceError: blockScopedVariable is not defined\n\nInside a loop\n\nVariables declared with let in loops can be referenced only inside that loop.\n\nfor (var i = 0; i < 3; i++) {\n  var j = i * 2;\n}\nconsole.log(i); // 3\nconsole.log(j); // 4\n\nfor (let k = 0; k < 3; k++) {\n  let l = k * 2;\n}\nconsole.log(typeof k); // undefined\nconsole.log(typeof l); // undefined\n// Trying to do console.log(k) or console.log(l) here would throw a ReferenceError.\n\nLoops with closures\n\nIf you use let instead of var in a loop, with each iteration you get a new variable. That means that you can safely use a closure inside a loop.\n\n// Logs 3 thrice, not what we meant.\nfor (var i = 0; i < 3; i++) {\n  setTimeout(() => console.log(i), 0);\n}\n\n// Logs 0, 1 and 2, as expected.\nfor (let j = 0; j < 3; j++) {\n  setTimeout(() => console.log(j), 0);\n}\n\nTemporal dead zone\n\nBecause of the temporal dead zone, variables declared using let can't be accessed before they are declared. Attempting to do so throws an error.\n\nconsole.log(noTDZ); // undefined\nvar noTDZ = 43;\nconsole.log(hasTDZ); // ReferenceError: hasTDZ is not defined\nlet hasTDZ = 42;\n\nNo re-declaring\n\nYou can't declare the same variable multiple times using let. You also can't declare a variable using let with the same identifier as another variable which was declared using var.\n\nvar a;\nvar a; // Works fine.\n\nlet b;\nlet b; // SyntaxError: Identifier 'b' has already been declared\n\nvar c;\nlet c; // SyntaxError: Identifier 'c' has already been declared\n\nconst\n\nconst is quite similar to let—it's block-scoped and has TDZ. There are, however, two things which are different.\n\nNo re-assigning\n\nVariable declared using const can't be re-assigned.\n\nconst a = 42;\na = 43; // TypeError: Assignment to constant variable.\n\n\nNote that it doesn't mean that the value is immutable. Its properties still can be changed.\n\nconst obj = {};\nobj.a = 42;\nconsole.log(obj.a); // 42\n\n\nIf you want to have an immutable object, you should use Object.freeze().\n\nInitializer is required\n\nYou always must specify a value when declaring a variable using const.\n\nconst a; // SyntaxError: Missing initializer in const declaration\n\nShare\nImprove this answer\nFollow\nedited Oct 25 '18 at 20:54\nketchupisred\n6313\n3 silver badges\n16\n16 bronze badges\nanswered Nov 23 '16 at 22:52\nMichał Perłakowski\n73.6k24\n24 gold badges\n140\n140 silver badges\n158\n158 bronze badges","comments":["This is very clear explanation about declaration in JS ... And suddenly realized where is my problem in one of the for loops :-|"]},{"answer":"In most basic terms,\nfor (let i = 0; i < 5; i++) {\n  // i accessible ✔️\n}\n// i not accessible ❌\n\nfor (var i = 0; i < 5; i++) {\n  // i accessible ✔️\n}\n// i accessible ✔️\n\n\n⚡️ Sandbox to play around ↓\n\nShare\nImprove this answer\nFollow\nanswered May 11 '20 at 17:04\nHasan Sefa Ozalp\n2,86721\n21 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"Here is an example for the difference between the two (support just started for chrome):\n\n\nAs you can see the var j variable is still having a value outside of the for loop scope (Block Scope), but the let i variable is undefined outside of the for loop scope.\n\n\"use strict\";\nconsole.log(\"var:\");\nfor (var j = 0; j < 2; j++) {\n  console.log(j);\n}\n\nconsole.log(j);\n\nconsole.log(\"let:\");\nfor (let i = 0; i < 2; i++) {\n  console.log(i);\n}\n\nconsole.log(i);\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 5 '19 at 12:03\nanswered Mar 6 '15 at 10:41\nvlio20\n7,94816\n16 gold badges\n86\n86 silver badges\n163\n163 bronze badges","comments":["What tool am I looking at here?","As a developer of desktop applets for Cinnamon, I haven't been exposed to such shiny tools."]},{"answer":"The main difference is the scope difference, while let can be only available inside the scope it's declared, like in for loop, var can be accessed outside the loop for example. From the documentation in MDN (examples also from MDN):\n\nlet allows you to declare variables that are limited in scope to the block, statement, or expression on which it is used. This is unlike the var keyword, which defines a variable globally, or locally to an entire function regardless of block scope.\n\nVariables declared by let have as their scope the block in which they are defined, as well as in any contained sub-blocks. In this way, let works very much like var. The main difference is that the scope of a var variable is the entire enclosing function:\n\nfunction varTest() {\n  var x = 1;\n  if (true) {\n    var x = 2;  // same variable!\n    console.log(x);  // 2\n  }\n  console.log(x);  // 2\n}\n\nfunction letTest() {\n  let x = 1;\n  if (true) {\n    let x = 2;  // different variable\n    console.log(x);  // 2\n  }\n  console.log(x);  // 1\n}`\n\n\nAt the top level of programs and functions, let, unlike var, does not create a property on the global object. For example:\n\nvar x = 'global';\nlet y = 'global';\nconsole.log(this.x); // \"global\"\nconsole.log(this.y); // undefined\n\n\nWhen used inside a block, let limits the variable's scope to that block. Note the difference between var whose scope is inside the function where it is declared.\n\nvar a = 1;\nvar b = 2;\n\nif (a === 1) {\n  var a = 11; // the scope is global\n  let b = 22; // the scope is inside the if-block\n\n  console.log(a);  // 11\n  console.log(b);  // 22\n} \n\nconsole.log(a); // 11\nconsole.log(b); // 2\n\n\nAlso don't forget it's ECMA6 feature, so it's not fully supported yet, so it's better always transpiles it to ECMA5 using Babel etc... for more info about visit babel website\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '19 at 7:03\nanswered Mar 22 '17 at 14:39\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":["I don't know if that last example is accurate. Because by calling it not from a function but a direct command line its still considered part of the same function. So, if you called it from outside of a function, it shouldn't behave in the same way."]},{"answer":"There are some subtle differences — let scoping behaves more like variable scoping does in more or less any other languages.\n\ne.g. It scopes to the enclosing block, They don't exist before they're declared, etc.\n\nHowever it's worth noting that let is only a part of newer Javascript implementations and has varying degrees of browser support.\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '19 at 2:53\nJack Bashford\n38.9k10\n10 gold badges\n37\n37 silver badges\n68\n68 bronze badges\nanswered Apr 17 '09 at 21:38\nolliej\n33.1k8\n8 gold badges\n56\n56 silver badges\n54\n54 bronze badges","comments":["It's also worth noting that ECMAScript is the standard and let is included in the 6th edition draft and will most likely be in the final specification.","That's the difference 3 years makes :D","Just stubled across this question and in 2012 it is still the case that only Mozilla browsers support let. Safari, IE, and Chome all don't.","The idea of accidentally creating partial block scope on accident is a good point, beware, let does not hoist, to use a variable defined by a let defined at the top of your block. If you have an if statement that is more than just a few lines of code, you may forget that you cannot use that variable until after it is defined. GREAT POINT!!!","@EricB: yes and no: \"In ECMAScript 2015, let will hoist the variable to the top of the block. However, referencing the variable in the block before the variable declaration results in a ReferenceError (my note: instead of good old undefined). The variable is in a 'temporal dead zone' from the start of the block until the declaration is processed.\" Same goes for \"switch statements because there is only one underlying block\". Source: developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/…"]},{"answer":"Variable Not Hoisting\n\nlet will not hoist to the entire scope of the block they appear in. By contrast, var could hoist as below.\n\n{\n   console.log(cc); // undefined. Caused by hoisting\n   var cc = 23;\n}\n\n{\n   console.log(bb); // ReferenceError: bb is not defined\n   let bb = 23;\n}\n\n\nActually, Per @Bergi, Both var and let are hoisted.\n\nGarbage Collection\n\nBlock scope of let is useful relates to closures and garbage collection to reclaim memory. Consider,\n\nfunction process(data) {\n    //...\n}\n\nvar hugeData = { .. };\n\nprocess(hugeData);\n\nvar btn = document.getElementById(\"mybutton\");\nbtn.addEventListener( \"click\", function click(evt){\n    //....\n});\n\n\nThe click handler callback does not need the hugeData variable at all. Theoretically, after process(..) runs, the huge data structure hugeData could be garbage collected. However, it's possible that some JS engine will still have to keep this huge structure, since the click function has a closure over the entire scope.\n\nHowever, the block scope can make this huge data structure to garbage collected.\n\nfunction process(data) {\n    //...\n}\n\n{ // anything declared inside this block can be garbage collected\n    let hugeData = { .. };\n    process(hugeData);\n}\n\nvar btn = document.getElementById(\"mybutton\");\nbtn.addEventListener( \"click\", function click(evt){\n    //....\n});\n\n\nlet loops\n\nlet in the loop can re-binds it to each iteration of the loop, making sure to re-assign it the value from the end of the previous loop iteration. Consider,\n\n// print '5' 5 times\nfor (var i = 0; i < 5; ++i) {\n    setTimeout(function () {\n        console.log(i);\n    }, 1000);  \n}\n\n\nHowever, replace var with let\n\n// print 1, 2, 3, 4, 5. now\nfor (let i = 0; i < 5; ++i) {\n    setTimeout(function () {\n        console.log(i);\n    }, 1000);  \n}\n\n\nBecause let create a new lexical environment with those names for a) the initialiser expression b) each iteration (previosly to evaluating the increment expression), more details are here.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Jan 17 '16 at 15:11\nzangw\n34.7k17\n17 gold badges\n132\n132 silver badges\n157\n157 bronze badges","comments":["Yip they are hoisted, but behave as if not hoisted because of the (drum roll) Temporal Dead Zone - a very dramatic name for an identifier not being accessible until it's declared:-)","So let is hoisted, but unavailable? How is that different than 'not hoisted'?","Hopefully Brian or Bergi come back to answer this. Is the declaration of let hoisted, but not the assignment? Thanks!","@N-ate, Here is one post of Bergi, maybe you can find answer in it.","It's interesting it is even called hoisting when it comes to let. I get that technically the parsing engine is pre-capturing it, but for all intents and purposes a programmer should treat it as if it doesn't exist. The hoisting of var on the other hand has implications to a programmer."]},{"answer":"The difference is in the scope of the variables declared with each.\n\nIn practice, there are a number of useful consequences of the difference in scope:\n\nlet variables are only visible in their nearest enclosing block ({ ... }).\nlet variables are only usable in lines of code that occur after the variable is declared (even though they are hoisted!).\nlet variables may not be redeclared by a subsequent var or let.\nGlobal let variables are not added to the global window object.\nlet variables are easy to use with closures (they do not cause race conditions).\n\nThe restrictions imposed by let reduce the visibility of the variables and increase the likelihood that unexpected name collisions will be found early. This makes it easier to track and reason about variables, including their reachability(helping with reclaiming unused memory).\n\nConsequently, let variables are less likely to cause problems when used in large programs or when independently-developed frameworks are combined in new and unexpected ways.\n\nvar may still be useful if you are sure you want the single-binding effect when using a closure in a loop (#5) or for declaring externally-visible global variables in your code (#4). Use of var for exports may be supplanted if export migrates out of transpiler space and into the core language.\n\nExamples\n\n1. No use outside nearest enclosing block: This block of code will throw a reference error because the second use of x occurs outside of the block where it is declared with let:\n\n{\n    let x = 1;\n}\nconsole.log(`x is ${x}`);  // ReferenceError during parsing: \"x is not defined\".\n\n\nIn contrast, the same example with var works.\n\n2. No use before declaration:\nThis block of code will throw a ReferenceError before the code can be run because x is used before it is declared:\n\n{\n    x = x + 1;  // ReferenceError during parsing: \"x is not defined\".\n    let x;\n    console.log(`x is ${x}`);  // Never runs.\n}\n\n\nIn contrast, the same example with var parses and runs without throwing any exceptions.\n\n3. No redeclaration: The following code demonstrates that a variable declared with let may not be redeclared later:\n\nlet x = 1;\nlet x = 2;  // SyntaxError: Identifier 'x' has already been declared\n\n\n4. Globals not attached to window:\n\nvar button = \"I cause accidents because my name is too common.\";\nlet link = \"Though my name is common, I am harder to access from other JS files.\";\nconsole.log(link);  // OK\nconsole.log(window.link);  // undefined (GOOD!)\nconsole.log(window.button);  // OK\n\n\n5. Easy use with closures: Variables declared with var do not work well with closures inside loops. Here is a simple loop that outputs the sequence of values that the variable i has at different points in time:\n\nfor (let i = 0; i < 5; i++) {\n    console.log(`i is ${i}`), 125/*ms*/);\n}\n\n\nSpecifically, this outputs:\n\ni is 0\ni is 1\ni is 2\ni is 3\ni is 4\n\n\nIn JavaScript we often use variables at a significantly later time than when they are created. When we demonstrate this by delaying the output with a closure passed to setTimeout:\n\nfor (let i = 0; i < 5; i++) {\n    setTimeout(_ => console.log(`i is ${i}`), 125/*ms*/);\n}\n\n\n... the output remains unchanged as long as we stick with let. In contrast, if we had used var i instead:\n\nfor (var i = 0; i < 5; i++) {\n    setTimeout(_ => console.log(`i is ${i}`), 125/*ms*/);\n}\n\n\n... the loop unexpectedly outputs \"i is 5\" five times:\n\ni is 5\ni is 5\ni is 5\ni is 5\ni is 5\n\nShare\nImprove this answer\nFollow\nedited May 22 '17 at 1:21\nanswered May 22 '17 at 1:09\nmormegil\n1,6421\n1 gold badge\n19\n19 silver badges\n22\n22 bronze badges","comments":["#5 is not caused by a race condition. By using var instead of let, the code is equivalent to: var i = 0; while (i < 5) { doSomethingLater(); i++; } i is outside the closure, and by the time that doSomethingLater() is executed, i has already been incremented 5 times, hence the output is i is 5 five times. By using let, the variable i is within the closure, so each async call gets its own copy of i instead of using the 'global' one that's created with var.","@DanielT.: I don't think the transformation of lifting the variable definition out of the loop initializer explains anything. That is simply the normal definition of the semantics of for. A more accurate transformation, though more complicated, is the classical for (var i = 0; i < 5; i++) { (function(j) { setTimeout(_ => console.log(i is ${j}), 125/*ms*/); })(i); } which introduces a \"function-activation record\" to save each value of i with the name of j inside the function.","How does this work? console.log(i is ${i}), 125/*ms*/);. Especially after the comma? I couldn't really get it."]},{"answer":"Here's an example to add on to what others have already written. Suppose you want to make an array of functions, adderFunctions, where each function takes a single Number argument and returns the sum of the argument and the function's index in the array. Trying to generate adderFunctions with a loop using the var keyword won't work the way someone might naïvely expect:\n\n// An array of adder functions.\nvar adderFunctions = [];\n\nfor (var i = 0; i < 1000; i++) {\n  // We want the function at index i to add the index to its argument.\n  adderFunctions[i] = function(x) {\n    // What is i bound to here?\n    return x + i;\n  };\n}\n\nvar add12 = adderFunctions[12];\n\n// Uh oh. The function is bound to i in the outer scope, which is currently 1000.\nconsole.log(add12(8) === 20); // => false\nconsole.log(add12(8) === 1008); // => true\nconsole.log(i); // => 1000\n\n// It gets worse.\ni = -8;\nconsole.log(add12(8) === 0); // => true\n\n\nThe process above doesn't generate the desired array of functions because i's scope extends beyond the iteration of the for block in which each function was created. Instead, at the end of the loop, the i in each function's closure refers to i's value at the end of the loop (1000) for every anonymous function in adderFunctions. This isn't what we wanted at all: we now have an array of 1000 different functions in memory with exactly the same behavior. And if we subsequently update the value of i, the mutation will affect all the adderFunctions.\n\nHowever, we can try again using the let keyword:\n\n// Let's try this again.\n// NOTE: We're using another ES6 keyword, const, for values that won't\n// be reassigned. const and let have similar scoping behavior.\nconst adderFunctions = [];\n\nfor (let i = 0; i < 1000; i++) {\n  // NOTE: We're using the newer arrow function syntax this time, but \n  // using the \"function(x) { ...\" syntax from the previous example \n  // here would not change the behavior shown.\n  adderFunctions[i] = x => x + i;\n}\n\nconst add12 = adderFunctions[12];\n\n// Yay! The behavior is as expected. \nconsole.log(add12(8) === 20); // => true\n\n// i's scope doesn't extend outside the for loop.\nconsole.log(i); // => ReferenceError: i is not defined\n\n\nThis time, i is rebound on each iteration of the for loop. Each function now keeps the value of i at the time of the function's creation, and adderFunctions behaves as expected.\n\nNow, image mixing the two behaviors and you'll probably see why it's not recommended to mix the newer let and const with the older var in the same script. Doing so can result is some spectacularly confusing code.\n\nconst doubleAdderFunctions = [];\n\nfor (var i = 0; i < 1000; i++) {\n    const j = i;\n    doubleAdderFunctions[i] = x => x + i + j;\n}\n\nconst add18 = doubleAdderFunctions[9];\nconst add24 = doubleAdderFunctions[12];\n\n// It's not fun debugging situations like this, especially when the\n// code is more complex than in this example.\nconsole.log(add18(24) === 42); // => false\nconsole.log(add24(18) === 42); // => false\nconsole.log(add18(24) === add24(18)); // => false\nconsole.log(add18(24) === 2018); // => false\nconsole.log(add24(18) === 2018); // => false\nconsole.log(add18(24) === 1033); // => true\nconsole.log(add24(18) === 1030); // => true\n\n\nDon't let this happen to you. Use a linter.\n\nNOTE: This is a teaching example intended to demonstrate the var/let behavior in loops and with function closures that would also be easy to understand. This would be a terrible way to add numbers. But the general technique of capturing data in anonymous function closures might be encountered in the real world in other contexts. YMMV.\n\nShare\nImprove this answer\nFollow\nedited Oct 9 '17 at 22:24\nanswered Aug 18 '14 at 0:58\nabroz\n3512\n2 silver badges\n7\n7 bronze badges","comments":["@aborz: Also very cool anonymous function syntax in the second example. It's just what I'm used to in C#. I've learned something today.","Correction: Technically, Arrow function syntax described here => developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/…","Actually, you don't need let value = i;. The for statement creates a lexical block."]},{"answer":"May the following two functions show the difference:\n\nfunction varTest() {\n    var x = 31;\n    if (true) {\n        var x = 71;  // Same variable!\n        console.log(x);  // 71\n    }\n    console.log(x);  // 71\n}\n\nfunction letTest() {\n    let x = 31;\n    if (true) {\n        let x = 71;  // Different variable\n        console.log(x);  // 71\n    }\n    console.log(x);  // 31\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 26 '16 at 16:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 17 '15 at 3:22\nAbdennour TOUMI\n67.7k29\n29 gold badges\n206\n206 silver badges\n212\n212 bronze badges","comments":[]},{"answer":"Function VS block scope:\n\nThe main difference between var and let is that variables declared with var are function scoped. Whereas functions declared with let are block scoped. For example:\n\nfunction testVar () {\n  if(true) {\n    var foo = 'foo';\n  }\n\n  console.log(foo);\n}\n\ntestVar();  \n// logs 'foo'\n\n\nfunction testLet () {\n  if(true) {\n    let bar = 'bar';\n  }\n\n  console.log(bar);\n}\n\ntestLet(); \n// reference error\n// bar is scoped to the block of the if statement \n\n\nvariables with var:\n\nWhen the first function testVar gets called the variable foo, declared with var, is still accessible outside the if statement. This variable foo would be available everywhere within the scope of the testVar function.\n\nvariables with let:\n\nWhen the second function testLet gets called the variable bar, declared with let, is only accessible inside the if statement. Because variables declared with let are block scoped (where a block is the code between curly brackets e.g if{} , for{}, function{}).\n\nlet variables don't get hoisted:\n\nAnother difference between var and let is variables with declared with let don't get hoisted. An example is the best way to illustrate this behavior:\n\nvariables with let don't get hoisted:\n\nconsole.log(letVar);\n\nlet letVar = 10;\n// referenceError, the variable doesn't get hoisted\n\n\nvariables with var do get hoisted:\n\nconsole.log(varVar);\n\nvar varVar = 10;\n// logs undefined, the variable gets hoisted\n\nGlobal let doesn't get attached to window:\n\nA variable declared with let in the global scope (which is code that is not in a function) doesn't get added as a property on the global window object. For example (this code is in global scope):\n\nvar bar = 5;\nlet foo  = 10;\n\nconsole.log(bar); // logs 5\nconsole.log(foo); // logs 10\n\nconsole.log(window.bar);  \n// logs 5, variable added to window object\n\nconsole.log(window.foo);\n// logs undefined, variable not added to window object\n\n\n\n\n\nWhen should let be used over var?\n\nUse let over var whenever you can because it is simply scoped more specific. This reduces potential naming conflicts which can occur when dealing with a large number of variables. var can be used when you want a global variable explicitly to be on the window object (always consider carefully if this is really necessary).\n\nShare\nImprove this answer\nFollow\nedited Sep 10 '18 at 7:39\nSuraj Rao\n28.3k10\n10 gold badges\n88\n88 silver badges\n94\n94 bronze badges\nanswered Sep 9 '18 at 13:08\nWillem van der Veen\n21.2k11\n11 gold badges\n121\n121 silver badges\n116\n116 bronze badges","comments":[]},{"answer":"let is interesting, because it allows us to do something like this:\n\n(() => {\n    var count = 0;\n\n    for (let i = 0; i < 2; ++i) {\n        for (let i = 0; i < 2; ++i) {\n            for (let i = 0; i < 2; ++i) {\n                console.log(count++);\n            }\n        }\n    }\n})();\n\n\nWhich results in counting [0, 7].\n\nWhereas\n\n(() => {\n    var count = 0;\n\n    for (var i = 0; i < 2; ++i) {\n        for (var i = 0; i < 2; ++i) {\n            for (var i = 0; i < 2; ++i) {\n                console.log(count++);\n            }\n        }\n    }\n})();\n\n\nOnly counts [0, 1].\n\nShare\nImprove this answer\nFollow\nedited Nov 26 '16 at 16:34\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 8 '16 at 0:21\nDmitry\n4,4884\n4 gold badges\n31\n31 silver badges\n46\n46 bronze badges","comments":["this is the first time i've ever seen anyone act like variable shadowing was desirable. no, the purpose of let is not to enable shadowing","purpose? it's a construct, you can use it however you please, one of the interesting ways is like this."]},{"answer":"It also appears that, at least in Visual Studio 2015, TypeScript 1.5, \"var\" allows multiple declarations of the same variable name in a block, and \"let\" doesn't.\n\nThis won't generate a compile error:\n\nvar x = 1;\nvar x = 2;\n\n\nThis will:\n\nlet x = 1;\nlet x = 2;\n\nShare\nImprove this answer\nFollow\nedited Nov 28 '16 at 9:31\nJohn Slegers\n39.1k17\n17 gold badges\n186\n186 silver badges\n155\n155 bronze badges\nanswered Aug 11 '15 at 0:35\nRDoc\n1772\n2 silver badges\n8\n8 bronze badges","comments":[]},{"answer":"ES6 introduced two new keyword(let and const) alternate to var.\n\nWhen you need a block level deceleration you can go with let and const instead of var.\n\nThe below table summarize the difference between var, let and const\n\nShare\nImprove this answer\nFollow\nedited Apr 13 at 18:50\nTylerH\n19.5k51\n51 gold badges\n65\n65 silver badges\n86\n86 bronze badges\nanswered Jan 26 '20 at 11:39\nSrikrushna\n2,8491\n1 gold badge\n30\n30 silver badges\n37\n37 bronze badges","comments":["The hoisted column is incorrect. They all hoist variable. The difference with var is that they hoist but do not initialize to the undefined value. If they did not hoist, they would not mask variables of the same name in enclosing blocks: stackoverflow.com/q/63337235/2326961"]},{"answer":"var is global scope (hoist-able) variable.\n\nlet and const is block scope.\n\ntest.js\n\n{\n    let l = 'let';\n    const c = 'const';\n    var v = 'var';\n    v2 = 'var 2';\n}\n\nconsole.log(v, this.v);\nconsole.log(v2, this.v2);\nconsole.log(l); // ReferenceError: l is not defined\nconsole.log(c); // ReferenceError: c is not defined\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nanswered Oct 28 '17 at 12:42\nMoslem Shahsavan\n92610\n10 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"When Using let\n\nThe let keyword attaches the variable declaration to the scope of whatever block (commonly a { .. } pair) it's contained in. In other words,let implicitly hijacks any block's scope for its variable declaration.\n\nlet variables cannot be accessed in the window object because they cannot be globally accessed.\n\nfunction a(){\n    { // this is the Max Scope for let variable\n        let x = 12;\n    }\n    console.log(x);\n}\na(); // Uncaught ReferenceError: x is not defined\n\n\nWhen Using var\n\nvar and variables in ES5 has scopes in functions meaning the variables are valid within the function and not outside the function itself.\n\nvar variables can be accessed in the window object because they cannot be globally accessed.\n\nfunction a(){ // this is the Max Scope for var variable\n    { \n        var x = 12;\n    }\n    console.log(x);\n}\na(); // 12\n\n\nIf you want to know more continue reading below\n\none of the most famous interview questions on scope also can suffice the exact use of let and var as below;\n\nWhen using let\n\nfor (let i = 0; i < 10 ; i++) {\n    setTimeout(\n        function a() {\n            console.log(i); //print 0 to 9, that is literally AWW!!!\n        }, \n        100 * i);\n}\n\n\nThis is because when using let, for every loop iteration the variable is scoped and has its own copy.\n\nWhen using var\n\nfor (var i = 0; i < 10 ; i++) {\n    setTimeout(\n        function a() {\n            console.log(i); //print 10 times 10\n        }, \n        100 * i);\n}\n\n\nThis is because when using var, for every loop iteration the variable is scoped and has shared copy.\n\nShare\nImprove this answer\nFollow\nedited May 22 '18 at 13:22\nanswered May 22 '18 at 13:12\nAnkur Soni\n4,7575\n5 gold badges\n32\n32 silver badges\n64\n64 bronze badges","comments":[]},{"answer":"If I read the specs right then let thankfully can also be leveraged to avoid self invoking functions used to simulate private only members - a popular design pattern that decreases code readability, complicates debugging, that adds no real code protection or other benefit - except maybe satisfying someone's desire for semantics, so stop using it. /rant\n\nvar SomeConstructor;\n\n{\n    let privateScope = {};\n\n    SomeConstructor = function SomeConstructor () {\n        this.someProperty = \"foo\";\n        privateScope.hiddenProperty = \"bar\";\n    }\n\n    SomeConstructor.prototype.showPublic = function () {\n        console.log(this.someProperty); // foo\n    }\n\n    SomeConstructor.prototype.showPrivate = function () {\n        console.log(privateScope.hiddenProperty); // bar\n    }\n\n}\n\nvar myInstance = new SomeConstructor();\n\nmyInstance.showPublic();\nmyInstance.showPrivate();\n\nconsole.log(privateScope.hiddenProperty); // error\n\n\nSee 'Emulating private interfaces'\n\nShare\nImprove this answer\nFollow\nedited Jan 12 '19 at 5:29\nanswered Oct 14 '16 at 5:01\nDaniel Sokolowski\n10.7k3\n3 gold badges\n61\n61 silver badges\n50\n50 bronze badges","comments":["Can you elaborate on how Immediately Invoked Function Expressions do not provide “code protection” and let does? (I assume you mean IIFE with “self invoking function”.)","And why do you set hiddenProperty in the constructor? There is only one hiddenProperty for all instances in your “class”."]},{"answer":"Some hacks with let:\n\n1.\n\n    let statistics = [16, 170, 10];\n    let [age, height, grade] = statistics;\n\n    console.log(height)\n\n\n2.\n\n    let x = 120,\n    y = 12;\n    [x, y] = [y, x];\n    console.log(`x: ${x} y: ${y}`);\n\n\n3.\n\n    let node = {\n                   type: \"Identifier\",\n                   name: \"foo\"\n               };\n\n    let { type, name, value } = node;\n\n    console.log(type);      // \"Identifier\"\n    console.log(name);      // \"foo\"\n    console.log(value);     // undefined\n\n    let node = {\n        type: \"Identifier\"\n    };\n\n    let { type: localType, name: localName = \"bar\" } = node;\n\n    console.log(localType);     // \"Identifier\"\n    console.log(localName);     // \"bar\"\n\nGetter and setter with let:\nlet jar = {\n    numberOfCookies: 10,\n    get cookies() {\n        return this.numberOfCookies;\n    },\n    set cookies(value) {\n        this.numberOfCookies = value;\n    }\n};\n\nconsole.log(jar.cookies)\njar.cookies = 7;\n\nconsole.log(jar.cookies)\n\nShare\nImprove this answer\nFollow\nedited Nov 26 '16 at 16:44\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 21 '16 at 17:42\nzloctb\n8,9266\n6 gold badges\n61\n61 silver badges\n78\n78 bronze badges","comments":["please what do this mean let { type, name, value } = node; ? you create a new object with 3 properties type/name/value and initialise them with the properties values from node ?","In example 3 you are re-declaring node which cause exception. These all examples also work perfectly with var too.","This doesn't answer the question; it could benefit from an explanation as to what each block of code is doing."]},{"answer":"The below shows how 'let' and 'var' are different in the scope:\n\nlet gfoo = 123;\nif (true) {\n    let gfoo = 456;\n}\nconsole.log(gfoo); // 123\n\nvar hfoo = 123;\nif (true) {\n    var hfoo = 456;\n}\nconsole.log(hfoo); // 456\n\n\nThe gfoo, defined by let initially is in the global scope, and when we declare gfoo again inside the if clause its scope changed and when a new value is assigned to the variable inside that scope it does not affect the global scope.\n\nWhereas hfoo, defined by var is initially in the global scope, but again when we declare it inside the if clause, it considers the global scope hfoo, although var has been used again to declare it. And when we re-assign its value we see that the global scope hfoo is also affected. This is the primary difference.\n\nShare\nImprove this answer\nFollow\nanswered Sep 7 '19 at 11:25\nPiklu Dey\n2001\n1 silver badge\n13\n13 bronze badges","comments":[]},{"answer":"let is a part of es6. These functions will explain the difference in easy way.\n\nfunction varTest() {\n  var x = 1;\n  if (true) {\n    var x = 2;  // same variable!\n    console.log(x);  // 2\n  }\n  console.log(x);  // 2\n}\n\nfunction letTest() {\n  let x = 1;\n  if (true) {\n    let x = 2;  // different variable\n    console.log(x);  // 2\n  }\n  console.log(x);  // 1\n}\n\nShare\nImprove this answer\nFollow\nanswered Dec 17 '17 at 10:47\nVipul Jain\n1041\n1 silver badge\n4\n4 bronze badges","comments":[]},{"answer":"let vs var. It's all about scope.\n\nvar variables are global and can be accessed basically everywhere, while let variables are not global and only exist until a closing parenthesis kills them.\n\nSee my example below, and note how the lion (let) variable acts differently in the two console.logs; it becomes out of scope in the 2nd console.log.\n\nvar cat = \"cat\";\nlet dog = \"dog\";\n\nvar animals = () => {\n    var giraffe = \"giraffe\";\n    let lion = \"lion\";\n\n    console.log(cat);  //will print 'cat'.\n    console.log(dog);  //will print 'dog', because dog was declared outside this function (like var cat).\n\n    console.log(giraffe); //will print 'giraffe'.\n    console.log(lion); //will print 'lion', as lion is within scope.\n}\n\nconsole.log(giraffe); //will print 'giraffe', as giraffe is a global variable (var).\nconsole.log(lion); //will print UNDEFINED, as lion is a 'let' variable and is now out of scope.\n\nShare\nImprove this answer\nFollow\nanswered Apr 18 '19 at 0:49\ndaCoda\n2,6324\n4 gold badges\n26\n26 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"As mentioned above:\n\nThe difference is scoping. var is scoped to the nearest function block and let is scoped to the nearest enclosing block, which can be smaller than a function block. Both are global if outside any block.Lets see an example:\n\nExample1:\n\nIn my both examples I have a function myfunc. myfunc contains a variable myvar equals to 10. In my first example I check if myvar equals to 10 (myvar==10) . If yes, I agian declare a variable myvar (now I have two myvar variables)using var keyword and assign it a new value (20). In next line I print its value on my console. After the conditional block I again print the value of myvar on my console. If you look at the output of myfunc, myvar has value equals to 20.\n\nExample2: In my second example instead of using var keyword in my conditional block I declare myvar using let keyword . Now when I call myfunc I get two different outputs: myvar=20 and myvar=10.\n\nSo the difference is very simple i.e its scope.\n\nShare\nImprove this answer\nFollow\nedited Aug 13 '18 at 14:02\nanswered Aug 7 '18 at 10:25\nN Randhawa\n6,7292\n2 gold badges\n40\n40 silver badges\n46\n46 bronze badges","comments":["Please don't post pictures of code, it's considered bad practice on SO as it will not be searchable for future users (as well as accessibility concerns). As well, this answer adds nothing that other answers haven't already addressed."]},{"answer":"I want to link these keywords to the Execution Context, because the Execution Context is important in all of this. The Execution Context has two phases: a Creation Phase and Execution Phase. In addition, each Execution Context has a Variable Environment and Outer Environment (its Lexical Environment).\n\nDuring the Creation Phase of an Execution Context, var, let and const will still store its variable in memory with an undefined value in the Variable Environment of the given Execution Context. The difference is in the Execution Phase. If you use reference a variable defined with var before it is assigned a value, it will just be undefined. No exception will be raised.\n\nHowever, you cannot reference the variable declared with let or const until it is declared. If you try to use it before it is declared, then an exception will be raised during the Execution Phase of the Execution Context. Now the variable will still be in memory, courtesy of the Creation Phase of the Execution Context, but the Engine will not allow you to use it:\n\nfunction a(){\n    b;\n    let b;\n}\na();\n> Uncaught ReferenceError: b is not defined\n\n\nWith a variable defined with var, if the Engine cannot find the variable in the current Execution Context's Variable Environment, then it will go up the scope chain (the Outer Environment) and check the Outer Environment's Variable Environment for the variable. If it cannot find it there, it will continue searching the Scope Chain. This is not the case with let and const.\n\nThe second feature of let is it introduces block scope. Blocks are defined by curly braces. Examples include function blocks, if blocks, for blocks, etc. When you declare a variable with let inside of a block, the variable is only available inside of the block. In fact, each time the block is run, such as within a for loop, it will create a new variable in memory.\n\nES6 also introduces the const keyword for declaring variables. const is also block scoped. The difference between let and const is that const variables need to be declared using an initializer, or it will generate an error.\n\nAnd, finally, when it comes to the Execution Context, variables defined with var will be attached to the 'this' object. In the global Execution Context, that will be the window object in browsers. This is not the case for let or const.\n\nShare\nImprove this answer\nFollow\nanswered Feb 13 '19 at 16:07\nDaniel Viglione\n6,2487\n7 gold badges\n43\n43 silver badges\n78\n78 bronze badges","comments":[]},{"answer":"As I am currently trying to get an in depth understanding of JavaScript I will share my brief research which contains some of the great pieces already discussed plus some other details in a different perspective.\n\nUnderstanding the difference between var and let can be easier if we understand the difference between function and block scope.\n\nLet's consider the following cases:\n\n(function timer() {\n    for(var i = 0; i <= 5; i++) {\n        setTimeout(function notime() { console.log(i); }, i * 1000);\n    }\n})();\n\n\n   Stack            VariableEnvironment //one VariablEnvironment for timer();\n                                       // when the timer is out - the value will be the same value for each call\n5. [setTimeout, i]  [i=5] \n4. [setTimeout, i]  \n3. [setTimeout, i]\n2. [setTimeout, i]\n1. [setTimeout, i]\n0. [setTimeout, i]\n\n####################    \n\n(function timer() {\n    for (let i = 0; i <= 5; i++) {\n        setTimeout(function notime() { console.log(i); }, i * 1000);\n    }\n})();\n\n   Stack           LexicalEnvironment - each iteration has a new lexical environment\n5. [setTimeout, i]  [i=5]       \n                      LexicalEnvironment \n4. [setTimeout, i]    [i=4]     \n                        LexicalEnvironment \n3. [setTimeout, i]      [i=3]       \n                         LexicalEnvironment \n2. [setTimeout, i]       [i=2]\n                           LexicalEnvironment \n1. [setTimeout, i]         [i=1]\n                             LexicalEnvironment \n0. [setTimeout, i]           [i=0]\n\n\nwhen timer() gets called an ExecutionContext is created which will contain both the VariableEnvironment and all the LexicalEnvironments corresponding to each iteration.\n\nAnd a simpler example\n\nFunction Scope\n\nfunction test() {\n    for(var z = 0; z < 69; z++) {\n        //todo\n    }\n    //z is visible outside the loop\n}\n\n\nBlock Scope\n\nfunction test() {\n    for(let z = 0; z < 69; z++) {\n        //todo\n    }\n    //z is not defined :(\n}\n\nShare\nImprove this answer\nFollow\nedited May 7 '19 at 22:47\nanswered Mar 11 '19 at 16:52\nLucian Nut\n5071\n1 gold badge\n7\n7 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"I just came across one use case that I had to use var over let to introduce new variable. Here's a case:\n\nI want to create a new variable with dynamic variable names.\n\nlet variableName = 'a';\neval(\"let \" + variableName + '= 10;');\nconsole.log(a);   // this doesn't work\n\nvar variableName = 'a';\neval(\"var \" + variableName + '= 10;');\nconsole.log(a);   // this works\n\n\nThe above code doesn't work because eval introduces a new block of code. The declaration using var will declare a variable outside of this block of code since var declares a variable in the function scope.\n\nlet, on the other hand, declares a variable in a block scope. So, a variable will only be visible in eval block.\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '20 at 20:05\nAshish Kamble\n1,5672\n2 gold badges\n19\n19 silver badges\n24\n24 bronze badges\nanswered Oct 25 '20 at 17:15\nSarvar Nishonboyev\n9,3178\n8 gold badges\n57\n57 silver badges\n56\n56 bronze badges","comments":["When will you ever have to create a dynamic variable name, and have to access it later? It is so much better to create an object and assign keys and values to it."]},{"answer":"Now I think there is better scoping of variables to a block of statements using let:\n\nfunction printnums()\n{\n    // i is not accessible here\n    for(let i = 0; i <10; i+=)\n    {\n       console.log(i);\n    }\n    // i is not accessible here\n\n    // j is accessible here\n    for(var j = 0; j <10; j++)\n    {\n       console.log(j);\n    }\n    // j is accessible here\n}\n\n\nI think people will start using let here after so that they will have similar scoping in JavaScript like other languages, Java, C#, etc.\n\nPeople with not a clear understanding about scoping in JavaScript used to make the mistake earlier.\n\nHoisting is not supported using let.\n\nWith this approach errors present in JavaScript are getting removed.\n\nRefer to ES6 In Depth: let and const to understand it better.\n\nShare\nImprove this answer\nFollow\nedited Nov 26 '16 at 16:33\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 1 '16 at 8:22\nswaraj patil\n2012\n2 silver badges\n5\n5 bronze badges","comments":["For in depth understanding on it refer link - davidwalsh.name/for-and-against-let"]}]},{"id":"417142","href":"https://stackoverflow.com/questions/417142/what-is-the-maximum-length-of-a-url-in-different-browsers","title":"What is the maximum length of a URL in different browsers?","description":"\n                \nWhat is the maximum length of a URL in different browsers? Does it differ among browsers?\nIs a maximum URL length part of the HTTP specification?\n    ","questionComments":["FWIW, for Windows users, server paths exceeding 250 characters may cause grief when building URLs, for example, see HttpContext.Current.Server.MapPath fails for long file names at forums.asp.net. bottom line: if one restriction does not get you, another one may.","From support.microsoft.com/kb/208427 \"Maximum URL length is 2,083 characters in Internet Explorer\"","May I ask why did you need to know that? I.e. what's the use-case for having a long URL?","@Lohoris: If a form uses get rather than post, then bookmarking the page reached by the filled-in form will capture the information that was entered. In some cases, that can be bad, but in other cases it can be useful. For that to work, however, the browser has to be able to handle a URL containing all the information.","@Lohoris When we write pages to generate reports we used a criteria form. It is useful on some reports to be able to email the url to someone with the criteria built in. Depending on the report we are at times forced to use post or the criteria gets truncated. Just another use case."],"answers":[{"answer":"Short answer - de facto limit of 2000 characters\n\nIf you keep URLs under 2000 characters, they'll work in virtually any combination of client and server software.\n\nIf you are targeting particular browsers, see below for more details on specific limits.\n\nLonger answer - first, the standards...\n\nRFC 2616 (Hypertext Transfer Protocol HTTP/1.1) section 3.2.1 says\n\nThe HTTP protocol does not place any a priori limit on the length of a URI. Servers MUST be able to handle the URI of any resource they serve, and SHOULD be able to handle URIs of unbounded length if they provide GET-based forms that could generate such URIs. A server SHOULD return 414 (Request-URI Too Long) status if a URI is longer than the server can handle (see section 10.4.15).\n\nThat RFC has been obsoleted by RFC7230 which is a refresh of the HTTP/1.1 specification. It contains similar language, but also goes on to suggest this:\n\nVarious ad hoc limitations on request-line length are found in practice. It is RECOMMENDED that all HTTP senders and recipients support, at a minimum, request-line lengths of 8000 octets.\n\n...and the reality\n\nThat's what the standards say. For the reality, there was an article on boutell.com (link goes to Internet Archive backup) that discussed what individual browser and server implementations will support. The executive summary is:\n\nExtremely long URLs are usually a mistake. URLs over 2,000 characters will not work in the most popular web browsers. Don't use them if you intend your site to work for the majority of Internet users.\n\n(Note: this is a quote from an article written in 2006, but in 2015 IE's declining usage means that longer URLs do work for the majority. However, IE still has the limitation...)\n\nInternet Explorer's limitations...\n\nIE8's maximum URL length is 2083 chars, and it seems IE9 has a similar limit.\n\nI've tested IE10 and the address bar will only accept 2083 chars. You can click a URL which is longer than this, but the address bar will still only show 2083 characters of this link.\n\nThere's a nice writeup on the IE Internals blog which goes into some of the background to this.\n\nThere are mixed reports IE11 supports longer URLs - see comments below. Given some people report issues, the general advice still stands.\n\nSearch engines like URLs < 2048 chars...\n\nBe aware that the sitemaps protocol, which allows a site to inform search engines about available pages, has a limit of 2048 characters in a URL. If you intend to use sitemaps, a limit has been decided for you! (see Calin-Andrei Burloiu's answer below)\n\nThere's also some research from 2010 into the maximum URL length that search engines will crawl and index. They found the limit was 2047 chars, which appears allied to the sitemap protocol spec. However, they also found the Google SERP tool wouldn't cope with URLs longer than 1855 chars.\n\nCDNs have limits\n\nCDNs also impose limits on URI length, and will return a 414 Too long request when these limits are reached, for example:\n\nFastly 8Kb\nCloudFront 8Kb\nCloudFlare 32Kb\n\n(credit to timrs2998 for providing that info in the comments)\n\nAdditional browser roundup\n\nI tested the following against an Apache 2.4 server configured with a very large LimitRequestLine and LimitRequestFieldSize.\n\nBrowser     Address bar   document.location\n                          or anchor tag\n------------------------------------------\nChrome          32779           >64k\nAndroid          8192           >64k\nFirefox          >64k           >64k\nSafari           >64k           >64k\nIE11             2047           5120\nEdge 16          2047          10240\n\n\nSee also this answer from Matas Vaitkevicius below.\n\nIs this information up to date?\n\nThis is a popular question, and as the original research is ~14 years old I'll try to keep it up to date: As of Sep 2020, the advice still stands. Even though IE11 may possibly accept longer URLs, the ubiquity of older IE installations plus the search engine limitations mean staying under 2000 chars is the best general policy.\n\nShare\nImprove this answer\nFollow\nedited Oct 17 '20 at 14:56\nanswered Jan 6 '09 at 16:22\nPaul Dixon\n281k48\n48 gold badges\n303\n303 silver badges\n336\n336 bronze badges","comments":["Note that IE11 won't bookmark URLs longer than 260 characters. I'm unsure if Edge has the same limitation.","Today IE11 cuts my URL to 2048 chars.","in Chrome in 2016 I've been able to open a url with 260300 ascii chars using the osx open command from a simple script, and could confirm that all the characters were passed through to the server. The url in the browser gets truncated to 32791 characters, concludinding with ... (%E2%80%A6%E2%80%A6)","@Paul Dixon It's really nice to see people that are willing to go above and beyond in answering questions on this site. Obviously people are showing their gratitude with the current upvote count being 3734, but I wanted to say thanks! :)","Mentioning any version of IE in 2020 update is ... strange."]},{"answer":"The longest URLs I came across are data URLs\n\nExample image URL from Google image results (11747 characters)\n\ndata:image/jpeg;base64,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\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '12 at 16:06\nSteve Konves\n2,5683\n3 gold badges\n23\n23 silver badges\n43\n43 bronze badges\nanswered Jul 18 '12 at 23:12\nCyberJunkie\n19k52\n52 gold badges\n137\n137 silver badges\n208\n208 bronze badges","comments":["He's talking about the fact that a base64 encoded jpeg is technically a URL, because it's specified as data:*. While he's correct in stating that it is a valid URL, I don't think that's what the question was asking.","... or just paste it in your address bar.","Because a data URL contains the protocol \"data:\", and the identifier, it's everything you need to LOCATE that \"file\" (even if the \"Filesystem\" is the space of all possible files). It is therefore a URL, which is also a URI. (But definitely not \"not a URL\")","@DoubleGras Google Chrome for Mac does not allow me to paste a URL that long into my address bar","Thanks for the info. I've just tested it successfully on Firefox and Chrome, Windows. So… it simply depends ;)"]},{"answer":"I wrote this test that keeps on adding 'a' to parameter until the browser fails\n\nC# part:\n\n[AcceptVerbs(HttpVerbs.Get)]\npublic ActionResult ParamTest(string x)\n{\n    ViewBag.TestLength = 0;\n    if (!string.IsNullOrEmpty(x))\n    {\n        System.IO.File.WriteAllLines(\"c:/result.txt\",\n                       new[] {Request.UserAgent, x.Length.ToString()});\n        ViewBag.TestLength = x.Length + 1;\n    }\n\n    return View();\n}\n\n\nView:\n\n<script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js\"></script>\n\n<script type=\"text/javascript\">\n    $(function() {\n        var text = \"a\";\n        for (var i = 0; i < parseInt(@ViewBag.TestLength)-1; i++) {\n            text += \"a\";\n        }\n\n        document.location.href = \"http://localhost:50766/Home/ParamTest?x=\" + text;\n    });\n</script>\n\n\nPART 1\n\nOn Chrome I got:\n\nMozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.130 Safari/537.36\n2046\n\n\nIt then blew up with:\n\nHTTP Error 404.15 - Not Found The request filtering module is configured to deny a request where the query string is too long.\n\nSame on Internet Explorer 8 and Firefox\n\nMozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET4.0C; .NET4.0E)\n2046\n\nMozilla/5.0 (Windows NT 6.1; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0\n2046\n\n\nPART 2\n\nI went easy mode and added additional limits to IISExpress applicationhost.config and web.config setting maxQueryStringLength=\"32768\".\n\nChrome failed with message 'Bad Request - Request Too Long\n\nHTTP Error 400. The size of the request headers is too long.\n\n\nafter 7744 characters.\n\nMozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.130 Safari/537.36\n7744\n\n\nPART 3\n\nAdded\n\n<headerLimits>\n    <add header=\"Content-type\" sizeLimit=\"32768\" />\n</headerLimits>\n\n\nwhich didn't help at all. I finally decided to use fiddler to remove the referrer from header.\n\nstatic function OnBeforeRequest(oSession: Session) {\n    if (oSession.url.Contains(\"localhost:50766\")) {\n        oSession.RequestHeaders.Remove(\"Referer\");\n    }\n\n\nWhich did nicely.\n\nChrome: got to 15613 characters. (I guess it's a 16K limit for IIS)\n\nAnd it failed again with:\n\n<BODY><h2>Bad Request - Request Too Long</h2>\n<hr><p>HTTP Error 400. The size of the request headers is too long.</p>\n\n\nMozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.130 Safari/537.36\n15613\n\n\nFirefox:\n\nMozilla/5.0 (Windows NT 6.1; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0\n15708\n\n\nInternet Explorer 8 failed with iexplore.exe crashing.\n\nAfter 2505\n\nMozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET4.0C; .NET4.0E)\n2505\n\n\nAndroid Emulator\n\nMozilla/5.0 (Linux; Android 5.1; Android SDK built for x86 Build/LKY45) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/39.0.0.0 Mobile Safari/537.36\n7377\n\n\nInternet Explorer 11\n\nMozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; Trident/7.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C)\n4043\n\n\nInternet Explorer 10\n\nMozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; Trident/6.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C)\n4043\n\n\nInternet Explorer 9\n\nMozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)\n4043\n\nShare\nImprove this answer\nFollow\nedited Aug 23 '18 at 9:51\nFrederik Struck-Schøning\n12.1k7\n7 gold badges\n56\n56 silver badges\n63\n63 bronze badges\nanswered Jul 6 '15 at 16:14\nMatas Vaitkevicius\n50.4k27\n27 gold badges\n214\n214 silver badges\n229\n229 bronze badges","comments":["So, in effect, my assumption of 512 chars is largely wrong ^_^ Thanks for the test. I will never care about the query param length anymore..","This should be the accepted answer... the first one doesn't actually provide hard limits for each browser which is what the questions asks for.","Might be worth looking into Safari too. Safari is the only browser that does not support client-generated downloads. The workarounds are: a) open a BLOB URI (a short, temporary URI that points to an in-memory Blob) in a new window, b) open a base-64 encoded data URI in a new window (may be very long, but supports mime typing). Details here: github.com/eligrey/FileSaver.js/issues/12","@Vaitkevicius do u know if a space(%20) is counted as one character or 3?","@Jun depends where... press F12 and paste following into the console console.log(\"%20\".length +\" \"+decodeURI(\"%20\").length) this should explain it"]},{"answer":"WWW FAQs: What is the maximum length of a URL? has its own answer based on empirical testing and research. The short answer is that going over 2048 characters makes Internet Explorer unhappy and thus this is the limit you should use. See the page for a long answer.\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '19 at 13:50\nanswered Jan 6 '09 at 16:18\nBrian\n24.6k16\n16 gold badges\n75\n75 silver badges\n163\n163 bronze badges","comments":[]},{"answer":"There is really no universal maximum URL length. The max length is determined only by what the client browser chooses to support, which varies widely. The 2,083 limit is only present in Internet Explorer (all versions up to 7.0). The max length in Firefox and Safari seems to be unlimited, although instability occurs with URLs reaching around 65,000 characters. Opera seems to have no max URL length whatsoever, and doesn't suffer instability at extremely long lengths.\n\nShare\nImprove this answer\nFollow\nanswered Aug 5 '10 at 10:17\nweb marketing strategies provi\n1,0191\n1 gold badge\n7\n7 silver badges\n2\n2 bronze badges","comments":["If the instability is around 65k it is probably right there near 65535 (2^16 - 1). Maybe they loop through chars using short i? Just a thought. I wonder what URL they tested for 65k+ o_o;;","This answers is maybe the one that should be accepted, as it provides the concrete answers: 2k for IE, 65k for Safari/Firefox, \"more\" for Opera.","I'm curious. Is the 65k URL a data scheme URI or really a URL in the classic sense?","I'd guess the instability is/was caused by API used to render the address bar. Many OS libraries cannot cope with overly long strings to be rendered on display with acceptable performance."]},{"answer":"On Apple platforms (iOS/macOS/tvOS/watchOS), the limit may be a 2 GB long URL scheme, as seen by this comment in the source code of Swift:\n\n// Make sure the URL string isn't too long.\n// We're limiting it to 2GB for backwards compatibility with 32-bit executables using NS/CFURL\nif ( (urlStringLength > 0) && (urlStringLength <= INT_MAX) )\n{\n...\n\n\nOn iOS, I've tested and confirmed that even a 300+ MB long URL is accepted. You can try such a long URL like this in Objective-C:\n\nNSString *path = [@\"a:\" stringByPaddingToLength:314572800 withString:@\"a\" startingAtIndex:0];\nNSString *js = [NSString stringWithFormat:@\"window.location.href = \\\"%@\\\";\", path];\n[self.webView stringByEvaluatingJavaScriptFromString:js];\n\n\nAnd catch if it succeed with:\n\n- (BOOL)webView:(UIWebView *)webView shouldStartLoadWithRequest:(NSURLRequest *)request navigationType:(UIWebViewNavigationType)navigationType\n{\n    NSLog(@\"length: %@\", @(request.URL.absoluteString.length));\n    return YES;\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '19 at 3:11\nanswered Jun 27 '16 at 6:49\nCœur\n33k21\n21 gold badges\n174\n174 silver badges\n235\n235 bronze badges","comments":["You sir deserve a +1 just for the effort of trying a 300MB URL","iOS isn't a browser in and of itself. Was this in Safari for iOS?","@Randall schemes are handled by the OS and then dispatched to the app that can open them. So all apps on iOS, including Safari, can handle long URI.","Thanks for the clarification. Presumably, though, this doesn't prevent an arbitrary app (say, eg, a Tor-powered browser) from introducing its own length restriction, correct?"]},{"answer":"The URI RFC (of which URLs are a subset) doesn't define a maximum length, however, it does recommend that the hostname part of the URI (if applicable) not exceed 255 characters in length:\n\nURI producers should use names that conform to the DNS syntax, even when use of DNS is not immediately apparent, and should limit these names to no more than 255 characters in length.\n\nAs noted in other posts though, some browsers have a practical limitation on the length of a URL.\n\nShare\nImprove this answer\nFollow\nanswered Jan 6 '09 at 16:20\ncasperOne\n71.3k17\n17 gold badges\n177\n177 silver badges\n240\n240 bronze badges","comments":[]},{"answer":"The HTTP 1.1 specification says:\n\nURIs in HTTP can be represented in absolute form or relative to some\nknown base URI [11], depending upon the context of their use. The two\nforms are differentiated by the fact that absolute URIs always begin\nwith a scheme name followed by a colon. For definitive information on\nURL syntax and semantics, see \"Uniform Resource Identifiers (URI): Generic Syntax and Semantics,\" RFC 2396 [42] (which replaces RFCs 1738 [4] and RFC 1808 [11]). This specification adopts the definitions of \"URI-reference\", \"absoluteURI\", \"relativeURI\", \"port\",\n\"host\",\"abs_path\", \"rel_path\", and \"authority\" from that\nspecification.\n\nThe HTTP protocol does not place any a priori limit on the length of\na URI. Servers MUST be able to handle the URI of any resource they serve, and SHOULD be able to handle URIs of unbounded length if they provide GET-based forms that could generate such URIs.* A server SHOULD return 414 (Request-URI Too Long) status if a URI is longer than the server can handle (see section 10.4.15).\n\nNote: Servers ought to be cautious about depending on URI lengths above 255 bytes, because some older client or proxy implementations might not properly support these lengths.\n\nAs mentioned by @Brian, the HTTP clients (e.g. browsers) may have their own limits, and HTTP servers will have different limits.\n\nShare\nImprove this answer\nFollow\nanswered Jan 6 '09 at 16:26\nGreg\n299k52\n52 gold badges\n359\n359 silver badges\n327\n327 bronze badges","comments":[]},{"answer":"Microsoft Support says \"Maximum URL length is 2,083 characters in Internet Explorer\".\n\nIE has problems with URLs longer than that. Firefox seems to work fine with >4k chars.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 '12 at 18:47\nTRiG\n9,3316\n6 gold badges\n50\n50 silver badges\n101\n101 bronze badges\nanswered May 26 '10 at 16:18\nMegaTux\n1,42223\n23 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"In URL as UI Jakob Nielsen recommends:\n\nthe social interface to the Web relies on email when users want to recommend Web pages to each other, and email is the second-most common way users get to new sites (search engines being the most common): make sure that all URLs on your site are less than 78 characters long so that they will not wrap across a line feed.\n\nThis is not the maximum but I'd consider this a practical maximum if you want your URL to be shared.\n\nShare\nImprove this answer\nFollow\nanswered Jan 8 '13 at 0:38\nPaul Morgan\n27.4k3\n3 gold badges\n22\n22 silver badges\n27\n27 bronze badges","comments":["I wonder where \"78\" comes from? Maybe that original 1999 article was written under the assumption that people are reading their email in 80x24 terminal windows? Still, good advice!","Well. IBM punch cards were also 80 columns. With two characters taken up by a carriage return and a line feed you get 78.","Haha. :-) I was actually considering referencing 1981-era 80x25 CGA monitors in my comment, but you reached even further back! ...I wasn't around for the punch card era, but were they 80 bytes across, or only 80 bits?","Not exactly a byte (8 bits). It encoded one character in each column.","@JonSchneider - 78 is quite specific, and may relate to readability of text (from a usability perspective given Nielsen's background), which is best between 50-60, and a maximum of 75."]},{"answer":"Sitemaps protocol, which is a way for webmasters to inform search engines about pages on their sites (also used by Google in Webmaster Tools), supports URLs with less than 2048 characters. So if you are planning to use this feature for Search Engine Optimization, take this into account.\n\nShare\nImprove this answer\nFollow\nedited Aug 17 '18 at 17:19\nHoldOffHunger\n11.9k7\n7 gold badges\n57\n57 silver badges\n105\n105 bronze badges\nanswered Aug 14 '11 at 12:50\nCalin-Andrei Burloiu\n1,4112\n2 gold badges\n13\n13 silver badges\n25\n25 bronze badges","comments":["This is a little confusing. Sitemap protocols \"supports URLs with less than 2048 characters.\" I imagined a site like example.com would work. I think this question is more about the maximum?"]},{"answer":"ASP.NET 2 and SQL Server reporting services 2005 have a limit of 2028. I found this out the hard way, where my dynamic URL generator would not pass over some parameters to a report beyond that point. This was under Internet Explorer 8.\n\nShare\nImprove this answer\nFollow\nedited Apr 23 '15 at 0:15\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 23 '13 at 23:17\nFandango68\n3,5122\n2 gold badges\n32\n32 silver badges\n56\n56 bronze badges","comments":[]},{"answer":"Why is the Internet Explorer limit only 2K while IIS has a limit of 16K? I don't think it makes sense.\n\nSo I want to start an experiment about Ajax request URL size limits.\n\nI have set my Tomcat HTTP connector's maxHttpHeaderSize=\"1048576\". And prepared a very long URL.\n\nThen I send a request with the long URL like the following:\n\nvar url=\"/ajax/url-length.jsp\";\njQuery.ajax(url,{data:{q:\"0\".repeat(1048000-url.length-4)}});\n\n\njQuery reports done. Tomcat reports the URL requested is 1048015 bytes. It was tested with Chrome 50 and Internet Explorer 11.\n\nSo web browsers won't truncate or limit your URL intentionally when sending Ajax requests.\n\nShare\nImprove this answer\nFollow\nedited Oct 22 '17 at 10:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 4 '16 at 12:23\nfuweichin\n7957\n7 silver badges\n9\n9 bronze badges","comments":["The variation between Internet Explorer and IIS makes sense when you consider that not all requests to a web server are done via a browser."]},{"answer":"Limit request line directive sets the maximum length of a URL. By default, it is set to 8190, which gives you a lot of room. However other servers and some browses, limit the length more.\n\nBecause all parameters are passed on the URL line, items that were in password of hidden fields will also be displayed in the URL of course. Neither mobile should be used for real security measures and should be considered cosmetic security at best.\n\nShare\nImprove this answer\nFollow\nedited Jun 9 '16 at 23:00\nAcey\n7,7304\n4 gold badges\n27\n27 silver badges\n46\n46 bronze badges\nanswered Aug 28 '13 at 10:11\nwebslatesoftware\n2012\n2 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"It seems that Chrome at least has raised this limit. I pasted 20,000 characters into the bookmarklet and it took it.\n\nShare\nImprove this answer\nFollow\nanswered Dec 14 '14 at 19:56\nwibberding\n6953\n3 gold badges\n9\n9 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"I have experience with SharePoint 2007, 2010 and there is a limit of the length URL you can create from the server side in this case SharePoint, so it depends mostly on, 1) the client (browser, version, and OS) and 2) the server technology, IIS, Apache, etc.\n\nShare\nImprove this answer\nFollow\nedited Apr 23 '15 at 0:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 15 '15 at 2:54\nLeonidas Menendez\n42911\n11 silver badges\n15\n15 bronze badges","comments":["Because SharePoint exposes web URLs as file paths, it runs into a separate limitation: the Windows file path length limit of 260 characters (or 248 characters when using an API). For more details about this limit, check out the \"Maximum Path Length Limitation\" section here: msdn.microsoft.com/en-us/library/aa365247(VS.85).aspx"]},{"answer":"According to the HTTP spec, there is no limit to a URL's length. Keep your URLs under 2048 characters; this will ensure the URLs work in all clients & server configurations. Also, search engines like URLs to remain under approximately 2000 characters.\n\nShare\nImprove this answer\nFollow\nanswered Sep 21 '19 at 7:09\nAnoop Gupta\n765\n5 bronze badges","comments":[]}]},{"id":"122102","href":"https://stackoverflow.com/questions/122102/what-is-the-most-efficient-way-to-deep-clone-an-object-in-javascript","title":"What is the most efficient way to deep clone an object in JavaScript?","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nWhat is the most efficient way to clone a JavaScript object? I've seen obj = eval(uneval(o)); being used, but that's non-standard and only supported by Firefox. I've done things like obj = JSON.parse(JSON.stringify(o)); but question the efficiency.  I've also seen recursive copying functions with various flaws.\n\nI'm surprised no canonical solution exists.\n    ","questionComments":["Eval is not evil. Using eval poorly is. If you are afraid of its side effects you are using it wrong. The side effects you fear are the reasons to use it. Did any one by the way actually answer your question?","Cloning objects is a tricky business, especially with custom objects of arbitrary collections. Which probably why there is no out-of-the box way to do it.","eval() is generally a bad idea because many Javascript engine's optimisers have to turn off when dealing with variables that are set via eval. Just having eval() in your code can lead to worse performance.","Possible duplicate of Most elegant way to clone a JavaScript object","Note that JSON method will loose any Javascript types that have no equivalent in JSON. For example: JSON.parse(JSON.stringify({a:null,b:NaN,c:Infinity,d:undefined,e:function(){},f:Number,g:false})) will generate {a: null, b: null, c: null, g: false}"],"answers":[{"answer":"Native deep cloning\n\nIt's called \"structured cloning\", works experimentally in Node 11 and later, and hopefully will land in browsers. See this answer for more details.\n\nFast cloning with data loss - JSON.parse/stringify\n\nIf you do not use Dates, functions, undefined, Infinity, RegExps, Maps, Sets, Blobs, FileLists, ImageDatas, sparse Arrays, Typed Arrays or other complex types within your object, a very simple one liner to deep clone an object is:\n\nJSON.parse(JSON.stringify(object))\n\nconst a = {\n  string: 'string',\n  number: 123,\n  bool: false,\n  nul: null,\n  date: new Date(),  // stringified\n  undef: undefined,  // lost\n  inf: Infinity,  // forced to 'null'\n  re: /.*/,  // lost\n}\nconsole.log(a);\nconsole.log(typeof a.date);  // Date object\nconst clone = JSON.parse(JSON.stringify(a));\nconsole.log(clone);\nconsole.log(typeof clone.date);  // result of .toISOString()\n Run code snippetExpand snippet\n\nSee Corban's answer for benchmarks.\n\nReliable cloning using a library\n\nSince cloning objects is not trivial (complex types, circular references, function etc.), most major libraries provide function to clone objects. Don't reinvent the wheel - if you're already using a library, check if it has an object cloning function. For example,\n\nlodash - cloneDeep; can be imported separately via the lodash.clonedeep module and is probably your best choice if you're not already using a library that provides a deep cloning function\nAngularJS - angular.copy\njQuery - jQuery.extend(true, { }, oldObject); .clone() only clones DOM elements\njust library - just-clone; Part of a library of zero-dependency npm modules that do just do one thing. Guilt-free utilities for every occasion.\nES6 (shallow copy)\n\nFor completeness, note that ES6 offers two shallow copy mechanisms: Object.assign() and the spread syntax. which copies values of all enumerable own properties from one object to another. For example:\n\nvar A1 = {a: \"2\"};\nvar A2 = Object.assign({}, A1);\nvar A3 = {...A1};  // Spread Syntax\n\nShare\nImprove this answer\nFollow\nedited May 28 at 23:04\ncommunity wiki\n\n\n20 revs, 18 users 24%\nDan Dascalescu","comments":["Beware! var A = { b: [ { a: [ 1, 2, 3], b: [4, 5, 6], c: [7, 8, 9] } ] }; B = Object.assign( {}, A ); delete B.b[0].b; It will also modify object A !","@Gabriel Hautclocq this is because A.b or B.b are both referring to the same object in the memory. if A had a property with a non-object value (like numbers or strings), it'll be copied normally. But when a property containing an object value is copied, it is copied by-reference, not by-value. Also, keep in mind that an Array is an object in JS. proof: typeof [] == 'object' && [] instanceof Array","@Unicornist Yes and that's why Object.assign does not answer the question which is: \"What is the most efficient way to deep clone an object in JavaScript?\". So at least it should NOT be presented as an ES6 solution for deep cloning. The title \"ES6\" is misleading, at least it should be changed to reflect that this is not a deep cloning method. The \"shallow\" word is easy to overlook and a lot of people just take the simplest solution they find in Stack Overflow without reading everything. It is dangerous to rely on Object.assign for object cloning. Hence my remark.","I used a library called really fast deep clone: github.com/davidmarkclements/rfdc Worked really well for me.","If you experience problems like in first comment, github.com/davidmarkclements/rfdc also will make \"shallow copy\", you'll need to enable option proto: true,"]},{"answer":"Checkout this benchmark: http://jsben.ch/#/bWfk9\n\nIn my previous tests where speed was a main concern I found\n\nJSON.parse(JSON.stringify(obj))\n\n\nto be the slowest way to deep clone an object (it is slower than jQuery.extend with deep flag set true by 10-20%).\n\njQuery.extend is pretty fast when the deep flag is set to false (shallow clone). It is a good option, because it includes some extra logic for type validation and doesn't copy over undefined properties, etc., but this will also slow you down a little.\n\nIf you know the structure of the objects you are trying to clone or can avoid deep nested arrays you can write a simple for (var i in obj) loop to clone your object while checking hasOwnProperty and it will be much much faster than jQuery.\n\nLastly if you are attempting to clone a known object structure in a hot loop you can get MUCH MUCH MORE PERFORMANCE by simply in-lining the clone procedure and manually constructing the object.\n\nJavaScript trace engines suck at optimizing for..in loops and checking hasOwnProperty will slow you down as well. Manual clone when speed is an absolute must.\n\nvar clonedObject = {\n  knownProp: obj.knownProp,\n  ..\n}\n\n\nBeware using the JSON.parse(JSON.stringify(obj)) method on Date objects - JSON.stringify(new Date()) returns a string representation of the date in ISO format, which JSON.parse() doesn't convert back to a Date object. See this answer for more details.\n\nAdditionally, please note that, in Chrome 65 at least, native cloning is not the way to go. According to JSPerf, performing native cloning by creating a new function is nearly 800x slower than using JSON.stringify which is incredibly fast all the way across the board.\n\nUpdate for ES6\n\nIf you are using Javascript ES6 try this native method for cloning or shallow copy.\n\nObject.assign({}, obj);\n\nShare\nImprove this answer\nFollow\nedited Nov 20 '19 at 4:31\ncommunity wiki\n\n\n16 revs, 14 users 60%\nCorban Brook","comments":["Note that there are 2 mistakes in your bench: first, it compares some shallow cloning (lodash _.clone and Object.assign) to some deep cloning (JSON.parse(JSON.stringify())). Secondly, it says \"deep clone\" for lodash but it does a shallow clone instead."]},{"answer":"Assuming that you have only variables and not any functions in your object, you can just use:\n\nvar newObject = JSON.parse(JSON.stringify(oldObject));\n\nShare\nImprove this answer\nFollow\nedited Oct 23 '14 at 23:47\ncommunity wiki\n\n\n3 revs, 3 users 63%\nSultan Shakir","comments":["Objects have properties, not variables. ;-)","functions and dates as well"]},{"answer":"Structured Cloning\n\nThe HTML standard includes an internal structured cloning/serialization algorithm that can create deep clones of objects. It is still limited to certain built-in types, but in addition to the few types supported by JSON it also supports Dates, RegExps, Maps, Sets, Blobs, FileLists, ImageDatas, sparse Arrays, Typed Arrays, and probably more in the future. It also preserves references within the cloned data, allowing it to support cyclical and recursive structures that would cause errors for JSON.\n\nSupport in Node.js: Experimental 🙂\n\nThe v8 module in Node.js currently (as of Node 11) exposes the structured serialization API directly, but this functionality is still marked as \"experimental\", and subject to change or removal in future versions. If you're using a compatible version, cloning an object is as simple as:\n\nconst v8 = require('v8');\n\nconst structuredClone = obj => {\n  return v8.deserialize(v8.serialize(obj));\n};\n\nDirect Support in Browsers: Maybe Eventually? 😐\n\nBrowsers do not currently provide a direct interface for the structured cloning algorithm, but a global structuredClone() function has been discussed in whatwg/html#793 on GitHub. As currently proposed, using it for most purposes would be as simple as:\n\nconst clone = structuredClone(original);\n\n\nUnless this is shipped, browsers' structured clone implementations are only exposed indirectly.\n\nAsynchronous Workaround: Usable. 😕\n\nThe lower-overhead way to create a structured clone with existing APIs is to post the data through one port of a MessageChannels. The other port will emit a message event with a structured clone of the attached .data. Unfortunately, listening for these events is necessarily asynchronous, and the synchronous alternatives are less practical.\n\nclass StructuredCloner {\n  constructor() {\n    this.pendingClones_ = new Map();\n    this.nextKey_ = 0;\n\n    const channel = new MessageChannel();\n    this.inPort_ = channel.port1;\n    this.outPort_ = channel.port2;\n\n    this.outPort_.onmessage = ({data: {key, value}}) => {\n      const resolve = this.pendingClones_.get(key);\n      resolve(value);\n      this.pendingClones_.delete(key);\n    };\n    this.outPort_.start();\n  }\n\n  cloneAsync(value) {\n    return new Promise(resolve => {\n      const key = this.nextKey_++;\n      this.pendingClones_.set(key, resolve);\n      this.inPort_.postMessage({key, value});\n    });\n  }\n}\n\nconst structuredCloneAsync = window.structuredCloneAsync =\n    StructuredCloner.prototype.cloneAsync.bind(new StructuredCloner);\n\nExample Use:\nconst main = async () => {\n  const original = { date: new Date(), number: Math.random() };\n  original.self = original;\n\n  const clone = await structuredCloneAsync(original);\n\n  // They're different objects:\n  console.assert(original !== clone);\n  console.assert(original.date !== clone.date);\n\n  // They're cyclical:\n  console.assert(original.self === original);\n  console.assert(clone.self === clone);\n\n  // They contain equivalent values:\n  console.assert(original.number === clone.number);\n  console.assert(Number(original.date) === Number(clone.date));\n\n  console.log(\"Assertions complete.\");\n};\n\nmain();\n\nSynchronous Workarounds: Awful! 🤢\n\nThere are no good options for creating structured clones synchronously. Here are a couple of impractical hacks instead.\n\nhistory.pushState() and history.replaceState() both create a structured clone of their first argument, and assign that value to history.state. You can use this to create a structured clone of any object like this:\n\nconst structuredClone = obj => {\n  const oldState = history.state;\n  history.replaceState(obj, null);\n  const clonedObj = history.state;\n  history.replaceState(oldState, null);\n  return clonedObj;\n};\n\nExample Use:\n\nShow code snippet\n\nThough synchronous, this can be extremely slow. It incurs all of the overhead associated with manipulating the browser history. Calling this method repeatedly can cause Chrome to become temporarily unresponsive.\n\nThe Notification constructor creates a structured clone of its associated data. It also attempts to display a browser notification to the user, but this will silently fail unless you have requested notification permission. In case you have the permission for other purposes, we'll immediately close the notification we've created.\n\nconst structuredClone = obj => {\n  const n = new Notification('', {data: obj, silent: true});\n  n.onshow = n.close.bind(n);\n  return n.data;\n};\n\nExample Use:\n\nShow code snippet\n\nShare\nImprove this answer\nFollow\nedited Feb 5 '19 at 2:21\nanswered Jun 6 '12 at 14:59\nJeremy\n1","comments":["This is just so wrong! That API is not meant to be used this way.","As the guy who implemented pushState in Firefox, I feel an odd mix of pride and revulsion at this hack. Well done, guys.","pushState or Notification hack does not work for some object types like Function","@ShishirArora You're right, I just tried it, it throws a 'Uncaught DOMException: The object could not be cloned.' This is also true for the Notification hack."]},{"answer":"If there wasn't any builtin one, you could try:\n\nfunction clone(obj) {\n    if (obj === null || typeof (obj) !== 'object' || 'isActiveClone' in obj)\n        return obj;\n\n    if (obj instanceof Date)\n        var temp = new obj.constructor(); //or new Date(obj);\n    else\n        var temp = obj.constructor();\n\n    for (var key in obj) {\n        if (Object.prototype.hasOwnProperty.call(obj, key)) {\n            obj['isActiveClone'] = null;\n            temp[key] = clone(obj[key]);\n            delete obj['isActiveClone'];\n        }\n    }\n    return temp;\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 27 '18 at 8:59\ncommunity wiki\n\n\n11 revs, 9 users 30%\nConroyP","comments":[]},{"answer":"The efficient way to clone(not deep-clone) an object in one line of code\n\nAn Object.assign method is part of the ECMAScript 2015 (ES6) standard and does exactly what you need.\n\nvar clone = Object.assign({}, obj);\n\n\nThe Object.assign() method is used to copy the values of all enumerable own properties from one or more source objects to a target object.\n\nRead more...\n\nThe polyfill to support older browsers:\n\nif (!Object.assign) {\n  Object.defineProperty(Object, 'assign', {\n    enumerable: false,\n    configurable: true,\n    writable: true,\n    value: function(target) {\n      'use strict';\n      if (target === undefined || target === null) {\n        throw new TypeError('Cannot convert first argument to object');\n      }\n\n      var to = Object(target);\n      for (var i = 1; i < arguments.length; i++) {\n        var nextSource = arguments[i];\n        if (nextSource === undefined || nextSource === null) {\n          continue;\n        }\n        nextSource = Object(nextSource);\n\n        var keysArray = Object.keys(nextSource);\n        for (var nextIndex = 0, len = keysArray.length; nextIndex < len; nextIndex++) {\n          var nextKey = keysArray[nextIndex];\n          var desc = Object.getOwnPropertyDescriptor(nextSource, nextKey);\n          if (desc !== undefined && desc.enumerable) {\n            to[nextKey] = nextSource[nextKey];\n          }\n        }\n      }\n      return to;\n    }\n  });\n}\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n3 revs, 3 users 95%\nEugene Tiurin","comments":["This doesn't recursively copy so doesn't really offer a solution to the problem of cloning an object.","This method worked, although I tested a few and _.extend({}, (obj)) was BY FAR the fastest: 20x faster than JSON.parse and 60% faster than Object.assign, for example. It copies all sub-objects quite well.","@mwhite there is a difference between clone and deep-clone. This answer does in fact clone, but it doesn't deep-clone.","the question was about recursive copies. Object.assign, as well as the given custom assign, do not copy recursively"]},{"answer":"Code:\n\n// extends 'from' object with members from 'to'. If 'to' is null, a deep clone of 'from' is returned\nfunction extend(from, to)\n{\n    if (from == null || typeof from != \"object\") return from;\n    if (from.constructor != Object && from.constructor != Array) return from;\n    if (from.constructor == Date || from.constructor == RegExp || from.constructor == Function ||\n        from.constructor == String || from.constructor == Number || from.constructor == Boolean)\n        return new from.constructor(from);\n\n    to = to || new from.constructor();\n\n    for (var name in from)\n    {\n        to[name] = typeof to[name] == \"undefined\" ? extend(from[name], null) : to[name];\n    }\n\n    return to;\n}\n\n\nTest:\n\nvar obj =\n{\n    date: new Date(),\n    func: function(q) { return 1 + q; },\n    num: 123,\n    text: \"asdasd\",\n    array: [1, \"asd\"],\n    regex: new RegExp(/aaa/i),\n    subobj:\n    {\n        num: 234,\n        text: \"asdsaD\"\n    }\n}\n\nvar clone = extend(obj);\n\nShare\nImprove this answer\nFollow\nedited Mar 26 '11 at 14:20\ncommunity wiki\n\n\n2 revs\nKamarey","comments":["I don't this handles circular structures"]},{"answer":"This is what I'm using:\n\nfunction cloneObject(obj) {\n    var clone = {};\n    for(var i in obj) {\n        if(typeof(obj[i])==\"object\" && obj[i] != null)\n            clone[i] = cloneObject(obj[i]);\n        else\n            clone[i] = obj[i];\n    }\n    return clone;\n}\n\nShare\nImprove this answer\nFollow\nedited Jul 16 '13 at 16:37\ncommunity wiki\n\n\n3 revs, 3 users 69%\nAlan","comments":["Trying: var a = {b: 1, c: 3, d: { a: 10, g: 20, h: { today: new Date() }}}; Not working for me. But Object.assign({}, a) did.","Worse, try let o = {}; o.o = o; cloneObject(o);"]},{"answer":"Deep copying objects in JavaScript (I think the best and the simplest)\n\n1. Using JSON.parse(JSON.stringify(object));\n\nvar obj = { \n  a: 1,\n  b: { \n    c: 2\n  }\n}\nvar newObj = JSON.parse(JSON.stringify(obj));\nobj.b.c = 20;\nconsole.log(obj); // { a: 1, b: { c: 20 } }\nconsole.log(newObj); // { a: 1, b: { c: 2 } } \n\n\n2.Using created method\n\nfunction cloneObject(obj) {\n    var clone = {};\n    for(var i in obj) {\n        if(obj[i] != null &&  typeof(obj[i])==\"object\")\n            clone[i] = cloneObject(obj[i]);\n        else\n            clone[i] = obj[i];\n    }\n    return clone;\n}\n\nvar obj = { \n  a: 1,\n  b: { \n    c: 2\n  }\n}\nvar newObj = cloneObject(obj);\nobj.b.c = 20;\n\nconsole.log(obj); // { a: 1, b: { c: 20 } }\nconsole.log(newObj); // { a: 1, b: { c: 2 } } \n\n\n3. Using Lo-Dash's _.cloneDeep link lodash\n\nvar obj = { \n  a: 1,\n  b: { \n    c: 2\n  }\n}\n\nvar newObj = _.cloneDeep(obj);\nobj.b.c = 20;\nconsole.log(obj); // { a: 1, b: { c: 20 } }\nconsole.log(newObj); // { a: 1, b: { c: 2 } } \n\n\n4. Using Object.assign() method\n\nvar obj = { \n  a: 1,\n  b: 2\n}\n\nvar newObj = _.clone(obj);\nobj.b = 20;\nconsole.log(obj); // { a: 1, b: 20 }\nconsole.log(newObj); // { a: 1, b: 2 }  \n\n\nBUT WRONG WHEN\n\nvar obj = { \n  a: 1,\n  b: { \n    c: 2\n  }\n}\n\nvar newObj = Object.assign({}, obj);\nobj.b.c = 20;\nconsole.log(obj); // { a: 1, b: { c: 20 } }\nconsole.log(newObj); // { a: 1, b: { c: 20 } } --> WRONG\n// Note: Properties on the prototype chain and non-enumerable properties cannot be copied.\n\n\n5.Using Underscore.js _.clone link Underscore.js\n\nvar obj = { \n  a: 1,\n  b: 2\n}\n\nvar newObj = _.clone(obj);\nobj.b = 20;\nconsole.log(obj); // { a: 1, b: 20 }\nconsole.log(newObj); // { a: 1, b: 2 }  \n\n\nBUT WRONG WHEN\n\nvar obj = { \n  a: 1,\n  b: { \n    c: 2\n  }\n}\n\nvar newObj = _.cloneDeep(obj);\nobj.b.c = 20;\nconsole.log(obj); // { a: 1, b: { c: 20 } }\nconsole.log(newObj); // { a: 1, b: { c: 20 } } --> WRONG\n// (Create a shallow-copied clone of the provided plain object. Any nested objects or arrays will be copied by reference, not duplicated.)\n\n\nJSBEN.CH Performance Benchmarking Playground 1~3 http://jsben.ch/KVQLd \n\nShare\nImprove this answer\nFollow\nedited Nov 20 '19 at 4:52\ncommunity wiki\n\n\n4 revs, 2 users 99%\nTính Ngô Quang","comments":["Hey, your last example is wrong. In my opinion, you must use _clone and not _cloneDeep for the wrong example.","This created method (2.) won't work for arrays, will it?","Method #2 is vulnerable to prototype pollution, similar to what happened to lodash's defaultsDeep. It should not copy if (i === '__proto__'), and it should not copy if (i === 'constuctor' && typeof obj[i] === 'function')."]},{"answer":"Deep copy by performance: Ranked from best to worst\n\nReassignment \"=\" (string arrays, number arrays - only)\nSlice (string arrays, number arrays - only)\nConcatenation (string arrays, number arrays - only)\nCustom function: for-loop or recursive copy\njQuery's $.extend\nJSON.parse (string arrays, number arrays, object arrays - only)\nUnderscore.js's _.clone (string arrays, number arrays - only)\nLo-Dash's _.cloneDeep\n\nDeep copy an array of strings or numbers (one level - no reference pointers):\n\nWhen an array contains numbers and strings - functions like .slice(), .concat(), .splice(), the assignment operator \"=\", and Underscore.js's clone function; will make a deep copy of the array's elements.\n\nWhere reassignment has the fastest performance:\n\nvar arr1 = ['a', 'b', 'c'];\nvar arr2 = arr1;\narr1 = ['a', 'b', 'c'];\n\n\nAnd .slice() has better performance than .concat(), http://jsperf.com/duplicate-array-slice-vs-concat/3\n\nvar arr1 = ['a', 'b', 'c'];  // Becomes arr1 = ['a', 'b', 'c']\nvar arr2a = arr1.slice(0);   // Becomes arr2a = ['a', 'b', 'c'] - deep copy\nvar arr2b = arr1.concat();   // Becomes arr2b = ['a', 'b', 'c'] - deep copy\n\n\nDeep copy an array of objects (two or more levels - reference pointers):\n\nvar arr1 = [{object:'a'}, {object:'b'}];\n\n\nWrite a custom function (has faster performance than $.extend() or JSON.parse):\n\nfunction copy(o) {\n   var out, v, key;\n   out = Array.isArray(o) ? [] : {};\n   for (key in o) {\n       v = o[key];\n       out[key] = (typeof v === \"object\" && v !== null) ? copy(v) : v;\n   }\n   return out;\n}\n\ncopy(arr1);\n\n\nUse third-party utility functions:\n\n$.extend(true, [], arr1); // Jquery Extend\nJSON.parse(arr1);\n_.cloneDeep(arr1); // Lo-dash\n\n\nWhere jQuery's $.extend has better performance:\n\nhttp://jsperf.com/js-deep-copy/2\nhttp://jsperf.com/jquery-extend-vs-json-parse/2\nShare\nImprove this answer\nFollow\nedited Mar 20 '18 at 15:11\ncommunity wiki\n\n\n12 revs, 2 users 93%\ntfmontague","comments":["With for-in loop you should use hasOwnProperty to exclude inherited properties. I use (possibly even faster) plain for loop over Object.keys.","In a deep copy, wouldn't you want to copy the inherited properties as well? Also, note that invoking the hasOwnProperty method, creates a performance hit (pushing the function call on and off the stack, and executing the method code) for every key."]},{"answer":"Cloning an Object was always a concern in JS, but it was all about before ES6, I list different ways of copying an object in JavaScript below, imagine you have the Object below and would like to have a deep copy of that:\n\nvar obj = {a:1, b:2, c:3, d:4};\n\n\nThere are few ways to copy this object, without changing the origin:\n\nES5+, Using a simple function to do the copy for you:\n    function deepCopyObj(obj) {\n        if (null == obj || \"object\" != typeof obj) return obj;\n        if (obj instanceof Date) {\n            var copy = new Date();\n            copy.setTime(obj.getTime());\n            return copy;\n        }\n        if (obj instanceof Array) {\n            var copy = [];\n            for (var i = 0, len = obj.length; i < len; i++) {\n                copy[i] = deepCopyObj(obj[i]);\n            }\n            return copy;\n        }\n        if (obj instanceof Object) {\n            var copy = {};\n            for (var attr in obj) {\n                if (obj.hasOwnProperty(attr)) copy[attr] = deepCopyObj(obj[attr]);\n            }\n            return copy;\n        }\n        throw new Error(\"Unable to copy obj this object.\");\n    }\n\nES5+, using JSON.parse and JSON.stringify.\n    var  deepCopyObj = JSON.parse(JSON.stringify(obj));\n\nAngularJs:\n    var  deepCopyObj = angular.copy(obj);\n\njQuery:\n    var deepCopyObj = jQuery.extend(true, {}, obj);\n\nUnderscoreJs & Loadash:\n    var deepCopyObj = _.cloneDeep(obj); //latest version UndescoreJs makes shallow copy\n\n\nHope these help...\n\nShare\nImprove this answer\nFollow\nedited Mar 4 at 2:01\ncommunity wiki\n\n\n12 revs, 3 users 83%\nAlireza","comments":["Thanks for the jQuery one, great!"]},{"answer":"var clone = function() {\n    var newObj = (this instanceof Array) ? [] : {};\n    for (var i in this) {\n        if (this[i] && typeof this[i] == \"object\") {\n            newObj[i] = this[i].clone();\n        }\n        else\n        {\n            newObj[i] = this[i];\n        }\n    }\n    return newObj;\n}; \n\nObject.defineProperty( Object.prototype, \"clone\", {value: clone, enumerable: false});\n\nShare\nImprove this answer\nFollow\nedited Feb 21 '13 at 15:01\ncommunity wiki\n\n\n5 revs, 4 users 31%\nZibri","comments":[]},{"answer":"There’s a library (called “clone”), that does this quite well. It provides the most complete recursive cloning/copying of arbitrary objects that I know of. It also supports circular references, which is not covered by the other answers, yet.\n\nYou can find it on npm, too. It can be used for the browser as well as Node.js.\n\nHere is an example on how to use it:\n\nInstall it with\n\nnpm install clone\n\n\nor package it with Ender.\n\nender build clone [...]\n\n\nYou can also download the source code manually.\n\nThen you can use it in your source code.\n\nvar clone = require('clone');\n\nvar a = { foo: { bar: 'baz' } };  // inital value of a\nvar b = clone(a);                 // clone a -> b\na.foo.bar = 'foo';                // change a\n\nconsole.log(a);                   // { foo: { bar: 'foo' } }\nconsole.log(b);                   // { foo: { bar: 'baz' } }\n\n\n(Disclaimer: I’m the author of the library.)\n\nShare\nImprove this answer\nFollow\nedited Mar 27 '13 at 8:04\ncommunity wiki\n\n\n3 revs\npvorb","comments":[]},{"answer":"I know this is an old post, but I thought this may be of some help to the next person who stumbles along.\n\nAs long as you don't assign an object to anything it maintains no reference in memory. So to make an object that you want to share among other objects, you'll have to create a factory like so:\n\nvar a = function(){\n    return {\n        father:'zacharias'\n    };\n},\nb = a(),\nc = a();\nc.father = 'johndoe';\nalert(b.father);\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '15 at 1:18\ncommunity wiki\n\n\n2 revs\nJoe","comments":[]},{"answer":"If you're using it, the Underscore.js library has a clone method.\n\nvar newObject = _.clone(oldObject);\n\nShare\nImprove this answer\nFollow\nedited Jul 22 '16 at 17:26\ncommunity wiki\n\n\n2 revs, 2 users 83%\nitsadok","comments":[]},{"answer":"Here's a version of ConroyP's answer above that works even if the constructor has required parameters:\n\n//If Object.create isn't already defined, we just do the simple shim,\n//without the second argument, since that's all we need here\nvar object_create = Object.create;\nif (typeof object_create !== 'function') {\n    object_create = function(o) {\n        function F() {}\n        F.prototype = o;\n        return new F();\n    };\n}\n\nfunction deepCopy(obj) {\n    if(obj == null || typeof(obj) !== 'object'){\n        return obj;\n    }\n    //make sure the returned object has the same prototype as the original\n    var ret = object_create(obj.constructor.prototype);\n    for(var key in obj){\n        ret[key] = deepCopy(obj[key]);\n    }\n    return ret;\n}\n\n\nThis function is also available in my simpleoo library.\n\nEdit:\n\nHere's a more robust version (thanks to Justin McCandless this now supports cyclic references as well):\n\n/**\n * Deep copy an object (make copies of all its object properties, sub-properties, etc.)\n * An improved version of http://keithdevens.com/weblog/archive/2007/Jun/07/javascript.clone\n * that doesn't break if the constructor has required parameters\n * \n * It also borrows some code from http://stackoverflow.com/a/11621004/560114\n */ \nfunction deepCopy(src, /* INTERNAL */ _visited, _copiesVisited) {\n    if(src === null || typeof(src) !== 'object'){\n        return src;\n    }\n\n    //Honor native/custom clone methods\n    if(typeof src.clone == 'function'){\n        return src.clone(true);\n    }\n\n    //Special cases:\n    //Date\n    if(src instanceof Date){\n        return new Date(src.getTime());\n    }\n    //RegExp\n    if(src instanceof RegExp){\n        return new RegExp(src);\n    }\n    //DOM Element\n    if(src.nodeType && typeof src.cloneNode == 'function'){\n        return src.cloneNode(true);\n    }\n\n    // Initialize the visited objects arrays if needed.\n    // This is used to detect cyclic references.\n    if (_visited === undefined){\n        _visited = [];\n        _copiesVisited = [];\n    }\n\n    // Check if this object has already been visited\n    var i, len = _visited.length;\n    for (i = 0; i < len; i++) {\n        // If so, get the copy we already made\n        if (src === _visited[i]) {\n            return _copiesVisited[i];\n        }\n    }\n\n    //Array\n    if (Object.prototype.toString.call(src) == '[object Array]') {\n        //[].slice() by itself would soft clone\n        var ret = src.slice();\n\n        //add it to the visited array\n        _visited.push(src);\n        _copiesVisited.push(ret);\n\n        var i = ret.length;\n        while (i--) {\n            ret[i] = deepCopy(ret[i], _visited, _copiesVisited);\n        }\n        return ret;\n    }\n\n    //If we've reached here, we have a regular object\n\n    //make sure the returned object has the same prototype as the original\n    var proto = (Object.getPrototypeOf ? Object.getPrototypeOf(src): src.__proto__);\n    if (!proto) {\n        proto = src.constructor.prototype; //this line would probably only be reached by very old browsers \n    }\n    var dest = object_create(proto);\n\n    //add this object to the visited array\n    _visited.push(src);\n    _copiesVisited.push(dest);\n\n    for (var key in src) {\n        //Note: this does NOT preserve ES5 property attributes like 'writable', 'enumerable', etc.\n        //For an example of how this could be modified to do so, see the singleMixin() function\n        dest[key] = deepCopy(src[key], _visited, _copiesVisited);\n    }\n    return dest;\n}\n\n//If Object.create isn't already defined, we just do the simple shim,\n//without the second argument, since that's all we need here\nvar object_create = Object.create;\nif (typeof object_create !== 'function') {\n    object_create = function(o) {\n        function F() {}\n        F.prototype = o;\n        return new F();\n    };\n}\n\nShare\nImprove this answer\nFollow\nedited Mar 12 '17 at 18:02\ncommunity wiki\n\n\n9 revs\nMatt Browne","comments":[]},{"answer":"The following creates two instances of the same object. I found it and am using it currently. It's simple and easy to use.\n\nvar objToCreate = JSON.parse(JSON.stringify(cloneThis));\n\nShare\nImprove this answer\nFollow\nedited Dec 1 '16 at 16:06\ncommunity wiki\n\n\n3 revs, 3 users 71%\nnathan rogers","comments":[]},{"answer":"Crockford suggests (and I prefer) using this function:\n\nfunction object(o) {\n    function F() {}\n    F.prototype = o;\n    return new F();\n}\n\nvar newObject = object(oldObject);\n\n\nIt's terse, works as expected and you don't need a library.\n\nEDIT:\n\nThis is a polyfill for Object.create, so you also can use this.\n\nvar newObject = Object.create(oldObject);\n\n\nNOTE: If you use some of this, you may have problems with some iteration who use hasOwnProperty. Because, create create new empty object who inherits oldObject. But it is still useful and practical for cloning objects.\n\nFor exemple if oldObject.a = 5;\n\nnewObject.a; // is 5\n\n\nbut:\n\noldObject.hasOwnProperty(a); // is true\nnewObject.hasOwnProperty(a); // is false\n\nShare\nImprove this answer\nFollow\nedited Mar 12 '16 at 14:59\ncommunity wiki\n\n\n2 revs, 2 users 50%\nprotonfish","comments":[]},{"answer":"Lodash has a nice _.cloneDeep(value) method:\n\nvar objects = [{ 'a': 1 }, { 'b': 2 }];\n\nvar deep = _.cloneDeep(objects);\nconsole.log(deep[0] === objects[0]);\n// => false\n\nShare\nImprove this answer\nFollow\nedited Dec 31 '17 at 12:59\ncommunity wiki\n\n\n2 revs, 2 users 67%\nopensas","comments":[]},{"answer":"function clone(obj)\n { var clone = {};\n   clone.prototype = obj.prototype;\n   for (property in obj) clone[property] = obj[property];\n   return clone;\n }\n\nShare\nImprove this answer\nFollow\nanswered Sep 23 '08 at 16:45\ncommunity wiki\n\n\nMark Cidade","comments":[]},{"answer":"Shallow copy one-liner (ECMAScript 5th edition):\n\nvar origin = { foo : {} };\nvar copy = Object.keys(origin).reduce(function(c,k){c[k]=origin[k];return c;},{});\n\nconsole.log(origin, copy);\nconsole.log(origin == copy); // false\nconsole.log(origin.foo == copy.foo); // true\n\n\nAnd shallow copy one-liner (ECMAScript 6th edition, 2015):\n\nvar origin = { foo : {} };\nvar copy = Object.assign({}, origin);\n\nconsole.log(origin, copy);\nconsole.log(origin == copy); // false\nconsole.log(origin.foo == copy.foo); // true\n\nShare\nImprove this answer\nFollow\nedited Jul 22 '16 at 17:27\ncommunity wiki\n\n\n3 revs, 2 users 82%\nMaël Nison","comments":[]},{"answer":"There seems to be no ideal deep clone operator yet for array-like objects. As the code below illustrates, John Resig's jQuery cloner turns arrays with non-numeric properties into objects that are not arrays, and RegDwight's JSON cloner drops the non-numeric properties. The following tests illustrate these points on multiple browsers:\n\nfunction jQueryClone(obj) {\n   return jQuery.extend(true, {}, obj)\n}\n\nfunction JSONClone(obj) {\n   return JSON.parse(JSON.stringify(obj))\n}\n\nvar arrayLikeObj = [[1, \"a\", \"b\"], [2, \"b\", \"a\"]];\narrayLikeObj.names = [\"m\", \"n\", \"o\"];\nvar JSONCopy = JSONClone(arrayLikeObj);\nvar jQueryCopy = jQueryClone(arrayLikeObj);\n\nalert(\"Is arrayLikeObj an array instance?\" + (arrayLikeObj instanceof Array) +\n      \"\\nIs the jQueryClone an array instance? \" + (jQueryCopy instanceof Array) +\n      \"\\nWhat are the arrayLikeObj names? \" + arrayLikeObj.names +\n      \"\\nAnd what are the JSONClone names? \" + JSONCopy.names)\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '13 at 19:00\ncommunity wiki\n\n\n3 revs, 2 users 98%\nPage Notes","comments":[]},{"answer":"Just because I didn't see AngularJS mentioned and thought that people might want to know...\n\nangular.copy also provides a method of deep copying objects and arrays.\n\nShare\nImprove this answer\nFollow\nedited Oct 15 '16 at 18:38\ncommunity wiki\n\n\n3 revs, 2 users 62%\nDan Atkinson","comments":["or it might be used the same way as jQiery extend: angular.extend({},obj);","@Galvani: It should be noted that jQuery.extend and angular.extend are both shallow copies. angular.copy is a deep copy."]},{"answer":"I have two good answers depending on whether your objective is to clone a \"plain old JavaScript object\" or not.\n\nLet's also assume that your intention is to create a complete clone with no prototype references back to the source object. If you're not interested in a complete clone, then you can use many of the Object.clone() routines provided in some of the other answers (Crockford's pattern).\n\nFor plain old JavaScript objects, a tried and true good way to clone an object in modern runtimes is quite simply:\n\nvar clone = JSON.parse(JSON.stringify(obj));\n\n\nNote that the source object must be a pure JSON object. This is to say, all of its nested properties must be scalars (like boolean, string, array, object, etc). Any functions or special objects like RegExp or Date will not be cloned.\n\nIs it efficient? Heck yes. We've tried all kinds of cloning methods and this works best. I'm sure some ninja could conjure up a faster method. But I suspect we're talking about marginal gains.\n\nThis approach is just simple and easy to implement. Wrap it into a convenience function and if you really need to squeeze out some gain, go for at a later time.\n\nNow, for non-plain JavaScript objects, there isn't a really simple answer. In fact, there can't be because of the dynamic nature of JavaScript functions and inner object state. Deep cloning a JSON structure with functions inside requires you recreate those functions and their inner context. And JavaScript simply doesn't have a standardized way of doing that.\n\nThe correct way to do this, once again, is via a convenience method that you declare and reuse within your code. The convenience method can be endowed with some understanding of your own objects so you can make sure to properly recreate the graph within the new object.\n\nWe're written our own, but the best general approach I've seen is covered here:\n\nhttp://davidwalsh.name/javascript-clone\n\nThis is the right idea. The author (David Walsh) has commented out the cloning of generalized functions. This is something you might choose to do, depending on your use case.\n\nThe main idea is that you need to special handle the instantiation of your functions (or prototypal classes, so to speak) on a per-type basis. Here, he's provided a few examples for RegExp and Date.\n\nNot only is this code brief, but it's also very readable. It's pretty easy to extend.\n\nIs this efficient? Heck yes. Given that the goal is to produce a true deep-copy clone, then you're going to have to walk the members of the source object graph. With this approach, you can tweak exactly which child members to treat and how to manually handle custom types.\n\nSo there you go. Two approaches. Both are efficient in my view.\n\nShare\nImprove this answer\nFollow\nedited Jul 22 '16 at 17:33\ncommunity wiki\n\n\n2 revs, 2 users 81%\nMichael Uzquiano","comments":[]},{"answer":"I am late to answer this question, but I have an another way of cloning the object:\n\nfunction cloneObject(obj) {\n    if (obj === null || typeof(obj) !== 'object')\n        return obj;\n    var temp = obj.constructor(); // changed\n    for (var key in obj) {\n        if (Object.prototype.hasOwnProperty.call(obj, key)) {\n            obj['isActiveClone'] = null;\n            temp[key] = cloneObject(obj[key]);\n            delete obj['isActiveClone'];\n        }\n    }\n    return temp;\n}\n\nvar b = cloneObject({\"a\":1,\"b\":2});   // calling\n\n\nwhich is much better and faster then:\n\nvar a = {\"a\":1,\"b\":2};\nvar b = JSON.parse(JSON.stringify(a));  \n\n\nand\n\nvar a = {\"a\":1,\"b\":2};\n\n// Deep copy\nvar newObject = jQuery.extend(true, {}, a);\n\n\nI have bench-marked the code and you can test the results here:\n\nand sharing the results:  References: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/hasOwnProperty\n\nShare\nImprove this answer\nFollow\nedited Dec 7 '20 at 10:46\ncommunity wiki\n\n\n5 revs, 2 users 85%\nMayur Agarwal","comments":["its funny but when I run your tests it actually shoed me that method 1 is the slowest one","same as me, block 1 is the lowest!","Only solution that worked for me! Had to deep clone an object that contained other objects with function properties. Perfect.","Why do you set obj['isActiveClone'] = null and then delete it? And why don't you call obj.hasOwnProperty(key)?"]},{"answer":"This isn't generally the most efficient solution, but it does what I need. Simple test cases below...\n\nfunction clone(obj, clones) {\n    // Makes a deep copy of 'obj'. Handles cyclic structures by\n    // tracking cloned obj's in the 'clones' parameter. Functions \n    // are included, but not cloned. Functions members are cloned.\n    var new_obj,\n        already_cloned,\n        t = typeof obj,\n        i = 0,\n        l,\n        pair; \n\n    clones = clones || [];\n\n    if (obj === null) {\n        return obj;\n    }\n\n    if (t === \"object\" || t === \"function\") {\n\n        // check to see if we've already cloned obj\n        for (i = 0, l = clones.length; i < l; i++) {\n            pair = clones[i];\n            if (pair[0] === obj) {\n                already_cloned = pair[1];\n                break;\n            }\n        }\n\n        if (already_cloned) {\n            return already_cloned; \n        } else {\n            if (t === \"object\") { // create new object\n                new_obj = new obj.constructor();\n            } else { // Just use functions as is\n                new_obj = obj;\n            }\n\n            clones.push([obj, new_obj]); // keep track of objects we've cloned\n\n            for (key in obj) { // clone object members\n                if (obj.hasOwnProperty(key)) {\n                    new_obj[key] = clone(obj[key], clones);\n                }\n            }\n        }\n    }\n    return new_obj || obj;\n}\n\n\nCyclic array test...\n\na = []\na.push(\"b\", \"c\", a)\naa = clone(a)\naa === a //=> false\naa[2] === a //=> false\naa[2] === a[2] //=> false\naa[2] === aa //=> true\n\n\nFunction test...\n\nf = new Function\nf.a = a\nff = clone(f)\nff === f //=> true\nff.a === a //=> false\n\nShare\nImprove this answer\nFollow\nanswered Apr 3 '11 at 2:08\ncommunity wiki\n\n\nneatonk","comments":[]},{"answer":"For the people who want to use the JSON.parse(JSON.stringify(obj)) version, but without losing the Date objects, you can use the second argument of parse method to convert the strings back to Date:\n\nfunction clone(obj) {\n  var regExp = /^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z$/;\n  return JSON.parse(JSON.stringify(obj), function(k, v) {\n    if (typeof v === 'string' && regExp.test(v))\n      return new Date(v)\n    return v;\n  })\n}\n\n// usage:\nvar original = {\n a: [1, null, undefined, 0, {a:null}, new Date()],\n b: {\n   c(){ return 0 }\n }\n}\n\nvar cloned = clone(original)\n\nconsole.log(cloned)\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Oct 24 '20 at 13:07\ncommunity wiki\n\n\n3 revs, 3 users 51%\nBuzinas","comments":["Not quite a 100% clone"]},{"answer":"Only when you can use ECMAScript 6 or transpilers.\n\nFeatures:\n\nWon't trigger getter/setter while copying.\nPreserves getter/setter.\nPreserves prototype informations.\nWorks with both object-literal and functional OO writing styles.\n\nCode:\n\nfunction clone(target, source){\n\n    for(let key in source){\n\n        // Use getOwnPropertyDescriptor instead of source[key] to prevent from trigering setter/getter.\n        let descriptor = Object.getOwnPropertyDescriptor(source, key);\n        if(descriptor.value instanceof String){\n            target[key] = new String(descriptor.value);\n        }\n        else if(descriptor.value instanceof Array){\n            target[key] = clone([], descriptor.value);\n        }\n        else if(descriptor.value instanceof Object){\n            let prototype = Reflect.getPrototypeOf(descriptor.value);\n            let cloneObject = clone({}, descriptor.value);\n            Reflect.setPrototypeOf(cloneObject, prototype);\n            target[key] = cloneObject;\n        }\n        else {\n            Object.defineProperty(target, key, descriptor);\n        }\n    }\n    let prototype = Reflect.getPrototypeOf(source);\n    Reflect.setPrototypeOf(target, prototype);\n    return target;\n}\n\nShare\nImprove this answer\nFollow\nedited Jul 22 '16 at 17:46\ncommunity wiki\n\n\n2 revs, 2 users 69%\nandrew","comments":[]},{"answer":"I disagree with the answer with the greatest votes here. A Recursive Deep Clone is much faster than the JSON.parse(JSON.stringify(obj)) approach mentioned.\n\nJsperf ranks it number one here: https://jsperf.com/deep-copy-vs-json-stringify-json-parse/5\nJsben from the answer above updated to show that a recursive deep clone beats all the others mentioned: http://jsben.ch/13YKQ\n\nAnd here's the function for quick reference:\n\nfunction cloneDeep (o) {\n  let newO\n  let i\n\n  if (typeof o !== 'object') return o\n\n  if (!o) return o\n\n  if (Object.prototype.toString.apply(o) === '[object Array]') {\n    newO = []\n    for (i = 0; i < o.length; i += 1) {\n      newO[i] = cloneDeep(o[i])\n    }\n    return newO\n  }\n\n  newO = {}\n  for (i in o) {\n    if (o.hasOwnProperty(i)) {\n      newO[i] = cloneDeep(o[i])\n    }\n  }\n  return newO\n}\n\nShare\nImprove this answer\nFollow\nanswered Jun 18 '17 at 6:34\ncommunity wiki\n\n\nprograhammer","comments":["I liked this approach but it doesn't handle dates properly; consider adding something like if(o instanceof Date) return new Date(o.valueOf()); after checking for null `","Crashes on circular references.","In latest stable Firefox, this is way longer than the other strategies at that Jsben.ch link, by an order of magnitude or more. It beats the others in the wrong direction."]},{"answer":"Here is a comprehensive clone() method that can clone any JavaScript object. It handles almost all the cases:\n\nfunction clone(src, deep) {\n\n    var toString = Object.prototype.toString;\n    if (!src && typeof src != \"object\") {\n        // Any non-object (Boolean, String, Number), null, undefined, NaN\n        return src;\n    }\n\n    // Honor native/custom clone methods\n    if (src.clone && toString.call(src.clone) == \"[object Function]\") {\n        return src.clone(deep);\n    }\n\n    // DOM elements\n    if (src.nodeType && toString.call(src.cloneNode) == \"[object Function]\") {\n        return src.cloneNode(deep);\n    }\n\n    // Date\n    if (toString.call(src) == \"[object Date]\") {\n        return new Date(src.getTime());\n    }\n\n    // RegExp\n    if (toString.call(src) == \"[object RegExp]\") {\n        return new RegExp(src);\n    }\n\n    // Function\n    if (toString.call(src) == \"[object Function]\") {\n\n        //Wrap in another method to make sure == is not true;\n        //Note: Huge performance issue due to closures, comment this :)\n        return (function(){\n            src.apply(this, arguments);\n        });\n    }\n\n    var ret, index;\n    //Array\n    if (toString.call(src) == \"[object Array]\") {\n        //[].slice(0) would soft clone\n        ret = src.slice();\n        if (deep) {\n            index = ret.length;\n            while (index--) {\n                ret[index] = clone(ret[index], true);\n            }\n        }\n    }\n    //Object\n    else {\n        ret = src.constructor ? new src.constructor() : {};\n        for (var prop in src) {\n            ret[prop] = deep\n                ? clone(src[prop], true)\n                : src[prop];\n        }\n    }\n    return ret;\n};\n\nShare\nImprove this answer\nFollow\nedited Jul 22 '16 at 17:31\ncommunity wiki\n\n\n4 revs, 4 users 59%\nuser1547016","comments":["It converts primitives into wrapper objects, not a good solution in most cases.","@DanubianSailor - I don't think it does...it seems to return primitives right away from the start, and doesn't seem to be doing anything to them that would turn them into wrapper objects as they are returned."]}]},{"id":"487258","href":"https://stackoverflow.com/questions/487258/what-is-a-plain-english-explanation-of-big-o-notation","title":"What is a plain English explanation of “Big O” notation?","description":"\n                \nI'd prefer as little formal definition as possible and simple mathematics.\n    ","questionComments":["Summary: The upper bound of the complexity of an algorithm. See also the similar question Big O, how do you calculate/approximate it? for a good explaination.","The other answers are quite good, just one detail to understand it: O(log n) or similar means, that it depends on the \"length\" or \"size\" of the input, not on the value itself. This could be hard to understand, but is very important. For example, this happens when your algorithm is splitting things in two in each iteration.","There is a lecture dedicated to complexity of the algorithms in the Lecture 8 of the MIT \"Introduction to Computer Science and Programming\" course youtube.com/watch?v=ewd7Lf2dr5Q It is not completely plain English, but gives nice explanation with examples that are easily understandable.","Big O is an estimate of the worst case performance of a function assuming the algorithm will perform the maximum number of iterations.","Big-O notation explained by a self-taught programmer"],"answers":[{"answer":"Quick note, my answer is almost certainly confusing Big Oh notation (which is an upper bound) with Big Theta notation \"Θ\" (which is a two-side bound). But in my experience, this is actually typical of discussions in non-academic settings. Apologies for any confusion caused.\n\nBigOh complexity can be visualized with this graph:\n\nThe simplest definition I can give for Big Oh notation is this:\n\nBig Oh notation is a relative representation of the complexity of an algorithm.\n\nThere are some important and deliberately chosen words in that sentence:\n\nrelative: you can only compare apples to apples. You can't compare an algorithm that does arithmetic multiplication to an algorithm that sorts a list of integers. But a comparison of two algorithms to do arithmetic operations (one multiplication, one addition) will tell you something meaningful;\nrepresentation: BigOh (in its simplest form) reduces the comparison between algorithms to a single variable. That variable is chosen based on observations or assumptions. For example, sorting algorithms are typically compared based on comparison operations (comparing two nodes to determine their relative ordering). This assumes that comparison is expensive. But what if the comparison is cheap but swapping is expensive? It changes the comparison; and\ncomplexity: if it takes me one second to sort 10,000 elements, how long will it take me to sort one million? Complexity in this instance is a relative measure to something else.\n\nCome back and reread the above when you've read the rest.\n\nThe best example of BigOh I can think of is doing arithmetic. Take two numbers (123456 and 789012). The basic arithmetic operations we learned in school were:\n\naddition;\nsubtraction;\nmultiplication; and\ndivision.\n\nEach of these is an operation or a problem. A method of solving these is called an algorithm.\n\nThe addition is the simplest. You line the numbers up (to the right) and add the digits in a column writing the last number of that addition in the result. The 'tens' part of that number is carried over to the next column.\n\nLet's assume that the addition of these numbers is the most expensive operation in this algorithm. It stands to reason that to add these two numbers together we have to add together 6 digits (and possibly carry a 7th). If we add two 100 digit numbers together we have to do 100 additions. If we add two 10,000 digit numbers we have to do 10,000 additions.\n\nSee the pattern? The complexity (being the number of operations) is directly proportional to the number of digits n in the larger number. We call this O(n) or linear complexity.\n\nSubtraction is similar (except you may need to borrow instead of carry).\n\nMultiplication is different. You line the numbers up, take the first digit in the bottom number and multiply it in turn against each digit in the top number and so on through each digit. So to multiply our two 6 digit numbers we must do 36 multiplications. We may need to do as many as 10 or 11 column adds to get the end result too.\n\nIf we have two 100-digit numbers we need to do 10,000 multiplications and 200 adds. For two one million digit numbers we need to do one trillion (1012) multiplications and two million adds.\n\nAs the algorithm scales with n-squared, this is O(n2) or quadratic complexity. This is a good time to introduce another important concept:\n\nWe only care about the most significant portion of complexity.\n\nThe astute may have realized that we could express the number of operations as: n2 + 2n. But as you saw from our example with two numbers of a million digits apiece, the second term (2n) becomes insignificant (accounting for 0.0002% of the total operations by that stage).\n\nOne can notice that we've assumed the worst case scenario here. While multiplying 6 digit numbers, if one of them has 4 digits and the other one has 6 digits, then we only have 24 multiplications. Still, we calculate the worst case scenario for that 'n', i.e when both are 6 digit numbers. Hence Big Oh notation is about the Worst-case scenario of an algorithm.\n\nThe Telephone Book\n\nThe next best example I can think of is the telephone book, normally called the White Pages or similar but it varies from country to country. But I'm talking about the one that lists people by surname and then initials or first name, possibly address and then telephone numbers.\n\nNow if you were instructing a computer to look up the phone number for \"John Smith\" in a telephone book that contains 1,000,000 names, what would you do? Ignoring the fact that you could guess how far in the S's started (let's assume you can't), what would you do?\n\nA typical implementation might be to open up to the middle, take the 500,000th and compare it to \"Smith\". If it happens to be \"Smith, John\", we just got really lucky. Far more likely is that \"John Smith\" will be before or after that name. If it's after we then divide the last half of the phone book in half and repeat. If it's before then we divide the first half of the phone book in half and repeat. And so on.\n\nThis is called a binary search and is used every day in programming whether you realize it or not.\n\nSo if you want to find a name in a phone book of a million names you can actually find any name by doing this at most 20 times. In comparing search algorithms we decide that this comparison is our 'n'.\n\nFor a phone book of 3 names it takes 2 comparisons (at most).\nFor 7 it takes at most 3.\nFor 15 it takes 4.\n…\nFor 1,000,000 it takes 20.\n\nThat is staggeringly good, isn't it?\n\nIn BigOh terms this is O(log n) or logarithmic complexity. Now the logarithm in question could be ln (base e), log10, log2 or some other base. It doesn't matter it's still O(log n) just like O(2n2) and O(100n2) are still both O(n2).\n\nIt's worthwhile at this point to explain that BigOh can be used to determine three cases with an algorithm:\n\nBest Case: In the telephone book search, the best case is that we find the name in one comparison. This is O(1) or constant complexity;\nExpected Case: As discussed above this is O(log n); and\nWorst Case: This is also O(log n).\n\nNormally we don't care about the best case. We're interested in the expected and worst case. Sometimes one or the other of these will be more important.\n\nBack to the telephone book.\n\nWhat if you have a phone number and want to find a name? The police have a reverse phone book but such look-ups are denied to the general public. Or are they? Technically you can reverse look-up a number in an ordinary phone book. How?\n\nYou start at the first name and compare the number. If it's a match, great, if not, you move on to the next. You have to do it this way because the phone book is unordered (by phone number anyway).\n\nSo to find a name given the phone number (reverse lookup):\n\nBest Case: O(1);\nExpected Case: O(n) (for 500,000); and\nWorst Case: O(n) (for 1,000,000).\nThe Traveling Salesman\n\nThis is quite a famous problem in computer science and deserves a mention. In this problem, you have N towns. Each of those towns is linked to 1 or more other towns by a road of a certain distance. The Traveling Salesman problem is to find the shortest tour that visits every town.\n\nSounds simple? Think again.\n\nIf you have 3 towns A, B, and C with roads between all pairs then you could go:\n\nA → B → C\nA → C → B\nB → C → A\nB → A → C\nC → A → B\nC → B → A\n\nWell, actually there's less than that because some of these are equivalent (A → B → C and C → B → A are equivalent, for example, because they use the same roads, just in reverse).\n\nIn actuality, there are 3 possibilities.\n\nTake this to 4 towns and you have (iirc) 12 possibilities.\nWith 5 it's 60.\n6 becomes 360.\n\nThis is a function of a mathematical operation called a factorial. Basically:\n\n5! = 5 × 4 × 3 × 2 × 1 = 120\n6! = 6 × 5 × 4 × 3 × 2 × 1 = 720\n7! = 7 × 6 × 5 × 4 × 3 × 2 × 1 = 5040\n…\n25! = 25 × 24 × … × 2 × 1 = 15,511,210,043,330,985,984,000,000\n…\n50! = 50 × 49 × … × 2 × 1 = 3.04140932 × 1064\n\nSo the BigOh of the Traveling Salesman problem is O(n!) or factorial or combinatorial complexity.\n\nBy the time you get to 200 towns there isn't enough time left in the universe to solve the problem with traditional computers.\n\nSomething to think about.\n\nPolynomial Time\n\nAnother point I wanted to make a quick mention of is that any algorithm that has a complexity of O(na) is said to have polynomial complexity or is solvable in polynomial time.\n\nO(n), O(n2) etc. are all polynomial time. Some problems cannot be solved in polynomial time. Certain things are used in the world because of this. Public Key Cryptography is a prime example. It is computationally hard to find two prime factors of a very large number. If it wasn't, we couldn't use the public key systems we use.\n\nAnyway, that's it for my (hopefully plain English) explanation of BigOh (revised).\n\nShare\nImprove this answer\nFollow\nedited Jul 2 at 11:45\nTop-Master\n3,6563\n3 gold badges\n18\n18 silver badges\n36\n36 bronze badges\nanswered Jan 28 '09 at 11:18\ncletus\n584k158\n158 gold badges\n891\n891 silver badges\n933\n933 bronze badges","comments":["While the other answers focus on explaining the differences between O(1), O(n^2) et al.... yours is the one which details how algorithms can get classified into n^2, nlog(n) etc. +1 for a good answer that helped me understand Big O notation as well","one might want to add that big-O represents an upper bound (given by an algorithm), big-Omega give a lower bound (usually given as a proof independent from a specific algorithm) and big-Theta means that an \"optimal\" algorithm reaching that lower bound is known.","This is good if you're looking for the longest answer, but not for the answer that best explains Big-O in a simple manner.","-1: This is blatantly wrong: _\"BigOh is relative representation of complexity of algorithm\". No. BigOh is an asymptotic upper bound and exists quite well independent of computer science. O(n) is linear. No, you are confusing BigOh with theta. log n is O(n). 1 is O(n). The number of upvotes to this answer (and the comments), which makes the basic mistake of confusing Theta with BigOh is quite embarassing...","\"By the time you get to 200 towns there isn't enough time left in the universe to solve the problem with traditional computers.\" When the universe is going to end?"]},{"answer":"It shows how an algorithm scales based on input size.\n\nO(n2): known as Quadratic complexity\n\n1 item: 1 operations\n10 items: 100 operations\n100 items: 10,000 operations\n\nNotice that the number of items increases by a factor of 10, but the time increases by a factor of 102. Basically, n=10 and so O(n2) gives us the scaling factor n2 which is 102.\n\nO(n): known as Linear complexity\n\n1 item: 1 second\n10 items: 10 seconds\n100 items: 100 seconds\n\nThis time the number of items increases by a factor of 10, and so does the time. n=10 and so O(n)'s scaling factor is 10.\n\nO(1): known as Constant complexity\n\n1 item: 1 operations\n10 items: 1 operations\n100 items: 1 operations\n\nThe number of items is still increasing by a factor of 10, but the scaling factor of O(1) is always 1.\n\nO(log n): known as Logarithmic complexity\n\n1 item: 1 operations\n10 items: 2 operations\n100 items: 3 operations\n1000 items: 4 operations\n10,000 items: 5 operations\n\nThe number of computations is only increased by a log of the input value. So in this case, assuming each computation takes 1 second, the log of the input n is the time required, hence log n.\n\nThat's the gist of it. They reduce the maths down so it might not be exactly n2 or whatever they say it is, but that'll be the dominating factor in the scaling.\n\nShare\nImprove this answer\nFollow\nedited Oct 11 '20 at 11:44\nRuben Helsloot\n10.7k5\n5 gold badges\n18\n18 silver badges\n36\n36 bronze badges\nanswered Jan 28 '09 at 11:28\nRay Hidayat\n15.3k4\n4 gold badges\n33\n33 silver badges\n43\n43 bronze badges","comments":["what does this definition mean exactly? (The number of items is still increasing by a factor of 10, but the scaling factor of O(1) is always 1.)","Not seconds, operations. Also, you missed out on factorial and logarithmic time.","This doesn't explain very well that O(n^2) could be describing an algorithm that runs in precisely .01*n^2 + 999999*n + 999999. It's important to know that algorithms are compared using this scale, and that the comparison works when n is 'sufficiently large'. Python's timsort actually uses insertion sort (worst/average case O(n^2)) for small arrays due to the fact that it has a small overhead.","This answer also confuses big O notation and Theta notation. The function of n that returns 1 for all its inputs (usually simply written as 1) is actually in O(n^2) (even though it is also in O(1)). Similarly, an algorithm that only has to do one step which takes a constant amount of time is also considered to be an O(1) algorithm, but also to be an O(n) and an O(n^2) algorithm. But maybe mathematicians and computer scientists don't agree on the definition :-/.","The O(log n) Logarithmic complexity considered in this answer is of the base 10. Generally the standard is to calculate with base 2. One should keep in mind this fact and should not get confused. Also as mentioned by @ChrisCharabaruk the complexity denotes number of operations and not seconds."]},{"answer":"Big-O notation (also called \"asymptotic growth\" notation) is what functions \"look like\" when you ignore constant factors and stuff near the origin. We use it to talk about how thing scale.\n\nBasics\n\nfor \"sufficiently\" large inputs...\n\nf(x) ∈ O(upperbound) means f \"grows no faster than\" upperbound\nf(x) ∈ Ɵ(justlikethis) mean f \"grows exactly like\" justlikethis\nf(x) ∈ Ω(lowerbound) means f \"grows no slower than\" lowerbound\n\nbig-O notation doesn't care about constant factors: the function 9x² is said to \"grow exactly like\" 10x². Neither does big-O asymptotic notation care about non-asymptotic stuff (\"stuff near the origin\" or \"what happens when the problem size is small\"): the function 10x² is said to \"grow exactly like\" 10x² - x + 2.\n\nWhy would you want to ignore the smaller parts of the equation? Because they become completely dwarfed by the big parts of the equation as you consider larger and larger scales; their contribution becomes dwarfed and irrelevant. (See example section.)\n\nPut another way, it's all about the ratio as you go to infinity. If you divide the actual time it takes by the O(...), you will get a constant factor in the limit of large inputs. Intuitively this makes sense: functions \"scale like\" one another if you can multiply one to get the other. That is when we say...\n\nactualAlgorithmTime(N) ∈ O(bound(N))\n                                       e.g. \"time to mergesort N elements \n                                             is O(N log(N))\"\n\n\n... this means that for \"large enough\" problem sizes N (if we ignore stuff near the origin), there exists some constant (e.g. 2.5, completely made up) such that:\n\nactualAlgorithmTime(N)                 e.g. \"mergesort_duration(N)       \"\n────────────────────── < constant            ───────────────────── < 2.5 \n       bound(N)                                    N log(N)         \n\n\nThere are many choices of constant; often the \"best\" choice is known as the \"constant factor\" of the algorithm... but we often ignore it like we ignore non-largest terms (see Constant Factors section for why they don't usually matter). You can also think of the above equation as a bound, saying \"In the worst-case scenario, the time it takes will never be worse than roughly N*log(N), within a factor of 2.5 (a constant factor we don't care much about)\".\n\nIn general, O(...) is the most useful one because we often care about worst-case behavior. If f(x) represents something \"bad\" like the processor or memory usage, then \"f(x) ∈ O(upperbound)\" means \"upperbound is the worst-case scenario of processor/memory usage\".\n\nApplications\n\nAs a purely mathematical construct, big-O notation is not limited to talking about processing time and memory. You can use it to discuss the asymptotics of anything where scaling is meaningful, such as:\n\nthe number of possible handshakes among N people at a party (Ɵ(N²), specifically N(N-1)/2, but what matters is that it \"scales like\" N²)\nprobabilistic expected number of people who have seen some viral marketing as a function of time\nhow website latency scales with the number of processing units in a CPU or GPU or computer cluster\nhow heat output scales on CPU dies as a function of transistor count, voltage, etc.\nhow much time an algorithm needs to run, as a function of input size\nhow much space an algorithm needs to run, as a function of input size\n\nExample\n\nFor the handshake example above, everyone in a room shakes everyone else's hand. In that example, #handshakes ∈ Ɵ(N²). Why?\n\nBack up a bit: the number of handshakes is exactly n-choose-2 or N*(N-1)/2 (each of N people shakes the hands of N-1 other people, but this double-counts handshakes so divide by 2):\n\n \n\nHowever, for very large numbers of people, the linear term N is dwarfed and effectively contributes 0 to the ratio (in the chart: the fraction of empty boxes on the diagonal over total boxes gets smaller as the number of participants becomes larger). Therefore the scaling behavior is order N², or the number of handshakes \"grows like N²\".\n\n#handshakes(N)\n────────────── ≈ 1/2\n     N²\n\n\nIt's as if the empty boxes on the diagonal of the chart (N*(N-1)/2 checkmarks) weren't even there (N2 checkmarks asymptotically).\n\n(temporary digression from \"plain English\":) If you wanted to prove this to yourself, you could perform some simple algebra on the ratio to split it up into multiple terms (lim means \"considered in the limit of\", just ignore it if you haven't seen it, it's just notation for \"and N is really really big\"):\n\n    N²/2 - N/2         (N²)/2   N/2         1/2\nlim ────────── = lim ( ────── - ─── ) = lim ─── = 1/2\nN→∞     N²       N→∞     N²     N²      N→∞  1\n                               ┕━━━┙\n             this is 0 in the limit of N→∞:\n             graph it, or plug in a really large number for N\n\n\ntl;dr: The number of handshakes 'looks like' x² so much for large values, that if we were to write down the ratio #handshakes/x², the fact that we don't need exactly x² handshakes wouldn't even show up in the decimal for an arbitrarily large while.\n\ne.g. for x=1million, ratio #handshakes/x²: 0.499999...\n\nBuilding Intuition\n\nThis lets us make statements like...\n\n\"For large enough inputsize=N, no matter what the constant factor is, if I double the input size...\n\n... I double the time an O(N) (\"linear time\") algorithm takes.\"\n... I double-squared (quadruple) the time an O(N²) (\"quadratic time\") algorithm takes.\" (e.g. a problem 100x as big takes 100²=10000x as long... possibly unsustainable)\n... I double-cubed (octuple) the time an O(N³) (\"cubic time\") algorithm takes.\" (e.g. a problem 100x as big takes 100³=1000000x as long... very unsustainable)\n... I add a fixed amount to the time an O(log(N)) (\"logarithmic time\") algorithm takes.\" (cheap!)\n... I don't change the time an O(1) (\"constant time\") algorithm takes.\" (the cheapest!)\n... I \"(basically) double\" the time an O(N log(N)) algorithm takes.\" (fairly common)\n... I ridiculously increase the time a O(2N) (\"exponential time\") algorithm takes.\" (you'd double (or triple, etc.) the time just by increasing the problem by a single unit)\n\n[for the mathematically inclined, you can mouse over the spoilers for minor sidenotes]\n\n(with credit to https://stackoverflow.com/a/487292/711085 )\n\n(technically the constant factor could maybe matter in some more esoteric examples, but I've phrased things above (e.g. in log(N)) such that it doesn't)\n\nThese are the bread-and-butter orders of growth that programmers and applied computer scientists use as reference points. They see these all the time. (So while you could technically think \"Doubling the input makes an O(√N) algorithm 1.414 times slower,\" it's better to think of it as \"this is worse than logarithmic but better than linear\".)\n\nConstant factors\n\nUsually, we don't care what the specific constant factors are, because they don't affect the way the function grows. For example, two algorithms may both take O(N) time to complete, but one may be twice as slow as the other. We usually don't care too much unless the factor is very large since optimizing is tricky business ( When is optimisation premature? ); also the mere act of picking an algorithm with a better big-O will often improve performance by orders of magnitude.\n\nSome asymptotically superior algorithms (e.g. a non-comparison O(N log(log(N))) sort) can have so large a constant factor (e.g. 100000*N log(log(N))), or overhead that is relatively large like O(N log(log(N))) with a hidden + 100*N, that they are rarely worth using even on \"big data\".\n\nWhy O(N) is sometimes the best you can do, i.e. why we need datastructures\n\nO(N) algorithms are in some sense the \"best\" algorithms if you need to read all your data. The very act of reading a bunch of data is an O(N) operation. Loading it into memory is usually O(N) (or faster if you have hardware support, or no time at all if you've already read the data). However, if you touch or even look at every piece of data (or even every other piece of data), your algorithm will take O(N) time to perform this looking. No matter how long your actual algorithm takes, it will be at least O(N) because it spent that time looking at all the data.\n\nThe same can be said for the very act of writing. All algorithms which print out N things will take N time because the output is at least that long (e.g. printing out all permutations (ways to rearrange) a set of N playing cards is factorial: O(N!)).\n\nThis motivates the use of data structures: a data structure requires reading the data only once (usually O(N) time), plus some arbitrary amount of preprocessing (e.g. O(N) or O(N log(N)) or O(N²)) which we try to keep small. Thereafter, modifying the data structure (insertions/deletions/ etc.) and making queries on the data take very little time, such as O(1) or O(log(N)). You then proceed to make a large number of queries! In general, the more work you're willing to do ahead of time, the less work you'll have to do later on.\n\nFor example, say you had the latitude and longitude coordinates of millions of road segments and wanted to find all street intersections.\n\nNaive method: If you had the coordinates of a street intersection, and wanted to examine nearby streets, you would have to go through the millions of segments each time, and check each one for adjacency.\nIf you only needed to do this once, it would not be a problem to have to do the naive method of O(N) work only once, but if you want to do it many times (in this case, N times, once for each segment), we'd have to do O(N²) work, or 1000000²=1000000000000 operations. Not good (a modern computer can perform about a billion operations per second).\nIf we use a simple structure called a hash table (an instant-speed lookup table, also known as a hashmap or dictionary), we pay a small cost by preprocessing everything in O(N) time. Thereafter, it only takes constant time on average to look up something by its key (in this case, our key is the latitude and longitude coordinates, rounded into a grid; we search the adjacent gridspaces of which there are only 9, which is a constant).\nOur task went from an infeasible O(N²) to a manageable O(N), and all we had to do was pay a minor cost to make a hash table.\nanalogy: The analogy in this particular case is a jigsaw puzzle: We created a data structure that exploits some property of the data. If our road segments are like puzzle pieces, we group them by matching color and pattern. We then exploit this to avoid doing extra work later (comparing puzzle pieces of like color to each other, not to every other single puzzle piece).\n\nThe moral of the story: a data structure lets us speed up operations. Even more, advanced data structures can let you combine, delay, or even ignore operations in incredibly clever ways. Different problems would have different analogies, but they'd all involve organizing the data in a way that exploits some structure we care about, or which we've artificially imposed on it for bookkeeping. We do work ahead of time (basically planning and organizing), and now repeated tasks are much much easier!\n\nPractical example: visualizing orders of growth while coding\n\nAsymptotic notation is, at its core, quite separate from programming. Asymptotic notation is a mathematical framework for thinking about how things scale and can be used in many different fields. That said... this is how you apply asymptotic notation to coding.\n\nThe basics: Whenever we interact with every element in a collection of size A (such as an array, a set, all keys of a map, etc.), or perform A iterations of a loop, that is a multiplicative factor of size A. Why do I say \"a multiplicative factor\"?--because loops and functions (almost by definition) have multiplicative running time: the number of iterations, times work done in the loop (or for functions: the number of times you call the function, times work done in the function). (This holds if we don't do anything fancy, like skip loops or exit the loop early, or change control flow in the function based on arguments, which is very common.) Here are some examples of visualization techniques, with accompanying pseudocode.\n\n(here, the xs represent constant-time units of work, processor instructions, interpreter opcodes, whatever)\n\nfor(i=0; i<A; i++)        // A * ...\n    some O(1) operation     // 1\n\n--> A*1 --> O(A) time\n\nvisualization:\n\n|<------ A ------->|\n1 2 3 4 5 x x ... x\n\nother languages, multiplying orders of growth:\n  javascript, O(A) time and space\n    someListOfSizeA.map((x,i) => [x,i])               \n  python, O(rows*cols) time and space\n    [[r*c for c in range(cols)] for r in range(rows)]\n\n\nExample 2:\n\nfor every x in listOfSizeA:   // A * (...\n    some O(1) operation         // 1\n    some O(B) operation         // B\n    for every y in listOfSizeC: // C * (...\n        some O(1) operation       // 1))\n\n--> O(A*(1 + B + C))\n    O(A*(B+C))        (1 is dwarfed)\n\nvisualization:\n\n|<------ A ------->|\n1 x x x x x x ... x\n\n2 x x x x x x ... x ^\n3 x x x x x x ... x |\n4 x x x x x x ... x |\n5 x x x x x x ... x B  <-- A*B\nx x x x x x x ... x |\n................... |\nx x x x x x x ... x v\n\nx x x x x x x ... x ^\nx x x x x x x ... x |\nx x x x x x x ... x |\nx x x x x x x ... x C  <-- A*C\nx x x x x x x ... x |\n................... |\nx x x x x x x ... x v\n\n\nExample 3:\n\nfunction nSquaredFunction(n) {\n    total = 0\n    for i in 1..n:        // N *\n        for j in 1..n:      // N *\n            total += i*k      // 1\n    return total\n}\n// O(n^2)\n\nfunction nCubedFunction(a) {\n    for i in 1..n:                // A *\n        print(nSquaredFunction(a))  // A^2\n}\n// O(a^3)\n\n\nIf we do something slightly complicated, you might still be able to imagine visually what's going on:\n\nfor x in range(A):\n    for y in range(1..x):\n        simpleOperation(x*y)\n\nx x x x x x x x x x |\nx x x x x x x x x   |\nx x x x x x x x     |\nx x x x x x x       |\nx x x x x x         |\nx x x x x           |\nx x x x             |\nx x x               |\nx x                 |\nx___________________|\n\n\nHere, the smallest recognizable outline you can draw is what matters; a triangle is a two dimensional shape (0.5 A^2), just like a square is a two-dimensional shape (A^2); the constant factor of two here remains in the asymptotic ratio between the two, however, we ignore it like all factors... (There are some unfortunate nuances to this technique I don't go into here; it can mislead you.)\n\nOf course this does not mean that loops and functions are bad; on the contrary, they are the building blocks of modern programming languages, and we love them. However, we can see that the way we weave loops and functions and conditionals together with our data (control flow, etc.) mimics the time and space usage of our program! If time and space usage becomes an issue, that is when we resort to cleverness and find an easy algorithm or data structure we hadn't considered, to reduce the order of growth somehow. Nevertheless, these visualization techniques (though they don't always work) can give you a naive guess at a worst-case running time.\n\nHere is another thing we can recognize visually:\n\n<----------------------------- N ----------------------------->\nx x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x\nx x x x x x x x x x x x x x x x\nx x x x x x x x\nx x x x\nx x\nx\n\n\nWe can just rearrange this and see it's O(N):\n\n<----------------------------- N ----------------------------->\nx x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x\nx x x x x x x x x x x x x x x x|x x x x x x x x|x x x x|x x|x\n\n\nOr maybe you do log(N) passes of the data, for O(N*log(N)) total time:\n\n   <----------------------------- N ----------------------------->\n ^  x x x x x x x x x x x x x x x x|x x x x x x x x x x x x x x x x\n |  x x x x x x x x|x x x x x x x x|x x x x x x x x|x x x x x x x x\nlgN x x x x|x x x x|x x x x|x x x x|x x x x|x x x x|x x x x|x x x x\n |  x x|x x|x x|x x|x x|x x|x x|x x|x x|x x|x x|x x|x x|x x|x x|x x\n v  x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x|x\n\n\nUnrelatedly but worth mentioning again: If we perform a hash (e.g. a dictionary/hashtable lookup), that is a factor of O(1). That's pretty fast.\n\n[myDictionary.has(x) for x in listOfSizeA]\n \\----- O(1) ------/    \n\n--> A*1 --> O(A)\n\n\nIf we do something very complicated, such as with a recursive function or divide-and-conquer algorithm, you can use the Master Theorem (usually works), or in ridiculous cases the Akra-Bazzi Theorem (almost always works) you look up the running time of your algorithm on Wikipedia.\n\nBut, programmers don't think like this because eventually, algorithm intuition just becomes second nature. You will start to code something inefficient and immediately think \"am I doing something grossly inefficient?\". If the answer is \"yes\" AND you foresee it actually mattering, then you can take a step back and think of various tricks to make things run faster (the answer is almost always \"use a hashtable\", rarely \"use a tree\", and very rarely something a bit more complicated).\n\nAmortized and average-case complexity\n\nThere is also the concept of \"amortized\" and/or \"average case\" (note that these are different).\n\nAverage Case: This is no more than using big-O notation for the expected value of a function, rather than the function itself. In the usual case where you consider all inputs to be equally likely, the average case is just the average of the running time. For example with quicksort, even though the worst-case is O(N^2) for some really bad inputs, the average case is the usual O(N log(N)) (the really bad inputs are very small in number, so few that we don't notice them in the average case).\n\nAmortized Worst-Case: Some data structures may have a worst-case complexity that is large, but guarantee that if you do many of these operations, the average amount of work you do will be better than worst-case. For example, you may have a data structure that normally takes constant O(1) time. However, occasionally it will 'hiccup' and take O(N) time for one random operation, because maybe it needs to do some bookkeeping or garbage collection or something... but it promises you that if it does hiccup, it won't hiccup again for N more operations. The worst-case cost is still O(N) per operation, but the amortized cost over many runs is O(N)/N = O(1) per operation. Because the big operations are sufficiently rare, the massive amount of occasional work can be considered to blend in with the rest of the work as a constant factor. We say the work is \"amortized\" over a sufficiently large number of calls that it disappears asymptotically.\n\nThe analogy for amortized analysis:\n\nYou drive a car. Occasionally, you need to spend 10 minutes going to the gas station and then spend 1 minute refilling the tank with gas. If you did this every time you went anywhere with your car (spend 10 minutes driving to the gas station, spend a few seconds filling up a fraction of a gallon), it would be very inefficient. But if you fill up the tank once every few days, the 11 minutes spent driving to the gas station is \"amortized\" over a sufficiently large number of trips, that you can ignore it and pretend all your trips were maybe 5% longer.\n\nComparison between average-case and amortized worst-case:\n\nAverage-case: We make some assumptions about our inputs; i.e. if our inputs have different probabilities, then our outputs/runtimes will have different probabilities (which we take the average of). Usually, we assume that our inputs are all equally likely (uniform probability), but if the real-world inputs don't fit our assumptions of \"average input\", the average output/runtime calculations may be meaningless. If you anticipate uniformly random inputs though, this is useful to think about!\nAmortized worst-case: If you use an amortized worst-case data structure, the performance is guaranteed to be within the amortized worst-case... eventually (even if the inputs are chosen by an evil demon who knows everything and is trying to screw you over). Usually, we use this to analyze algorithms that may be very 'choppy' in performance with unexpected large hiccups, but over time perform just as well as other algorithms. (However unless your data structure has upper limits for much outstanding work it is willing to procrastinate on, an evil attacker could perhaps force you to catch up on the maximum amount of procrastinated work all-at-once.\n\nThough, if you're reasonably worried about an attacker, there are many other algorithmic attack vectors to worry about besides amortization and average-case.)\n\nBoth average-case and amortization are incredibly useful tools for thinking about and designing with scaling in mind.\n\n(See Difference between average case and amortized analysis if interested in this subtopic.)\n\nMultidimensional big-O\n\nMost of the time, people don't realize that there's more than one variable at work. For example, in a string-search algorithm, your algorithm may take time O([length of text] + [length of query]), i.e. it is linear in two variables like O(N+M). Other more naive algorithms may be O([length of text]*[length of query]) or O(N*M). Ignoring multiple variables is one of the most common oversights I see in algorithm analysis, and can handicap you when designing an algorithm.\n\nThe whole story\n\nKeep in mind that big-O is not the whole story. You can drastically speed up some algorithms by using caching, making them cache-oblivious, avoiding bottlenecks by working with RAM instead of disk, using parallelization, or doing work ahead of time -- these techniques are often independent of the order-of-growth \"big-O\" notation, though you will often see the number of cores in the big-O notation of parallel algorithms.\n\nAlso keep in mind that due to hidden constraints of your program, you might not really care about asymptotic behavior. You may be working with a bounded number of values, for example:\n\nIf you're sorting something like 5 elements, you don't want to use the speedy O(N log(N)) quicksort; you want to use insertion sort, which happens to perform well on small inputs. These situations often come up in divide-and-conquer algorithms, where you split up the problem into smaller and smaller subproblems, such as recursive sorting, fast Fourier transforms, or matrix multiplication.\nIf some values are effectively bounded due to some hidden fact (e.g. the average human name is softly bounded at perhaps 40 letters, and human age is softly bounded at around 150). You can also impose bounds on your input to effectively make terms constant.\n\nIn practice, even among algorithms which have the same or similar asymptotic performance, their relative merit may actually be driven by other things, such as: other performance factors (quicksort and mergesort are both O(N log(N)), but quicksort takes advantage of CPU caches); non-performance considerations, like ease of implementation; whether a library is available, and how reputable and maintained the library is.\n\nPrograms will also run slower on a 500MHz computer vs 2GHz computer. We don't really consider this as part of the resource bounds, because we think of the scaling in terms of machine resources (e.g. per clock cycle), not per real second. However, there are similar things which can 'secretly' affect performance, such as whether you are running under emulation, or whether the compiler optimized code or not. These might make some basic operations take longer (even relative to each other), or even speed up or slow down some operations asymptotically (even relative to each other). The effect may be small or large between different implementation and/or environment. Do you switch languages or machines to eke out that little extra work? That depends on a hundred other reasons (necessity, skills, coworkers, programmer productivity, the monetary value of your time, familiarity, workarounds, why not assembly or GPU, etc...), which may be more important than performance.\n\nThe above issues, like the effect of the choice of which programming language is used, are almost never considered as part of the constant factor (nor should they be); yet one should be aware of them because sometimes (though rarely) they may affect things. For example in cpython, the native priority queue implementation is asymptotically non-optimal (O(log(N)) rather than O(1) for your choice of insertion or find-min); do you use another implementation? Probably not, since the C implementation is probably faster, and there are probably other similar issues elsewhere. There are tradeoffs; sometimes they matter and sometimes they don't.\n\n(edit: The \"plain English\" explanation ends here.)\n\nMath addenda\n\nFor completeness, the precise definition of big-O notation is as follows: f(x) ∈ O(g(x)) means that \"f is asymptotically upper-bounded by const*g\": ignoring everything below some finite value of x, there exists a constant such that |f(x)| ≤ const * |g(x)|. (The other symbols are as follows: just like O means ≤, Ω means ≥. There are lowercase variants: o means <, and ω means >.) f(x) ∈ Ɵ(g(x)) means both f(x) ∈ O(g(x)) and f(x) ∈ Ω(g(x)) (upper- and lower-bounded by g): there exists some constants such that f will always lie in the \"band\" between const1*g(x) and const2*g(x). It is the strongest asymptotic statement you can make and roughly equivalent to ==. (Sorry, I elected to delay the mention of the absolute-value symbols until now, for clarity's sake; especially because I have never seen negative values come up in a computer science context.)\n\nPeople will often use = O(...), which is perhaps the more correct 'comp-sci' notation, and entirely legitimate to use; \"f = O(...)\" is read \"f is order ... / f is xxx-bounded by ...\" and is thought of as \"f is some expression whose asymptotics are ...\". I was taught to use the more rigorous ∈ O(...). ∈ means \"is an element of\" (still read as before). In this particular case, O(N²) contains elements like {2 N², 3 N², 1/2 N², 2 N² + log(N), - N² + N^1.9, ...} and is infinitely large, but it's still a set.\n\nO and Ω are not symmetric (n = O(n²), but n² is not O(n)), but Ɵ is symmetric, and (since these relations are all transitive and reflexive) Ɵ, therefore, is symmetric and transitive and reflexive, and therefore partitions the set of all functions into equivalence classes. An equivalence class is a set of things that we consider to be the same. That is to say, given any function you can think of, you can find a canonical/unique 'asymptotic representative' of the class (by generally taking the limit... I think); just like you can group all integers into odds or evens, you can group all functions with Ɵ into x-ish, log(x)^2-ish, etc... by basically ignoring smaller terms (but sometimes you might be stuck with more complicated functions which are separate classes unto themselves).\n\nThe = notation might be the more common one and is even used in papers by world-renowned computer scientists. Additionally, it is often the case that in a casual setting, people will say O(...) when they mean Ɵ(...); this is technically true since the set of things Ɵ(exactlyThis) is a subset of O(noGreaterThanThis)... and it's easier to type. ;-)\n\nShare\nImprove this answer\nFollow\nedited Jul 7 at 17:05\nanswered Jul 8 '11 at 4:46\nninjagecko\n78.9k22\n22 gold badges\n131\n131 silver badges\n140\n140 bronze badges","comments":["An excellent mathematical answer, but the OP asked for a plain English answer. This level of mathematical description isn't required to understand the answer, though for people particularly mathematically minded it may be a lot simpler to understand than \"plain English\". However the OP asked for the latter.","Presumably people other than the OP might have an interest in the answers to this question. Isn't that the guiding principle of the site?","While I can maybe see why people might skim my answer and think it is too mathy (especially the \"math is the new plain english\" snide remarks, since removed), the original question asks about big-O which is about functions, so I attempt to be explicit and talk about functions in a way that complements the plain-English intuition. The math here can often be glossed over, or understood with a highschool math background. I do feel that people may look at the Math Addenda at the end though, and assume that is part of the answer, when it is merely there to see what the real math looks like.","This is a fantastic answer; much better IMO than the one with the most votes. The \"math\" required doesn't go beyond what's needed to understand the expressions in the parentheses after the \"O,\" which no reasonable explanation that uses any examples can avoid.","\"f(x) ∈ O(upperbound) means f \"grows no faster than\" upperbound\" these three simply worded, but mathematically proper explanations of big Oh, Theta, and Omega are golden. He described to me in plain english the point that 5 different sources couldn't seem to translate to me without writing complex mathematical expressions. Thanks man! :)"]},{"answer":"EDIT: Quick note, this is almost certainly confusing Big O notation (which is an upper bound) with Theta notation (which is both an upper and lower bound). In my experience this is actually typical of discussions in non-academic settings. Apologies for any confusion caused.\n\nIn one sentence: As the size of your job goes up, how much longer does it take to complete it?\n\nObviously that's only using \"size\" as the input and \"time taken\" as the output — the same idea applies if you want to talk about memory usage etc.\n\nHere's an example where we have N T-shirts which we want to dry. We'll assume it's incredibly quick to get them in the drying position (i.e. the human interaction is negligible). That's not the case in real life, of course...\n\nUsing a washing line outside: assuming you have an infinitely large back yard, washing dries in O(1) time. However much you have of it, it'll get the same sun and fresh air, so the size doesn't affect the drying time.\n\nUsing a tumble dryer: you put 10 shirts in each load, and then they're done an hour later. (Ignore the actual numbers here — they're irrelevant.) So drying 50 shirts takes about 5 times as long as drying 10 shirts.\n\nPutting everything in an airing cupboard: If we put everything in one big pile and just let general warmth do it, it will take a long time for the middle shirts to get dry. I wouldn't like to guess at the detail, but I suspect this is at least O(N^2) — as you increase the wash load, the drying time increases faster.\n\nOne important aspect of \"big O\" notation is that it doesn't say which algorithm will be faster for a given size. Take a hashtable (string key, integer value) vs an array of pairs (string, integer). Is it faster to find a key in the hashtable or an element in the array, based on a string? (i.e. for the array, \"find the first element where the string part matches the given key.\") Hashtables are generally amortised (~= \"on average\") O(1) — once they're set up, it should take about the same time to find an entry in a 100 entry table as in a 1,000,000 entry table. Finding an element in an array (based on content rather than index) is linear, i.e. O(N) — on average, you're going to have to look at half the entries.\n\nDoes this make a hashtable faster than an array for lookups? Not necessarily. If you've got a very small collection of entries, an array may well be faster — you may be able to check all the strings in the time that it takes to just calculate the hashcode of the one you're looking at. As the data set grows larger, however, the hashtable will eventually beat the array.\n\nShare\nImprove this answer\nFollow\nedited Nov 8 '11 at 6:15\nanswered Jan 28 '09 at 11:16\nJon Skeet\n1.3m800\n800 gold badges\n8772\n8772 silver badges\n8958\n8958 bronze badges","comments":["A hashtable requires an algorithm to run to calculate the index of the actual array ( depending on the implementation ). And an array just have O(1) because it's just an adress. But this has nothing to do with the question, just an observation :)","jon's explanation has very much todo with the question i think. it's exactly how one could explain it to some mum, and she would eventually understand it i think :) i like the clothes example (in particular the last, where it explains the exponential growth of complexity)","Filip: I'm not talking about address an array by index, I'm talking about finding a matching entry in an array. Could you reread the answer and see if that's still unclear?","@Filip Ekberg I think you're thinking of a direct-address table where each index maps to a key directly hence is O(1), however I believe Jon is talking about an unsorted array of key/val pairs which you have to search through linearly.","@RBT: No, it's not a binary look-up. It can get to the right hash bucket immediately, just based on a transformation from hash code to bucket index. After that, finding the right hash code in the bucket may be linear or it may be a binary search... but by that time you're down to a very small proportion of the total size of the dictionary."]},{"answer":"Big O describes an upper limit on the growth behaviour of a function, for example the runtime of a program, when inputs become large.\n\nExamples:\n\nO(n): If I double the input size the runtime doubles\n\nO(n2): If the input size doubles the runtime quadruples\n\nO(log n): If the input size doubles the runtime increases by one\n\nO(2n): If the input size increases by one, the runtime doubles\n\nThe input size is usually the space in bits needed to represent the input.\n\nShare\nImprove this answer\nFollow\nedited Jan 11 '14 at 11:11\nanswered Jan 28 '09 at 11:23\nstarblue\n52.1k14\n14 gold badges\n90\n90 silver badges\n146\n146 bronze badges","comments":["incorrect! for example O(n): If I double the input size the runtime will multiply to finite non zero constant. I mean O(n) = O(n + n)","I'm talking about the f in f(n) = O(g(n)), not the g as you seem to understand.","I upvoted, but the last sentence doesn't contribute much I feel. We don't often talk about \"bits\" when discussing or measuring Big(O).","You should add an example for O(n log n).","That's not so clear, essentially it behaves a little worse than O(n). So if n doubles, the runtime is multiplied by a factor somewhat larger than 2."]},{"answer":"Big O notation is most commonly used by programmers as an approximate measure of how long a computation (algorithm) will take to complete expressed as a function of the size of the input set.\n\nBig O is useful to compare how well two algorithms will scale up as the number of inputs is increased.\n\nMore precisely Big O notation is used to express the asymptotic behavior of a function. That means how the function behaves as it approaches infinity.\n\nIn many cases the \"O\" of an algorithm will fall into one of the following cases:\n\nO(1) - Time to complete is the same regardless of the size of input set. An example is accessing an array element by index.\nO(Log N) - Time to complete increases roughly in line with the log2(n). For example 1024 items takes roughly twice as long as 32 items, because Log2(1024) = 10 and Log2(32) = 5. An example is finding an item in a binary search tree (BST).\nO(N) - Time to complete that scales linearly with the size of the input set. In other words if you double the number of items in the input set, the algorithm takes roughly twice as long. An example is counting the number of items in a linked list.\nO(N Log N) - Time to complete increases by the number of items times the result of Log2(N). An example of this is heap sort and quick sort.\nO(N^2) - Time to complete is roughly equal to the square of the number of items. An example of this is bubble sort.\nO(N!) - Time to complete is the factorial of the input set. An example of this is the traveling salesman problem brute-force solution.\n\nBig O ignores factors that do not contribute in a meaningful way to the growth curve of a function as the input size increases towards infinity. This means that constants that are added to or multiplied by the function are simply ignored.\n\nShare\nImprove this answer\nFollow\nedited Sep 13 '11 at 3:08\nHod - Monica's Army\n86514\n14 silver badges\n28\n28 bronze badges\nanswered Sep 5 '11 at 16:31\ncdiggins\n15.8k6\n6 gold badges\n93\n93 silver badges\n95\n95 bronze badges","comments":["cdiggins, what if i have O(N/2) complexity , should it be O(N) or O(N/2), for example what the complexity if i will loop over half string.","@Melad This is an example of a constant (0.5) being multiplied to the function. This is ignored as it is considered to have a meaningful effect for very large values of N."]},{"answer":"Big O is just a way to \"Express\" yourself in a common way, \"How much time / space does it take to run my code?\".\n\nYou may often see O(n), O(n2), O(nlogn) and so forth, all these are just ways to show; How does an algorithm change?\n\nO(n) means Big O is n, and now you might think, \"What is n!?\" Well \"n\" is the amount of elements. Imaging you want to search for an Item in an Array. You would have to look on Each element and as \"Are you the correct element/item?\" in the worst case, the item is at the last index, which means that it took as much time as there are items in the list, so to be generic, we say \"oh hey, n is a fair given amount of values!\".\n\nSo then you might understand what \"n2\" means, but to be even more specific, play with the thought you have a simple, the simpliest of the sorting algorithms; bubblesort. This algorithm needs to look through the whole list, for each item.\n\nMy list\n\n1\n6\n3\n\nThe flow here would be:\n\nCompare 1 and 6, which is biggest? Ok 6 is in the right position, moving forward!\nCompare 6 and 3, oh, 3 is less! Let's move that, Ok the list changed, we need to start from the begining now!\n\nThis is O n2 because, you need to look at all items in the list there are \"n\" items. For each item, you look at all items once more, for comparing, this is also \"n\", so for every item, you look \"n\" times meaning n*n = n2\n\nI hope this is as simple as you want it.\n\nBut remember, Big O is just a way to experss yourself in the manner of time and space.\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 20:47\nElrond_EGLDer\n48.5k25\n25 gold badges\n192\n192 silver badges\n180\n180 bronze badges\nanswered Jan 28 '09 at 11:14\nFilip Ekberg\n35.3k18\n18 gold badges\n118\n118 silver badges\n179\n179 bronze badges","comments":["for logN we consider for loop running from 0 to N/2 the what about O(log log N)? I mean how does program look like? pardon me for pure math skills"]},{"answer":"Big O describes the fundamental scaling nature of an algorithm.\n\nThere is a lot of information that Big O does not tell you about a given algorithm. It cuts to the bone and gives only information about the scaling nature of an algorithm, specifically how the resource use (think time or memory) of an algorithm scales in response to the \"input size\".\n\nConsider the difference between a steam engine and a rocket. They are not merely different varieties of the same thing (as, say, a Prius engine vs. a Lamborghini engine) but they are dramatically different kinds of propulsion systems, at their core. A steam engine may be faster than a toy rocket, but no steam piston engine will be able to achieve the speeds of an orbital launch vehicle. This is because these systems have different scaling characteristics with regards to the relation of fuel required (\"resource usage\") to reach a given speed (\"input size\").\n\nWhy is this so important? Because software deals with problems that may differ in size by factors up to a trillion. Consider that for a moment. The ratio between the speed necessary to travel to the Moon and human walking speed is less than 10,000:1, and that is absolutely tiny compared to the range in input sizes software may face. And because software may face an astronomical range in input sizes there is the potential for the Big O complexity of an algorithm, it's fundamental scaling nature, to trump any implementation details.\n\nConsider the canonical sorting example. Bubble-sort is O(n2) while merge-sort is O(n log n). Let's say you have two sorting applications, application A which uses bubble-sort and application B which uses merge-sort, and let's say that for input sizes of around 30 elements application A is 1,000x faster than application B at sorting. If you never have to sort much more than 30 elements then it's obvious that you should prefer application A, as it is much faster at these input sizes. However, if you find that you may have to sort ten million items then what you'd expect is that application B actually ends up being thousands of times faster than application A in this case, entirely due to the way each algorithm scales.\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 20:48\nElrond_EGLDer\n48.5k25\n25 gold badges\n192\n192 silver badges\n180\n180 bronze badges\nanswered Jan 28 '09 at 13:12\nWedge\n18.7k7\n7 gold badges\n45\n45 silver badges\n69\n69 bronze badges","comments":[]},{"answer":"Here is the plain English bestiary I tend to use when explaining the common varieties of Big-O\n\nIn all cases, prefer algorithms higher up on the list to those lower on the list. However, the cost of moving to a more expensive complexity class varies significantly.\n\nO(1):\n\nNo growth. Regardless of how big as the problem is, you can solve it in the same amount of time. This is somewhat analogous to broadcasting where it takes the same amount of energy to broadcast over a given distance, regardless of the number of people that lie within the broadcast range.\n\nO(log n):\n\nThis complexity is the same as O(1) except that it's just a little bit worse. For all practical purposes, you can consider this as a very large constant scaling. The difference in work between processing 1 thousand and 1 billion items is only a factor six.\n\nO(n):\n\nThe cost of solving the problem is proportional to the size of the problem. If your problem doubles in size, then the cost of the solution doubles. Since most problems have to be scanned into the computer in some way, as data entry, disk reads, or network traffic, this is generally an affordable scaling factor.\n\nO(n log n):\n\nThis complexity is very similar to O(n). For all practical purposes, the two are equivalent. This level of complexity would generally still be considered scalable. By tweaking assumptions some O(n log n) algorithms can be transformed into O(n) algorithms. For example, bounding the size of keys reduces sorting from O(n log n) to O(n).\n\nO(n2):\n\nGrows as a square, where n is the length of the side of a square. This is the same growth rate as the \"network effect\", where everyone in a network might know everyone else in the network. Growth is expensive. Most scalable solutions cannot use algorithms with this level of complexity without doing significant gymnastics. This generally applies to all other polynomial complexities - O(nk) - as well.\n\nO(2n):\n\nDoes not scale. You have no hope of solving any non-trivially sized problem. Useful for knowing what to avoid, and for experts to find approximate algorithms which are in O(nk).\n\nShare\nImprove this answer\nFollow\nedited Mar 10 '14 at 6:51\nanswered Jan 27 '14 at 23:09\nAndrew Prock\n6,3035\n5 gold badges\n37\n37 silver badges\n58\n58 bronze badges","comments":["Could you please consider a different analogy for O(1)? The engineer in me wants to pull out a discussion about RF impedance due to obstructions."]},{"answer":"Big O is a measure of how much time/space an algorithm uses relative to the size of its input.\n\nIf an algorithm is O(n) then the time/space will increase at the same rate as its input.\n\nIf an algorithm is O(n2) then the time/space increase at the rate of its input squared.\n\nand so on.\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 20:49\nElrond_EGLDer\n48.5k25\n25 gold badges\n192\n192 silver badges\n180\n180 bronze badges\nanswered Jan 28 '09 at 11:19\nBrownie\n7,6105\n5 gold badges\n25\n25 silver badges\n38\n38 bronze badges","comments":["It's not about space. It's about complexity which means time.","I have always believed it can be about time OR space. but not about both at the same time.","Complexity most definitely can be about space. Have a look at this: en.wikipedia.org/wiki/PSPACE","This answer is the most \"plain\" one here. Previous ones actually assume readers know enough to understand them but writers are not aware of it. They think theirs are simple and plain, which are absolutely not. Writing a lot text with pretty format and making fancy artificial examples that are hard to non-CS people is not plain and simple, it is just attractive to stackoverflowers who are mostly CS people to up vote. Explaining CS term in plain English needs nothing about code and math at all. +1 for this answer though it is still not good enough.","This answer makes the (common) error of assuming that f=O(g) means that f and g are proportional."]},{"answer":"It is very difficult to measure the speed of software programs, and when we try, the answers can be very complex and filled with exceptions and special cases. This is a big problem, because all those exceptions and special cases are distracting and unhelpful when we want to compare two different programs with one another to find out which is \"fastest\".\n\nAs a result of all this unhelpful complexity, people try to describe the speed of software programs using the smallest and least complex (mathematical) expressions possible. These expressions are very very crude approximations: Although, with a bit of luck, they will capture the \"essence\" of whether a piece of software is fast or slow.\n\nBecause they are approximations, we use the letter \"O\" (Big Oh) in the expression, as a convention to signal to the reader that we are making a gross oversimplification. (And to make sure that nobody mistakenly thinks that the expression is in any way accurate).\n\nIf you read the \"Oh\" as meaning \"on the order of\" or \"approximately\" you will not go too far wrong. (I think the choice of the Big-Oh might have been an attempt at humour).\n\nThe only thing that these \"Big-Oh\" expressions try to do is to describe how much the software slows down as we increase the amount of data that the software has to process. If we double the amount of data that needs to be processed, does the software need twice as long to finish it's work? Ten times as long? In practice, there are a very limited number of big-Oh expressions that you will encounter and need to worry about:\n\nThe good:\n\nO(1) Constant: The program takes the same time to run no matter how big the input is.\nO(log n) Logarithmic: The program run-time increases only slowly, even with big increases in the size of the input.\n\nThe bad:\n\nO(n) Linear: The program run-time increases proportionally to the size of the input.\nO(n^k) Polynomial: - Processing time grows faster and faster - as a polynomial function - as the size of the input increases.\n\n... and the ugly:\n\nO(k^n) Exponential The program run-time increases very quickly with even moderate increases in the size of the problem - it is only practical to process small data sets with exponential algorithms.\nO(n!) Factorial The program run-time will be longer than you can afford to wait for anything but the very smallest and most trivial-seeming datasets.\nShare\nImprove this answer\nFollow\nanswered May 29 '13 at 13:51\nWilliam Payne\n2,5753\n3 gold badges\n21\n21 silver badges\n24\n24 bronze badges","comments":["I've also heard the term Linearithmic - O(n log n) which would be considered good."]},{"answer":"What is a plain English explanation of Big O? With as little formal definition as possible and simple mathematics.\n\nA Plain English Explanation of the Need for Big-O Notation:\n\nWhen we program, we are trying to solve a problem. What we code is called an algorithm. Big O notation allows us to compare the worse case performance of our algorithms in a standardized way. Hardware specs vary over time and improvements in hardware can reduce the time it takes an algorithms to run. But replacing the hardware does not mean our algorithm is any better or improved over time, as our algorithm is still the same. So in order to allow us to compare different algorithms, to determine if one is better or not, we use Big O notation.\n\nA Plain English Explanation of What Big O Notation is:\n\nNot all algorithms run in the same amount of time, and can vary based on the number of items in the input, which we'll call n. Based on this, we consider the worse case analysis, or an upper-bound of the run-time as n get larger and larger. We must be aware of what n is, because many of the Big O notations reference it.\n\nShare\nImprove this answer\nFollow\nedited Oct 7 '13 at 14:02\nanswered Feb 22 '13 at 1:00\nJames Oravec\n17.1k25\n25 gold badges\n78\n78 silver badges\n146\n146 bronze badges","comments":[]},{"answer":"Ok, my 2cents.\n\nBig-O, is rate of increase of resource consumed by program, w.r.t. problem-instance-size\n\nResource : Could be total-CPU time, could be maximum RAM space. By default refers to CPU time.\n\nSay the problem is \"Find the sum\",\n\nint Sum(int*arr,int size){\n      int sum=0;\n      while(size-->0) \n         sum+=arr[size]; \n\n      return sum;\n}\n\n\nproblem-instance= {5,10,15} ==> problem-instance-size = 3, iterations-in-loop= 3\n\nproblem-instance= {5,10,15,20,25} ==> problem-instance-size = 5 iterations-in-loop = 5\n\nFor input of size \"n\" the program is growing at speed of \"n\" iterations in array. Hence Big-O is N expressed as O(n)\n\nSay the problem is \"Find the Combination\",\n\n    void Combination(int*arr,int size)\n    { int outer=size,inner=size;\n      while(outer -->0) {\n        inner=size;\n        while(inner -->0)\n          cout<<arr[outer]<<\"-\"<<arr[inner]<<endl;\n      }\n    }\n\n\nproblem-instance= {5,10,15} ==> problem-instance-size = 3, total-iterations = 3*3 = 9\n\nproblem-instance= {5,10,15,20,25} ==> problem-instance-size = 5, total-iterations= 5*5 =25\n\nFor input of size \"n\" the program is growing at speed of \"n*n\" iterations in array. Hence Big-O is N2 expressed as O(n2)\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 20:48\nElrond_EGLDer\n48.5k25\n25 gold badges\n192\n192 silver badges\n180\n180 bronze badges\nanswered Aug 23 '11 at 4:06\nAjeet Ganga\n7,66010\n10 gold badges\n53\n53 silver badges\n72\n72 bronze badges","comments":["while (size-->0) I hope this wouldn't ask again."]},{"answer":"A simple straightforward answer can be:\n\nBig O represents the worst possible time/space for that algorithm. The algorithm will never take more space/time above that limit. Big O represents time/space complexity in the extreme case.\n\nShare\nImprove this answer\nFollow\nedited Mar 14 '14 at 16:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 13 '13 at 10:23\nAlienOnEarth\n7057\n7 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"Big O notation is a way of describing the upper bound of an algorithm in terms of space or running time. The n is the number of elements in the the problem (i.e size of an array, number of nodes in a tree, etc.) We are interested in describing the running time as n gets big.\n\nWhen we say some algorithm is O(f(n)) we are saying that the running time (or space required) by that algorithm is always lower than some constant times f(n).\n\nTo say that binary search has a running time of O(logn) is to say that there exists some constant c which you can multiply log(n) by that will always be larger than the running time of binary search. In this case you will always have some constant factor of log(n) comparisons.\n\nIn other words where g(n) is the running time of your algorithm, we say that g(n) = O(f(n)) when g(n) <= c*f(n) when n > k, where c and k are some constants.\n\nShare\nImprove this answer\nFollow\nanswered Jul 17 '10 at 2:29\nJohn C Earls\n7368\n8 silver badges\n10\n10 bronze badges","comments":["We can use BigO notation to measure the worst case and average case as well. en.wikipedia.org/wiki/Big_O_notation"]},{"answer":"\"What is a plain English explanation of Big O? With as little formal definition as possible and simple mathematics.\"\n\nSuch a beautifully simple and short question seems at least to deserve an equally short answer, like a student might receive during tutoring.\n\nBig O notation simply tells how much time* an algorithm can run within, in terms of only the amount of input data**.\n\n( *in a wonderful, unit-free sense of time!)\n(**which is what matters, because people will always want more, whether they live today or tomorrow)\n\nWell, what's so wonderful about Big O notation if that's what it does?\n\nPractically speaking, Big O analysis is so useful and important because Big O puts the focus squarely on the algorithm's own complexity and completely ignores anything that is merely a proportionality constant—like a JavaScript engine, the speed of a CPU, your Internet connection, and all those things which become quickly become as laughably outdated as a Model T. Big O focuses on performance only in the way that matters equally as much to people living in the present or in the future.\n\nBig O notation also shines a spotlight directly on the most important principle of computer programming/engineering, the fact which inspires all good programmers to keep thinking and dreaming: the only way to achieve results beyond the slow forward march of technology is to invent a better algorithm.\n\nShare\nImprove this answer\nFollow\nedited Aug 24 '13 at 6:50\nanswered Aug 15 '13 at 1:57\nJoseph Myers\n5,85124\n24 silver badges\n35\n35 bronze badges","comments":["Being asked to explain something mathematical without mathematics is always a personal challenge to me, as a bona fide Ph.D. mathematician and teacher who believes that such a thing is actually possible. And being a programmer as well, I hope that no one minds that I found answering this particular question, without mathematics, to be a challenge that was completely irresistible."]},{"answer":"Algorithm example (Java):\n\npublic boolean search(/* for */Integer K,/* in */List</* of */Integer> L)\n{\n    for(/* each */Integer i:/* in */L)\n    {\n        if(i == K)\n        {\n            return true;\n        }\n    }\n    \n    return false;\n}\n\n\nAlgorithm description:\n\nThis algorithm searches a list, item by item, looking for a key,\n\nIterating on each item in the list, if it's the key then return True,\n\nIf the loop has finished without finding the key, return False.\n\nBig-O notation represents the upper-bound on the Complexity (Time, Space, ..)\n\nTo find The Big-O on Time Complexity:\n\nCalculate how much time (regarding input size) the worst case takes:\n\nWorst-Case: the key doesn't exist in the list.\n\nTime(Worst-Case) = 4n+1\n\nTime: O(4n+1) = O(n) | in Big-O, constants are neglected\n\nO(n) ~ Linear\n\nThere's also Big-Omega, which represent the complexity of the Best-Case:\n\nBest-Case: the key is the first item.\n\nTime(Best-Case) = 4\n\nTime: Ω(4) = O(1) ~ Instant\\Constant\n\nShare\nImprove this answer\nFollow\nedited Nov 6 '20 at 15:38\nanswered Mar 23 '13 at 15:19\nKhaled.K\n5,5561\n1 gold badge\n30\n30 silver badges\n48\n48 bronze badges","comments":["Where does your constant 4 comes from?","@Rod iterator init, iterator comparison, iterator read, key comparison.. I think C would be better"]},{"answer":"Big O\n\nf(x) = O(g(x)) when x goes to a (for example, a = +∞) means that there is a function k such that:\n\nf(x) = k(x)g(x)\n\nk is bounded in some neighborhood of a (if a = +∞, this means that there are numbers N and M such that for every x > N, |k(x)| < M).\n\nIn other words, in plain English: f(x) = O(g(x)), x → a, means that in a neighborhood of a, f decomposes into the product of g and some bounded function.\n\nSmall o\n\nBy the way, here is for comparison the definition of small o.\n\nf(x) = o(g(x)) when x goes to a means that there is a function k such that:\n\nf(x) = k(x)g(x)\n\nk(x) goes to 0 when x goes to a.\n\nExamples\n\nsin x = O(x) when x → 0.\n\nsin x = O(1) when x → +∞,\n\nx2 + x = O(x) when x → 0,\n\nx2 + x = O(x2) when x → +∞,\n\nln(x) = o(x) = O(x) when x → +∞.\n\nAttention! The notation with the equal sign \"=\" uses a \"fake equality\": it is true that o(g(x)) = O(g(x)), but false that O(g(x)) = o(g(x)). Similarly, it is ok to write \"ln(x) = o(x) when x → +∞\", but the formula \"o(x) = ln(x)\" would make no sense.\n\nMore examples\n\nO(1) = O(n) = O(n2) when n → +∞ (but not the other way around, the equality is \"fake\"),\n\nO(n) + O(n2) = O(n2) when n → +∞\n\nO(O(n2)) = O(n2) when n → +∞\n\nO(n2)O(n3) = O(n5) when n → +∞\n\nHere is the Wikipedia article: https://en.wikipedia.org/wiki/Big_O_notation\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 20:50\nElrond_EGLDer\n48.5k25\n25 gold badges\n192\n192 silver badges\n180\n180 bronze badges\nanswered Mar 15 '13 at 21:18\nAlexey\n3,2815\n5 gold badges\n26\n26 silver badges\n40\n40 bronze badges","comments":["You are stating \"Big O\" and \"Small o\" without explainy what they are, introducing lots of mathematical concepts without telling why they are important and the link to wikipedia may be in this case too obvious for this kind of question.","@AditSaxena What do you mean \"without explaining what they are\"? I exactly explained what they are. That is, \"big O\" and \"small o\" are nothing by themselves, only a formula like \"f(x) = O(g(x))\" has a meaning, which i explained (in plain English, but without defining of course all the necessary things from a Calculus course). Sometimes \"O(f(x))\" is viewed as the class (actually the set) of all the functions \"g(x)\" such that \"g(x) = O(f(x))\", but this is an extra step, which is not necessary for understanding the basics.","Well, ok, there are words that are not plain English, but it is inevitable, unless i would have to include all necessary definitions from Mathematical Analysis.","Hi #Alexey, please have a look at accepted answer: it is long but it is well constructed and well formatted. It starts with a simple definition with no mathematical background needed. While doing so he introduce thre 3 \"technical\" words which he explains immediately (relative, representation, complexity). This goes on step by step while digging into this field.","Big O is used for understanding asymptotic behavior of algorithms for the same reason it is used for understanding asymptotic behavior of functions (asymptotic behavior is the behavior near infinity). It is a convenient notation for comparing a complicated function (the actual time or space the algorithm takes) to simple ones (anything simple, usually a power function) near infinity, or near anything else. I only explained what it is (gave the definition). How to compute with big O is a different story, maybe i'll add some examples, since you are interested."]},{"answer":"Big O notation is a way of describing how quickly an algorithm will run given an arbitrary number of input parameters, which we'll call \"n\". It is useful in computer science because different machines operate at different speeds, and simply saying that an algorithm takes 5 seconds doesn't tell you much because while you may be running a system with a 4.5 Ghz octo-core processor, I may be running a 15 year old, 800 Mhz system, which could take longer regardless of the algorithm. So instead of specifying how fast an algorithm runs in terms of time, we say how fast it runs in terms of number of input parameters, or \"n\". By describing algorithms in this way, we are able to compare the speeds of algorithms without having to take into account the speed of the computer itself.\n\nShare\nImprove this answer\nFollow\nedited May 12 '15 at 14:02\nanswered Jun 25 '14 at 20:32\nuser2427354","comments":[]},{"answer":"Not sure I'm further contributing to the subject but still thought I'd share: I once found this blog post to have some quite helpful (though very basic) explanations & examples on Big O:\n\nVia examples, this helped get the bare basics into my tortoiseshell-like skull, so I think it's a pretty descent 10-minute read to get you headed in the right direction.\n\nShare\nImprove this answer\nFollow\nedited Jan 15 '13 at 20:23\nn00begon\n3,4773\n3 gold badges\n26\n26 silver badges\n41\n41 bronze badges\nanswered Sep 29 '12 at 20:54\nPriidu Neemre\n2,5561\n1 gold badge\n35\n35 silver badges\n35\n35 bronze badges","comments":["@William ...and people tend to die of old age, species go extinct, planets turn barren etc."]},{"answer":"You want to know all there is to know of big O? So do I.\n\nSo to talk of big O, I will use words that have just one beat in them. One sound per word. Small words are quick. You know these words, and so do I. We will use words with one sound. They are small. I am sure you will know all of the words we will use!\n\nNow, let’s you and me talk of work. Most of the time, I do not like work. Do you like work? It may be the case that you do, but I am sure I do not.\n\nI do not like to go to work. I do not like to spend time at work. If I had my way, I would like just to play, and do fun things. Do you feel the same as I do?\n\nNow at times, I do have to go to work. It is sad, but true. So, when I am at work, I have a rule: I try to do less work. As near to no work as I can. Then I go play!\n\nSo here is the big news: the big O can help me not to do work! I can play more of the time, if I know big O. Less work, more play! That is what big O helps me do.\n\nNow I have some work. I have this list: one, two, three, four, five, six. I must add all things in this list.\n\nWow, I hate work. But oh well, I have to do this. So here I go.\n\nOne plus two is three… plus three is six... and four is... I don’t know. I got lost. It is too hard for me to do in my head. I don’t much care for this kind of work.\n\nSo let's not do the work. Let's you and me just think how hard it is. How much work would I have to do, to add six numbers?\n\nWell, let’s see. I must add one and two, and then add that to three, and then add that to four… All in all, I count six adds. I have to do six adds to solve this.\n\nHere comes big O, to tell us just how hard this math is.\n\nBig O says: we must do six adds to solve this. One add, for each thing from one to six. Six small bits of work... each bit of work is one add.\n\nWell, I will not do the work to add them now. But I know how hard it would be. It would be six adds.\n\nOh no, now I have more work. Sheesh. Who makes this kind of stuff?!\n\nNow they ask me to add from one to ten! Why would I do that? I did not want to add one to six. To add from one to ten… well… that would be even more hard!\n\nHow much more hard would it be? How much more work would I have to do? Do I need more or less steps?\n\nWell, I guess I would have to do ten adds… one for each thing from one to ten. Ten is more than six. I would have to work that much more to add from one to ten, than one to six!\n\nI do not want to add right now. I just want to think on how hard it might be to add that much. And, I hope, to play as soon as I can.\n\nTo add from one to six, that is some work. But do you see, to add from one to ten, that is more work?\n\nBig O is your friend and mine. Big O helps us think on how much work we have to do, so we can plan. And, if we are friends with big O, he can help us choose work that is not so hard!\n\nNow we must do new work. Oh, no. I don’t like this work thing at all.\n\nThe new work is: add all things from one to n.\n\nWait! What is n? Did I miss that? How can I add from one to n if you don’t tell me what n is?\n\nWell, I don’t know what n is. I was not told. Were you? No? Oh well. So we can’t do the work. Whew.\n\nBut though we will not do the work now, we can guess how hard it would be, if we knew n. We would have to add up n things, right? Of course!\n\nNow here comes big O, and he will tell us how hard this work is. He says: to add all things from one to N, one by one, is O(n). To add all these things, [I know I must add n times.][1] That is big O! He tells us how hard it is to do some type of work.\n\nTo me, I think of big O like a big, slow, boss man. He thinks on work, but he does not do it. He might say, \"That work is quick.\" Or, he might say, \"That work is so slow and hard!\" But he does not do the work. He just looks at the work, and then he tells us how much time it might take.\n\nI care lots for big O. Why? I do not like to work! No one likes to work. That is why we all love big O! He tells us how fast we can work. He helps us think of how hard work is.\n\nUh oh, more work. Now, let’s not do the work. But, let’s make a plan to do it, step by step.\n\nThey gave us a deck of ten cards. They are all mixed up: seven, four, two, six… not straight at all. And now... our job is to sort them.\n\nErgh. That sounds like a lot of work!\n\nHow can we sort this deck? I have a plan.\n\nI will look at each pair of cards, pair by pair, through the deck, from first to last. If the first card in one pair is big and the next card in that pair is small, I swap them. Else, I go to the next pair, and so on and so on... and soon, the deck is done.\n\nWhen the deck is done, I ask: did I swap cards in that pass? If so, I must do it all once more, from the top.\n\nAt some point, at some time, there will be no swaps, and our sort of the deck would be done. So much work!\n\nWell, how much work would that be, to sort the cards with those rules?\n\nI have ten cards. And, most of the time -- that is, if I don’t have lots of luck -- I must go through the whole deck up to ten times, with up to ten card swaps each time through the deck.\n\nBig O, help me!\n\nBig O comes in and says: for a deck of n cards, to sort it this way will be done in O(N squared) time.\n\nWhy does he say n squared?\n\nWell, you know n squared is n times n. Now, I get it: n cards checked, up to what might be n times through the deck. That is two loops, each with n steps. That is n squared much work to be done. A lot of work, for sure!\n\nNow when big O says it will take O(n squared) work, he does not mean n squared adds, on the nose. It might be some small bit less, for some case. But in the worst case, it will be near n squared steps of work to sort the deck.\n\nNow here is where big O is our friend.\n\nBig O points out this: as n gets big, when we sort cards, the job gets MUCH MUCH MORE HARD than the old just-add-these-things job. How do we know this?\n\nWell, if n gets real big, we do not care what we might add to n or n squared.\n\nFor big n, n squared is more large than n.\n\nBig O tells us that to sort things is more hard than to add things. O(n squared) is more than O(n) for big n. That means: if n gets real big, to sort a mixed deck of n things MUST take more time, than to just add n mixed things.\n\nBig O does not solve the work for us. Big O tells us how hard the work is.\n\nI have a deck of cards. I did sort them. You helped. Thanks.\n\nIs there a more fast way to sort the cards? Can big O help us?\n\nYes, there is a more fast way! It takes some time to learn, but it works... and it works quite fast. You can try it too, but take your time with each step and do not lose your place.\n\nIn this new way to sort a deck, we do not check pairs of cards the way we did a while ago. Here are your new rules to sort this deck:\n\nOne: I choose one card in the part of the deck we work on now. You can choose one for me if you like. (The first time we do this, “the part of the deck we work on now” is the whole deck, of course.)\n\nTwo: I splay the deck on that card you chose. What is this splay; how do I splay? Well, I go from the start card down, one by one, and I look for a card that is more high than the splay card.\n\nThree: I go from the end card up, and I look for a card that is more low than the splay card.\n\nOnce I have found these two cards, I swap them, and go on to look for more cards to swap. That is, I go back to step Two, and splay on the card you chose some more.\n\nAt some point, this loop (from Two to Three) will end. It ends when both halves of this search meet at the splay card. Then, we have just splayed the deck with the card you chose in step One. Now, all the cards near the start are more low than the splay card; and the cards near the end are more high than the splay card. Cool trick!\n\nFour (and this is the fun part): I have two small decks now, one more low than the splay card, and one more high. Now I go to step one, on each small deck! That is to say, I start from step One on the first small deck, and when that work is done, I start from step One on the next small deck.\n\nI break up the deck in parts, and sort each part, more small and more small, and at some time I have no more work to do. Now this may seem slow, with all the rules. But trust me, it is not slow at all. It is much less work than the first way to sort things!\n\nWhat is this sort called? It is called Quick Sort! That sort was made by a man called C. A. R. Hoare and he called it Quick Sort. Now, Quick Sort gets used all the time!\n\nQuick Sort breaks up big decks in small ones. That is to say, it breaks up big tasks in small ones.\n\nHmmm. There may be a rule in there, I think. To make big tasks small, break them up.\n\nThis sort is quite quick. How quick? Big O tells us: this sort needs O(n log n) work to be done, in the mean case.\n\nIs it more or less fast than the first sort? Big O, please help!\n\nThe first sort was O(n squared). But Quick Sort is O(n log n). You know that n log n is less than n squared, for big n, right? Well, that is how we know that Quick Sort is fast!\n\nIf you have to sort a deck, what is the best way? Well, you can do what you want, but I would choose Quick Sort.\n\nWhy do I choose Quick Sort? I do not like to work, of course! I want work done as soon as I can get it done.\n\nHow do I know Quick Sort is less work? I know that O(n log n) is less than O(n squared). The O's are more small, so Quick Sort is less work!\n\nNow you know my friend, Big O. He helps us do less work. And if you know big O, you can do less work too!\n\nYou learned all that with me! You are so smart! Thank you so much!\n\nNow that work is done, let’s go play!\n\n[1]: There is a way to cheat and add all the things from one to n, all at one time. Some kid named Gauss found this out when he was eight. I am not that smart though, so don't ask me how he did it.\n\nShare\nImprove this answer\nFollow\nedited Mar 10 '16 at 23:03\nanswered Dec 27 '15 at 10:34\njohnwbyrd\n2,7421\n1 gold badge\n24\n24 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"I've more simpler way to understand the time complexity he most common metric for calculating time complexity is Big O notation. This removes all constant factors so that the running time can be estimated in relation to N as N approaches infinity. In general you can think of it like this:\n\nstatement;\n\n\nIs constant. The running time of the statement will not change in relation to N\n\nfor ( i = 0; i < N; i++ )\n  statement;\n\n\nIs linear. The running time of the loop is directly proportional to N. When N doubles, so does the running time.\n\nfor ( i = 0; i < N; i++ ) \n{\nfor ( j = 0; j < N; j++ )\n  statement;\n}\n\n\nIs quadratic. The running time of the two loops is proportional to the square of N. When N doubles, the running time increases by N * N.\n\nwhile ( low <= high ) \n{\n mid = ( low + high ) / 2;\n if ( target < list[mid] )\n high = mid - 1;\n else if ( target > list[mid] )\n  low = mid + 1;\nelse break;\n}\n\n\nIs logarithmic. The running time of the algorithm is proportional to the number of times N can be divided by 2. This is because the algorithm divides the working area in half with each iteration.\n\nvoid quicksort ( int list[], int left, int right )\n{\n  int pivot = partition ( list, left, right );\n  quicksort ( list, left, pivot - 1 );\n  quicksort ( list, pivot + 1, right );\n}\n\n\nIs N * log ( N ). The running time consists of N loops (iterative or recursive) that are logarithmic, thus the algorithm is a combination of linear and logarithmic.\n\nIn general, doing something with every item in one dimension is linear, doing something with every item in two dimensions is quadratic, and dividing the working area in half is logarithmic. There are other Big O measures such as cubic, exponential, and square root, but they're not nearly as common. Big O notation is described as O ( ) where is the measure. The quicksort algorithm would be described as O ( N * log ( N ) ).\n\nNote: None of this has taken into account best, average, and worst case measures. Each would have its own Big O notation. Also note that this is a VERY simplistic explanation. Big O is the most common, but it's also more complex that I've shown. There are also other notations such as big omega, little o, and big theta. You probably won't encounter them outside of an algorithm analysis course.\n\nSee more at: Here\nShare\nImprove this answer\nFollow\nedited Sep 15 '15 at 13:52\nSanjeev Sangral\n1,2852\n2 gold badges\n24\n24 silver badges\n36\n36 bronze badges\nanswered Jan 30 '15 at 7:00\nnitin kumar\n56210\n10 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"Say you order Harry Potter: Complete 8-Film Collection [Blu-ray] from Amazon and download the same film collection online at the same time. You want to test which method is faster. The delivery takes almost a day to arrive and the download completed about 30 minutes earlier. Great! So it’s a tight race.\n\nWhat if I order several Blu-ray movies like The Lord of the Rings, Twilight, The Dark Knight Trilogy, etc. and download all the movies online at the same time? This time, the delivery still take a day to complete, but the online download takes 3 days to finish. For online shopping, the number of purchased item (input) doesn’t affect the delivery time. The output is constant. We call this O(1).\n\nFor online downloading, the download time is directly proportional to the movie file sizes (input). We call this O(n).\n\nFrom the experiments, we know that online shopping scales better than online downloading. It is very important to understand big O notation because it helps you to analyze the scalability and efficiency of algorithms.\n\nNote: Big O notation represents the worst-case scenario of an algorithm. Let’s assume that O(1) and O(n) are the worst-case scenarios of the example above.\n\nReference : http://carlcheo.com/compsci\n\nShare\nImprove this answer\nFollow\nanswered Dec 6 '15 at 6:01\nraaz\n12k21\n21 gold badges\n60\n60 silver badges\n81\n81 bronze badges","comments":[]},{"answer":"Assume we're talking about an algorithm A, which should do something with a dataset of size n.\n\nThen O( <some expression X involving n> ) means, in simple English:\n\nIf you're unlucky when executing A, it might take as much as X(n) operations to complete.\n\nAs it happens, there are certain functions (think of them as implementations of X(n)) that tend to occur quite often. These are well known and easily compared (Examples: 1, Log N, N, N^2, N!, etc..)\n\nBy comparing these when talking about A and other algorithms, it is easy to rank the algorithms according to the number of operations they may (worst-case) require to complete.\n\nIn general, our goal will be to find or structure an algorithm A in such a way that it will have a function X(n) that returns as low a number as possible.\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '19 at 5:19\nanswered Oct 25 '13 at 15:11\nKjartan\n17.3k14\n14 gold badges\n67\n67 silver badges\n84\n84 bronze badges","comments":[]},{"answer":"If you have a suitable notion of infinity in your head, then there is a very brief description:\n\nBig O notation tells you the cost of solving an infinitely large problem.\n\nAnd furthermore\n\nConstant factors are negligible\n\nIf you upgrade to a computer that can run your algorithm twice as fast, big O notation won't notice that. Constant factor improvements are too small to even be noticed in the scale that big O notation works with. Note that this is an intentional part of the design of big O notation.\n\nAlthough anything \"larger\" than a constant factor can be detected, however.\n\nWhen interested in doing computations whose size is \"large\" enough to be considered as approximately infinity, then big O notation is approximately the cost of solving your problem.\n\nIf the above doesn't make sense, then you don't have a compatible intuitive notion of infinity in your head, and you should probably disregard all of the above; the only way I know to make these ideas rigorous, or to explain them if they aren't already intuitively useful, is to first teach you big O notation or something similar. (although, once you well understand big O notation in the future, it may be worthwhile to revisit these ideas)\n\nShare\nImprove this answer\nFollow\nanswered May 16 '15 at 16:02\nuser1084944","comments":[]},{"answer":"What is a plain English explanation of “Big O” notation?\n\nVery Quick Note:\n\nThe O in \"Big O\" refers to as \"Order\"(or precisely \"order of\")\nso you could get its idea literally that it's used to order something to compare them.\n\n\"Big O\" does two things:\n\nEstimates how many steps of the method your computer applies to accomplish a task.\nFacilitate the process to compare with others in order to determine whether it's good or not?\n\"Big O' achieves the above two with standardized Notations.\n\nThere are seven most used notations\n\nO(1), means your computer gets a task done with 1 step, it's excellent, Ordered No.1\nO(logN), means your computer complete a task with logN steps, its good, Ordered No.2\nO(N), finish a task with N steps, its fair, Order No.3\nO(NlogN), ends a task with O(NlogN) steps, it's not good, Order No.4\nO(N^2), get a task done with N^2 steps, it's bad, Order No.5\nO(2^N), get a task done with 2^N steps, it's horrible, Order No.6\nO(N!), get a task done with N! steps, it's terrible, Order No.7\n\nSuppose you get notation O(N^2), not only you are clear the method takes N*N steps to accomplish a task, also you see that it's not good as O(NlogN) from its ranking.\n\nPlease note the order at line end, just for your better understanding.There's more than 7 notations if all possibilities considered.\n\nIn CS, the set of steps to accomplish a task is called algorithms.\nIn Terminology, Big O notation is used to describe the performance or complexity of an algorithm.\n\nIn addition, Big O establishes the worst-case or measure the Upper-Bound steps.\nYou could refer to Big-Ω (Big-Omega) for best case.\n\nBig-Ω (Big-Omega) notation (article) | Khan Academy\n\nSummary\n\"Big O\" describes the algorithm's performance and evaluates it.\n\nor address it formally, \"Big O\" classifies the algorithms and standardize the comparison process.\n\nShare\nImprove this answer\nFollow\nedited Apr 13 '18 at 13:53\nanswered Apr 13 '18 at 12:36\nAbstProcDo\n15k14\n14 gold badges\n54\n54 silver badges\n99\n99 bronze badges","comments":[]},{"answer":"Definition :- Big O notation is a notation which says how a algorithm performance will perform if the data input increases.\n\nWhen we talk about algorithms there are 3 important pillars Input , Output and Processing of algorithm. Big O is symbolic notation which says if the data input is increased in what rate will the performance vary of the algorithm processing.\n\nI would encourage you to see this youtube video which explains Big O Notation in depth with code examples.\n\nSo for example assume that a algorithm takes 5 records and the time required for processing the same is 27 seconds. Now if we increase the records to 10 the algorithm takes 105 seconds.\n\nIn simple words the time taken is square of the number of records. We can denote this by O(n ^ 2). This symbolic representation is termed as Big O notation.\n\nNow please note the units can be anything in inputs it can be bytes , bits number of records , the performance can be measured in any unit like second , minutes , days and so on. So its not the exact unit but rather the relationship.\n\nFor example look at the below function \"Function1\" which takes a collection and does processing on the first record. Now for this function the performance will be same irrespective you put 1000 , 10000 or 100000 records. So we can denote it by O(1).\n\nvoid Function1(List<string> data)\n{\nstring str = data[0];\n}\n\n\nNow see the below function \"Function2()\". In this case the processing time will increase with number of records. We can denote this algorithm performance using O(n).\n\nvoid Function2(List<string> data)\n        {\n            foreach(string str in data)\n            {\n                if (str == \"shiv\")\n                {\n                    return;\n                }\n            }\n        }\n\n\nWhen we see a Big O notation for any algorithm we can classify them in to three categories of performance :-\n\nLog and constant category :- Any developer would love to see their algorithm performance in this category.\nLinear :- Developer will not want to see algorithms in this category , until its the last option or the only option left.\nExponential :- This is where we do not want to see our algorithms and a rework is needed.\n\nSo by looking at Big O notation we categorize good and bad zones for algorithms.\n\nI would recommend you to watch this 10 minutes video which discusses Big O with sample code\n\nhttps://www.youtube.com/watch?v=k6kxtzICG_g\n\nShare\nImprove this answer\nFollow\nedited May 11 '18 at 9:43\nanswered May 11 '18 at 8:33\nShivprasad Koirala\n23.9k7\n7 gold badges\n76\n76 silver badges\n66\n66 bronze badges","comments":[]},{"answer":"Simplest way to look at it (in plain English)\n\nWe are trying to see how the number of input parameters, affects the running time of an algorithm. If the running time of your application is proportional to the number of input parameters, then it is said to be in Big O of n.\n\nThe above statement is a good start but not completely true.\n\nA more accurate explanation (mathematical)\n\nSuppose\n\nn=number of input parameters\n\nT(n)= The actual function that expresses the running time of the algorithm as a function of n\n\nc= a constant\n\nf(n)= An approximate function that expresses the running time of the algorithm as a function of n\n\nThen as far as Big O is concerned, the approximation f(n) is considered good enough as long as the below condition is true.\n\nlim     T(n) ≤ c×f(n)\nn→∞\n\n\nThe equation is read as As n approaches infinity, T of n, is less than or equal to c times f of n.\n\nIn big O notation this is written as\n\nT(n)∈O(n)\n\n\nThis is read as T of n is in big O of n.\n\nBack to English\n\nBased on the mathematical definition above, if you say your algorithm is a Big O of n, it means it is a function of n (number of input parameters) or faster. If your algorithm is Big O of n, then it is also automatically the Big O of n square.\n\nBig O of n means my algorithm runs at least as fast as this. You cannot look at Big O notation of your algorithm and say its slow. You can only say its fast.\n\nCheck this out for a video tutorial on Big O from UC Berkley. It is actually a simple concept. If you hear professor Shewchuck (aka God level teacher) explaining it, you will say \"Oh that's all it is!\".\n\nShare\nImprove this answer\nFollow\nedited Jul 28 '20 at 21:07\nanswered Aug 16 '15 at 20:38\ndeveloper747\n13.3k22\n22 gold badges\n79\n79 silver badges\n136\n136 bronze badges","comments":["Link to video is dead :(","Look for CS 61B Lecture 19: Asymptotic Analysis"]},{"answer":"I found a really great explanation about big O notation especially for a someone who's not much into mathematics.\n\nhttps://rob-bell.net/2009/06/a-beginners-guide-to-big-o-notation/\n\nBig O notation is used in Computer Science to describe the performance or complexity of an algorithm. Big O specifically describes the worst-case scenario, and can be used to describe the execution time required or the space used (e.g. in memory or on disk) by an algorithm.\n\nAnyone who's read Programming Pearls or any other Computer Science books and doesn’t have a grounding in Mathematics will have hit a wall when they reached chapters that mention O(N log N) or other seemingly crazy syntax. Hopefully this article will help you gain an understanding of the basics of Big O and Logarithms.\n\nAs a programmer first and a mathematician second (or maybe third or fourth) I found the best way to understand Big O thoroughly was to produce some examples in code. So, below are some common orders of growth along with descriptions and examples where possible.\n\nO(1)\n\nO(1) describes an algorithm that will always execute in the same time (or space) regardless of the size of the input data set.\n\nbool IsFirstElementNull(IList<string> elements) {\n    return elements[0] == null;\n}\n\nO(N)\n\nO(N) describes an algorithm whose performance will grow linearly and in direct proportion to the size of the input data set. The example below also demonstrates how Big O favours the worst-case performance scenario; a matching string could be found during any iteration of the for loop and the function would return early, but Big O notation will always assume the upper limit where the algorithm will perform the maximum number of iterations.\n\nbool ContainsValue(IList<string> elements, string value) {\n    foreach (var element in elements)\n    {\n        if (element == value) return true;\n    }\n\n    return false;\n} \n\nO(N2)\n\nO(N2) represents an algorithm whose performance is directly proportional to the square of the size of the input data set. This is common with algorithms that involve nested iterations over the data set. Deeper nested iterations will result in O(N3), O(N4) etc.\n\nbool ContainsDuplicates(IList<string> elements) {\n    for (var outer = 0; outer < elements.Count; outer++)\n    {\n        for (var inner = 0; inner < elements.Count; inner++)\n        {\n            // Don't compare with self\n            if (outer == inner) continue;\n\n            if (elements[outer] == elements[inner]) return true;\n        }\n    }\n\n    return false;\n}\n\nO(2N)\n\nO(2N) denotes an algorithm whose growth doubles with each additon to the input data set. The growth curve of an O(2N) function is exponential - starting off very shallow, then rising meteorically. An example of an O(2N) function is the recursive calculation of Fibonacci numbers:\n\nint Fibonacci(int number) {\n    if (number <= 1) return number;\n\n    return Fibonacci(number - 2) + Fibonacci(number - 1);\n}\n\nLogarithms\n\nLogarithms are slightly trickier to explain so I'll use a common example:\n\nBinary search is a technique used to search sorted data sets. It works by selecting the middle element of the data set, essentially the median, and compares it against a target value. If the values match it will return success. If the target value is higher than the value of the probe element it will take the upper half of the data set and perform the same operation against it. Likewise, if the target value is lower than the value of the probe element it will perform the operation against the lower half. It will continue to halve the data set with each iteration until the value has been found or until it can no longer split the data set.\n\nThis type of algorithm is described as O(log N). The iterative halving of data sets described in the binary search example produces a growth curve that peaks at the beginning and slowly flattens out as the size of the data sets increase e.g. an input data set containing 10 items takes one second to complete, a data set containing 100 items takes two seconds, and a data set containing 1000 items will take three seconds. Doubling the size of the input data set has little effect on its growth as after a single iteration of the algorithm the data set will be halved and therefore on a par with an input data set half the size. This makes algorithms like binary search extremely efficient when dealing with large data sets.\n\nShare\nImprove this answer\nFollow\nedited Oct 4 '19 at 7:25\nrevo\n44.5k14\n14 gold badges\n68\n68 silver badges\n110\n110 bronze badges\nanswered Jan 29 '17 at 15:39\nshanwije\n5317\n7 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"This is a very simplified explanation, but I hope it covers most important details.\n\nLet's say your algorithm dealing with the problem depends on some 'factors', for example let's make it N and X.\n\nDepending on N and X, your algorithm will require some operations, for example in the WORST case it's 3(N^2) + log(X) operations.\n\nSince Big-O doesn't care too much about constant factor (aka 3), the Big-O of your algorithm is O(N^2 + log(X)). It basically translates 'the amount of operations your algorithm needs for the worst case scales with this'.\n\nShare\nImprove this answer\nFollow\nanswered Oct 11 '15 at 18:00\nnkt\n3131\n1 gold badge\n5\n5 silver badges\n11\n11 bronze badges","comments":[]}]},{"id":"9329446","href":"https://stackoverflow.com/questions/9329446/for-each-over-an-array-in-javascript","title":"For-each over an array in JavaScript","description":"\n                \nHow can I loop through all the entries in an array using JavaScript?\n\nI thought it was something like this:\n\nforEach(instance in theArray)\n\n\nWhere theArray is my array, but this seems to be incorrect.\n    ","questionComments":[],"answers":[{"answer":"TL;DR\n\nYour best bets are usually\n\na for-of loop (ES2015+ only; spec | MDN) - simple and async-friendly\nforEach (ES5+ only; spec | MDN) (or its relatives some and such) - not async-friendly (but see details)\na simple old-fashioned for loop - async-friendly\n(rarely) for-in with safeguards - async-friendly\n\nSome quick \"don't\"s:\n\nDon't use for-in unless you use it with safeguards or are at least aware of why it might bite you.\nDon't use map if you're not using its return value.\n(There's sadly someone out there teaching map [spec / MDN] as though it were forEach — but that's not what it's for. If you aren't using the array it creates, don't use map.)\nDon't use forEach if the callback does asynchronous work and you want the forEach to wait until that work is done (because it won't).\n\nBut there's lots more to explore, read on...\n\nJavaScript has powerful semantics for looping through arrays and array-like objects. I've split the answer into two parts: Options for genuine arrays, and options for things that are just array-like, such as the arguments object, other iterable objects (ES2015+), DOM collections, and so on.\n\nOkay, let's look at our options:\n\nFor Actual Arrays\n\nYou have five options (two supported basically forever, another added by ECMAScript 5 [\"ES5\"], and two more added in ECMAScript 2015 (\"ES2015\", aka \"ES6\"):\n\nUse for-of (use an iterator implicitly) (ES2015+)\nUse forEach and related (ES5+)\nUse a simple for loop\nUse for-in correctly\nUse an iterator explicitly (ES2015+)\n\n(You can see those old specs here: ES5, ES2015, but both have been superceded; the current editor's draft is always here.)\n\nDetails:\n\n1. Use for-of (use an iterator implicitly) (ES2015+)\n\nES2015 added iterators and iterables to JavaScript. Arrays are iterable (so are strings, Maps, and Sets, as well as DOM collections and lists, as you'll see later). Iterable objects provide iterators for their values. The new for-of statement loops through the values returned by an iterator:\n\nconst a = [\"a\", \"b\", \"c\"];\nfor (const val of a) { // You can use `let` instead of `const` if you like\n    console.log(val);\n}\n// a\n// b\n// c\n Run code snippetExpand snippet\n\nIt doesn't get simpler than that! Under the covers, that gets an iterator from the array and loops through the values the iterator returns. The iterator provided by arrays provides the values of the array elements, in order beginning to end.\n\nNotice how val is scoped to each loop iteration; trying to use val after the end of the loop would fail because it doesn't exist outside the loop body.\n\nIn theory, a for-of loop involves several function calls (one to get the iterator, then one to get each value from it). Even when that's true, it's nothing to worry about, function calls are very cheap in modern JavaScript engines (it bothered me for forEach [below] until I looked into it; details). But additionally, JavaScript engines optimize those calls away (in performance-critical code) when dealing with native iterators for things like arrays.\n\nfor-of is entirely async-friendly. If you need the work in a loop body to be done in series (not in parallel), an await in the loop body will wait for the promise to settle before continuing. Here's a silly example:\n\nShow code snippet\n\nNote how the words appear with a delay before each one.\n\nIt's a matter of coding style, but for-of is the first thing I reach for when looping through anything iterable.\n\n2. Use forEach and related\n\nIn any even vaguely-modern environment (so, not IE8) where you have access to the Array features added by ES5, you can use forEach (spec | MDN) if you're only dealing with synchronous code (or you don't need to wait for an asynchronous process to finish during the loop):\n\nconst a = [\"a\", \"b\", \"c\"];\na.forEach((entry) => {\n    console.log(entry);\n});\n Run code snippetExpand snippet\n\nforEach accepts a callback function and, optionally, a value to use as this when calling that callback (not used above). The callback is called for each entry in the array, in order, skipping non-existent entries in sparse arrays. Although I only used one parameter above, the callback is called with three arguments: The value of each entry, the index of that entry, and a reference to the array you're iterating over (in case your function doesn't already have it handy).\n\nLike for-of, forEach has the advantage that you don't have to declare indexing and value variables in the containing scope; in this case, they're supplied as arguments to the iteration function, and so nicely scoped to just that iteration.\n\nUnlike for-of, forEach has the disadvantage that it doesn't understand async functions and await. If you use an async function as the callback, forEach does not wait for that function's promise to settle before continuing. Here's the async example from for-of using forEach instead — notice how there's an initial delay, but then all the text appears right away instead of waiting:\n\nShow code snippet\n\nforEach is the \"loop through them all\" function, but ES5 defined several other useful \"work your way through the array and do things\" functions, including:\n\nevery (spec | MDN) - stops looping the first time the callback returns a falsy value\nsome (spec | MDN) - stops looping the first time the callback returns a truthy value\nfilter (spec | MDN) - creates a new array including elements where the callback returns a truthy value, omitting the ones where it doesn't\nmap (spec | MDN) - creates a new array from the values returned by the callback\nreduce (spec | MDN) - builds up a value by repeatedly calling the callback, passing in previous values; see the spec for the details\nreduceRight (spec | MDN) - like reduce, but works in descending rather than ascending order\n\nAs with forEach, if you use an async function as your callback, none of those waits for the function's promise to settle. That means:\n\nUsing an async function callback is never appropriate with every, some, and filter since they will treat the returned promise as though it were a truthy value; they don't wait for the promise to settle and then use the fulfillment value.\nUsing an async function callback is often appropriate with map, if the goal is to turn an array of something into an array of promises, perhaps for passing to one of the promise combinator functions (Promise.all, Promise.race, promise.allSettled, or Promise.any).\nUsing an async function callback is rarely appropriate with reduce or reduceRight, because (again) the callback will always return a promise. But there is an idiom of building a chain of promises from an array that uses reduce (const promise = array.reduce((p, element) => p.then(/*...something using `element`...*/));), but usually in those cases a for-of or for loop in an async function will be clearer and easier to debug.\n3. Use a simple for loop\n\nSometimes the old ways are the best:\n\nconst a = [\"a\", \"b\", \"c\"];\nfor (let index = 0; index < a.length; ++index) {\n    console.log(a[index]);\n}\n Run code snippetExpand snippet\n\nIf the length of the array won't change during the loop, and it's in performance-sensitive code (unlikely), a slightly more complicated version grabbing the length up front might be a tiny bit faster:\n\nconst a = [\"a\", \"b\", \"c\"];\nfor (let index = 0, len = a.length; index < len; ++index) {\n    console.log(a[index]);\n}\n Run code snippetExpand snippet\n\nAnd/or counting backward:\n\nconst a = [\"a\", \"b\", \"c\"];\nfor (let index = a.length - 1; index >= 0; --index) {\n    console.log(a[index]);\n}\n Run code snippetExpand snippet\n\nBut with modern JavaScript engines, it's rare you need to eke out that last bit of juice.\n\nBefore ES2015, the loop variable had to exist in the containing scope, because var only has function-level scope, not block-level scope. But as you saw in the examples above, you can use let within the for to scope the variables to just the loop. And when you do that, the index variable is recreated for each loop iteration, meaning closures created in the loop body keep a reference to the index for that specific iteration, which solves the old \"closures in loops\" problem:\n\nShow code snippet\n\nIn the above, you get \"Index is: 0\" if you click the first and \"Index is: 4\" if you click the last. This does not work if you use var instead of let.\n\nLike for-of, for loops work well in async functions. Here's the earlier example using a for loop:\n\nShow code snippet\n\n4. Use for-in correctly\n\nfor-in isn't for looping through arrays, it's for looping through the names of an object's properties. It does often seem to work for looping through arrays as a by-product of the fact that arrays are objects, but it doesn't just loop through the array indexes, it loops through all enumerable properties of the object (including inherited ones). (It also used to be that the order wasn't specified; it is now [details in this other answer], but even though the order is specified now, the rules are complex, there are exceptions, and relying on the order is not best practice.)\n\nThe only real use cases for for-in on an array are:\n\nIt's a sparse array with massive gaps in it, or\nYou're using non-element properties and you want to include them in the loop\n\nLooking only at that first example: You can use for-in to visit those sparse array elements if you use appropriate safeguards:\n\n// `a` is a sparse array\nconst a = [];\na[0] = \"a\";\na[10] = \"b\";\na[10000] = \"c\";\nfor (const name in a) {\n    if (a.hasOwnProperty(name)  &&      // These checks are\n        /^0$|^[1-9]\\d*$/.test(name) &&  // explained\n        name <= 4294967294              // below\n       ) {\n        console.log(a[name]);\n    }\n}\n Run code snippetExpand snippet\n\nNote the three checks:\n\nThat the object has its own property by that name (not one it inherits from its prototype), and\n\nThat the name is all decimal digits (e.g., normal string form, not scientific notation), and\n\nThat the name's value when coerced to a number is <= 2^32 - 2 (which is 4,294,967,294). Where does that number come from? It's part of the definition of an array index in the specification. Other numbers (non-integers, negative numbers, numbers greater than 2^32 - 2) are not array indexes. The reason it's 2^32 - 2 is that that makes the greatest index value one lower than 2^32 - 1, which is the maximum value an array's length can have. (E.g., an array's length fits in a 32-bit unsigned integer.)\n\nYou wouldn't do that in inline code, of course. You'd write a utility function. Perhaps:\n\nShow code snippet\n\n...although with that said, most code only does the hasOwnProperty check.\n\nLike for, for-in works well in asynchronous functions if the work within it needs to be done in series.\n\nShow code snippet\n\n5. Use an iterator explicitly (ES2015+)\n\nfor-of uses an iterator implicitly, doing all the scut work for you. Sometimes, you might want to use an iterator explicitly. It looks like this:\n\nconst a = [\"a\", \"b\", \"c\"];\nconst it = a.values(); // Or `const it = a[Symbol.iterator]();` if you like\nlet entry;\nwhile (!(entry = it.next()).done) {\n    console.log(entry.value);\n}\n Run code snippetExpand snippet\n\nAn iterator is an object matching the Iterator definition in the specification. Its next method returns a new result object each time you call it. The result object has a property, done, telling us whether it's done, and a property value with the value for that iteration. (done is optional if it would be false, value is optional if it would be undefined.)\n\nWhat you get for value varies depending on the iterator. On arrays, the default iterator provides the value of each array element (\"a\", \"b\", and \"c\" in the example earlier). Arrays also have three other methods that return iterators:\n\nvalues(): This is an alias for the [Symbol.iterator] method that returns the default iterator.\nkeys(): Returns an iterator that provides each key (index) in the array. In the example above, it would provide \"0\", then \"1\", then \"2\" (yes, as strings).\nentries(): Returns an iterator that provides [key, value] arrays.\n\nSince iterator objects don't advance until you call next, they work well in async function loops. Here's the earlier for-of example using the iterator explicitly:\n\nShow code snippet\n\nFor Array-Like Objects\n\nAside from true arrays, there are also array-like objects that have a length property and properties with all-digits names: NodeList instances, HTMLCollection instances, the arguments object, etc. How do we loop through their contents?\n\nUse most of the options above\n\nAt least some, and possibly most or even all, of the array approaches above apply equally well to array-like objects:\n\nUse for-of (use an iterator implicitly) (ES2015+)\n\nfor-of uses the iterator provided by the object (if any). That includes host-provided objects (like DOM collections and lists). For instance, HTMLCollection instances from getElementsByXYZ methods and NodeLists instances from querySelectorAll both support iteration. (This is defined quite subtly by the HTML and DOM specifications. Basically, any object with length and indexed access is automatically iterable. It doesn't have to be marked iterable; that is used only for collections that, in addition to being iterable, support forEach, values, keys, and entries methods. NodeList does; HTMLCollection doesn't, but both are iterable.)\n\nHere's an example of looping through div elements:\n\nShow code snippet\n\nUse forEach and related (ES5+)\n\nThe various functions on Array.prototype are \"intentionally generic\" and can be used on array-like objects via Function#call (spec | MDN) or Function#apply (spec | MDN). (If you have to deal with IE8 or earlier [ouch], see the \"Caveat for host-provided objects\" at the end of this answer, but it's not an issue with vaguely-modern browsers.)\n\nSuppose you wanted to use forEach on a Node's childNodes collection (which, being an HTMLCollection, doesn't have forEach natively). You'd do this:\n\nArray.prototype.forEach.call(node.childNodes, (child) => {\n    // Do something with `child`\n});\n\n\n(Note, though, that you could just use for-of on node.childNodes.)\n\nIf you're going to do that a lot, you might want to grab a copy of the function reference into a variable for reuse, e.g.:\n\n// (This is all presumably in a module or some scoping function)\nconst forEach = Array.prototype.forEach.call.bind(Array.prototype.forEach);\n\n// Then later...\nforEach(node.childNodes, (child) => {\n    // Do something with `child`\n});\n\n\nUse a simple for loop\n\nPerhaps obviously, a simple for loop works for array-like objects.\n\nUse an iterator explicitly (ES2015+)\n\nSee #1.\n\nYou may be able to get away with for-in (with safeguards), but with all of these more appropriate options, there's no reason to try.\n\nCreate a true array\n\nOther times, you may want to convert an array-like object into a true array. Doing that is surprisingly easy:\n\nUse Array.from\n\nArray.from (spec) | (MDN) (ES2015+, but easily polyfilled) creates an array from an array-like object, optionally passing the entries through a mapping function first. So:\n\nconst divs = Array.from(document.querySelectorAll(\"div\"));\n\n\n...takes the NodeList from querySelectorAll and makes an array from it.\n\nThe mapping function is handy if you were going to map the contents in some way. For instance, if you wanted to get an array of the tag names of the elements with a given class:\n\n// Typical use (with an arrow function):\nconst divs = Array.from(document.querySelectorAll(\".some-class\"), element => element.tagName);\n\n// Traditional function (since `Array.from` can be polyfilled):\nvar divs = Array.from(document.querySelectorAll(\".some-class\"), function(element) {\n    return element.tagName;\n});\n\n\nUse spread syntax (...)\n\nIt's also possible to use ES2015's spread syntax. Like for-of, this uses the iterator provided by the object (see #1 in the previous section):\n\nconst trueArray = [...iterableObject];\n\n\nSo for instance, if we want to convert a NodeList into a true array, with spread syntax this becomes quite succinct:\n\nconst divs = [...document.querySelectorAll(\"div\")];\n\n\nUse the slice method of arrays\n\nWe can use the slice method of arrays, which like the other methods mentioned above is \"intentionally generic\" and so can be used with array-like objects, like this:\n\nconst trueArray = Array.prototype.slice.call(arrayLikeObject);\n\n\nSo for instance, if we want to convert a NodeList into a true array, we could do this:\n\nconst divs = Array.prototype.slice.call(document.querySelectorAll(\"div\"));\n\n\n(If you still have to handle IE8 [ouch], will fail; IE8 didn't let you use host-provided objects as this like that.)\n\nCaveat for host-provided objects\n\nIf you use Array.prototype functions with host-provided array-like objects (for example, DOM collections and such provided by the browser rather than the JavaScript engine), obsolete browsers like IE8 didn't necessarily handle that way, so if you have to support them, be sure to test in your target environments. But it's not an issue with vaguely-modern browsers. (For non-browser environments, naturally it'll depend on the environment.)\n\nShare\nImprove this answer\nFollow\nedited Jun 16 at 8:58\nanswered Feb 17 '12 at 13:53\nT.J. Crowder\n897k166\n166 gold badges\n1650\n1650 silver badges\n1666\n1666 bronze badges","comments":["What do you mean by non-element properties?","@Alex - Properties on the array that don't represent array elements. For example: const a = [\"a\", \"b\"]; a.example = 42; That array has three properties (other than the ones all arrays have), whose names are the strings \"0\", \"1\", and \"example\". The property named \"example\" is a non-element property. The other two are element properties, because they represent the elements of the array."]},{"answer":"Note: This answer is hopelessly out-of-date. For a more modern approach, look at the methods available on an array. Methods of interest might be:\n\nforEach\nmap\nfilter\nzip\nreduce\nevery\nsome\n\nThe standard way to iterate an array in JavaScript is a vanilla for-loop:\n\nvar length = arr.length,\n    element = null;\nfor (var i = 0; i < length; i++) {\n  element = arr[i];\n  // Do something with element\n}\n\n\nNote, however, that this approach is only good if you have a dense array, and each index is occupied by an element. If the array is sparse, then you can run into performance problems with this approach, since you will iterate over a lot of indices that do not really exist in the array. In this case, a for .. in-loop might be a better idea. However, you must use the appropriate safeguards to ensure that only the desired properties of the array (that is, the array elements) are acted upon, since the for..in-loop will also be enumerated in legacy browsers, or if the additional properties are defined as enumerable.\n\nIn ECMAScript 5 there will be a forEach method on the array prototype, but it is not supported in legacy browsers. So to be able to use it consistently you must either have an environment that supports it (for example, Node.js for server side JavaScript), or use a \"Polyfill\". The Polyfill for this functionality is, however, trivial and since it makes the code easier to read, it is a good polyfill to include.\n\nShare\nImprove this answer\nFollow\nedited Sep 3 '19 at 19:57\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 17 '12 at 13:55\nPatrikAkerstrand\n43.8k11\n11 gold badges\n74\n74 silver badges\n92\n92 bronze badges","comments":["Is there a way to do it in just one line of code. For example in facebook I like to speed up videos with document.getElementsByTagName(\"video\")[28].playbackRate = 2.2. If I could easily map across all elements then I could avoid having to identify which video (e.g. index 28 in this case). Any ideas?","@stevec: Array.from(document.querySelectorAll('video')).forEach(video => video.playbackRate = 2.2);"]},{"answer":"If you’re using the jQuery library, you can use jQuery.each:\n\n$.each(yourArray, function(index, value) {\n  // do your stuff here\n});\n\n\nEDIT :\n\nAs per question, user want code in javascript instead of jquery so the edit is\n\nvar length = yourArray.length;   \nfor (var i = 0; i < length; i++) {\n  // Do something with yourArray[i].\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 12 '15 at 5:17\nAnik Islam Abhi\n24.5k8\n8 gold badges\n52\n52 silver badges\n76\n76 bronze badges\nanswered Feb 17 '12 at 14:01\nPoonam\n4,3881\n1 gold badge\n13\n13 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"Loop backwards\n\nI think the reverse for loop deserves a mention here:\n\nfor (var i = array.length; i--; ) {\n     // process array[i]\n}\n\nAdvantages:\nYou do not need to declare a temporary len variable, or compare against array.length on each iteration, either of which might be a minute optimisation.\nRemoving siblings from the DOM in reverse order is usually more efficient. (The browser needs to do less shifting of elements in its internal arrays.)\nIf you modify the array while looping, at or after index i (for example you remove or insert an item at array[i]), then a forward loop would skip the item that shifted left into position i, or re-process the ith item that was shifted right. In a traditional for loop, you could update i to point to the next item that needs processing - 1, but simply reversing the direction of iteration is often a simpler and more elegant solution.\nSimilarly, when modifying or removing nested DOM elements, processing in reverse can circumvent errors. For example, consider modifying the innerHTML of a parent node before handling its children. By the time the child node is reached it will be detached from the DOM, having been replaced by a newly created child when the parent's innerHTML was written.\nIt is shorter to type, and read, than some of the other options available. Although it loses to forEach() and to ES6's for ... of.\nDisadvantages:\nIt processes the items in reverse order. If you were building a new array from the results, or printing things on screen, naturally the output will be reversed with respect to the original order.\nRepeatedly inserting siblings into the DOM as a first child in order to retain their order is less efficient. (The browser would keep having to shift things right.) To create DOM nodes efficiently and in order, just loop forwards and append as normal (and also use a \"document fragment\").\nThe reverse loop is confusing to junior developers. (You may consider that an advantage, depending on your outlook.)\nShould I always use it?\n\nSome developers use the reverse for loop by default, unless there is a good reason to loop forwards.\n\nAlthough the performance gains are usually insignificant, it sort of screams:\n\n\"Just do this to every item in the list, I don't care about the order!\"\n\nHowever in practice that is not actually a reliable indication of intent, since it is indistinguishable from those occasions when you do care about the order, and really do need to loop in reverse. So in fact another construct would be needed to accurately express the \"don't care\" intent, something currently unavailable in most languages, including ECMAScript, but which could be called, for example, forEachUnordered().\n\nIf order doesn't matter, and efficiency is a concern (in the innermost loop of a game or animation engine), then it may be acceptable to use the reverse for loop as your go-to pattern. Just remember that seeing a reverse for loop in existing code does not necessarily mean that the order irrelevant!\n\nIt was better to use forEach()\n\nIn general for higher level code where clarity and safety are greater concerns, I previously recommended using Array::forEach as your default pattern for looping (although these days I prefer to use for..of). Reasons to prefer forEach over a reverse loop are:\n\nIt is clearer to read.\nIt indicates that i is not going to be shifted within the block (which is always a possible surprise hiding in long for and while loops).\nIt gives you a free scope for closures.\nIt reduces leakage of local variables and accidental collision with (and mutation of) outer variables.\n\nThen when you do see the reverse for loop in your code, that is a hint that it is reversed for a good reason (perhaps one of the reasons described above). And seeing a traditional forward for loop may indicate that shifting can take place.\n\n(If the discussion of intent makes no sense to you, then you and your code may benefit from watching Crockford's lecture on Programming Style & Your Brain.)\n\nIt is now even better to use for..of!\n\nThere is a debate about whether for..of or forEach() are preferable:\n\nFor maximum browser support, for..of requires a polyfill for iterators, making your app slightly slower to execute and slightly larger to download.\n\nFor that reason (and to encourage use of map and filter), some front-end style guides ban for..of completely!\n\nBut the above concerns is not applicable to Node.js applications, where for..of is now well supported.\n\nAnd furthermore await does not work inside forEach(). Using for..of is the clearest pattern in this case.\n\nPersonally, I tend to use whatever looks easiest to read, unless performance or minification has become a major concern. So these days I prefer to use for..of instead of forEach(), but I will always use map or filter or find or some when applicable. (For the sake of my colleagues, I rarely use reduce.)\n\nHow does it work?\nfor (var i = 0; i < array.length; i++) { ... }   // Forwards\n\nfor (var i = array.length; i--; )    { ... }   // Reverse\n\n\nYou will notice that i-- is the middle clause (where we usually see a comparison) and the last clause is empty (where we usually see i++). That means that i-- is also used as the condition for continuation. Crucially, it is executed and checked before each iteration.\n\nHow can it start at array.length without exploding?\n\nBecause i-- runs before each iteration, on the first iteration we will actually be accessing the item at array.length - 1 which avoids any issues with Array-out-of-bounds undefined items.\n\nWhy doesn't it stop iterating before index 0?\n\nThe loop will stop iterating when the condition i-- evaluates to a falsey value (when it yields 0).\n\nThe trick is that unlike --i, the trailing i-- operator decrements i but yields the value before the decrement. Your console can demonstrate this:\n\n> var i = 5; [i, i--, i];\n\n[5, 5, 4]\n\nSo on the final iteration, i was previously 1 and the i-- expression changes it to 0 but actually yields 1 (truthy), and so the condition passes. On the next iteration i-- changes i to -1 but yields 0 (falsey), causing execution to immediately drop out of the bottom of the loop.\n\nIn the traditional forwards for loop, i++ and ++i are interchangeable (as Douglas Crockford points out). However in the reverse for loop, because our decrement is also our condition expression, we must stick with i-- if we want to process the item at index 0.\n\nTrivia\n\nSome people like to draw a little arrow in the reverse for loop, and end with a wink:\n\nfor (var i = array.length; i --> 0 ;) {\n\n\nCredits go to WYL for showing me the benefits and horrors of the reverse for loop.\n\nShare\nImprove this answer\nFollow\nedited Sep 20 '19 at 4:11\nanswered May 2 '14 at 14:21\njoeytwiddle\n24.9k12\n12 gold badges\n108\n108 silver badges\n93\n93 bronze badges","comments":[]},{"answer":"Some C-style languages use foreach to loop through enumerations. In JavaScript this is done with the for..in loop structure:\n\nvar index,\n    value;\nfor (index in obj) {\n    value = obj[index];\n}\n\n\nThere is a catch. for..in will loop through each of the object's enumerable members, and the members on its prototype. To avoid reading values that are inherited through the object's prototype, simply check if the property belongs to the object:\n\nfor (i in obj) {\n    if (obj.hasOwnProperty(i)) {\n        //do stuff\n    }\n}\n\n\nAdditionally, ECMAScript 5 has added a forEach method to Array.prototype which can be used to enumerate over an array using a calback (the polyfill is in the docs so you can still use it for older browsers):\n\narr.forEach(function (val, index, theArray) {\n    //do stuff\n});\n\n\nIt's important to note that Array.prototype.forEach doesn't break when the callback returns false. jQuery and Underscore.js provide their own variations on each to provide loops that can be short-circuited.\n\nShare\nImprove this answer\nFollow\nedited Jul 13 '13 at 1:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 17 '12 at 14:00\nzzzzBov\n160k47\n47 gold badges\n309\n309 silver badges\n350\n350 bronze badges","comments":[]},{"answer":"If you want to loop over an array, use the standard three-part for loop.\n\nfor (var i = 0; i < myArray.length; i++) {\n    var arrayItem = myArray[i];\n}\n\n\nYou can get some performance optimisations by caching myArray.length or iterating over it backwards.\n\nShare\nImprove this answer\nFollow\nanswered Feb 17 '12 at 13:55\nQuentin\n815k108\n108 gold badges\n1094\n1094 silver badges\n1220\n1220 bronze badges","comments":[]},{"answer":"If you don't mind emptying the array:\n\nvar x;\n\nwhile(x = y.pop()){ \n\n    alert(x); //do something \n\n}\n\n\nx will contain the last value of y and it will be removed from the array. You can also use shift() which will give and remove the first item from y.\n\nShare\nImprove this answer\nFollow\nedited May 30 '14 at 18:37\njoeytwiddle\n24.9k12\n12 gold badges\n108\n108 silver badges\n93\n93 bronze badges\nanswered Mar 10 '13 at 2:37\ngaby de wilde\n1,14511\n11 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"I know this is an old post, and there are so many great answers already. For a little more completeness I figured I'd throw in another one using AngularJS. Of course, this only applies if you're using Angular, obviously, nonetheless I'd like to put it anyway.\n\nangular.forEach takes 2 arguments and an optional third argument. The first argument is the object (array) to iterate over, the second argument is the iterator function, and the optional third argument is the object context (basically referred to inside the loop as 'this'.\n\nThere are different ways to use the forEach loop of angular. The simplest and probably most used is\n\nvar temp = [1, 2, 3];\nangular.forEach(temp, function(item) {\n    //item will be each element in the array\n    //do something\n});\n\n\nAnother way that is useful for copying items from one array to another is\n\nvar temp = [1, 2, 3];\nvar temp2 = [];\nangular.forEach(temp, function(item) {\n    this.push(item); //\"this\" refers to the array passed into the optional third parameter so, in this case, temp2.\n}, temp2);\n\n\nThough, you don't have to do that, you can simply do the following and it's equivalent to the previous example:\n\nangular.forEach(temp, function(item) {\n    temp2.push(item);\n});\n\n\nNow there are pros and cons of using the angular.forEach function as opposed to the built in vanilla-flavored for loop.\n\nPros\n\nEasy readability\nEasy writability\nIf available, angular.forEach will use the ES5 forEach loop. Now, I will get to efficientcy in the cons section, as the forEach loops are much slower than the for loops. I mention this as a pro because it's nice to be consistent and standardized.\n\nConsider the following 2 nested loops, which do exactly the same thing. Let's say that we have 2 arrays of objects and each object contains an array of results, each of which has a Value property that's a string (or whatever). And let's say we need to iterate over each of the results and if they're equal then perform some action:\n\nangular.forEach(obj1.results, function(result1) {\n    angular.forEach(obj2.results, function(result2) {\n        if (result1.Value === result2.Value) {\n            //do something\n        }\n    });\n});\n\n//exact same with a for loop\nfor (var i = 0; i < obj1.results.length; i++) {\n    for (var j = 0; j < obj2.results.length; j++) {\n        if (obj1.results[i].Value === obj2.results[j].Value) {\n            //do something\n        }\n    }\n}\n\n\nGranted this is a very simple hypothetical example, but I've written triple embedded for loops using the second approach and it was very hard to read, and write for that matter.\n\nCons\n\nEfficiency. angular.forEach, and the native forEach, for that matter, are both so much slower than the normal for loop....about 90% slower. So for large data sets, best to stick to the native for loop.\nNo break, continue, or return support. continue is actually supported by \"accident\", to continue in an angular.forEach you simple put a return; statement in the function like angular.forEach(array, function(item) { if (someConditionIsTrue) return; }); which will cause it to continue out of the function for that iteration. This is also due to the fact that the native forEach does not support break or continue either.\n\nI'm sure there's various other pros and cons as well, and please feel free to add any that you see fit. I feel that, bottom line, if you need efficiency, stick with just the native for loop for your looping needs. But, if your datasets are smaller and a some efficiency is okay to give up in exchange for readability and writability, then by all means throw an angular.forEach in that bad boy.\n\nShare\nImprove this answer\nFollow\nanswered Jun 20 '14 at 22:56\nuser2359695\n6977\n7 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"A forEach implementation (see in jsFiddle):\n\nfunction forEach(list,callback) {\n  var length = list.length;\n  for (var n = 0; n < length; n++) {\n    callback.call(list[n]);\n  }\n}\n\nvar myArray = ['hello','world'];\n\nforEach(\n  myArray,\n  function(){\n    alert(this); // do something\n  }\n);\n\nShare\nImprove this answer\nFollow\nedited Dec 18 '13 at 12:22\nanswered Apr 10 '13 at 0:26\nnmoliveira\n1,60915\n15 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"As of ECMAScript 6:\n\nlist = [0, 1, 2, 3]\nfor (let obj of list) {\n    console.log(obj)\n}\n Run code snippetExpand snippet\n\nWhere of avoids the oddities associated with in and makes it work like the for loop of any other language, and let binds i within the loop as opposed to within the function.\n\nThe braces ({}) can be omitted when there is only one command (e.g. in the example above).\n\nShare\nImprove this answer\nFollow\nedited Sep 12 '19 at 5:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 26 '16 at 16:14\nZaz\n40.4k10\n10 gold badges\n71\n71 silver badges\n93\n93 bronze badges","comments":[]},{"answer":"Probably the for(i = 0; i < array.length; i++) loop is not the best choice. Why? If you have this:\n\nvar array = new Array();\narray[1] = \"Hello\";\narray[7] = \"World\";\narray[11] = \"!\";\n\n\nThe method will call from array[0] to array[2]. First, this will first reference variables you don't even have, second you would not have the variables in the array, and third this will make the code bolder. Look here, it's what I use:\n\nfor(var i in array){\n    var el = array[i];\n    //If you want 'i' to be INT just put parseInt(i)\n    //Do something with el\n}\n\n\nAnd if you want it to be a function, you can do this:\n\nfunction foreach(array, call){\n    for(var i in array){\n        call(array[i]);\n    }\n}\n\n\nIf you want to break, a little more logic:\n\nfunction foreach(array, call){\n    for(var i in array){\n        if(call(array[i]) == false){\n            break;\n        }\n    }\n}\n\n\nExample:\n\nforeach(array, function(el){\n    if(el != \"!\"){\n        console.log(el);\n    } else {\n        console.log(el+\"!!\");\n    }\n});\n\n\nIt returns:\n\n//Hello\n//World\n//!!!\n\nShare\nImprove this answer\nFollow\nedited Mar 8 '14 at 10:49\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 2 '13 at 2:23\nFederico Piragua\n6577\n7 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"There are three implementations of foreach in jQuery as follows.\n\nvar a = [3,2];\n\n$(a).each(function(){console.log(this.valueOf())}); //Method 1\n$.each(a, function(){console.log(this.valueOf())}); //Method 2\n$.each($(a), function(){console.log(this.valueOf())}); //Method 3\n\nShare\nImprove this answer\nFollow\nedited Mar 8 '14 at 10:50\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 25 '13 at 16:14\nRajesh Paul\n6,0586\n6 gold badges\n33\n33 silver badges\n51\n51 bronze badges","comments":[]},{"answer":"An easy solution now would be to use the underscore.js library. It's providing many useful tools, such as each and will automatically delegate the job to the native forEach if available.\n\nA CodePen example of how it works is:\n\nvar arr = [\"elemA\", \"elemB\", \"elemC\"];\n_.each(arr, function(elem, index, ar)\n{\n...\n});\n\nSee also\nDocumentation for native Array.prototype.forEach().\nIn for_each...in (MDN) it is explained that for each (variable in object) is deprecated as the part of ECMA-357 (EAX) standard.\nfor...of (MDN) describes the next way of iterating using for (variable of object) as the part of the Harmony (ECMAScript 6) proposal.\nShare\nImprove this answer\nFollow\nedited May 30 '15 at 22:23\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 17 '13 at 9:07\nMicka\n1,4741\n1 gold badge\n15\n15 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"There isn't any for each loop in native JavaScript. You can either use libraries to get this functionality (I recommend Underscore.js), use a simple for in loop.\n\nfor (var instance in objects) {\n   ...\n}\n\n\nHowever, note that there may be reasons to use an even simpler for loop (see Stack Overflow question Why is using “for…in” with array iteration such a bad idea?)\n\nvar instance;\nfor (var i=0; i < objects.length; i++) {\n    var instance = objects[i];\n    ...\n}\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:47\nCommunity♦\n11\n1 silver badge\nanswered Feb 17 '12 at 13:58\njoidegn\n1,0208\n8 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"This is an iterator for NON-sparse list where the index starts at 0, which is the typical scenario when dealing with document.getElementsByTagName or document.querySelectorAll)\n\nfunction each( fn, data ) {\n\n    if(typeof fn == 'string')\n        eval('fn = function(data, i){' + fn + '}');\n\n    for(var i=0, L=this.length; i < L; i++) \n        fn.call( this[i], data, i );   \n\n    return this;\n}\n\nArray.prototype.each = each;  \n\n\nExamples of usage:\n\nExample #1\n\nvar arr = [];\n[1, 2, 3].each( function(a){ a.push( this * this}, arr);\narr = [1, 4, 9]\n\n\nExample #2\n\neach.call(document.getElementsByTagName('p'), \"this.className = data;\",'blue');\n\n\nEach p tag gets class=\"blue\"\n\nExample #3\n\neach.call(document.getElementsByTagName('p'), \n    \"if( i % 2 == 0) this.className = data;\",\n    'red'\n);\n\n\nEvery other p tag gets class=\"red\">\n\nExample #4\n\neach.call(document.querySelectorAll('p.blue'), \n    function(newClass, i) {\n        if( i < 20 )\n            this.className = newClass;\n    }, 'green'\n);\n\n\nAnd finally the first 20 blue p tags are changed to green\n\nCaution when using string as function: the function is created out-of-context and ought to be used only where you are certain of variable scoping. Otherwise, better to pass functions where scoping is more intuitive.\n\nShare\nImprove this answer\nFollow\nedited Sep 29 '16 at 12:28\nKarl Gjertsen\n4,2088\n8 gold badges\n35\n35 silver badges\n61\n61 bronze badges\nanswered Jan 30 '14 at 15:25\nTim\n4395\n5 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"There are a few ways to loop through an array in JavaScript, as below:\n\nfor - it's the most common one. Full block of code for looping\n\n\nvar languages = [\"Java\", \"JavaScript\", \"C#\", \"Python\"];\nvar i, len, text;\nfor (i = 0, len = languages.length, text = \"\"; i < len; i++) {\n    text += languages[i] + \"<br>\";\n}\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>\n Run code snippetExpand snippet\n\nwhile - loop while a condition is through. It seems to be the fastest loop\n\n\nvar text = \"\";\nvar i = 0;\nwhile (i < 10) {\n    text +=  i + \") something<br>\";\n    i++;\n}\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>\n Run code snippetExpand snippet\n\ndo/while - also loop through a block of code while the condition is true, will run at least one time\n\n\nvar text = \"\"\nvar i = 0;\n\ndo {\n    text += i + \") something <br>\";\n    i++;\n}\nwhile (i < 10);\n\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>\n Run code snippetExpand snippet\n\nFunctional loops - forEach, map, filter, also reduce (they loop through the function, but they are used if you need to do something with your array, etc.\n\n// For example, in this case we loop through the number and double them up using the map function\nvar numbers = [65, 44, 12, 4];\ndocument.getElementById(\"example\").innerHTML = numbers.map(function(num){return num * 2});\n<p id=\"example\"></p>\n Run code snippetExpand snippet\n\nFor more information and examples about functional programming on arrays, look at the blog post Functional programming in JavaScript: map, filter and reduce.\n\nShare\nImprove this answer\nFollow\nedited Oct 22 '19 at 23:32\nanswered May 10 '17 at 14:32\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"ECMAScript 5 (the version on JavaScript) to work with Arrays:\n\nforEach - Iterates through every item in the array and do whatever you need with each item.\n\n['C', 'D', 'E'].forEach(function(element, index) {\n  console.log(element + \" is #\" + (index+1) + \" in the musical scale\");\n});\n\n// Output\n// C is the #1 in musical scale\n// D is the #2 in musical scale\n// E is the #3 in musical scale\n\n\nIn case, more interested on operation on array using some inbuilt feature.\n\nmap - It creates a new array with the result of the callback function. This method is good to be used when you need to format the elements of your array.\n\n// Let's upper case the items in the array\n['bob', 'joe', 'jen'].map(function(elem) {\n  return elem.toUpperCase();\n});\n\n// Output: ['BOB', 'JOE', 'JEN']\n\n\nreduce - As the name says, it reduces the array to a single value by calling the given function passing in the current element and the result of the previous execution.\n\n[1,2,3,4].reduce(function(previous, current) {\n  return previous + current;\n});\n// Output: 10\n// 1st iteration: previous=1, current=2 => result=3\n// 2nd iteration: previous=3, current=3 => result=6\n// 3rd iteration: previous=6, current=4 => result=10\n\n\nevery - Returns true or false if all the elements in the array pass the test in the callback function.\n\n// Check if everybody has 18 years old of more.\nvar ages = [30, 43, 18, 5];\nages.every(function(elem) {\n  return elem >= 18;\n});\n\n// Output: false\n\n\nfilter - Very similar to every except that filter returns an array with the elements that return true to the given function.\n\n// Finding the even numbers\n[1,2,3,4,5,6].filter(function(elem){\n  return (elem % 2 == 0)\n});\n\n// Output: [2,4,6]\n\nShare\nImprove this answer\nFollow\nedited Sep 3 '19 at 20:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 9 '17 at 16:51\nAnil Kumar Arya\n2,9127\n7 gold badges\n35\n35 silver badges\n63\n63 bronze badges","comments":[]},{"answer":"There's no inbuilt ability to break in forEach. To interrupt execution use the Array#some like below:\n\n[1,2,3].some(function(number) {\n    return number === 1;\n});\n\n\nThis works because some returns true as soon as any of the callbacks, executed in array order, returns true, short-circuiting the execution of the rest. Original Answer see Array prototype for some\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Jul 27 '15 at 7:07\nPriyanshu Chauhan\n4,5933\n3 gold badges\n29\n29 silver badges\n31\n31 bronze badges","comments":[]},{"answer":"I also would like to add this as a composition of a reverse loop and an answer above for someone that would like this syntax too.\n\nvar foo = [object,object,object];\nfor (var i = foo.length, item; item = foo[--i];) {\n    console.log(item);\n}\n\n\nPros:\n\nThe benefit for this: You have the reference already in the first like that won't need to be declared later with another line. It is handy when looping trough the object array.\n\nCons:\n\nThis will break whenever the reference is false - falsey (undefined, etc.). It can be used as an advantage though. However, it would make it a little bit harder to read. And also depending on the browser it can be \"not\" optimized to work faster than the original one.\n\nShare\nImprove this answer\nFollow\nedited Mar 28 '20 at 16:08\nVB_Dojnaz\n3365\n5 silver badges\n16\n16 bronze badges\nanswered Aug 28 '15 at 7:27\nVolkan Seçkin Akbayır\n6466\n6 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"jQuery way using $.map:\n\nvar data = [1, 2, 3, 4, 5, 6, 7];\n\nvar newData = $.map(data, function(element) {\n    if (element % 2 == 0) {\n        return element;\n    }\n});\n\n// newData = [2, 4, 6];\n\nShare\nImprove this answer\nFollow\nanswered Apr 1 '14 at 11:15\nDaniel W.\n27.2k10\n10 gold badges\n78\n78 silver badges\n132\n132 bronze badges","comments":[]},{"answer":"Using loops with ECMAScript 6 destructuring and the spread operator\n\nDestructuring and using of the spread operator have proven quite useful for newcomers to ECMAScript 6 as being more human-readable/aesthetic, although some JavaScript veterans might consider it messy. Juniors or some other people might find it useful.\n\nThe following examples will use the for...of statement and the .forEach method.\n\nExamples 6, 7, and 8 can be used with any functional loops like .map, .filter, .reduce, .sort, .every, .some. For more information about these methods, check out the Array Object.\n\nExample 1: Normal for...of loop - no tricks here.\n\nlet arrSimple = ['a', 'b', 'c'];\n\nfor (let letter of arrSimple) {\n  console.log(letter);\n}\n Run code snippetExpand snippet\n\nExample 2: Split words to characters\n\nlet arrFruits = ['apple', 'orange', 'banana'];\n\nfor (let [firstLetter, ...restOfTheWord] of arrFruits) {\n  // Create a shallow copy using the spread operator\n  let [lastLetter] = [...restOfTheWord].reverse();\n  console.log(firstLetter, lastLetter, restOfTheWord);\n}\n Run code snippetExpand snippet\n\nExample 3: Looping with a key and value\n\n// let arrSimple = ['a', 'b', 'c'];\n\n// Instead of keeping an index in `i` as per example `for(let i = 0 ; i<arrSimple.length;i++)`\n// this example will use a multi-dimensional array of the following format type:\n// `arrWithIndex: [number, string][]`\n\nlet arrWithIndex = [\n  [0, 'a'],\n  [1, 'b'],\n  [2, 'c'],\n];\n\n// Same thing can be achieved using `.map` method\n// let arrWithIndex = arrSimple.map((i, idx) => [idx, i]);\n\n// Same thing can be achieved using `Object.entries`\n// NOTE: `Object.entries` method doesn't work on Internet Explorer  unless it's polyfilled\n// let arrWithIndex = Object.entries(arrSimple);\n\nfor (let [key, value] of arrWithIndex) {\n  console.log(key, value);\n}\n Run code snippetExpand snippet\n\nExample 4: Get object properties inline\n\nlet arrWithObjects = [{\n    name: 'Jon',\n    age: 32\n  },\n  {\n    name: 'Elise',\n    age: 33\n  }\n];\n\nfor (let { name, age: aliasForAge } of arrWithObjects) {\n  console.log(name, aliasForAge);\n}\n Run code snippetExpand snippet\n\nExample 5: Get deep object properties of what you need\n\nlet arrWithObjectsWithArr = [{\n    name: 'Jon',\n    age: 32,\n    tags: ['driver', 'chef', 'jogger']\n  },\n  {\n    name: 'Elise',\n    age: 33,\n    tags: ['best chef', 'singer', 'dancer']\n  }\n];\n\nfor (let { name, tags: [firstItemFromTags, ...restOfTags] } of arrWithObjectsWithArr) {\n  console.log(name, firstItemFromTags, restOfTags);\n}\n Run code snippetExpand snippet\n\nExample 6: Is Example 3 used with .forEach\n\nlet arrWithIndex = [\n  [0, 'a'],\n  [1, 'b'],\n  [2, 'c'],\n];\n\n// Not to be confused here, `forEachIndex` is the real index\n// `mappedIndex` was created by \"another user\", so you can't really trust it\n\narrWithIndex.forEach(([mappedIndex, item], forEachIndex) => {\n  console.log(forEachIndex, mappedIndex, item);\n});\n Run code snippetExpand snippet\n\nExample 7: Is Example 4 used with .forEach\n\nlet arrWithObjects = [{\n    name: 'Jon',\n    age: 32\n  },\n  {\n    name: 'Elise',\n    age: 33\n  }\n];\n// NOTE: Destructuring objects while using shorthand functions\n// are required to be surrounded by parentheses\narrWithObjects.forEach( ({ name, age: aliasForAge }) => {\n  console.log(name, aliasForAge)\n});\n Run code snippetExpand snippet\n\nExample 8: Is Example 5 used with .forEach\n\nlet arrWithObjectsWithArr = [{\n    name: 'Jon',\n    age: 32,\n    tags: ['driver', 'chef', 'jogger']\n  },\n  {\n    name: 'Elise',\n    age: 33,\n    tags: ['best chef', 'singer', 'dancer']\n  }\n];\n\narrWithObjectsWithArr.forEach(({\n  name,\n  tags: [firstItemFromTags, ...restOfTags]\n}) => {\n  console.log(name, firstItemFromTags, restOfTags);\n});\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Oct 9 '18 at 20:19\ndarklightcode\n2,3571\n1 gold badge\n12\n12 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"A way closest to your idea would be to use Array.forEach() which accepts a closure function which will be executed for each element of the array.\n\nmyArray.forEach(\n  (item) => {\n    // Do something\n    console.log(item);\n  }\n);\n\n\nAnother viable way would be to use Array.map() which works in the same way, but it also takes all values that you return and returns them in a new array (essentially mapping each element to a new one), like this:\n\nvar myArray = [1, 2, 3];\nmyArray = myArray.map(\n  (item) => {\n    return item + 1;\n  }\n);\n\nconsole.log(myArray); // [2, 3, 4]\n\nShare\nImprove this answer\nFollow\nedited Sep 4 '19 at 17:51\nCherryDT\n14.7k2\n2 gold badges\n32\n32 silver badges\n51\n51 bronze badges\nanswered Nov 9 '17 at 15:31\nAnte Jablan Adamović\n1,31510\n10 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"Performance\n\nToday (2019-12-18) I perform test on my macOS v10.13.6 (High Sierra), on Chrome v 79.0, Safari v13.0.4 and Firefox v71.0 (64 bit) - conclusions about optimisation (and micro-optimisation which usually is not worth to introduce it to code because the benefit is small, but code complexity grows).\n\nIt looks like the traditional for i (Aa) is a good choice to write fast code on all browsers.\n\nThe other solutions, like for-of (Ad), all in group C.... are usually 2 - 10 (and more) times slower than Aa, but for small arrays it is ok to use it - for the sake of increase code clarity.\n\nThe loops with array length cached in n (Ab, Bb, Be) are sometimes faster, sometimes not. Probably compilers automatically detect this situation and introduce caching. The speed differences between the cached and no-cached versions (Aa, Ba, Bd) are about ~1%, so it looks like introduce n is a micro-optimisation.\n\nThe i-- like solutions where the loop starts from the last array element (Ac, Bc) are usually ~30% slower than forward solutions - probably the reason is the way of CPU memory cache working - forward memory reading is more optimal for CPU caching). Is recommended to NOT USE such solutions.\n\nDetails\n\nIn tests we calculate the sum of array elements. I perform a test for small arrays (10 elements) and big arrays (1M elements) and divide them into three groups:\n\nA - for tests\nB - while tests\nC - other/alternative methods\n\nShow code snippet\n\nCross browser results\n\nResults for all tested browsers\n\nbrowsers**\n\nArray with 10 elements\n\nResults for Chrome. You can perform the test on your machine here.\n\nArray with 1,000,000 elements\n\nResults for Chrome. You can perform the test on your machine here\n\nShare\nImprove this answer\nFollow\nedited Mar 8 '20 at 19:17\nanswered Dec 18 '19 at 17:09\nKamil Kiełczewski\n57.6k22\n22 gold badges\n275\n275 silver badges\n253\n253 bronze badges","comments":[]},{"answer":"The lambda syntax doesn't usually work in Internet Explorer 10 or below.\n\nI usually use the\n\n[].forEach.call(arrayName,function(value,index){\n    console.log(\"value of the looped element\" + value);\n    console.log(\"index of the looped element\" + index);\n});\n\n\nIf you are a jQuery fan and already have a jQuery file running, you should reverse the positions of the index and value parameters\n\n$(\"#ul>li\").each(function(**index, value**){\n    console.log(\"value of the looped element\" + value);\n    console.log(\"index of the looped element\" + index);\n});\n\nShare\nImprove this answer\nFollow\nedited Sep 3 '19 at 20:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 11 '17 at 6:16\nMurtuza Husain\n312\n2 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"You can call forEach like this:\n\nforEach will iterate over the array you provide and for each iteration it will have element which holds the value of that iteration. If you need index you can get the current index by passing the i as the second parameter in the callback function for forEach.\n\nForeach is basically a High Order Function, Which takes another function as its parameter.\n\nlet theArray= [1,3,2];\n\ntheArray.forEach((element) => {\n  // Use the element of the array\n  console.log(element)\n}\n\n\nOutput:\n\n1\n3\n2\n\n\nYou can also iterate over an array like this:\n\nfor (let i=0; i<theArray.length; i++) {\n  console.log(i); // i will have the value of each index\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 25 '20 at 12:13\nanswered Jul 17 '18 at 12:30\nNouman Dilshad\n6028\n8 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"If you want to use forEach(), it will look like -\n\ntheArray.forEach ( element => {\n    console.log(element);\n});\n\n\nIf you want to use for(), it will look like -\n\nfor(let idx = 0; idx < theArray.length; idx++){\n    let element = theArray[idx];\n    console.log(element);\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 4 '19 at 23:18\ncfnerd\n3,25812\n12 gold badges\n28\n28 silver badges\n39\n39 bronze badges\nanswered May 30 '18 at 9:05\nHarunur Rashid\n3,9351\n1 gold badge\n16\n16 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"If you want to loop through an array of objects with the arrow function:\n\nlet arr = [{name:'john', age:50}, {name:'clark', age:19}, {name:'mohan', age:26}];\n\narr.forEach((person)=>{\n  console.log('I am ' + person.name + ' and I am ' + person.age + ' old');\n})\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Sep 3 '19 at 20:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 8 '19 at 14:04\nsubhashish negi\n1561\n1 silver badge\n8\n8 bronze badges","comments":[]},{"answer":"As per the new updated feature ECMAScript 6 (ES6) and ECMAScript 2015, you can use the following options with loops:\n\nfor loops\n\nfor(var i = 0; i < 5; i++){\n  console.log(i);\n}\n\n// Output: 0,1,2,3,4\n\n\nfor...in loops\n\nlet obj = {\"a\":1, \"b\":2}\n\nfor(let k in obj){\n  console.log(k)\n}\n\n// Output: a,b\n\n\nArray.forEach()\n\nlet array = [1,2,3,4]\n\narray.forEach((x) => {\n  console.log(x);\n})\n\n// Output: 1,2,3,4\n\n\nfor...of loops\n\nlet array = [1,2,3,4]\n\nfor(let x of array){\n  console.log(x);\n}\n\n// Output: 1,2,3,4\n\n\nwhile loops\n\nlet x = 0\n\nwhile(x < 5){\n  console.log(x)\n  x++\n}\n\n// Output: 1,2,3,4\n\n\ndo...while loops\n\nlet x = 0\n\ndo{\n  console.log(x)\n  x++\n}while(x < 5)\n\n// Output: 1,2,3,4\n\nShare\nImprove this answer\nFollow\nedited Mar 8 '20 at 14:51\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 22 '20 at 8:14\nankitkanojia\n2,8824\n4 gold badges\n18\n18 silver badges\n30\n30 bronze badges","comments":[]},{"answer":"Summary:\n\nWhen iterating over an array, we often want to accomplish one of the following goals:\n\nWe want to iterate over the array and create a new array:\n\nArray.prototype.map\n\n\n\nWe want to iterate over the array and don't create a new array:\n\nArray.prototype.forEach\n\nfor..of loop\n\nIn JavaScript, there are many ways of accomplishing both of these goals. However, some are more convenient than others. Below you can find some commonly used methods (the most convenient IMO) to accomplish array iteration in JavaScript.\n\nCreating new array: Map\n\nmap() is a function located on Array.prototype which can transform every element of an array and then returns a new array. map() takes as an argument a callback function and works in the following manner:\n\nlet arr = [1, 2, 3, 4, 5];\n\nlet newArr = arr.map((element, index, array) => {\n  return element * 2;\n})\n\nconsole.log(arr);\nconsole.log(newArr);\n Run code snippetExpand snippet\n\nThe callback which we have passed into map() as an argument gets executed for every element. Then an array gets returned which has the same length as the original array. In this new array element is transformed by the callback function passed in as an argument to map().\n\nThe distinct difference between map and another loop mechanism like forEach and a for..of loop is that map returns a new array and leaves the old array intact (except if you explicitly manipulate it with thinks like splice).\n\nAlso, note that the map function's callback provides the index number of the current iteration as a second argument. Furthermore, does the third argument provide the array on which map was called? Sometimes these properties can be very useful.\n\nLoop using forEach\n\nforEach is a function which is located on Array.prototype which takes a callback function as an argument. It then executes this callback function for every element in the array. In contrast to the map() function, the forEach function returns nothing (undefined). For example:\n\nlet arr = [1, 2, 3, 4, 5];\n\narr.forEach((element, index, array) => {\n\n  console.log(element * 2);\n\n  if (index === 4) {\n    console.log(array)\n  }\n  // index, and oldArray are provided as 2nd and 3th argument by the callback\n\n})\n\nconsole.log(arr);\n Run code snippetExpand snippet\n\nJust like the map function, the forEach callback provides the index number of the current iteration as a second argument. Also, does the third argument provide the array on which forEach was called?\n\nLoop through elements using for..of\n\nThe for..of loop loops through every element of an array (or any other iterable object). It works in the following manner:\n\nlet arr = [1, 2, 3, 4, 5];\n\nfor(let element of arr) {\n  console.log(element * 2);\n}\n Run code snippetExpand snippet\n\nIn the above example, element stands for an array element and arr is the array which we want to loop. Note that the name element is arbitrary, and we could have picked any other name like 'el' or something more declarative when this is applicable.\n\nDon't confuse the for..in loop with the for..of loop. for..in will loop through all enumerable properties of the array whereas the for..of loop will only loop through the array elements. For example:\n\nlet arr = [1, 2, 3, 4, 5];\n\narr.foo = 'foo';\n\nfor(let element of arr) {\n  console.log(element);\n}\n\nfor(let element in arr) {\n  console.log(element);\n}\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Mar 28 '20 at 18:11\nVB_Dojnaz\n3365\n5 silver badges\n16\n16 bronze badges\nanswered Sep 8 '18 at 7:55\nWillem van der Veen\n21.2k11\n11 gold badges\n121\n121 silver badges\n116\n116 bronze badges","comments":[]},{"answer":"If you have a massive array you should use iterators to gain some efficiency. Iterators are a property of certain JavaScript collections (like Map, Set, String, Array). Even, for..of uses iterator under-the-hood.\n\nIterators improve efficiency by letting you consume the items in a list one at a time as if they were a stream. What makes an iterator special is how it traverses a collection. Other loops need to load the entire collection up front in order to iterate over it, whereas an iterator only needs to know the current position in the collection.\n\nYou access the current item by calling the iterator’s next method. The next method will return the value of the current item and a boolean to indicate when you have reached the end of the collection. The following is an example of creating an iterator from an array.\n\nTransform your regular array to iterator using values() method like this:\n\n    const myArr = [2,3,4]\n\nlet it = myArr.values();\n\nconsole.log(it.next());\nconsole.log(it.next());\nconsole.log(it.next());\nconsole.log(it.next());\n Run code snippetExpand snippet\n\nYou can also transform your regular array to iterator using Symbol.iterator like this:\n\nconst myArr = [2,3,4]\n\nlet it = myArr[Symbol.iterator]();\n\nconsole.log(it.next());\nconsole.log(it.next());\nconsole.log(it.next());\nconsole.log(it.next());\n Run code snippetExpand snippet\n\nYou can also transform your regular array to an iterator like this:\n\nlet myArr = [8, 10, 12];\n\nfunction makeIterator(array) {\n    var nextIndex = 0;\n    \n    return {\n       next: function() {\n           return nextIndex < array.length ?\n               {value: array[nextIndex++], done: false} :\n               {done: true};\n       }\n    };\n};\n\nvar it = makeIterator(myArr);\n\nconsole.log(it.next().value);   // {value: 8, done: false}\nconsole.log(it.next().value);   // {value: 10, done: false}\nconsole.log(it.next().value);   // {value: 12, done: false}\nconsole.log(it.next().value);   // {value: undefined, done: true}\n Run code snippetExpand snippet\n\nNOTE:\n\nIterators are exhaustible in nature.\nObjects are not iterable by default. Use for..in in that case because instead of values it works with keys.\n\nYou can read more about iteration protocol here.\n\nShare\nImprove this answer\nFollow\nedited Jul 6 '18 at 11:32\nanswered Jul 6 '18 at 7:11\nBlackBeard\n8,7687\n7 gold badges\n44\n44 silver badges\n55\n55 bronze badges","comments":[]}]},{"id":"161813","href":"https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-a-git-repository","title":"How to resolve merge conflicts in a Git repository","description":"\n                \nI want to resolve merge conflicts in my Git repository.\nHow can I do that?\n    ","questionComments":["The following blog post seems to give a very good example on how to handle merge conflict with Git that should get you going in the right direction. Handling and Avoiding Conflicts in Git","You can configure a merge tool (kdiff3 jebaird.com/2013/07/08/…) and then use git mergetool. When you're working in large developer teams you'll always encounter merge conflicts.","Don't forget that you can mitigate most merge conflicts by regularly merging downstream!","Also see git-tower.com/learn/git/ebook/command-line/tools-services/…","Fascinating question: Asked in 2008, 100% open ended with no hint at all about what it's really about (is it about GUI? about the git commands? about semantics? about pushing/pulling or just general conflicts?) - completely unanswerable. 30 answers, all of them (as far as a quick glance shows) more or less going on about different diff3 and merge tools, none accepted. Top-voted answer mentions a command that does not even work out of the box with a default git installation. Managed to hit the SE start page for me today, 2017, with 1.3m views and thousands of votes both ways. Fascinating."],"answers":[{"answer":"Try: git mergetool\n\nIt opens a GUI that steps you through each conflict, and you get to choose how to merge. Sometimes it requires a bit of hand editing afterwards, but usually it's enough by itself. It is much better than doing the whole thing by hand certainly.\n\nAs per Josh Glover's comment:\n\nThe command\n\ndoesn't necessarily open a GUI unless you install one. Running git mergetool for me resulted in vimdiff being used. You can install one of the following tools to use it instead: meld, opendiff, kdiff3, tkdiff, xxdiff, tortoisemerge, gvimdiff, diffuse, ecmerge, p4merge, araxis, vimdiff, emerge.\n\nBelow is the sample procedure to use vimdiff for resolve merge conflicts. Based on this link\n\nStep 1: Run following commands in your terminal\n\ngit config merge.tool vimdiff\ngit config merge.conflictstyle diff3\ngit config mergetool.prompt false\n\n\nThis will set vimdiff as the default merge tool.\n\nStep 2: Run following command in terminal\n\ngit mergetool\n\n\nStep 3: You will see a vimdiff display in following format\n\n  ╔═══════╦══════╦════════╗\n  ║       ║      ║        ║\n  ║ LOCAL ║ BASE ║ REMOTE ║\n  ║       ║      ║        ║\n  ╠═══════╩══════╩════════╣\n  ║                       ║\n  ║        MERGED         ║\n  ║                       ║\n  ╚═══════════════════════╝\n\n\nThese 4 views are\n\nLOCAL – this is file from the current branch\n\nBASE – common ancestor, how file looked before both changes\n\nREMOTE – file you are merging into your branch\n\nMERGED – merge result, this is what gets saved in the repo\n\nYou can navigate among these views using ctrl+w. You can directly reach MERGED view using ctrl+w followed by j.\n\nMore information about vimdiff navigation is here and here.\n\nStep 4. You could edit the MERGED view the following way\n\nIf you want to get changes from REMOTE\n\n:diffg RE\n\n\nIf you want to get changes from BASE\n\n:diffg BA\n\n\nIf you want to get changes from LOCAL\n\n:diffg LO\n\n\nStep 5. Save, Exit, Commit and Clean up\n\n:wqa save and exit from vi\n\ngit commit -m \"message\"\n\ngit clean Remove extra files (e.g. *.orig) created by diff tool.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 20:59\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 2 '08 at 17:50\nPeter Burns\n42.8k7\n7 gold badges\n35\n35 silver badges\n56\n56 bronze badges","comments":["FYI you can use git mergetool -y to save a few keystrokes if you're merging a lot of files at once.","Well, it doesn't necessarily open a GUI unless you install one. Running git mergetool for me resulted in vimdiff being used. You can install one of the following tools to use it instead: meld opendiff kdiff3 tkdiff xxdiff tortoisemerge gvimdiff diffuse ecmerge p4merge araxis vimdiff emerge.","Good point Josh. On ubuntu I've had the best luck with meld, its three way merge display isn't bad. On OSX git chose a nice default.","This opened KDiff3. Which I have absolutely no clue how to use.","You can also use Beyond Compare 3 now (git mergetool -t bc3)."]},{"answer":"Here's a probable use case, from the top:\n\nYou're going to pull some changes, but oops, you're not up to date:\n\ngit fetch origin\ngit pull origin master\n\nFrom ssh://gitosis@example.com:22/projectname\n * branch            master     -> FETCH_HEAD\nUpdating a030c3a..ee25213\nerror: Entry 'filename.c' not uptodate. Cannot merge.\n\n\nSo you get up-to-date and try again, but have a conflict:\n\ngit add filename.c\ngit commit -m \"made some wild and crazy changes\"\ngit pull origin master\n\nFrom ssh://gitosis@example.com:22/projectname\n * branch            master     -> FETCH_HEAD\nAuto-merging filename.c\nCONFLICT (content): Merge conflict in filename.c\nAutomatic merge failed; fix conflicts and then commit the result.\n\n\nSo you decide to take a look at the changes:\n\ngit mergetool\n\n\nOh my, oh my, upstream changed some things, but just to use my changes...no...their changes...\n\ngit checkout --ours filename.c\ngit checkout --theirs filename.c\ngit add filename.c\ngit commit -m \"using theirs\"\n\n\nAnd then we try a final time\n\ngit pull origin master\n\nFrom ssh://gitosis@example.com:22/projectname\n * branch            master     -> FETCH_HEAD\nAlready up-to-date.\n\n\nTa-da!\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 4 '10 at 17:04\ncoolaj86\n65.6k14\n14 gold badges\n95\n95 silver badges\n109\n109 bronze badges","comments":["This was super helpful because I had a lot of merge errors with binary files (art assets) and merging those seems to always fail, so I need to overwrite it with the new file always and not \"merge\"","Careful! The meaning of --ours and --theirs is reversed. --ours == the remote. --theirs == local. See git merge --help","In my case, I confirm that --theirs = remote repository, --ours = my own local repository. It is the opposite of @mmell comments.","@mmell Only on a rebase, apparently. See this question","Guys, \"ours\" and \"theirs\" is relative to whether or not you are merging or rebasing. If you're merging, then \"ours\" means the branch you're merging into, and \"theirs\" is the branch you're merging in. When you're rebasing, then \"ours\" means the commits you're rebasing onto, while \"theirs\" refers to the commits that you want to rebase."]},{"answer":"I find merge tools rarely help me understand the conflict or the resolution. I'm usually more successful looking at the conflict markers in a text editor and using git log as a supplement.\n\nHere are a few tips:\n\nTip One\n\nThe best thing I have found is to use the \"diff3\" merge conflict style:\n\ngit config merge.conflictstyle diff3\n\nThis produces conflict markers like this:\n\n<<<<<<<\nChanges made on the branch that is being merged into. In most cases,\nthis is the branch that I have currently checked out (i.e. HEAD).\n|||||||\nThe common ancestor version.\n=======\nChanges made on the branch that is being merged in. This is often a \nfeature/topic branch.\n>>>>>>>\n\n\nThe middle section is what the common ancestor looked like. This is useful because you can compare it to the top and bottom versions to get a better sense of what was changed on each branch, which gives you a better idea for what the purpose of each change was.\n\nIf the conflict is only a few lines, this generally makes the conflict very obvious. (Knowing how to fix a conflict is very different; you need to be aware of what other people are working on. If you're confused, it's probably best to just call that person into your room so they can see what you're looking at.)\n\nIf the conflict is longer, then I will cut and paste each of the three sections into three separate files, such as \"mine\", \"common\" and \"theirs\".\n\nThen I can run the following commands to see the two diff hunks that caused the conflict:\n\ndiff common mine\ndiff common theirs\n\n\nThis is not the same as using a merge tool, since a merge tool will include all of the non-conflicting diff hunks too. I find that to be distracting.\n\nTip Two\n\nSomebody already mentioned this, but understanding the intention behind each diff hunk is generally very helpful for understanding where a conflict came from and how to handle it.\n\ngit log --merge -p <name of file>\n\n\nThis shows all of the commits that touched that file in between the common ancestor and the two heads you are merging. (So it doesn't include commits that already exist in both branches before merging.) This helps you ignore diff hunks that clearly are not a factor in your current conflict.\n\nTip Three\n\nVerify your changes with automated tools.\n\nIf you have automated tests, run those. If you have a lint, run that. If it's a buildable project, then build it before you commit, etc. In all cases, you need to do a bit of testing to make sure your changes didn't break anything. (Heck, even a merge without conflicts can break working code.)\n\nTip Four\n\nPlan ahead; communicate with co-workers.\n\nPlanning ahead and being aware of what others are working on can help prevent merge conflicts and/or help resolve them earlier -- while the details are still fresh in mind.\n\nFor example, if you know that you and another person are both working on different refactoring that will both affect the same set of files, you should talk to each other ahead of time and get a better sense for what types of changes each of you is making. You might save considerable time and effort if you conduct your planned changes serially rather than in parallel.\n\nFor major refactorings that cut across a large swath of code, you should strongly consider working serially: everybody stops working on that area of the code while one person performs the complete refactoring.\n\nIf you can't work serially (due to time pressure, maybe), then communicating about expected merge conflicts at least helps you solve the problems sooner while the details are still fresh in mind. For example, if a co-worker is making a disruptive series of commits over the course of a one-week period, you may choose to merge/rebase on that co-workers branch once or twice each day during that week. That way, if you do find merge/rebase conflicts, you can solve them more quickly than if you wait a few weeks to merge everything together in one big lump.\n\nTip Five\n\nIf you're unsure of a merge, don't force it.\n\nMerging can feel overwhelming, especially when there are a lot of conflicting files and the conflict markers cover hundreds of lines. Often times when estimating software projects we don't include enough time for overhead items like handling a gnarly merge, so it feels like a real drag to spend several hours dissecting each conflict.\n\nIn the long run, planning ahead and being aware of what others are working on are the best tools for anticipating merge conflicts and prepare yourself to resolve them correctly in less time.\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '14 at 17:32\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 28 '11 at 21:08\nMark E. Haase\n23.6k8\n8 gold badges\n61\n61 silver badges\n69\n69 bronze badges","comments":["The diff3 option is a great feature to have with merges. The only GUI I've come across that shows it is Perforce's p4merge, which can be installed and used separately from Perforce's other tools (which I've not used, but heard complaints about).","After a rebase attempt which resulted in a merge conflict: $ git log --merge -p build.xml output: fatal: --merge without MERGE_HEAD?","what if I have changes on one file from branch1 and deletion of that file in branch2. How can I solve that merge conflict? Is there any way using git where I can merge them by keeping the changes of one branch?","git config merge.conflictstyle diff3 - thank you, sir. This is amazing and has freed me from trying to find (and pay $$) for a good 3 way merge GUI. IMO this is better because it shows the common ancestor as well as local/remote, and shows the last commit log lines which (AFAIK) no GUI does. The commits definitely help you identify what code belongs to what branch.","I have found that sometimes the diff3 conflictstyle results in enormous diff hunks that are largely identical, whereas the default will produce smaller, more manageable, hunks. Unfortunately, I don't have a reproducer I can use for a bug report. But if you encounter this problem you might consider turning off the option temporarily."]},{"answer":"Identify which files are in conflict (Git should tell you this).\n\nOpen each file and examine the diffs; Git demarcates them. Hopefully it will be obvious which version of each block to keep. You may need to discuss it with fellow developers who committed the code.\n\nOnce you've resolved the conflict in a file git add the_file.\n\nOnce you've resolved all conflicts, do git rebase --continue or whatever command Git said to do when you completed.\n\nShare\nImprove this answer\nFollow\nedited Aug 7 '14 at 17:48\nuser456814\nanswered Oct 2 '08 at 12:41\ndavetron5000\n22k10\n10 gold badges\n64\n64 silver badges\n97\n97 bronze badges","comments":["@Justin Think of Git as tracking content rather than tracking files. Then it's easy to see that the content you've updated isn't in the repository and needs to be added. This way of thinking also explains why Git doesn't track empty folders: Although they are technically files, there isn't any content to track.","content is there, conflict occurs because there 2 version of content. Therefore \"git add\" does not sound correct. And it does not work (git add, git commit) if you want commit only that one file after conflict was resolved (\"fatal: cannot do a partial commit during a merge.\")","Yes, technically, this answers the question which as asked, but is not a usable answer, in my opinion, sorry. What's the point of making one branch the same as another? Of course a merge will have conflicts..","Thulfir: who said anything about making one branch the same as another? There are different scenarios where you need to merge, without \"making one branch the same as another\". One is when you're done with a development branch and want to incorporate its changes into the master branch; after this, the development branch can be deleted. Another one is when you want to rebase your development branch, in order to ease the eventual final merge into the master.","@JustinGrant git add stages files in the index; it does not add anything to the repository. git commit adds things to the repository. This usage makes sense for merges -- the merge automatically stages all of the changes that can be merged automatically; it is your responsibility to merge the rest of the changes and add those to the index when you are done."]},{"answer":"Merge conflicts happens when changes are made to a file at the same time. Here is how to solve it.\n\ngit CLI\n\nHere are simple steps what to do when you get into conflicted state:\n\nNote the list of conflicted files with: git status (under Unmerged paths section).\n\nSolve the conflicts separately for each file by one of the following approaches:\n\nUse GUI to solve the conflicts: git mergetool (the easiest way).\n\nTo accept remote/other version, use: git checkout --theirs path/file. This will reject any local changes you did for that file.\n\nTo accept local/our version, use: git checkout --ours path/file\n\nHowever you've to be careful, as remote changes that conflicts were done for some reason.\n\nRelated: What is the precise meaning of \"ours\" and \"theirs\" in git?\n\nEdit the conflicted files manually and look for the code block between <<<<</>>>>> then choose the version either from above or below =====. See: How conflicts are presented.\n\nPath and filename conflicts can be solved by git add/git rm.\n\nFinally, review the files ready for commit using: git status.\n\nIf you still have any files under Unmerged paths, and you did solve the conflict manually, then let Git know that you solved it by: git add path/file.\n\nIf all conflicts were solved successfully, commit the changes by: git commit -a and push to remote as usual.\n\nSee also: Resolving a merge conflict from the command line at GitHub\n\nFor practical tutorial, check: Scenario 5 - Fixing Merge Conflicts by Katacoda.\n\nDiffMerge\n\nI've successfully used DiffMerge which can visually compare and merge files on Windows, macOS and Linux/Unix.\n\nIt graphically can show the changes between 3 files and it allows automatic merging (when safe to do so) and full control over editing the resulting file.\n\nImage source: DiffMerge (Linux screenshot)\n\nSimply download it and run in repo as:\n\ngit mergetool -t diffmerge .\n\nmacOS\n\nOn macOS you can install via:\n\nbrew install caskroom/cask/brew-cask\nbrew cask install diffmerge\n\n\nAnd probably (if not provided) you need the following extra simple wrapper placed in your PATH (e.g. /usr/bin):\n\n#!/bin/sh\nDIFFMERGE_PATH=/Applications/DiffMerge.app\nDIFFMERGE_EXE=${DIFFMERGE_PATH}/Contents/MacOS/DiffMerge\nexec ${DIFFMERGE_EXE} --nosplash \"$@\"\n\n\nThen you can use the following keyboard shortcuts:\n\n⌘-Alt-Up/Down to jump to previous/next changes.\n⌘-Alt-Left/Right to accept change from left or right\n\nAlternatively you can use opendiff (part of Xcode Tools) which lets you merge two files or directories together to create a third file or directory.\n\nShare\nImprove this answer\nFollow\nedited Oct 15 '19 at 9:32\nanswered Aug 5 '15 at 14:29\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges","comments":[]},{"answer":"Check out the answers in Stack Overflow question Aborting a merge in Git, especially Charles Bailey's answer which shows how to view the different versions of the file with problems, for example,\n\n# Common base version of the file.\ngit show :1:some_file.cpp\n\n# 'Ours' version of the file.\ngit show :2:some_file.cpp\n\n# 'Theirs' version of the file.\ngit show :3:some_file.cpp\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:47\nCommunity♦\n11\n1 silver badge\nanswered Oct 3 '08 at 15:15\nPat Notz\n189k29\n29 gold badges\n87\n87 silver badges\n92\n92 bronze badges","comments":["Also check out the \"-m\" option to \"git checkout -m\" - it allows you to extract the different flies back out into your workspace","This saved me. Looking at each file separately allowed me to remember what I was going for in each branch. Then I could make the decision to choose."]},{"answer":"If you're making frequent small commits, then start by looking at the commit comments with git log --merge. Then git diff will show you the conflicts.\n\nFor conflicts that involve more than a few lines, it's easier to see what's going on in an external GUI tool. I like opendiff -- Git also supports vimdiff, gvimdiff, kdiff3, tkdiff, meld, xxdiff, emerge out of the box and you can install others: git config merge.tool \"your.tool\" will set your chosen tool and then git mergetool after a failed merge will show you the diffs in context.\n\nEach time you edit a file to resolve a conflict, git add filename will update the index and your diff will no longer show it. When all the conflicts are handled and their files have been git add-ed, git commit will complete your merge.\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '14 at 17:43\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 2 '08 at 16:11\nPaul\n16k3\n3 gold badges\n31\n31 silver badges\n25\n25 bronze badges","comments":["Using \"git add\" is the real trick here. You may not even want to commit (maybe you want to stash), but you have to do \"git add\" to complete the merge. I think mergetool does the add for you (although it isn't in the manpage), but if you do the merge manually, you need to use \"git add\" to complete it (even if you don't want to commit)."]},{"answer":"I either want my or their version in full, or want to review individual changes and decide for each of them.\n\nFully accept my or theirs version:\n\nAccept my version (local, ours):\n\ngit checkout --ours -- <filename>\ngit add <filename>              # Marks conflict as resolved\ngit commit -m \"merged bla bla\"  # An \"empty\" commit\n\n\nAccept their version (remote, theirs):\n\ngit checkout --theirs -- <filename>\ngit add <filename>\ngit commit -m \"merged bla bla\"\n\n\nIf you want to do for all conflict files run:\n\ngit merge --strategy-option ours\n\n\nor\n\ngit merge --strategy-option theirs\n\n\nReview all changes and accept them individually\n\ngit mergetool\nReview changes and accept either version for each of them.\ngit add <filename>\ngit commit -m \"merged bla bla\"\n\nDefault mergetool works in command line. How to use a command line mergetool should be a separate question.\n\nYou can also install visual tool for this, e.g. meld and run\n\ngit mergetool -t meld\n\n\nIt will open local version (ours), \"base\" or \"merged\" version (the current result of the merge) and remote version (theirs). Save the merged version when you are finished, run git mergetool -t meld again until you get \"No files need merging\", then go to Steps 3. and 4.\n\nShare\nImprove this answer\nFollow\nedited Jun 19 '18 at 3:29\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 29 '16 at 13:02\nNoidea\n1,2958\n8 silver badges\n16\n16 bronze badges","comments":["This command: git checkout --theirs -- <filename> changed ALL the files to theirs, not just <filename>","Actually I was wrong. This only updates specified file."]},{"answer":"See How Conflicts Are Presented or, in Git, the git merge documentation to understand what merge conflict markers are.\n\nAlso, the How to Resolve Conflicts section explains how to resolve the conflicts:\n\nAfter seeing a conflict, you can do two things:\n\nDecide not to merge. The only clean-ups you need are to reset the index file to the HEAD commit to reverse 2. and to clean up working tree changes made by 2. and 3.; git merge --abort can be used for this.\n\nResolve the conflicts. Git will mark the conflicts in the working tree. Edit the files into shape and git add them to the index. Use git commit to seal the deal.\n\nYou can work through the conflict with a number of tools:\n\nUse a mergetool. git mergetool to launch a graphical mergetool which will work you through the merge.\n\nLook at the diffs. git diff will show a three-way diff, highlighting changes from both the HEAD and MERGE_HEAD versions.\n\nLook at the diffs from each branch. git log --merge -p <path> will show diffs first for the HEAD version and then the MERGE_HEAD version.\n\nLook at the originals. git show :1:filename shows the common ancestor, git show :2:filename shows the HEAD version, and git show :3:filename shows the MERGE_HEAD version.\n\nYou can also read about merge conflict markers and how to resolve them in the Pro Git book section Basic Merge Conflicts.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jul 14 '13 at 18:34\nuser456814","comments":[]},{"answer":"For Emacs users which want to resolve merge conflicts semi-manually:\n\ngit diff --name-status --diff-filter=U\n\n\nshows all files which require conflict resolution.\n\nOpen each of those files one by one, or all at once by:\n\nemacs $(git diff --name-only --diff-filter=U)\n\n\nWhen visiting a buffer requiring edits in Emacs, type\n\nALT+x vc-resolve-conflicts\n\n\nThis will open three buffers (mine, theirs, and the output buffer). Navigate by pressing 'n' (next region), 'p' (prevision region). Press 'a' and 'b' to copy mine or theirs region to the output buffer, respectively. And/or edit the output buffer directly.\n\nWhen finished: Press 'q'. Emacs asks you if you want to save this buffer: yes. After finishing a buffer mark it as resolved by running from the teriminal:\n\ngit add FILENAME\n\n\nWhen finished with all buffers type\n\ngit commit\n\n\nto finish the merge.\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '14 at 17:24\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 22 '13 at 23:04\neci\n2,01418\n18 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"Bonus:\n\nIn speaking of pull/fetch/merge in the previous answers, I would like to share an interesting and productive trick,\n\ngit pull --rebase\n\nThis above command is the most useful command in my Git life which saved a lot of time.\n\nBefore pushing your newly committed change to remote server, try git pull --rebase rather git pull and manual merge and it will automatically sync the latest remote server changes (with a fetch + merge) and will put your local latest commit at the top in the Git log. No need to worry about manual pull/merge.\n\nIn case of a conflict, just use\n\ngit mergetool\ngit add conflict_file\ngit rebase --continue\n\n\nFind details at: What does “git pull –rebase” do?\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 25 '15 at 15:24\nSazzad Hissain Khan\n30.5k21\n21 gold badges\n138\n138 silver badges\n201\n201 bronze badges","comments":[]},{"answer":"Simply, if you know well that changes in one of the repositories is not important, and want to resolve all changes in favor of the other one, use:\n\ngit checkout . --ours\n\n\nto resolve changes in the favor of your repository, or\n\ngit checkout . --theirs\n\n\nto resolve changes in favor of the other or the main repository.\n\nOr else you will have to use a GUI merge tool to step through files one by one, say the merge tool is p4merge, or write any one's name you've already installed\n\ngit mergetool -t p4merge\n\n\nand after finishing a file, you will have to save and close, so the next one will open.\n\nShare\nImprove this answer\nFollow\nedited Jun 19 '18 at 3:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 26 '16 at 17:42\nMohamed\n2,9091\n1 gold badge\n25\n25 silver badges\n35\n35 bronze badges","comments":["git checkout . --theirs resolved my problem thanks","if you prefer to resolve conflicts manually try opening the folder in Visual Studio Code, it marks files with conflicts and colors conflict lines inside every one"]},{"answer":"Please follow the following steps to fix merge conflicts in Git:\n\nCheck the Git status: git status\n\nGet the patchset: git fetch (checkout the right patch from your Git commit)\n\nCheckout a local branch (temp1 in my example here): git checkout -b temp1\n\nPull the recent contents from master: git pull --rebase origin master\n\nStart the mergetool and check the conflicts and fix them...and check the changes in the remote branch with your current branch: git mergetool\n\nCheck the status again: git status\n\nDelete the unwanted files locally created by mergetool, usually mergetool creates extra file with *.orig extension. Please delete that file as that is just the duplicate and fix changes locally and add the correct version of your files. git add #your_changed_correct_files\n\nCheck the status again: git status\n\nCommit the changes to the same commit id (this avoids a new separate patch set): git commit --amend\n\nPush to the master branch: git push (to your Git repository)\n\nShare\nImprove this answer\nFollow\nedited Jun 19 '18 at 3:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 16 '15 at 7:02\nChhabilal\n1,04611\n11 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"There are three steps:\n\nFind which files cause conflicts by the command\n\n git status\n\n\nCheck the files, in which you would find the conflicts marked like\n\n <<<<<<<<head\n blablabla\n\n\nChange it to the way you want it, and then commit with the commands\n\n git add solved_conflicts_files\n git commit -m 'merge msg'\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 23 '17 at 14:38\nQijun Liu\n1,5151\n1 gold badge\n11\n11 silver badges\n11\n11 bronze badges","comments":["Worked for me! Thanks!","You must pay attention if do this during rebase. You should use git rebase --continue instead of git commit"]},{"answer":"You could fix merge conflicts in a number of ways as other have detailed.\n\nI think the real key is knowing how changes flow with local and remote repositories. The key to this is understanding tracking branches. I have found that I think of the tracking branch as the 'missing piece in the middle' between me my local, actual files directory and the remote defined as origin.\n\nI've personally got into the habit of 2 things to help avoid this.\n\nInstead of:\n\ngit add .\ngit commit -m\"some msg\"\n\n\nWhich has two drawbacks -\n\na) All new/changed files get added and that might include some unwanted changes.\nb) You don't get to review the file list first.\n\nSo instead I do:\n\ngit add file,file2,file3...\ngit commit # Then type the files in the editor and save-quit.\n\n\nThis way you are more deliberate about which files get added and you also get to review the list and think a bit more while using the editor for the message. I find it also improves my commit messages when I use a full screen editor rather than the -m option.\n\n[Update - as time has passed I've switched more to:\n\ngit status # Make sure I know whats going on\ngit add .\ngit commit # Then use the editor\n\n\n]\n\nAlso (and more relevant to your situation), I try to avoid:\n\ngit pull\n\n\nor\n\ngit pull origin master.\n\n\nbecause pull implies a merge and if you have changes locally that you didn't want merged you can easily end up with merged code and/or merge conflicts for code that shouldn't have been merged.\n\nInstead I try to do\n\ngit checkout master\ngit fetch   \ngit rebase --hard origin/master # or whatever branch I want.\n\n\nYou may also find this helpful:\n\ngit branch, fork, fetch, merge, rebase and clone, what are the differences?\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:18\nCommunity♦\n11\n1 silver badge\nanswered Apr 19 '13 at 1:08\nMichael Durrant\n85.6k84\n84 gold badges\n288\n288 silver badges\n437\n437 bronze badges","comments":["Hey, I kinda understood your answer. But since i'm new to github merge conflicts, I think there is something missing. What happens to your local modifications when you do git checkout master and git fetch and git rebase --hard origin/master","I believe you should add more details on what to do. Another example which is confusing me, you mentioned in your answer: we do git add ., will it save our local modifications so we can follow up with git checkout master ? or are they two different scenarios ?","@MichaelDurrant $ git rebase --hard origin/master b5a30cc159ba8dd error: unknown option hard' usage: git rebase [-i] [options] [--exec <cmd>] [--onto <newbase>] [<upstream>] [<branch>] or: git rebase [-i] [options] [--exec <cmd>] [--onto <newbase>] --root [<branch>] or: git rebase --continue | --abort | --skip | --edit-todo `"]},{"answer":"CoolAJ86's answer sums up pretty much everything. In case you have changes in both branches in the same piece of code you will have to do a manual merge. Open the file in conflict in any text editor and you should see following structure.\n\n(Code not in Conflict)\n>>>>>>>>>>>\n(first alternative for conflict starts here)\nMultiple code lines here\n===========\n(second alternative for conflict starts here)\nMultiple code lines here too    \n<<<<<<<<<<<\n(Code not in conflict here)\n\n\nChoose one of the alternatives or a combination of both in a way that you want new code to be, while removing equal signs and angle brackets.\n\ngit commit -a -m \"commit message\"\ngit push origin master\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '14 at 17:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 25 '14 at 16:17\niankit\n7,34810\n10 gold badges\n44\n44 silver badges\n55\n55 bronze badges","comments":[]},{"answer":"If you want to merge from branch test to master, you can follow these steps:\n\nStep 1: Go to the branch\n\ngit checkout test\n\n\nStep 2:\n\ngit pull --rebase origin master\n\n\nStep 3: If there are some conflicts, go to these files to modify it.\n\nStep 4: Add these changes\n\ngit add #your_changes_files\n\n\nStep 5:\n\ngit rebase --continue\n\n\nStep 6: If there is still conflict, go back to step 3 again. If there is no conflict, do following:\n\ngit push origin +test\n\n\nStep 7: And then there is no conflict between test and master. You can use merge directly.\n\nShare\nImprove this answer\nFollow\nedited Feb 2 at 5:24\nHenry\n5202\n2 silver badges\n16\n16 bronze badges\nanswered Aug 18 '14 at 19:42\nHaimei\n11.5k3\n3 gold badges\n45\n45 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"git log --merge -p [[--] path]\n\n\nDoes not seem to always work for me and usually ends up displaying every commit that was different between the two branches, this happens even when using -- to separate the path from the command.\n\nWhat I do to work around this issue is open up two command lines and in one run\n\ngit log ..$MERGED_IN_BRANCH --pretty=full -p [path]\n\n\nand in the other\n\ngit log $MERGED_IN_BRANCH.. --pretty=full -p [path]\n\n\nReplacing $MERGED_IN_BRANCH with the branch I merged in and [path] with the file that is conflicting. This command will log all the commits, in patch form, between (..) two commits. If you leave one side empty like in the commands above git will automatically use HEAD (the branch you are merging into in this case).\n\nThis will allow you to see what commits went into the file in the two branches after they diverged. It usually makes it much easier to solve conflicts.\n\nShare\nImprove this answer\nFollow\nedited Jan 5 '16 at 3:45\nstites\n4,0435\n5 gold badges\n29\n29 silver badges\n43\n43 bronze badges\nanswered Dec 11 '14 at 15:19\nBrian Di Palma\n6,2733\n3 gold badges\n17\n17 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"Using patience\n\nFor a big merge conflict, using patience provided good results for me. It will try to match blocks rather than individual lines.\n\nIf you change the indentation of your program for instance, the default Git merge strategy sometimes matches single braces { which belongs to different functions. This is avoided with patience:\n\ngit merge -s recursive -X patience other-branch\n\n\nFrom the documentation:\n\nWith this option, merge-recursive spends a little extra time to avoid \nmismerges that sometimes occur due to unimportant matching lines \n(e.g., braces from distinct functions). Use this when the branches to \nbe merged have diverged wildly.\n\nComparison with the common ancestor\n\nIf you have a merge conflict and want to see what others had in mind when modifying their branch, it's sometimes easier to compare their branch directly with the common ancestor (instead of our branch). For that you can use merge-base:\n\ngit diff $(git merge-base <our-branch> <their-branch>) <their-branch>\n\n\nUsually, you only want to see the changes for a particular file:\n\ngit diff $(git merge-base <our-branch> <their-branch>) <their-branch> <file>\n\nShare\nImprove this answer\nFollow\nedited Aug 6 '20 at 8:31\nanswered Nov 30 '16 at 19:51\nConchylicultor\n2,5082\n2 gold badges\n23\n23 silver badges\n31\n31 bronze badges","comments":["In my case this didn't resolve merge conflicts well, since for some reason it kept duplicate lines of config in C# projects. Though it was more friendly than ENTIRE FILE IS DIFFERENT, which I had before"]},{"answer":"As of December 12th 2016, you can merge branches and resolve conflicts on github.com\n\nThus, if you don't want to use the command-line or any 3rd party tools that are offered here from older answers, go with GitHub's native tool.\n\nThis blog post explains in detail, but the basics are that upon 'merging' two branches via the UI, you will now see a 'resolve conflicts' option that will take you to an editor allowing you to deal with these merge conflicts.\n\nShare\nImprove this answer\nFollow\nedited Jan 9 '17 at 19:57\nanswered Jan 9 '17 at 19:45\nmaxwell\n1,99619\n19 silver badges\n33\n33 bronze badges","comments":["this is not asking about github thus I down voted what I view to be a very poor answer.","@mschuett is right, the question is \"how to resolve conflicts in git\", not \"how to resolve conflicts in github\". There is a difference and there is already far too many people that think git and github are the same thing, so anything that propagate that feeling is wrong."]},{"answer":"I always follow the below steps to avoid conflicts.\n\ngit checkout master (Come to the master branch)\ngit pull (Update your master to get the latest code)\ngit checkout -b mybranch (Check out a new a branch and start working on that branch so that your master always remains top of trunk.)\ngit add . and git commit and git push (on your local branch after your changes)\ngit checkout master (Come back to your master)\n\nNow you can do the same and maintain as many local branches you want and work simultaneous by just doing a git checkout to your branch whenever necessary.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 12 '15 at 4:25\nChetan\n1,0501\n1 gold badge\n8\n8 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"Merge conflicts could occur in different situations:\n\nWhen running git fetch and then git merge\nWhen running git fetch and then git rebase\nWhen running git pull (which is actually equal to one of the above-mentioned conditions)\nWhen running git stash pop\nWhen you're applying git patches (commits that are exported to files to be transferred, for example, by email)\n\nYou need to install a merge tool which is compatible with Git to resolve the conflicts. I personally use KDiff3, and I've found it nice and handy. You can download its Windows version here:\n\nhttps://sourceforge.net/projects/kdiff3/files/\n\nBTW, if you install Git Extensions there is an option in its setup wizard to install Kdiff3.\n\nThen setup the Git configuration to use KDiff3 as its mergetool:\n\n$ git config --global --add merge.tool kdiff3\n$ git config --global --add mergetool.kdiff3.path \"C:/Program Files/KDiff3/kdiff3.exe\"\n$ git config --global --add mergetool.kdiff3.trustExitCode false\n\n$ git config --global --add diff.guitool kdiff3\n$ git config --global --add difftool.kdiff3.path \"C:/Program Files/KDiff3/kdiff3.exe\"\n$ git config --global --add difftool.kdiff3.trustExitCode false\n\n\n(Remember to replace the path with the actual path of the KDiff3 EXE file.)\n\nThen every time you come across a merge conflict, you just need to run this command:\n\n$ git mergetool\n\n\nThen it opens Kdiff3, and first tries to resolve the merge conflicts automatically. Most of the conflicts would be resolved spontaneously and you need to fix the rest manually.\n\nHere's what Kdiff3 looks like:\n\nThen once you're done, save the file and it goes to the next file with a conflict and you do the same thing again until all the conflicts are resolved.\n\nTo check if everything is merged successfully, just run the mergetool command again. You should get this result:\n\n$ git mergetool\nNo files need merging\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 18 '16 at 5:29\nakazemis\n32.8k4\n4 gold badges\n28\n28 silver badges\n40\n40 bronze badges","comments":[]},{"answer":"This answer is to add an alternative for those Vim users like me that prefers to do everything within the editor.\n\nTL;DR\n\nTpope came up with this great plugin for Vim called fugitive. Once installed, you can run :Gstatus to check the files that have conflict and :Gdiff to open Git in a three-way merge.\n\nOnce in the three-way merge, fugitive will let you get the changes of any of the branches you are merging in the following fashion:\n\n:diffget //2, get changes from original (HEAD) branch:\n:diffget //3, get changes from merging branch:\n\nOnce you are finished merging the file, type :Gwrite in the merged buffer.\n\nVimcasts released a great video explaining these steps in detail.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:49\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 16 '17 at 6:01\nVicente Bolea\n1,16312\n12 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"GitLens for Visual Studio Code\n\nYou can try GitLens for Visual Studio Code. The key features are:\n\n3. Easily resolve conflicts\n\nI already like this feature:\n\n2. Current Line Blame.\n\n3. Gutter Blame\n\n4. Status Bar Blame\n\nAnd there are many features. You can check them here.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:56\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 5 '19 at 18:33\nIlyas karim\n3,5913\n3 gold badges\n30\n30 silver badges\n40\n40 bronze badges","comments":["One of the best tools I have ever used, and I'm still using it for all my projects!"]},{"answer":"git fetch <br>\ngit checkout **your branch**<br>\ngit rebase master<br>\n\n\nIn this step you will try to fix the conflict using your preferred IDE.\n\nYou can follow this link to check how to fix the conflict in the file.\n\ngit add<br>\ngit rebase --continue<br>\ngit commit --amend<br>\ngit push origin HEAD:refs/drafts/master  (push like a drafts)<br>\n\n\nNow everything is fine and you will find your commit in Gerrit.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 5 '17 at 13:25\nBaini.Marouane\n5391\n1 gold badge\n8\n8 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"I understood what a merge conflict was, but when I saw the output of git diff, it looked like nonsense to me at first:\n\ngit diff\n++<<<<<<< HEAD\n + display full last name boolean in star table\n++=======\n+ users viewer.id/star.id, and conversation uses user.id\n+\n++>>>>>>> feat/rspec-tests-for-cancancan\n\n\nBut here is what helped me:\n\nEverything between <<<<<<< and ======= is what was in one file, and\n\nEverything between ======= and >>>>>>> is what was in the other file\n\nSo literally all you have to do is open the file with the merge conflicts and remove those lines from either branch (or just make them the same), and the merge will immediately succeed. Problem solved!\n\nShare\nImprove this answer\nFollow\nedited Jul 16 at 8:51\nanswered Feb 9 at 11:24\nstevec\n18k7\n7 gold badges\n79\n79 silver badges\n124\n124 bronze badges","comments":[]},{"answer":"A safer way to resolve conflicts is to use git-mediate (the common solutions suggested here are quite error prone imho).\n\nSee this post for a quick intro on how to use it.\n\nShare\nImprove this answer\nFollow\nanswered Dec 29 '16 at 16:46\nyairchu\n21.4k7\n7 gold badges\n65\n65 silver badges\n105\n105 bronze badges","comments":[]},{"answer":"For those who are using Visual Studio (Visual Studio 2015 in my case)\n\nClose your project in Visual Studio. Especially in big projects, Visual Studio tends to freak out when merging using the UI.\n\nDo the merge in a command prompt.\n\ngit checkout target_branch\n\ngit merge source_branch\n\nThen open the project in Visual Studio and go to Team Explorer → Branch. Now there is a message that says Merge is pending and conflicting files are listed right below the message.\n\nClick the conflicting file and you will have the option to Merge, Compare, Take Source, and Take Target. The merge tool in Visual Studio is very easy to use.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:28\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 10 '17 at 20:29\nMiguel\n1,3451\n1 gold badge\n26\n26 silver badges\n28\n28 bronze badges","comments":["I'm using VS Code 2017 on a very large project and do not have a need to close the project. It handles it quite well :)"]},{"answer":"Try Visual Studio Code for editing if you aren't already.\n\nAfter you try merging (and land up in merge conflicts), Visual Studio Code automatically detects the merge conflicts.\n\nIt can help you very well by showing the changes made to the original one and if you should accept incoming or\n\ncurrent change (meaning original one before merging)'.\n\nIt helped me and it can work for you too!\n\nPS: It will work only if you've configured Git with with your code and Visual Studio Code.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:53\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 16 '18 at 6:26\nKailash Bhalaki\n2723\n3 silver badges\n5\n5 bronze badges","comments":[]},{"answer":"I am using Microsoft's Visual Studio Code for resolving conflicts. It's very simple to use. I keep my project open in the workspace. It detects and highlights conflicts. Moreover, it gives GUI options to select whatever change I want to keep from HEAD or incoming.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 21:57\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 2 '19 at 6:53\nAmmar Mujeeb\n1,03614\n14 silver badges\n21\n21 bronze badges","comments":[]}]},{"id":"215718","href":"https://stackoverflow.com/questions/215718/how-can-i-reset-or-revert-a-file-to-a-specific-revision","title":"How can I reset or revert a file to a specific revision?","description":"\n                \nI have made some changes to a file which has been committed a few times as part of a group of files, but now want to reset/revert the changes on it back to a previous version. \n\nI have done a git log along with a git diff to find the revision I need, but just have no idea how to get the file back to its former state in the past.\n    ","questionComments":["After revert, don't forget --cached when checking git diff. link","I found your question when I googled mine. But after I read the solution, I checked my log and found out, that I made thouse changes as a standalone commit, so I made git revert for that commit, and everything else stayed as I wanted it. Not a solution, just another way to do it sometimes.","I use this manual solution: $ git revert <commit> then unstash wanted changes then upload this wanted changes into a new commit."],"answers":[{"answer":"Assuming the hash of the commit you want is c5f567:\n\ngit checkout c5f567 -- file1/to/restore file2/to/restore\n\n\nThe git checkout man page gives more information.\n\nIf you want to revert to the commit before c5f567, append ~1 (where 1 is the number of commits you want to go back, it can be anything):\n\ngit checkout c5f567~1 -- file1/to/restore file2/to/restore\n\n\nAs a side note, I've always been uncomfortable with this command because it's used for both ordinary things (changing between branches) and unusual, destructive things (discarding changes in the working directory).\n\nThere is also a new git restore command that is specifically designed for restoring working copy files that have been modified. If your git is new enough you can use this command, but the documentation comes with a warning:\n\nTHIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE.\n\nShare\nImprove this answer\nFollow\nedited Apr 1 at 23:22\nanswered Oct 18 '08 at 23:39\nGreg Hewgill\n843k170\n170 gold badges\n1107\n1107 silver badges\n1243\n1243 bronze badges","comments":["@shadowhand: Is there a way to reverse that, so it's the version right after?","@aliteralmind: No, unfortunately the Git history shortcut notation only goes backwards in history.","If you're going to use a branch name for abcde (e.g. develop) you'll want git checkout develop -- file/to/restore (note the double dash)","@aliteralmind: Actually, yes, there's a way to do it: \"git log --reverse -1 --ancestry-path yourgitrev..master\" and then use the appropriate options to just get the git rev. --ancestry-path will \"draw a line\" between two commits and -1 will show you just one version, and --reverse will ensure the first entry emitted is the oldest one.","Personally I find HEAD^ easier to type than HEAD~1 :)"]},{"answer":"You can quickly review the changes made to a file using the diff command:\n\ngit diff <commit hash> <filename>\n\n\nThen to revert a specific file to that commit use the reset command:\n\ngit reset <commit hash> <filename>\n\n\nYou may need to use the --hard option if you have local modifications.\n\nA good workflow for managaging waypoints is to use tags to cleanly mark points in your timeline. I can't quite understand your last sentence but what you may want is diverge a branch from a previous point in time. To do this, use the handy checkout command:\n\ngit checkout <commit hash>\ngit checkout -b <new branch name>\n\n\nYou can then rebase that against your mainline when you are ready to merge those changes:\n\ngit checkout <my branch>\ngit rebase master\ngit checkout master\ngit merge <my branch>\n\nShare\nImprove this answer\nFollow\nanswered Dec 17 '08 at 6:59\nChris Lloyd\n11k7\n7 gold badges\n33\n33 silver badges\n31\n31 bronze badges","comments":["'git checkout <commit hash>' command has given me back my older version of the project exactly this for which I was searching Thanks Chris.","To revert the file git checkout <commit hash> <filename> worked better for me than git reset","I wanted an early version of a single file because I had overwritten 150 lines with a badly chosen copy/paste. git checkout <commit hash> <filename> worked for me. This should not be the accepted answer, IMHO. git reset did not.","cannot use git reset to reset single file, you will get an error fatal: Cannot do hard reset with paths","What slier said: you cannot git reset --hard <commit hash> <filename>. This will error with fatal: Cannot do hard reset with paths. What Motti Strom said: use git checkout <commit hash> <filename>"]},{"answer":"You can use any reference to a git commit, including the SHA-1 if that's most convenient. The point is that the command looks like this:\n\ngit checkout [commit-ref] -- [filename]\n\nShare\nImprove this answer\nFollow\nedited Apr 29 '14 at 12:22\nGeorge Stocker\n55.4k29\n29 gold badges\n169\n169 silver badges\n231\n231 bronze badges\nanswered Apr 7 '09 at 21:48\nfoxxtrot\n10.7k4\n4 gold badges\n25\n25 silver badges\n27\n27 bronze badges","comments":["What is the difference between this answer, which has --, and the accepted one which does not?","In git, a ' -- ' before the file list tells git that all the next arguments should be interpreted as filenames, not as branch-names or anything else. It's a helpful disambiguator sometimes.","The '--' is not only a git convention, but something you find in various places in on the *nix commandline. rm -- -f (remove a file named -f) seems to be the canonical example. More detail here","Just add to what @HawkeyeParker said, rm command uses getopt(3) to parse its arguments. getopt is the command to parse command arguments. gnu.org/software/libc/manual/html_node/Getopt.html","@Honey Yes, that's what I mean, and yeah, probably not common at all. I've seen that example in various places, maybe just to make it sortof memorable: rm -f is well-known to be scary/dangerous. But, the point is, in *nix a file name can start with a '-', and this will confuse various commandline interpreters which, when they see a '-', expect a command option to follow. It could be any file starting with '-'; e.g., \"-mySpecialFile\"."]},{"answer":"git checkout -- foo\n\n\nThat will reset foo to HEAD. You can also:\n\ngit checkout HEAD^ foo\n\n\nfor one revision back, etc.\n\nShare\nImprove this answer\nFollow\nedited Mar 18 '13 at 7:47\nanswered Aug 29 '08 at 20:56\nGreg Hewgill\n843k170\n170 gold badges\n1107\n1107 silver badges\n1243\n1243 bronze badges","comments":["I'd suggest using syntax git checkout -- foo to avoid any mistakes if foo is anything special (like a directory or a file called -f). With git, if you're unsure, always prefix all files and directories with the special argument --.","An additional note to Mikko's comment: -- is not a git command and not special to git. It is a bash built-in to signify the end of command options. You can use it with many other bash commands too.","@matthaeus it's also neither specific to bash nor a shell feature at all. It's a convention implemented in many different commands (and supported by getopt).","No, -- is not a builtin special word in bash. But it is a common convention supported by many commandline parsers and used by many CLIs, including git."]},{"answer":"And to revert to last committed version, which is most frequently needed, you can use this simpler command.\n\ngit checkout HEAD file/to/restore\n\nShare\nImprove this answer\nFollow\nanswered Jan 14 '12 at 6:15\nCDR\n7,68610\n10 gold badges\n44\n44 silver badges\n46\n46 bronze badges","comments":["what is the difference between this (git checkout HEAD file/to/restore) and git reset --hard file/to/restore ???","1) easier to remember more general way 2) no worries to press Enter before entering file name"]},{"answer":"I had the same issue just now and I found this answer easiest to understand (commit-ref is the SHA value of the change in the log you want to go back to):\n\ngit checkout [commit-ref] [filename]\n\n\nThis will put that old version in your working directory and from there you can commit it if you want.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:47\nCommunity♦\n11\n1 silver badge\nanswered May 27 '09 at 17:52\nbbrown\n6,2705\n5 gold badges\n35\n35 silver badges\n42\n42 bronze badges","comments":["best answer so far"]},{"answer":"If you know how many commits you need to go back, you can use:\n\ngit checkout master~5 image.png\n\n\nThis assumes that you're on the master branch, and the version you want is 5 commits back.\n\nShare\nImprove this answer\nFollow\nedited Jun 1 '12 at 7:06\nchim\n7,7353\n3 gold badges\n44\n44 silver badges\n58\n58 bronze badges\nanswered Apr 7 '09 at 14:03\nRon DeVera\n13.7k5\n5 gold badges\n39\n39 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"I think I've found it....from http://www-cs-students.stanford.edu/~blynn/gitmagic/ch02.html\n\nSometimes you just want to go back and forget about every change past a certain point because they're all wrong.\n\nStart with:\n\n$ git log\n\nwhich shows you a list of recent commits, and their SHA1 hashes.\n\nNext, type:\n\n$ git reset --hard SHA1_HASH\n\nto restore the state to a given commit and erase all newer commits from the record permanently.\n\nShare\nImprove this answer\nFollow\nedited Nov 20 '11 at 0:55\nZMorek\n6891\n1 gold badge\n8\n8 silver badges\n24\n24 bronze badges\nanswered Dec 17 '08 at 6:53\njdee\n10.5k10\n10 gold badges\n36\n36 silver badges\n35\n35 bronze badges","comments":["Git never removes anything. Your old commits are still there but unless there is a branch tip pointing at them they are not reachable anymore. git reflog will still show them until you clean your repository with git-gc.","@Bombe: Thank you for the information. I had checked out an old version of a file. After reading your comment, I was able to use \"gitref\" to lookup the partial SHA1 hash, and use \"checkout\" to get back to the most recent version. Other git users might find this information helpful.","possibly followed by a git push --force","If you have uncommitted changes, you will loose them if do a git reset --hard","@Bombe - \"Git never removes anything. Your old commits are still there but unless there is a branch tip pointing at them they are not reachable anymore.\" - but commits like this are pruned after some set time, so \"Git never removes anything\" is untrue."]},{"answer":"This worked for me:\n\ngit checkout <commit hash> file\n\n\nThen commit the change:\n\ngit commit -a\n\nShare\nImprove this answer\nFollow\nanswered Aug 25 '11 at 22:12\nv2k\n1,0539\n9 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"You have to be careful when you say \"rollback\". If you used to have one version of a file in commit $A, and then later made two changes in two separate commits $B and $C (so what you are seeing is the third iteration of the file), and if you say \"I want to roll back to the first one\", do you really mean it?\n\nIf you want to get rid of the changes both the second and the third iteration, it is very simple:\n\n$ git checkout $A file\n\n\nand then you commit the result. The command asks \"I want to check out the file from the state recorded by the commit $A\".\n\nOn the other hand, what you meant is to get rid of the change the second iteration (i.e. commit $B) brought in, while keeping what commit $C did to the file, you would want to revert $B\n\n$ git revert $B\n\n\nNote that whoever created commit $B may not have been very disciplined and may have committed totally unrelated change in the same commit, and this revert may touch files other than file you see offending changes, so you may want to check the result carefully after doing so.\n\nShare\nImprove this answer\nFollow\nanswered Jan 11 '09 at 8:13\ngitster","comments":["I did this, but then a \"git log file\" would say that I was on the original commit, HEAD. It seemed that \"git checkout\" was failing. However, a git status showed that the file was actually changed and and a \"git diff --staged file\" would show the actual changes. Also, a \"git status\" showed the file changed as well. So don't use \"git log\" here to track which files changed.","@FrederickOllinger - that behavior makes sense, because git log shows commits, and you haven't committed the change (the reversion). If you do git commit after that revert, then git log will show the change."]},{"answer":"As of git v2.23.0 there's a new git restore method which is supposed to assume part of what git checkout was responsible for (even the accepted answer mentions that git checkout is quite confusing). See highlights of changes on github blog.\n\nThe default behaviour of this command is to restore the state of a working tree with the content coming from the source parameter (which in your case will be a commit hash).\n\nSo based on Greg Hewgill's answer (assuming the commit hash is c5f567) the command would look like this:\n\ngit restore --source=c5f567 file1/to/restore file2/to/restore\n\n\nOr if you want to restore to the content of one commit before c5f567:\n\ngit restore --source=c5f567~1 file1/to/restore file2/to/restore\n\nShare\nImprove this answer\nFollow\nanswered Aug 27 '19 at 14:08\nmjarosie\n1,46216\n16 silver badges\n25\n25 bronze badges","comments":["I suppose it's a dead thread kind of thing, but this is the correct \"modern\" answer."]},{"answer":"Amusingly, git checkout foo will not work if the working copy is in a directory named foo; however, both git checkout HEAD foo and git checkout ./foo will:\n\n$ pwd\n/Users/aaron/Documents/work/foo\n$ git checkout foo\nD   foo\nAlready on \"foo\"\n$ git checkout ./foo\n$ git checkout HEAD foo\n\nShare\nImprove this answer\nFollow\nedited Jul 2 '19 at 13:56\nleiyc\n8817\n7 silver badges\n19\n19 bronze badges\nanswered Aug 29 '08 at 21:26\nAaron Maenpaa\n108k10\n10 gold badges\n91\n91 silver badges\n107\n107 bronze badges","comments":[]},{"answer":"Here's how rebase works:\n\ngit checkout <my branch>\ngit rebase master\ngit checkout master\ngit merge <my branch>\n\n\nAssume you have\n\n---o----o----o----o  master\n    \\---A----B       <my branch>\n\n\nThe first two commands ... commit git checkout git rebase master\n\n... check out the branch of changes you want to apply to the master branch. The rebase command takes the commits from <my branch> (that are not found in master) and reapplies them to the head of master. In other words, the parent of the first commit in <my branch> is no longer a previous commit in the master history, but the current head of master. The two commands are the same as:\n\ngit rebase master <my branch>\n\n\nIt might be easier to remember this command as both the \"base\" and \"modify\" branches are explicit.\n\n. The final history result is:\n\n---o----o----o----o   master\n                   \\----A'----B'  <my branch>\n\n\nThe final two commands ...\n\ngit checkout master\ngit merge <my branch>\n\n\n... do a fast-forward merge to apply all <my branch> changes onto master. Without this step, the rebase commit does not get added to master. The final result is:\n\n---o----o----o----o----A'----B'  master, <my branch>\n\n\nmaster and <my branch> both reference B'. Also, from this point it is safe to delete the <my branch> reference.\n\ngit branch -d <my branch>\n\nShare\nImprove this answer\nFollow\nedited Apr 29 '14 at 12:21\nGeorge Stocker\n55.4k29\n29 gold badges\n169\n169 silver badges\n231\n231 bronze badges\nanswered Feb 24 '09 at 9:43\ncmcginty\n103k38\n38 gold badges\n152\n152 silver badges\n156\n156 bronze badges","comments":[]},{"answer":"Git revert file to a specific commit\ngit checkout Last_Stable_commit_Number -- fileName\n\n\n2.Git revert file to a specific branch\n\ngit checkout branchName_Which_Has_stable_Commit fileName\n\nShare\nImprove this answer\nFollow\nedited Apr 28 '20 at 5:43\ncxxl\n4,1043\n3 gold badges\n25\n25 silver badges\n46\n46 bronze badges\nanswered Feb 6 '19 at 9:30\nireshika piyumalie\n1,63618\n18 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"First Reset Head For Target File\n\ngit reset HEAD path_to_file\n\n\nSecond Checkout That File\n\ngit checkout -- path_to_file\n\nShare\nImprove this answer\nFollow\nanswered Apr 4 '17 at 10:25\nGulshan Maurya\n9909\n9 silver badges\n21\n21 bronze badges","comments":["+1, though not sure of the intent of resetting HEAD. It may or may not be needed. In my situation i only wanted to revert one particular file to the version in repository (which keeping remaining local changes intact. Just running the second step above was sufficient for me","Yes I only need to run the 2nd command. Like --> shellhacks.com/git-revert-file-to-previous-commit"]},{"answer":"In the case that you want to revert a file to a previous commit (and the file you want to revert already committed) you can use\n\ngit checkout HEAD^1 path/to/file\n\n\nor\n\ngit checkout HEAD~1 path/to/file\n\n\nThen just stage and commit the \"new\" version.\n\nArmed with the knowledge that a commit can have two parents in the case of a merge, you should know that HEAD^1 is the first parent and HEAD~1 is the second parent.\n\nEither will work if there is only one parent in the tree.\n\nShare\nImprove this answer\nFollow\nanswered Jan 11 '14 at 0:29\nModernIncantations\n3712\n2 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"git-aliases, awk and shell-functions to the rescue!\n\ngit prevision <N> <filename>\n\n\nwhere <N> is the number of revisions of the file to rollback for file <filename>.\nFor example, to checkout the immediate previous revision of a single file x/y/z.c, run\n\ngit prevision -1 x/y/z.c\n\nHow git prevision works?\n\nAdd the following to your gitconfig\n\n[alias]\n        prevision = \"!f() { git checkout `git log --oneline $2 |  awk -v commit=\"$1\" 'FNR == -commit+1 {print $1}'` $2;} ;f\"\n\n\nThe command basically\n\nperforms a git log on the specified file and\npicks the appropriate commit-id in the history of the file and\nexecutes a git checkout to the commit-id for the specified file.\n\nEssentially, all that one would manually do in this situation,\nwrapped-up in one beautiful, efficient git-alias - git-prevision\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered May 1 '15 at 1:46\nTheCodeArtist\n19.4k3\n3 gold badges\n60\n60 silver badges\n124\n124 bronze badges","comments":[]},{"answer":"Many suggestions here, most along the lines of git checkout $revision -- $file. A couple of obscure alternatives:\n\ngit show $revision:$file > $file\n\n\nAnd also, I use this a lot just to see a particular version temporarily:\n\ngit show $revision:$file\n\n\nor\n\ngit show $revision:$file | vim -R -\n\n\n(OBS: $file needs to be prefixed with ./ if it is a relative path for git show $revision:$file to work)\n\nAnd the even more weird:\n\ngit archive $revision $file | tar -x0 > $file\n\nShare\nImprove this answer\nFollow\nedited Feb 17 '18 at 23:05\nanswered Jan 7 '16 at 22:19\nPeter V. Mørch\n9,8895\n5 gold badges\n49\n49 silver badges\n68\n68 bronze badges","comments":["This is a nice alternative if you're not sure which commit version you want and need to \"peek\" around without overwriting your working directory."]},{"answer":"I have to plug EasyGit here, which is a wrapper to make git more approachable to novices without confusing seasoned users. One of the things it does is give more meanings to git revert. In this case, you would simply say:\n\neg revert foo/bar foo/baz\n\nShare\nImprove this answer\nFollow\nedited Nov 10 '13 at 17:59\nanswered Oct 19 '08 at 0:16\nAristotle Pagaltzis\n103k21\n21 gold badges\n94\n94 silver badges\n96\n96 bronze badges","comments":["It should be eg revert --in REVISON -- FILENAME. The --in is important. For the Windows users out there: Open git bash. Execute echo %PATH. The first path should be in your user directory ending with bin. Create that path. Store eg there. Name it eg. Not eg.txt."]},{"answer":"Note, however, that git checkout ./foo and git checkout HEAD ./foo are not exactly the same thing; case in point:\n\n$ echo A > foo\n$ git add foo\n$ git commit -m 'A' foo\nCreated commit a1f085f: A\n1 files changed, 1 insertions(+), 0 deletions(-)\ncreate mode 100644 foo\n$ echo B >> foo\n$ git add foo\n$ echo C >> foo\n$ cat foo\nA\nB\nC\n$ git checkout ./foo\n$ cat foo\nA\nB\n$ git checkout HEAD ./foo\n$ cat foo\nA\n\n\n(The second add stages the file in the index, but it does not get committed.)\n\nGit checkout ./foo means revert path ./foo from the index; adding HEAD instructs Git to revert that path in the index to its HEAD revision before doing so.\n\nShare\nImprove this answer\nFollow\nedited Apr 29 '14 at 12:21\nGeorge Stocker\n55.4k29\n29 gold badges\n169\n169 silver badges\n231\n231 bronze badges\nanswered Aug 31 '08 at 11:54\nDamien Diederen\n2,4641\n1 gold badge\n17\n17 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"For me none of the reply seemed really clear and therefore I would like to add mine which seems super easy.\n\nI have a commit abc1 and after it I have done several (or one modification) to a file file.txt.\n\nNow say that I messed up something in the file file.txt and I want to go back to a previous commit abc1.\n\n1.git checkout file.txt : this will remove local changes, if you don't need them\n\n2.git checkout abc1 file.txt : this will bring your file to your wanted version\n\n3.git commit -m \"Restored file.txt to version abc1\" : this will commit your reversion.\n\ngit push : this will push everything on the remote repository\n\nBetween the step 2 and 3 of course you can do git status to understand what is going on. Usually you should see the file.txt already added and that is why there is no need of a git add.\n\nShare\nImprove this answer\nFollow\nanswered Mar 22 '17 at 21:33\ndesmond13\n2,1862\n2 gold badges\n21\n21 silver badges\n30\n30 bronze badges","comments":["OK so I guess steps 1. and 2. are mutually exclusive: if abc1 is your last commit there is no need for 2. and if there were other commits after abc1 you can directly do 2."]},{"answer":"Many answers here claims to use git reset ... <file> or git checkout ... <file> but by doing so, you will loose every modifications on <file> committed after the commit you want to revert.\n\nIf you want to revert changes from one commit on a single file only, just as git revert would do but only for one file (or say a subset of the commit files), I suggest to use both git diff and git apply like that (with <sha> = the hash of the commit you want to revert) :\n\ngit diff <sha>^ <sha> path/to/file.ext | git apply -R\n\n\nBasically, it will first generate a patch corresponding to the changes you want to revert, and then reverse-apply the patch to drop those changes.\n\nOf course, it shall not work if reverted lines had been modified by any commit between <sha1> and HEAD (conflict).\n\nShare\nImprove this answer\nFollow\nanswered Dec 7 '16 at 14:43\nVince\n2,8941\n1 gold badge\n25\n25 silver badges\n26\n26 bronze badges","comments":["That should be the approved answer. May I suggest a slightly simplified version: git show -p <sha> path/to/file.ext|git apply -R","you can use <sha>^! instead of <sha>^ <sha>"]},{"answer":"In order to go to a previous commit version of the file, get the commit number, say eb917a1 then\n\ngit checkout eb917a1 YourFileName\n\n\nIf you just need to go back to the last commited version\n\ngit reset HEAD YourFileName\ngit checkout YourFileName\n\n\nThis will simply take you to the last committed state of the file\n\nShare\nImprove this answer\nFollow\nanswered Feb 25 '14 at 14:01\nshah1988\n2,4561\n1 gold badge\n17\n17 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"This is a very simple step. Checkout file to the commit id we want, here one commit id before, and then just git commit amend and we are done.\n\n# git checkout <previous commit_id> <file_name>\n# git commit --amend\n\n\nThis is very handy. If we want to bring any file to any prior commit id at the top of commit, we can easily do.\n\nShare\nImprove this answer\nFollow\nanswered Jan 24 '19 at 17:21\nAbhishek Dwivedi\n4,5093\n3 gold badges\n12\n12 silver badges\n18\n18 bronze badges","comments":["Thanks, Abhishek. Based on your answer, I made this Shellscipt: gist.github.com/ivanleoncz/c20033e5f4b24304cbc39e0bac1d43e8 Feel free to improve :)."]},{"answer":"git checkout ref|commitHash -- filePath\n\ne.g.\n\ngit checkout HEAD~5 -- foo.bar\nor \ngit checkout 048ee28 -- foo.bar\n\nShare\nImprove this answer\nFollow\nanswered Sep 26 '13 at 17:04\nAmos Folarin\n1,84618\n18 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"Use git log to obtain the hash key for specific version and then use git checkout <hashkey>\n\nNote: Do not forget to type the hash before the last one. Last hash points your current position (HEAD) and changes nothing.\n\nShare\nImprove this answer\nFollow\nedited Nov 5 '12 at 4:25\nvicvicvic\n5,5453\n3 gold badges\n31\n31 silver badges\n50\n50 bronze badges\nanswered Dec 5 '11 at 20:09\nmustafakyr\n811\n1 silver badge\n1\n1 bronze badge","comments":[]},{"answer":"Obviously someone either needs to write an intelligible book on git, or git needs to be better explained in the documentation. Faced with this same problem I guessed that\n\ncd <working copy>\ngit revert master\n\n\nwould undo the last commit which is seemed to do.\n\nIan\n\nShare\nImprove this answer\nFollow\nedited Dec 16 '11 at 3:40\nChadwick\n12.1k7\n7 gold badges\n47\n47 silver badges\n65\n65 bronze badges\nanswered Dec 16 '11 at 3:03\nIan Davis\n711\n1 silver badge\n1\n1 bronze badge","comments":[]},{"answer":"You can do it in 4 steps:\n\nrevert the entire commit with the file you want to specifically revert - it will create a new commit on your branch\nsoft reset that commit - removes the commit and moves the changes to the working area\nhandpick the files to revert and commit them\ndrop all other files in your work area\n\nWhat you need to type in your terminal:\n\ngit revert <commit_hash>\ngit reset HEAD~1\ngit add <file_i_want_to_revert> && git commit -m 'reverting file'\ngit checkout .\n\ngood luck\n\nShare\nImprove this answer\nFollow\nanswered May 8 '18 at 10:26\nNir M.\n1291\n1 silver badge\n4\n4 bronze badges","comments":["doesn't that revert ALL changes?","@arcee123 Yes, but the subsequent reset undoes the revert of all changes. The problem is that git-revert only operates on the whole repo, so to compensate we have to undo everything else.","I recommend using: 1. git revert --no-commit <commit_hash> 2. git reset HEAD This saves an extra commit floating around and does all the changes only in your working directory.","@greg-hewgill 's answer is better and spot on. This one is lousy and should not be used.","This is exactly what is needed for a true revert of specific files. I needed to undo changes to a few files from an earlier commit that had already been pushed to the remote repository. I reverted, reset, and committed the result: git revert _oldcommit_ --no-commit git reset -- _unchanged1_ _unchanged2_ ... git commit -m \"branch without changes to specific files\" The new branch tip reflected all changes except the reverted files."]},{"answer":"git revert <hash>\n\n\nWill revert a given commit. It sounds like you think git revert only affects the most recent commit.\n\nThat doesn't solve your problem, if you want to revert a change in a specific file and that commit changed more than that file.\n\nShare\nImprove this answer\nFollow\nanswered Dec 17 '08 at 18:56\nOtto\n16.9k14\n14 gold badges\n54\n54 silver badges\n62\n62 bronze badges","comments":[]},{"answer":"if you commit a wrong file in your last commits follow the instruction :\n\nopen source tree, change to this commit\n\nchange the lines and find your commit that the wrong file sent as commit\n\nyou can see the list of your changes in that commit \nselect it and then click on ... buttons right-hand side ... click reverse file\nthen you can see it on file status tab at the bottom left-hand side then click unstage:\n\nopen your visual studio code and revert back by committing your removed files\nafter them all, you can see results in your last commit in the source tree\n\nShare\nImprove this answer\nFollow\nanswered Aug 23 '18 at 9:53\nsaber tabatabaee yazdi\n2,3903\n3 gold badges\n30\n30 silver badges\n45\n45 bronze badges","comments":[]}]},{"id":"46155","href":"https://stackoverflow.com/questions/46155/how-to-validate-an-email-address-in-javascript","title":"How to validate an email address in JavaScript","description":"\n                \nIs there a regular expression to verify an email address in JavaScript?\n    ","questionComments":["Warning!! The accepted answer if factually wrong as it does not conform to specifications. Read all answers for more details.","@DavidMårtensson It's mostly useless to validate emails according to the specification, the specification is much more liberal compared to what de facto is considered to be a well formed email. If your goal is for example to validate an email in a form to catch mistakes you can't conform to the specification, it's just too forgiving to catch actual user errors.","@Alex The reason I added this comment is that the suggested regex in the accepted answer will not allow existing live email addresses which is a bad start for a customer, and the really big problem is that even IF the address was accepted it still does not say if it works. The only way to reliably verify that a supplied email is a working valid email is to send a mail with a verification link. So, if your use case does not demand that you verify the email, just do a minimal test for @, otherwise use a verification email. Regex will only provide bad user experience.","@David Mårtensson I added a + on your thoughts. However I do think that a verification email-link thing also can be bad user experience. One that can make you lose a customer.","@mikael1000 Sure, but what is the purpose of a regex validation when you will not know if its a valid email anyway. If you do not want to intrude on the customer with a validation link just do the most simple validation <something> at <something> and leave it at that. It will ensure that the customer at least added something that might be an email, anything more it mostly a waste of code until you get to actually validating. You could possibly check if the domain exists with a dns lookup."],"answers":[{"answer":"Using regular expressions is probably the best way. You can see a bunch of tests here (taken from chromium)\n\nfunction validateEmail(email) {\n    const re = /^(([^<>()[\\]\\\\.,;:\\s@\"]+(\\.[^<>()[\\]\\\\.,;:\\s@\"]+)*)|(\".+\"))@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\])|(([a-zA-Z\\-0-9]+\\.)+[a-zA-Z]{2,}))$/;\n    return re.test(String(email).toLowerCase());\n}\n\n\nHere's the example of regular expresion that accepts unicode:\n\nconst re = /^(([^<>()[\\]\\.,;:\\s@\\\"]+(\\.[^<>()[\\]\\.,;:\\s@\\\"]+)*)|(\\\".+\\\"))@(([^<>()[\\]\\.,;:\\s@\\\"]+\\.)+[^<>()[\\]\\.,;:\\s@\\\"]{2,})$/i;\n\n\nBut keep in mind that one should not rely only upon JavaScript validation. JavaScript can easily be disabled. This should be validated on the server side as well.\n\nHere's an example of the above in action:\n\nfunction validateEmail(email) {\n  const re = /^(([^<>()[\\]\\\\.,;:\\s@\\\"]+(\\.[^<>()[\\]\\\\.,;:\\s@\\\"]+)*)|(\\\".+\\\"))@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\])|(([a-zA-Z\\-0-9]+\\.)+[a-zA-Z]{2,}))$/;\n  return re.test(email);\n}\n\nfunction validate() {\n  const $result = $(\"#result\");\n  const email = $(\"#email\").val();\n  $result.text(\"\");\n\n  if (validateEmail(email)) {\n    $result.text(email + \" is valid :)\");\n    $result.css(\"color\", \"green\");\n  } else {\n    $result.text(email + \" is not valid :(\");\n    $result.css(\"color\", \"red\");\n  }\n  return false;\n}\n\n$(\"#email\").on(\"input\", validate);\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n\n<label for=email>Enter an email address:</label>\n<input id=\"email\">\n<h2 id=\"result\"></h2>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jul 16 at 22:56\ncommunity wiki\n\n\n25 revs, 23 users 35%\nrnevius","comments":["This regex eliminates valid, in-use emails. Do not use. Google for \"RFC822\" or \"RFC2822\" to get a proper regex.","This doesn't even accept the examples in RFC 822. Some simple cases it doesn't match a\\@b@c.com, a(b)@c.com. See the RFC for more. Here's a regex that won't reject any valid addresses [^@]+@[^@]+\\.[^@]+ and protects against common errors.","You cannot validate email addresses, period. The only one who can validate an email address is the provider of the email address. For example, this answer says these email addresses: %2@gmail.com, \"%2\"@gmail.com, \"a..b\"@gmail.com, \"a_b\"@gmail.com, _@gmail.com, 1@gmail.com , 1_example@something.gmail.com are all valid, but Gmail will never allow any of these email addresses. You should do this by accepting the email address and sending an email message to that email address, with a code/link the user must visit to confirm validity.","@KevinFegan let's be realistic: you would not be using JavaScript to confirm whether an e-mail is authentic. I see this validation as perfectly reasonable when a user signs up. You probably do not want to bother sending verification e-mails to addresses that cannot possibly exist. Some might also have outbound e-mail limits, making it north worth it to send e-mails to email@localhost, i don't have an email or any other funny user inputs.","gautam+@Gmail.com - showing is valid which should not"]},{"answer":"I've slightly modified Jaymon's answer for people who want really simple validation in the form of:\n\nanystring@anystring.anystring\n\n\nThe regular expression:\n\n/\\S+@\\S+\\.\\S+/\n\n\nTo prevent matching multiple @ signs:\n\n/^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/\n\n\nExample JavaScript function:\n\nfunction validateEmail(email) \n    {\n        var re = /\\S+@\\S+\\.\\S+/;\n        return re.test(email);\n    }\n    \nconsole.log(validateEmail('anystring@anystring.anystring'));\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jul 29 at 15:50\ncommunity wiki\n\n\n9 revs, 9 users 37%\nC. Lee","comments":["You can implement something 20x as long that might cause problems for a few users and might not be valid in the future, or you can grab ImmortalFirefly's version to make sure they at least put in the effort to make it look real. Depending on your application it may be more likely to come across someone will get mad because you don't accept their unconventional email, rather than someone who causes problems by entering email addresses that don't really exist (which they can do anyways by entering a 100% valid RFC2822 email address but using an unregistered username or domain). Upvoted!","@ImmortalFirefly, the regex you provided will actually match name@again@example.com. Try pasting your line into a JavaScript console. I believe your intention was to match only the entire text, which would require the beginning of text '^' and end of text '$' operators. The one I'm using is /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/.test('name@again@example.com')","The second regexp does not require a top-level domain, i.e. it accepts user@domain. But AFAIK this is actually a valid e-mail address, although uncommon. The first regexp requires a TLD, so it doesn't cover these types of addresses."]},{"answer":"Just for completeness, here you have another RFC 2822 compliant regex\n\nThe official standard is known as RFC 2822. It describes the syntax that valid email addresses must adhere to. You can (but you shouldn't — read on) implement it with this regular expression:\n\n(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\n\n(...) We get a more practical implementation of RFC 2822 if we omit the syntax using double quotes and square brackets. It will still match 99.99% of all email addresses in actual use today.\n\n[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\n\nA further change you could make is to allow any two-letter country code top level domain, and only specific generic top level domains. This regex filters dummy email addresses like asdf@adsf.adsf. You will need to update it as new top-level domains are added.\n\n[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+(?:[A-Z]{2}|com|org|net|gov|mil|biz|info|mobi|name|aero|jobs|museum)\\b\n\nSo even when following official standards, there are still trade-offs to be made. Don't blindly copy regular expressions from online libraries or discussion forums. Always test them on your own data and with your own applications.\n\nEmphasis mine\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n7 revs, 5 users 83%\nvoyager","comments":["NB: \"In actual use today\" may have been valid when the code was written, back in 200x. The code will likely remain in use beyond that specific year. (If I had a dime for every \"meh, no one will ever use a 4+-letter TLD except those specific ones\" I had to fix, I could corner the world's copper and nickel market ;))"]},{"answer":"Wow, there are lots of complexity here. If all you want to do is just catch the most obvious syntax errors, I would do something like this:\n\n^\\S+@\\S+$\n\n\nIt usually catches the most obvious errors that the user makes and assures that the form is mostly right, which is what JavaScript validation is all about.\n\nShare\nImprove this answer\nFollow\nedited Nov 28 '18 at 10:31\ncommunity wiki\n\n\n4 revs, 4 users 62%\nJaymon","comments":["+1 as sending email and seeing what happens is the only real sure way to validate an email address , theres no need to do more than a simple regex match.","But it won't accept \"Mohit Atray\"@gmail.com because it contains space character. Maybe we should just use /^\\S.*@\\S+$/ regex."]},{"answer":"There's something you have to understand the second you decide to use a regular expression to validate emails: It's probably not a good idea. Once you have come to terms with that, there are many implementations out there that can get you halfway there, this article sums them up nicely.\n\nIn short, however, the only way to be absolutely, positively sure that what the user entered is in fact an email is to actually send an email and see what happens. Other than that it's all just guesses.\n\nShare\nImprove this answer\nFollow\nanswered May 2 '09 at 17:18\ncommunity wiki\n\n\nPaolo Bergantino","comments":["@kommradHomer -- a \"regex invalid\" address is almost always valid, because whatever regex you use to validate an email address is almost certainly wrong and will exclude valid email addresses. An email address is name_part@domain_part and practically anything, including an @, is valid in the name_part; The address foo@bar@machine.subdomain.example.museum is legal, although it must be escaped as foo\\@bar@machine..... Once the email reaches the domain e.g. 'example.com' that domain can route the mail \"locally\" so \"strange\" usernames and hostnames can exist."]},{"answer":"HTML5 itself has email validation. If your browser supports HTML5 then you can use the following code.\n\n<form><input type=\"email\" placeholder=\"me@example.com\" required>\n    <input type=\"submit\">\n</form>\n\n\njsFiddle link\n\nFrom the HTML5 spec:\n\nA valid e-mail address is a string that matches the email production of the following ABNF, the character set for which is Unicode.\n\nemail   = 1*( atext / \".\" ) \"@\" label *( \".\" label )\nlabel   = let-dig [ [ ldh-str ] let-dig ]  ; limited to a length of 63 characters by RFC 1034 section 3.5\natext   = < as defined in RFC 5322 section 3.2.3 >\nlet-dig = < as defined in RFC 1034 section 3.5 >\nldh-str = < as defined in RFC 1034 section 3.5 >\n\n\nThis requirement is a willful violation of RFC 5322, which defines a syntax for e-mail addresses that is simultaneously too strict (before the \"@\" character), too vague (after the \"@\" character), and too lax (allowing comments, whitespace characters, and quoted strings in manners unfamiliar to most users) to be of practical use here.\n\nThe following JavaScript- and Perl-compatible regular expression is an implementation of the above definition.\n\n/^[a-zA-Z0-9.!#$%&'*+\\/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$/\n\nShare\nImprove this answer\nFollow\nedited Dec 3 '20 at 21:01\ncommunity wiki\n\n\n7 revs, 5 users 38%\nAnoop","comments":["this is good, but the problem with this is that it must be inside a form tag and submitted by a submit input, which not everyone has the luxury of doing. Also, you can't really style the error message."]},{"answer":"I have found this to be the best solution:\n\n/^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/\n\n\nIt allows the following formats:\n\n1.  prettyandsimple@example.com\n2.  very.common@example.com\n3.  disposable.style.email.with+symbol@example.com\n4.  other.email-with-dash@example.com\n9.  #!$%&'*+-/=?^_`{}|~@example.org\n6.  \"()[]:,;@\\\\\\\"!#$%&'*+-/=?^_`{}| ~.a\"@example.org\n7.  \" \"@example.org (space between the quotes)\n8.  üñîçøðé@example.com (Unicode characters in local part)\n9.  üñîçøðé@üñîçøðé.com (Unicode characters in domain part)\n10. Pelé@example.com (Latin)\n11. δοκιμή@παράδειγμα.δοκιμή (Greek)\n12. 我買@屋企.香港 (Chinese)\n13. 甲斐@黒川.日本 (Japanese)\n14. чебурашка@ящик-с-апельсинами.рф (Cyrillic)\n\n\nIt's clearly versatile and allows the all-important international characters, while still enforcing the basic anything@anything.anything format. It will block spaces which are technically allowed by RFC, but they are so rare that I'm happy to do this.\n\nShare\nImprove this answer\nFollow\nanswered Sep 21 '15 at 1:52\ncommunity wiki\n\n\nAndrew","comments":[]},{"answer":"In modern browsers you can build on top of @Sushil's answer with pure JavaScript and the DOM:\n\nfunction validateEmail(value) {\n  var input = document.createElement('input');\n\n  input.type = 'email';\n  input.required = true;\n  input.value = value;\n\n  return typeof input.checkValidity === 'function' ? input.checkValidity() : /\\S+@\\S+\\.\\S+/.test(value);\n}\n\n\nI've put together an example in the fiddle http://jsfiddle.net/boldewyn/2b6d5/. Combined with feature detection and the bare-bones validation from Squirtle's Answer, it frees you from the regular expression massacre and does not bork on old browsers.\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '18 at 7:07\ncommunity wiki\n\n\n6 revs, 4 users 66%\nBoldewyn","comments":["This should be the accepted answer by a long shot. Let browser vendors with on staff regex gurus maintain massively complicated regexes for email addresses. Your average frontend dev building a form for collecting email does not often have time to master verbose regex. Yes you have to rely on the regex the vendor provides, but if you need something more complex, do it on the server and or send an actual email and check the response"]},{"answer":"This is the correct RFC822 version.\n\nfunction checkEmail(emailAddress) {\n  var sQtext = '[^\\\\x0d\\\\x22\\\\x5c\\\\x80-\\\\xff]';\n  var sDtext = '[^\\\\x0d\\\\x5b-\\\\x5d\\\\x80-\\\\xff]';\n  var sAtom = '[^\\\\x00-\\\\x20\\\\x22\\\\x28\\\\x29\\\\x2c\\\\x2e\\\\x3a-\\\\x3c\\\\x3e\\\\x40\\\\x5b-\\\\x5d\\\\x7f-\\\\xff]+';\n  var sQuotedPair = '\\\\x5c[\\\\x00-\\\\x7f]';\n  var sDomainLiteral = '\\\\x5b(' + sDtext + '|' + sQuotedPair + ')*\\\\x5d';\n  var sQuotedString = '\\\\x22(' + sQtext + '|' + sQuotedPair + ')*\\\\x22';\n  var sDomain_ref = sAtom;\n  var sSubDomain = '(' + sDomain_ref + '|' + sDomainLiteral + ')';\n  var sWord = '(' + sAtom + '|' + sQuotedString + ')';\n  var sDomain = sSubDomain + '(\\\\x2e' + sSubDomain + ')*';\n  var sLocalPart = sWord + '(\\\\x2e' + sWord + ')*';\n  var sAddrSpec = sLocalPart + '\\\\x40' + sDomain; // complete RFC822 email address spec\n  var sValidEmail = '^' + sAddrSpec + '$'; // as whole string\n\n  var reValidEmail = new RegExp(sValidEmail);\n\n  return reValidEmail.test(emailAddress);\n}\n\nShare\nImprove this answer\nFollow\nedited Feb 25 '15 at 15:18\ncommunity wiki\n\n\n2 revs, 2 users 91%\nbvl","comments":["IDN addresses are not validated (info@üpöü.com)","'a@a' returns valid: jsfiddle.net/pmiranda/guoyh4dv"]},{"answer":"JavaScript can match a regular expression:\n\nemailAddress.match( / some_regex /);\n\n\nHere's an RFC22 regular expression for emails:\n\n^((?>[a-zA-Z\\d!#$%&'*+\\-/=?^_`{|}~]+\\x20*|\"((?=[\\x01-\\x7f])[^\"\\\\]|\\\\[\\x01-\\x7f])*\n\"\\x20*)*(?<angle><))?((?!\\.)(?>\\.?[a-zA-Z\\d!#$%&'*+\\-/=?^_`{|}~]+)+|\"((?=[\\x01-\\x\n7f])[^\"\\\\]|\\\\[\\x01-\\x7f])*\")@(((?!-)[a-zA-Z\\d\\-]+(?<!-)\\.)+[a-zA-Z]{2,}|\\[(((?(?<\n!\\[)\\.)(25[0-5]|2[0-4]\\d|[01]?\\d?\\d)){4}|[a-zA-Z\\d\\-]*[a-zA-Z\\d]:((?=[\\x01-\\x7f])\n[^\\\\\\[\\]]|\\\\[\\x01-\\x7f])+)\\])(?(angle)>)$\n\nShare\nImprove this answer\nFollow\nedited Aug 24 '13 at 20:45\ncommunity wiki\n\n\nBen Scheirman","comments":["@Kato: It uses some incompatible extensions, including (?> to stop backtracking and (?<angle><)…(?(angle)>) to avoid providing a lengthy |.","The match method returns an array, the test method, which returns a boolean, would be better for this situation."]},{"answer":"Correct validation of email address in compliance with the RFCs is not something that can be achieved with a one-liner regular expression. An article with the best solution I've found in PHP is What is a valid email address?. Obviously, it has been ported to Java. I think the function is too complex to be ported and used in JavaScript. JavaScript/node.js port: https://www.npmjs.com/package/email-addresses.\n\nA good practice is to validate your data on the client, but double-check the validation on the server. With this in mind, you can simply check whether a string looks like a valid email address on the client and perform the strict check on the server.\n\nHere's the JavaScript function I use to check if a string looks like a valid mail address:\n\nfunction looksLikeMail(str) {\n    var lastAtPos = str.lastIndexOf('@');\n    var lastDotPos = str.lastIndexOf('.');\n    return (lastAtPos < lastDotPos && lastAtPos > 0 && str.indexOf('@@') == -1 && lastDotPos > 2 && (str.length - lastDotPos) > 2);\n}\n\n\nExplanation:\n\nlastAtPos < lastDotPos: Last @ should be before last . since @ cannot be part of server name (as far as I know).\n\nlastAtPos > 0: There should be something (the email username) before the last @.\n\nstr.indexOf('@@') == -1: There should be no @@ in the address. Even if @ appears as the last character in email username, it has to be quoted so \" would be between that @ and the last @ in the address.\n\nlastDotPos > 2: There should be at least three characters before the last dot, for example a@b.com.\n\n(str.length - lastDotPos) > 2: There should be enough characters after the last dot to form a two-character domain. I'm not sure if the brackets are necessary.\n\nShare\nImprove this answer\nFollow\nedited Oct 31 '18 at 9:15\ncommunity wiki\n\n\n5 revs, 4 users 82%\nMiloš Rašić","comments":[]},{"answer":"All email addresses contain an 'at' (i.e. @) symbol. Test that necessary condition:\n\nemail.indexOf(\"@\") > 0\n\n\nDon't bother with anything more complicated. Even if you could perfectly determine whether an email is RFC-syntactically valid, that wouldn't tell you whether it belongs to the person who supplied it. That's what really matters.\n\nTo test that, send a validation message.\n\nShare\nImprove this answer\nFollow\nedited Sep 20 '20 at 22:06\ncommunity wiki\n\n\n6 revs, 4 users 70%\nColonel Panic","comments":["what if there will be more than one '@' symbol? other restricted symbols? This validation cannot be trusted...","is a@b valid email ?","Its better than most, yes you could have more than one @ with this, but that could also be a valid email like \"@\"@mydomain.jskd or elldffs(this is @ comment)@mydomain.kjfdij. Both are syntactically valid emails"]},{"answer":"This was stolen from http://codesnippets.joyent.com/posts/show/1917\n\nemail = $('email');\nfilter = /^([a-zA-Z0-9_\\.\\-])+\\@(([a-zA-Z0-9\\-])+\\.)+([a-zA-Z0-9]{2,4})+$/;\nif (filter.test(email.value)) {\n  // Yay! valid\n  return true;\n}\nelse\n  {return false;}\n\nShare\nImprove this answer\nFollow\nanswered May 2 '09 at 17:19\ncommunity wiki\n\n\nAdam McKee","comments":[]},{"answer":"Do this:\n\n^([a-zA-Z0-9!#$%&'*+\\/=?^_`{|}~-]+(?:\\.[a-zA-Z0-9!#$%&'*+\\/=?^_`{|}~-]+)*@(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]*[a-zA-Z0-9])?\\.)+[a-zA-Z0-9](?:[a-zA-Z0-9-]*[a-zA-Z0-9])?)$\n\n\nIt's based on RFC 2822\n\nTest it at https://regex101.com/r/857lzc/1\n\nOften when storing email addresses in the database I make them lowercase and, in practice, regexs can usually be marked case insensitive. In those cases this is slightly shorter:\n\n[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\n\n\nHere's an example of it being used in JavaScript (with the case insensitive flag i at the end).\n\nvar emailCheck=/^[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?$/i;\nconsole.log( emailCheck.test('some.body@domain.co.uk') );\n\n\nNote:\nTechnically some emails can include quotes in the section before the @ symbol with escape characters inside the quotes (so your email user can be obnoxious and contain stuff like @ and \"...\" as long as it's written in quotes). NOBODY DOES THIS EVER! It's obsolete. But, it IS included in the true RFC 2822 standard and omitted here.\n\nNote 2: The beginning of an email (before the @ sign) can be case sensitive (via the spec). However, anyone with a case-sensitive email is probably used to having issues, and, in practice, case insensitive is a safe assumption. More info: Are email addresses case sensitive?\n\nMore info: http://www.regular-expressions.info/email.html\n\nShare\nImprove this answer\nFollow\nedited Jun 11 at 8:42\ncommunity wiki\n\n\n10 revs, 4 users 71%\nRyan Taylor","comments":["gautam+@Gmail.com - showing is valid which should not"]},{"answer":"I'm really looking forward to solve this problem. So I modified email validation regular expression above\n\nOriginal\n/^(([^<>()\\[\\]\\\\.,;:\\s@\"]+(\\.[^<>()\\[\\]\\\\.,;:\\s@\"]+)*)|(\".+\"))@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}])|(([a-zA-Z\\-0-9]+\\.)+[a-zA-Z]{2,}))$/\n\nModified\n/^(([^<>()\\[\\]\\.,;:\\s@\\\"]+(\\.[^<>()\\[\\]\\.,;:\\s@\\\"]+)*)|(\\\".+\\\"))@(([^<>()\\.,;\\s@\\\"]+\\.{0,1})+[^<>()\\.,;:\\s@\\\"]{2,})$/\n\nto pass the examples in Wikipedia Email Address.\n\nAnd you can see the result in here.\n\nShare\nImprove this answer\nFollow\nedited Nov 13 '16 at 10:21\ncommunity wiki\n\n\n2 revs, 2 users 97%\nKeith Lee","comments":[]},{"answer":"Simply check out if the entered email address is valid or not using HTML.\n\n<input type=\"email\"/>\n\n\nThere isn't any need to write a function for validation.\n\nShare\nImprove this answer\nFollow\nedited Mar 14 '14 at 16:30\ncommunity wiki\n\n\n3 revs, 3 users 33%\nLearner","comments":[]},{"answer":"You should not use regular expressions to validate an input string to check if it's an email. It's too complicated and would not cover all the cases.\n\nNow since you can only cover 90% of the cases, write something like:\n\nfunction isPossiblyValidEmail(txt) {\n   return txt.length > 5 && txt.indexOf('@')>0;\n}\n\n\nYou can refine it. For instance, 'aaa@' is valid. But overall you get the gist. And don't get carried away... A simple 90% solution is better than 100% solution that does not work.\n\nThe world needs simpler code...\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '15 at 17:24\ncommunity wiki\n\n\n5 revs, 2 users 79%\nZo72","comments":["This allows the entry of so many invalid email addresses it is useless advice."]},{"answer":"It's hard to get an email validator 100% correct. The only real way to get it correct would be to send a test email to the account. That said, there are a few basic checks that can help make sure that you're getting something reasonable.\n\nSome things to improve:\n\nInstead of new RegExp, just try writing the regexp out like this:\n\nif (reg.test(/@/))\n\n\nSecond, check to make sure that a period comes after the @ sign, and make sure that there are characters between the @s and periods.\n\nShare\nImprove this answer\nFollow\nedited Apr 15 '18 at 10:15\ncommunity wiki\n\n\n2 revs, 2 users 84%\njacobangel","comments":[]},{"answer":"This is how node-validator does it:\n\n/^(?:[\\w\\!\\#\\$\\%\\&\\'\\*\\+\\-\\/\\=\\?\\^\\`\\{\\|\\}\\~]+\\.)*[\\w\\!\\#\\$\\%\\&\\'\\*\\+\\-\\/\\=\\?\\^\\`\\{\\|\\}\\~]+@(?:(?:(?:[a-zA-Z0-9](?:[a-zA-Z0-9\\-](?!\\.)){0,61}[a-zA-Z0-9]?\\.)+[a-zA-Z0-9](?:[a-zA-Z0-9\\-](?!$)){0,61}[a-zA-Z0-9]?)|(?:\\[(?:(?:[01]?\\d{1,2}|2[0-4]\\d|25[0-5])\\.){3}(?:[01]?\\d{1,2}|2[0-4]\\d|25[0-5])\\]))$/\n\nShare\nImprove this answer\nFollow\nedited Apr 15 '18 at 10:22\ncommunity wiki\n\n\n4 revs, 3 users 85%\npera","comments":[]},{"answer":"A solution that does not check the existence of the TLD is incomplete.\n\nAlmost all answers to this questions suggest using Regex to validate emails addresses. I think Regex is only good for a rudimentary validation. It seems that the checking validation of email addresses is actually two separate problems:\n\n1- Validation of email format: Making sure if the email complies with the format and pattern of emails in RFC 5322 and if the TLD actually exists. A list of all valid TLDs can be found here.\n\nFor example, although the address example@example.ccc will pass the regex, it is not a valid email, because ccc is not a top-level domain by IANA.\n\n2- Making sure the email actually exists: For doing this, the only option is to send the users an email.\n\nShare\nImprove this answer\nFollow\nedited Jul 2 '18 at 1:47\ncommunity wiki\n\n\n2 revs\nbman","comments":[]},{"answer":"Use this code inside your validator function:\n\nvar emailID = document.forms[\"formName\"][\"form element id\"].value;\natpos = emailID.indexOf(\"@\");\ndotpos = emailID.lastIndexOf(\".\");\nif (atpos < 1 || ( dotpos - atpos < 2 ))\n{\n    alert(\"Please enter correct email ID\")\n    return false;\n}\n\n\nElse you can use jQuery. Inside rules define:\n\neMailId: {\n    required: true,\n    email: true\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 15 '18 at 10:23\ncommunity wiki\n\n\n3 revs, 3 users 60%\nOrchid","comments":[]},{"answer":"Regex update 2018! try this\n\nlet val = 'email@domain.com';\nif(/^[a-z0-9][a-z0-9-_\\.]+@([a-z]|[a-z0-9]?[a-z0-9-]+[a-z0-9])\\.[a-z0-9]{2,10}(?:\\.[a-z]{2,10})?$/.test(val)) {\n   console.log('passed');\n}\n\n\ntypscript version complete\n\n//\nexport const emailValid = (val:string):boolean => /^[a-z0-9][a-z0-9-_\\.]+@([a-z]|[a-z0-9]?[a-z0-9-]+[a-z0-9])\\.[a-z0-9]{2,10}(?:\\.[a-z]{2,10})?$/.test(val);\n\n\nmore info https://git.io/vhEfc\n\nShare\nImprove this answer\nFollow\nedited Aug 7 '18 at 14:08\ncommunity wiki\n\n\n5 revs, 3 users 78%\nJuan Pablo","comments":[]},{"answer":"In contrast to squirtle, here is a complex solution, but it does a mighty fine job of validating emails properly:\n\nfunction isEmail(email) { \n    return /^((([a-z]|\\d|[!#\\$%&'\\*\\+\\-\\/=\\?\\^_`{\\|}~]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])+(\\.([a-z]|\\d|[!#\\$%&'\\*\\+\\-\\/=\\?\\^_`{\\|}~]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])+)*)|((\\x22)((((\\x20|\\x09)*(\\x0d\\x0a))?(\\x20|\\x09)+)?(([\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f]|\\x21|[\\x23-\\x5b]|[\\x5d-\\x7e]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])|(\\\\([\\x01-\\x09\\x0b\\x0c\\x0d-\\x7f]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF]))))*(((\\x20|\\x09)*(\\x0d\\x0a))?(\\x20|\\x09)+)?(\\x22)))@((([a-z]|\\d|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])|(([a-z]|\\d|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])([a-z]|\\d|-|\\.|_|~|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])*([a-z]|\\d|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])))\\.)+(([a-z]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])|(([a-z]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])([a-z]|\\d|-|\\.|_|~|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])*([a-z]|[\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF])))$/i.test(email);\n} \n\n\nUse like so:\n\n\n\nif (isEmail('youremail@yourdomain.com')){ console.log('This is email is valid'); }\n\nShare\nImprove this answer\nFollow\nedited Jun 1 '16 at 5:12\ncommunity wiki\n\n\n4 revs, 4 users 56%\nsteve","comments":[]},{"answer":"Regex for validating email address\n\n[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])+\n\nShare\nImprove this answer\nFollow\nedited Jul 5 '19 at 11:09\ncommunity wiki\n\n\n7 revs, 5 users 59%\nPrabhat Kasera","comments":[]},{"answer":"Here is a very good discussion about using regular expressions to validate email addresses; \"Comparing E-mail Address Validating Regular Expressions\"\n\nHere is the current top expression, that is JavaScript compatible, for reference purposes:\n\n/^[-a-z0-9~!$%^&*_=+}{\\'?]+(\\.[-a-z0-9~!$%^&*_=+}{\\'?]+)*@([a-z0-9_][-a-z0-9_]*(\\.[-a-z0-9_]+)*\\.(aero|arpa|biz|com|coop|edu|gov|info|int|mil|museum|name|net|org|pro|travel|mobi|[a-z][a-z])|([0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}))(:[0-9]{1,5})?$/i\n\nShare\nImprove this answer\nFollow\nanswered May 28 '10 at 22:05\ncommunity wiki\n\n\nEric Schoonover","comments":[]},{"answer":"Apparently, that's it:\n\n/^([\\w\\!\\#$\\%\\&\\'\\*\\+\\-\\/\\=\\?\\^\\`{\\|\\}\\~]+\\.)*[\\w\\!\\#$\\%\\&\\'\\*\\+\\-\\/\\=\\?\\^\\`{\\|\\}\\~]+@((((([a-z0-9]{1}[a-z0-9\\-]{0,62}[a-z0-9]{1})|[a-z])\\.)+[a-z]{2,6})|(\\d{1,3}\\.){3}\\d{1,3}(\\:\\d{1,5})?)$/i\n\n\nTaken from http://fightingforalostcause.net/misc/2006/compare-email-regex.php on Oct 1 '10.\n\nBut, of course, that's ignoring internationalization.\n\nShare\nImprove this answer\nFollow\nanswered Oct 1 '10 at 9:37\ncommunity wiki\n\n\nFélix Saparelli","comments":[]},{"answer":"My knowledge of regular expressions is not that good. That's why I check the general syntax with a simple regular expression first and check more specific options with other functions afterwards. This may not be not the best technical solution, but this way I'm way more flexible and faster.\n\nThe most common errors I've come across are spaces (especially at the beginning and end) and occasionally a double dot.\n\nfunction check_email(val){\n    if(!val.match(/\\S+@\\S+\\.\\S+/)){ // Jaymon's / Squirtle's solution\n        // Do something\n        return false;\n    }\n    if( val.indexOf(' ')!=-1 || val.indexOf('..')!=-1){\n        // Do something\n        return false;\n    }\n    return true;\n}\n\ncheck_email('check@thiscom'); // Returns false\ncheck_email('check@this..com'); // Returns false\ncheck_email(' check@this.com'); // Returns false\ncheck_email('check@this.com'); // Returns true\n\nShare\nImprove this answer\nFollow\nedited Mar 14 '14 at 16:29\ncommunity wiki\n\n\n3 revs, 2 users 78%\nLinkmichiel","comments":[]},{"answer":"Wikipedia standard mail syntax :\n\nhttps://en.wikipedia.org/wiki/Email_address#Examples https://fr.wikipedia.org/wiki/Adresse_%C3%A9lectronique#Syntaxe_exacte\n\nfunction validMail(mail)\n{\n    return /^(([^<>()\\[\\]\\.,;:\\s@\\\"]+(\\.[^<>()\\[\\]\\.,;:\\s@\\\"]+)*)|(\\\".+\\\"))@(([^<>()\\.,;\\s@\\\"]+\\.{0,1})+([^<>()\\.,;:\\s@\\\"]{2,}|[\\d\\.]+))$/.test(mail);\n}\n\n// VALID MAILS\n\nvalidMail('Abc@example.com') // Return true\nvalidMail('Abc@example.com.') // Return true\nvalidMail('Abc@10.42.0.1') // Return true\nvalidMail('user@localserver') // Return true\nvalidMail('Abc.123@example.com') // Return true\nvalidMail('user+mailbox/department=shipping@example.com') // Return true\nvalidMail('\"very.(),:;<>[]\\\".VERY.\\\"very@\\\\ \\\"very\\\".unusual\"@strange.example.com') // Return true\nvalidMail('!#$%&\\'*+-/=?^_`.{|}~@example.com') // Return true\nvalidMail('\"()<>[]:,;@\\\\\\\"!#$%&\\'-/=?^_`{}| ~.a\"@example.org') // Return true\nvalidMail('\"Abc@def\"@example.com') // Return true\nvalidMail('\"Fred Bloggs\"@example.com') // Return true\nvalidMail('\"Joe.\\\\Blow\"@example.com') // Return true\nvalidMail('Loïc.Accentué@voilà.fr') // Return true\nvalidMail('\" \"@example.org') // Return true\nvalidMail('user@[IPv6:2001:DB8::1]') // Return true\n\n// INVALID MAILS\n\nvalidMail('Abc.example.com') // Return false\nvalidMail('A@b@c@example.com') // Return false\nvalidMail('a\"b(c)d,e:f;g<h>i[j\\k]l@example.com') // Return false\nvalidMail('just\"not\"right@example.com') // Return false\nvalidMail('this is\"not\\allowed@example.com') // Return false\nvalidMail('this\\ still\\\"not\\\\allowed@example.com') // Return false\nvalidMail('john..doe@example.com') // Return false\nvalidMail('john.doe@example..com') // Return false\n\n\nShow this test : https://regex101.com/r/LHJ9gU/1\n\nShare\nImprove this answer\nFollow\nanswered Jun 21 '17 at 9:10\ncommunity wiki\n\n\nLiberateur","comments":[]},{"answer":"I was looking for a Regex in JS that passes all Email Address test cases:\n\nemail@example.com Valid email\n\nfirstname.lastname@example.com Email contains dot in the address field\n\nemail@subdomain.example.com Email contains dot with subdomain\n\nfirstname+lastname@example.com Plus sign is considered valid character\n\nemail@192.0.2.123 Domain is valid IP address\n\nemail@[192.0.2.123] Square bracket around IP address is considered valid\n\n“email”@example.com Quotes around email is considered valid\n\n1234567890@example.com Digits in address are valid\n\nemail@domain-one.example Dash in domain name is valid\n\n_______@example.com Underscore in the address field is valid\n\nemail@example.name .name is valid Top Level Domain name\n\nemail@example.co.jp Dot in Top Level Domain name also considered valid (using co.jp as example here)\n\nfirstname-lastname@example.com Dash in address field is valid\n\nHere we go :\n\nhttp://regexr.com/3f07j\n\nOR regex:\n\nRegex = /(([^<>()\\[\\]\\\\.,;:\\s@\"]+(\\.[^<>()\\[\\]\\\\.,;:\\s@\"]+)*)|(\".+\"))@[*[a-zA-Z0-9-]+.[a-zA-Z0-9-.]+]*/\n\nShare\nImprove this answer\nFollow\nedited Aug 2 '18 at 23:15\ncommunity wiki\n\n\n4 revs, 3 users 82%\nNegin","comments":[]},{"answer":"var testresults\n\nfunction checkemail() {\n  var str = document.validation.emailcheck.value\n  var filter = /^([\\w-]+(?:\\.[\\w-]+)*)@((?:[\\w-]+\\.)*\\w[\\w-]{0,66})\\.([a-z]{2,6}(?:\\.[a-z]{2})?)$/i\n  if (filter.test(str))\n    testresults = true\n  else {\n    alert(\"Please input a valid email address!\")\n    testresults = false\n  }\n  return (testresults)\n}\n\nfunction checkbae() {\n  if (document.layers || document.getElementById || document.all)\n    return checkemail()\n  else\n    return true\n}\n<form name=\"validation\" onSubmit=\"return checkbae()\">\n  Please input a valid email address:<br />\n\n  <input type=\"text\" size=18 name=\"emailcheck\">\n  <input type=\"submit\" value=\"Submit\">\n</form>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Aug 11 at 11:55\ncommunity wiki\n\n\n3 revs, 3 users 52%\nTugrul","comments":[]}]},{"id":"38549","href":"https://stackoverflow.com/questions/38549/what-is-the-difference-between-inner-join-and-outer-join","title":"What is the difference between “INNER JOIN” and “OUTER JOIN”?","description":"\n                \nAlso how do LEFT JOIN, RIGHT JOIN and FULL JOIN fit in?\n    ","questionComments":["Of the answers & comments & their references below only one actually explains how Venn diagrams represent the operators: The circle intersection area represents the set of rows in A JOIN B. The area unique to each circle represents the set of rows you get by taking its table's rows that don't participate in A JOIN B and adding the columns unique to the other table all set to NULL. (And most give a vague bogus correspondence of the circles to A and B.)","@DanteTheSmith No, that suffers from the same problems as the diagrams here. See my comment above re the question & below re that very blog post: \"Jeff repudiates his blog a few pages down in the comments\". Venn diagrams show elements in sets. Just try to identify exactly what the sets are and what the elements are in these diagrams. The sets aren't the tables and the elements aren't their rows. Also any two tables can be joined, so PKs & FKs are irrelvant. All bogus. You are doing just what thousands of others have done--got a vague impression you (wrongly) assume makes sense.","My preceding comment is about a confused repudiated Jeff Atwood blog post.","My 1st comment's link is external, but i.stack.imgur.com has permanent copies of its illustrations of output (not input) for inner, left & full joins (in green)."],"answers":[{"answer":"Assuming you're joining on columns with no duplicates, which is a very common case:\n\nAn inner join of A and B gives the result of A intersect B, i.e. the inner part of a Venn diagram intersection.\n\nAn outer join of A and B gives the results of A union B, i.e. the outer parts of a Venn diagram union.\n\nExamples\n\nSuppose you have two tables, with a single column each, and data as follows:\n\nA    B\n-    -\n1    3\n2    4\n3    5\n4    6\n\n\nNote that (1,2) are unique to A, (3,4) are common, and (5,6) are unique to B.\n\nInner join\n\nAn inner join using either of the equivalent queries gives the intersection of the two tables, i.e. the two rows they have in common.\n\nselect * from a INNER JOIN b on a.a = b.b;\nselect a.*, b.*  from a,b where a.a = b.b;\n\na | b\n--+--\n3 | 3\n4 | 4\n\n\nLeft outer join\n\nA left outer join will give all rows in A, plus any common rows in B.\n\nselect * from a LEFT OUTER JOIN b on a.a = b.b;\nselect a.*, b.*  from a,b where a.a = b.b(+);\n\na |  b\n--+-----\n1 | null\n2 | null\n3 |    3\n4 |    4\n\n\nRight outer join\n\nA right outer join will give all rows in B, plus any common rows in A.\n\nselect * from a RIGHT OUTER JOIN b on a.a = b.b;\nselect a.*, b.*  from a,b where a.a(+) = b.b;\n\na    |  b\n-----+----\n3    |  3\n4    |  4\nnull |  5\nnull |  6\n\n\nFull outer join\n\nA full outer join will give you the union of A and B, i.e. all the rows in A and all the rows in B. If something in A doesn't have a corresponding datum in B, then the B portion is null, and vice versa.\n\nselect * from a FULL OUTER JOIN b on a.a = b.b;\n\n a   |  b\n-----+-----\n   1 | null\n   2 | null\n   3 |    3\n   4 |    4\nnull |    6\nnull |    5\n\nShare\nImprove this answer\nFollow\nedited Sep 28 '17 at 19:52\nDarryl Hein\n136k88\n88 gold badges\n206\n206 silver badges\n257\n257 bronze badges\nanswered Sep 1 '08 at 22:59\nMark Harrison\n272k116\n116 gold badges\n310\n310 silver badges\n436\n436 bronze badges","comments":["It would be good to augment the example by adding another row in table B with value 4. This will show that inner joins need not be on equal no of rows.","An excellent explanation, however this statement: An outer join of A and B gives the results of A union B, i.e. the outer parts of a venn diagram union. isn't phrased accurately. An outer join will give the results of A intersect B in addition to one of the following: all of A (left join), all of B (right join) or all of A and all of B (full join). Only this last scenario is really A union B. Still, a well written explanation.","@Ameer, Thanks. Join does not guarantee an order, you would need to add an ORDER BY clause.","@Damian yes, OUTER JOIN and FULL OUTER JOIN are equivalent, along with LEFT/RIGHT JOIN are equivalent to LEFT/RIGHT OUTER JOIN, in the same way INNER JOIN is equivalent to a simple JOIN","I have downvoted this because it is wrong. Please consider removing the answer as it will mislead generations of computer science students who are fooled by the large upcote count. Venn diagrams do not explain join. The inner part of a join is not intersection."]},{"answer":"The Venn diagrams don't really do it for me.\n\nThey don't show any distinction between a cross join and an inner join, for example, or more generally show any distinction between different types of join predicate or provide a framework for reasoning about how they will operate.\n\nThere is no substitute for understanding the logical processing and it is relatively straightforward to grasp anyway.\n\nImagine a cross join.\nEvaluate the on clause against all rows from step 1 keeping those where the predicate evaluates to true\n(For outer joins only) add back in any outer rows that were lost in step 2.\n\n(NB: In practice the query optimiser may find more efficient ways of executing the query than the purely logical description above but the final result must be the same)\n\nI'll start off with an animated version of a full outer join. Further explanation follows.\n\nExplanation\n\nSource Tables\n\nFirst start with a CROSS JOIN (AKA Cartesian Product). This does not have an ON clause and simply returns every combination of rows from the two tables.\n\nSELECT A.Colour, B.Colour FROM A CROSS JOIN B\n\nInner and Outer joins have an \"ON\" clause predicate.\n\nInner Join. Evaluate the condition in the \"ON\" clause for all rows in the cross join result. If true return the joined row. Otherwise discard it.\nLeft Outer Join. Same as inner join then for any rows in the left table that did not match anything output these with NULL values for the right table columns.\nRight Outer Join. Same as inner join then for any rows in the right table that did not match anything output these with NULL values for the left table columns.\nFull Outer Join. Same as inner join then preserve left non matched rows as in left outer join and right non matching rows as per right outer join.\nSome examples\n\nSELECT A.Colour, B.Colour FROM A INNER JOIN B ON A.Colour = B.Colour\n\nThe above is the classic equi join.\n\nAnimated Version\n\nSELECT A.Colour, B.Colour FROM A INNER JOIN B ON A.Colour NOT IN ('Green','Blue')\n\nThe inner join condition need not necessarily be an equality condition and it need not reference columns from both (or even either) of the tables. Evaluating A.Colour NOT IN ('Green','Blue') on each row of the cross join returns.\n\nSELECT A.Colour, B.Colour FROM A INNER JOIN B ON 1 =1\n\nThe join condition evaluates to true for all rows in the cross join result so this is just the same as a cross join. I won't repeat the picture of the 16 rows again.\n\nSELECT A.Colour, B.Colour FROM A LEFT OUTER JOIN B ON A.Colour = B.Colour\n\nOuter Joins are logically evaluated in the same way as inner joins except that if a row from the left table (for a left join) does not join with any rows from the right hand table at all it is preserved in the result with NULL values for the right hand columns.\n\nSELECT A.Colour, B.Colour FROM A LEFT OUTER JOIN B ON A.Colour = B.Colour WHERE B.Colour IS NULL\n\nThis simply restricts the previous result to only return the rows where B.Colour IS NULL. In this particular case these will be the rows that were preserved as they had no match in the right hand table and the query returns the single red row not matched in table B. This is known as an anti semi join.\n\nIt is important to select a column for the IS NULL test that is either not nullable or for which the join condition ensures that any NULL values will be excluded in order for this pattern to work correctly and avoid just bringing back rows which happen to have a NULL value for that column in addition to the un matched rows.\n\nSELECT A.Colour, B.Colour FROM A RIGHT OUTER JOIN B ON A.Colour = B.Colour\n\nRight outer joins act similarly to left outer joins except they preserve non matching rows from the right table and null extend the left hand columns.\n\nSELECT A.Colour, B.Colour FROM A FULL OUTER JOIN B ON A.Colour = B.Colour\n\nFull outer joins combine the behaviour of left and right joins and preserve the non matching rows from both the left and the right tables.\n\nSELECT A.Colour, B.Colour FROM A FULL OUTER JOIN B ON 1 = 0\n\nNo rows in the cross join match the 1=0 predicate. All rows from both sides are preserved using normal outer join rules with NULL in the columns from the table on the other side.\n\nSELECT COALESCE(A.Colour, B.Colour) AS Colour FROM A FULL OUTER JOIN B ON 1 = 0\n\nWith a minor amend to the preceding query one could simulate a UNION ALL of the two tables.\n\nSELECT A.Colour, B.Colour FROM A LEFT OUTER JOIN B ON A.Colour = B.Colour WHERE B.Colour = 'Green'\n\nNote that the WHERE clause (if present) logically runs after the join. One common error is to perform a left outer join and then include a WHERE clause with a condition on the right table that ends up excluding the non matching rows. The above ends up performing the outer join...\n\n... And then the \"Where\" clause runs. NULL= 'Green' does not evaluate to true so the row preserved by the outer join ends up discarded (along with the blue one) effectively converting the join back to an inner one.\n\nIf the intention was to include only rows from B where Colour is Green and all rows from A regardless the correct syntax would be\n\nSELECT A.Colour, B.Colour FROM A LEFT OUTER JOIN B ON A.Colour = B.Colour AND B.Colour = 'Green'\n\nSQL Fiddle\n\nSee these examples run live at SQLFiddle.com.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Dec 13 '14 at 11:58\nMartin Smith\n406k80\n80 gold badges\n688\n688 silver badges\n780\n780 bronze badges","comments":["I will say that while this doesn't work for me nearly as well as the Venn diagrams, I appreciate that people vary and learn differently and this is a very well presented explanation unlike any I've seen before, so I support @ypercube in awarding the bonus points. Also good work explaining the difference of putting additional conditions in the JOIN clause vs the WHERE clause. Kudos to you, Martin Smith.","@OldPro The Venn diagrams are OK as far as they go I suppose but they are silent on how to represent a cross join, or to differentiate one kind of join predicate such as equi join from another. The mental model of evaluating the join predicate on each row of the cross join result then adding back in unmatched rows if an outer join and finally evaluating the where works better for me.","The Venn diagrams are good for representing Unions and Intersections and Differences but not joins. They have some minor educational value for very simple joins, i.e. joins where the joining condition is on unique columns.","@Arth - Nope you're wrong. SQL Fiddle sqlfiddle.com/#!3/9eecb7db59d16c80417c72d1/5155 this is something the Venn diagrams can't illustrate.","How did you do these animations? Great answer, the only bit I dislike is your modesty in saying that the Venn diagrams don't do it for you. The reality is that they are insufficient to model what's going on and this is important to tell, lest people get the wrong idea."]},{"answer":"Joins are used to combine the data from two tables, with the result being a new, temporary table. Joins are performed based on something called a predicate, which specifies the condition to use in order to perform a join. The difference between an inner join and an outer join is that an inner join will return only the rows that actually match based on the join predicate. For eg- Lets consider Employee and Location table:\n\nInner Join:- Inner join creates a new result table by combining column values of two tables (Employee and Location) based upon the join-predicate. The query compares each row of Employee with each row of Location to find all pairs of rows which satisfy the join-predicate. When the join-predicate is satisfied by matching non-NULL values, column values for each matched pair of rows of Employee and Location are combined into a result row. Here’s what the SQL for an inner join will look like:\n\nselect  * from employee inner join location on employee.empID = location.empID\nOR\nselect  * from employee, location where employee.empID = location.empID\n\n\nNow, here is what the result of running that SQL would look like: \n\nOuter Join:- An outer join does not require each record in the two joined tables to have a matching record. The joined table retains each record—even if no other matching record exists. Outer joins subdivide further into left outer joins and right outer joins, depending on which table's rows are retained (left or right).\n\nLeft Outer Join:- The result of a left outer join (or simply left join) for tables Employee and Location always contains all records of the \"left\" table (Employee), even if the join-condition does not find any matching record in the \"right\" table (Location). Here is what the SQL for a left outer join would look like, using the tables above:\n\nselect  * from employee left outer join location on employee.empID = location.empID;\n//Use of outer keyword is optional\n\n\nNow, here is what the result of running this SQL would look like: \n\nRight Outer Join:- A right outer join (or right join) closely resembles a left outer join, except with the treatment of the tables reversed. Every row from the \"right\" table (Location) will appear in the joined table at least once. If no matching row from the \"left\" table (Employee) exists, NULL will appear in columns from Employee for those records that have no match in Location. This is what the SQL looks like:\n\nselect * from employee right outer join location  on employee.empID = location.empID;\n//Use of outer keyword is optional\n\n\nUsing the tables above, we can show what the result set of a right outer join would look like:\n\nFull Outer Joins:- Full Outer Join or Full Join is to retain the nonmatching information by including nonmatching rows in the results of a join, use a full outer join. It includes all rows from both tables, regardless of whether or not the other table has a matching value.\n\nImage Source\n\nMySQL 8.0 Reference Manual - Join Syntax\n\nOracle Join operations\n\nShare\nImprove this answer\nFollow\nedited May 8 '20 at 18:52\nanswered Dec 18 '14 at 6:54\najitksharma\n4,1082\n2 gold badges\n19\n19 silver badges\n38\n38 bronze badges","comments":["best answer so far, alternative syntax - that's what I've been looking for, thanks!","The Venn diagrams are mislabelled. See my comments on the question & other answers. Also most of this language is poor. Eg: \"When the join-predicate is satisfied by matching non-NULL values, column values for each matched pair of rows of Employee and Location are combined into a result row.\" No, not \"When the join-predicate is satisfied by matching non-NULL values\". Values in rows don't matter other than whether the condition as a whole being true or false. Some values could well be NULL for a true condition.","Please use text, not images/links, for text--including tables & ERDs. Use images only for what cannot be expressed as text or to augment text. Images cannot be searched for or cut & pasted. Include a legend/key & explanation with an image."]},{"answer":"Inner Join\n\nRetrieve the matched rows only, that is, A intersect B.\n\nSELECT *\nFROM dbo.Students S\nINNER JOIN dbo.Advisors A\n    ON S.Advisor_ID = A.Advisor_ID\n\nLeft Outer Join\n\nSelect all records from the first table, and any records in the second table that match the joined keys.\n\nSELECT *\nFROM dbo.Students S\nLEFT JOIN dbo.Advisors A\n    ON S.Advisor_ID = A.Advisor_ID\n\nFull Outer Join\n\nSelect all records from the second table, and any records in the first table that match the joined keys.\n\nSELECT *\nFROM dbo.Students S\nFULL JOIN dbo.Advisors A\n    ON S.Advisor_ID = A.Advisor_ID\n\nReferences\n\nInner and outer joins SQL examples and the Join block\n\nSQL: JOINS\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jan 27 '14 at 12:16\nTushar Gupta - curioustushar\n55k22\n22 gold badges\n95\n95 silver badges\n103\n103 bronze badges","comments":["What is the name of tool? I find it is interesting as it shows number of rows and venn-diagrams","@GrijeshChauhan Yeah But you can Try to run it using wine .","Ohh! yes I ..I used SQLyog using wine.. there is also PlayOnLinux","Your text is unclear & wrong. The \"matched rows only\" are rows from the cross join of A & B & what is retrieved (A inner join B) is not A intersect B but (A left join B) intersect (A right join B). The \"selected\" rows are not from A & B, they are from A cross join B & from null-extended values of rows from A & B.","@TusharGupta-curioustushar you should include the \"Tables used for SQL Examples\""]},{"answer":"In simple words:\n\nAn inner join retrieve the matched rows only.\n\nWhereas an outer join retrieve the matched rows from one table and all rows in other table ....the result depends on which one you are using:\n\nLeft: Matched rows in the right table and all rows in the left table\n\nRight: Matched rows in the left table and all rows in the right table or\n\nFull: All rows in all tables. It doesn't matter if there is a match or not\n\nShare\nImprove this answer\nFollow\nedited Jul 21 '14 at 15:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 12 '13 at 11:07\nvidyadhar\n2,9466\n6 gold badges\n19\n19 silver badges\n29\n29 bronze badges","comments":["@nomen Not that this answer addresses it, but INNER JOIN is an intersection and FULL OUTER JOIN is the corresponding UNION if the left & right sets/circles contain the rows of (respectively) LEFT & RIGHT join. PS This answer is unclear about rows in input vs output. It confuses \"in the left/right table\" with \"has a left/right part in the left/right\" and it uses \"matched row\" vs \"all\" to mean row extended by row from other table vs by nulls."]},{"answer":"A inner join only shows rows if there is a matching record on the other (right) side of the join.\n\nA (left) outer join shows rows for each record on the left hand side, even if there are no matching rows on the other (right) side of the join. If there is no matching row, the columns for the other (right) side would show NULLs.\n\nShare\nImprove this answer\nFollow\nedited Jan 5 '15 at 1:14\nanswered Sep 1 '08 at 22:38\n1800 INFORMATION\n121k29\n29 gold badges\n152\n152 silver badges\n235\n235 bronze badges","comments":[]},{"answer":"Inner joins require that a record with a related ID exist in the joined table.\n\nOuter joins will return records for the left side even if nothing exists for the right side.\n\nFor instance, you have an Orders and an OrderDetails table. They are related by an \"OrderID\".\n\nOrders\n\nOrderID\nCustomerName\n\nOrderDetails\n\nOrderDetailID\nOrderID\nProductName\nQty\nPrice\n\nThe request\n\nSELECT Orders.OrderID, Orders.CustomerName\n  FROM Orders \n INNER JOIN OrderDetails\n    ON Orders.OrderID = OrderDetails.OrderID\n\n\nwill only return Orders that also have something in the OrderDetails table.\n\nIf you change it to OUTER LEFT JOIN\n\nSELECT Orders.OrderID, Orders.CustomerName\n  FROM Orders \n  LEFT JOIN OrderDetails\n    ON Orders.OrderID = OrderDetails.OrderID\n\n\nthen it will return records from the Orders table even if they have no OrderDetails records.\n\nYou can use this to find Orders that do not have any OrderDetails indicating a possible orphaned order by adding a where clause like WHERE OrderDetails.OrderID IS NULL.\n\nShare\nImprove this answer\nFollow\nedited Sep 10 '18 at 8:25\nSergeyUr\n3241\n1 gold badge\n4\n4 silver badges\n18\n18 bronze badges\nanswered Sep 1 '08 at 22:47\nBrian Boatright\n34.3k33\n33 gold badges\n76\n76 silver badges\n102\n102 bronze badges","comments":["I appreciate the simple yet realistic example. I changed a request like SELECT c.id, c.status, cd.name, c.parent_id, cd.description, c.image FROM categories c,  categories_description cd WHERE c.id = cd.categories_id AND c.status = 1 AND cd.language_id = 2 ORDER BY c.parent_id ASC to SELECT c.id, c.status, cd.name, c.parent_id, cd.description, c.image FROM categories c INNER JOIN  categories_description cd ON c.id = cd.categories_id WHERE c.status = 1 AND cd.language_id = 2 ORDER BY c.parent_id ASC (MySQL) with success. I wasn't sure about the additional conditions, they mix well..."]},{"answer":"In simple words :\n\nInner join -> Take ONLY common records from parent and child tables WHERE primary key of Parent table matches Foreign key in Child table.\n\nLeft join ->\n\npseudo code\n\n1.Take All records from left Table\n2.for(each record in right table,) {\n    if(Records from left & right table matching on primary & foreign key){\n       use their values as it is as result of join at the right side for 2nd table.\n    } else {\n       put value NULL values in that particular record as result of join at the right side for 2nd table.\n    }\n  }\n\n\nRight join : Exactly opposite of left join . Put name of table in LEFT JOIN at right side in Right join , you get same output as LEFT JOIN.\n\nOuter join : Show all records in Both tables No matter what. If records in Left table are not matching to right table based on Primary , Forieign key , use NULL value as result of join .\n\nExample :\n\nLets assume now for 2 tables\n\n1.employees  , 2.phone_numbers_employees\n\nemployees : id , name \n\nphone_numbers_employees : id , phone_num , emp_id   \n\n\nHere , employees table is Master table , phone_numbers_employees is child table(it contains emp_id as foreign key which connects employee.id so its child table.)\n\nInner joins\n\nTake the records of 2 tables ONLY IF Primary key of employees table(its id) matches Foreign key of Child table phone_numbers_employees(emp_id).\n\nSo query would be :\n\nSELECT e.id , e.name , p.phone_num FROM employees AS e INNER JOIN phone_numbers_employees AS p ON e.id = p.emp_id;\n\n\nHere take only matching rows on primary key = foreign key as explained above.Here non matching rows on primary key = foreign key are skipped as result of join.\n\nLeft joins :\n\nLeft join retains all rows of the left table, regardless of whether there is a row that matches on the right table.\n\nSELECT e.id , e.name , p.phone_num FROM employees AS e LEFT JOIN phone_numbers_employees AS p ON e.id = p.emp_id;\n\n\nOuter joins :\n\nSELECT e.id , e.name , p.phone_num FROM employees AS e OUTER JOIN phone_numbers_employees AS p ON e.id = p.emp_id;\n\n\nDiagramatically it looks like :\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Feb 19 '15 at 4:50\nPratik\n10.8k6\n6 gold badges\n33\n33 silver badges\n70\n70 bronze badges","comments":["The result has nothing to (do per se) with primary/unique/candidate keys & foreign keys. The baviour can and should be described without reference to them. A cross join is calculated, then rows not matching the ON condition are filtered out; additionally for outer joins rows filtered/unmatched rows are extended by NULLs (per LEFT/RIGHT/FULL and included.","The assumption that SQL joins are always a match on primary/foreign keys is leading to this misuse of Venn diagrams. Please revise your answer accordingly."]},{"answer":"You use INNER JOIN to return all rows from both tables where there is a match. i.e. In the resulting table all the rows and columns will have values.\n\nIn OUTER JOIN the resulting table may have empty columns. Outer join may be either LEFT or RIGHT.\n\nLEFT OUTER JOIN returns all the rows from the first table, even if there are no matches in the second table.\n\nRIGHT OUTER JOIN returns all the rows from the second table, even if there are no matches in the first table.\n\nShare\nImprove this answer\nFollow\nedited Jun 9 '15 at 3:21\nshA.t\n15.4k5\n5 gold badges\n47\n47 silver badges\n96\n96 bronze badges\nanswered Sep 27 '12 at 7:33\nvijikumar\n1,69711\n11 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"INNER JOIN requires there is at least a match in comparing the two tables. For example, table A and table B which implies A ٨ B (A intersection B).\n\nLEFT OUTER JOIN and LEFT JOIN are the same. It gives all the records matching in both tables and all possibilities of the left table.\n\nSimilarly, RIGHT OUTER JOIN and RIGHT JOIN are the same. It gives all the records matching in both tables and all possibilities of the right table.\n\nFULL JOIN is the combination of LEFT OUTER JOIN and RIGHT OUTER JOIN without duplication.\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '13 at 21:25\nA_Pointar\n12112\n12 bronze badges\nanswered Sep 2 '10 at 9:49\nnaga\n6195\n5 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"The answer is in the meaning of each one, so in the results.\n\nNote :\nIn SQLite there is no RIGHT OUTER JOIN or FULL OUTER JOIN.\nAnd also in MySQL there is no FULL OUTER JOIN.\n\nMy answer is based on above Note.\n\nWhen you have two tables like these:\n\n--[table1]               --[table2]\nid | name                id | name\n---+-------              ---+-------\n1  | a1                  1  | a2\n2  | b1                  3  | b2\n\n\nCROSS JOIN / OUTER JOIN :\nYou can have all of those tables data with CROSS JOIN or just with , like this:\n\nSELECT * FROM table1, table2\n--[OR]\nSELECT * FROM table1 CROSS JOIN table2\n\n--[Results:]\nid | name | id | name \n---+------+----+------\n1  | a1   | 1  | a2\n1  | a1   | 3  | b2\n2  | b1   | 1  | a2\n2  | b1   | 3  | b2\n\n\nINNER JOIN :\nWhen you want to add a filter to above results based on a relation like table1.id = table2.id you can use INNER JOIN:\n\nSELECT * FROM table1, table2 WHERE table1.id = table2.id\n--[OR]\nSELECT * FROM table1 INNER JOIN table2 ON table1.id = table2.id\n\n--[Results:]\nid | name | id | name \n---+------+----+------\n1  | a1   | 1  | a2\n\n\nLEFT [OUTER] JOIN :\nWhen you want to have all rows of one of tables in the above result -with same relation- you can use LEFT JOIN:\n(For RIGHT JOIN just change place of tables)\n\nSELECT * FROM table1, table2 WHERE table1.id = table2.id \nUNION ALL\nSELECT *, Null, Null FROM table1 WHERE Not table1.id In (SELECT id FROM table2)\n--[OR]\nSELECT * FROM table1 LEFT JOIN table2 ON table1.id = table2.id\n\n--[Results:]\nid | name | id   | name \n---+------+------+------\n1  | a1   | 1    | a2\n2  | b1   | Null | Null\n\n\nFULL OUTER JOIN :\nWhen you also want to have all rows of the other table in your results you can use FULL OUTER JOIN:\n\nSELECT * FROM table1, table2 WHERE table1.id = table2.id\nUNION ALL\nSELECT *, Null, Null FROM table1 WHERE Not table1.id In (SELECT id FROM table2)\nUNION ALL\nSELECT Null, Null, * FROM table2 WHERE Not table2.id In (SELECT id FROM table1)\n--[OR] (recommended for SQLite)\nSELECT * FROM table1 LEFT JOIN table2 ON table1.id = table2.id\nUNION ALL\nSELECT * FROM table2 LEFT JOIN table1 ON table2.id = table1.id\nWHERE table1.id IS NULL\n--[OR]\nSELECT * FROM table1 FULL OUTER JOIN table2 On table1.id = table2.id\n\n--[Results:]\nid   | name | id   | name \n-----+------+------+------\n1    | a1   | 1    | a2\n2    | b1   | Null | Null\nNull | Null | 3    | b2\n\n\nWell, as your need you choose each one that covers your need ;).\n\nShare\nImprove this answer\nFollow\nedited Sep 12 '17 at 8:50\nanswered Apr 13 '15 at 13:07\nshA.t\n15.4k5\n5 gold badges\n47\n47 silver badges\n96\n96 bronze badges","comments":["You can add to your note, that there is no full outer join in MySQL either."]},{"answer":"Inner join.\n\nA join is combining the rows from two tables. An inner join attempts to match up the two tables based on the criteria you specify in the query, and only returns the rows that match. If a row from the first table in the join matches two rows in the second table, then two rows will be returned in the results. If there’s a row in the first table that doesn’t match a row in the second, it’s not returned; likewise, if there’s a row in the second table that doesn’t match a row in the first, it’s not returned.\n\nOuter Join.\n\nA left join attempts to find match up the rows from the first table to rows in the second table. If it can’t find a match, it will return the columns from the first table and leave the columns from the second table blank (null).\n\nShare\nImprove this answer\nFollow\nedited Feb 2 '16 at 11:14\nSandesh\n1,1523\n3 gold badges\n21\n21 silver badges\n39\n39 bronze badges\nanswered Apr 11 '14 at 9:18\nKanwar Singh\n84811\n11 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"INNER JOIN most typical join for two or more tables. It returns data match on both table ON primarykey and forignkey relation.\nOUTER JOIN is same as INNER JOIN, but it also include NULL data on ResultSet.\nLEFT JOIN = INNER JOIN + Unmatched data of left table with Null match on right table.\nRIGHT JOIN = INNER JOIN + Unmatched data of right table with Null match on left table.\nFULL JOIN = INNER JOIN + Unmatched data on both right and left tables with Null matches.\nSelf join is not a keyword in SQL, when a table references data in itself knows as self join. Using INNER JOIN and OUTER JOIN we can write self join queries.\n\nFor example:\n\nSELECT * \nFROM   tablea a \n       INNER JOIN tableb b \n               ON a.primary_key = b.foreign_key \n       INNER JOIN tablec c \n               ON b.primary_key = c.foreign_key \n\nShare\nImprove this answer\nFollow\nedited Mar 21 '19 at 22:19\nanswered Dec 26 '17 at 16:49\nPremraj\n59k24\n24 gold badges\n216\n216 silver badges\n163\n163 bronze badges","comments":[]},{"answer":"I don't see much details about performance and optimizer in the other answers.\n\nSometimes it is good to know that only INNER JOIN is associative which means the optimizer has the most option to play with it. It can reorder the join order to make it faster keeping the same result. The optimizer can use the most join modes.\n\nGenerally it is a good practice to try to use INNER JOIN instead of the different kind of joins. (Of course if it is possible considering the expected result set.)\n\nThere are a couple of good examples and explanation here about this strange associative behavior:\n\nAre left outer joins associative?\nDoes the join order matter in SQL?\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Nov 17 '13 at 12:59\nLajos Veres\n13.2k7\n7 gold badges\n40\n40 silver badges\n56\n56 bronze badges","comments":["It can't possibly be \"good practice\" to use one type of join over another. Which join you use determines the data that you want. If you use a different one you're incorrect. Plus, in Oracle at least this answer is completely wrong. It sounds completely wrong for everything and you have no proof. Do you have proof?","1. I mean try to use. I saw lots of people using LEFT OUTER joins everywhere without any good reason. (The joined columns were 'not null'.) In those cases it would be definitely better to use INNER joins. 2. I have added a link explaining the non-associative behaviour better than I could.","As I know INNER JOIN is slower than LEFT JOIN in most of the times, And people can use LEFT JOIN instead of INNER JOIN by adding a WHERE for removing unexpected NULL results ;).","These comments made me a bit uncertain. Why do you think INNER is slower?","Depends upon the engine. gnu join, joinkeys, DB2, MySQL. Performance traps abound, such as loose typing or an explicit cast."]},{"answer":"Having criticized the much-loved red-shaded Venn diagram, I thought it only fair to post my own attempt.\n\nAlthough @Martin Smith's answer is the best of this bunch by a long way, his only shows the key column from each table, whereas I think ideally non-key columns should also be shown.\n\nThe best I could do in the half hour allowed, I still don't think it adequately shows that the nulls are there due to absence of key values in TableB or that OUTER JOIN is actually a union rather than a join:\n\nShare\nImprove this answer\nFollow\nanswered Jan 22 '16 at 15:23\nonedaywhen\n51.3k12\n12 gold badges\n91\n91 silver badges\n132\n132 bronze badges","comments":["Question is asking for Difference between INNER and OUTER joins though, not necessarily left outer join lol","@LearnByReading: my picture on the right is a right outer join i.e. replace TableA a LEFT OUTER JOIN TableB b with TableB B RIGHT OUTER JOIN TableA a"]},{"answer":"The precise algorithm for INNER JOIN, LEFT/RIGHT OUTER JOIN are as following:\n\nTake each row from the first table: a\nConsider all rows from second table beside it: (a, b[i])\nEvaluate the ON ... clause against each pair: ON( a, b[i] ) = true/false?\nWhen the condition evaluates to true, return that combined row (a, b[i]).\nWhen reach end of second table without any match, and this is an Outer Join then return a (virtual) pair using Null for all columns of other table: (a, Null) for LEFT outer join or (Null, b) for RIGHT outer join. This is to ensure all rows of first table exists in final results.\n\nNote: the condition specified in ON clause could be anything, it is not required to use Primary Keys (and you don't need to always refer to Columns from both tables)! For example:\n\n... ON T1.title = T2.title AND T1.version < T2.version ( => see this post as a sample usage: Select only rows with max value on a column)\n... ON T1.y IS NULL\n... ON 1 = 0 (just as sample)\n\nNote: Left Join = Left Outer Join, Right Join = Right Outer Join.\n\nShare\nImprove this answer\nFollow\nedited Oct 11 '18 at 14:16\nanswered Nov 8 '16 at 12:25\nS.Serpooshan\n6,5083\n3 gold badges\n30\n30 silver badges\n53\n53 bronze badges","comments":[]},{"answer":"Simplest Definitions\n\nInner Join: Returns matched records from both tables.\n\nFull Outer Join: Returns matched and unmatched records from both tables with null for unmatched records from Both Tables.\n\nLeft Outer Join: Returns matched and unmatched records only from table on Left Side.\n\nRight Outer Join: Returns matched and unmatched records only from table on Right Side.\n\nIn-Short\n\nMatched + Left Unmatched + Right Unmatched = Full Outer Join\n\nMatched + Left Unmatched = Left Outer Join\n\nMatched + Right Unmatched = Right Outer Join\n\nMatched = Inner Join\n\nShare\nImprove this answer\nFollow\nanswered Apr 28 '16 at 9:10\nAkshay Khale\n7,2377\n7 gold badges\n44\n44 silver badges\n53\n53 bronze badges","comments":["This is brilliant and explains why join doesn't work as expected for Time Series index's. Time stamps one second apart are unmatched.","@yeliabsalohcin You don't explain \"as expected\" here or \"works\" in your comment on the question. It's just some unexplained personal misconception you strangely expect others to have. If you treat words as sloppily when you are reading--misinterpreting clear writing and/or accepting unclear writing--as when you are writing here then you can expect to have misconceptions. In fact this answer like most here is unclear & wrong. \"Inner Join: Returns matched records from both tables\" is wrong when input column sets differ. It's trying to say a certain something, but it isn't. (See my answer.)"]},{"answer":"In Simple Terms,\n\n1.INNER JOIN OR EQUI JOIN : Returns the resultset that matches only the condition in both the tables.\n\n2.OUTER JOIN : Returns the resultset of all the values from both the tables even if there is condition match or not.\n\n3.LEFT JOIN : Returns the resultset of all the values from left table and only rows that match the condition in right table.\n\n4.RIGHT JOIN : Returns the resultset of all the values from right table and only rows that match the condition in left table.\n\n5.FULL JOIN : Full Join and Full outer Join are same.\n\nShare\nImprove this answer\nFollow\nedited Oct 13 '16 at 9:04\nanswered Oct 13 '16 at 8:53\nAnands23\n6617\n7 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"The General Idea\n\nPlease see the answer by Martin Smith for a better illustations and explanations of the different joins, including and especially differences between FULL OUTER JOIN, RIGHT OUTER JOIN and LEFT OUTER JOIN.\n\nThese two table form a basis for the representation of the JOINs below:\n\nCROSS JOIN\n\nSELECT *\n  FROM citizen\n CROSS JOIN postalcode\n\n\nThe result will be the Cartesian products of all combinations. No JOIN condition required:\n\nINNER JOIN\n\nINNER JOIN is the same as simply: JOIN\n\nSELECT *\n  FROM citizen    c\n  JOIN postalcode p ON c.postal = p.postal\n\n\nThe result will be combinations that satisfies the required JOIN condition:\n\nLEFT OUTER JOIN\n\nLEFT OUTER JOIN is the same as LEFT JOIN\n\nSELECT *\n  FROM citizen         c\n  LEFT JOIN postalcode p ON c.postal = p.postal\n\n\nThe result will be everything from citizen even if there are no matches in postalcode. Again a JOIN condition is required:\n\nData for playing\n\nAll examples have been run on an Oracle 18c. They're available at dbfiddle.uk which is also where screenshots of tables came from.\n\nCREATE TABLE citizen (id      NUMBER,\n                      name    VARCHAR2(20),\n                      postal  NUMBER,  -- <-- could do with a redesign to postalcode.id instead.\n                      leader  NUMBER);\n\nCREATE TABLE postalcode (id      NUMBER,\n                         postal  NUMBER,\n                         city    VARCHAR2(20),\n                         area    VARCHAR2(20));\n\nINSERT INTO citizen (id, name, postal, leader)\n              SELECT 1, 'Smith', 2200,  null FROM DUAL\n        UNION SELECT 2, 'Green', 31006, 1    FROM DUAL\n        UNION SELECT 3, 'Jensen', 623,  1    FROM DUAL;\n\nINSERT INTO postalcode (id, postal, city, area)\n                 SELECT 1, 2200,     'BigCity',         'Geancy'  FROM DUAL\n           UNION SELECT 2, 31006,    'SmallTown',       'Snizkim' FROM DUAL\n           UNION SELECT 3, 31006,    'Settlement',      'Moon'    FROM DUAL  -- <-- Uuh-uhh.\n           UNION SELECT 4, 78567390, 'LookoutTowerX89', 'Space'   FROM DUAL;\n\nBlurry boundaries when playing with JOIN and WHERE\nCROSS JOIN\n\nCROSS JOIN resulting in rows as The General Idea/INNER JOIN:\n\nSELECT *\n  FROM citizen          c\n  CROSS JOIN postalcode p\n WHERE c.postal = p.postal -- < -- The WHERE condition is limiting the resulting rows\n\n\nUsing CROSS JOIN to get the result of a LEFT OUTER JOIN requires tricks like adding in a NULL row. It's omitted.\n\nINNER JOIN\n\nINNER JOIN becomes a cartesian products. It's the same as The General Idea/CROSS JOIN:\n\nSELECT *\n  FROM citizen    c\n  JOIN postalcode p ON 1 = 1  -- < -- The ON condition makes it a CROSS JOIN\n\n\nThis is where the inner join can really be seen as the cross join with results not matching the condition removed. Here none of the resulting rows are removed.\n\nUsing INNER JOIN to get the result of a LEFT OUTER JOIN also requires tricks. It's omitted.\n\nLEFT OUTER JOIN\n\nLEFT JOIN results in rows as The General Idea/CROSS JOIN:\n\nSELECT *\n  FROM citizen         c\n  LEFT JOIN postalcode p ON 1 = 1 -- < -- The ON condition makes it a CROSS JOIN\n\n\nLEFT JOIN results in rows as The General Idea/INNER JOIN:\n\nSELECT *\n  FROM citizen         c\n  LEFT JOIN postalcode p ON c.postal = p.postal\n WHERE p.postal IS NOT NULL -- < -- removed the row where there's no mathcing result from postalcode\n\nThe troubles with the Venn diagram\n\nAn image internet search on \"sql join cross inner outer\" will show a multitude of Venn diagrams. I used to have a printed copy of one on my desk. But there are issues with the representation.\n\nVenn diagram are excellent for set theory, where an element can be in one or both sets. But for databases, an element in one \"set\" seem, to me, to be a row in a table, and therefore not also present in any other tables. There is no such thing as one row present in multiple tables. A row is unique to the table.\n\nSelf joins are a corner case where each element is in fact the same in both sets. But it's still not free of any of the issues below.\n\nThe set A represents the set on the left (the citizen table) and the set B is the set on the right (the postalcode table) in below discussion.\n\nCROSS JOIN\n\nEvery element in both sets are matched with every element in the other set, meaning we need A amount of every B elements and B amount of every A elements to properly represent this Cartesian product. Set theory isn't made for multiple identical elements in a set, so I find Venn diagrams to properly represent it impractical/impossible. It doesn't seem that UNION fits at all.\n\nThe rows are distinct. The UNION is 7 rows in total. But they're incompatible for a common SQL results set. And this is not how a CROSS JOIN works at all:\n\nTrying to represent it like this:\n\n..but now it just looks like an INTERSECTION, which it's certainly not. Furthermore there's no element in the INTERSECTION that is actually in any of the two distinct sets. However, it looks very much like the searchable results similar to this:\n\nFor reference one searchable result for CROSS JOINs can be seen at Tutorialgateway. The INTERSECTION, just like this one, is empty.\n\nINNER JOIN\n\nThe value of an element depends on the JOIN condition. It's possible to represent this under the condition that every row becomes unique to that condition. Meaning id=x is only true for one row. Once a row in table A (citizen) matches multiple rows in table B (postalcode) under the JOIN condition, the result has the same problems as the CROSS JOIN: The row needs to be represented multiple times, and the set theory isn't really made for that. Under the condition of uniqueness, the diagram could work though, but keep in mind that the JOIN condition determines the placement of an element in the diagram. Looking only at the values of the JOIN condition with the rest of the row just along for the ride:\n\nThis representation falls completely apart when using an INNER JOIN with a ON 1 = 1 condition making it into a CROSS JOIN.\n\nWith a self-JOIN, the rows are in fact idential elements in both tables, but representing the tables as both A and B isn't very suitable. For example a common self-JOIN condition that makes an element in A to be matching a different element in B is ON A.parent = B.child, making the match from A to B on seperate elements. From the examples that would be a SQL like this:\n\nSELECT *\n  FROM citizen c1\n  JOIN citizen c2 ON c1.id = c2.leader\n\n\nMeaning Smith is the leader of both Green and Jensen.\n\nOUTER JOIN\n\nAgain the troubles begin when one row has multiple matches to rows in the other table. This is further complicated because the OUTER JOIN can be though of as to match the empty set. But in set theory the union of any set C and an empty set, is always just C. The empty set adds nothing. The representation of this LEFT OUTER JOIN is usually just showing all of A to illustrate that rows in A are selected regardless of whether there is a match or not from B. The \"matching elements\" however has the same problems as the illustration above. They depend on the condition. And the empty set seems to have wandered over to A:\n\nWHERE clause - making sense\n\nFinding all rows from a CROSS JOIN with Smith and postalcode on the Moon:\n\nSELECT *\n  FROM citizen          c\n CROSS JOIN postalcode  p\n WHERE c.name = 'Smith'\n   AND p.area = 'Moon';\n\n\nNow the Venn diagram isn't used to reflect the JOIN. It's used only for the WHERE clause:\n\n..and that makes sense.\n\nWhen INTERSECT and UNION makes sense\nINTERSECT\n\nAs explained an INNER JOIN is not really an INTERSECT. However INTERSECTs can be used on results of seperate queries. Here a Venn diagram makes sense, because the elements from the seperate queries are in fact rows that either belonging to just one of the results or both. Intersect will obviously only return results where the row is present in both queries. This SQL will result in the same row as the one above WHERE, and the Venn diagram will also be the same:\n\nSELECT *\n  FROM citizen          c\n CROSS JOIN postalcode  p\n WHERE c.name = 'Smith'\nINTERSECT\nSELECT *\n  FROM citizen          c\n CROSS JOIN postalcode  p\n WHERE p.area = 'Moon';\n\nUNION\n\nAn OUTER JOIN is not a UNION. However UNION work under the same conditions as INTERSECT, resulting in a return of all results combining both SELECTs:\n\nSELECT *\n  FROM citizen          c\n CROSS JOIN postalcode  p\n WHERE c.name = 'Smith'\nUNION\nSELECT *\n  FROM citizen          c\n CROSS JOIN postalcode  p\n WHERE p.area = 'Moon';\n\n\nwhich is equivalent to:\n\nSELECT *\n  FROM citizen          c\n CROSS JOIN postalcode  p\n WHERE c.name = 'Smith'\n   OR p.area = 'Moon';\n\n\n..and gives the result:\n\nAlso here a Venn diagram makes sense:\n\nWhen it doesn't apply\n\nAn important note is that these only work when the structure of the results from the two SELECT's are the same, enabling a comparison or union. The results of these two will not enable that:\n\nSELECT *\n  FROM citizen\n WHERE name = 'Smith'\n\nSELECT *\n  FROM postalcode\n WHERE area = 'Moon';\n\n\n..trying to combine the results with UNION gives a\n\nORA-01790: expression must have same datatype as corresponding expression\n\n\nFor further interest read Say NO to Venn Diagrams When Explaining JOINs and sql joins as venn diagram. Both also cover EXCEPT.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered May 6 '20 at 23:26\nScratte\n2,6266\n6 gold badges\n16\n16 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"There is a lot of misinformation out there on this topic, including here on Stack Overflow.\n\nleft join on (aka left outer join on) returns inner join on rows union all unmatched left table rows extended by nulls.\n\nright join (on aka right outer join on) returns inner join on rows union all unmatched right table rows extended by nulls.\n\nfull join on (aka full outer join on) returns inner join on rowsunion all unmatched left table rows extended by nulls union all unmatched right table rows extended by nulls.\n\n(SQL Standard 2006 SQL/Foundation 7.7 Syntax Rules 1, General Rules 1 b, 3 c & d, 5 b.)\n\nSo don't outer join until you know what underlying inner join is involved.\n\nFind out what rows inner join on returns:\nCROSS JOIN vs INNER JOIN in SQL\n\nThat also explains why Venn(-like) diagrams are not helpful for inner vs outer join.\nFor more on why Venn(-like) diagrams are not helpful for joins:\nVenn Diagram for Natural Join\n\nShare\nImprove this answer\nFollow\nedited Mar 6 at 3:40\nanswered Sep 7 '17 at 8:35\nphilipxy\n14.1k5\n5 gold badges\n30\n30 silver badges\n70\n70 bronze badges","comments":["I have indeed read your many comments. When you say, \"a Venn diagram, when properly interpreted, can represent inner vs outer join\" do you mean when properly interpreted by the observer or the Venn diagram itself? If the latter, please draw it :)","I'm not sure what you are trying to say. I am talking about the standard interpretation of a Venn diagram as sets of elements. (Because some uses of diagrams don't even manage that.) \"Properly\" for an application includes saying what the sets and/or elements are. See comment at the top of this page with 50 upvotes re a Venn diagram for inner vs outer joins. I'll edit some of my comments into this question. I don't want a Venn diagram in this post.","I don't want Venn diagrams either!","I must admit that, despite my quick phrasing in comments, because SQL involves bags & nulls and SQL culture doesn't have common terminology to name & distinguish between relevant notions, it is non-trivial even to explain clearly how elements of a Venn diagram are 1:1 with output \"rows\", let alone input \"rows\". Or what inner or outer joins do, let alone their difference. \"value\" may or may not include NULL, \"row\" may be a list of values vs a slot in a table value or variable & \"=\" may be SQL \"=\" vs equality.","Similar to our Cartesian-product-vs-relational-product discussion, I suspect it is the case that the Venn diagrams make a lot of sense to folk who already understand the differences between the join types!"]},{"answer":"Inner join - An inner join using either of the equivalent queries gives the intersection of the two tables, i.e. the two rows they have in common.\n\nLeft outer join - A left outer join will give all rows in A, plus any common rows in B.\n\nFull outer join - A full outer join will give you the union of A and B, i.e. All the rows in A and all the rows in B. If something in A doesn't have a corresponding datum in B, then the B portion is null, and vice versay\n\nShare\nImprove this answer\nFollow\nedited Jun 23 '16 at 13:55\nanswered Feb 2 '16 at 11:43\nSandesh\n1,1523\n3 gold badges\n21\n21 silver badges\n39\n39 bronze badges","comments":["This is both wrong and unclear. Join is not an intersection unless the tables have the same columns. Outer joins don't have rows from A or B unless they have the same columns, in which case there are not nulls added. You are trying to say something, but you are not saying it. You are not explaining correctly or clearly.","@philipxy: Disagreed on your statement Join is not an intersection unless the tables have the same columns No. You can join any columns that you want and if the value match, they will join together.","That comment is as unclear as your answer. (I suppose you might be thinking something like, the set of subrow values for the common columns of the result is the intersection of the sets of subrow values for the common columns of each of the inputs; but that's not what you have written. You are not clear.)","What I meant was that join is only an intersection of inputs when it is a natural inner join of inputs with the same columns. You are using the words \"intersection\" & \"union\" wrongly."]},{"answer":"1.Inner Join: Also called as Join. It returns the rows present in both the Left table, and right table only if there is a match. Otherwise, it returns zero records.\n\nExample:\n\nSELECT\n  e1.emp_name,\n  e2.emp_salary    \nFROM emp1 e1\nINNER JOIN emp2 e2\n  ON e1.emp_id = e2.emp_id\n\n\n2.Full Outer Join: Also called as Full Join. It returns all the rows present in both the Left table, and right table.\n\nExample:\n\nSELECT\n  e1.emp_name,\n  e2.emp_salary    \nFROM emp1 e1\nFULL OUTER JOIN emp2 e2\n  ON e1.emp_id = e2.emp_id\n\n\n3.Left Outer join: Or simply called as Left Join. It returns all the rows present in the Left table and matching rows from the right table (if any).\n\n4.Right Outer Join: Also called as Right Join. It returns matching rows from the left table (if any), and all the rows present in the Right table.\n\nAdvantages of Joins\n\nExecutes faster.\nShare\nImprove this answer\nFollow\nedited Jul 28 '17 at 4:17\nanswered Jul 10 '17 at 11:56\nLaxmi\n3,59921\n21 silver badges\n30\n30 bronze badges","comments":["This is only correct when the tables have the same column set. (It confuses inner join with intersection & full join with union.) Also \"match\" is undefined. Read my other comments."]},{"answer":"Joins are more easily explained with an example:\n\nTo simulate persons and emails stored in separate tables,\n\nTable A and Table B are joined by Table_A.id = Table_B.name_id\n\nInner Join\n\nOnly matched ids' rows are shown.\n\nOuter Joins\n\nMatched ids and not matched rows for Table A are shown.\n\nMatched ids and not matched rows for Table B are shown.\n\n Matched ids and not matched rows from both Tables are shown.\n\nNote: Full outer join is not available on MySQL\n\nShare\nImprove this answer\nFollow\nedited Jul 31 '20 at 23:33\nanswered Jul 31 '20 at 10:45\nHGG-Dev\n5753\n3 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"Consider below 2 tables:\n\nEMP\n\nempid   name    dept_id salary\n1       Rob     1       100\n2       Mark    1       300\n3       John    2       100\n4       Mary    2       300\n5       Bill    3       700\n6       Jose    6       400\n\n\nDepartment\n\ndeptid  name\n1       IT\n2       Accounts\n3       Security\n4       HR\n5       R&D\n\nInner Join:\n\nMostly written as just JOIN in sql queries. It returns only the matching records between the tables.\n\nFind out all employees and their department names:\nSelect a.empid, a.name, b.name as dept_name\nFROM emp a\nJOIN department b\nON a.dept_id = b.deptid\n;\n\nempid   name    dept_name\n1       Rob     IT\n2       Mark    IT\n3       John    Accounts\n4       Mary    Accounts\n5       Bill    Security\n\n\nAs you see above, Jose is not printed from EMP in the output as it's dept_id 6 does not find a match in the Department table. Similarly, HR and R&D rows are not printed from Department table as they didn't find a match in the Emp table.\n\nSo, INNER JOIN or just JOIN, returns only matching rows.\n\nLEFT JOIN :\n\nThis returns all records from the LEFT table and only matching records from the RIGHT table.\n\nSelect a.empid, a.name, b.name as dept_name\nFROM emp a\nLEFT JOIN department b\nON a.dept_id = b.deptid\n;\n\nempid   name    dept_name\n1       Rob     IT\n2       Mark    IT\n3       John    Accounts\n4       Mary    Accounts\n5       Bill    Security\n6       Jose    \n\n\nSo, if you observe the above output, all records from the LEFT table(Emp) are printed with just matching records from RIGHT table.\n\nHR and R&D rows are not printed from Department table as they didn't find a match in the Emp table on dept_id.\n\nSo, LEFT JOIN returns ALL rows from Left table and only matching rows from RIGHT table.\n\nCan also check DEMO here.\n\nShare\nImprove this answer\nFollow\nedited Nov 25 '18 at 15:04\nanswered Nov 25 '18 at 14:50\nMayank Porwal\n27.6k7\n7 gold badges\n25\n25 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"The difference between inner join and outer join is as follow:\n\nInner join is a join that combined tables based on matching tuples, whereas outer join is a join that combined table based on both matched and unmatched tuple.\nInner join merges matched row from two table in where unmatched row are omitted, whereas outer join merges rows from two tables and unmatched rows fill with null value.\nInner join is like an intersection operation, whereas outer join is like an union operation.\nInner join is two types, whereas outer join are three types.\nouter join is faster than inner join.\nShare\nImprove this answer\nFollow\nedited Jan 9 '20 at 14:05\nphilipxy\n14.1k5\n5 gold badges\n30\n30 silver badges\n70\n70 bronze badges\nanswered Oct 17 '17 at 12:25\nrashedcs\n2,8212\n2 gold badges\n32\n32 silver badges\n33\n33 bronze badges","comments":["An outer join result is the same as inner join but plus some additional rows so I have no idea why you think outer join would be faster. Also what are these \"two types\" of inner join? I suppose you are referring to full,left, and right for outer?","Outer join is not faster than inner join."]},{"answer":"There are a lot of good answers here with very accurate relational algebra examples. Here is a very simplified answer that might be helpful for amateur or novice coders with SQL coding dilemmas.\n\nBasically, more often than not, JOIN queries boil down to two cases:\n\nFor a SELECT of a subset of A data:\n\nuse INNER JOIN when the related B data you are looking for MUST exist per database design;\nuse LEFT JOIN when the related B data you are looking for MIGHT or MIGHT NOT exist per database design.\nShare\nImprove this answer\nFollow\nedited Aug 1 '20 at 1:25\nphilipxy\n14.1k5\n5 gold badges\n30\n30 silver badges\n70\n70 bronze badges\nanswered Oct 25 '19 at 17:22\nForguesR\n3,3831\n1 gold badge\n14\n14 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"A Demonstration\nSetup\n\nHop into psql and create a tiny database of cats and humans. You can just copy-paste this whole section.\n\nCREATE DATABASE catdb;\n\\c catdb;\n\\pset null '[NULL]' -- how to display null values\n\nCREATE TABLE humans (\n  name text primary key\n);\nCREATE TABLE cats (\n  human_name text references humans(name),\n  name text\n);\n\nINSERT INTO humans (name)\nVALUES ('Abe'), ('Ann'), ('Ben'), ('Jen');\n\nINSERT INTO cats (human_name, name)\nVALUES\n('Abe', 'Axel'),\n(NULL, 'Bitty'),\n('Jen', 'Jellybean'),\n('Jen', 'Juniper');\n\nQuerying\n\nHere's a query we'll run several times, changing [SOMETHING JOIN] to the various types to see the results.\n\nSELECT\nhumans.name AS human_name,\ncats.name AS cat_name\nFROM humans\n[SOMETHING JOIN] cats ON humans.name = cats.human_name\nORDER BY humans.name;\n\n\nAn INNER JOIN returns all human-cat pairs. Any human without a cat or cat without a human is excluded.\n\n human_name | cat_name\n------------+-----------\n Abe        | Axel\n Jen        | Jellybean\n Jen        | Juniper\n\n\nA FULL OUTER JOIN returns all humans and all cats, with NULL if there is no match on either side.\n\n human_name | cat_name\n------------+-----------\n Abe        | Axel\n Ann        | [NULL]\n Ben        | [NULL]\n Jen        | Jellybean\n Jen        | Juniper\n [NULL]     | Bitty\n\n\nA LEFT OUTER JOIN returns all humans (the left table). Any human without a cat gets a NULL in the cat_name column. Any cat without a human is excluded.\n\n human_name | cat_name\n------------+-----------\n Abe        | Axel\n Ann        | [NULL]\n Ben        | [NULL]\n Jen        | Jellybean\n Jen        | Juniper\n\n\nA RIGHT OUTER JOIN returns all cats (the right table). Any cat without a human gets a NULL in the human_name column. Any human without a cat is excluded.\n\n human_name | cat_name\n------------+-----------\n Abe        | Axel\n Jen        | Jellybean\n Jen        | Juniper\n [NULL]     | Bitty\n\nINNER vs OUTER\n\nYou can see that while an INNER JOIN gets only matching pairs, each kind of OUTER join includes some items without a match.\n\nHowever, the actual words INNER and OUTER do not need to appear in queries:\n\nJOIN by itself implies INNER\nLEFT JOIN, RIGHT JOIN and OUTER JOIN all imply OUTER\nShare\nImprove this answer\nFollow\nedited Apr 23 at 19:44\nanswered Apr 23 at 19:38\nNathan Long\n115k91\n91 gold badges\n317\n317 silver badges\n420\n420 bronze badges","comments":[]}]},{"id":"1144783","href":"https://stackoverflow.com/questions/1144783/how-to-replace-all-occurrences-of-a-string-in-javascript","title":"How to replace all occurrences of a string in JavaScript","description":"\n                \nI have this string in my JavaScript code:\n\"Test abc test test abc test test test abc test test abc\"\n\nDoing:\nstr = str.replace('abc', '');\n\nSeems to only remove the first occurrence of abc in the string above.\nHow can I replace all occurrences of it?\n    ","questionComments":["When replacing all occurrences of aba in ababa with ca, which result do you expect? caba? abca? cca?","String.prototype.replaceAll() is now a standard part of ECMAScript tc39.es/ecma262/#sec-string.prototype.replaceall, documented at developer.mozilla.org/docs/Web/JavaScript/Reference/… and shipped in Safari 13.1, Firefox 77 and Chrome Dev/Canary and will ship in Chrome 85. From the docs: “If searchValue is a string, replaces all occurrences of searchValue (as if .split(searchValue).join(replaceValue) or a global & properly-escaped regular expression had been used). If searchValue is a non-global regular expression, throws an exception”","Use regex instead of string, should look like str.replace(/abc/g, ''); so g to get all matches."],"answers":[{"answer":"Update: In the latest versions of most popular browsers, you can use replaceAll as shown here:\n\nlet result = \"1 abc 2 abc 3\".replaceAll(\"abc\", \"xyz\");\n// `result` is \"1 xyz 2 xyz 3\"\n\n\nBut check Can I use or another compatibility table first to make sure the browsers you're targeting have added support for it first.\n\nFor Node and compatibility with older/non-current browsers:\n\nNote: Don't use the following solution in performance critical code.\n\nAs an alternative to regular expressions for a simple literal string, you could use\n\nstr = \"Test abc test test abc test...\".split(\"abc\").join(\"\");\n\n\nThe general pattern is\n\nstr.split(search).join(replacement)\n\n\nThis used to be faster in some cases than using replaceAll and a regular expression, but that doesn't seem to be the case anymore in modern browsers.\n\nBenchmark: https://jsben.ch/TZYzj\n\nConclusion: If you have a performance critical use case (e.g processing hundreds of strings), use the Regexp method. But for most typical use cases, this is well worth not having to worry about special characters.\n\nShare\nImprove this answer\nFollow\nedited Jun 1 at 13:14\nEscapeNetscape\n2,5041\n1 gold badge\n28\n28 silver badges\n31\n31 bronze badges\nanswered Jul 17 '09 at 20:29\nMatthew Crumley\n96.6k24\n24 gold badges\n105\n105 silver badges\n126\n126 bronze badges","comments":["Funny that they needed more than 20 years to add a function like replaceAll.","I discourage from using replaceAll at this moment (2020). It is not supported by some browsers that had updates in this year caniuse.com/?search=replaceAll It is too early","NodeJS supports replaceAll in 15.x versions.","@Remirror haha! true"]},{"answer":"As of August 2020: Modern browsers have support for the String.replaceAll() method defined by the ECMAScript 2021 language specification.\n\nFor older/legacy browsers:\n\nstr = str.replace(/abc/g, '');\n\n\nIn response to comment:\n\nvar find = 'abc';\nvar re = new RegExp(find, 'g');\n\nstr = str.replace(re, '');\n\n\nIn response to Click Upvote's comment, you could simplify it even more:\n\nfunction replaceAll(str, find, replace) {\n  return str.replace(new RegExp(find, 'g'), replace);\n}\n\n\nNote: Regular expressions contain special (meta) characters, and as such it is dangerous to blindly pass an argument in the find function above without pre-processing it to escape those characters. This is covered in the Mozilla Developer Network's JavaScript Guide on Regular Expressions, where they present the following utility function (which has changed at least twice since this answer was originally written, so make sure to check the MDN site for potential updates):\n\nfunction escapeRegExp(string) {\n  return string.replace(/[.*+\\-?^${}()|[\\]\\\\]/g, '\\\\$&'); // $& means the whole matched string\n}\n\n\nSo in order to make the replaceAll() function above safer, it could be modified to the following if you also include escapeRegExp:\n\nfunction replaceAll(str, find, replace) {\n  return str.replace(new RegExp(escapeRegExp(find), 'g'), replace);\n}\n\nShare\nImprove this answer\nFollow\nedited May 24 at 17:30\nanswered Jul 17 '09 at 17:54\nSean Bright\n111k17\n17 gold badges\n131\n131 silver badges\n139\n139 bronze badges","comments":[]},{"answer":"For the sake of completeness, I got to thinking about which method I should use to do this. There are basically two ways to do this as suggested by the other answers on this page.\n\nNote: In general, extending the built-in prototypes in JavaScript is generally not recommended. I am providing as extensions on the String prototype simply for purposes of illustration, showing different implementations of a hypothetical standard method on the String built-in prototype.\n\nRegular Expression Based Implementation\nString.prototype.replaceAll = function(search, replacement) {\n    var target = this;\n    return target.replace(new RegExp(search, 'g'), replacement);\n};\n\nSplit and Join (Functional) Implementation\nString.prototype.replaceAll = function(search, replacement) {\n    var target = this;\n    return target.split(search).join(replacement);\n};\n\n\nNot knowing too much about how regular expressions work behind the scenes in terms of efficiency, I tended to lean toward the split and join implementation in the past without thinking about performance. When I did wonder which was more efficient, and by what margin, I used it as an excuse to find out.\n\nOn my Chrome Windows 8 machine, the regular expression based implementation is the fastest, with the split and join implementation being 53% slower. Meaning the regular expressions are twice as fast for the lorem ipsum input I used.\n\nCheck out this benchmark running these two implementations against each other.\n\nAs noted in the comment below by @ThomasLeduc and others, there could be an issue with the regular expression-based implementation if search contains certain characters which are reserved as special characters in regular expressions. The implementation assumes that the caller will escape the string beforehand or will only pass strings that are without the characters in the table in Regular Expressions (MDN).\n\nMDN also provides an implementation to escape our strings. It would be nice if this was also standardized as RegExp.escape(str), but alas, it does not exist:\n\nfunction escapeRegExp(str) {\n  return str.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\"); // $& means the whole matched string\n}\n\n\nWe could call escapeRegExp within our String.prototype.replaceAll implementation, however, I'm not sure how much this will affect the performance (potentially even for strings for which the escape is not needed, like all alphanumeric strings).\n\nShare\nImprove this answer\nFollow\nedited May 27 '17 at 21:55\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 12 '13 at 1:46\nCory Gross\n35.5k16\n16 gold badges\n61\n61 silver badges\n78\n78 bronze badges","comments":[]},{"answer":"Using a regular expression with the g flag set will replace all:\n\nsomeString = 'the cat looks like a cat';\nanotherString = someString.replace(/cat/g, 'dog');\n// anotherString now contains \"the dog looks like a dog\"\n\nSee here also\nShare\nImprove this answer\nFollow\nedited May 17 '16 at 12:15\nR3tep\n11.3k9\n9 gold badges\n39\n39 silver badges\n69\n69 bronze badges\nanswered May 6 '09 at 23:18\nAdam A\n13.6k6\n6 gold badges\n27\n27 silver badges\n37\n37 bronze badges","comments":[]},{"answer":"Here's a string prototype function based on the accepted answer:\n\nString.prototype.replaceAll = function (find, replace) {\n    var str = this;\n    return str.replace(new RegExp(find, 'g'), replace);\n};\n\n\nEDIT\n\nIf your find will contain special characters then you need to escape them:\n\nString.prototype.replaceAll = function (find, replace) {\n    var str = this;\n    return str.replace(new RegExp(find.replace(/[-\\/\\\\^$*+?.()|[\\]{}]/g, '\\\\$&'), 'g'), replace);\n};\n\n\nFiddle: http://jsfiddle.net/cdbzL/\n\nShare\nImprove this answer\nFollow\nedited Oct 7 '13 at 16:40\nanswered Feb 11 '13 at 23:03\njesal\n7,1345\n5 gold badges\n47\n47 silver badges\n51\n51 bronze badges","comments":[]},{"answer":"Update:\n\nIt's somewhat late for an update, but since I just stumbled on this question, and noticed that my previous answer is not one I'm happy with. Since the question involved replaceing a single word, it's incredible nobody thought of using word boundaries (\\b)\n\n'a cat is not a caterpillar'.replace(/\\bcat\\b/gi,'dog');\n//\"a dog is not a caterpillar\"\n\n\nThis is a simple regex that avoids replacing parts of words in most cases. However, a dash - is still considered a word boundary. So conditionals can be used in this case to avoid replacing strings like cool-cat:\n\n'a cat is not a cool-cat'.replace(/\\bcat\\b/gi,'dog');//wrong\n//\"a dog is not a cool-dog\" -- nips\n'a cat is not a cool-cat'.replace(/(?:\\b([^-]))cat(?:\\b([^-]))/gi,'$1dog$2');\n//\"a dog is not a cool-cat\"\n\n\nbasically, this question is the same as the question here: Javascript replace \" ' \" with \" '' \"\n\n@Mike, check the answer I gave there... regexp isn't the only way to replace multiple occurrences of a subsrting, far from it. Think flexible, think split!\n\nvar newText = \"the cat looks like a cat\".split('cat').join('dog');\n\n\nAlternatively, to prevent replacing word parts -which the approved answer will do, too! You can get around this issue using regular expressions that are, I admit, somewhat more complex and as an upshot of that, a tad slower, too:\n\nvar regText = \"the cat looks like a cat\".replace(/(?:(^|[^a-z]))(([^a-z]*)(?=cat)cat)(?![a-z])/gi,\"$1dog\");\n\n\nThe output is the same as the accepted answer, however, using the /cat/g expression on this string:\n\nvar oops = 'the cat looks like a cat, not a caterpillar or coolcat'.replace(/cat/g,'dog');\n//returns \"the dog looks like a dog, not a dogerpillar or cooldog\" ?? \n\n\nOops indeed, this probably isn't what you want. What is, then? IMHO, a regex that only replaces 'cat' conditionally. (ie not part of a word), like so:\n\nvar caterpillar = 'the cat looks like a cat, not a caterpillar or coolcat'.replace(/(?:(^|[^a-z]))(([^a-z]*)(?=cat)cat)(?![a-z])/gi,\"$1dog\");\n//return \"the dog looks like a dog, not a caterpillar or coolcat\"\n\n\nMy guess is, this meets your needs. It's not fullproof, of course, but it should be enough to get you started. I'd recommend reading some more on these pages. This'll prove useful in perfecting this expression to meet your specific needs.\n\nhttp://www.javascriptkit.com/jsref/regexp.shtml\n\nhttp://www.regular-expressions.info\n\nFinal addition:\n\nGiven that this question still gets a lot of views, I thought I might add an example of .replace used with a callback function. In this case, it dramatically simplifies the expression and provides even more flexibility, like replacing with correct capitalisation or replacing both cat and cats in one go:\n\n'Two cats are not 1 Cat! They\\'re just cool-cats, you caterpillar'\n   .replace(/(^|.\\b)(cat)(s?\\b.|$)/gi,function(all,char1,cat,char2)\n    {\n       //check 1st, capitalize if required\n       var replacement = (cat.charAt(0) === 'C' ? 'D' : 'd') + 'og';\n       if (char1 === ' ' && char2 === 's')\n       {//replace plurals, too\n           cat = replacement + 's';\n       }\n       else\n       {//do not replace if dashes are matched\n           cat = char1 === '-' || char2 === '-' ? cat : replacement;\n       }\n       return char1 + cat + char2;//return replacement string\n    });\n//returns:\n//Two dogs are not 1 Dog! They're just cool-cats, you caterpillar\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:47\nCommunity♦\n11\n1 silver badge\nanswered Mar 1 '12 at 10:02\nElias Van Ootegem\n68.6k9\n9 gold badges\n101\n101 silver badges\n141\n141 bronze badges","comments":[]},{"answer":"Match against a global regular expression:\n\nanotherString = someString.replace(/cat/g, 'dog');\n\nShare\nImprove this answer\nFollow\nanswered May 6 '09 at 23:23\nscronide\n11.3k3\n3 gold badges\n26\n26 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"For replacing a single time use:\n\nvar res = str.replace('abc', \"\");\n\n\nFor replacing multiple times use:\n\nvar res = str.replace(/abc/g, \"\");\n\nShare\nImprove this answer\nFollow\nedited May 29 '19 at 12:33\nMihai Chelaru\n6,03514\n14 gold badges\n37\n37 silver badges\n46\n46 bronze badges\nanswered May 29 '19 at 11:11\nIndrajeet Singh\n2,74522\n22 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"These are the most common and readable methods.\n\nvar str = \"Test abc test test abc test test test abc test test abc\"\n\n\nMethod 1:\n\nstr = str.replace(/abc/g, \"replaced text\");\n\n\nMethod 2:\n\nstr = str.split(\"abc\").join(\"replaced text\");\n\n\nMethod 3:\n\nstr = str.replace(new RegExp(\"abc\", \"g\"), \"replaced text\");\n\n\nMethod 4:\n\nwhile(str.includes(\"abc\")){\n    str = str.replace(\"abc\", \"replaced text\");\n}\n\n\nOutput:\n\nconsole.log(str);\n// Test replaced text test test replaced text test test test replaced text test test replaced text\n\nShare\nImprove this answer\nFollow\nedited Mar 8 '20 at 18:27\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 25 '19 at 9:38\nAdnan Toky\n1,2028\n8 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"str = str.replace(/abc/g, '');\n\n\nOr try the replaceAll method, as recommended in this answer:\n\nstr = str.replaceAll('abc', '');\n\n\nor:\n\nvar search = 'abc';\nstr = str.replaceAll(search, '');\n\n\nEDIT: Clarification about replaceAll availability\n\nThe replaceAll method is added to String's prototype. This means it will be available for all string objects/literals.\n\nExample:\n\nvar output = \"test this\".replaceAll('this', 'that'); // output is 'test that'.\noutput = output.replaceAll('that', 'this'); // output is 'test this'\n\nShare\nImprove this answer\nFollow\nedited May 10 at 9:18\nnik7\n7473\n3 gold badges\n9\n9 silver badges\n17\n17 bronze badges\nanswered Jul 17 '09 at 17:55\nSolutionYogi\n29.8k11\n11 gold badges\n68\n68 silver badges\n77\n77 bronze badges","comments":[]},{"answer":"Using RegExp in JavaScript could do the job for you, just simply do something like below code, don't forget the /g after which standout for global:\n\nvar str =\"Test abc test test abc test test test abc test test abc\";\nstr = str.replace(/abc/g, '');\n\n\nIf you think of reuse, create a function to do that for you, but it's not recommended as it's only one line function, but again if you heavily use this, you can write something like this:\n\nString.prototype.replaceAll = String.prototype.replaceAll || function(string, replaced) {\n  return this.replace(new RegExp(string, 'g'), replaced);\n};\n\n\nand simply use it in your code over and over like below:\n\nvar str =\"Test abc test test abc test test test abc test test abc\";\nstr = str.replaceAll('abc', '');\n\n\nBut as I mention earlier, it won't make a huge difference in terms of lines to be written or performance, only caching the function may effect some faster performance on long strings and also a good practice of DRY code if you want to reuse.\n\nShare\nImprove this answer\nFollow\nedited Oct 12 '19 at 5:18\nanswered Jun 6 '17 at 13:39\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"Say you want to replace all the 'abc' with 'x':\n\nlet some_str = 'abc def def lom abc abc def'.split('abc').join('x')\nconsole.log(some_str) //x def def lom x x def\n\n\nI was trying to think about something more simple than modifying the string prototype.\n\nShare\nImprove this answer\nFollow\nedited May 27 '17 at 22:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 10 '16 at 14:59\nEmilio Grisolía\n1,0931\n1 gold badge\n9\n9 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"Use a regular expression:\n\nstr.replace(/abc/g, '');\n\nShare\nImprove this answer\nFollow\nedited May 27 '17 at 21:56\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 17 '09 at 17:56\nDonnie DeBoer\n2,41715\n15 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"Replacing single quotes:\n\nfunction JavaScriptEncode(text){\n    text = text.replace(/'/g,'&apos;')\n    // More encode here if required\n\n    return text;\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 17 '17 at 15:53\nTermininja\n5,85912\n12 gold badges\n42\n42 silver badges\n46\n46 bronze badges\nanswered Jun 19 '15 at 21:24\nChris Rosete\n1,14114\n14 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"Performance\n\nToday 27.12.2019 I perform tests on macOS v10.13.6 (High Sierra) for the chosen solutions.\n\nConclusions\n\nThe str.replace(/abc/g, ''); (C) is a good cross-browser fast solution for all strings.\nSolutions based on split-join (A,B) or replace (C,D) are fast\nSolutions based on while (E,F,G,H) are slow - usually ~4 times slower for small strings and about ~3000 times (!) slower for long strings\nThe recurrence solutions (RA,RB) are slow and do not work for long strings\n\nI also create my own solution. It looks like currently it is the shortest one which does the question job:\n\nstr.split`abc`.join``\n\n\nShow code snippet\n\nDetails\n\nThe tests were performed on Chrome 79.0, Safari 13.0.4 and Firefox 71.0 (64 bit). The tests RA and RB use recursion. Results\n\nShort string - 55 characters\n\nYou can run tests on your machine HERE. Results for Chrome:\n\nLong string: 275 000 characters\n\nThe recursive solutions RA and RB gives\n\nRangeError: Maximum call stack size exceeded\n\nFor 1M characters they even break Chrome\n\nI try to perform tests for 1M characters for other solutions, but E,F,G,H takes so much time that browser ask me to break script so I shrink test string to 275K characters. You can run tests on your machine HERE. Results for Chrome\n\nCode used in tests\n\nShow code snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Dec 27 '19 at 16:03\nKamil Kiełczewski\n57.6k22\n22 gold badges\n275\n275 silver badges\n253\n253 bronze badges","comments":["Now this is one hell of an in depth answer! Thank you very much! Although, what I'm curious about is why the \"new RegExp(...)\" syntax gives that much of an improvement."]},{"answer":"str = str.replace(new RegExp(\"abc\", 'g'), \"\");\n\n\nworked better for me than the above answers. so new RegExp(\"abc\", 'g') creates a RegExp what matches all occurence ('g' flag) of the text (\"abc\"). The second part is what gets replaced to, in your case empty string (\"\"). str is the string, and we have to override it, as replace(...) just returns result, but not overrides. In some cases you might want to use that.\n\nShare\nImprove this answer\nFollow\nedited Dec 29 '17 at 17:52\nanswered Dec 28 '17 at 12:27\ncsomakk\n4,9511\n1 gold badge\n25\n25 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"This is the fastest version that doesn't use regular expressions.\n\nRevised jsperf\n\nreplaceAll = function(string, omit, place, prevstring) {\n  if (prevstring && string === prevstring)\n    return string;\n  prevstring = string.replace(omit, place);\n  return replaceAll(prevstring, omit, place, string)\n}\n\n\nIt is almost twice as fast as the split and join method.\n\nAs pointed out in a comment here, this will not work if your omit variable contains place, as in: replaceAll(\"string\", \"s\", \"ss\"), because it will always be able to replace another occurrence of the word.\n\nThere is another jsperf with variants on my recursive replace that go even faster (http://jsperf.com/replace-all-vs-split-join/12)!\n\nUpdate July 27th 2017: It looks like RegExp now has the fastest performance in the recently released Chrome 59.\nShare\nImprove this answer\nFollow\nedited Jul 27 '17 at 15:57\nanswered Apr 4 '14 at 18:49\nCole Lawrence\n5955\n5 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"Loop it until number occurrences comes to 0, like this:\n\nfunction replaceAll(find, replace, str) {\n    while (str.indexOf(find) > -1) {\n        str = str.replace(find, replace);\n    }\n    return str;\n}\n\nShare\nImprove this answer\nFollow\nedited May 10 at 7:07\nnik7\n7473\n3 gold badges\n9\n9 silver badges\n17\n17 bronze badges\nanswered Jun 5 '13 at 4:57\nRaseela\n2853\n3 silver badges\n2\n2 bronze badges","comments":["This method is dangerous, do not use it. If the replacement string contains the search keyword, then an infinite loop will occur. At the very least, store the result of .indexOf in a variable, and use this variable as the second parameter of .indexOf (minus length of keyword, plus length of replacement string)."]},{"answer":"If what you want to find is already in a string, and you don't have a regex escaper handy, you can use join/split:\n\n    function replaceMulti(haystack, needle, replacement)\n    {\n        return haystack.split(needle).join(replacement);\n    }\n\n    someString = 'the cat looks like a cat';\n    console.log(replaceMulti(someString, 'cat', 'dog'));\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '18 at 17:42\nPitu\n898\n8 bronze badges\nanswered Jun 19 '13 at 23:21\nrakslice\n7,9463\n3 gold badges\n47\n47 silver badges\n52\n52 bronze badges","comments":[]},{"answer":"function replaceAll(str, find, replace) {\n  var i = str.indexOf(find);\n  if (i > -1){\n    str = str.replace(find, replace); \n    i = i + replace.length;\n    var st2 = str.substring(i);\n    if(st2.indexOf(find) > -1){\n      str = str.substring(0,i) + replaceAll(st2, find, replace);\n    }       \n  }\n  return str;\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 29 '14 at 19:17\nanswered Sep 29 '14 at 19:12\nTim Rivoli\n1901\n1 silver badge\n5\n5 bronze badges","comments":[]},{"answer":"I like this method (it looks a little cleaner):\n\ntext = text.replace(new RegExp(\"cat\",\"g\"), \"dog\"); \n\nShare\nImprove this answer\nFollow\nedited May 27 '17 at 21:57\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 15 '13 at 14:03\nOwen\n3,7015\n5 gold badges\n39\n39 silver badges\n48\n48 bronze badges","comments":[]},{"answer":"var str = \"ff ff f f a de def\";\nstr = str.replace(/f/g,'');\nalert(str);\n\n\nhttp://jsfiddle.net/ANHR9/\n\nShare\nImprove this answer\nFollow\nanswered Sep 4 '13 at 10:01\npkdkk\n3,4977\n7 gold badges\n38\n38 silver badges\n65\n65 bronze badges","comments":[]},{"answer":"while (str.indexOf('abc') !== -1)\n{\n    str = str.replace('abc', '');\n}\n\nShare\nImprove this answer\nFollow\nanswered Apr 29 '14 at 10:25\nzdennis\n1671\n1 silver badge\n2\n2 bronze badges","comments":[]},{"answer":"The simplest way to this without using any regex is split and join like the code here:\n\nvar str = \"Test abc test test abc test test test abc test test abc\";\nconsole.log(str.split('abc').join(''));\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Feb 15 at 8:09\nRan Marciano\n1,2625\n5 gold badges\n9\n9 silver badges\n25\n25 bronze badges\nanswered May 14 '19 at 18:42\nsajadre\n9502\n2 gold badges\n10\n10 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"If the string contain similar pattern like abccc, you can use this:\n\nstr.replace(/abc(\\s|$)/g, \"\")\n\nShare\nImprove this answer\nFollow\nedited Apr 27 '18 at 8:49\ncommunity wiki\n\n\n3 revs, 2 users 78%\nmostafa elmadany","comments":[]},{"answer":"The previous answers are way too complicated. Just use the replace function like this:\n\nstr.replace(/your_regex_pattern/g, replacement_string);\n\n\nExample:\n\nvar str = \"Test abc test test abc test test test abc test test abc\";\n\nvar res = str.replace(/[abc]+/g, \"\");\n\nconsole.log(res);\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Nov 18 '18 at 3:27\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 23 '18 at 9:34\nBlack\n13.3k27\n27 gold badges\n121\n121 silver badges\n203\n203 bronze badges","comments":[]},{"answer":"As of August 2020 there is a Stage 4 proposal to ECMAScript that adds the replaceAll method to String.\n\nIt's now supported in Chrome 85+, Edge 85+, Firefox 77+, Safari 13.1+.\n\nThe usage is the same as the replace method:\n\nString.prototype.replaceAll(searchValue, replaceValue)\n\n\nHere's an example usage:\n\n'Test abc test test abc test.'.replaceAll('abc', 'foo'); // -> 'Test foo test test foo test.'\n\n\nIt's supported in most modern browsers, but there exist polyfills:\n\ncore-js\nes-shims\n\nIt is supported in the V8 engine behind an experimental flag --harmony-string-replaceall. Read more on the V8 website.\n\nShare\nImprove this answer\nFollow\nedited Aug 24 '20 at 11:09\nanswered Nov 11 '19 at 7:25\nThomas Orlita\n1,32913\n13 silver badges\n24\n24 bronze badges","comments":["According to MDN, this has been available since Firefox 77 and Chromium 85."]},{"answer":"If you are trying to ensure that the string you are looking for won't exist even after the replacement, you need to use a loop.\n\nFor example:\n\nvar str = 'test aabcbc';\nstr = str.replace(/abc/g, '');\n\n\nWhen complete, you will still have 'test abc'!\n\nThe simplest loop to solve this would be:\n\nvar str = 'test aabcbc';\nwhile (str != str.replace(/abc/g, '')){\n   str.replace(/abc/g, '');\n}\n\n\nBut that runs the replacement twice for each cycle. Perhaps (at risk of being voted down) that can be combined for a slightly more efficient but less readable form:\n\nvar str = 'test aabcbc';\nwhile (str != (str = str.replace(/abc/g, ''))){}\n// alert(str); alerts 'test '!\n\n\nThis can be particularly useful when looking for duplicate strings.\nFor example, if we have 'a,,,b' and we wish to remove all duplicate commas.\n[In that case, one could do .replace(/,+/g,','), but at some point the regex gets complex and slow enough to loop instead.]\n\nShare\nImprove this answer\nFollow\nanswered Sep 28 '14 at 19:58\nSamGoody\n12.1k8\n8 gold badges\n71\n71 silver badges\n85\n85 bronze badges","comments":[]},{"answer":"Although people have mentioned the use of regex but there's a better approach if you want to replace the text irrespective of the case of the text. Like uppercase or lowercase. Use below syntax\n\n//Consider below example\noriginalString.replace(/stringToBeReplaced/gi, '');\n\n//Output will be all the occurrences removed irrespective of casing.\n\n\nYou can refer the detailed example here.\n\nShare\nImprove this answer\nFollow\nedited Jun 8 '16 at 18:51\nevandrix\n5,6854\n4 gold badges\n25\n25 silver badges\n34\n34 bronze badges\nanswered May 3 '16 at 18:39\nCheezy Code\n1,6051\n1 gold badge\n12\n12 silver badges\n17\n17 bronze badges","comments":["from the example site: \"/toBeReplacedString/gi is the regex you need to use. Here g represents for global match and i represents case insensitive. By default regex is case sensitive\""]},{"answer":"Just add /g\n\n\ndocument.body.innerHTML = document.body.innerHTML.replace('hello', 'hi');\n\n\nto\n\n// Replace 'hello' string with /hello/g regular expression.\ndocument.body.innerHTML = document.body.innerHTML.replace(/hello/g, 'hi');\n\n\n/g means global\n\nShare\nImprove this answer\nFollow\nedited Oct 15 '15 at 12:13\nValentin Podkamennyi\n6,6174\n4 gold badges\n24\n24 silver badges\n41\n41 bronze badges\nanswered Jun 5 '15 at 7:16\nReza Fahmi\n2503\n3 silver badges\n10\n10 bronze badges","comments":[]}]},{"id":"901712","href":"https://stackoverflow.com/questions/901712/how-do-i-check-whether-a-checkbox-is-checked-in-jquery","title":"How do I check whether a checkbox is checked in jQuery?","description":"\n                \nI need to check the checked property of a checkbox and perform an action based on the checked property using jQuery.\nFor example, if the age checkbox is checked, then I need to show a textbox to enter age, else hide the textbox.\nBut the following code returns false by default:\n\n\nif ($('#isAgeSelected').attr('checked')) {\n  $(\"#txtAge\").show();\n} else {\n  $(\"#txtAge\").hide();\n}\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<input type=\"checkbox\" id=\"isAgeSelected\"/>\n<div id=\"txtAge\" style=\"display:none\">\n  Age is selected\n</div>\n Run code snippetHide resultsExpand snippet\n\n\nHow do I successfully query the checked property?\n    ","questionComments":["Check some other ways to do this using jQuery here stackoverflow.com/a/22019103/1868660","related stackoverflow.com/questions/4086957/…","why not $('#isAgeSelected').checked","For a comprehensive ( and correct ) answer see: stackoverflow.com/questions/426258/…","Since jQuery selectors return array, you can use $('#isAgeSelected')[0].checked"],"answers":[{"answer":"How do I successfully query the checked property?\n\nThe checked property of a checkbox DOM element will give you the checked state of the element.\n\nGiven your existing code, you could therefore do this:\n\nif(document.getElementById('isAgeSelected').checked) {\n    $(\"#txtAge\").show();\n} else {\n    $(\"#txtAge\").hide();\n}\n\n\nHowever, there's a much prettier way to do this, using toggle:\n\n$('#isAgeSelected').click(function() {\n    $(\"#txtAge\").toggle(this.checked);\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<input type=\"checkbox\" id=\"isAgeSelected\"/>\n<div id=\"txtAge\" style=\"display:none\">Age is something</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '18 at 2:06\ncommunity wiki\n\n\n11 revs, 9 users 36%\nkarim79","comments":["This is not an answer to the question. this.checked is not jQuery, as the OP asked for. Also, it only works when user clicks on the checkbox, which is not part of the question. The question is, again, How to check whether a checkbox is checked in jQuery? at any given time with or without clicking the checkbox and in jQuery."]},{"answer":"Use jQuery's is() function:\n\nif($(\"#isAgeSelected\").is(':checked'))\n    $(\"#txtAge\").show();  // checked\nelse\n    $(\"#txtAge\").hide();  // unchecked\n\nShare\nImprove this answer\nFollow\nedited Aug 23 '12 at 3:42\ncommunity wiki\n\n\nBhanu Krishnan","comments":["A little bit cleaner solution would be $(\"#txtAge\").toggle($(\"#isAgeSelected\").is(':checked'))."]},{"answer":"Using jQuery > 1.6\n\n<input type=\"checkbox\" value=\"1\" name=\"checkMeOut\" id=\"checkMeOut\" checked=\"checked\" />\n\n// traditional attr\n$('#checkMeOut').attr('checked'); // \"checked\"\n// new property method\n$('#checkMeOut').prop('checked'); // true\n\n\nUsing the new property method:\n\nif($('#checkMeOut').prop('checked')) {\n    // something when checked\n} else {\n    // something else when not\n}\n\nShare\nImprove this answer\nFollow\nanswered Jun 23 '11 at 17:29\ncommunity wiki\n\n\nSeanDowney","comments":[]},{"answer":"jQuery 1.6+\n\n$('#isAgeSelected').prop('checked')\n\n\njQuery 1.5 and below\n\n$('#isAgeSelected').attr('checked')\n\n\nAny version of jQuery\n\n// Assuming an event handler on a checkbox\nif (this.checked)\n\n\nAll credit goes to Xian.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:26\ncommunity wiki\n\n\n4 revs, 3 users 81%\nungalcrys","comments":["Technically, this.checked is using straight Javascript. But I love that cross-jQuery-version answer!"]},{"answer":"I am using this and this is working absolutely fine:\n\n$(\"#checkkBoxId\").attr(\"checked\") ? alert(\"Checked\") : alert(\"Unchecked\");\n\n\nNote: If the checkbox is checked it will return true otherwise undefined, so better check for the \"TRUE\" value.\n\nShare\nImprove this answer\nFollow\nedited May 7 '14 at 12:18\ncommunity wiki\n\n\n3 revs, 3 users 71%\nPradeep","comments":[]},{"answer":"Use:\n\n<input type=\"checkbox\" name=\"planned_checked\" checked id=\"planned_checked\"> Planned\n\n$(\"#planned_checked\").change(function() {\n    if($(this).prop('checked')) {\n        alert(\"Checked Box Selected\");\n    } else {\n        alert(\"Checked Box deselect\");\n    }\n});\n\n\n    $(\"#planned_checked\").change(function() {\n        if($(this).prop('checked')) {\n            alert(\"Checked Box Selected\");\n        } else {\n            alert(\"Checked Box deselect\");\n        }\n    });\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js\"></script>\n<input type=\"checkbox\" name=\"planned_checked\" checked id=\"planned_checked\"> Planned\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 15 '18 at 7:16\ncommunity wiki\n\n\n4 revs, 4 users 39%\nLalji Dhameliya","comments":[]},{"answer":"Since jQuery 1.6, the behavior of jQuery.attr() has changed and users are encouraged not to use it to retrieve an element's checked state. Instead, you should use jQuery.prop():\n\n$(\"#txtAge\").toggle(\n    $(\"#isAgeSelected\").prop(\"checked\") // For checked attribute it returns true/false;\n                                        // Return value changes with checkbox state\n);\n\n\nTwo other possibilities are:\n\n$(\"#txtAge\").get(0).checked\n$(\"#txtAge\").is(\":checked\")\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 17:10\ncommunity wiki\n\n\n3 revs, 2 users 81%\nSalman A","comments":[]},{"answer":"This worked for me:\n\n$get(\"isAgeSelected \").checked == true\n\n\nWhere isAgeSelected is the id of the control.\n\nAlso, @karim79's answer works fine. I am not sure what I missed at the time I tested it.\n\nNote, this is answer uses Microsoft Ajax, not jQuery\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\ncommunity wiki\n\n\n6 revs, 4 users 62%\nPrasad","comments":[]},{"answer":"If you are using an updated version of jquery, you must go for .prop method to resolve your issue:\n\n$('#isAgeSelected').prop('checked') will return true if checked and false if unchecked. I confirmed it and I came across this issue earlier. $('#isAgeSelected').attr('checked') and $('#isAgeSelected').is('checked') is returning undefined which is not a worthy answer for the situation. So do as given below.\n\nif($('#isAgeSelected').prop('checked')) {\n    $(\"#txtAge\").show();\n} else {\n    $(\"#txtAge\").hide();\n}\n\n\nHope it helps :)- Thanks.\n\nShare\nImprove this answer\nFollow\nedited Sep 12 '15 at 16:10\ncommunity wiki\n\n\n2 revs\nRajesh Omanakuttan","comments":[]},{"answer":"Use:\n\n<input type=\"checkbox\" id=\"abc\" value=\"UDB\">UDB\n<input type=\"checkbox\" id=\"abc\" value=\"Prasad\">Prasad\n\n$('input#abc').click(function(){\n  if($(this).is(':checked'))\n  {\n    var checkedOne=$(this).val()\n    alert(checkedOne);\n\n    // Do some other action\n  }\n})\n\n\nThis can help if you want that the required action has to be done only when you check the box not at the time you remove the check.\n\nShare\nImprove this answer\nFollow\nedited Oct 29 '18 at 10:25\ncommunity wiki\n\n\n3 revs, 3 users 81%\nUDB","comments":[]},{"answer":"Using the Click event handler for the checkbox property is unreliable, as the checked property can change during the execution of the event handler itself!\n\nIdeally, you'd want to put your code into a change event handler such as it is fired every time the value of the check box is changed (independent of how it's done so).\n\n$('#isAgeSelected').bind('change', function () {\n\n   if ($(this).is(':checked'))\n     $(\"#txtAge\").show();\n   else\n     $(\"#txtAge\").hide();\n});\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 17:09\ncommunity wiki\n\n\n2 revs, 2 users 75%\narviman","comments":[]},{"answer":"I decided to post an answer on how to do that exact same thing without jQuery. Just because I'm a rebel.\n\nvar ageCheckbox = document.getElementById('isAgeSelected');\nvar ageInput = document.getElementById('txtAge');\n\n// Just because of IE <333\nageCheckbox.onchange = function() {\n    // Check if the checkbox is checked, and show/hide the text field.\n    ageInput.hidden = this.checked ? false : true;\n};\n\n\nFirst you get both elements by their ID. Then you assign the checkboxe's onchange event a function that checks whether the checkbox got checked and sets the hidden property of the age text field appropriately. In that example using the ternary operator.\n\nHere is a fiddle for you to test it.\n\nAddendum\n\nIf cross-browser compatibility is an issue then I propose to set the CSS display property to none and inline.\n\nelem.style.display = this.checked ? 'inline' : 'none';\n\n\nSlower but cross-browser compatible.\n\nShare\nImprove this answer\nFollow\nedited Apr 5 '12 at 15:50\ncommunity wiki\n\n\nOctavian A. Damiean","comments":[]},{"answer":"I believe you could do this:\n\nif ($('#isAgeSelected :checked').size() > 0)\n{\n    $(\"#txtAge\").show(); \n} else { \n    $(\"#txtAge\").hide();\n}\n\nShare\nImprove this answer\nFollow\nanswered May 23 '09 at 15:34\ncommunity wiki\n\n\nxenon","comments":[]},{"answer":"I ran in to the exact same issue. I have an ASP.NET checkbox\n\n<asp:CheckBox ID=\"chkBox1\" CssClass='cssChkBox1' runat=\"server\" />\n\n\nIn the jQuery code I used the following selector to check if the checkbox was checked or not, and it seems to work like a charm.\n\nif ($(\"'.cssChkBox1 input[type=checkbox]'\").is(':checked'))\n{ ... } else { ... }\n\n\nI'm sure you can also use the ID instead of the CssClass,\n\nif ($(\"'#cssChkBox1 input[type=checkbox]'\").is(':checked'))\n{ ... } else { ... }\n\n\nI hope this helps you.\n\nShare\nImprove this answer\nFollow\nedited May 25 '11 at 10:59\ncommunity wiki\n\n\nNertim","comments":[]},{"answer":"This code will help you\n\n$('#isAgeSelected').click(function(){\n   console.log(this.checked);\n   if(this.checked == true) {\n        $(\"#txtAge\").show();\n    } else {\n       $(\"#txtAge\").hide();\n   }\n});\n\nShare\nImprove this answer\nFollow\nedited Sep 3 '19 at 4:01\ncommunity wiki\n\n\n5 revs, 2 users 91%\nsandeep kumar","comments":[]},{"answer":"There are many ways to check if a checkbox is checked or not:\n\nWay to check using jQuery\n\nif (elem.checked)\nif ($(elem).prop(\"checked\"))\nif ($(elem).is(\":checked\"))\nif ($(elem).attr('checked'))\n\n\nCheck example or also document:\n\nhttp://api.jquery.com/attr/\n\nhttp://api.jquery.com/prop/\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 17:30\ncommunity wiki\n\n\n2 revs, 2 users 78%\nParth Chavda","comments":[]},{"answer":"You can try the change event of checkbox to track the :checked state change.\n\n$(\"#isAgeSelected\").on('change', function() {\n  if ($(\"#isAgeSelected\").is(':checked'))\n    alert(\"checked\");\n  else {\n    alert(\"unchecked\");\n  }\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<input type=\"checkbox\" id=\"isAgeSelected\" />\n<div id=\"txtAge\" style=\"display:none\">\n  Age is selected\n</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Sep 23 '20 at 15:39\ncommunity wiki\n\n\n2 revs, 2 users 55%\nkabirbaidhya","comments":[]},{"answer":"This works for me:\n\n/* isAgeSelected being id for checkbox */\n\n$(\"#isAgeSelected\").click(function(){\n  $(this).is(':checked') ? $(\"#txtAge\").show() : $(\"#txtAge\").hide();\n});\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 17:08\ncommunity wiki\n\n\n3 revs, 3 users 60%\nashish amatya","comments":[]},{"answer":"This is some different method to do the same thing:\n\n$(document).ready(function (){\n\n    $('#isAgeSelected').click(function() {\n        // $(\"#txtAge\").toggle(this.checked);\n\n        // Using a pure CSS selector\n        if ($(this.checked)) {\n            alert('on check 1');\n        };\n\n        // Using jQuery's is() method\n        if ($(this).is(':checked')) {\n            alert('on checked 2');\n        };\n\n        //  // Using jQuery's filter() method\n        if ($(this).filter(':checked')) {\n            alert('on checked 3');\n        };\n    });\n});\n<script src=\"http://code.jquery.com/jquery-1.9.1.js\"></script>\n<input type=\"checkbox\" id=\"isAgeSelected\"/>\n<div id=\"txtAge\" style=\"display:none\">Age is something</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 17:34\ncommunity wiki\n\n\n2 revs, 2 users 79%\nSangeet Shah","comments":[]},{"answer":"Use this:\n\nif ($('input[name=\"salary_in.Basic\"]:checked').length > 0)\n\n\nThe length is greater than zero if the checkbox is checked.\n\nShare\nImprove this answer\nFollow\nedited Jan 16 '17 at 8:51\ncommunity wiki\n\n\n3 revs, 3 users 55%\nHamid N K","comments":[]},{"answer":"My way of doing this is:\n\nif ( $(\"#checkbox:checked\").length ) {       \n    alert(\"checkbox is checked\");\n} else {\n    alert(\"checkbox is not checked\");\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 6 '15 at 20:52\ncommunity wiki\n\n\n2 revs, 2 users 80%\nDalius I","comments":[]},{"answer":"$(selector).attr('checked') !== undefined\n\n\nThis returns true if the input is checked and false if it is not.\n\nShare\nImprove this answer\nFollow\nedited Mar 21 '13 at 11:13\ncommunity wiki\n\n\nfe_lix_","comments":[]},{"answer":"$(document).ready(function() {    \n    $('#agecheckbox').click(function() {\n        if($(this).is(\":checked\"))\n        {\n            $('#agetextbox').show();\n        } else {\n            $('#agetextbox').hide();\n        }\n    });\n});\n\nShare\nImprove this answer\nFollow\nedited Nov 26 '14 at 15:07\ncommunity wiki\n\n\n3 revs, 2 users 78%\nJumper Pot","comments":[]},{"answer":"You can use:\n\n  if(document.getElementById('isAgeSelected').checked)\n    $(\"#txtAge\").show();  \n  else\n    $(\"#txtAge\").hide();\n\nif($(\"#isAgeSelected\").is(':checked'))\n  $(\"#txtAge\").show();  \nelse\n  $(\"#txtAge\").hide();\n\n\nBoth of them should work.\n\nShare\nImprove this answer\nFollow\nedited Sep 21 '16 at 15:21\ncommunity wiki\n\n\n2 revs, 2 users 97%\nMuhammad Awais","comments":[]},{"answer":"1) If your HTML markup is:\n\n<input type=\"checkbox\"  />\n\n\nattr used:\n\n$(element).attr(\"checked\"); // Will give you undefined as initial value of checkbox is not set\n\n\nIf prop is used:\n\n$(element).prop(\"checked\"); // Will give you false whether or not initial value is set\n\n\n2) If your HTML markup is:\n\n <input type=\"checkbox\"  checked=\"checked\" />// May be like this also  checked=\"true\"\n\n\nattr used:\n\n$(element).attr(\"checked\") // Will return checked whether it is checked=\"true\"\n\n\nProp used:\n\n$(element).prop(\"checked\") // Will return true whether checked=\"checked\"\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 17:25\ncommunity wiki\n\n\n3 revs, 3 users 77%\nSomnath Kharat","comments":["This is a REAL problem. My workaround - add a change event to the input: <input type=\"checkbox\" onchange=\"ChangeChkBox()\" /> then use that event to change a boolean JavaScript variable, and use the JavaScript variable instead of querying the checkbox directly."]},{"answer":"This example is for button.\n\nTry the following:\n\n<input type=\"button\" class=\"check\" id=\"checkall\" value=\"Check All\" />  &nbsp; <input type=\"button\" id=\"remove\" value=\"Delete\" /> <br/>\n\n<input type=\"checkbox\" class=\"cb-element\"  value=\"1\" /> Checkbox  1 <br/>\n<input type=\"checkbox\" class=\"cb-element\"  value=\"2\" /> Checkbox  2 <br/>\n<input type=\"checkbox\" class=\"cb-element\"  value=\"3\" /> Checkbox  3 <br/>\n\n\n$('#remove').attr('disabled', 'disabled'); \n\n$(document).ready(function() {  \n\n    $('.cb-element').click(function() {\n\n        if($(this).prop('checked'))\n        {\n            $('#remove').attr('disabled', false);\n        }\n        else\n        {\n            $('#remove').attr('disabled', true);\n        }\n    });   \n\n    $('.check:button').click(function()\n{\n    var checked = !$(this).data('checked');\n    $('input:checkbox').prop('checked', checked);\n    $(this).data('checked', checked);\n\n    if(checked == true)\n    {\n        $(this).val('Uncheck All');\n         $('#remove').attr('disabled', false);\n    }\n\n    else if(checked == false)\n    {\n        $(this).val('Check All');\n        $('#remove').attr('disabled', true);\n    }\n});\n});\n\nShare\nImprove this answer\nFollow\nedited Jun 2 '16 at 14:17\ncommunity wiki\n\n\n2 revs, 2 users 97%\nusayee","comments":[]},{"answer":"The top answer didn't do it for me. This did though:\n\n<script type=\"text/javascript\">\n    $(document).ready(function(){\n\n        $(\"#li_13\").click(function(){\n            if($(\"#agree\").attr('checked')){\n                $(\"#saveForm\").fadeIn();\n            }\n            else\n            {\n                $(\"#saveForm\").fadeOut();\n            }\n        });\n    });\n</script>\n\n\nBasically when the element #li_13 is clicked, it checks if the element # agree (which is the checkbox) is checked by using the .attr('checked') function. If it is then fadeIn the #saveForm element, and if not fadeOut the saveForm element.\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 17:12\ncommunity wiki\n\n\n4 revs, 2 users 72%\nBigHomie","comments":[]},{"answer":"Though you have proposed a JavaScript solution for your problem (displaying a textbox when a checkbox is checked), this problem could be solved just by css. With this approach, your form works for users who have disabled JavaScript.\n\nAssuming that you have the following HTML:\n\n<label for=\"show_textbox\">Show Textbox</label>\n<input id=\"show_textbox\" type=\"checkbox\" />\n<input type=\"text\" />\n\n\nYou can use the following CSS to achieve the desired functionality:\n\n #show_textbox:not(:checked) + input[type=text] {display:none;}\n\n\nFor other scenarios, you may think of appropriate CSS selectors.\n\nHere is a Fiddle to demonstrate this approach.\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 17:32\ncommunity wiki\n\n\n4 revs, 2 users 88%\nOrmoz","comments":[]},{"answer":"I am using this:\n\n <input type=\"checkbox\" id=\"isAgeSelected\" value=\"1\" /> <br/>\n <input type=\"textbox\" id=\"txtAge\" />\n\n $(\"#isAgeSelected\").is(':checked') ? $(\"#txtAge\").show() : $(\"#txtAge\").hide();\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '16 at 17:22\ncommunity wiki\n\n\n2 revs, 2 users 71%\nNishant","comments":[]},{"answer":"Toggle: 0/1 or else\n\n<input type=\"checkbox\" id=\"nolunch\" />\n<input id=\"checklunch />\"\n\n    $('#nolunch').change(function () {\n    if ($(this).is(':checked')) {\n        $('#checklunch').val('1');\n    };\n    if ($(this).is(':checked') == false) {\n        $('#checklunch').val('0');\n    };\n});\n\nShare\nImprove this answer\nFollow\nedited May 5 '15 at 8:48\ncommunity wiki\n\n\n2 revs, 2 users 96%\nuser2385302","comments":[]}]},{"id":"273192","href":"https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python","title":"How can I safely create a nested directory in Python?","description":"\n                \nWhat is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:\nimport os\n\nfile_path = \"/my/directory/filename.txt\"\ndirectory = os.path.dirname(file_path)\n\ntry:\n    os.stat(directory)\nexcept:\n    os.mkdir(directory)\n\nf = file(filename)\n\nSomehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:\ndef ensure_dir(file_path):\n    directory = os.path.dirname(file_path)\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\nIs there a flag for \"open\", that makes this happen automatically?\n    ","questionComments":["In general you might need to account for the case where there's no directory in the filename. On my machine dirname('foo.txt') gives '', which doesn't exist and causes makedirs() to fail.","if the path exists one has not only to check if it is a directory and not a regular file or another object (many answers check this) it is also necessary to check if it is writable (I did not find an answer that checked this)","In case you came here to create parent directories of file path string p, here is my code snippet: os.makedirs(p[:p.rindex(os.path.sep)], exist_ok=True)"],"answers":[{"answer":"On Python ≥ 3.5, use pathlib.Path.mkdir:\n\nfrom pathlib import Path\nPath(\"/my/directory\").mkdir(parents=True, exist_ok=True)\n\n\nFor older versions of Python, I see two answers with good qualities, each with a small flaw, so I will give my take on it:\n\nTry os.path.exists, and consider os.makedirs for the creation.\n\nimport os\nif not os.path.exists(directory):\n    os.makedirs(directory)\n\n\nAs noted in comments and elsewhere, there's a race condition – if the directory is created between the os.path.exists and the os.makedirs calls, the os.makedirs will fail with an OSError. Unfortunately, blanket-catching OSError and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.\n\nOne option would be to trap the OSError and examine the embedded error code (see Is there a cross-platform way of getting information from Python’s OSError):\n\nimport os, errno\n\ntry:\n    os.makedirs(directory)\nexcept OSError as e:\n    if e.errno != errno.EEXIST:\n        raise\n\n\nAlternatively, there could be a second os.path.exists, but suppose another created the directory after the first check, then removed it before the second one – we could still be fooled.\n\nDepending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.\n\nModern versions of Python improve this code quite a bit, both by exposing FileExistsError (in 3.3+)...\n\ntry:\n    os.makedirs(\"path/to/directory\")\nexcept FileExistsError:\n    # directory already exists\n    pass\n\n\n...and by allowing a keyword argument to os.makedirs called exist_ok (in 3.2+).\n\nos.makedirs(\"path/to/directory\", exist_ok=True)  # succeeds even if directory exists.\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '19 at 9:23\nBoris\n7,6557\n7 gold badges\n66\n66 silver badges\n67\n67 bronze badges\nanswered Nov 7 '08 at 19:06\nBlair Conrad\n207k24\n24 gold badges\n128\n128 silver badges\n110\n110 bronze badges","comments":["The race condition is a good point, but the approach in stackoverflow.com/questions/273192/#273208, will mask a failure to create the directory. Don't feel bad for voting down - you don't like the answer. It's what votes are for.","Remember that os.path.exists() isn't free. If the normal case is that the directory will be there, then the case where it isn't should be handled as an exception. In other words, try to open and write to your file, catch the OSError exception and, based on errno, do your makedir() and re-try or re-raise. This creates duplication of code unless you wrap the writing in a local method.","os.path.exists also returns True for a file. I have posted an answer to address this.","As commenters to other answers here have noted, the exists_ok parameter to os.makedirs() can be used to cover how prior existence of the path is handled, since Python 3.2.","os.mkdirs() can create unintended folders if a path separator is accidentally left out, the current folder is not as expected, a path element contains the path separator. If you use os.mkdir() these bugs will raise an exception, alerting you to their existence."]},{"answer":"Python 3.5+:\nimport pathlib\npathlib.Path('/my/directory').mkdir(parents=True, exist_ok=True) \n\n\npathlib.Path.mkdir as used above recursively creates the directory and does not raise an exception if the directory already exists. If you don't need or want the parents to be created, skip the parents argument.\n\nPython 3.2+:\n\nUsing pathlib:\n\nIf you can, install the current pathlib backport named pathlib2. Do not install the older unmaintained backport named pathlib. Next, refer to the Python 3.5+ section above and use it the same.\n\nIf using Python 3.4, even though it comes with pathlib, it is missing the useful exist_ok option. The backport is intended to offer a newer and superior implementation of mkdir which includes this missing option.\n\nUsing os:\n\nimport os\nos.makedirs(path, exist_ok=True)\n\n\nos.makedirs as used above recursively creates the directory and does not raise an exception if the directory already exists. It has the optional exist_ok argument only if using Python 3.2+, with a default value of False. This argument does not exist in Python 2.x up to 2.7. As such, there is no need for manual exception handling as with Python 2.7.\n\nPython 2.7+:\n\nUsing pathlib:\n\nIf you can, install the current pathlib backport named pathlib2. Do not install the older unmaintained backport named pathlib. Next, refer to the Python 3.5+ section above and use it the same.\n\nUsing os:\n\nimport os\ntry: \n    os.makedirs(path)\nexcept OSError:\n    if not os.path.isdir(path):\n        raise\n\n\nWhile a naive solution may first use os.path.isdir followed by os.makedirs, the solution above reverses the order of the two operations. In doing so, it prevents a common race condition having to do with a duplicated attempt at creating the directory, and also disambiguates files from directories.\n\nNote that capturing the exception and using errno is of limited usefulness because OSError: [Errno 17] File exists, i.e. errno.EEXIST, is raised for both files and directories. It is more reliable simply to check if the directory exists.\n\nAlternative:\n\nmkpath creates the nested directory, and does nothing if the directory already exists. This works in both Python 2 and 3.\n\nimport distutils.dir_util\ndistutils.dir_util.mkpath(path)\n\n\nPer Bug 10948, a severe limitation of this alternative is that it works only once per python process for a given path. In other words, if you use it to create a directory, then delete the directory from inside or outside Python, then use mkpath again to recreate the same directory, mkpath will simply silently use its invalid cached info of having previously created the directory, and will not actually make the directory again. In contrast, os.makedirs doesn't rely on any such cache. This limitation may be okay for some applications.\n\nWith regard to the directory's mode, please refer to the documentation if you care about it.\n\nShare\nImprove this answer\nFollow\nedited May 17 '18 at 17:16\nanswered Jan 16 '13 at 17:31\nAsclepius\n43.4k14\n14 gold badges\n122\n122 silver badges\n111\n111 bronze badges","comments":["This answer covers pretty much every special case as far as I can tell. I plan on wrapping this in a \"if not os.path.isdir()\" though since I expect the directory to exist almost every time and I can avoid the exception that way.","@CharlesL. An exception is probably cheaper than the disk IO of the check, if your reason is performance.","@jpmc26 but makedirs does additional stat, umask, lstat when only checking to throw OSError.","This is the wrong answer, as it introduces a potential FS race cond. See answer from Aaron Hall.","as @sleepycal has said, this suffers from a similar race condition as the accepted answer. If between raising the error and checking os.path.isdir someone else deletes the folder, you will raise the wrong, outdated, and confusing error that folder exists."]},{"answer":"Using try except and the right error code from errno module gets rid of the race condition and is cross-platform:\n\nimport os\nimport errno\n\ndef make_sure_path_exists(path):\n    try:\n        os.makedirs(path)\n    except OSError as exception:\n        if exception.errno != errno.EEXIST:\n            raise\n\n\nIn other words, we try to create the directories, but if they already exist we ignore the error. On the other hand, any other error gets reported. For example, if you create dir 'a' beforehand and remove all permissions from it, you will get an OSError raised with errno.EACCES (Permission denied, error 13).\n\nShare\nImprove this answer\nFollow\nedited Apr 24 '17 at 1:55\nvallentin\n19.6k6\n6 gold badges\n44\n44 silver badges\n70\n70 bronze badges\nanswered Feb 17 '11 at 17:17\nHeikki Toivonen\n30.3k10\n10 gold badges\n40\n40 silver badges\n43\n43 bronze badges","comments":["The accepted answer is actually dangerous because it has a race-condition. It is simpler, though, so if you are unaware of the race-condition, or think it won't apply to you, that would be your obvious first pick.","Raising the exception only when exception.errno != errno.EEXIST will unintentionally ignore the case when path exists but is a non-directory object such as a file. The exception should ideally be raised if the path is a non-directory object.","Note that the above code is equivalent to os.makedirs(path,exist_ok=True)","@Navin The exist_ok parameter was introduced in Python 3.2. It is not present in Python 2.x. I will incorporate it into my answer.","@HeikkiToivonen Technically speaking, if another program is modifying the directories and files at the same time your program is, your entire program is one giant race condition. What's to stop another program from just deleting this directory after the code creates it and before you actually put files in it?"]},{"answer":"I would personally recommend that you use os.path.isdir() to test instead of os.path.exists().\n\n>>> os.path.exists('/tmp/dirname')\nTrue\n>>> os.path.exists('/tmp/dirname/filename.etc')\nTrue\n>>> os.path.isdir('/tmp/dirname/filename.etc')\nFalse\n>>> os.path.isdir('/tmp/fakedirname')\nFalse\n\n\nIf you have:\n\n>>> dir = raw_input(\":: \")\n\n\nAnd a foolish user input:\n\n:: /tmp/dirname/filename.etc\n\n\n... You're going to end up with a directory named filename.etc when you pass that argument to os.makedirs() if you test with os.path.exists().\n\nShare\nImprove this answer\nFollow\nedited May 31 '14 at 14:06\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 14 '09 at 17:57\ncrimsonstone","comments":[]},{"answer":"Starting from Python 3.5, pathlib.Path.mkdir has an exist_ok flag:\n\nfrom pathlib import Path\npath = Path('/my/directory/filename.txt')\npath.parent.mkdir(parents=True, exist_ok=True) \n# path.parent ~ os.path.dirname(path)\n\n\nThis recursively creates the directory and does not raise an exception if the directory already exists.\n\n(just as os.makedirs got an exist_ok flag starting from python 3.2 e.g os.makedirs(path, exist_ok=True))\n\nNote: when i posted this answer none of the other answers mentioned exist_ok...\n\nShare\nImprove this answer\nFollow\nedited Oct 28 '20 at 6:13\nanswered Dec 14 '16 at 16:06\nhiro protagonist\n37k12\n12 gold badges\n70\n70 silver badges\n88\n88 bronze badges","comments":[]},{"answer":"Check os.makedirs: (It makes sure the complete path exists.)\nTo handle the fact the directory might exist, catch OSError. (If exist_ok is False (the default), an OSError is raised if the target directory already exists.)\n\nimport os\ntry:\n    os.makedirs('./path/to/somewhere')\nexcept OSError:\n    pass\n\nShare\nImprove this answer\nFollow\nedited May 16 '19 at 12:15\nGeorgy\n6,8417\n7 gold badges\n49\n49 silver badges\n59\n59 bronze badges\nanswered Nov 7 '08 at 19:01\nDouglas Mayle\n18.5k7\n7 gold badges\n40\n40 silver badges\n57\n57 bronze badges","comments":["with the try/except, you will mask errors in directory creation, in the case when the directory didn't exist but for some reason you can't make it"]},{"answer":"Insights on the specifics of this situation\n\nYou give a particular file at a certain path and you pull the directory from the file path. Then after making sure you have the directory, you attempt to open a file for reading. To comment on this code:\n\nfilename = \"/my/directory/filename.txt\"\ndir = os.path.dirname(filename)\n\n\nWe want to avoid overwriting the builtin function, dir. Also, filepath or perhaps fullfilepath is probably a better semantic name than filename so this would be better written:\n\nimport os\nfilepath = '/my/directory/filename.txt'\ndirectory = os.path.dirname(filepath)\n\n\nYour end goal is to open this file, you initially state, for writing, but you're essentially approaching this goal (based on your code) like this, which opens the file for reading:\n\nif not os.path.exists(directory):\n    os.makedirs(directory)\nf = file(filename)\n\nAssuming opening for reading\n\nWhy would you make a directory for a file that you expect to be there and be able to read?\n\nJust attempt to open the file.\n\nwith open(filepath) as my_file:\n    do_stuff(my_file)\n\n\nIf the directory or file isn't there, you'll get an IOError with an associated error number: errno.ENOENT will point to the correct error number regardless of your platform. You can catch it if you want, for example:\n\nimport errno\ntry:\n    with open(filepath) as my_file:\n        do_stuff(my_file)\nexcept IOError as error:\n    if error.errno == errno.ENOENT:\n        print 'ignoring error because directory or file is not there'\n    else:\n        raise\n\nAssuming we're opening for writing\n\nThis is probably what you're wanting.\n\nIn this case, we probably aren't facing any race conditions. So just do as you were, but note that for writing, you need to open with the w mode (or a to append). It's also a Python best practice to use the context manager for opening files.\n\nimport os\nif not os.path.exists(directory):\n    os.makedirs(directory)\nwith open(filepath, 'w') as my_file:\n    do_stuff(my_file)\n\n\nHowever, say we have several Python processes that attempt to put all their data into the same directory. Then we may have contention over creation of the directory. In that case it's best to wrap the makedirs call in a try-except block.\n\nimport os\nimport errno\nif not os.path.exists(directory):\n    try:\n        os.makedirs(directory)\n    except OSError as error:\n        if error.errno != errno.EEXIST:\n            raise\nwith open(filepath, 'w') as my_file:\n    do_stuff(my_file)\n\nShare\nImprove this answer\nFollow\nedited Apr 1 '16 at 21:54\nanswered Jan 22 '15 at 23:49\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":[]},{"answer":"Try the os.path.exists function\n\nif not os.path.exists(dir):\n    os.mkdir(dir)\n\nShare\nImprove this answer\nFollow\nedited Oct 15 '15 at 16:05\njesterjunk\n2,09418\n18 silver badges\n17\n17 bronze badges\nanswered Nov 7 '08 at 19:00\ngone\n3,6802\n2 gold badges\n21\n21 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"I have put the following down. It's not totally foolproof though.\n\nimport os\n\ndirname = 'create/me'\n\ntry:\n    os.makedirs(dirname)\nexcept OSError:\n    if os.path.exists(dirname):\n        # We are nearly safe\n        pass\n    else:\n        # There was an error on creation, so make sure we know about it\n        raise\n\n\nNow as I say, this is not really foolproof, because we have the possiblity of failing to create the directory, and another process creating it during that period.\n\nShare\nImprove this answer\nFollow\nedited May 31 '14 at 14:05\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 7 '08 at 21:23\nAli Afshar\n38.9k12\n12 gold badges\n89\n89 silver badges\n108\n108 bronze badges","comments":[]},{"answer":"Check if a directory exists and create it if necessary?\n\nThe direct answer to this is, assuming a simple situation where you don't expect other users or processes to be messing with your directory:\n\nif not os.path.exists(d):\n    os.makedirs(d)\n\n\nor if making the directory is subject to race conditions (i.e. if after checking the path exists, something else may have already made it) do this:\n\nimport errno\ntry:\n    os.makedirs(d)\nexcept OSError as exception:\n    if exception.errno != errno.EEXIST:\n        raise\n\n\nBut perhaps an even better approach is to sidestep the resource contention issue, by using temporary directories via tempfile:\n\nimport tempfile\n\nd = tempfile.mkdtemp()\n\n\nHere's the essentials from the online doc:\n\nmkdtemp(suffix='', prefix='tmp', dir=None)\n    User-callable function to create and return a unique temporary\n    directory.  The return value is the pathname of the directory.\n\n    The directory is readable, writable, and searchable only by the\n    creating user.\n\n    Caller is responsible for deleting the directory when done with it.\n\nNew in Python 3.5: pathlib.Path with exist_ok\n\nThere's a new Path object (as of 3.4) with lots of methods one would want to use with paths - one of which is mkdir.\n\n(For context, I'm tracking my weekly rep with a script. Here's the relevant parts of code from the script that allow me to avoid hitting Stack Overflow more than once a day for the same data.)\n\nFirst the relevant imports:\n\nfrom pathlib import Path\nimport tempfile\n\n\nWe don't have to deal with os.path.join now - just join path parts with a /:\n\ndirectory = Path(tempfile.gettempdir()) / 'sodata'\n\n\nThen I idempotently ensure the directory exists - the exist_ok argument shows up in Python 3.5:\n\ndirectory.mkdir(exist_ok=True)\n\n\nHere's the relevant part of the documentation:\n\nIf exist_ok is true, FileExistsError exceptions will be ignored (same behavior as the POSIX mkdir -p command), but only if the last path component is not an existing non-directory file.\n\nHere's a little more of the script - in my case, I'm not subject to a race condition, I only have one process that expects the directory (or contained files) to be there, and I don't have anything trying to remove the directory.\n\ntodays_file = directory / str(datetime.datetime.utcnow().date())\nif todays_file.exists():\n    logger.info(\"todays_file exists: \" + str(todays_file))\n    df = pd.read_json(str(todays_file))\n\n\nPath objects have to be coerced to str before other APIs that expect str paths can use them.\n\nPerhaps Pandas should be updated to accept instances of the abstract base class, os.PathLike.\n\nShare\nImprove this answer\nFollow\nedited Jul 7 '17 at 3:19\nanswered Jan 22 '15 at 23:45\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":[]},{"answer":"In Python 3.4 you can also use the brand new pathlib module:\n\nfrom pathlib import Path\npath = Path(\"/my/directory/filename.txt\")\ntry:\n    if not path.parent.exists():\n        path.parent.mkdir(parents=True)\nexcept OSError:\n    # handle error; you can also catch specific errors like\n    # FileExistsError and so on.\n\nShare\nImprove this answer\nFollow\nanswered Mar 11 '15 at 20:50\nAntti Haapala\n119k21\n21 gold badges\n247\n247 silver badges\n285\n285 bronze badges","comments":[]},{"answer":"For a one-liner solution, you can use IPython.utils.path.ensure_dir_exists():\n\nfrom IPython.utils.path import ensure_dir_exists\nensure_dir_exists(dir)\n\n\nFrom the documentation: Ensure that a directory exists. If it doesn’t exist, try to create it and protect against a race condition if another process is doing the same.\n\nIPython is an extension package, not part of the standard library.\n\nShare\nImprove this answer\nFollow\nedited Jul 28 at 13:01\nLutz Prechelt\n30.1k6\n6 gold badges\n52\n52 silver badges\n82\n82 bronze badges\nanswered Mar 29 '16 at 15:50\ntashuhka\n4,5723\n3 gold badges\n40\n40 silver badges\n62\n62 bronze badges","comments":[]},{"answer":"In Python3, os.makedirs supports setting exist_ok. The default setting is False, which means an OSError will be raised if the target directory already exists. By setting exist_ok to True, OSError (directory exists) will be ignored and the directory will not be created.\n\nos.makedirs(path,exist_ok=True)\n\n\nIn Python2, os.makedirs doesn't support setting exist_ok. You can use the approach in heikki-toivonen's answer:\n\nimport os\nimport errno\n\ndef make_sure_path_exists(path):\n    try:\n        os.makedirs(path)\n    except OSError as exception:\n        if exception.errno != errno.EEXIST:\n            raise\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:26\nCommunity♦\n11\n1 silver badge\nanswered Jan 3 '17 at 22:33\neuccas\n6378\n8 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"The relevant Python documentation suggests the use of the EAFP coding style (Easier to Ask for Forgiveness than Permission). This means that the code\n\ntry:\n    os.makedirs(path)\nexcept OSError as exception:\n    if exception.errno != errno.EEXIST:\n        raise\n    else:\n        print \"\\nBE CAREFUL! Directory %s already exists.\" % path\n\n\nis better than the alternative\n\nif not os.path.exists(path):\n    os.makedirs(path)\nelse:\n    print \"\\nBE CAREFUL! Directory %s already exists.\" % path\n\n\nThe documentation suggests this exactly because of the race condition discussed in this question. In addition, as others mention here, there is a performance advantage in querying once instead of twice the OS. Finally, the argument placed forward, potentially, in favour of the second code in some cases --when the developer knows the environment the application is running-- can only be advocated in the special case that the program has set up a private environment for itself (and other instances of the same program).\n\nEven in that case, this is a bad practice and can lead to long useless debugging. For example, the fact we set the permissions for a directory should not leave us with the impression permissions are set appropriately for our purposes. A parent directory could be mounted with other permissions. In general, a program should always work correctly and the programmer should not expect one specific environment.\n\nShare\nImprove this answer\nFollow\nedited Dec 31 '17 at 3:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 14 '14 at 15:29\nkavadias\n9389\n9 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"You can use mkpath\n\n# Create a directory and any missing ancestor directories. \n# If the directory already exists, do nothing.\n\nfrom distutils.dir_util import mkpath\nmkpath(\"test\")    \n\n\nNote that it will create the ancestor directories as well.\n\nIt works for Python 2 and 3.\n\nShare\nImprove this answer\nFollow\nanswered Sep 13 '16 at 21:44\nDennis Golomazov\n13.3k4\n4 gold badges\n68\n68 silver badges\n75\n75 bronze badges","comments":[]},{"answer":"I found this Q/A and I was initially puzzled by some of the failures and errors I was getting. I am working in Python 3 (v.3.5 in an Anaconda virtual environment on an Arch Linux x86_64 system).\n\nConsider this directory structure:\n\n└── output/         ## dir\n   ├── corpus       ## file\n   ├── corpus2/     ## dir\n   └── subdir/      ## dir\n\n\nHere are my experiments/notes, which clarifies things:\n\n# ----------------------------------------------------------------------------\n# [1] https://stackoverflow.com/questions/273192/how-can-i-create-a-directory-if-it-does-not-exist\n\nimport pathlib\n\n\"\"\" Notes:\n        1.  Include a trailing slash at the end of the directory path\n            (\"Method 1,\" below).\n        2.  If a subdirectory in your intended path matches an existing file\n            with same name, you will get the following error:\n            \"NotADirectoryError: [Errno 20] Not a directory:\" ...\n\"\"\"\n# Uncomment and try each of these \"out_dir\" paths, singly:\n\n# ----------------------------------------------------------------------------\n# METHOD 1:\n# Re-running does not overwrite existing directories and files; no errors.\n\n# out_dir = 'output/corpus3'                ## no error but no dir created (missing tailing /)\n# out_dir = 'output/corpus3/'               ## works\n# out_dir = 'output/corpus3/doc1'           ## no error but no dir created (missing tailing /)\n# out_dir = 'output/corpus3/doc1/'          ## works\n# out_dir = 'output/corpus3/doc1/doc.txt'   ## no error but no file created (os.makedirs creates dir, not files!  ;-)\n# out_dir = 'output/corpus2/tfidf/'         ## fails with \"Errno 20\" (existing file named \"corpus2\")\n# out_dir = 'output/corpus3/tfidf/'         ## works\n# out_dir = 'output/corpus3/a/b/c/d/'       ## works\n\n# [2] https://docs.python.org/3/library/os.html#os.makedirs\n\n# Uncomment these to run \"Method 1\":\n\n#directory = os.path.dirname(out_dir)\n#os.makedirs(directory, mode=0o777, exist_ok=True)\n\n# ----------------------------------------------------------------------------\n# METHOD 2:\n# Re-running does not overwrite existing directories and files; no errors.\n\n# out_dir = 'output/corpus3'                ## works\n# out_dir = 'output/corpus3/'               ## works\n# out_dir = 'output/corpus3/doc1'           ## works\n# out_dir = 'output/corpus3/doc1/'          ## works\n# out_dir = 'output/corpus3/doc1/doc.txt'   ## no error but creates a .../doc.txt./ dir\n# out_dir = 'output/corpus2/tfidf/'         ## fails with \"Errno 20\" (existing file named \"corpus2\")\n# out_dir = 'output/corpus3/tfidf/'         ## works\n# out_dir = 'output/corpus3/a/b/c/d/'       ## works\n\n# Uncomment these to run \"Method 2\":\n\n#import os, errno\n#try:\n#       os.makedirs(out_dir)\n#except OSError as e:\n#       if e.errno != errno.EEXIST:\n#               raise\n# ----------------------------------------------------------------------------\n\n\nConclusion: in my opinion, \"Method 2\" is more robust.\n\n[1] How can I create a directory if it does not exist?\n\n[2] https://docs.python.org/3/library/os.html#os.makedirs\n\nShare\nImprove this answer\nFollow\nedited Dec 16 '17 at 19:26\nanswered Dec 16 '17 at 4:16\nVictoria Stuart\n3,3042\n2 gold badges\n29\n29 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"I use os.path.exists(), here is a Python 3 script that can be used to check if a directory exists, create one if it does not exist, and delete it if it does exist (if desired).\n\nIt prompts users for input of the directory and can be easily modified.\n\nShare\nImprove this answer\nFollow\nedited Dec 31 '17 at 3:16\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 9 '17 at 3:56\nMichael Strobel\n3494\n4 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"Use this command check and create dir\n\n if not os.path.isdir(test_img_dir):\n     os.mkdir(test_img_dir)\n\nShare\nImprove this answer\nFollow\nedited May 16 '19 at 19:07\nJean-François Fabre♦\n128k22\n22 gold badges\n107\n107 silver badges\n171\n171 bronze badges\nanswered Apr 16 '18 at 7:30\nManivannan Murugavel\n1,17113\n13 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"Why not use subprocess module if running on a machine that supports command mkdir with -p option ? Works on python 2.7 and python 3.6\n\nfrom subprocess import call\ncall(['mkdir', '-p', 'path1/path2/path3'])\n\n\nShould do the trick on most systems.\n\nIn situations where portability doesn't matter (ex, using docker) the solution is a clean 2 lines. You also don't have to add logic to check if directories exist or not. Finally, it is safe to re-run without any side effects\n\nIf you need error handling:\n\nfrom subprocess import check_call\ntry:\n    check_call(['mkdir', '-p', 'path1/path2/path3'])\nexcept:\n    handle...\n\nShare\nImprove this answer\nFollow\nedited May 16 '19 at 19:37\nJean-François Fabre♦\n128k22\n22 gold badges\n107\n107 silver badges\n171\n171 bronze badges\nanswered Sep 11 '18 at 18:23\nGeoff Paul Bremner\n1922\n2 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"I saw Heikki Toivonen and A-B-B's answers and thought of this variation.\n\nimport os\nimport errno\n\ndef make_sure_path_exists(path):\n    try:\n        os.makedirs(path)\n    except OSError as exception:\n        if exception.errno != errno.EEXIST or not os.path.isdir(path):\n            raise\n\nShare\nImprove this answer\nFollow\nedited Dec 31 '17 at 3:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 8 '16 at 4:08\nalissonmuller\n1672\n2 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"You have to set the full path before creating the directory:\n\nimport os,sys,inspect\nimport pathlib\n\ncurrentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\nyour_folder = currentdir + \"/\" + \"your_folder\"\n\nif not os.path.exists(your_folder):\n   pathlib.Path(your_folder).mkdir(parents=True, exist_ok=True)\n\n\nThis works for me and hopefully, it will works for you as well\n\nShare\nImprove this answer\nFollow\nedited May 19 '19 at 0:40\nanswered May 19 '19 at 0:32\nHussam Kurd\n4,9851\n1 gold badge\n32\n32 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"You can use os.listdir for this:\n\nimport os\nif 'dirName' in os.listdir('parentFolderPath')\n    print('Directory Exists')\n\nShare\nImprove this answer\nFollow\nedited Sep 30 '17 at 12:31\ndippas\n50k15\n15 gold badges\n95\n95 silver badges\n108\n108 bronze badges\nanswered Jun 8 '16 at 12:52\niPhynx\n4196\n6 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"Call the function create_dir() at the entry point of your program/project.\n\nimport os\n\ndef create_dir(directory):\n    if not os.path.exists(directory):\n        print('Creating Directory '+directory)\n        os.makedirs(directory)\n\ncreate_dir('Project directory')\n\nShare\nImprove this answer\nFollow\nanswered Apr 28 '18 at 16:00\nSteffi Keran Rani J\n2,6173\n3 gold badges\n20\n20 silver badges\n44\n44 bronze badges","comments":[]},{"answer":"If you consider the following:\n\nos.path.isdir('/tmp/dirname')\n\n\nmeans a directory (path) exists AND is a directory. So for me this way does what I need. So I can make sure it is folder (not a file) and exists.\n\nShare\nImprove this answer\nFollow\nedited Dec 3 '16 at 16:35\nanswered Dec 3 '16 at 16:00\nRalph Schwerdt\n891\n1 silver badge\n2\n2 bronze badges","comments":[]},{"answer":"You can both create a file, and all its parent directories in 1 command with fastcore extension to pathlib: path.mk_write(data)\n\nfrom fastcore.utils import Path\nPath('/dir/to/file.txt').mk_write('Hello World')\n\n\nSee more in fastcore documentation\n\nShare\nImprove this answer\nFollow\nedited Aug 18 at 3:14\nanswered Oct 22 '20 at 3:32\nkorakot\n26.5k13\n13 gold badges\n91\n91 silver badges\n116\n116 bronze badges","comments":[]},{"answer":"import os\nif os.path.isfile(filename):\n    print \"file exists\"\nelse:\n    \"Your code here\"\n\n\nWhere your code here is use the (touch) command\n\nThis will check if the file is there if it is not then it will create it.\n\nShare\nImprove this answer\nFollow\nanswered Jul 5 '17 at 23:15\nEvil Exists\n591\n1 silver badge\n9\n9 bronze badges","comments":[]},{"answer":"In case you're writing a file to a variable path, you can use this on the file's path to make sure that the parent directories are created.\n\nfrom pathlib import Path\n\npath_to_file = Path(\"zero/or/more/directories/file.ext\")\nparent_directory_of_file = path_to_file.parent\nparent_directory_of_file.mkdir(parents=True, exist_ok=True)\n\n\nWorks even if path_to_file is file.ext (zero directories deep).\n\nSee pathlib.PurePath.parent and pathlib.Path.mkdir.\n\nShare\nImprove this answer\nFollow\nanswered Aug 17 at 17:24\nDominykas Mostauskis\n6,5912\n2 gold badges\n43\n43 silver badges\n58\n58 bronze badges","comments":[]},{"answer":"Under Linux you can create directory in one line:\n\nimport os\nos.system(\"mkdir -p {0}\".format('mydir'))\n\nShare\nImprove this answer\nFollow\nanswered Sep 10 '20 at 3:39\nSergiy Maksymenko\n1491\n1 silver badge\n3\n3 bronze badges","comments":[]}]},{"id":"2765421","href":"https://stackoverflow.com/questions/2765421/how-do-i-push-a-new-local-branch-to-a-remote-git-repository-and-track-it-too","title":"How do I push a new local branch to a remote Git repository and track it too?","description":"\n                \nI want to be able to do the following:\n\nCreate a local branch based on some other (remote or local) branch (via git branch or git checkout -b)\n\nPush the local branch\nto the remote repository (publish), but make it\ntrackable so git pull and git push will work immediately.\n\n\nHow do I do that?\nI know about --set-upstream in Git 1.7, but that is a post-creation action. I want to find a way to make a similar change when pushing the branch to the remote repository.\n    ","questionComments":["just to point out --set-upstream is -u","lots of answers containing unrelated information (like how to create a branch) and if the answer applies, then information is missing regarding the magic parameters used.","@VividD \"added an illustrative picture\" - Seriously? o.O"],"answers":[{"answer":"In Git 1.7.0 and later, you can checkout a new branch:\n\ngit checkout -b <branch>\n\n\nEdit files, add and commit. Then push with the -u (short for --set-upstream) option:\n\ngit push -u origin <branch>\n\n\nGit will set up the tracking information during the push.\n\nShare\nImprove this answer\nFollow\nedited Sep 23 '17 at 20:27\nThe Red Pea\n12.9k12\n12 gold badges\n80\n80 silver badges\n114\n114 bronze badges\nanswered Jun 3 '11 at 20:50\nDaniel Ruoso\n74.4k1\n1 gold badge\n14\n14 silver badges\n8\n8 bronze badges","comments":["It's also worth noting that if you have an existing tracking branch already set on the branch you're pushing, and push.default is set to upstream, this will not do what you think it will do. It will try to push over the existing tracking branch. Use: git push -u origin mynewfeature:mynewfeature or do git branch --unset-upstream first.","I still needed to 'git branch --set-upstream-to origin/remote' in order for 'git status' to correctly report my branch status with respect to the remote branch.","For people using Git from Visual Studio: Actually this is that \"Publish Branch\" in Visual Studio does. After executing git push with -u parameter i can finally see my branch as published in VS UI.","You can also use git push -u origin HEAD","@Stephane You only need the -u once to initiate tracking. Afterward just use git push"]},{"answer":"If you are not sharing your repo with others, this is useful to push all your branches to the remote, and --set-upstream tracking correctly for you:\n\ngit push --all -u\n\n\n(Not exactly what the OP was asking for, but this one-liner is pretty popular)\n\nIf you are sharing your repo with others this isn't really good form as you will clog up the repo with all your dodgy experimental branches.\n\nShare\nImprove this answer\nFollow\nedited Mar 19 '18 at 1:53\nanswered Jan 20 '14 at 11:36\nErichBSchulz\n13.1k5\n5 gold badges\n51\n51 silver badges\n50\n50 bronze badges","comments":["and git pull --all pulls it all back elsewhere ? kewl","Git allows to commit a branch and not push it for very good reasons. Only using git push --all is like dropping a piece of git architecture. If it works for you, it is perfectly ok, great, do it forever. But PLEASE don't recommend others to avoid learning git just because it is a quick way to do things.","This really isn't the right answer and isn't a good tool to be recommending without a real explanation of what it does and what the implications are. Please consider taking this answer down.","@Federico @akronymn Where can one find the dangers of doing git  push --all -u?","@akronymn @ Federico - I've edited it to spell out what I see the dangers are - is that better?"]},{"answer":"Prior to the introduction of git push -u, there was no git push option to obtain what you desire. You had to add new configuration statements.\n\nIf you create a new branch using:\n\n$ git checkout -b branchB\n$ git push origin branchB:branchB\n\n\nYou can use the git config command to avoid editing directly the .git/config file:\n\n$ git config branch.branchB.remote origin\n$ git config branch.branchB.merge refs/heads/branchB\n\n\nOr you can edit manually the .git/config file to add tracking information to this branch:\n\n[branch \"branchB\"]\n    remote = origin\n    merge = refs/heads/branchB\n\nShare\nImprove this answer\nFollow\nedited Mar 2 at 7:13\nflyingdutchman\n6368\n8 silver badges\n11\n11 bronze badges\nanswered May 4 '10 at 13:03\nLohrun\n5,4041\n1 gold badge\n22\n22 silver badges\n22\n22 bronze badges","comments":["sometimes your need this git push origin -u local_branch:remote_branch","why does \"git push origin -u remote_branch_name \" work sometimes and sometimes not?"]},{"answer":"Simply put, to create a new local branch, do:\n\ngit branch <branch-name>\n\n\nTo push it to the remote repository, do:\n\ngit push -u origin <branch-name>\n\nShare\nImprove this answer\nFollow\nedited Feb 10 '16 at 19:30\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 24 '15 at 12:09\npiyushmandovra\n3,7232\n2 gold badges\n17\n17 silver badges\n29\n29 bronze badges","comments":["git branch <branch-name> and git checkout -b <branch-name> both create a branch but checkout switch to the new branch","dude bracket is just to mention you have to replace with whatever branch name you want to create and push.","@AdiPrasetyo can you elaborate what you are trying to say/ask?"]},{"answer":"A slight variation of the solutions already given here:\n\nCreate a local branch based on some other (remote or local) branch:\n\ngit checkout -b branchname\n\n\nPush the local branch to the remote repository (publish), but make it trackable so git pull and git push will work immediately\n\ngit push -u origin HEAD\n\n\nUsing HEAD is a \"handy way to push the current branch to the same name on the remote\". Source: https://git-scm.com/docs/git-push In Git terms, HEAD (in uppercase) is a reference to the top of the current branch (tree).\n\nThe -u option is just short for --set-upstream. This will add an upstream tracking reference for the current branch. you can verify this by looking in your .git/config file:\n\nShare\nImprove this answer\nFollow\nedited Jan 29 '20 at 9:30\nAlexander Tobias Bockstaller\n4,4574\n4 gold badges\n33\n33 silver badges\n56\n56 bronze badges\nanswered Jul 5 '16 at 8:13\nbg17aw\n2,3831\n1 gold badge\n17\n17 silver badges\n26\n26 bronze badges","comments":["Thank you :) git push -u origin <branch-name> wasn't working for me but using HEAD instead of <branch-name> worked perfectly :)"]},{"answer":"I simply do\n\ngit push -u origin localBranch:remoteBranchToBeCreated\n\n\nover an already cloned project.\n\nGit creates a new branch named remoteBranchToBeCreated under my commits I did in localBranch.\n\nEdit: this changes your current local branch's (possibly named localBranch) upstream to origin/remoteBranchToBeCreated. To fix that, simply type:\n\ngit branch --set-upstream-to=origin/localBranch\n\n\nor\n\ngit branch -u origin/localBranch\n\n\nSo your current local branch now tracks origin/localBranch back.\n\nShare\nImprove this answer\nFollow\nedited Sep 27 '20 at 13:43\nanswered Mar 20 '17 at 11:13\nArda\n5,7952\n2 gold badges\n45\n45 silver badges\n65\n65 bronze badges","comments":["This is what exactly i was actively looking for","git throws error: src refspec <new branch> does not match any. when I try this.","This should be the top answer."]},{"answer":"I suppose that you have already cloned a project like:\n\ngit clone http://github.com/myproject.git\n\n\nThen in your local copy, create a new branch and check it out:\n\ngit checkout -b <newbranch>\n\n\nSupposing that you made a \"git bare --init\" on your server and created the myapp.git, you should:\n\ngit remote add origin ssh://example.com/var/git/myapp.git\ngit push origin master\n\n\nAfter that, users should be able to\n\ngit clone http://example.com/var/git/myapp.git\n\n\nNOTE: I'm assuming that you have your server up and running. If it isn't, it won't work. A good how-to is here.\n\nADDED\n\nAdd a remote branch:\n\ngit push origin master:new_feature_name\n\n\nCheck if everything is good (fetch origin and list remote branches):\n\ngit fetch origin\ngit branch -r\n\n\nCreate a local branch and track the remote branch:\n\ngit checkout -tb new_feature_name origin/new_feature_name\n\n\nUpdate everything:\n\ngit pull\n\nShare\nImprove this answer\nFollow\nedited Feb 10 '16 at 19:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 4 '10 at 13:04\nVP.\n5,0116\n6 gold badges\n42\n42 silver badges\n69\n69 bronze badges","comments":["William's script I linked to does about the same with the additional option to delete remote branches and some safeguards, too",">to push the local branch to remote repo (publish), but make it >trackable so git pull and git push will work immediately. its what github does automatically when you push your code to their repository :-)","This does not respond to the question, the <newbranch> of the original repo is not trackable (and is renamed as <master> is the new repo you clone in step 3).","seems kind of overkill. does the git remote add origin make the local branch trackable? is that the key command here?","@Roni Yaniv: no git remote add origin only register a new remote repository. It is just a step needed before pushing your branch to that remote repository (if you don't want to type the whole address each time)"]},{"answer":"edit Outdated, just use git push -u origin $BRANCHNAME\n\nUse git publish-branch from William's miscellaneous Git tools.\n\nOK, no Ruby, so - ignoring the safeguards! - take the last three lines of the script and create a bash script, git-publish-branch:\n\n#!/bin/bash\nREMOTE=$1 # Rewrite this to make it optional...\nBRANCH=$2\n# Uncomment the following line to create BRANCH locally first\n#git checkout -b ${BRANCH}\ngit push ${ORIGIN} ${BRANCH}:refs/heads/${BRANCH} &&\ngit config branch.${BRANCH}.remote ${REMOTE} &&\ngit config branch.${BRANCH}.merge refs/heads/${BRANCH}\n\n\nThen run git-publish-branch REMOTENAME BRANCHNAME, where REMOTENAME is usually origin (you may modify the script to take origin as default, etc...)\n\nShare\nImprove this answer\nFollow\nedited Jan 16 at 2:49\nDevin Rhode\n19.2k6\n6 gold badges\n43\n43 silver badges\n59\n59 bronze badges\nanswered May 4 '10 at 13:03\nTobias Kienzler\n22k21\n21 gold badges\n112\n112 silver badges\n206\n206 bronze badges","comments":["this assumes I have ruby installed. no such luck. any other ideas?","the ruby script calls git push and git config command. I used the code of the script to edit my answer. You might used this information to create a small shell script that does the puslishing for you.","William's miscellaneous git tools appears to have moved (that link is now dead). A working link is: gitorious.org/willgit","\"William's\" link broken again; new link seems to be git-wt-commit.rubyforge.org","Edited answer to just have the one working link (github.com/DanielVartanov/willgit)"]},{"answer":"To create a new branch by branching off from an existing branch\n\ngit checkout -b <new_branch>\n\n\nand then push this new branch to repository using\n\ngit push -u origin <new_branch>\n\n\nThis creates and pushes all local commits to a newly created remote branch origin/<new_branch>\n\nShare\nImprove this answer\nFollow\nedited Jan 4 '19 at 14:43\nShubham\n2,5793\n3 gold badges\n19\n19 silver badges\n34\n34 bronze badges\nanswered Jun 3 '15 at 20:36\ncptjack\n3194\n4 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"For GitLab version prior to 1.7, use:\n\ngit checkout -b name_branch\n\n\n(name_branch, ex: master)\n\nTo push it to the remote repository, do:\n\ngit push -u origin name_new_branch\n\n\n(name_new_branch, example: feature)\n\nShare\nImprove this answer\nFollow\nedited Jan 4 '19 at 14:32\nShubham\n2,5793\n3 gold badges\n19\n19 silver badges\n34\n34 bronze badges\nanswered Dec 6 '16 at 18:42\nFadid\n1,10213\n13 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"I made an alias so that whenever I create a new branch, it will push and track the remote branch accordingly. I put following chunk into the .bash_profile file:\n\n# Create a new branch, push to origin and track that remote branch\npublishBranch() {\n  git checkout -b $1\n  git push -u origin $1\n}\nalias gcb=publishBranch\n\n\nUsage: just type gcb thuy/do-sth-kool with thuy/do-sth-kool is my new branch name.\n\nShare\nImprove this answer\nFollow\nanswered Jan 5 '16 at 10:11\nThuy Trinh\n2,7881\n1 gold badge\n19\n19 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"You can do it in 2 steeps:\n\n1. Use the checkout for create the local branch:\n\ngit checkout -b yourBranchName\n\n\nWork with your Branch as you want.\n\n2. Use the push command to autocreate the branch and send the code to the remote repository:\n\ngit push -u origin yourBanchName\n\n\nThere are mutiple ways to do this but I think that this way is really simple.\n\nShare\nImprove this answer\nFollow\nanswered Oct 2 '19 at 10:11\nJavier C.\n6,2094\n4 gold badges\n35\n35 silver badges\n47\n47 bronze badges","comments":[]},{"answer":"Building slightly upon the answers here, I've wrapped this process up as a simple Bash script, which could of course be used as a Git alias as well.\n\nThe important addition to me is that this prompts me to run unit tests before committing and passes in the current branch name by default.\n\n$ git_push_new_branch.sh\n\n  Have you run your unit tests yet? If so, pass OK or a branch name, and try again\n\n  usage: git_push_new_branch {OK|BRANCH_NAME}\n\n  e.g.\n\n  git_push_new_branch           -> Displays prompt reminding you to run unit tests\n  git_push_new_branch OK        -> Pushes the current branch as a new branch to the origin\n  git_push_new_branch MYBRANCH  -> Pushes branch MYBRANCH as a new branch to the origin\n\ngit_push_new_branch.sh\nfunction show_help()\n{\n  IT=$(cat <<EOF\n\n  Have you run your unit tests yet? If so, pass OK or a branch name, and try again\n\n  usage: git_push_new_branch {OK|BRANCH_NAME}\n\n  e.g.\n\n  git_push_new_branch.sh           -> Displays prompt reminding you to run unit tests\n  git_push_new_branch.sh OK        -> Pushes the current branch as a new branch to the origin\n  git_push_new_branch.sh MYBRANCH  -> Pushes branch MYBRANCH as a new branch to the origin\n\n  )\n  echo \"$IT\"\n  exit\n}\n\nif [ -z \"$1\" ]\nthen\n  show_help\nfi\n\nCURR_BRANCH=$(git rev-parse --abbrev-ref HEAD)\nif [ \"$1\" == \"OK\" ]\nthen\n  BRANCH=$CURR_BRANCH\nelse\n  BRANCH=${1:-$CURR_BRANCH}\nfi\n\ngit push -u origin $BRANCH\n\nShare\nImprove this answer\nFollow\nedited Jul 18 '19 at 11:29\nanswered Apr 21 '17 at 13:30\nBrad Parks\n55.7k55\n55 gold badges\n224\n224 silver badges\n293\n293 bronze badges","comments":[]},{"answer":"For greatest flexibility, you could use a custom Git command. For example, create the following Python script somewhere in your $PATH under the name git-publish and make it executable:\n\n#!/usr/bin/env python3\n\nimport argparse\nimport subprocess\nimport sys\n\n\ndef publish(args):\n    return subprocess.run(['git', 'push', '--set-upstream', args.remote, args.branch]).returncode\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description='Push and set upstream for a branch')\n    parser.add_argument('-r', '--remote', default='origin',\n                        help=\"The remote name (default is 'origin')\")\n    parser.add_argument('-b', '--branch', help='The branch name (default is whatever HEAD is pointing to)',\n                        default='HEAD')\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n    return publish(args)\n\n\nif __name__ == '__main__':\n    sys.exit(main())\n\n\nThen git publish -h will show you usage information:\n\nusage: git-publish [-h] [-r REMOTE] [-b BRANCH]\n\nPush and set upstream for a branch\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -r REMOTE, --remote REMOTE\n                        The remote name (default is 'origin')\n  -b BRANCH, --branch BRANCH\n                        The branch name (default is whatever HEAD is pointing to)\n\nShare\nImprove this answer\nFollow\nedited May 16 '20 at 12:10\nanswered Dec 31 '19 at 13:47\nEugene Yarmash\n123k34\n34 gold badges\n284\n284 silver badges\n342\n342 bronze badges","comments":[]},{"answer":"I think this is the simplest alias, add to your ~/.gitconfig\n\n[alias]\n  publish-branch = !git push -u origin $(git rev-parse --abbrev-ref HEAD)\n\n\nYou just run\n\ngit publish-branch\n\n\nand... it publishes the branch\n\nShare\nImprove this answer\nFollow\nanswered Jan 16 at 2:54\nDevin Rhode\n19.2k6\n6 gold badges\n43\n43 silver badges\n59\n59 bronze badges","comments":[]}]},{"id":"3737139","href":"https://stackoverflow.com/questions/3737139/reference-what-does-this-symbol-mean-in-php","title":"Reference — What does this symbol mean in PHP?","description":"\n                \nWhat is this?\nThis is a collection of questions that come up every now and then about syntax in PHP. This is also a Community Wiki, so everyone is invited to participate in maintaining this list.\nWhy is this?\nIt used to be hard to find questions about operators and other syntax tokens.¹\nThe main idea is to have links to existing questions on Stack Overflow, so it's easier for us to reference them, not to copy over content from the PHP Manual.\nNote: Since January 2013, Stack Overflow does support special characters. Just surround the search terms by quotes, e.g. [php] \"==\" vs \"===\"\nWhat should I do here?\nIf you have been pointed here by someone because you have asked such a question, please find the particular syntax below. The linked pages to the PHP manual along with the linked questions will likely answer your question then. If so, you are encouraged to upvote the answer. This list is not meant as a substitute to the help others provided.\nThe List\nIf your particular token is not listed below, you might find it in the List of Parser Tokens.\n\n& Bitwise Operators or References\n\nWhat does it mean to start a PHP function with an ampersand?\nUnderstanding PHP & (ampersand, bitwise and) operator\nPHP \"&\" operator\nDifference between & and && in PHP\nWhat does \"&\" mean here in PHP?\nWhat does \"&\" mean in this case?\nWhat does the \"&\" sign mean in PHP?\nWhat does this signature mean (&) in PHP?\nHow does the \"&\" operator work in a PHP function?\nWhat does & in &2 mean in PHP?\nWhen should I use a bitwise operator?\nIs there ever a need to use ampersand in front of an object? (&$)\n\n\n=& References\n\nReference assignment operator in PHP, =&\nWhat do the \"=&\" and \"&=\" operators in PHP mean?\nWhat do the '&=' and '=&' operators do?\nWhat does =& mean in PHP?\n\n\n&= Bitwise Operators\n\nWhat do the \"=&\" and \"&=\" operators in PHP mean?\nWhat do the '&=' and '=&' operators do?\n\n\n&& Logical Operators\n\n'AND' vs '&&' as operator\nDifference between & and && in PHP\nIs there any difference between \"and\" and \"&&\" operators in PHP?\nPHP - and / or keywords\n\n\n% Arithmetic Operators\n\nWhat does the percent sign mean in PHP?\nWhat is the PHP operator % and how do I use it in real-world examples?\n\n\n!! Logical Operators\n\nDouble not (!!) operator in PHP\n\n\n@ Error Control Operators\n\nWhat is the use of the @ symbol in PHP?\n'At' symbol before variable name in PHP: @$_POST\nPHP functions and @functions\nShould I use @ in my PHP code?\nWhat does @ mean in PHP?\n\n\n?: Ternary Operator\n\nWhat are the PHP operators \"?\" and \":\" called and what do they do?\n?: operator (the 'Elvis operator') in PHP\nWhere can I read about conditionals done with \"?\" and \":\" (colon)?\nUsing PHP 5.3 ?: operator\n\n\n?? Null Coalesce Operator (since PHP 7)\n\nC#'s null coalescing operator (??) in PHP\n\n\n?string\n?int\n?array\n?bool\n?float Nullable return type declaration (since PHP 7.1)\n\nNullable return type declaration\nphp method argument type hinting with question mark (?type)\n\n\n: Alternative syntax for control structures, Ternary Operator, Return Type Declaration\n\nWhat is \":\" in PHP?\nWhat does \":\" mean in PHP?\nColon after method declaration?\n\n\n:: Scope Resolution Operator\n\nWhat do two colons mean in PHP?\nWhat's the meaning of the PHP token name T_PAAMAYIM_NEKUDOTAYIM?\nWhat's the difference between :: (double colon) and -> (arrow) in PHP?\nWhat exactly are late static bindings in PHP?\nstatic::staticFunctionName()\nUnexpected T_PAAMAYIM_NEKUDOTAYIM, expecting T_NS_Separator\n\n\n\\ Namespaces\n\nBackslash in PHP -- what does it mean?\nWhat does a \\ (backslash) do in PHP (5.3+)?\n\n\n-> Classes And Objects\n\nWhat is the \"->\" PHP operator called?\nWhere do we use the object operator \"->\" in PHP?\nWhat's the difference between :: (double colon) and -> (arrow) in PHP?\nWhat does the PHP syntax $var1->$var2 mean?\nWhat does \"->\" mean/refer to in PHP?\n\n\n=> Arrays\n\nWhat does \"=>\" mean in PHP?\nUse of => in PHP\nWhat does $k => $v in foreach($ex as $k=>$v) mean?\n\n\n^ Bitwise Operators\n\nHow does the bitwise operator XOR ('^') work?\nWhat does ^ mean in PHP?\n\n\n>> Bitwise Operators\n\nWhat does >> mean in PHP?\n\n\n<< Bitwise Operators\n\nStrange print behaviour in PHP?\n\n\n<<< Heredoc or Nowdoc\n\nWhat does <<<END mean in PHP?\nPHP expression <<<EOB\nIn PHP, what does \"<<<\" represent?\nUsing <<<CON in PHP\nWhat's this kind of syntax in PHP?\n\n\n= Assignment Operators\n\nThe 3 different equals\n\n\n== Comparison Operators\n\nHow do the PHP equality (== double equals) and identity (=== triple equals) comparison operators differ?\nPHP != and == operators\nThe 3 different equals\nType-juggling and (strict) greater/lesser-than comparisons in PHP\n\n\n=== Comparison Operators\n\nWhat does \"===\" mean?\nHow do the PHP equality (== double equals) and identity (=== triple equals) comparison operators differ?\nThe 3 different equals\nType-juggling and (strict) greater/lesser-than comparisons in PHP\n\n\n!== Comparison Operators\n\nWhat does !== comparison operator in PHP mean?\nIs there a difference between !== and != in PHP?\n\n\n!= Comparison Operators\n\nPHP != and == operators\nIs there a difference between !== and != in PHP?\ncomparing, !== versus !=\nWhat is the difference between <> and !=\n\n\n<> Comparison Operators\n\nPHP operator <>\nPHP's <> operator\nWhat is the difference between <> and !=\nType-juggling and (strict) greater/lesser-than comparisons in PHP\n\n\n<=> Comparison Operators (since PHP 7.0)\n\nSpaceship (three way comparison) operator\n\n\n| Bitwise Operators\n\nWhat is the difference between the | and || operators?\nWhat Does Using A Single Pipe '|' In A Function Argument Do?\n\n\n|| Logical Operators\n\nWhat is the difference between the | and || operators?\nPHP - and / or keywords\nWhat exactly does || mean?\nThe behaviour of the or operator in PHP\n\n\n~ Bitwise Operators\n\nWhat does this ~ operator mean here?\n\n\n+ Arithmetic Operators, Array Operators\n\n+ operator for array in PHP?\n\n\n+= and -= Assignment Operators\n\nWhat is += used for?\nWhat does `$page -= 1` in my PHP document mean?\n\n\n++ and -- Incrementing/Decrementing Operators\n\nUnderstanding Incrementing\nAnswer below\n\n\n.= Assignment Operators\n\nWhat is the difference between .= and += in PHP?\nTo understand a line of PHP\n\n\n. String Operators\n\nDifference between period and comma when concatenating with echo versus return?\nWhat does a . (dot) do in PHP?\n\n\n, Function Arguments\n\nDifference between period and comma when concatenating with echo versus return?\n\n, Variable Declarations\n\nWhat do commas mean in a variable declaration?\n\n\n$$ Variable Variables\n\nWhat does $$ (dollar dollar or double dollar) mean in PHP?\nwhat is \"$$\" in PHP\n$function() and $$variable\n\n\n` Execution Operator\n\nWhat are the backticks `` called?\n\n\n<?= Short Open Tags\n\nWhat does this symbol mean in PHP <?=\nWhat does '<?=' mean in PHP?\nWhat does <?= mean?\n\n\n[] Arrays (short syntax since PHP 5.4)\n\nPHP arrays... What is/are the meaning(s) of an empty bracket?\nWhat is the meaning of []\nPhp array_push() vs myArray[]\nWhat does [] mean when reading from a PHP array?\nShorthand for arrays: literal $var = [] empty array\n\n\n<? Opening and Closing tags\n\nAre PHP short tags acceptable to use?\n\n\n... Argument unpacking (since PHP 5.6)\n\n** Exponentiation (since PHP 5.6)\n\n# One-line shell-style comment\n\nCan I use hashes for comments in PHP?\n\n\n?-> NullSafe Operator Calls (since PHP 8.0)\n\nWhat does this symbol mean \"?->\" in php, within an object or null value\n\n\n    ","questionComments":["I know this isn't strictly PHP, but what about including a link to phpdoc.org for phpDocumentor comment syntax, which is commonly used and it's also impossible to search for /**?","Can I suggest square bracket and curly bracket ?","I ran into this problem a lot too (not being able to search for special characters), which is why I made SymbolHound, a search engine that doesn't ignore special characters. I also posted it on StackApps.","Well, from the heading Why is this?, I'd guess it's because \"The main idea is to have links to existing questions on Stack Overflow, so it's easier for us to reference them\".","A question was asked today (Nov.20/15) stackoverflow.com/questions/33833259/what-is-rscat-in-php asking \"What is $rsCat in php\" (should that question still be made visible and not deleted). Strangely enough, there isn't a reference about $ variable, but about $$ Variable Variables only. I believe that should be amended somewhere."],"answers":[{"answer":"Incrementing / Decrementing Operators\n\n++ increment operator\n\n-- decrement operator\n\nExample    Name              Effect\n---------------------------------------------------------------------\n++$a       Pre-increment     Increments $a by one, then returns $a.\n$a++       Post-increment    Returns $a, then increments $a by one.\n--$a       Pre-decrement     Decrements $a by one, then returns $a.\n$a--       Post-decrement    Returns $a, then decrements $a by one.\n\n\nThese can go before or after the variable.\n\nIf put before the variable, the increment/decrement operation is done to the variable first then the result is returned. If put after the variable, the variable is first returned, then the increment/decrement operation is done.\n\nFor example:\n\n$apples = 10;\nfor ($i = 0; $i < 10; ++$i) {\n    echo 'I have ' . $apples-- . \" apples. I just ate one.\\n\";\n}\n\n\nLive example\n\nIn the case above ++$i is used, since it is faster. $i++ would have the same results.\n\nPre-increment is a little bit faster because it really increments the variable and after that 'returns' the result. Post-increment creates a special variable, copies there the value of the first variable and only after the first variable is used, replaces its value with second's.\n\nHowever, you must use $apples--, since first, you want to display the current number of apples, and then you want to subtract one from it.\n\nYou can also increment letters in PHP:\n\n$i = \"a\";\nwhile ($i < \"c\") {\n    echo $i++;\n}\n\n\nOnce z is reached aa is next, and so on.\n\nNote that character variables can be incremented but not decremented and even so only plain ASCII characters (a-z and A-Z) are supported.\n\nStack Overflow Posts:\n\nUnderstanding Incrementing\nShare\nImprove this answer\nFollow\nedited Nov 12 '18 at 8:39\ncommunity wiki\n\n\n16 revs, 9 users 80%\nPeter Ajtai","comments":["For everyone's sake, please remove the bolded information about pre-incrementing being infinitesimally faster. This is the absolute worst example of premature optimization and this kind of information should not be in people's heads if they are just starting to learn PHP.","@Lotus - I consider it a fun fact. If you're a beginner to PHP, or C++, etc, it seems pretty wacky that ++i and i++ are different enough to work at different speeds. I found it fascinating.","@Peter Ajtai Yes, it's interesting, but from the way you've structured your post you make it seem like one of the prime facts of PHP that is absolutely vital to using the language."]},{"answer":"Bitwise Operator\n\nWhat is a bit? A bit is a representation of 1 or 0. Basically OFF(0) and ON(1)\n\nWhat is a byte? A byte is made up of 8 bits and the highest value of a byte is 255, which would mean every bit is set. We will look at why a byte's maximum value is 255.\n\n-------------------------------------------\n|      1 Byte ( 8 bits )                  |\n-------------------------------------------\n|Place Value | 128| 64| 32| 16| 8| 4| 2| 1|     \n-------------------------------------------\n\n\nThis representation of 1 Byte\n\n1 + 2 + 4 + 8 + 16 + 32 + 64 + 128 = 255 (1 Byte)\n\nA few examples for better understanding\nThe \"AND\" operator: &\n$a =  9;\n$b = 10;\necho $a & $b;\n\n\nThis would output the number 8. Why? Well let's see using our table example.\n\n-------------------------------------------\n|      1 Byte ( 8 bits )                  |\n-------------------------------------------\n|Place Value | 128| 64| 32| 16| 8| 4| 2| 1|     \n-------------------------------------------\n|      $a    |   0|  0|  0|  0| 1| 0| 0| 1|    \n-------------------------------------------\n|      $b    |   0|  0|  0|  0| 1| 0| 1| 0|\n------------------------------------------- \n|      &     |   0|  0|  0|  0| 1| 0| 0| 0|\n------------------------------------------- \n\n\nSo you can see from the table the only bit they share together is the 8 bit.\n\nSecond example\n\n$a =  36;\n$b = 103;\necho $a & $b; // This would output the number 36.\n$a = 00100100\n$b = 01100111\n\n\nThe two shared bits are 32 and 4, which when added together return 36.\n\nThe \"Or\" operator: |\n$a =  9;\n$b = 10;\necho $a | $b;\n\n\nThis would output the number 11. Why?\n\n-------------------------------------------\n|      1 Byte ( 8 bits )                  |\n-------------------------------------------\n|Place Value | 128| 64| 32| 16| 8| 4| 2| 1|     \n-------------------------------------------\n|      $a    |   0|  0|  0|  0| 1| 0| 0| 1|    \n-------------------------------------------\n|      $b    |   0|  0|  0|  0| 1| 0| 1| 0|\n------------------------------------------- \n|      |     |   0|  0|  0|  0| 1| 0| 1| 1|\n-------------------------------------------\n\n\nYou will notice that we have 3 bits set, in the 8, 2, and 1 columns. Add those up: 8+2+1=11.\n\nShare\nImprove this answer\nFollow\nedited Sep 19 '16 at 12:15\ncommunity wiki\n\n\n3 revs, 3 users 62%\nAnkur Saxena","comments":["What if $a takes a value greater than 255?","@AycanYaşıt Most of the operating system is using 32 bit and 64 bit system, that means the limit is much more than 255 (8 bits).","@AycanYaşıt Actually, the representation here with one byte length isn't even correct, as even the smallest integer is still 64 bit (8 byte) in memory on a modern 64bit platform.","Why and & is 0 0 0 0 1 0 0 0 and or | is 0 0 0 0 1 0 1 1?"]},{"answer":"<=> Spaceship Operator\nAdded in PHP 7\n\nThe spaceship operator <=> is the latest comparison operator added in PHP 7. It is a non-associative binary operator with the same precedence as equality operators (==, !=, ===, !==). This operator allows for simpler three-way comparison between left-hand and right-hand operands.\n\nThe operator results in an integer expression of:\n\n0 when both operands are equal\nLess than 0 when the left-hand operand is less than the right-hand operand\nGreater than 0 when the left-hand operand is greater than the right-hand operand\n\ne.g.\n\n1 <=> 1; // 0\n1 <=> 2; // -1\n2 <=> 1; // 1\n\n\nA good practical application of using this operator would be in comparison type callbacks that are expected to return a zero, negative, or positive integer based on a three-way comparison between two values. The comparison function passed to usort is one such example.\n\nBefore PHP 7 you would write...\n$arr = [4,2,1,3];\n\nusort($arr, function ($a, $b) {\n    if ($a < $b) {\n        return -1;\n    } elseif ($a > $b) {\n        return 1;\n    } else {\n        return 0;\n    }\n});\n\nSince PHP 7 you can write...\n$arr = [4,2,1,3];\n\nusort($arr, function ($a, $b) {\n    return $a <=> $b;\n    // return -1 * ($a <=> $b); // for reversing order\n});\n\nShare\nImprove this answer\nFollow\nedited Apr 26 at 0:32\ncommunity wiki\n\n\n12 revs, 6 users 78%\nSherif","comments":["Not sure how $a <=> $b is different to $a - $b","@AcidShout $a - $b works for numbers, but not strings, objects, or arrays.","@mcrumley No, it's worse than that. In general $a - $b doesn't even work for numbers; it works only for integers. It doesn't work for non-integer numbers, because usort casts your comparator function's return values to int, which means 0.5 gets cast to 0, which means that two numbers with a difference of less than 1, such as 4 and 4.6, may (depending upon which one gets passed as the first argument to your comparator function) incorrectly compare as equal.","@MarkAmery the migration guide isn't the documented behavior of the operator. For that you want to look at the language operators section of the manual for that php.net/language.operators.comparison the actual behavior behind this relies on various comparison functions of the API, like when you're doing strcmp for strings, where you can not guarantee the actual return value in every single case. Sure, it's almost always 1, 0, or -1, but for the cases where you can't guarantee it like in wrapping libc's strcmp, you offer up the same defined behavior as the underlying spec to be safe","@MarkAmery The point here is not to allow people to rely on undefined behavior. For the one case where someones gets a value that is not exactly 1, 0, or -1, you get someone filing a bug report thinking there's something wrong in the language. Which is why we document that all we can guarantee is that value will be less than, greater than, or equal to 0, and not necessarily 1, 0, and -1."]},{"answer":"_ Alias for gettext()\n\nThe underscore character '_' as in _() is an alias to the gettext() function.\n\nShare\nImprove this answer\nFollow\nedited Feb 19 '18 at 8:14\ncommunity wiki\n\n\n4 revs, 4 users 75%\nHabeeb Perwad","comments":["Any idea what the double underscore function is? __(). It is used in WordPress. I cannot find a definition for it anywhere. Example of its use: core.trac.wordpress.org/browser/tags/5.4/src/wp-admin/includes/…. It seems that to use the WP image_size_names_choose() filter, __() must be used to add the \"short name\" to the array of named_sizes you want to add.","@SherylHohman Look like it is translation function. developer.wordpress.org/reference/functions/__","Thanks so much! I envy your superior Google skills (and vast coding knowledge) :-)"]},{"answer":"Syntax\tName\tDescription\nx == y\tEquality\ttrue if x and y have the same key/value pairs\nx != y\tInequality\ttrue if x is not equal to y\nx === y\tIdentity\ttrue if x and y have the same key/value pairs\nin the same order and of the same types\nx !== y\tNon-identity\ttrue if x is not identical to y\nx <=> y\tSpaceship\t0 if x is equal to y, greater than 0 if x > y, less than 0 if x < y\n++x\tPre-increment\tIncrements x by one, then returns x\nx++\tPost-increment\tReturns x, then increments x by one\n--x\tPre-decrement\tDecrements x by one, then returns x\nx--\tPost-decrement\tReturns x, then decrements x by one\nx and y\tAnd\ttrue if both x and y are true. If x=6, y=3 then\n(x < 10 and y > 1) returns true\nx && y\tAnd\ttrue if both x and y are true. If x=6, y=3 then\n(x < 10 && y > 1) returns true\nx or y\tOr\ttrue if any of x or y are true. If x=6, y=3 then\n(x < 10 or y > 10) returns true\nx || y\tOr\ttrue if any of x or y are true. If x=6, y=3 then\n(x < 3 || y > 1) returns true\na . b\tConcatenation\tConcatenate two strings: \"Hi\" . \"Ha\"\nShare\nImprove this answer\nFollow\nedited Jul 7 at 17:59\ncommunity wiki\n\n\n10 revs, 10 users 20%\nAnkur Saxena","comments":[]},{"answer":"Magic constants: Although these are not just symbols but important part of this token family. There are eight magical constants that change depending on where they are used.\n\n__LINE__: The current line number of the file.\n\n__FILE__: The full path and filename of the file. If used inside an include, the name of the included file is returned. Since PHP 4.0.2, __FILE__ always contains an absolute path with symlinks resolved whereas in older versions it contained relative path under some circumstances.\n\n__DIR__: The directory of the file. If used inside an include, the directory of the included file is returned. This is equivalent to dirname(__FILE__). This directory name does not have a trailing slash unless it is the root directory. (Added in PHP 5.3.0.)\n\n__FUNCTION__: The function name. (Added in PHP 4.3.0) As of PHP 5 this constant returns the function name as it was declared (case-sensitive). In PHP 4 its value is always lowercased.\n\n__CLASS__: The class name. (Added in PHP 4.3.0) As of PHP 5 this constant returns the class name as it was declared (case-sensitive). In PHP 4 its value is always lowercased. The class name includes the namespace it was declared in (e.g. Foo\\Bar). Note that as of PHP 5.4 __CLASS__ works also in traits. When used in a trait method, __CLASS__ is the name of the class the trait is used in.\n\n__TRAIT__: The trait name. (Added in PHP 5.4.0) As of PHP 5.4 this constant returns the trait as it was declared (case-sensitive). The trait name includes the namespace it was declared in (e.g. Foo\\Bar).\n\n__METHOD__: The class method name. (Added in PHP 5.0.0) The method name is returned as it was declared (case-sensitive).\n\n__NAMESPACE__: The name of the current namespace (case-sensitive). This constant is defined in compile-time (Added in PHP 5.3.0).\n\nSource\n\nShare\nImprove this answer\nFollow\nedited Feb 21 '14 at 0:42\ncommunity wiki\n\n\n2 revs, 2 users 66%\nn.1","comments":[]},{"answer":"Type Operators\n\ninstanceof is used to determine whether a PHP variable is an instantiated object of a certain class.\n\n<?php\nclass mclass { }\nclass sclass { }\n$a = new mclass;\nvar_dump($a instanceof mclass);\nvar_dump($a instanceof sclass);\n\n\nThe above example will output:\n\nbool(true)\nbool(false)\n\n\nReason: Above Example $a is a object of the mclass so use only a mclass data not instance of with the sclass\n\nExample with inheritance\n<?php \nclass pclass { } \nclass childclass extends pclass { } \n$a = new childclass; \nvar_dump($a instanceof childclass); \nvar_dump($a instanceof pclass);\n\n\nThe above example will output:\n\nbool(true)\nbool(true)\n\nExample with Clone\n<?php \nclass cloneable { } \n$a = new cloneable;\n$b = clone $a; \nvar_dump($a instanceof cloneable); \nvar_dump($b instanceof cloneable);\n\n\nThe above example will output:\n\nbool(true)\nbool(true)\n\nShare\nImprove this answer\nFollow\nedited Mar 13 '16 at 1:16\ncommunity wiki\n\n\n3 revs, 3 users 51%\nMaulik patel","comments":["The above works with 'interfaces' as well. This is useful for checking that a particular interface is available."]},{"answer":"An overview of operators in PHP:\nLogical Operators:\n$a && $b : TRUE if both $a and $b are TRUE.\n$a || $b : TRUE if either $a or $b is TRUE.\n$a xor $b : TRUE if either $a or $b is TRUE, but not both.\n! $a : TRUE if $a is not TRUE.\n$a and $b : TRUE if both $a and $b are TRUE.\n$a or $b : TRUE if either $a or $b is TRUE.\nComparison operators:\n$a == $b : TRUE if $a is equal to $b after type juggling.\n$a === $b : TRUE if $a is equal to $b, and they are of the same type.\n$a != $b : TRUE if $a is not equal to $b after type juggling.\n$a <> $b : TRUE if $a is not equal to $b after type juggling.\n$a !== $b : TRUE if $a is not equal to $b, or they are not of the same type.\n$a < $b : TRUE if $a is strictly less than $b.\n$a > $b : TRUE if $a is strictly greater than $b.\n$a <= $b : TRUE if $a is less than or equal to $b.\n$a >= $b : TRUE if $a is greater than or equal to $b.\n$a <=> $b : An integer less than, equal to, or greater than zero when $a is respectively less than, equal to, or greater than $b. Available as of PHP 7.\n$a ? $b : $c : if $a return $b else return $c (ternary operator)\n$a ?? $c : Same as $a ? $a : $c (null coalescing operator - requires PHP>=7)\nArithmetic Operators:\n-$a : Opposite of $a.\n$a + $b : Sum of $a and $b.\n$a - $b : Difference of $a and $b.\n$a * $b : Product of $a and $b.\n$a / $b : Quotient of $a and $b.\n$a % $b : Remainder of $a divided by $b.\n$a ** $b : Result of raising $a to the $b'th power (introduced in PHP 5.6)\nIncrementing/Decrementing Operators:\n++$a : Increments $a by one, then returns $a.\n$a++ : Returns $a, then increments $a by one.\n--$a : Decrements $a by one, then returns $a.\n$a-- : Returns $a, then decrements $a by one.\nBitwise Operators:\n$a & $b : Bits that are set in both $a and $b are set.\n$a | $b : Bits that are set in either $a or $b are set.\n$a ^ $b : Bits that are set in $a or $b but not both are set.\n~ $a : Bits that are set in $a are not set, and vice versa.\n$a << $b : Shift the bits of $a $b steps to the left (each step means \"multiply by two\")\n$a >> $b : Shift the bits of $a $b steps to the right (each step means \"divide by two\")\nString Operators:\n$a . $b : Concatenation of $a and $b.\nArray Operators:\n$a + $b : Union of $a and $b.\n$a == $b : TRUE if $a and $b have the same key/value pairs.\n$a === $b : TRUE if $a and $b have the same key/value pairs in the same order and of the same types.\n$a != $b : TRUE if $a is not equal to $b.\n$a <> $b : TRUE if $a is not equal to $b.\n$a !== $b : TRUE if $a is not identical to $b.\nAssignment Operators:\n$a = $b : The value of $b is assigned to $a\n$a += $b : Same as $a = $a + $b\n$a -= $b : Same as $a = $a - $b\n*$a = $b : Same as $a = $a * $b\n$a /= $b : Same as $a = $a / $b\n$a %= $b : Same as $a = $a % $b\n**$a = $b : Same as $a = $a ** $b\n$a .= $b : Same as $a = $a . $b\n$a &= $b : Same as $a = $a & $b\n$a |= $b : Same as $a = $a | $b\n$a ^= $b : Same as $a = $a ^ $b\n$a <<= $b : Same as $a = $a << $b\n$a >>= $b : Same as $a = $a >> $b\n$a ??= $b : The value of $b is assigned to $a if $a is null or not defined (null coalescing assignment operator - requires PHP>=7.4)\nNote\n\nand operator and or operator have lower precedence than assignment operator =.\n\nThis means that $a = true and false; is equivalent to ($a = true) and false.\n\nIn most cases you will probably want to use && and ||, which behave in a way known from languages like C, Java or JavaScript.\n\nShare\nImprove this answer\nFollow\nedited Jan 21 at 13:52\ncommunity wiki\n\n\n14 revs, 9 users 86%\nJohn Slegers","comments":["There is an error in $a ?? $c, it says is the same as $a ? $a : $c, but ternary operator checks if value is true, on the other hand, null coalescing checks for null values, so, if $a is 0, you will get 0 (because 0 is not null), for example if you have: $a=0; $c=5; then $a?$a:$c returns 5, and $a??$c returns 0."]},{"answer":"Spaceship Operator <=> (Added in PHP 7)\n\nExamples for <=> Spaceship operator (PHP 7, Source: PHP Manual):\n\nIntegers, Floats, Strings, Arrays & objects for Three-way comparison of variables.\n\n// Integers\necho 10 <=> 10; // 0\necho 10 <=> 20; // -1\necho 20 <=> 10; // 1\n\n// Floats\necho 1.5 <=> 1.5; // 0\necho 1.5 <=> 2.5; // -1\necho 2.5 <=> 1.5; // 1\n\n// Strings\necho \"a\" <=> \"a\"; // 0\necho \"a\" <=> \"b\"; // -1\necho \"b\" <=> \"a\"; // 1\n// Comparison is case-sensitive\necho \"B\" <=> \"a\"; // -1\n\necho \"a\" <=> \"aa\"; // -1\necho \"zz\" <=> \"aa\"; // 1\n\n// Arrays\necho [] <=> []; // 0\necho [1, 2, 3] <=> [1, 2, 3]; // 0\necho [1, 2, 3] <=> []; // 1\necho [1, 2, 3] <=> [1, 2, 1]; // 1\necho [1, 2, 3] <=> [1, 2, 4]; // -1\n\n// Objects\n$a = (object) [\"a\" => \"b\"]; \n$b = (object) [\"a\" => \"b\"]; \necho $a <=> $b; // 0\n\n$a = (object) [\"a\" => \"b\"]; \n$b = (object) [\"a\" => \"c\"]; \necho $a <=> $b; // -1\n\n$a = (object) [\"a\" => \"c\"]; \n$b = (object) [\"a\" => \"b\"]; \necho $a <=> $b; // 1\n\n// only values are compared\n$a = (object) [\"a\" => \"b\"]; \n$b = (object) [\"b\" => \"b\"]; \necho $a <=> $b; // 1\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n6 revs, 4 users 93%\nrajangupta","comments":[]},{"answer":"{} Curly braces\n\nBlocks - curly braces/no curly braces?\nCurly braces in string in PHP\nPHP curly braces in array notation\n\nAnd some words about last post\n\n$x[4] = 'd'; // it works\n$x{4} = 'd'; // it works\n\n$echo $x[4]; // it works\n$echo $x{4}; // it works\n\n$x[] = 'e'; // it works\n$x{} = 'e'; // does not work\n\n$x = [1, 2]; // it works\n$x = {1, 2}; // does not work\n\necho \"${x[4]}\"; // it works\necho \"${x{4}}\"; // does not work\n\necho \"{$x[4]}\"; // it works\necho \"{$x{4}}\"; // it works\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:02\ncommunity wiki\n\n\n2 revs\nmnv","comments":["{''} notation for property names. echo $movies->movie->{'great-lines'}->line; can be used to access data in SimpleXMLElement. Maybe it can be used in other cases too. php.net/manual/en/simplexml.examples-basic.php"]},{"answer":"Null coalescing operator (??)\n\nThis operator has been added in PHP 7.0 for the common case of needing to use a ternary operator in conjunction with isset(). It returns its first operand if it exists and is not NULL; otherwise it returns its second operand.\n\n<?php\n// Fetches the value of $_GET['user'] and returns 'nobody'\n// if it does not exist.\n$username = $_GET['user'] ?? 'nobody';\n// This is equivalent to:\n$username = isset($_GET['user']) ? $_GET['user'] : 'nobody';\n\n// Coalescing can be chained: this will return the first\n// defined value out of $_GET['user'], $_POST['user'], and\n// 'nobody'.\n$username = $_GET['user'] ?? $_POST['user'] ?? 'nobody';\n?>\n\nShare\nImprove this answer\nFollow\nedited Feb 16 '18 at 14:14\ncommunity wiki\n\n\n3 revs, 3 users 94%\nVIPIN A ROY","comments":[]},{"answer":"PHP Strings: PHP Strings can be specified in four ways not just two ways:\n\n1) Single Quote Strings:\n\n$string = 'This is my string'; // print This is my string\n\n\n2) Double Quote Strings:\n\n$str = 'string';\n\n$string = \"This is my $str\"; // print This is my string\n\n\n3) Heredoc:\n\n$string = <<<EOD\nThis is my string\nEOD; // print This is my string\n\n\n4) Nowdoc (since PHP 5.3.0):\n\n$string = <<<'END_OF_STRING'\n    This is my string \nEND_OF_STRING; // print This is my string\n\nShare\nImprove this answer\nFollow\nedited Feb 2 '16 at 13:13\ncommunity wiki\n\n\n3 revs, 3 users 90%\ndevpro","comments":["@Rizier123 : What does mean by \"Heredocs can not be used for initializing class properties. Since PHP 5.3, this limitation is valid only for heredocs containing variables.\"?"]},{"answer":"QUESTION:\n\nWhat does => mean?\n\nANSWER:\n\n=> Is the symbol we humans decided to use to separate \"Key\" => \"Value\" pairs in Associative Arrays.\n\nELABORATING:\n\nTo understand this, we have to know what Associative Arrays are. The first thing that comes up when a conventional programmer thinks of an array (in PHP) would be something similar to:\n\n$myArray1 = array(2016, \"hello\", 33);//option 1\n\n$myArray2 = [2016, \"hello\", 33];//option 2\n\n$myArray3 = [];//option 3\n$myArray3[] = 2016; \n$myArray3[] = \"hello\"; \n$myArray3[] = 33;\n\n\nWhere as, if we wanted to call the array in some later part of the code, we could do:\n\necho $myArray1[1];// output: hello\necho $myArray2[1];// output: hello\necho $myArray3[1];// output: hello\n\n\nSo far so good. However, as humans, we might find it hard to remember that index [0] of the array is the value of the year 2016, index [1] of the array is a greetings, and index [2] of the array is a simple integer value. The alternative we would then have is to use what is called an Associative Array. An Associative array has a few differences from a Sequential Array (which is what the previous cases were since they increment the index used in a predetermined sequence, by incrementing by 1 for each following value).\n\nDifferences (between a sequential and associative array):\n\nDurring the declaration of an Associative Array, you don't only include the value of what you want to put in the array, but you also put the index value (called the key) which you want to use when calling the array in later parts of the code. The following syntax is used during it's declaration: \"key\" => \"value\".\n\nWhen using the Associative Array, the key value would then be placed inside the index of the array to retrieve the desired value.\n\nFor instance:\n\n$myArray1 = array( \n    \"Year\" => 2016, \n    \"Greetings\" => \"hello\", \n    \"Integer_value\" => 33);//option 1\n\n$myArray2 = [ \n    \"Year\" =>  2016, \n    \"Greetings\" => \"hello\", \n    \"Integer_value\" => 33];//option 2\n\n$myArray3 = [];//option 3\n$myArray3[\"Year\"] = 2016; \n$myArray3[\"Greetings\"] = \"hello\"; \n$myArray3[\"Integer_value\"] = 33;\n\n\nAnd now, to receive the same output as before, the key value would be used in the arrays index:\n\necho $myArray1[\"Greetings\"];// output: hello\necho $myArray2[\"Greetings\"];// output: hello\necho $myArray3[\"Greetings\"];// output: hello\n\n\nFINAL POINT:\n\nSo from the above example, it is pretty easy to see that the => symbol is used to express the relationship of an Associative Array between each of the key and value pairs in an array DURING the initiation of the values within the array.\n\nShare\nImprove this answer\nFollow\nedited Dec 7 '20 at 10:03\ncommunity wiki\n\n\n4 revs, 2 users 63%\nWebeng","comments":[]},{"answer":"Question:\n\nWhat does \"&\" mean here in PHP?\n\nPHP \"&\" operator\n\nMakes life more easier once we get used to it..(check example below carefully)\n\n& usually checks bits that are set in both $a and $b are set.\n\nhave you even noticed how these calls works?\n\n   error_reporting(E_ERROR | E_WARNING | E_PARSE);\n    error_reporting(E_ERROR | E_WARNING | E_PARSE | E_NOTICE);\n    error_reporting(E_ALL & ~E_NOTICE);\n    error_reporting(E_ALL);\n\n\nSo behind all above is game of bitwise operator and bits.\n\nOne usefull case of these is easy configurations like give below, so a single integer field can store thousands of combos for you.\n\nMost people have already read the docs but didn't reliase the real world use case of these bitwise operators.\n\nExample That you 'll love\n<?php\n\nclass Config {\n\n    // our constants must be 1,2,4,8,16,32,64 ....so on\n    const TYPE_CAT=1;\n    const TYPE_DOG=2;\n    const TYPE_LION=4;\n    const TYPE_RAT=8;\n    const TYPE_BIRD=16;\n    const TYPE_ALL=31;\n\n    private $config;\n\n    public function __construct($config){\n        $this->config=$config;\n\n        if($this->is(Config::TYPE_CAT)){\n            echo 'cat ';\n        }\n        if($this->is(Config::TYPE_DOG)){\n            echo 'dog ';\n        }\n        if($this->is(Config::TYPE_RAT)){\n            echo 'rat ';\n        }\n        if($this->is(Config::TYPE_LION)){\n            echo 'lion ';\n        }\n        if($this->is(Config::TYPE_BIRD)){\n            echo 'bird ';\n        }\n        echo \"\\n\";\n    }\n\n    private function is($value){\n        return $this->config & $value;\n    }\n}\n\nnew Config(Config::TYPE_ALL);\n// cat dog rat lion bird\nnew Config(Config::TYPE_BIRD);\n//bird\nnew Config(Config::TYPE_BIRD | Config::TYPE_DOG);\n//dog bird\nnew Config(Config::TYPE_ALL & ~Config::TYPE_DOG & ~Config::TYPE_CAT);\n//rat lion bird\n\nShare\nImprove this answer\nFollow\nedited Mar 20 '17 at 5:37\ncommunity wiki\n\n\n2 revs\ndev.mraj","comments":[]},{"answer":"== is used for check equality without considering variable data-type\n\n=== is used for check equality for both the variable value and data-type\n\nExample\n\n$a = 5\n\nif ($a == 5) - will evaluate to true\n\nif ($a == '5') - will evaluate to true, because while comparing this both value PHP internally convert that string value into integer and then compare both values\n\nif ($a === 5) - will evaluate to true\n\nif ($a === '5') - will evaluate to false, because value is 5, but this value 5 is not an integer.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n3 revs, 3 users 74%\nParth Nayak","comments":[]},{"answer":"Null Coalesce operator \"??\" (Added in PHP 7)\n\nNot the catchiest name for an operator, but PHP 7 brings in the rather handy null coalesce so I thought I'd share an example.\n\nIn PHP 5, we already have a ternary operator, which tests a value, and then returns the second element if that returns true and the third if it doesn't:\n\necho $count ? $count : 10; // outputs 10\n\n\nThere is also a shorthand for that which allows you to skip the second element if it's the same as the first one: echo $count ?: 10; // also outputs 10\n\nIn PHP 7 we additionally get the ?? operator which rather than indicating extreme confusion which is how I would usually use two question marks together instead allows us to chain together a string of values. Reading from left to right, the first value which exists and is not null is the value that will be returned.\n\n// $a is not set\n$b = 16;\n\necho $a ?? 2; // outputs 2\necho $a ?? $b ?? 7; // outputs 16\n\n\nThis construct is useful for giving priority to one or more values coming perhaps from user input or existing configuration, and safely falling back on a given default if that configuration is missing. It's kind of a small feature but it's one that I know I'll be using as soon as my applications upgrade to PHP 7.\n\nShare\nImprove this answer\nFollow\nanswered Dec 6 '17 at 16:05\ncommunity wiki\n\n\nYogi Ghorecha","comments":[]},{"answer":"Nullable return type declaration\n\nPHP 7 adds support for return type declarations. Similarly to argument type declarations, return type declarations specify the type of value that will be returned from a function. The same types are available for return type declarations as are available for argument type declarations.\n\nStrict typing also has an effect on return type declarations. In the default weak mode, returned values will be coerced to the correct type if they are not already of that type. In strong mode, the returned value must be of the correct type, otherwise, a TypeError will be thrown.\n\nAs of PHP 7.1.0, return values can be marked as nullable by prefixing the type name with a question mark (?). This signifies that the function returns either the specified type or NULL.\n\n<?php\nfunction get_item(): ?string {\n    if (isset($_GET['item'])) {\n        return $_GET['item'];\n    } else {\n        return null;\n    }\n}\n?>\n\n\nSource\n\nShare\nImprove this answer\nFollow\nedited May 1 '19 at 8:17\ncommunity wiki\n\n\n2 revs, 2 users 95%\nJohn Conde","comments":[]},{"answer":"Three DOTS as Splat Operator (...) (since PHP 5.6)\n\nPHP has an operator \"...\" (Three dots) which is referred as Splat Operator. It is used to pass arbitrary number of parameters in a function and this type of function is called Variadic Functions. Let’s take examples to use of \"...\" (Three dots).\n\nExample 1:\n\n<?php\nfunction calculateNumbers(...$params){\n    $total = 0;\n    foreach($params as $v){\n        $total = $total + $v;\n    }\n    return $total;\n}\n\necho calculateNumbers(10, 20, 30, 40, 50);\n\n//Output 150\n?>\n\n\nEach arguments of calculateNumbers() function pass through $params as an array when use \"… \".\n\nThere are many different ways to use \"… \" operator. Below some examples:\n\nExample 2:\n\n<?php\nfunction calculateNumbers($no1, $no2, $no3, $no4, $no5){\n    $total = $no1 + $no2 + $no3 + $no4 + $no5;\n    return $total;\n}\n\n$numbers = array(10, 20, 30, 40, 50);\necho calculateNumbers(...$numbers);\n\n//Output 150\n?>\n\n\nExample 3:\n\n<?php\nfunction calculateNumbers(...$params){\n    $total = 0;\n    foreach($params as $v){\n        $total = $total + $v;\n    }\n    return $total;\n}\n$no1 = 70;\n$numbers = array(10, 20, 30, 40, 50);\necho calculateNumbers($no1, ...$numbers);\n\n//Output 220\n?>\n\n\nExample 4:\n\n<?php\nfunction calculateNumbers(...$params){\n    $total = 0;\n    foreach($params as $v){\n        $total = $total + $v;\n    }\n    return $total;\n}\n\n$numbers1 = array(10, 20, 30, 40, 50);\n$numbers2 = array(100, 200, 300, 400, 500);\necho calculateNumbers(...$numbers1, ...$numbers2);\n\n//Output 1650\n\n?>\n\nShare\nImprove this answer\nFollow\nanswered Sep 30 '19 at 15:21\ncommunity wiki\n\n\nYogi Ghorecha","comments":["[TODO] Include new functionality in PHP8 to use the splat operator with \"named parameters\" ref: stackoverflow.com/a/64997399/2943403"]},{"answer":"?-> NullSafe Operator\n\nAdded in PHP 8.0\n\nIt's the NullSafe Operator, it returns null in case you try to invoke functions or get values from null. Nullsafe operator can be chained and can be used both on the methods and properties.\n\n$objDrive = null;\n$drive = $objDrive?->func?->getDriver()?->value; //return null\n$drive = $objDrive->func->getDriver()->value; // Error: Trying to get property 'func' of non-object\n\n\nNullsafe operator doesn't work with array keys:\n\n$drive['admin']?->getDriver()?->value //Warning: Trying to access array offset on value of type null\n\n$drive = [];\n$drive['admin']?->getAddress()?->value //Warning: Undefined array key \"admin\"\n\nShare\nImprove this answer\nFollow\nedited Nov 27 '20 at 22:25\ncommunity wiki\n\n\n4 revs, 2 users 69%\nJohn Conde","comments":["Adding this feels rather premature, nobody will see this operator in any live code, and it might not even be added. It would be better to wait until the details are finalised and document it properly.","We are already getting questions on it. :/ If the proposal fails we can then decide if this is worth keeping.","@JohnConde I'd be tempted to close them as off-topic, because they're asking about an imaginary programming language; or perhaps \"this question belongs on a different part of the timeline, please check the settings on your time machine\" ;)","lol The thought crossed my mind. I asked myself if this would offer value to future visitors and, for now, the answer is \"yes\". But that may change...","@JohnConde The problem is that we can't actually give a correct answer yet - the actual behaviour of the operator might completely change, or it might never be added, so anything we write now is as likely to mislead as inform. The only honest answer is \"a syntax error, but there's a possibility it will mean something in the future\"."]},{"answer":"NullSafe Operator \"?->\" (possibly) since php8\n\nIn PHP8 it's been accepted this new operator, you can find the documentation here. ?-> it's the NullSafe Operator, it returns null in case you try to invoke functions or get values from null...\n\nExamples:\n\n<?php\n$obj = null;\n$obj = $obj?->attr; //return null\n$obj = ?->funct(); // return null\n$obj = $objDrive->attr; // Error: Trying to get property 'attr' of non-object\n?>\n\nShare\nImprove this answer\nFollow\nedited Sep 21 '20 at 15:27\ncommunity wiki\n\n\n3 revs\nBerto99","comments":["Adding this feels rather premature, nobody will see this operator in any live code, and it might not even be added. It would be better to wait until the details are finalised and document it properly.","@IMSoP i'm with you, however i was invited to do so here stackoverflow.com/questions/62178354/… ...","It looks like we now have two answers about this. Personally, I would just have voted to close the other question rather than trying to answer, because right now there is no such operator.","@IMSoP there are a lot of questions here on StackOverflow about C++ Proposal, and they are not been closed: despite that, i'm with you about not posting here this operator for the moment","I don't know much about the C++ process and when it's reasonable to discuss proposals, and to be fair this one seems fairly likely to succeed workout modification, but in general there are a lot of features proposed for PHP that never make it to the language, and it would be rather confusing for users to come across them all in reference lists. That said, I'm partly just being a grumpy old man here :P"]},{"answer":"PHP Arrays:\n\nAn array is a data structure that stores one or more similar type of values in a single value\n\n• Numeric array − An array with a numeric index. Values are stored and accessed in linear fashion.\n\n• Associative array − An array with strings as index. This stores element values in association with key values rather than in a strict linear index order.\n\n• Multidimensional array − An array containing one or more arrays and values are accessed using multiple indices Numeric Array\n\nThese arrays can store numbers, strings and any object but their index will be represented by numbers. By default array index starts from zero.\n\nExample :\n\n<html>\n   <body>\n   \n      <?php\n         /* First method to create array. */\n         $numbers = array( 1, 2, 3, 4, 5);\n         \n         foreach( $numbers as $value ) {\n            echo \"Value is $value <br />\";\n         }\n         \n         /* Second method to create array. */\n         $numbers[0] = \"one\";\n         $numbers[1] = \"two\";\n         $numbers[2] = \"three\";\n         $numbers[3] = \"four\";\n         $numbers[4] = \"five\";\n         \n         foreach( $numbers as $value ) {\n            echo \"Value is $value <br />\";\n         }\n      ?>\n      \n   </body>\n</html>\n\n\nOutput :\n\nValue is 1 \nValue is 2 \nValue is 3 \nValue is 4 \nValue is 5 \nValue is one \nValue is two \nValue is three \nValue is four \nValue is five\n\n\nAssociative Arrays\n\nThe associative arrays are very similar to numeric arrays in term of functionality but they are different in terms of their index. Associative array will have their index as string so that you can establish a strong association between key and values.\n\nExample:\n\n<html>\n   <body>\n      \n      <?php\n         /* First method to associate create array. */\n         $salaries = array(\"mohammad\" => 2000, \"qadir\" => 1000, \"zara\" => 500);\n         \n         echo \"Salary of mohammad is \". $salaries['mohammad'] . \"<br />\";\n         echo \"Salary of qadir is \".  $salaries['qadir']. \"<br />\";\n         echo \"Salary of zara is \".  $salaries['zara']. \"<br />\";\n         \n         /* Second method to create array. */\n         $salaries['mohammad'] = \"high\";\n         $salaries['qadir'] = \"medium\";\n         $salaries['zara'] = \"low\";\n         \n         echo \"Salary of mohammad is \". $salaries['mohammad'] . \"<br />\";\n         echo \"Salary of qadir is \".  $salaries['qadir']. \"<br />\";\n         echo \"Salary of zara is \".  $salaries['zara']. \"<br />\";\n      ?>\n   \n   </body>\n</html>\n\n\nOutput :\n\nSalary of mohammad is 2000\nSalary of qadir is 1000\nSalary of zara is 500\nSalary of mohammad is high\nSalary of qadir is medium\nSalary of zara is low\n\n\nMultidimensional Arrays\n\nA multi-dimensional array each element in the main array can also be an array. And each element in the sub-array can be an array, and so on. Values in the multi-dimensional array are accessed using multiple index.\n\nExample\n\n<html>\n   <body>\n      \n      <?php\n         $marks = array( \n            \"mohammad\" => array (\n               \"physics\" => 35,\n               \"maths\" => 30,   \n               \"chemistry\" => 39\n            ),\n            \n            \"qadir\" => array (\n               \"physics\" => 30,\n               \"maths\" => 32,\n               \"chemistry\" => 29\n            ),\n            \n            \"zara\" => array (\n               \"physics\" => 31,\n               \"maths\" => 22,\n               \"chemistry\" => 39\n            )\n         );\n         \n         /* Accessing multi-dimensional array values */\n         echo \"Marks for mohammad in physics : \" ;\n         echo $marks['mohammad']['physics'] . \"<br />\"; \n         \n         echo \"Marks for qadir in maths : \";\n         echo $marks['qadir']['maths'] . \"<br />\"; \n         \n         echo \"Marks for zara in chemistry : \" ;\n         echo $marks['zara']['chemistry'] . \"<br />\"; \n      ?>\n   \n   </body>\n</html>\n\n\nOutput:\n\nMarks for mohammad in physics : 35\nMarks for qadir in maths : 32\nMarks for zara in chemistry : 39\n\n\nPHP Array Functions\n\narray() -> Creates an array\n\narray_change_key_case() -> Changes all keys in an array to lowercase or uppercase\n\narray_chunk() -> Splits an array into chunks of arrays array_column() -> Returns the values from a single column in the input array\n\narray_combine() -> Creates an array by using the elements from one \"keys\" array and one \"values\" array\n\narray_count_values() -> Counts all the values of an array\n\narray_diff() -> Compare arrays, and returns the differences (compare values only)\n\narray_diff_assoc() -> Compare arrays, and returns the differences (compare keys and values)\n\narray_diff_key() -> Compare arrays, and returns the differences (compare keys only)\n\narray_diff_uassoc() -> Compare arrays, and returns the differences (compare keys and values, using a user-defined key comparison function)\n\narray_diff_ukey() -> Compare arrays, and returns the differences (compare keys only, using a user-defined key comparison function)\n\narray_fill() -> Fills an array with values\n\narray_fill_keys() -> Fills an array with values, specifying keys\n\narray_filter() -> Filters the values of an array using a callback function\n\narray_flip() -> Flips/Exchanges all keys with their associated values in an array\n\narray_intersect() -> Compare arrays, and returns the matches (compare values only)\n\narray_intersect_assoc() -> Compare arrays and returns the matches (compare keys and values)\n\narray_intersect_key() -> Compare arrays, and returns the matches (compare keys only)\n\narray_intersect_uassoc() -> Compare arrays, and returns the matches (compare keys and values, using a user-defined key comparison function)\n\narray_intersect_ukey() -> Compare arrays, and returns the matches (compare keys only, using a user-defined key comparison function)\n\narray_key_exists() -> Checks if the specified key exists in the array\n\narray_keys() -> Returns all the keys of an array\n\narray_map() -> Sends each value of an array to a user-made function, which returns new values\n\narray_merge() -> Merges one or more arrays into one array\n\narray_merge_recursive() -> Merges one or more arrays into one array recursively\n\narray_multisort() -> Sorts multiple or multi-dimensional arrays\n\nShare\nImprove this answer\nFollow\nanswered Jul 16 at 9:49\ncommunity wiki\n\n\nRamki","comments":[]}]},{"id":"406230","href":"https://stackoverflow.com/questions/406230/regular-expression-to-match-a-line-that-doesnt-contain-a-word","title":"Regular expression to match a line that doesn't contain a word","description":"\n                \nI know it's possible to match a word and then reverse the matches using other tools (e.g. grep -v). However, is it possible to match lines that do not contain a specific word, e.g. hede, using a regular expression?\nInput:\nhoho\nhihi\nhaha\nhede\n\nCode:\ngrep \"<Regex for 'doesn't contain hede'>\" input\n\nDesired output:\nhoho\nhihi\nhaha\n\n    ","questionComments":["Probably a couple years late, but what's wrong with: ([^h]*(h([^e]|$)|he([^d]|$)|hed([^e]|$)))*? The idea is simple. Keep matching until you see the start of the unwanted string, then only match in the N-1 cases where the string is unfinished (where N is the length of the string). These N-1 cases are \"h followed by non-e\", \"he followed by non-d\", and \"hed followed by non-e\". If you managed to pass these N-1 cases, you successfully didn't match the unwanted string so you can start looking for [^h]* again","@stevendesu: try this for 'a-very-very-long-word' or even better half a sentence. Have fun typing. BTW, it is nearly unreadable. Don't know about the performance impact.","@PeterSchuetze: Sure it's not pretty for very very long words, but it is a viable and correct solution. Although I haven't run tests on the performance, I wouldn't imagine it being too slow since most of the latter rules are ignored until you see an h (or the first letter of the word, sentence, etc.). And you could easily generate the regex string for long strings using iterative concatenation. If it works and can be generated quickly, is legibility important? That's what comments are for.","@stevendesu: i'm even later, but that answer is almost completely wrong. for one thing, it requires the subject to contain \"h\" which it shouldn't have to, given the task is \"match lines which [do] not contain a specific word\". let us assume you meant to make the inner group optional, and that the pattern is anchored: ^([^h]*(h([^e]|$)|he([^d]|$)|hed([^e]|$))?)*$ this fails when instances of \"hede\" are preceded by partial instances of \"hede\" such as in \"hhede\".","This question has been added to the Stack Overflow Regular Expression FAQ, under \"Advanced Regex-Fu\"."],"answers":[{"answer":"The notion that regex doesn't support inverse matching is not entirely true. You can mimic this behavior by using negative look-arounds:\n\n^((?!hede).)*$\n\n\nThe regex above will match any string, or line without a line break, not containing the (sub)string 'hede'. As mentioned, this is not something regex is \"good\" at (or should do), but still, it is possible.\n\nAnd if you need to match line break chars as well, use the DOT-ALL modifier (the trailing s in the following pattern):\n\n/^((?!hede).)*$/s\n\n\nor use it inline:\n\n/(?s)^((?!hede).)*$/\n\n\n(where the /.../ are the regex delimiters, i.e., not part of the pattern)\n\nIf the DOT-ALL modifier is not available, you can mimic the same behavior with the character class [\\s\\S]:\n\n/^((?!hede)[\\s\\S])*$/\n\nExplanation\n\nA string is just a list of n characters. Before, and after each character, there's an empty string. So a list of n characters will have n+1 empty strings. Consider the string \"ABhedeCD\":\n\n    ┌──┬───┬──┬───┬──┬───┬──┬───┬──┬───┬──┬───┬──┬───┬──┬───┬──┐\nS = │e1│ A │e2│ B │e3│ h │e4│ e │e5│ d │e6│ e │e7│ C │e8│ D │e9│\n    └──┴───┴──┴───┴──┴───┴──┴───┴──┴───┴──┴───┴──┴───┴──┴───┴──┘\n\nindex    0      1      2      3      4      5      6      7\n\n\nwhere the e's are the empty strings. The regex (?!hede). looks ahead to see if there's no substring \"hede\" to be seen, and if that is the case (so something else is seen), then the . (dot) will match any character except a line break. Look-arounds are also called zero-width-assertions because they don't consume any characters. They only assert/validate something.\n\nSo, in my example, every empty string is first validated to see if there's no \"hede\" up ahead, before a character is consumed by the . (dot). The regex (?!hede). will do that only once, so it is wrapped in a group, and repeated zero or more times: ((?!hede).)*. Finally, the start- and end-of-input are anchored to make sure the entire input is consumed: ^((?!hede).)*$\n\nAs you can see, the input \"ABhedeCD\" will fail because on e3, the regex (?!hede) fails (there is \"hede\" up ahead!).\n\nShare\nImprove this answer\nFollow\nedited May 8 '17 at 20:35\ncommunity wiki\n\n\n10 revs, 6 users 83%\nBart Kiers","comments":["I would not go so far as to say that this is something regex is bad at. The convenience of this solution is pretty obvious and the performance hit compared to a programmatic search is often going to be unimportant.","Strictly speaking negative loook-ahead makes you regular expression not-regular.","@PeterK, sure, but this is SO, not MathOverflow or CS-Stackexchange. People asking a question here are generally looking for a practical answer. Most libraries or tools (like grep, which the OP mentions) with regex-support all have features that mke them non-regular in a theoretical sense.","@Bart Kiers, no offense to you answer, just this abuse of terminology irritates me a bit. The really confusing part here is that regular expressions in the strict sense can very much do what OP wants, but the common language to write them does not allow it, which leads to (mathematically ugly) workarounds like look-aheads. Please see this answer below and my comment there for (theoretically aligned) proper way of doing it. Needless to say it works faster on large inputs.","In case you ever wondered how to do this in vim: ^\\(\\(hede\\)\\@!.\\)*$"]},{"answer":"Note that the solution to does not start with “hede”:\n\n^(?!hede).*$\n\n\nis generally much more efficient than the solution to does not contain “hede”:\n\n^((?!hede).)*$\n\n\nThe former checks for “hede” only at the input string’s first position, rather than at every position.\n\nShare\nImprove this answer\nFollow\nedited Aug 27 '13 at 16:58\ncommunity wiki\n\n\n3 revs, 2 users 69%\nFireCoding","comments":["Thanks, I used it to validate that the string dosn't contain squence of digits ^((?!\\d{5,}).)*","Hello! I can't compose does not end with \"hede\" regex. Can you help with it?","@AleksYa: just use the \"contain\" version, and include the end anchor into the search string: change the string to \"not match\" from \"hede\" to \"hede$\"","@AleksYa: the does not end version could be done using negative lookbehind as: (.*)(?<!hede)$. @Nyerguds' version would work as well but completely misses the point on performance the answer mentions.","Why are so many answers saying ^((?!hede).)*$ ? Is it not more efficient to use ^(?!.*hede).*$ ? It does the same thing but in fewer steps"]},{"answer":"If you're just using it for grep, you can use grep -v hede to get all lines which do not contain hede.\n\nETA Oh, rereading the question, grep -v is probably what you meant by \"tools options\".\n\nShare\nImprove this answer\nFollow\nanswered Jan 2 '09 at 7:41\ncommunity wiki\n\n\nAthena","comments":["Tip: for progressively filtering out what you don't want: grep -v \"hede\" | grep -v \"hihi\" | ...etc.","Or using only one process grep -v -e hede -e hihi -e ...","Or just grep -v \"hede\\|hihi\" :)","If you have many patterns that you want to filter out, put them in a file and use grep -vf pattern_file file","Or simply egrep or grep -Ev \"hede|hihi|etc\" to avoid the awkward escaping."]},{"answer":"Answer:\n\n^((?!hede).)*$\n\n\nExplanation:\n\n^the beginning of the string, ( group and capture to \\1 (0 or more times (matching the most amount possible)),\n(?! look ahead to see if there is not,\n\nhede your string,\n\n) end of look-ahead, . any character except \\n,\n)* end of \\1 (Note: because you are using a quantifier on this capture, only the LAST repetition of the captured pattern will be stored in \\1)\n$ before an optional \\n, and the end of the string\n\nShare\nImprove this answer\nFollow\nedited Dec 6 '17 at 11:23\ncommunity wiki\n\n\n3 revs, 2 users 72%\nJessica","comments":["awesome that worked for me in sublime text 2 using multiple words '^((?!DSAU_PW8882WEB2|DSAU_PW8884WEB2|DSAU_PW8884WEB).)*$'","@DamodarBashyal I know I'm pretty late here, but you could totally remove the second term there and you would get the exact same results"]},{"answer":"The given answers are perfectly fine, just an academic point:\n\nRegular Expressions in the meaning of theoretical computer sciences ARE NOT ABLE do it like this. For them it had to look something like this:\n\n^([^h].*$)|(h([^e].*$|$))|(he([^h].*$|$))|(heh([^e].*$|$))|(hehe.+$) \n\n\nThis only does a FULL match. Doing it for sub-matches would even be more awkward.\n\nShare\nImprove this answer\nFollow\nanswered Sep 2 '11 at 15:53\ncommunity wiki\n\n\nHades32","comments":["Important to note this only uses basic POSIX.2 regular expressions and thus whilst terse is more portable for when PCRE is not available.","I agree. Many if not most regular expressions are not regular languages and could not be recognized by a finite automata.","@ThomasMcLeod, Hades32: Is it within the realms of any possible regular language to be able to say ‘not’ and ‘and’ as well as the ‘or’ of an expression such as ‘(hede|Hihi)’? (This maybe a question for CS.)","@JohnAllen: ME!!! …Well, not the actual regex but the academic reference, which also relates closely to computational complexity; PCREs fundamentally can not guarantee the same efficiency as POSIX regular expressions.","Sorry -this answer just doesn't work, it will match hhehe and even match hehe partially (the second half)"]},{"answer":"If you want the regex test to only fail if the entire string matches, the following will work:\n\n^(?!hede$).*\n\n\ne.g. -- If you want to allow all values except \"foo\" (i.e. \"foofoo\", \"barfoo\", and \"foobar\" will pass, but \"foo\" will fail), use: ^(?!foo$).*\n\nOf course, if you're checking for exact equality, a better general solution in this case is to check for string equality, i.e.\n\nmyStr !== 'foo'\n\n\nYou could even put the negation outside the test if you need any regex features (here, case insensitivity and range matching):\n\n!/^[a-f]oo$/i.test(myStr)\n\n\nThe regex solution at the top of this answer may be helpful, however, in situations where a positive regex test is required (perhaps by an API).\n\nShare\nImprove this answer\nFollow\nedited Nov 7 '18 at 21:51\ncommunity wiki\n\n\n9 revs\nRoy Tinker","comments":["what about trailing whitespaces? Eg, if I want test to fail with string \" hede    \"?","@eagor the \\s directive matches a single whitespace character","thanks, but I didn't manage to update the regex to make this work.","@eagor: ^(?!\\s*hede\\s*$).*"]},{"answer":"FWIW, since regular languages (aka rational languages) are closed under complementation, it's always possible to find a regular expression (aka rational expression) that negates another expression. But not many tools implement this.\n\nVcsn supports this operator (which it denotes {c}, postfix).\n\nYou first define the type of your expressions: labels are letter (lal_char) to pick from a to z for instance (defining the alphabet when working with complementation is, of course, very important), and the \"value\" computed for each word is just a Boolean: true the word is accepted, false, rejected.\n\nIn Python:\n\nIn [5]: import vcsn\n        c = vcsn.context('lal_char(a-z), b')\n        c\nOut[5]: {a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z} → 𝔹\n\n\nthen you enter your expression:\n\nIn [6]: e = c.expression('(hede){c}'); e\nOut[6]: (hede)^c\n\n\nconvert this expression to an automaton:\n\nIn [7]: a = e.automaton(); a\n\n\nfinally, convert this automaton back to a simple expression.\n\nIn [8]: print(a.expression())\n        \\e+h(\\e+e(\\e+d))+([^h]+h([^e]+e([^d]+d([^e]+e[^]))))[^]*\n\n\nwhere + is usually denoted |, \\e denotes the empty word, and [^] is usually written . (any character). So, with a bit of rewriting ()|h(ed?)?|([^h]|h([^e]|e([^d]|d([^e]|e.)))).*.\n\nYou can see this example here, and try Vcsn online there.\n\nShare\nImprove this answer\nFollow\nedited Jan 8 '18 at 23:58\ncommunity wiki\n\n\n5 revs, 2 users 98%\nakim","comments":["True, but ugly, and only doable for small character sets. You don't want to do this with Unicode strings :-)","There are more tools that allow it, one of the most impressive being Ragel. There it would be written as (any* - ('hehe' any*)) for start-aligned match or (any* -- ('hehe' any*)) for unaligned.","@reinierpost: why is it ugly and what's the problem with unicode? I can't agree on both. (I have no experience with vcsn, but have with DFA).","@PedroGimeno When you anchored, you made sure to put this regex in parens first? Otherwise the precedences between anchors and | won't play nicely. '^(()|h(ed?)?|([^h]|h([^e]|e([^d]|d([^e]|e.)))).*)$'.","I think it's worth remarking that this method is for matching lines that are not the word 'hede', rather than lines than don't contain the word 'hede' which is what the OP asked for. See my answer for the latter."]},{"answer":"Here's a good explanation of why it's not easy to negate an arbitrary regex. I have to agree with the other answers, though: if this is anything other than a hypothetical question, then a regex is not the right choice here.\n\nShare\nImprove this answer\nFollow\nanswered Jan 2 '09 at 8:03\ncommunity wiki\n\n\nJosh Lee","comments":["Some tools, and specifically mysqldumpslow, only offer this way to filter data, so in such a case, finding a regex to do this is the best solution apart from rewriting the tool (various patches for this have not been included by MySQL AB / Sun / Oracle.","Exactly analagous to my situation. Velocity template engine uses regular expressions to decide when to apply a transformation (escape html) and I want it to always work EXCEPT in one situation.","What alternative is there? Ive never encountered anything that could do precise string matching besides regex. If OP is using a programming language, there may be other tools available, but if he/she is using not writing code, there probably isnt any other choice.","One of many non-hypothetical scenarios where a regex is the best available choice: I'm in an IDE (Android Studio) that shows log output, and the only filtering tools provided are: plain strings, and regex. Trying to do this with plain strings would be a complete fail."]},{"answer":"With negative lookahead, regular expression can match something not contains specific pattern. This is answered and explained by Bart Kiers. Great explanation!\n\nHowever, with Bart Kiers' answer, the lookahead part will test 1 to 4 characters ahead while matching any single character. We can avoid this and let the lookahead part check out the whole text, ensure there is no 'hede', and then the normal part (.*) can eat the whole text all at one time.\n\nHere is the improved regex:\n\n/^(?!.*?hede).*$/\n\n\nNote the (*?) lazy quantifier in the negative lookahead part is optional, you can use (*) greedy quantifier instead, depending on your data: if 'hede' does present and in the beginning half of the text, the lazy quantifier can be faster; otherwise, the greedy quantifier be faster. However if 'hede' does not present, both would be equal slow.\n\nHere is the demo code.\n\nFor more information about lookahead, please check out the great article: Mastering Lookahead and Lookbehind.\n\nAlso, please check out RegexGen.js, a JavaScript Regular Expression Generator that helps to construct complex regular expressions. With RegexGen.js, you can construct the regex in a more readable way:\n\nvar _ = regexGen;\n\nvar regex = _(\n    _.startOfLine(),             \n    _.anything().notContains(       // match anything that not contains:\n        _.anything().lazy(), 'hede' //   zero or more chars that followed by 'hede',\n                                    //   i.e., anything contains 'hede'\n    ), \n    _.endOfLine()\n);\n\nShare\nImprove this answer\nFollow\nanswered Jul 14 '14 at 18:21\ncommunity wiki\n\n\namobiz","comments":["so to simply check if given string does not contain str1 and str2: ^(?!.*(str1|str2)).*$","Yes, or you can use lazy quantifier: ^(?!.*?(?:str1|str2)).*$, depending on your data. Added the ?: since we don't need to capture it.","This is by far the best answer by a factor of 10xms. If you added your jsfiddle code and results onto the answer people might notice it. I wonder why the lazy version is faster than the greedy version when there is no hede. Shouldn't they take the same amount of time?","Yes, they take the same amount of time since they both tests the whole text."]},{"answer":"Benchmarks\n\nI decided to evaluate some of the presented Options and compare their performance, as well as use some new Features. Benchmarking on .NET Regex Engine: http://regexhero.net/tester/\n\nBenchmark Text:\n\nThe first 7 lines should not match, since they contain the searched Expression, while the lower 7 lines should match!\n\nRegex Hero is a real-time online Silverlight Regular Expression Tester.\nXRegex Hero is a real-time online Silverlight Regular Expression Tester.\nRegex HeroRegex HeroRegex HeroRegex HeroRegex Hero is a real-time online Silverlight Regular Expression Tester.\nRegex Her Regex Her Regex Her Regex Her Regex Her Regex Her Regex Hero is a real-time online Silverlight Regular Expression Tester.\nRegex Her is a real-time online Silverlight Regular Expression Tester.Regex Hero\negex Hero egex Hero egex Hero egex Hero egex Hero egex Hero Regex Hero is a real-time online Silverlight Regular Expression Tester.\nRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRegex Hero is a real-time online Silverlight Regular Expression Tester.\n\nRegex Her\negex Hero\negex Hero is a real-time online Silverlight Regular Expression Tester.\nRegex Her is a real-time online Silverlight Regular Expression Tester.\nRegex Her Regex Her Regex Her Regex Her Regex Her Regex Her is a real-time online Silverlight Regular Expression Tester.\nNobody is a real-time online Silverlight Regular Expression Tester.\nRegex Her o egex Hero Regex  Hero Reg ex Hero is a real-time online Silverlight Regular Expression Tester.\n\nResults:\n\nResults are Iterations per second as the median of 3 runs - Bigger Number = Better\n\n01: ^((?!Regex Hero).)*$                    3.914   // Accepted Answer\n02: ^(?:(?!Regex Hero).)*$                  5.034   // With Non-Capturing group\n03: ^(?>[^R]+|R(?!egex Hero))*$             6.137   // Lookahead only on the right first letter\n04: ^(?>(?:.*?Regex Hero)?)^.*$             7.426   // Match the word and check if you're still at linestart\n05: ^(?(?=.*?Regex Hero)(?#fail)|.*)$       7.371   // Logic Branch: Find Regex Hero? match nothing, else anything\n\nP1: ^(?(?=.*?Regex Hero)(*FAIL)|(*ACCEPT))  ?????   // Logic Branch in Perl - Quick FAIL\nP2: .*?Regex Hero(*COMMIT)(*FAIL)|(*ACCEPT) ?????   // Direct COMMIT & FAIL in Perl\n\n\nSince .NET doesn't support action Verbs (*FAIL, etc.) I couldn't test the solutions P1 and P2.\n\nSummary:\n\nI tried to test most proposed solutions, some Optimizations are possible for certain words. For Example if the First two letters of the search string are not the Same, answer 03 can be expanded to ^(?>[^R]+|R+(?!egex Hero))*$ resulting in a small performance gain.\n\nBut the overall most readable and performance-wise fastest solution seems to be 05 using a conditional statement or 04 with the possesive quantifier. I think the Perl solutions should be even faster and more easily readable.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\nFalco","comments":["You should time ^(?!.*hede) too. /// Also, it's probably better to rank the expressions for the matching corpus and the non-matching corpus separately because it's usually a case that most line match or most lines don't."]},{"answer":"Not regex, but I've found it logical and useful to use serial greps with pipe to eliminate noise.\n\neg. search an apache config file without all the comments-\n\ngrep -v '\\#' /opt/lampp/etc/httpd.conf      # this gives all the non-comment lines\n\n\nand\n\ngrep -v '\\#' /opt/lampp/etc/httpd.conf |  grep -i dir\n\n\nThe logic of serial grep's is (not a comment) and (matches dir)\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '11 at 20:19\ncommunity wiki\n\n\n2 revs, 2 users 77%\nkiwalk","comments":["I think he is asking for the regex version of the grep -v","This is dangerous. Also misses lines like good_stuff #comment_stuff"]},{"answer":"with this, you avoid to test a lookahead on each positions:\n\n/^(?:[^h]+|h++(?!ede))*+$/\n\n\nequivalent to (for .net):\n\n^(?>(?:[^h]+|h+(?!ede))*)$\n\n\nOld answer:\n\n/^(?>[^h]+|h+(?!ede))*$/\n\nShare\nImprove this answer\nFollow\nedited Jun 4 '18 at 10:00\ncommunity wiki\n\n\n11 revs, 2 users 96%\nCasimir et Hippolyte","comments":["Good point; I'm surprised nobody mentioned this approach before. However, that particular regex is prone to catastrophic backtracking when applied to text that doesn't match. Here's how I would do it: /^[^h]*(?:h+(?!ede)[^h]*)*$/","...or you can just make all the quantifiers possessive. ;)","@Alan Moore - I'm surprised too. I saw your comment (and best regex in the pile) here only after posting this same pattern in an answer below.","@ridgerunner, doesn't have to be the best tho. I've seen benchmarks where the top answer performs better. (I was surprised about that tho.)"]},{"answer":"Aforementioned (?:(?!hede).)* is great because it can be anchored.\n\n^(?:(?!hede).)*$               # A line without hede\n\nfoo(?:(?!hede).)*bar           # foo followed by bar, without hede between them\n\n\nBut the following would suffice in this case:\n\n^(?!.*hede)                    # A line without hede\n\n\nThis simplification is ready to have \"AND\" clauses added:\n\n^(?!.*hede)(?=.*foo)(?=.*bar)   # A line with foo and bar, but without hede\n^(?!.*hede)(?=.*foo).*bar       # Same\n\nShare\nImprove this answer\nFollow\nedited Aug 23 '16 at 0:10\ncommunity wiki\n\n\n2 revs\nikegami","comments":[]},{"answer":"Here's how I'd do it:\n\n^[^h]*(h(?!ede)[^h]*)*$\n\n\nAccurate and more efficient than the other answers. It implements Friedl's \"unrolling-the-loop\" efficiency technique and requires much less backtracking.\n\nShare\nImprove this answer\nFollow\nanswered Dec 20 '13 at 3:03\ncommunity wiki\n\n\nridgerunner","comments":[]},{"answer":"An, in my opinon, more readable variant of the top answer:\n\n^(?!.*hede)\n\n\nBasically, \"match at the beginning of the line if and only if it does not have 'hede' in it\" - so the requirement translated almost directly into regex.\n\nOf course, it's possible to have multiple failure requirements:\n\n^(?!.*(hede|hodo|hada))\n\n\nDetails: The ^ anchor ensures the regex engine doesn't retry the match at every location in the string, which would match every string.\n\nThe ^ anchor in the beginning is meant to represent the beginning of the line. The grep tool matches each line one at a time, in contexts where you're working with a multiline string, you can use the \"m\" flag:\n\n/^(?!.*hede)/m # JavaScript syntax\n\n\nor\n\n(?m)^(?!.*hede) # Inline flag\n\nShare\nImprove this answer\nFollow\nedited Dec 8 '18 at 20:18\ncommunity wiki\n\n\n5 revs, 2 users 54%\nDannie P","comments":["Excellent example with multiple negation.","One difference from top answer is that this does not match anything, and that matches the whole line if without \"hede\""]},{"answer":"If you want to match a character to negate a word similar to negate character class:\n\nFor example, a string:\n\n<?\n$str=\"aaa        bbb4      aaa     bbb7\";\n?>\n\n\nDo not use:\n\n<?\npreg_match('/aaa[^bbb]+?bbb7/s', $str, $matches);\n?>\n\n\nUse:\n\n<?\npreg_match('/aaa(?:(?!bbb).)+?bbb7/s', $str, $matches);\n?>\n\n\nNotice \"(?!bbb).\" is neither lookbehind nor lookahead, it's lookcurrent, for example:\n\n\"(?=abc)abcde\", \"(?!abc)abcde\"\n\nShare\nImprove this answer\nFollow\nedited Apr 3 '14 at 16:17\ncommunity wiki\n\n\n5 revs, 3 users 86%\ndiyism","comments":["There is no \"lookcurrent\" in perl regexp's. This is truly a negative lookahead (prefix (?!). Positive lookahead's prefix would be (?= while the corresponding lookbehind prefixes would be (?<! and (?<= respectively. A lookahead means that you read the next characters (hence “ahead”) without consuming them. A lookbehind means that you check characters that have already been consumed.","Not sure how (?!abc)abcde makes any sense at all."]},{"answer":"Since no one else has given a direct answer to the question that was asked, I'll do it.\n\nThe answer is that with POSIX grep, it's impossible to literally satisfy this request:\n\ngrep \"<Regex for 'doesn't contain hede'>\" input\n\n\nThe reason is that POSIX grep is only required to work with Basic Regular Expressions, which are simply not powerful enough for accomplishing that task (they are not capable of parsing all regular languages, because of lack of alternation).\n\nHowever, GNU grep implements extensions that allow it. In particular, \\| is the alternation operator in GNU's implementation of BREs. If your regular expression engine supports alternation, parentheses and the Kleene star, and is able to anchor to the beginning and end of the string, that's all you need for this approach. Note however that negative sets [^ ... ] are very convenient in addition to those, because otherwise, you need to replace them with an expression of the form (a|b|c| ... ) that lists every character that is not in the set, which is extremely tedious and overly long, even more so if the whole character set is Unicode.\n\nThanks to formal language theory, we get to see how such an expression looks like. With GNU grep, the answer would be something like:\n\ngrep \"^\\([^h]\\|h\\(h\\|eh\\|edh\\)*\\([^eh]\\|e[^dh]\\|ed[^eh]\\)\\)*\\(\\|h\\(h\\|eh\\|edh\\)*\\(\\|e\\|ed\\)\\)$\" input\n\n\n(found with Grail and some further optimizations made by hand).\n\nYou can also use a tool that implements Extended Regular Expressions, like egrep, to get rid of the backslashes:\n\negrep \"^([^h]|h(h|eh|edh)*([^eh]|e[^dh]|ed[^eh]))*(|h(h|eh|edh)*(|e|ed))$\" input\n\n\nHere's a script to test it (note it generates a file testinput.txt in the current directory). Several of the expressions presented fail this test.\n\n#!/bin/bash\nREGEX=\"^\\([^h]\\|h\\(h\\|eh\\|edh\\)*\\([^eh]\\|e[^dh]\\|ed[^eh]\\)\\)*\\(\\|h\\(h\\|eh\\|edh\\)*\\(\\|e\\|ed\\)\\)$\"\n\n# First four lines as in OP's testcase.\ncat > testinput.txt <<EOF\nhoho\nhihi\nhaha\nhede\n\nh\nhe\nah\nhead\nahead\nahed\naheda\nahede\nhhede\nhehede\nhedhede\nhehehehehehedehehe\nhedecidedthat\nEOF\ndiff -s -u <(grep -v hede testinput.txt) <(grep \"$REGEX\" testinput.txt)\n\n\nIn my system it prints:\n\nFiles /dev/fd/63 and /dev/fd/62 are identical\n\n\nas expected.\n\nFor those interested in the details, the technique employed is to convert the regular expression that matches the word into a finite automaton, then invert the automaton by changing every acceptance state to non-acceptance and vice versa, and then converting the resulting FA back to a regular expression.\n\nAs everyone has noted, if your regular expression engine supports negative lookahead, the regular expression is much simpler. For example, with GNU grep:\n\ngrep -P '^((?!hede).)*$' input\n\n\nHowever, this approach has the disadvantage that it requires a backtracking regular expression engine. This makes it unsuitable in installations that are using secure regular expression engines like RE2, which is one reason to prefer the generated approach in some circumstances.\n\nUsing Kendall Hopkins' excellent FormalTheory library, written in PHP, which provides a functionality similar to Grail, and a simplifier written by myself, I've been able to write an online generator of negative regular expressions given an input phrase (only alphanumeric and space characters currently supported): http://www.formauri.es/personal/pgimeno/misc/non-match-regex/\n\nFor hede it outputs:\n\n^([^h]|h(h|e(h|dh))*([^eh]|e([^dh]|d[^eh])))*(h(h|e(h|dh))*(ed?)?)?$\n\n\nwhich is equivalent to the above.\n\nShare\nImprove this answer\nFollow\nedited Oct 1 '20 at 15:59\ncommunity wiki\n\n\n8 revs\nPedro Gimeno","comments":[]},{"answer":"The OP did not specify or Tag the post to indicate the context (programming language, editor, tool) the Regex will be used within.\n\nFor me, I sometimes need to do this while editing a file using Textpad.\n\nTextpad supports some Regex, but does not support lookahead or lookbehind, so it takes a few steps.\n\nIf I am looking to retain all lines that Do NOT contain the string hede, I would do it like this:\n\n1. Search/replace the entire file to add a unique \"Tag\" to the beginning of each line containing any text.\n\n    Search string:^(.)  \n    Replace string:<@#-unique-#@>\\1  \n    Replace-all  \n\n\n2. Delete all lines that contain the string hede (replacement string is empty):\n\n    Search string:<@#-unique-#@>.*hede.*\\n  \n    Replace string:<nothing>  \n    Replace-all  \n\n\n3. At this point, all remaining lines Do NOT contain the string hede. Remove the unique \"Tag\" from all lines (replacement string is empty):\n\n    Search string:<@#-unique-#@>\n    Replace string:<nothing>  \n    Replace-all  \n\n\nNow you have the original text with all lines containing the string hede removed.\n\n\nIf I am looking to Do Something Else to only lines that Do NOT contain the string hede, I would do it like this:\n\n1. Search/replace the entire file to add a unique \"Tag\" to the beginning of each line containing any text.\n\n    Search string:^(.)  \n    Replace string:<@#-unique-#@>\\1  \n    Replace-all  \n\n\n2. For all lines that contain the string hede, remove the unique \"Tag\":\n\n    Search string:<@#-unique-#@>(.*hede)\n    Replace string:\\1  \n    Replace-all  \n\n\n3. At this point, all lines that begin with the unique \"Tag\", Do NOT contain the string hede. I can now do my Something Else to only those lines.\n\n4. When I am done, I remove the unique \"Tag\" from all lines (replacement string is empty):\n\n    Search string:<@#-unique-#@>\n    Replace string:<nothing>  \n    Replace-all  \n\nShare\nImprove this answer\nFollow\nedited Apr 26 '13 at 22:46\ncommunity wiki\n\n\n2 revs\nKevin Fegan","comments":[]},{"answer":"Another option is that to add a positive look-ahead and check if hede is anywhere in the input line, then we would negate that, with an expression similar to:\n\n^(?!(?=.*\\bhede\\b)).*$\n\n\nwith word boundaries.\n\nThe expression is explained on the top right panel of regex101.com, if you wish to explore/simplify/modify it, and in this link, you can watch how it would match against some sample inputs, if you like.\n\nRegEx Circuit\n\njex.im visualizes regular expressions:\n\nShare\nImprove this answer\nFollow\nedited Jul 15 '20 at 10:42\ncommunity wiki\n\n\n2 revs, 2 users 97%\nEmma","comments":["I don't understand how the \"inner\" positive lookahead is useful."]},{"answer":"Since the introduction of ruby-2.4.1, we can use the new Absent Operator in Ruby’s Regular Expressions\n\nfrom the official doc\n\n(?~abc) matches: \"\", \"ab\", \"aab\", \"cccc\", etc.\nIt doesn't match: \"abc\", \"aabc\", \"ccccabc\", etc.\n\n\nThus, in your case ^(?~hede)$ does the job for you\n\n2.4.1 :016 > [\"hoho\", \"hihi\", \"haha\", \"hede\"].select{|s| /^(?~hede)$/.match(s)}\n => [\"hoho\", \"hihi\", \"haha\"]\n\nShare\nImprove this answer\nFollow\nanswered Mar 23 '17 at 13:42\ncommunity wiki\n\n\naelor","comments":[]},{"answer":"Through PCRE verb (*SKIP)(*F)\n\n^hede$(*SKIP)(*F)|^.*$\n\n\nThis would completely skips the line which contains the exact string hede and matches all the remaining lines.\n\nDEMO\n\nExecution of the parts:\n\nLet us consider the above regex by splitting it into two parts.\n\nPart before the | symbol. Part shouldn't be matched.\n\n^hede$(*SKIP)(*F)\n\n\nPart after the | symbol. Part should be matched.\n\n^.*$\n\n\nPART 1\n\nRegex engine will start its execution from the first part.\n\n^hede$(*SKIP)(*F)\n\n\nExplanation:\n\n^ Asserts that we are at the start.\nhede Matches the string hede\n$ Asserts that we are at the line end.\n\nSo the line which contains the string hede would be matched. Once the regex engine sees the following (*SKIP)(*F) (Note: You could write (*F) as (*FAIL)) verb, it skips and make the match to fail. | called alteration or logical OR operator added next to the PCRE verb which inturn matches all the boundaries exists between each and every character on all the lines except the line contains the exact string hede. See the demo here. That is, it tries to match the characters from the remaining string. Now the regex in the second part would be executed.\n\nPART 2\n\n^.*$\n\n\nExplanation:\n\n^ Asserts that we are at the start. ie, it matches all the line starts except the one in the hede line. See the demo here.\n\n.* In the Multiline mode, . would match any character except newline or carriage return characters. And * would repeat the previous character zero or more times. So .* would match the whole line. See the demo here.\n\nHey why you added .* instead of .+ ?\n\nBecause .* would match a blank line but .+ won't match a blank. We want to match all the lines except hede , there may be a possibility of blank lines also in the input . so you must use .* instead of .+ . .+ would repeat the previous character one or more times. See .* matches a blank line here.\n\n$ End of the line anchor is not necessary here.\n\nShare\nImprove this answer\nFollow\nedited Oct 9 '14 at 7:51\ncommunity wiki\n\n\n2 revs\nAvinash Raj","comments":[]},{"answer":"It may be more maintainable to two regexes in your code, one to do the first match, and then if it matches run the second regex to check for outlier cases you wish to block for example ^.*(hede).* then have appropriate logic in your code.\n\nOK, I admit this is not really an answer to the posted question posted and it may also use slightly more processing than a single regex. But for developers who came here looking for a fast emergency fix for an outlier case then this solution should not be overlooked.\n\nShare\nImprove this answer\nFollow\nedited Sep 13 '16 at 13:55\ncommunity wiki\n\n\n2 revs, 2 users 80%\nandrew pate","comments":[]},{"answer":"The TXR Language supports regex negation.\n\n$ txr -c '@(repeat)\n@{nothede /~hede/}\n@(do (put-line nothede))\n@(end)'  Input\n\n\nA more complicated example: match all lines that start with a and end with z, but do not contain the substring hede:\n\n$ txr -c '@(repeat)\n@{nothede /a.*z&~.*hede.*/}\n@(do (put-line nothede))\n@(end)' -\naz         <- echoed\naz\nabcz       <- echoed\nabcz\nabhederz   <- not echoed; contains hede\nahedez     <- not echoed; contains hede\nace        <- not echoed; does not end in z\nahedz      <- echoed\nahedz\n\n\nRegex negation is not particularly useful on its own but when you also have intersection, things get interesting, since you have a full set of boolean set operations: you can express \"the set which matches this, except for things which match that\".\n\nShare\nImprove this answer\nFollow\nanswered Jun 25 '14 at 1:23\ncommunity wiki\n\n\nKaz","comments":["Note that it is also the solution for ElasticSearch Lucene based regex."]},{"answer":"The below function will help you get your desired output\n\n<?PHP\n      function removePrepositions($text){\n\n            $propositions=array('/\\bfor\\b/i','/\\bthe\\b/i'); \n\n            if( count($propositions) > 0 ) {\n                foreach($propositions as $exceptionPhrase) {\n                    $text = preg_replace($exceptionPhrase, '', trim($text));\n\n                }\n            $retval = trim($text);\n\n            }\n        return $retval;\n    }\n\n\n?>\n\nShare\nImprove this answer\nFollow\nedited Mar 11 '17 at 1:42\ncommunity wiki\n\n\n2 revs, 2 users 91%\nDaniel Nyamasyo","comments":[]},{"answer":"I wanted to add another example for if you are trying to match an entire line that contains string X, but does not also contain string Y.\n\nFor example, let's say we want to check if our URL / string contains \"tasty-treats\", so long as it does not also contain \"chocolate\" anywhere.\n\nThis regex pattern would work (works in JavaScript too)\n\n^(?=.*?tasty-treats)((?!chocolate).)*$\n\n\n(global, multiline flags in example)\n\nInteractive Example: https://regexr.com/53gv4\n\nMatches\n\n(These urls contain \"tasty-treats\" and also do not contain \"chocolate\")\n\nexample.com/tasty-treats/strawberry-ice-cream\nexample.com/desserts/tasty-treats/banana-pudding\nexample.com/tasty-treats-overview\nDoes Not Match\n\n(These urls contain \"chocolate\" somewhere - so they won't match even though they contain \"tasty-treats\")\n\nexample.com/tasty-treats/chocolate-cake\nexample.com/home-cooking/oven-roasted-chicken\nexample.com/tasty-treats/banana-chocolate-fudge\nexample.com/desserts/chocolate/tasty-treats\nexample.com/chocolate/tasty-treats/desserts\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\nMatthew Rideout","comments":["This was very helpful, thank you."]},{"answer":"^((?!hede).)*$ is an elegant solution, except since it consumes characters you won't be able to combine it with other criteria. For instance, say you wanted to check for the non-presence of \"hede\" and the presence of \"haha.\" This solution would work because it won't consume characters:\n\n^(?!.*\\bhede\\b)(?=.*\\bhaha\\b) \n\nShare\nImprove this answer\nFollow\nedited Jun 10 '20 at 22:17\ncommunity wiki\n\n\n2 revs, 2 users 67%\ncloudhopperpilot","comments":[]},{"answer":"As long as you are dealing with lines, simply mark the negative matches and target the rest.\n\nIn fact, I use this trick with sed because ^((?!hede).)*$ looks not supported by it.\n\nFor the desired output\n\nMark the negative match: (e.g. lines with hede), using a character not included in the whole text at all. An emoji could probably be a good choice for this purpose.\n\ns/(.*hede)/🔒\\1/g\n\n\nTarget the rest (the unmarked strings: e.g. lines without hede). Suppose you want to keep only the target and delete the rest (as you want):\n\ns/^🔒.*//g\n\nFor a better understanding\n\nSuppose you want to delete the target:\n\nMark the negative match: (e.g. lines with hede), using a character not included in the whole text at all. An emoji could probably be a good choice for this purpose.\n\ns/(.*hede)/🔒\\1/g\n\n\nTarget the rest (the unmarked strings: e.g. lines without hede). Suppose you want to delete the target:\n\ns/^[^🔒].*//g\n\n\nRemove the mark:\n\ns/🔒//g\n\nShare\nImprove this answer\nFollow\nanswered Jun 15 '20 at 11:02\ncommunity wiki\n\n\nAnas R.","comments":[]},{"answer":"How to use PCRE's backtracking control verbs to match a line not containing a word\n\nHere's a method that I haven't seen used before:\n\n/.*hede(*COMMIT)^|/\n\nHow it works\n\nFirst, it tries to find \"hede\" somewhere in the line. If successful, at this point, (*COMMIT) tells the engine to, not only not backtrack in the event of a failure, but also not to attempt any further matching in that case. Then, we try to match something that cannot possibly match (in this case, ^).\n\nIf a line does not contain \"hede\" then the second alternative, an empty subpattern, successfully matches the subject string.\n\nThis method is no more efficient than a negative lookahead, but I figured I'd just throw it on here in case someone finds it nifty and finds a use for it for other, more interesting applications.\n\nShare\nImprove this answer\nFollow\nanswered Oct 11 '17 at 10:12\ncommunity wiki\n\n\njaytea","comments":[]},{"answer":"A simpler solution is to use the not operator !\n\nYour if statement will need to match \"contains\" and not match \"excludes\".\n\nvar contains = /abc/;\nvar excludes =/hede/;\n\nif(string.match(contains) && !(string.match(excludes))){  //proceed...\n\n\nI believe the designers of RegEx anticipated the use of not operators.\n\nShare\nImprove this answer\nFollow\nedited Sep 13 '16 at 14:06\ncommunity wiki\n\n\n2 revs\nuser1691651-John","comments":[]},{"answer":"Maybe you'll find this on Google while trying to write a regex that is able to match segments of a line (as opposed to entire lines) which do not contain a substring. Tooke me a while to figure out, so I'll share:\n\nGiven a string: \n<span class=\"good\">bar</span><span class=\"bad\">foo</span><span class=\"ugly\">baz</span>\n\n\nI want to match <span> tags which do not contain the substring \"bad\".\n\n/<span(?:(?!bad).)*?> will match <span class=\\\"good\\\"> and <span class=\\\"ugly\\\">.\n\nNotice that there are two sets (layers) of parentheses:\n\nThe innermost one is for the negative lookahead (it is not a capture group)\nThe outermost was interpreted by Ruby as capture group but we don't want it to be a capture group, so I added ?: at it's beginning and it is no longer interpreted as a capture group.\n\nDemo in Ruby:\n\ns = '<span class=\"good\">bar</span><span class=\"bad\">foo</span><span class=\"ugly\">baz</span>'\ns.scan(/<span(?:(?!bad).)*?>/)\n# => [\"<span class=\\\"good\\\">\", \"<span class=\\\"ugly\\\">\"]\n\nShare\nImprove this answer\nFollow\nanswered Apr 25 '18 at 18:15\ncommunity wiki\n\n\nBrunoF","comments":[]}]},{"id":"115983","href":"https://stackoverflow.com/questions/115983/how-can-i-add-a-blank-directory-to-a-git-repository","title":"How can I add a blank directory to a Git repository?","description":"\n                \nHow can I add a blank directory (that contains no files) to a Git repository?\n    ","questionComments":["While it's not useful, there is a way to hack an empty (really empty) directory into your repo. It won't checkout with current versions of Git, however.","@tiwo I for one disagree that it's not useful. Your directory hierarchy is part of your project, so it should be version controlled.","In my case, I'd like to add a directory structure for tmp files, but not the tmp files themselves. By doing this, my tester has the correct structure (otherwise there are errors) but I don't clog my commits with tmp data. So yes, it's useful to me!","@AdamMarshall I think tiwo was saying that the hack is not useful, since it is ignored by checkout. Tmp dirs do sound like a useful feature for a VCS.","Why not have the procedure that creates the tmp files also create the tmp directory?"],"answers":[{"answer":"Another way to make a directory stay (almost) empty (in the repository) is to create a .gitignore file inside that directory that contains these four lines:\n\n# Ignore everything in this directory\n*\n# Except this file\n!.gitignore\n\n\nThen you don't have to get the order right the way that you have to do in m104's solution.\n\nThis also gives the benefit that files in that directory won't show up as \"untracked\" when you do a git status.\n\nMaking @GreenAsJade's comment persistent:\n\nI think it's worth noting that this solution does precisely what the question asked for, but is not perhaps what many people looking at this question will have been looking for. This solution guarantees that the directory remains empty. It says \"I truly never want files checked in here\". As opposed to \"I don't have any files to check in here, yet, but I need the directory here, files may be coming later\".\n\nShare\nImprove this answer\nFollow\nedited Nov 20 '18 at 11:59\nHelloGoodbye\n2,8346\n6 gold badges\n33\n33 silver badges\n43\n43 bronze badges\nanswered May 31 '09 at 22:10\nJamie Flournoy\n48k1\n1 gold badge\n22\n22 silver badges\n11\n11 bronze badges","comments":["I think the README solution proposed by @JohnMee should be used together with this one; the .gitignore file provides an explanation of what we want to keep out of version control, while the README file explains what is the purpose of the directory, which are both very important pieces of information.","@pedromanoel I write the documentation you would put in the README inside the .gitignore file (as comments).","spot the 1 difference: 1.) an empty folder, 2.) a folder with .gitignore file in it. ;-)","This is perfect for cache folders.","Unfortunately, this results in a non-empty directory, it has a single hidden file."]},{"answer":"You can't. See the Git FAQ.\n\nCurrently the design of the git index (staging area) only permits files to be listed, and nobody competent enough to make the change to allow empty directories has cared enough about this situation to remedy it.\n\nDirectories are added automatically when adding files inside them. That is, directories never have to be added to the repository, and are not tracked on their own.\n\nYou can say \"git add <dir>\" and it will add files in there.\n\nIf you really need a directory to exist in checkouts you should create a file in it. .gitignore works well for this purpose; you can leave it empty, or fill in the names of files you expect to show up in the directory.\n\nShare\nImprove this answer\nFollow\nedited May 4 '12 at 13:12\nGilles 'SO- stop being evil'\n93.8k35\n35 gold badges\n191\n191 silver badges\n232\n232 bronze badges\nanswered Sep 22 '08 at 16:42\nAndy Lester\n82.6k12\n12 gold badges\n94\n94 silver badges\n144\n144 bronze badges","comments":["Below answer is MUCH better. The fact that git the low level software doesn't allow it doesn't matter to me as much as HOW to actually use Git when I need an empty directory. Adding a 2 line .gitignore seems acceptable to me.","Well if one want to move files into a new directory, they can't do it through git mv as git will complain that new directory is not under version control","You can read \"it's impossible, you can't, etc.\" all over the Internet for this frequent question. The .gitignore trick is a frequent answer, and satisfies many needs. However it IS possible to make git track an truly empty directory, see my answer","Though the more I think of it, the more it feels like \"SHA hash of the empty string\", if it exists, actually would be a well-defined identifier for an empty tree, unless it would be impossible to tell whether that object is a tree or a blob.","I've seen a lot of repos that use an empty file called .gitkeep for this purpose."]},{"answer":"Create an empty file called .gitkeep in the directory, and add that.\n\nShare\nImprove this answer\nFollow\nedited Oct 9 '13 at 22:21\nMark Amery\n115k61\n61 gold badges\n361\n361 silver badges\n414\n414 bronze badges\nanswered Dec 7 '11 at 16:03\nArtur79\n10.8k1\n1 gold badge\n20\n20 silver badges\n22\n22 bronze badges","comments":["I have added an answer encouraging to create .keep instead.",".gitkeep has not been prescribed by Git and is going to make people second guess its meaning, which will lead them to google searches, which will lead them here. The .git prefix convention should be reserved for files and directories that Git itself uses.","@t-mart \"The .git prefix convention should be reserved...\" Why? Does git request this reservation?","In this case a README or ABOUT file would be just as good or better. Leaving a note for the next guy, just like we all used to do it before URLs.","Doesn't work if you're writing a unit test that should test code on an empty directory..."]},{"answer":"You could always put a README file in the directory with an explanation of why you want this, otherwise empty, directory in the repository.\n\nShare\nImprove this answer\nFollow\nedited Apr 26 '12 at 2:51\nWill\n21.8k11\n11 gold badges\n86\n86 silver badges\n99\n99 bronze badges\nanswered Mar 14 '11 at 23:38\nJohn Mee\n44.8k31\n31 gold badges\n133\n133 silver badges\n172\n172 bronze badges","comments":["+1, Good suggestion, an empty directory does not make any sense unless it is going to be used in the future. So create a README file inside it and write what this directory is for, and what files will be put there in the future. That solves both two problems.","@ilius Nonsense. A directory structure containing empty directories may be highly desirable in many situations (like an MVC app where you want a models directory but haven't gotten around to creating any models yet, or a shared views directory you plan to add shared views to, later). Moreover, putting a README in each one of these is overkill as it's obvious what they're there for, and it's easy to forget to put a README in each one of them. AND you have to remember to remove the README when you add some other files to them. Basically, git should definitely allow empty directories.","@Jez: I disagree. The point is that git is designed to control (and index) source-code. Importantly, the id of a commit is a hash of the contents. That is to say, it must have contents. You don't need a README in every part of the tree, only leaf nodes. If you have places you intend to put code, but no code, and you won't even take the time to echo \"place for models\" >> README, then what you have is an idea not a commit. It is not of interest to git. Saying \"I want the running app to have XYZ empty directories\" is a runtime problem, not a source problem. Handle it w/ your installer.","@JoeAtzberger It's a missing feature, not an intentional limitation. From the Git FAQ: Currently the design of the Git index (staging area) only permits files to be listed, and nobody competent enough to make the change to allow empty directories has cared enough about this situation to remedy it.","@jbo5112 Yes, the \"special code\" you refer to is the \"installer\" I mentioned. Your webapp installation already has to handle creating a database, local config, pulling dependencies or 100 other operations, but a couple empty directories are beyond it? Try gradle, passenger, chef, a primitive Makefile, etc. There is no security difference between creating directories and the other (potentially far more complicated/dangerous) work of installing an app. And if you really have no deps, config, DB, etc., and no installer, then just use the README. No case requires you to do both."]},{"answer":"touch .keep\n\n\nOn Linux, this creates an empty file named .keep. For what it's worth, this name is agnostic to Git. Secondly, as another user has noted, the .git prefix convention can be reserved for files and directories that Git itself uses for configuration purposes.\n\nAlternatively, as noted in another answer, the directory can contain a descriptive README.md file instead.\n\nEither way this requires that the presence of the file won't cause your application to break.\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '20 at 13:29\nanswered Jan 29 '14 at 4:29\nAsclepius\n43.4k14\n14 gold badges\n122\n122 silver badges\n111\n111 bronze badges","comments":["This is good for an initial bare directory, but what if it starts to fill with files? Then Git will notice them and claim them as untracked files. The selected answer here works far more elegantly to allow one to keep a directory but then safely ignore the contents.","The question and the predominant general concern is about adding an empty directory. If it later has a resident file, obviously delete the .keep file or just disregard it. If instead the files in the directory are to be ignored, that's a different question altogether.","It was suggested that git clean -nd | sed s/'^Would remove '// | xargs -I{} touch \"{}.keep\" will do this in all untracked empty directories.","Don't like this solution, it is tough to guess what this file does. Also, if you are generating files in your dev environment (like logs or images, etc.), this isn`t keeping those file from being versioned and making their way into production, which is not nice.","Elegant: the .keep file together with the commit message shows the intent of \"keeping\" the project structure. Adding Readme or Abouts I think will cause more confusion..."]},{"answer":"Why would we need empty versioned folders\n\nFirst things first:\n\nAn empty directory cannot be part of a tree under the Git versioning system.\n\nIt simply won't be tracked. But there are scenarios in which \"versioning\" empty directories can be meaningful, for example:\n\nscaffolding a predefined folder structure, making it available to every user/contributor of the repository; or, as a specialized case of the above, creating a folder for temporary files, such as a cache/ or logs/ directories, where we want to provide the folder but .gitignore its contents\nrelated to the above, some projects won't work without some folders (which is often a hint of a poorly designed project, but it's a frequent real-world scenario and maybe there could be, say, permission problems to be addressed).\nSome suggested workarounds\n\nMany users suggest:\n\nPlacing a README file or another file with some content in order to make the directory non-empty, or\nCreating a .gitignore file with a sort of \"reverse logic\" (i.e. to include all the files) which, at the end, serves the same purpose of approach #1.\n\nWhile both solutions surely work I find them inconsistent with a meaningful approach to Git versioning.\n\nWhy are you supposed to put bogus files or READMEs that maybe you don't really want in your project?\nWhy use .gitignore to do a thing (keeping files) that is the very opposite of what it's meant for (excluding files), even though it is possible?\n.gitkeep approach\n\nUse an empty file called .gitkeep in order to force the presence of the folder in the versioning system.\n\nAlthough it may seem not such a big difference:\n\nYou use a file that has the single purpose of keeping the folder. You don't put there any info you don't want to put.\n\nFor instance, you should use READMEs as, well, READMEs with useful information, not as an excuse to keep the folder.\n\nSeparation of concerns is always a good thing, and you can still add a .gitignore to ignore unwanted files.\n\nNaming it .gitkeep makes it very clear and straightforward from the filename itself (and also to other developers, which is good for a shared project and one of the core purposes of a Git repository) that this file is\n\nA file unrelated to the code (because of the leading dot and the name)\nA file clearly related to Git\nIts purpose (keep) is clearly stated and consistent and semantically opposed in its meaning to ignore\nAdoption\n\nI've seen the .gitkeep approach adopted by very important frameworks like Laravel, Angular-CLI.\n\nShare\nImprove this answer\nFollow\nedited Jun 9 '19 at 9:53\nManu Manjunath\n5,6601\n1 gold badge\n30\n30 silver badges\n31\n31 bronze badges\nanswered Dec 4 '13 at 23:32\nCranio\n9,1042\n2 gold badges\n31\n31 silver badges\n51\n51 bronze badges","comments":["You missed one thought - whats the reason for keeping and empty folder (e.g. /logs, /tmp, /uploads)? Yes - its to keep the folder empty. :) So if you want to keep a folder empty, you have to ignore the files inside it.","@RomanAllenstein: not necessarily. It could be that you create a repo with a given structure which can become populated later. Those files will be added to the repo as soon as they are created, and it will be annoying to start deleting or editing .gitignore files (and dangerous, because probably you do not even realize that they are not being tracked: git is ignoring them)","If you edit your answer to replace .gitkeep with any other non git-prefixed file name you get my upvote, I think this one is the best and most informative answer. Reason: I think \".git*\" should be reserved for git prescribed files, while this is just a mere placeholder. My first guess when I saw that is that for example a \".gitkeep\" file would be auto-ignored (that would be a nice feature) but that is not the case, right?","@Santosh You could edit my post and be useful to the community instead of childishly bragging against a non-native speaker and uselessly polluting the comments, which is [IN]consistent with average intelligent behaviour. That's why edits are for, btw. Thanks for the free lesson anyway, duly appreciated :)","I wonder why people have such a hard time to understand why one wants to add \"empty\" folders to git. You have to start somewhere, right? So, usually you start with your projects folder structure and - alas - at the start of the project there is nothing there yet. Once your project repo is done, team workers can clone and start working on the SAME structure."]},{"answer":"As described in other answers, Git is unable to represent empty directories in its staging area. (See the Git FAQ.) However, if, for your purposes, a directory is empty enough if it contains a .gitignore file only, then you can create .gitignore files in empty directories only via:\n\nfind . -type d -empty -exec touch {}/.gitignore \\;\n\nShare\nImprove this answer\nFollow\nedited Dec 23 '14 at 11:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 3 '11 at 15:17\nmjs\n57.9k27\n27 gold badges\n82\n82 silver badges\n114\n114 bronze badges","comments":["You may want to ignore the .git directory: find . -name .git -prune -o -type d -empty -exec touch {}/.gitignore \\;","A simpler variation for most situations is find * -type d -empty -exec touch {}/.gitignore \\;","Since OS X creates a .DS_Store file in almost every directoy, this does not work there. The only (DANGEROUS!) workaround i found, was to delete all the .DS_Store files first via find . -name .DS_Store -exec rm {} \\; and then use the preferred variant from this answer. Be sure to only execute this in the correct folder!","Does anyone know a way to do this in Windows from the command line? I've seen some solutions here in Ruby and Python, but I'd like a barebones solution if it can be managed.","@akhan Adding something to .gitignore has no influence on the -empty flag of the find command. My comment is about removing the .DS_Store files in a directory tree, so the -empty flag can be applied."]},{"answer":"Andy Lester is right, but if your directory just needs to be empty, and not empty empty, you can put an empty .gitignore file in there as a workaround.\n\nAs an aside, this is an implementation issue, not a fundamental Git storage design problem. As has been mentioned many times on the Git mailing list, the reason that this has not been implemented is that no one has cared enough to submit a patch for it, not that it couldn’t or shouldn’t be done.\n\nShare\nImprove this answer\nFollow\nedited Jan 29 '15 at 18:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 22 '08 at 17:28\nAristotle Pagaltzis\n103k21\n21 gold badges\n94\n94 silver badges\n96\n96 bronze badges","comments":["That's exactly what I said. Both paragraphs are addressed in the snippet of FAQ I posted.","I think the aside is unteresting and useful to know -- it can be fixed, just don't expect it anytime soon when there's such an easy workaround for most cases.","Sorry, I didn’t read the last paragraph, and while I did read the first paragraph, well, I’m not sure why I repeated that information.","Of course, this extra answer does serve to point out the fact.","I got here looking at a case where the build fell down if the directory doesn't exist and by default it is empty, but it doesn't need to be empty. Creating a .gitignore does the right thing."]},{"answer":"The Ruby on Rails log folder creation way:\n\nmkdir log && touch log/.gitkeep && git add log/.gitkeep\n\n\nNow the log directory will be included in the tree. It is super-useful when deploying, so you won't have to write a routine to make log directories.\n\nThe logfiles can be kept out by issuing,\n\necho log/dev.log >> .gitignore\n\n\nbut you probably knew that.\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '18 at 20:52\nrogerdpack\n52.1k31\n31 gold badges\n220\n220 silver badges\n338\n338 bronze badges\nanswered Oct 22 '12 at 13:24\nThomas E\n3,7042\n2 gold badges\n18\n18 silver badges\n13\n13 bronze badges","comments":["What does that have to do with Ruby on Rails?","@QuolonelQuestions github.com/rails/rails/blob/master/activerecord/test/migrations/…","It has now been renamed to .keep github.com/rails/rails/blob/main/activerecord/test/migrations/…"]},{"answer":"Git does not track empty directories. See the Git FAQ for more explanation. The suggested workaround is to put a .gitignore file in the empty directory. I do not like that solution, because the .gitignore is \"hidden\" by Unix convention. Also there is no explanation why the directories are empty.\n\nI suggest to put a README file in the empty directory explaining why the directory is empty and why it needs to be tracked in Git. With the README file in place, as far as Git is concerned, the directory is no longer empty.\n\nThe real question is why do you need the empty directory in git? Usually you have some sort of build script that can create the empty directory before compiling/running. If not then make one. That is a far better solution than putting empty directories in git.\n\nSo you have some reason why you need an empty directory in git. Put that reason in the README file. That way other developers (and future you) know why the empty directory needs to be there. You will also know that you can remove the empty directory when the problem requiring the empty directory has been solved.\n\nTo list every empty directory use the following command:\n\nfind -name .git -prune -o -type d -empty -print\n\n\nTo create placeholder READMEs in every empty directory:\n\nfind -name .git -prune -o -type d -empty -exec sh -c \\\n  \"echo this directory needs to be empty because reasons > {}/README.emptydir\" \\;\n\n\nTo ignore everything in the directory except the README file put the following lines in your .gitignore:\n\npath/to/emptydir/*\n!path/to/emptydir/README.emptydir\npath/to/otheremptydir/*\n!path/to/otheremptydir/README.emptydir\n\n\nAlternatively, you could just exclude every README file from being ignored:\n\npath/to/emptydir/*\npath/to/otheremptydir/*\n!README.emptydir\n\n\nTo list every README after they are already created:\n\nfind -name README.emptydir\n\nShare\nImprove this answer\nFollow\nedited Feb 8 '18 at 13:41\nanswered May 6 '11 at 15:45\nlesmana\n23k8\n8 gold badges\n74\n74 silver badges\n83\n83 bronze badges","comments":[]},{"answer":"WARNING: This tweak is not truly working as it turns out. Sorry for the inconvenience.\n\nOriginal post below:\n\nI found a solution while playing with Git internals!\n\nSuppose you are in your repository.\n\nCreate your empty directory:\n\n$ mkdir path/to/empty-folder\n\n\nAdd it to the index using a plumbing command and the empty tree SHA-1:\n\n$ git update-index --index-info\n040000 tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904    path/to/empty-folder\n\n\nType the command and then enter the second line. Press Enter and then Ctrl + D to terminate your input. Note: the format is mode [SPACE] type [SPACE] SHA-1hash [TAB] path (the tab is important, the answer formatting does not preserve it).\n\nThat's it! Your empty folder is in your index. All you have to do is commit.\n\nThis solution is short and apparently works fine (see the EDIT!), but it is not that easy to remember...\n\nThe empty tree SHA-1 can be found by creating a new empty Git repository, cd into it and issue git write-tree, which outputs the empty tree SHA-1.\n\nEDIT:\n\nI've been using this solution since I found it. It appears to work exactly the same way as creating a submodule, except that no module is defined anywhere. This leads to errors when issuing git submodule init|update. The problem is that git update-index rewrites the 040000 tree part into 160000 commit.\n\nMoreover, any file placed under that path won't ever be noticed by Git, as it thinks they belong to some other repository. This is nasty as it can easily be overlooked!\n\nHowever, if you don't already (and won't) use any Git submodules in your repository, and the \"empty\" folder will remain empty or if you want Git to know of its existence and ignore its content, you can go with this tweak. Going the usual way with submodules takes more steps that this tweak.\n\nShare\nImprove this answer\nFollow\nedited Dec 23 '14 at 11:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 20 '12 at 15:50\nofavre\n3,6281\n1 gold badge\n24\n24 silver badges\n23\n23 bronze badges","comments":["After putting the empty folder into the index and committing, is it then possible to git svn dcommit it with the desired result?","It's unlikely that this tweak will work with any other tool. Like stated in the warning and the edit, I discourage using it unless in a quite restricted case.","And of course this is why messing with the git internals is contraindicated.","I've created a better solution based on this that doesn't have these drawbacks: stackoverflow.com/a/58543445/277882"]},{"answer":"Let's say you need an empty directory named tmp :\n\n$ mkdir tmp\n$ touch tmp/.gitignore\n$ git add tmp\n$ echo '*' > tmp/.gitignore\n$ git commit -m 'Empty directory' tmp\n\n\nIn other words, you need to add the .gitignore file to the index before you can tell Git to ignore it (and everything else in the empty directory).\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '16 at 11:34\nGAMITG\n3,6707\n7 gold badges\n30\n30 silver badges\n50\n50 bronze badges\nanswered Oct 8 '08 at 0:13\nm104\n1,0286\n6 silver badges\n6\n6 bronze badges","comments":["Two things: You could just \"echo '*' > tmp/.gitignore\" instead of touching, and \"git commit -m\" does not commit changes done after you've added the files to the index.","If you just do echo bla > file you will not get file: File exists because > will overwrite the file if it's already there or create a new one if it doesn't exist.","/bin/sh cultural assumption!* If \"here\" is csh and the variable noclobber is set, you will indeed get file: File exists. If someone says \"I get this\", don't assume they're an idiot and reply \"No you don't\". * c2.com/cgi/wiki?AmericanCulturalAssumption","@clacke If someone decides to use a different shell than everyone else, they should state that expressly if they are encountering problems. Unlike with nationality, everyone has their free choice of shell.","@SeldomNeedy Maybe they are looking for help because they don't even know they are using a different shell than everybody else."]},{"answer":"Maybe adding an empty directory seems like it would be the path of least resistance because you have scripts that expect that directory to exist (maybe because it is a target for generated binaries). Another approach would be to modify your scripts to create the directory as needed.\n\nmkdir --parents .generated/bin ## create a folder for storing generated binaries\nmv myprogram1 myprogram2 .generated/bin ## populate the directory as needed\n\n\nIn this example, you might check in a (broken) symbolic link to the directory so that you can access it without the \".generated\" prefix (but this is optional).\n\nln -sf .generated/bin bin\ngit add bin\n\n\nWhen you want to clean up your source tree you can just:\n\nrm -rf .generated ## this should be in a \"clean\" script or in a makefile\n\n\nIf you take the oft-suggested approach of checking in an almost-empty folder, you have the minor complexity of deleting the contents without also deleting the \".gitignore\" file.\n\nYou can ignore all of your generated files by adding the following to your root .gitignore:\n\n.generated\n\nShare\nImprove this answer\nFollow\nanswered Oct 26 '11 at 16:33\nBrent Bradburn\n42.1k13\n13 gold badges\n130\n130 silver badges\n140\n140 bronze badges","comments":["Note: The symbolic link that I suggested is \"broken\" in a clean checkout because the .generated directory does not initially exist. It will no longer be broken once you do your build.","I agree in some cases this is a very good idea, but in others (such as distributing a project where you have an otherwise empty skeleton with folders such as models/ and views/ ) you would want the user to have these directories at hand rather than manually having to read read the docs, and it could be a bit much to expect them to run some sort of installation script after cloning the repo. I think this answer in combination with @john-mee's README answer should cover most if not all cases."]},{"answer":"You can't and unfortunately will never be able to. This is a decision made by Linus Torvald himself. He knows what's good for us.\n\nThere is a rant out there somewhere I read once.\n\nI found Re: Empty directories.., but maybe there is another one.\n\nYou have to live with the workarounds...unfortunately.\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '16 at 11:35\nGAMITG\n3,6707\n7 gold badges\n30\n30 silver badges\n50\n50 bronze badges\nanswered Mar 15 '15 at 18:17\nuser2334883\n3813\n3 silver badges\n4\n4 bronze badges","comments":["I know you posted this as an example of a bad argument, but I appreciate the link because it's actually a well-reasoned argument against tracking directories. ;-)","This answer seems to be inconsistent, since in the next post on the referenced thread, Linus Torvald says he expects that they will need to add directory tracking: markmail.org/message/libip4vpvvxhyqbl . In fact, he says he \"would welcome patches that [add support for tracking empty directories]\"","Patrick, he also uses the word \"idiotic\" there. I suspect his wording adresses the people here in this thread and so I assume he will not implement something \"idiotic\" into Git by himself."]},{"answer":"I've been facing the issue with empty directories, too. The problem with using placeholder files is that you need to create them, and delete them, if they are not necessary anymore (because later on there were added sub-directories or files. With big source trees managing these placeholder files can be cumbersome and error prone.\n\nThis is why I decided to write an open source tool which can manage the creation/deletion of such placeholder files automatically. It is written for .NET platform and runs under Mono (.NET for Linux) and Windows.\n\nJust have a look at: http://code.google.com/p/markemptydirs\n\nShare\nImprove this answer\nFollow\nedited Jun 22 '14 at 17:38\nanswered Jul 23 '09 at 22:33\nJonny Dee","comments":[]},{"answer":"I like the answers by @Artur79 and @mjs so I've been using a combination of both and made it a standard for our projects.\n\nfind . -type d -empty -exec touch {}/.gitkeep \\;\n\n\nHowever, only a handful of our developers work on Mac or Linux. A lot work on Windows and I could not find an equivalent simple one-liner to accomplish the same there. Some were lucky enough to have Cygwin installed for other reasons, but prescribing Cygwin just for this seemed overkill.\n\nEdit for a better solution\n\nSo, since most of our developers already have Ant installed, the first thing I thought of was to put together an Ant build file to accomplish this independently of the platform. This can still be found here\n\nHowever, I later thought It would be better to make this into a small utility command, so I recreated it using Python and published it to the PyPI here. You can install it by simply running:\n\npip3 install gitkeep2\n\n\nIt will allow you to create and remove .gitkeep files recursively, and it will also allow you to add messages to them for your peers to understand why those directories are important. This last bit is bonus. I thought it would be nice if the .gitkeep files could be self-documenting.\n\n$ gitkeep --help\nUsage: gitkeep [OPTIONS] PATH\n\n  Add a .gitkeep file to a directory in order to push them into a Git repo\n  even if they're empty.\n\n  Read more about why this is necessary at: https://git.wiki.kernel.org/inde\n  x.php/Git_FAQ#Can_I_add_empty_directories.3F\n\nOptions:\n  -r, --recursive     Add or remove the .gitkeep files recursively for all\n                      sub-directories in the specified path.\n  -l, --let-go        Remove the .gitkeep files from the specified path.\n  -e, --empty         Create empty .gitkeep files. This will ignore any\n                      message provided\n  -m, --message TEXT  A message to be included in the .gitkeep file, ideally\n                      used to explain why it's important to push the specified\n                      directory to source control even if it's empty.\n  -v, --verbose       Print out everything.\n  --help              Show this message and exit.\n\n\nI hope you find it useful.\n\nShare\nImprove this answer\nFollow\nedited Dec 22 '18 at 0:20\nanswered May 15 '17 at 19:08\nMig82\n3,8031\n1 gold badge\n33\n33 silver badges\n57\n57 bronze badges","comments":[]},{"answer":"When you add a .gitignore file, if you are going to put any amount of content in it (that you want Git to ignore) you might want to add a single line with just an asterisk * to make sure you don't add the ignored content accidentally.\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '16 at 11:34\nGAMITG\n3,6707\n7 gold badges\n30\n30 silver badges\n50\n50 bronze badges\nanswered Sep 24 '08 at 6:43\nMichael Johnson\n2,18915\n15 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"Reading @ofavre's and @stanislav-bashkyrtsev's answers using broken GIT submodule references to create the GIT directories, I'm surprised that nobody has suggested yet this simple amendment of the idea to make the whole thing sane and safe:\n\nRather than hacking a fake submodule into GIT, just add an empty real one.\n\nEnter: https://gitlab.com/empty-repo/empty.git\n\nA GIT repository with exactly one commit:\n\ncommit e84d7b81f0033399e325b8037ed2b801a5c994e0\nAuthor: Nobody <none>\nDate: Thu Jan 1 00:00:00 1970 +0000\n\n\nNo message, no committed files.\n\nUsage\n\nTo add an empty directory to you GIT repo:\n\ngit submodule add https://gitlab.com/empty-repo/empty.git path/to/dir\n\n\nTo convert all existing empty directories to submodules:\n\nfind . -type d -empty -delete -exec git submodule add -f https://gitlab.com/empty-repo/empty.git \\{\\} \\;\n\n\nGit will store the latest commit hash when creating the submodule reference, so you don't have to worry about me (or GitLab) using this to inject malicious files. Unfortunately I have not found any way to force which commit ID is used during checkout, so you'll have to manually check that the reference commit ID is e84d7b81f0033399e325b8037ed2b801a5c994e0 using git submodule status after adding the repo.\n\nStill not a native solution, but the best we probably can have without somebody getting their hands really, really dirty in the GIT codebase.\n\nAppendix: Recreating this commit\n\nYou should be able to recreate this exact commit using (in an empty directory):\n\n# Initialize new GIT repository\ngit init\n\n# Set author data (don't set it as part of the `git commit` command or your default data will be stored as “commit author”)\ngit config --local user.name \"Nobody\"\ngit config --local user.email \"none\"\n\n# Set both the commit and the author date to the start of the Unix epoch (this cannot be done using `git commit` directly)\nexport GIT_AUTHOR_DATE=\"Thu Jan 1 00:00:00 1970 +0000\"\nexport GIT_COMMITTER_DATE=\"Thu Jan 1 00:00:00 1970 +0000\"\n\n# Add root commit\ngit commit --allow-empty --allow-empty-message --no-edit\n\n\nCreating reproducible GIT commits is surprisingly hard…\n\nShare\nImprove this answer\nFollow\nanswered Oct 24 '19 at 14:23\nntninja\n8189\n9 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"There's no way to get Git to track directories, so the only solution is to add a placeholder file within the directory that you want Git to track.\n\nThe file can be named and contain anything you want, but most people use an empty file named .gitkeep (although some people prefer the VCS-agnostic .keep).\n\nThe prefixed . marks it as a hidden file.\n\nAnother idea would be to add a README file explaining what the directory will be used for.\n\nShare\nImprove this answer\nFollow\nanswered Apr 26 '15 at 22:54\nZaz\n40.4k10\n10 gold badges\n71\n71 silver badges\n93\n93 bronze badges","comments":[]},{"answer":"As mentioned it's not possible to add empty directories, but here is a one liner that adds empty .gitignore files to all directories.\n\nruby -e 'require \"fileutils\" ; Dir.glob([\"target_directory\",\"target_directory/**\"]).each { |f| FileUtils.touch(File.join(f, \".gitignore\")) if File.directory?(f) }'\n\nI have stuck this in a Rakefile for easy access.\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '16 at 11:34\nGAMITG\n3,6707\n7 gold badges\n30\n30 silver badges\n50\n50 bronze badges\nanswered Apr 19 '11 at 14:10\nPeter Hoeg\n8739\n9 silver badges\n12\n12 bronze badges","comments":["I'd rather use find . -type d -empty -print0 | xargs --null bash -c 'for a; do { echo \"*\"; echo \"!.gitignore\"; } >>\"$a/.gitignore\"; done' --"]},{"answer":"Many have already answered this question. Just adding a PowerShell version here.\n\nFind all the empty folders in the directory\n\nAdd a empty .gitkeep file in there\n\nGet-ChildItem 'Path to your Folder' -Recurse -Directory | Where-Object {[System.IO.Directory]::GetFileSystemEntries($_.FullName).Count -eq 0} | ForEach-Object { New-Item ($_.FullName + \"\\.gitkeep\") -ItemType file}\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Aug 13 '19 at 9:34\nHainan Zhao\n1,48314\n14 silver badges\n15\n15 bronze badges","comments":["Nice.‌‌ ༼ ͡☉ ͜ʖ ͡☉ ༽"]},{"answer":"The solution of Jamie Flournoy works great. Here is a bit enhanced version to keep the .htaccess :\n\n# Ignore everything in this directory\n*\n# Except this file\n!.gitignore\n!.htaccess\n\n\nWith this solution you are able to commit a empty folder, for example /log, /tmp or /cache and the folder will stay empty.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:02\nCommunity♦\n11\n1 silver badge\nanswered Jun 22 '14 at 13:06\nRoman\n2,0782\n2 gold badges\n23\n23 silver badges\n43\n43 bronze badges","comments":["He wants to keep a empty directory and not a file.","And i have mentioned that it will keep the .htaccess, too. Example: if a software has a directory for log-files (like oxid eshop) that should not be accesible via web, there is a .htaccess in the directory. If you put the above mentioned .gitignore in the folder, the .htaccess will not be comitted and the folder will be accessible via web.","If you have a .htaccess file that's under version control, then you already have the directory containing it under version control. Thus, the problem is already solved - the .gitignore file becomes irrelevant.","@Wallacoloo Related to the question you're right, nevertheless the file is useful, I'll use it for an upload-directory like that where files shall be protected by .htaccess. Contrary to Romans explanation the .htaccess-file will be committed as it's excluded by the ignore-rule. [old thread, I know]"]},{"answer":"I always build a function to check for my desired folder structure and build it for me within the project. This gets around this problem as the empty folders are held in Git by proxy.\n\nfunction check_page_custom_folder_structure () {\n    if (!is_dir(TEMPLATEPATH.\"/page-customs\"))\n        mkdir(TEMPLATEPATH.\"/page-customs\");    \n    if (!is_dir(TEMPLATEPATH.\"/page-customs/css\"))\n        mkdir(TEMPLATEPATH.\"/page-customs/css\");\n    if (!is_dir(TEMPLATEPATH.\"/page-customs/js\"))\n        mkdir(TEMPLATEPATH.\"/page-customs/js\");\n}\n\n\nThis is in PHP, but I am sure most languages support the same functionality, and because the creation of the folders is taken care of by the application, the folders will always be there.\n\nShare\nImprove this answer\nFollow\nedited Jan 29 '15 at 18:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 4 '11 at 10:06\nMild Fuzz\n26.4k28\n28 gold badges\n95\n95 silver badges\n143\n143 bronze badges","comments":["Just so we're all on the same page, I do not do this anymore. It's a waste of time. The .gitkeep convention is a much better practise.","I can't see how this can be a waste of time. When your TEMPLATEPATH is obviously dynamic you can't use the .gitkeep solution. And even with a nondynamic folder structure you should add some more stuff instead of removing the very good solution of checking directories e.g. check for permissions and chmod the files. Adding a way to mark directories inside a global .gitignore would be perfect for me. Something like #keep /path/to/dir"]},{"answer":"Here is a hack, but it's funny that it works (Git 2.2.1). Similar to what @Teka suggested, but easier to remember:\n\nAdd a submodule to any repository (git submodule add path_to_repo)\nThis will add a folder and a file .submodules. Commit a change.\nDelete .submodules file and commit the change.\n\nNow, you have a directory that gets created when commit is checked out. An interesting thing though is that if you look at the content of tree object of this file you'll get:\n\nfatal: Not a valid object name b64338b90b4209263b50244d18278c0999867193\n\nI wouldn't encourage to use it though since it may stop working in the future versions of Git. Which may leave your repository corrupted.\n\nShare\nImprove this answer\nFollow\nedited Jan 29 '15 at 18:54\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 24 '14 at 10:24\nStanislav Bashkyrtsev\n11.6k7\n7 gold badges\n35\n35 silver badges\n39\n39 bronze badges","comments":["This actually works but I think confuses the heck out of IntelliJ... :|","I've created a better solution based on this that doesn't have these drawbacks: stackoverflow.com/a/58543445/277882"]},{"answer":"This solution worked for me.\n\n1. Add a .gitignore file to your empty directory:\n*\n*/\n!.gitignore\n\n* ignore all files in the folder\n*/ Ignore subdirectories\n!.gitignore include the .gitignore file\n2. Then remove your cache, stage your files, commit and push:\ngit rm -r --cached .\ngit add . // or git stage .\ngit commit -m \".gitignore fix\"\ngit push\n\nShare\nImprove this answer\nFollow\nedited Jun 18 at 13:23\nanswered Sep 3 '20 at 15:04\nDevonDahon\n4,5062\n2 gold badges\n41\n41 silver badges\n60\n60 bronze badges","comments":[]},{"answer":"If you want to add a folder that will house a lot of transient data in multiple semantic directories, then one approach is to add something like this to your root .gitignore...\n\n/app/data/**/*.*\n!/app/data/**/*.md\n\nThen you can commit descriptive README.md files (or blank files, doesn't matter, as long as you can target them uniquely like with the *.md in this case) in each directory to ensure that the directories all remain part of the repo but the files (with extensions) are kept ignored. LIMITATION: .'s are not allowed in the directory names!\n\nYou can fill up all of these directories with xml/images files or whatever and add more directories under /app/data/ over time as the storage needs for your app develop (with the README.md files serving to burn in a description of what each storage directory is for exactly).\n\nThere is no need to further alter your .gitignore or decentralise by creating a new .gitignore for each new directory. Probably not the smartest solution but is terse gitignore-wise and always works for me. Nice and simple! ;)\n\nShare\nImprove this answer\nFollow\nedited May 11 '17 at 14:14\nanswered May 11 '17 at 13:36\najmedway\n1,42413\n13 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"An easy way to do this is by adding a .gitkeep file to the directory you wish to (currently) keep empty.\n\nSee this SOF answer for further info - which also explains why some people find the competing convention of adding a .gitignore file (as stated in many answers here) confusing.\n\nShare\nImprove this answer\nFollow\nanswered Jun 17 '19 at 5:03\narcseldon\n30.4k14\n14 gold badges\n104\n104 silver badges\n117\n117 bronze badges","comments":[]},{"answer":"Sometimes you have to deal with bad written libraries or software, which need a \"real\" empty and existing directory. Putting a simple .gitignore or .keep might break them and cause a bug. The following might help in these cases, but no guarantee...\n\nFirst create the needed directory:\n\nmkdir empty\n\n\nThen you add a broken symbolic link to this directory (but on any other case than the described use case above, please use a README with an explanation):\n\nln -s .this.directory empty/.keep\n\n\nTo ignore files in this directory, you can add it in your root .gitignore:\n\necho \"/empty\" >> .gitignore\n\n\nTo add the ignored file, use a parameter to force it:\n\ngit add -f empty/.keep\n\n\nAfter the commit you have a broken symbolic link in your index and git creates the directory. The broken link has some advantages, since it is no regular file and points to no regular file. So it even fits to the part of the question \"(that contains no files)\", not by the intention but by the meaning, I guess:\n\nfind empty -type f\n\n\nThis commands shows an empty result, since no files are present in this directory. So most applications, which get all files in a directory usually do not see this link, at least if they do a \"file exists\" or a \"is readable\". Even some scripts will not find any files there:\n\n$ php -r \"var_export(glob('empty/.*'));\"\narray (\n  0 => 'empty/.',\n  1 => 'empty/..',\n)\n\n\nBut I strongly recommend to use this solution only in special circumstances, a good written README in an empty directory is usually a better solution. (And I do not know if this works with a windows filesystem...)\n\nShare\nImprove this answer\nFollow\nanswered Jun 2 '16 at 16:42\nTrendfischer\n5,7614\n4 gold badges\n33\n33 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"Adding one more option to the fray.\n\nAssuming you would like to add a directory to git that, for all purposes related to git, should remain empty and never have it's contents tracked, a .gitignore as suggested numerous times here, will do the trick.\n\nThe format, as mentioned, is:\n\n*\n!.gitignore\n\n\nNow, if you want a way to do this at the command line, in one fell swoop, while inside the directory you want to add, you can execute:\n\n$ echo \"*\" > .gitignore && echo '!.gitignore' >> .gitignore && git add .gitignore\n\n\nMyself, I have a shell script that I use to do this. Name the script whatever you whish, and either add it somewhere in your include path, or reference it directly:\n\n#!/bin/bash\n\ndir=''\n\nif [ \"$1\" != \"\" ]; then\n    dir=\"$1/\"\nfi\n\necho \"*\" > $dir.gitignore && \\\necho '!.gitignore' >> $dir.gitignore && \\\ngit add $dir.gitignore\n\n\nWith this, you can either execute it from within the directory you wish to add, or reference the directory as it's first and only parameter:\n\n$ ignore_dir ./some/directory\n\n\nAnother option (in response to a comment by @GreenAsJade), if you want to track an empty folder that MAY contain tracked files in the future, but will be empty for now, you can ommit the * from the .gitignore file, and check that in. Basically, all the file is saying is \"do not ignore me\", but otherwise, the directory is empty and tracked.\n\nYour .gitignore file would look like:\n\n!.gitignore\n\n\nThat's it, check that in, and you have an empty, yet tracked, directory that you can track files in at some later time.\n\nThe reason I suggest keeping that one line in the file is that it gives the .gitignore purpose. Otherwise, some one down the line may think to remove it. It may help if you place a comment above the line.\n\nShare\nImprove this answer\nFollow\nedited May 28 '16 at 16:38\nanswered May 26 '16 at 1:18\nMike\n1,79915\n15 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"You can't. This is an intentional design decision by the Git maintainers. Basically, the purpose of a Source Code Management System like Git is managing source code and empty directories aren't source code. Git is also often described as a content tracker, and again, empty directories aren't content (quite the opposite, actually), so they are not tracked.\n\nShare\nImprove this answer\nFollow\nanswered Sep 22 '08 at 19:50\nJörg W Mittag\n340k72\n72 gold badges\n416\n416 silver badges\n617\n617 bronze badges","comments":["I contest this view. Structure is content, and everything you name contributes to content.","An empty file isn't source code or content either. It's just a name. Yet Git will happily track empty files. I don't think it was an intentional design decision to make Git refuse to track empty directories. I think tracking empty directories is a feature that simply isn't needed 99% of the time, so they didn't bother to do the extra work required to make it work properly. Git can do it if someone wants the feature badly enough to implement it. I doubt the Git maintainers would be opposed to such a patch if it were done correctly.","@TobyAllen here is the updated FAQ link The top answer is also what is recommended by the FAQ with more precise instructions.","It's a missing feature (and low priority), not an intentional limitation. From the Git FAQ: Currently the design of the Git index (staging area) only permits files to be listed, and nobody competent enough to make the change to allow empty directories has cared enough about this situation to remedy it.","Don't really agree. I can find various reasons why I want to track an empty folder. For example, I am developing a very lightweight PHP MVC framework for my projects. I have specific folders for placing models, views, etc. When I make a new site based on my framework, those folders are empty since there are no models or views by default, but I do need the folder to exist, else my framework won't work!"]}]},{"id":"4456438","href":"https://stackoverflow.com/questions/4456438/how-to-pass-null-a-real-surname-to-a-soap-web-service-in-actionscript-3","title":"How to pass “Null” (a real surname!) to a SOAP web service in ActionScript 3","description":"\n                \nWe have an employee whose surname is Null. Our employee lookup application is killed when that last name is used as the search term (which happens to be quite often now). The error received (thanks Fiddler!) is:\n\n<soapenv:Fault>\n   <faultcode>soapenv:Server.userException</faultcode>\n   <faultstring>coldfusion.xml.rpc.CFCInvocationException: [coldfusion.runtime.MissingArgumentException : The SEARCHSTRING parameter to the getFacultyNames function is required but was not passed in.]</faultstring>\n\n\nCute, huh?\n\nThe parameter type is string.\n\nI am using:\n\n\nWSDL (SOAP)\nFlex 3.5\nActionScript 3\nColdFusion 8\n\n\nNote that the error does not occur when calling the webservice as an object from a ColdFusion page.\n    ","questionComments":["It may not help you that much with the specific problem, but SOAP 1.2 allows for nullable values, see w3.org/TR/2001/WD-soap12-20010709/#_Toc478383513","I have a feeling it involves Dave Null.","Has the employee considered to change his name?","Referenced on BBC: bbc.com/future/story/…","He should really consider buying a Pointer dog and calling him NullPointer."],"answers":[{"answer":"Tracking it down\n\nAt first I thought this was a coercion bug where null was getting coerced to \"null\" and a test of \"null\" == null was passing. It's not. I was close, but so very, very wrong. Sorry about that!\n\nI've since done lots of fiddling on wonderfl.net and tracing through the code in mx.rpc.xml.*. At line 1795 of XMLEncoder (in the 3.5 source), in setValue, all of the XMLEncoding boils down to\n\ncurrentChild.appendChild(xmlSpecialCharsFilter(Object(value)));\n\n\nwhich is essentially the same as:\n\ncurrentChild.appendChild(\"null\");\n\n\nThis code, according to my original fiddle, returns an empty XML element. But why?\n\nCause\n\nAccording to commenter Justin Mclean on bug report FLEX-33664, the following is the culprit (see last two tests in my fiddle which verify this):\n\nvar thisIsNotNull:XML = <root>null</root>;\nif(thisIsNotNull == null){\n    // always branches here, as (thisIsNotNull == null) strangely returns true\n    // despite the fact that thisIsNotNull is a valid instance of type XML\n}\n\n\nWhen currentChild.appendChild is passed the string \"null\", it first converts it to a root XML element with text null, and then tests that element against the null literal. This is a weak equality test, so either the XML containing null is coerced to the null type, or the null type is coerced to a root xml element containing the string \"null\", and the test passes where it arguably should fail. One fix might be to always use strict equality tests when checking XML (or anything, really) for \"nullness.\"\n\nSolution\nThe only reasonable workaround I can think of, short of fixing this bug in every damn version of ActionScript, is to test fields for \"null\" and escape them as CDATA values.\n\nCDATA values are the most appropriate way to mutate an entire text value that would otherwise cause encoding/decoding problems. Hex encoding, for instance, is meant for individual characters. CDATA values are preferred when you're escaping the entire text of an element. The biggest reason for this is that it maintains human readability.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:18\nCommunity♦\n11\n1 silver badge\nanswered Aug 1 '13 at 17:31\nBen Burns\n14.3k3\n3 gold badges\n29\n29 silver badges\n54\n54 bronze badges","comments":[]},{"answer":"On the xkcd note, the Bobby Tables website has good advice for avoiding the improper interpretation of user data (in this case, the string \"Null\") in SQL queries in various languages, including ColdFusion.\n\nIt is not clear from the question that this is the source of the problem, and given the solution noted in a comment to the first answer (embedding the parameters in a structure) it seems likely that it was something else.\n\nShare\nImprove this answer\nFollow\nedited Aug 10 '13 at 13:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 27 '12 at 20:00\nAlex Dupuy\n5,6442\n2 gold badges\n34\n34 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"The problem could be in Flex's SOAP encoder. Try extending the SOAP encoder in your Flex application and debug the program to see how the null value is handled.\n\nMy guess is, it's passed as NaN (Not a Number). This will mess up the SOAP message unmarshalling process sometime (most notably in the JBoss 5 server...). I remember extending the SOAP encoder and performing an explicit check on how NaN is handled.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 16:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 16 '11 at 8:13\nuncaught_exceptions\n20.6k4\n4 gold badges\n37\n37 silver badges\n48\n48 bronze badges","comments":["name=\"Null\" is of course usefull, and I dont see how it should be related to NaN."]},{"answer":"@doc_180 had the right concept, except he is focused on numbers, whereas the original poster had issues with strings.\n\nThe solution is to change the mx.rpc.xml.XMLEncoder file. This is line 121:\n\n    if (content != null)\n        result += content;\n\n\n(I looked at Flex 4.5.1 SDK; line numbers may differ in other versions.)\n\nBasically, the validation fails because 'content is null' and therefore your argument is not added to the outgoing SOAP Packet; thus causing the missing parameter error.\n\nYou have to extend this class to remove the validation. Then there is a big snowball up the chain, modifying SOAPEncoder to use your modified XMLEncoder, and then modifying Operation to use your modified SOAPEncoder, and then moidfying WebService to use your alternate Operation class.\n\nI spent a few hours on it, but I need to move on. It'll probably take a day or two.\n\nYou may be able to just fix the XMLEncoder line and do some monkey patching to use your own class.\n\nI'll also add that if you switch to using RemoteObject/AMF with ColdFusion, the null is passed without problems.\n\n11/16/2013 update:\n\nI have one more recent addition to my last comment about RemoteObject/AMF. If you are using ColdFusion 10; then properties with a null value on an object are removed from the server-side object. So, you have to check for the properties existence before accessing it or you will get a runtime error.\n\nCheck like this:\n\n<cfif (structKeyExists(arguments.myObject,'propertyName')>\n <!--- no property code --->\n<cfelse>\n <!--- handle property  normally --->\n</cfif>\n\n\nThis is a change in behavior from ColdFusion 9; where the null properties would turn into empty strings.\n\nEdit 12/6/2013\n\nSince there was a question about how nulls are treated, here is a quick sample application to demonstrate how a string \"null\" will relate to the reserved word null.\n\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<s:Application xmlns:fx=\"http://ns.adobe.com/mxml/2009\"\n               xmlns:s=\"library://ns.adobe.com/flex/spark\"\n               xmlns:mx=\"library://ns.adobe.com/flex/mx\" minWidth=\"955\" minHeight=\"600\" initialize=\"application1_initializeHandler(event)\">\n    <fx:Script>\n        <![CDATA[\n            import mx.events.FlexEvent;\n\n            protected function application1_initializeHandler(event:FlexEvent):void\n            {\n                var s :String = \"null\";\n                if(s != null){\n                    trace('null string is not equal to null reserved word using the != condition');\n                } else {\n                    trace('null string is equal to null reserved word using the != condition');\n                }\n\n                if(s == null){\n                    trace('null string is equal to null reserved word using the == condition');\n                } else {\n                    trace('null string is not equal to null reserved word using the == condition');\n                }\n\n                if(s === null){\n                    trace('null string is equal to null reserved word using the === condition');\n                } else {\n                    trace('null string is not equal to null reserved word using the === condition');\n                }\n            }\n        ]]>\n    </fx:Script>\n    <fx:Declarations>\n        <!-- Place non-visual elements (e.g., services, value objects) here -->\n    </fx:Declarations>\n</s:Application>\n\n\nThe trace output is:\n\nnull string is not equal to null reserved word using the != condition\n\nnull string is not equal to null reserved word using the == condition\n\nnull string is not equal to null reserved word using the === condition\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '19 at 16:54\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 3 '12 at 15:51\nJeffryHouser\n39k4\n4 gold badges\n36\n36 silver badges\n57\n57 bronze badges","comments":["@Reboog711 The employee's last name is literally the string \"Null\" as in, \"My name is Pat Null\" Your answer fails to pass the employee's last name. You answer just hides the fact that \"Null\" is being inappropriately coerced into the language concept of null by the appendChild() method as described by Ben Burns. The result is still failure of the system to deal with Mr. or Ms. Null.","@MaxxDaymon I think you misconstrue what my answer actually is. It doesn't present a solution; but rather an explanation of why the problem occurs; and quotes relevant code from the Flex Framework. My more recent edit is perhaps misplaced; as it discusses an alternate approach and is not directly related to the original question.","You're sort of on the right track, but at that point in the code content is the string \"null\", and \"null\" == null returns false, so that test behaves as intended. Instead I believe the problem is a mix of how XML.appendChild handles a string argument, and how a root XML element containing only the string \"null\" can be coerced to a literal null.","@Reboog711 Take a look at my fiddle. \"null\" != null` returning true is desired behavior here. If the opposite happened, this would discard the string \"null\" from the encoding process, which in fact would be the cause of the problem. However because this test succeeds, the encoder keeps going, until XML.appendChild discards it due to a coercion bug.","No worries. If you want to see the real problem add var xml:XML = <root>null</root>;  var s:String = (xml == null) ? \"wtf? xml coerced to null?!!\" : \"xml not coerced to null.\"; trace(s); to your code sample."]},{"answer":"Translate all characters into their hex-entity equivalents. In this case, Null would be converted into &#4E;&#75;&#6C;&#6C;\n\nShare\nImprove this answer\nFollow\nanswered Apr 30 '12 at 19:03\ndoogle\n3,25115\n15 silver badges\n23\n23 bronze badges","comments":["Please don't do this. CDATA was created for use in cases where you need to escape an entire block of text.","I could be wrong, but I don't think downvoting just because it wasn't your solution is how it's supposed to work. Also you have to keep in mind the problem calls for a heuristic solution since there isn't one obvious way, as made evident by the variety of solutions posted. Lastly, keeping in mind I don't know CF, wouldn't a decoder just equate the inner text of <message><![CDATA[NULL]]></message> to the inner text of <message>NULL</message>? If so, then is CDATA really a solution at all?","I downvoted because this is an anti-pattern. The bug in this case isn't in CF, it's in ActionScript. However, you raise a good point nonetheless. I'll add a test to my fiddle for CDATA encoding."]},{"answer":"Stringifying a null value in ActionScript will give the string \"NULL\". My suspicion is that someone has decided that it is, therefore, a good idea to decode the string \"NULL\" as null, causing the breakage you see here -- probably because they were passing in null objects and getting strings in the database, when they didn't want that (so be sure to check for that kind of bug, too).\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '14 at 10:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 28 '12 at 20:15\nAndrew Aylett\n36.7k4\n4 gold badges\n64\n64 silver badges\n93\n93 bronze badges","comments":["Yes, there are a number of possibilities here which will require more debugging to narrow down. 1) Is the WSDL used here expressive enough to distinguish between \"NULL\" as a string value and an actual null (or omitted) value? 2) If so, is the client encoding the last name correctly (as a string and not a null literal) 3) If so, is the service properly interpreting \"NULL\" as a string, or coercing it to a null value?"]},{"answer":"As a hack, you could consider having a special handling on the client side, converting 'Null' string to something that will never occur, for example, XXNULLXX and converting back on the server.\n\nIt is not pretty, but it may solve the issue for such a boundary case.\n\nShare\nImprove this answer\nFollow\nedited Aug 10 '13 at 13:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 28 '12 at 8:43\nMark\n1,5091\n1 gold badge\n15\n15 silver badges\n28\n28 bronze badges","comments":["XXNULLXX could be a name too. You don't know. Maybe people in Indonesia do not have surname and use a variant of XXX as their surname when required.","Same concept, but update all the names in the database and preface then with some character (1Null, 1Smith). Strip off that character in the client. Of course this might be mite work than Reboog's solution.","@BenBurns Yeah, but what if I want to name my kid &#78;&#117;&#108;&#108;?","@Sirens That is not the problem. If my name is \"<&quot;>\", then I expect it to be properly escaped as &quot;&lt;&amp;quot;&gt;&quot;, that goes without saying. The real problem is with an application behaving as if it uses a blacklist for names."]},{"answer":"Well, I guess that Flex' implementation of the SOAP Encoder seems to serialize null values incorrectly. Serializing them as a String Null doesn't seem to be a good solution. The formally correct version seems to be to pass a null value as:\n\n<childtag2 xsi:nil=\"true\" />\n\n\nSo the value of \"Null\" would be nothing else than a valid string, which is exactly what you are looking for.\n\nI guess getting this fixed in Apache Flex shouldn't be that hard to get done. I would recommend opening a Jira issue or to contact the guys of the apache-flex mailinglist. However this would only fix the client side. I can't say if ColdFusion will be able to work with null values encoded this way.\n\nSee also Radu Cotescu's blog post How to send null values in soapUI requests.\n\nShare\nImprove this answer\nFollow\nedited Feb 22 '14 at 21:20\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 17 '13 at 7:56\nChristofer Dutz\n2,2751\n1 gold badge\n21\n21 silver badges\n31\n31 bronze badges","comments":["There's good info here, so I won't downvote, but I figured it's worth a comment. By default, XMLEncoder.as will actually encode a true null value properly, by setting xsi:nil=\"true\" on the element. The issue actually appears to be in the way the ActionScript XML type itself (not the encoder) handles the string \"null\"."]},{"answer":"It's a kludge, but assuming there's a minimum length for SEARCHSTRING, for example 2 characters, substring the SEARCHSTRING parameter at the second character and pass it as two parameters instead: SEARCHSTRING1 (\"Nu\") and SEARCHSTRING2 (\"ll\"). Concatenate them back together when executing the query to the database.\n\nShare\nImprove this answer\nFollow\nedited Jun 18 '15 at 10:52\nDhanuka\n2,7365\n5 gold badges\n25\n25 silver badges\n37\n37 bronze badges\nanswered Apr 28 '12 at 19:48\nSPitBalls.com\n5024\n4 silver badges\n6\n6 bronze badges","comments":["CDATA was added to the XML spec to avoid these types of kludges.","There is no need to escape \"Null\" with CDATA, there is no such thing as a null keyword in XML.","Agree with @eckes. I don't understand why there is all this talk of CDATA. CDATA is only useful to escape characters that have special meaning in XML. none of: n, u, l have special semantics in XML. \"NULL\" and \"<![CDATA[NULL]]>\" are identical to an XML parser.","@jasonkarns - I agree 100% that there should be nothing special about the string/text node NULL, but to be pedantic, <blah>null</blah> and <blah><![CDATA[null]]> are not the same to an XML parser. They should produce the same results, however the logic flow for handling them is different. It is this effect that we're exploiting as a workaround to the bug in the flex XML implementation. I advocate for this over other approaches as it preserves the readability of the text, and has no side effects for other parsers."]}]},{"id":"2432764","href":"https://stackoverflow.com/questions/2432764/how-to-change-the-uri-url-for-a-remote-git-repository","title":"How to change the URI (URL) for a remote Git repository?","description":"\n                \nI have a repo (origin) on a USB key that I cloned on my hard drive (local). I moved \"origin\" to a NAS and successfully tested cloning it from here.\n\nI would like to know if I can change the URI of \"origin\" in the settings of \"local\" so it will now pull from the NAS, and not from the USB key.\n\nFor now, I can see two solutions:\n\n\npush everything to the usb-orign, and copy it to the NAS again (implies a lot of work due to new commits to nas-origin);\nadd a new remote to \"local\" and delete the old one (I fear I'll break my history).\n\n    ","questionComments":["I had to do this on an old version of git (1.5.6.5) and the set-url option did not exist. Simply deleting the unwanted remote and adding a new one with the same name worked without problem and maintained history just fine.","in my case i need to check my permission i have two private git repositories and this second account is admin of that new repo and first one is my default user account and i should grant permission to first","Nice Doc is available here. docs.github.com/en/free-pro-team@latest/github/using-git/…"],"answers":[{"answer":"You can\n\ngit remote set-url origin new.git.url/here\n\n\n(see git help remote) or you can edit .git/config and change the URLs there. You're not in any danger of losing history unless you do something very silly (and if you're worried, just make a copy of your repo, since your repo is your history.)\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '20 at 14:22\nHarry B\n2,5501\n1 gold badge\n18\n18 silver badges\n40\n40 bronze badges\nanswered Mar 12 '10 at 12:55\nhobbs\n193k16\n16 gold badges\n185\n185 silver badges\n273\n273 bronze badges","comments":["If you have a different shell user then maybe you want to specify your git user in the beginning of the new url e.g.: myself@git://new.url.here","You may also want to set the master upstream branch for your new origin location with: git branch -u origin/master. This will allow you to just git push instead of having to git push origin master every time.","@kelorek or you can just git push -u origin master the first time :)","I also had to git remote set-url --push origin git://... in order to set the origin ... (push) url.","For multiple branches, you can use git push -u --all to push all branches at once to new url (instead of git push -u origin master)"]},{"answer":"git remote -v\n# View existing remotes\n# origin  https://github.com/user/repo.git (fetch)\n# origin  https://github.com/user/repo.git (push)\n\ngit remote set-url origin https://github.com/user/repo2.git\n# Change the 'origin' remote's URL\n\ngit remote -v\n# Verify new remote URL\n# origin  https://github.com/user/repo2.git (fetch)\n# origin  https://github.com/user/repo2.git (push)\n\n\nChanging a remote's URL\n\nShare\nImprove this answer\nFollow\nedited Dec 18 '13 at 4:49\nSteven Penny\n1\nanswered Oct 10 '13 at 14:43\nUtensil\n12.4k1\n1 gold badge\n14\n14 silver badges\n10\n10 bronze badges","comments":["Amazing that you got almost a thousand upvotes and consequently almost ten thousand points for just giving the same answer as the accepted one, but then three years later.","To get them all, I added: git remote set-url --push origin git@github.com/User/Branch.git and git remote set-url composer https://github.com/User/Branch.git","@MS Berends The git remote -v helped for verification, whereas the accepted solution did not provide that.","you gave more details...","@MSBerends his answer is more verbose in technical level."]},{"answer":"Change Host for a Git Origin Server\n\nfrom: http://pseudofish.com/blog/2010/06/28/change-host-for-a-git-origin-server/\n\nHopefully this isn’t something you need to do. The server that I’ve been using to collaborate on a few git projects with had the domain name expire. This meant finding a way of migrating the local repositories to get back in sync.\n\nUpdate: Thanks to @mawolf for pointing out there is an easy way with recent git versions (post Feb, 2010):\n\ngit remote set-url origin ssh://newhost.com/usr/local/gitroot/myproject.git\n\n\nSee the man page for details.\n\nIf you’re on an older version, then try this:\n\nAs a caveat, this works only as it is the same server, just with different names.\n\nAssuming that the new hostname is newhost.com, and the old one was oldhost.com, the change is quite simple.\n\nEdit the .git/config file in your working directory. You should see something like:\n\n[remote \"origin\"]\nfetch = +refs/heads/*:refs/remotes/origin/*\nurl = ssh://oldhost.com/usr/local/gitroot/myproject.git\n\n\nChange oldhost.com to newhost.com, save the file and you’re done.\n\nFrom my limited testing (git pull origin; git push origin; gitx) everything seems in order. And yes, I know it is bad form to mess with git internals.\n\nShare\nImprove this answer\nFollow\nedited Sep 5 '12 at 23:45\nCraig McQueen\n37.9k27\n27 gold badges\n114\n114 silver badges\n172\n172 bronze badges\nanswered Feb 15 '11 at 2:52\nyoda\n4,3113\n3 gold badges\n17\n17 silver badges\n9\n9 bronze badges","comments":["Bad form? Perhaps. But if you need to do something the authors didn't expect anyone would ever need to do, then sometimes messing with the internals is required. But you do have to be willing to accept the consequences if you get it wrong. Backup your local repository _before_ messing with git internals.","where I can find .git/config"]},{"answer":"git remote set-url origin git://new.location\n\n\n(alternatively, open .git/config, look for [remote \"origin\"], and edit the url = line.\n\nYou can check it worked by examining the remotes:\n\ngit remote -v\n# origin  git://new.location (fetch)\n# origin  git://new.location (push)\n\n\nNext time you push, you'll have to specify the new upstream branch, e.g.:\n\ngit push -u origin master\n\n\nSee also: GitHub: Changing a remote's URL\n\nShare\nImprove this answer\nFollow\nanswered Apr 26 '15 at 23:13\nZaz\n40.4k10\n10 gold badges\n71\n71 silver badges\n93\n93 bronze badges","comments":["I could not set the new origin by editing .git/config. It said the git repository named in the URL wasn't a git repository. Once I removed and re-created origin, all was well. I had not looked up git remote set-url as a solution to my problem, though.","+1 for providing a complete answer with the git push -u command. Maybe obvious to others, wasn't for me."]},{"answer":"Switching remote URLs\n\nOpen Terminal.\n\nIst Step:- Change the current working directory to your local project.\n\n2nd Step:- List your existing remotes in order to get the name of the remote you want to change.\n\ngit remote -v\n\norigin  https://github.com/USERNAME/REPOSITORY.git (fetch)\n\norigin  https://github.com/USERNAME/REPOSITORY.git (push)\n\n\nChange your remote's URL from HTTPS to SSH with the git remote set-url command.\n\n3rd Step:- git remote set-url origin git@github.com:USERNAME/REPOSITORY.git\n\n4th Step:- Now Verify that the remote URL has changed.\n\ngit remote -v Verify new remote URL\n\norigin  git@github.com:USERNAME/REPOSITORY.git (fetch)\norigin  git@github.com:USERNAME/REPOSITORY.git (push)\n\nShare\nImprove this answer\nFollow\nedited Jan 9 '19 at 5:30\nCommunity♦\n11\n1 silver badge\nanswered Dec 8 '17 at 11:01\nVIKAS KOHLI\n6,6583\n3 gold badges\n39\n39 silver badges\n46\n46 bronze badges","comments":["Do you have to remove the old origin before you add the new origin?","I didn't remove from the project anything. I simply do the above steps and it worked"]},{"answer":"As seen here,\n\n$ git remote rm origin\n$ git remote add origin git@github.com:aplikacjainfo/proj1.git\n$ git config master.remote origin\n$ git config master.merge refs/heads/master\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '20 at 20:58\ntrashgod\n197k26\n26 gold badges\n214\n214 silver badges\n931\n931 bronze badges\nanswered Apr 2 '20 at 8:24\nZahid Hassan Shaikot\n6975\n5 silver badges\n13\n13 bronze badges","comments":["When adding an answer to a ten year old question with twenty one other answers it is really important to include an explanation of your answer and to point out what new aspect of the question your answer addresses. With answers that are a series of commands it is useful to explain what each is doing and how to undo the effects of each of them if that is possible. The undo is important in case someone is able to perform the first few steps, but then encounters an error on a later step.","@JasonAller I think this is fairly self-explanatory though and it's the best answer here by far, the others are a joke."]},{"answer":"remove origin using command on gitbash git remote rm origin\nAnd now add new Origin using gitbash git remote add origin (Copy HTTP URL from your project repository in bit bucket) done\nShare\nImprove this answer\nFollow\nedited Sep 14 '16 at 10:36\nanswered Jun 24 '16 at 11:10\nSunil Chaudhary\n1,01911\n11 silver badges\n25\n25 bronze badges","comments":["This is really useful answer because without git remote rm origin git remembers details about the old origin.","The above git remote rm origin resolves the issue of multiple remotes: issue where I was not able to set the remote url. remote.origin.url has multiple values fatal: could not set 'remote.origin.url'"]},{"answer":"Write the below command from your repo terminal:\n\ngit remote set-url origin git@github.com:<username>/<repo>.git\n\n\nRefer this link for more details about changing the url in the remote.\n\nShare\nImprove this answer\nFollow\nedited Jul 21 '20 at 17:35\nanswered Dec 19 '19 at 9:25\nviveknaskar\n1,6321\n1 gold badge\n13\n13 silver badges\n27\n27 bronze badges","comments":["it helped.The link was useful"]},{"answer":"git remote set-url {name} {url}\n\ngit remote set-url origin https://github.com/myName/GitTest.git\n\nShare\nImprove this answer\nFollow\nedited Aug 17 at 15:29\nBuddyBob\n5,5951\n1 gold badge\n8\n8 silver badges\n29\n29 bronze badges\nanswered Dec 28 '15 at 4:53\n최봉재\n2,0471\n1 gold badge\n13\n13 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"if you cloned your local will automatically consist,\n\nremote URL where it gets cloned.\n\nyou can check it using git remote -v\n\nif you want to made change in it,\n\ngit remote set-url origin https://github.io/my_repo.git\n\n\nhere,\n\norigin - your branch\n\nif you want to overwrite existing branch you can still use it.. it will override your existing ... it will do,\n\ngit remote remove url\nand \ngit remote add origin url\n\n\nfor you...\n\nShare\nImprove this answer\nFollow\nanswered Jul 31 '17 at 7:33\nMohideen bin Mohammed\n14.9k7\n7 gold badges\n87\n87 silver badges\n101\n101 bronze badges","comments":["I had multiple remotes added, so git remote rm origin command was needed for removing all the associated urls. Then the add command worked."]},{"answer":"I worked:\n\ngit remote set-url origin <project>\n\nShare\nImprove this answer\nFollow\nanswered May 6 '18 at 18:24\nDiego Santa Cruz Mendezú\n2,95329\n29 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"To check git remote connection:\n\ngit remote -v\n\n\nNow, set the local repository to remote git:\n\ngit remote set-url origin https://NewRepoLink.git\n\n\nNow to make it upstream or push use following code:\n\ngit push --set-upstream origin master -f\n\nShare\nImprove this answer\nFollow\nedited Dec 18 '18 at 8:08\nanswered Dec 18 '18 at 5:22\nAnupam Maurya\n1,07315\n15 silver badges\n23\n23 bronze badges","comments":["I was pushing and yet github didn't show my new branch. That last --set-upstream made it work."]},{"answer":"Troubleshooting :\n\nYou may encounter these errors when trying to changing a remote. No such remote '[name]'\n\nThis error means that the remote you tried to change doesn't exist:\n\ngit remote set-url sofake https://github.com/octocat/Spoon-Knife fatal: No such remote 'sofake'\n\nCheck that you've correctly typed the remote name.\n\nReference : https://help.github.com/articles/changing-a-remote-s-url/\n\nShare\nImprove this answer\nFollow\nanswered Oct 15 '18 at 6:16\nAmitesh Bharti\n7,7963\n3 gold badges\n42\n42 silver badges\n46\n46 bronze badges","comments":[]},{"answer":"In the Git Bash, enter the command:\n\ngit remote set-url origin https://NewRepoLink.git\n\nEnter the Credentials\n\nDone\n\nShare\nImprove this answer\nFollow\nanswered Apr 25 '17 at 9:48\ndevDeejay\n4,27925\n25 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"You have a lot of ways to do that:\n\nConsole\n\ngit remote set-url origin [Here new url] \n\n\nJust be sure that you've opened it in a place where a repository is.\n\nConfig\n\nIt is placed in .git/config (same folder as repository)\n\n[core]\n    repositoryformatversion = 0\n    filemode = false\n    bare = false\n    logallrefupdates = true\n    symlinks = false\n    ignorecase = true\n[remote \"origin\"]\n    url = [Here new url]  <------------------------------------\n...\n\n\nTortoiseGit\n\nThen just edit URL.\n\nSourceTree\n\nClick on the \"Settings\" button on the toolbar to open the Repository Settings window.\n\nClick \"Add\" to add a remote repository path to the repository. A \"Remote details\" window will open.\n\nEnter a name for the remote path.\n\nEnter the URL/Path for the remote repository\n\nEnter the username for the hosting service for the remote repository.\n\nClick 'OK' to add the remote path.\n\nBack on the Repository Settings window, click 'OK'. The new remote path should be added on the repository now.\n\nIf you need to edit an already added remote path, just click the 'Edit' button. You should be directed to the \"Remote details\" window where you can edit the details (URL/Path/Host Type) of the remote path.\n\nTo remove a remote repository path, click the 'Remove' button\n\nref. Support\n\nShare\nImprove this answer\nFollow\nanswered Apr 2 '19 at 13:37\nPrzemek Struciński\n3,8461\n1 gold badge\n22\n22 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"Change remote git URI to git@github.com rather than https://github.com\n\ngit remote set-url origin git@github.com:<username>/<repo>.git\n\n\nExample:\n\ngit remote set-url origin git@github.com:Chetabahana/my_repo_name.git\n\n\nThe benefit is that you may do git push automatically when you use ssh-agent :\n\n#!/bin/bash\n\n# Check ssh connection\nssh-add -l &>/dev/null\n[[ \"$?\" == 2 ]] && eval `ssh-agent`\nssh-add -l &>/dev/null\n[[ \"$?\" == 1 ]] && expect $HOME/.ssh/agent\n\n# Send git commands to push\ngit add . && git commit -m \"your commit\" && git push -u origin master\n\n\nPut a script file $HOME/.ssh/agent to let it runs ssh-add using expect as below:\n\n#!/usr/bin/expect -f\nset HOME $env(HOME)\nspawn ssh-add $HOME/.ssh/id_rsa\nexpect \"Enter passphrase for $HOME/.ssh/id_rsa:\"\nsend \"<my_passphrase>\\n\";\nexpect \"Identity added: $HOME/.ssh/id_rsa ($HOME/.ssh/id_rsa)\"\ninteract\n\nShare\nImprove this answer\nFollow\nedited Oct 11 '19 at 1:24\nBKSpurgeon\n26.1k11\n11 gold badges\n88\n88 silver badges\n68\n68 bronze badges\nanswered May 25 '19 at 11:54\nChetabahana\n8,0743\n3 gold badges\n53\n53 silver badges\n71\n71 bronze badges","comments":[]},{"answer":"Navigate to the project root of the local repository and check for existing remotes:\n\ngit remote -v\n\n\nIf your repository is using SSH you will see something like:\n\n> origin  git@github.com:USERNAME/REPOSITORY.git (fetch)\n> origin  git@github.com:USERNAME/REPOSITORY.git (push)\n\n\nAnd if your repository is using HTTPS you will see something like:\n\n> origin  https://github.com/USERNAME/REPOSITORY.git (fetch)\n> origin  https://github.com/USERNAME/REPOSITORY.git (push)\n\n\nChanging the URL is done with git remote set-url. Depending on the output of git remote -v, you can change the URL in the following manner:\n\nIn case of SSH, you can change the URL from REPOSITORY.git to NEW_REPOSITORY.git like:\n\n$ git remote set-url origin git@github.com:USERNAME/NEW_REPOSITORY.git\n\n\nAnd in case of HTTPS, you can change the URL from REPOSITORY.git to NEW_REPOSITORY.git like:\n\n$ git remote set-url origin https://github.com/USERNAME/NEW_REPOSITORY.git\n\n\nNOTE: If you've changed your GitHub username, you can follow the same process as above to update the change in the username associated with your repository. You would only have to update the USERNAME in the git remote set-url command.\n\nShare\nImprove this answer\nFollow\nanswered Aug 17 '20 at 20:03\nSaurabh\n1,0911\n1 gold badge\n9\n9 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"To change the remote upstream: git remote set-url origin <url>\n\nTo add more upstreams: git remote add newplace <url>\n\nSo you can choose where to work git push origin <branch> or git push newplace <branch>\n\nShare\nImprove this answer\nFollow\nanswered Feb 28 '20 at 13:43\nAnderson Cossul\n2112\n2 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"If you're using TortoiseGit then follow the below steps:\n\nGo to your local checkout folder and right click to go to TortoiseGit -> Settings\nIn the left pane choose Git -> Remote\nIn the right pane choose origin\nNow change the URL text box value to where ever your new remote repository is\n\nYour branch and all your local commits will remain intact and you can keep working as you were before.\n\nShare\nImprove this answer\nFollow\nedited Sep 13 '17 at 19:11\nDon't Panic\n38k9\n9 gold badges\n55\n55 silver badges\n72\n72 bronze badges\nanswered Aug 20 '17 at 15:14\nVipul bhojwani\n3063\n3 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"You can change the url by editing the config file. Go to your project root:\n\nnano .git/config\n\n\nThen edit the url field and set your new url. Save the changes. You can verify the changes by using the command.\n\ngit remote -v \n\nShare\nImprove this answer\nFollow\nanswered Feb 7 '20 at 4:24\nAbhi Das\n3356\n6 silver badges\n8\n8 bronze badges","comments":[]},{"answer":"An alternative approach is to rename the 'old' origin (in the example below I name it simply old-origin) and adding a new one. This might be the desired approach if you still want to be able to push to the old origin every now and then:\n\ngit remote rename origin old-origin\ngit remote add origin git@new-git-server.com>:<username>/<projectname>.git\n\n\nAnd in case you need to push your local state to the new origin:\n\ngit push -u origin --all\ngit push -u origin --tags\n\nShare\nImprove this answer\nFollow\nedited Sep 20 '20 at 12:34\nanswered Sep 20 '20 at 12:25\njojo\n8,0952\n2 gold badges\n40\n40 silver badges\n65\n65 bronze badges","comments":[]},{"answer":"For me, the accepted answer worked only in the case of fetch but not pull. I did the following to make it work for push as well.\n\ngit remote set-url --push origin new.git.url/here\n\n\nSo to update the fetch URL:\n\ngit remote set-url origin new.git.url/here\n\n\nTo update the pull URL:\n\ngit remote set-url --push origin new.git.url/here\n\nShare\nImprove this answer\nFollow\nanswered May 6 at 11:27\nShailendra Madda\n17.7k15\n15 gold badges\n77\n77 silver badges\n120\n120 bronze badges","comments":[]},{"answer":"Removing a remote\n\nUse the git remote rm command to remove a remote URL from your repository.\n\n    $ git remote -v\n    # View current remotes\n    > origin  https://github.com/OWNER/REPOSITORY.git (fetch)\n    > origin  https://github.com/OWNER/REPOSITORY.git (push)\n    > destination  https://github.com/FORKER/REPOSITORY.git (fetch)\n    > destination  https://github.com/FORKER/REPOSITORY.git (push)\n\n    $ git remote rm destination\n    # Remove remote\n    $ git remote -v\n    # Verify it's gone\n    > origin  https://github.com/OWNER/REPOSITORY.git (fetch)\n    > origin  https://github.com/OWNER/REPOSITORY.git (push)\n\nShare\nImprove this answer\nFollow\nanswered Jun 6 '20 at 11:05\nTayyab Roy\n3062\n2 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"If you would like to set the username and password as well in the origin url, you can follow the below steps.\n\nExporting the password in a variable would avoid issues with special characters.\n\nSteps:\n\nexport gituser='<Username>:<password>@'\ngit remote set-url origin https://${gituser}<gitlab_repo_url> \ngit push origin <Branch Name>\n\nShare\nImprove this answer\nFollow\nanswered Mar 3 at 5:52\nRajesh Somasundaram\n931\n1 silver badge\n9\n9 bronze badges","comments":[]},{"answer":"check your privilege\n\nin my case i need to check my username\n\ni have two or three repository with seperate credentials.\n\nproblem is my permission i have two private git server and repositories\n\nthis second account is admin of that new repo and first one is my default user account and i should grant permission to first\n\nShare\nImprove this answer\nFollow\nedited Mar 19 '20 at 10:25\nanswered Feb 6 '20 at 16:35\nsaber tabatabaee yazdi\n2,3903\n3 gold badges\n30\n30 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"You can rename a repository if you're either an organization owner or have admin permissions for the repository.\n\n git remote set-url origin new_url\n\n\nknow more\n\nShare\nImprove this answer\nFollow\nanswered Jul 27 at 10:26\nMD SHAYON\n3,31822\n22 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"For those who want to make this change from Visual Studio 2019\n\nOpen Team Explorer (Ctrl+M)\n\nHome -> Settings\n\nGit -> Repository Settings\n\nRemotes -> Edit\n\nShare\nImprove this answer\nFollow\nanswered Oct 25 '19 at 17:53\nDinch\n3983\n3 silver badges\n8\n8 bronze badges","comments":[]},{"answer":"If your repository is private then\n\nOpen Control Panel from the Start menu\nSelect User Accounts\nSelect \"Manage your credentials\" in the left hand menu\nDelete any credentials related to Git or GitHub\n\nReference\n\nShare\nImprove this answer\nFollow\nanswered Dec 10 '19 at 5:08\nMike Lee\n1,59017\n17 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"(Only Windows PS) To change a server/protocol recursively in all local repos\nGet-ChildItem -Directory -Recurse -Depth [Number] -Hidden -name | %{$_.replace(\"\\.git\",\"\")} | %{git -C $_ remote set-url origin $(git -C $_ remote get-url origin).replace(\"[OLD SERVER]\", \"[NEW SERVER]\")}\n\nShare\nImprove this answer\nFollow\nanswered May 17 at 10:05\nThomas Brüggemann\n2161\n1 silver badge\n7\n7 bronze badges","comments":[]},{"answer":"If your on linux/Mac with Sed/grep its also pretty easy to change without losing associations.\n\nRecently did this to change my username for all my repos locally in config but done the same approach for remotes lines entirely too.\n\nVARIABLE_FIND='old'; VARIABLE_REPLACE='new'; path_name='~/PycharmProjects/*/.git/'; grep -rl --include=config \"${VARIABLE_FIND}\" \"${path_name}\" | xargs sed -i \"s|${VARIABLE_FIND}|${VARIABLE_REPLACE}|g\"\n\n\nFor replacing whole line where there is a match you can do this.\n\nVARIABLE_FIND='someneedle'; VARIABLE_REPLACE='somenewvalue'; path_name='/home/*/' grep -rl --include=config \"${VARIABLE_FIND}\" \"${path_name}\" | xargs sed -i \"/${VARIABLE_FIND//\\//\\\\/}/c\\\\${VARIABLE_REPLACE}\" ;\n\n\nReference: Replace whole line containing a string using Sed\n\nShare\nImprove this answer\nFollow\nanswered Jul 6 at 13:07\nMik R\n14110\n10 bronze badges","comments":[]}]},{"id":"114543","href":"https://stackoverflow.com/questions/114543/how-to-horizontally-center-an-element","title":"How to horizontally center an element","description":"\n                \nHow can I horizontally center a <div> within another <div> using CSS?\n<div id=\"outer\">\n  <div id=\"inner\">Foo foo</div>\n</div>\n\n\n    ","questionComments":["Of those great answers, I just want to highlight that you must give \"#inner\" a \"width\", or it will be \"100%\", and you can't tell if it's already centered."],"answers":[{"answer":"You can apply this CSS to the inner <div>:\n\n#inner {\n  width: 50%;\n  margin: 0 auto;\n}\n\n\nOf course, you don't have to set the width to 50%. Any width less than the containing <div> will work. The margin: 0 auto is what does the actual centering.\n\nIf you are targeting Internet Explorer 8 (and later), it might be better to have this instead:\n\n#inner {\n  display: table;\n  margin: 0 auto;\n}\n\n\nIt will make the inner element center horizontally and it works without setting a specific width.\n\nWorking example here:\n\n#inner {\n  display: table;\n  margin: 0 auto;\n  border: 1px solid black;\n}\n\n#outer {\n  border: 1px solid red;\n  width:100%\n}\n<div id=\"outer\">\n  <div id=\"inner\">Foo foo</div>\n</div>\n Run code snippetExpand snippet\n\nEDIT\n\nWith flexbox it is very easy to style the div horizontally and vertically centered.\n\n#inner {  \n  border: 1px solid black;\n}\n\n#outer {\n  border: 1px solid red;\n  width:100%;\n  display: flex;\n  justify-content: center;\n}\n<div id=\"outer\">\n  <div id=\"inner\">Foo foo</div>\n</div>\n Run code snippetExpand snippet\n\nTo align the div vertically centered, use the property align-items: center.\n\nShare\nImprove this answer\nFollow\nedited Jan 23 at 6:05\ncommunity wiki\n\n\n16 revs, 12 users 22%\nAhmerMH","comments":["For the vertical centering I usually use \"line-height\" (line-height == height). This is simple and nice but it's only working with a one line content text :)","You have to use the !DOCTYPE tag on your html page to make it work well on IE.","Note that it may be necessary to add \"float:none;\" for the #inner.","You also set the top and bottom margins to 0, which is unrelated. Better putting margin-left: auto; margin-right: auto I think.","Not necessarily margin:0 auto: it can be margin: <whatever_vertical_margin_you_need> auto second being the horizontal margin."]},{"answer":"If you don't want to set a fixed width on the inner div you could do something like this:\n\n#outer {\n  width: 100%;\n  text-align: center;\n}\n\n#inner {\n  display: inline-block;\n}\n<div id=\"outer\">  \n    <div id=\"inner\">Foo foo</div>\n</div>\n Run code snippetExpand snippet\n\nThat makes the inner div into an inline element that can be centered with text-align.\n\nShare\nImprove this answer\nFollow\nedited Nov 22 '17 at 11:34\ncommunity wiki\n\n\n5 revs, 4 users 62%\nAlfred","comments":["@SabaAhang the correct syntax for that would be float: none; and is probably only needed because #inner has inherited a float of either left or right from somewhere else in your CSS.","This is a nice solution. Just keep in mind that inner will inherit text-align so you may want to set inner's text-align to initial or some other value.","but isn't the question related to centering a div entirely and not just the text? can text-align be used to center align divs? or is it just for text?"]},{"answer":"The best approaches are with CSS 3.\n\nBox model:\n\n#outer {\n  width: 100%;\n  /* Firefox */\n  display: -moz-box;\n  -moz-box-pack: center;\n  -moz-box-align: center;\n  /* Safari and Chrome */\n  display: -webkit-box;\n  -webkit-box-pack: center;\n  -webkit-box-align: center;\n  /* W3C */\n  display: box;\n  box-pack: center;\n  box-align: center;\n}\n\n#inner {\n  width: 50%;\n}\n<div id=\"outer\">\n  <div id=\"inner\">Foo foo</div>\n</div>\n Run code snippetExpand snippet\n\nAccording to your usability you may also use the box-orient, box-flex, box-direction properties.\n\nFlex:\n\n#outer {\n    display: flex;\n    flex-direction: row;\n    flex-wrap: wrap;\n    justify-content: center;\n    align-items: center;\n}\n\nRead more about centering the child elements\n\nLink 2\n\nLink 3\n\nLink 4\n\nAnd this explains why the box model is the best approach:\n\nWhy is the W3C box model considered better?\nShare\nImprove this answer\nFollow\nedited May 15 '19 at 13:38\ncommunity wiki\n\n\n13 revs, 9 users 50%\nKonga Raju","comments":["Make sure you read this answer first before you go about implementing this solution.","Safari, as of now, still requires -webkit flags for flexbox (display: -webkit-flex; and -webkit-align-items: center; and -webkit-justify-content: center;)","I always think that use lots code is bad practice for example with this code I center my div: display: table; margin: auto; simple and easy"]},{"answer":"Suppose that your div is 200 pixels wide:\n\n.centered {\n  position: absolute;\n  left: 50%;\n  margin-left: -100px;\n}\n\n\nMake sure the parent element is positioned, i.e., relative, fixed, absolute, or sticky.\n\nIf you don't know the width of your div, you can use transform:translateX(-50%); instead of the negative margin.\n\nhttps://jsfiddle.net/gjvfxxdj/\n\nWith CSS calc(), the code can get even simpler:\n\n\n\n\n.centered {\n  width: 200px;\n  position: absolute;\n  left: calc(50% - 100px);\n}\n\n\nThe principle is still the same; put the item in the middle and compensate for the width.\n\nShare\nImprove this answer\nFollow\nedited May 9 '20 at 14:01\ncommunity wiki\n\n\n9 revs, 9 users 29%\nnuno_cruz","comments":["I don't like this solution because when the inner element is too broad for the screen, you can't scroll over the whole element horizontally. margin: 0 auto works better.","margin-left: auto; margin-right: auto; centres a block level element","The default width for most block level elements is auto, which fills the available area on screen. Just being centered places it in the same position as left alignment. If you wish it to be visually centered you should set a width (or a max-width although Internet Explorer 6 and earlier do not support this, and IE 7 only supports it in standards mode)."]},{"answer":"I've created this example to show how to vertically and horizontally align.\n\nThe code is basically this:\n\n#outer {\n position: relative;\n}\n\n\nand...\n\n#inner {\n  margin: auto;\n  position: absolute;\n  left:0;\n  right: 0;\n  top: 0;\n  bottom: 0;\n}\n\n\nAnd it will stay in the center even when you resize your screen.\n\nShare\nImprove this answer\nFollow\nedited yesterday\ncommunity wiki\n\n\n7 revs, 6 users 38%\nTom Maton","comments":["+1 for this method, I was about to answer with it. Note that you must declare a width on the element you wish to center horizontally (or height if centering vertically). Here's a comprehensive explanation: codepen.io/shshaw/full/gEiDt. One of the more versatile and widely-supported methods of centering elements vertically and/or horizontally.","You cannot use padding within the div, but if you want to give the illusion use a border of the same color.","I think for this method to work, you need to set the with and height of inner div"]},{"answer":"Some posters have mentioned the CSS 3 way to center using display:box.\n\nThis syntax is outdated and shouldn't be used anymore. [See also this post].\n\nSo just for completeness here is the latest way to center in CSS 3 using the Flexible Box Layout Module.\n\nSo if you have simple markup like:\n\n<div class=\"box\">\n  <div class=\"item1\">A</div>\n  <div class=\"item2\">B</div>\n  <div class=\"item3\">C</div>\n</div>\n\n\n...and you want to center your items within the box, here's what you need on the parent element (.box):\n\n.box {\n    display: flex;\n    flex-wrap: wrap; /* Optional. only if you want the items to wrap */\n    justify-content: center; /* For horizontal alignment */\n    align-items: center; /* For vertical alignment */\n}\n\n\nShow code snippet\n\nIf you need to support older browsers which use older syntax for flexbox here's a good place to look.\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '18 at 20:14\ncommunity wiki\n\n\n8 revs, 4 users 86%\nDanield","comments":["what do you mean by \"syntax is outdated\", is it deprecated?","The Flexbox specification has gone through 3 major revisions. The most recent draft is from Sept 2012, which officially deprecates all previous drafts. However, browser support is spotty (particularly old Android browsers): stackoverflow.com/questions/15662578/…","This worked for me in Chrome when Justin Poliey's version didn't.","Isn't the \"justify-content: center;\" for the vertical alignment and the \"align-items: center;\" for the horizontal alignment?","@WouterVanherck it depends on the flex-direction value. If it is 'row' (the default) - then justify-content: center;  is for the horizontal alignment (like I mentioned in the answer) If it is 'column' - then justify-content: center; is for the vertical alignment."]},{"answer":"If you don't want to set a fixed width and don't want the extra margin, add display: inline-block to your element.\n\nYou can use:\n\n#element {\n    display: table;\n    margin: 0 auto;\n}\n\nShare\nImprove this answer\nFollow\nedited Oct 29 '13 at 17:23\ncommunity wiki\n\n\nSalman von Abbas","comments":["same requirements as display:inline-block too (quirksmode.org/css/display.html)","I used this, too, but I've never encountered display: table; before. What does it do?"]},{"answer":"Centering a div of unknown height and width\n\nHorizontally and vertically. It works with reasonably modern browsers (Firefox, Safari/WebKit, Chrome, Internet & Explorer & 10, Opera, etc.)\n\n.content {\n  position: absolute;\n  left: 50%;\n  top: 50%;\n  transform: translate(-50%, -50%);\n}\n<div class=\"content\">This works with any content</div>\n Run code snippetExpand snippet\n\nTinker with it further on Codepen or on JSBin.\n\nShare\nImprove this answer\nFollow\nedited Feb 25 at 3:07\ncommunity wiki\n\n\n8 revs, 5 users 67%\niamnotsam","comments":["This is the only one that works for perfect centering and will remain centered even after the contents in the div are modified.","It's a nice trick, but there is a little caveat. If the element has inline content that's wider than 50% of the parent's width, then the extra 50% offset from the left will extrapolate the parent's width, breaking the content to the next lines to avoid overflow. But it's possible to keep the content inline by setting in the centered element the white-space attribute to nowrap. Try that in this JSFiddle."]},{"answer":"Set the width and set margin-left and margin-right to auto. That's for horizontal only, though. If you want both ways, you'd just do it both ways. Don't be afraid to experiment; it's not like you'll break anything.\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '18 at 19:11\ncommunity wiki\n\n\n4 revs, 4 users 33%\nSneakyness","comments":[]},{"answer":"It cannot be centered if you don't give it a width. Otherwise, it will take, by default, the whole horizontal space.\n\nShare\nImprove this answer\nFollow\nedited May 8 '20 at 17:02\ncommunity wiki\n\n\n6 revs, 6 users 25%\ngizmo","comments":["and if you don't know the width? Say because the content is dynamic?","max-width? what about that?","I use width: fit-content; and margin: 0 auto. I think this can work with unknown width."]},{"answer":"CSS 3's box-align property\n\n#outer {\n    width: 100%;\n    height: 100%;\n    display: box;\n    box-orient: horizontal;\n    box-pack: center;\n    box-align: center;\n}\n\nShare\nImprove this answer\nFollow\nedited May 9 '20 at 14:13\ncommunity wiki\n\n\n3 revs, 3 users 63%\nneoneye","comments":["Make sure you read this answer first before you go about implementing this solution."]},{"answer":"I recently had to center a \"hidden\" div (i.e., display:none;) that had a tabled form within it that needed to be centered on the page. I wrote the following jQuery code to display the hidden div and then update the CSS content to the automatic generated width of the table and change the margin to center it. (The display toggle is triggered by clicking on a link, but this code wasn't necessary to display.)\n\nNOTE: I'm sharing this code, because Google brought me to this Stack Overflow solution and everything would have worked except that hidden elements don't have any width and can't be resized/centered until after they are displayed.\n\n$(function(){\n  $('#inner').show().width($('#innerTable').width()).css('margin','0 auto');\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div id=\"inner\" style=\"display:none;\">\n  <form action=\"\">\n    <table id=\"innerTable\">\n      <tr><td>Name:</td><td><input type=\"text\"></td></tr>\n      <tr><td>Email:</td><td><input type=\"text\"></td></tr>\n      <tr><td>Email:</td><td><input type=\"submit\"></td></tr>\n    </table>\n  </form>\n</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited May 9 '20 at 13:51\ncommunity wiki\n\n\n4 revs, 4 users 60%\nJames Moberg","comments":[]},{"answer":"The way I usually do it is using absolute position:\n\n#inner{\n  left: 0;\n  right: 0;\n  margin-left: auto;\n  margin-right: auto;\n  position: absolute;\n}\n\n\nThe outer div doesn't need any extra properties for this to work.\n\nShare\nImprove this answer\nFollow\nedited yesterday\ncommunity wiki\n\n\n4 revs, 3 users 66%\nwilliam44isme","comments":["This may not work if you have other divs below the centered div."]},{"answer":"For Firefox and Chrome:\n\n<div style=\"width:100%;\">\n  <div style=\"width: 50%; margin: 0px auto;\">Text</div>\n</div>\n Run code snippetExpand snippet\n\nFor Internet Explorer, Firefox, and Chrome:\n\n<div style=\"width:100%; text-align:center;\">\n  <div style=\"width: 50%; margin: 0px auto; text-align:left;\">Text</div>\n</div>\n Run code snippetExpand snippet\n\nThe text-align: property is optional for modern browsers, but it is necessary in Internet Explorer Quirks Mode for legacy browsers support.\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '18 at 19:13\ncommunity wiki\n\n\n7 revs, 7 users 47%\nch2o","comments":["There is no need for text-align property. It's completely un-necessary.","text-align is actually necessary for it to work in IE quicks mode, so if you don't mind adding a little expression to support older browsers keep it there. (IE8 with IE8 rules and IE7 rules both work without text-align, so may be it's only IE6 and older that are concerned)"]},{"answer":"Use:\n\n#outerDiv {\n  width: 500px;\n}\n\n#innerDiv {\n  width: 200px;\n  margin: 0 auto;\n}\n<div id=\"outerDiv\">\n  <div id=\"innerDiv\">Inner Content</div>\n</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited May 11 '20 at 19:25\ncommunity wiki\n\n\n5 revs, 5 users 39%\nAnkit Jain","comments":[]},{"answer":"Another solution for this without having to set a width for one of the elements is using the CSS 3 transform attribute.\n\n#outer {\n  position: relative;\n}\n\n#inner {\n  position: absolute;\n  left: 50%;\n\n  transform: translateX(-50%);\n}\n\n\nThe trick is that translateX(-50%) sets the #inner element 50 percent to the left of its own width. You can use the same trick for vertical alignment.\n\nHere's a Fiddle showing horizontal and vertical alignment.\n\nMore information is on Mozilla Developer Network.\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '18 at 19:08\ncommunity wiki\n\n\n2 revs, 2 users 89%\nKilian Stinson","comments":["One may need vendor prefixes as well : -webkit-transform: translate(-50%,0); \t-moz-transform: translate(-50%,0); \t-ms-transform: translate(-50%,0); \t-khtml-transform: translate(-50%,0); \t-o-transform: translate(-50%,0);"]},{"answer":"Chris Coyier who wrote an excellent post on 'Centering in the Unknown' on his blog. It's a roundup of multiple solutions. I posted one that isn't posted in this question. It has more browser support than the Flexbox solution, and you're not using display: table; which could break other things.\n\n/* This parent can be any width and height */\n.outer {\n  text-align: center;\n}\n\n/* The ghost, nudged to maintain perfect centering */\n.outer:before {\n  content: '.';\n  display: inline-block;\n  height: 100%;\n  vertical-align: middle;\n  width: 0;\n  overflow: hidden;\n}\n\n/* The element to be centered, can\n   also be of any width and height */\n.inner {\n  display: inline-block;\n  vertical-align: middle;\n  width: 300px;\n}\n\nShare\nImprove this answer\nFollow\nedited May 11 '20 at 20:11\ncommunity wiki\n\n\n4 revs, 4 users 78%\nWillem de Wit","comments":[]},{"answer":"I recently found an approach:\n\n#outer {\n    position: absolute;\n    left: 50%;\n}\n\n#inner {\n    position: relative;\n    left: -50%;\n}\n\n\nBoth elements must be the same width to function correctly.\n\nShare\nImprove this answer\nFollow\nedited May 11 '20 at 19:23\ncommunity wiki\n\n\n4 revs, 2 users 85%\nBenjaminRH","comments":["Just set this rule for #inner only: #inner { position:relative; left:50%; transform:translateX(-50%); }. This works for any width."]},{"answer":"For example, see this link and the snippet below:\n\ndiv#outer {\n  height: 120px;\n  background-color: red;\n}\n\ndiv#inner {\n  width: 50%;\n  height: 100%;\n  background-color: green;\n  margin: 0 auto;\n  text-align: center; /* For text alignment to center horizontally. */\n  line-height: 120px; /* For text alignment to center vertically. */\n}\n<div id=\"outer\" style=\"width:100%;\">\n  <div id=\"inner\">Foo foo</div>\n</div>\n Run code snippetExpand snippet\n\nIf you have a lot of children under a parent, so your CSS content must be like this example on fiddle.\n\nThe HTML content look likes this:\n\n<div id=\"outer\" style=\"width:100%;\">\n    <div class=\"inner\"> Foo Text </div>\n    <div class=\"inner\"> Foo Text </div>\n    <div class=\"inner\"> Foo Text </div>\n    <div class=\"inner\"> </div>\n    <div class=\"inner\"> </div>\n    <div class=\"inner\"> </div>\n    <div class=\"inner\"> </div>\n    <div class=\"inner\"> </div>\n    <div class=\"inner\"> Foo Text </div>\n</div>\n\n\nThen see this example on fiddle.\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '18 at 18:44\ncommunity wiki\n\n\n4 revs, 3 users 63%\nLalit Kumar","comments":[]},{"answer":"Centering only horizontally\n\nIn my experience, the best way to center a box horizontally is to apply the following properties:\n\nThe container:\nshould have text-align: center;\nThe content box:\nshould have display: inline-block;\nDemo:\n\n.container {\n  width: 100%;\n  height: 120px;\n  background: #CCC;\n  text-align: center;\n}\n\n.centered-content {\n  display: inline-block;\n  background: #FFF;\n  padding: 20px;\n  border: 1px solid #000;\n}\n<div class=\"container\">\n  <div class=\"centered-content\">\n    Center this!\n  </div>\n</div>\n Run code snippetExpand snippet\n\nSee also this Fiddle!\n\nCentering both horizontally & vertically\n\nIn my experience, the best way to center a box both vertically and horizontally is to use an additional container and apply the following properties:\n\nThe outer container:\nshould have display: table;\nThe inner container:\nshould have display: table-cell;\nshould have vertical-align: middle;\nshould have text-align: center;\nThe content box:\nshould have display: inline-block;\nDemo:\n\n.outer-container {\n  display: table;\n  width: 100%;\n  height: 120px;\n  background: #CCC;\n}\n\n.inner-container {\n  display: table-cell;\n  vertical-align: middle;\n  text-align: center;\n}\n\n.centered-content {\n  display: inline-block;\n  background: #FFF;\n  padding: 20px;\n  border: 1px solid #000;\n}\n<div class=\"outer-container\">\n  <div class=\"inner-container\">\n    <div class=\"centered-content\">\n      Center this!\n    </div>\n  </div>\n</div>\n Run code snippetExpand snippet\n\nSee also this Fiddle!\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\n4 revs, 4 users 75%\nJohn Slegers","comments":[]},{"answer":"Flexbox\n\ndisplay: flex behaves like a block element and lays out its content according to the flexbox model. It works with justify-content: center.\n\nPlease note: Flexbox is compatible all browsers exept Internet Explorer. See display: flex not working on Internet Explorer for a complete and up to date list of browsers compatibility.\n\nShow code snippet\n\nText-align: center\n\nApplying text-align: center the inline contents are centered within the line box. However since the inner div has by default width: 100% you have to set a specific width or use one of the following:\n\ndisplay: block\ndisplay: inline\ndisplay: inline-block\n\nShow code snippet\n\nMargin: 0 auto\n\nUsing margin: 0 auto is another option and it is more suitable for older browsers compatibility. It works together with display: table.\n\nShow code snippet\n\nTransform\n\ntransform: translate lets you modify the coordinate space of the CSS visual formatting model. Using it, elements can be translated, rotated, scaled, and skewed. To center horizontally it require position: absolute and left: 50%.\n\nShow code snippet\n\n<center> (Deprecated)\n\nThe tag <center> is the HTML alternative to text-align: center. It works on older browsers and most of the new ones but it is not considered a good practice since this feature is obsolete and has been removed from the Web standards.\n\nShow code snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 14 at 5:22\nanswered Jun 9 '17 at 8:34\nPaolo Forgia\n5,9547\n7 gold badges\n39\n39 silver badges\n55\n55 bronze badges","comments":[]},{"answer":"The easiest way:\n\n#outer {\n  width: 100%;\n  text-align: center;\n}\n#inner {\n  margin: auto;\n  width: 200px;\n}\n<div id=\"outer\">\n  <div id=\"inner\">Blabla</div>\n</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '18 at 18:51\ncommunity wiki\n\n\n4 revs, 3 users 57%\njoan16v","comments":["As your fiddle notes, #inner has to have a width set on it.","#outer doesn't need any width:100%; as the <div> by default always has width:100%. and text-align:center is also not a necessary at all."]},{"answer":"If width of the content is unknown you can use the following method. Suppose we have these two elements:\n\n.outer -- full width\n.inner -- no width set (but a max-width could be specified)\n\nSuppose the computed width of the elements are 1000 pixels and 300 pixels respectively. Proceed as follows:\n\nWrap .inner inside .center-helper\nMake .center-helper an inline block; it becomes the same size as .inner making it 300 pixels wide.\nPush .center-helper 50% right relative to its parent; this places its left at 500 pixels wrt. outer.\nPush .inner 50% left relative to its parent; this places its left at -150 pixels wrt. center helper which means its left is at 500 - 150 = 350 pixels wrt. outer.\nSet overflow on .outer to hidden to prevent horizontal scrollbar.\n\nDemo:\n\nbody {\n  font: medium sans-serif;\n}\n\n.outer {\n  overflow: hidden;\n  background-color: papayawhip;\n}\n\n.center-helper {\n  display: inline-block;\n  position: relative;\n  left: 50%;\n  background-color: burlywood;\n}\n\n.inner {\n  display: inline-block;\n  position: relative;\n  left: -50%;\n  background-color: wheat;\n}\n<div class=\"outer\">\n  <div class=\"center-helper\">\n    <div class=\"inner\">\n      <h1>A div with no defined width</h1>\n      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit.<br>\n          Duis condimentum sem non turpis consectetur blandit.<br>\n          Donec dictum risus id orci ornare tempor.<br>\n          Proin pharetra augue a lorem elementum molestie.<br>\n          Nunc nec justo sit amet nisi tempor viverra sit amet a ipsum.</p>\n    </div>\n  </div>\n</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited May 11 '20 at 20:18\ncommunity wiki\n\n\n5 revs, 2 users 79%\nSalman A","comments":[]},{"answer":"You can do something like this\n\n#container {\n   display: table;\n   width: <width of your container>;\n   height: <height of your container>;\n}\n\n#inner {\n   width: <width of your center div>;\n   display: table-cell;\n   margin: 0 auto;\n   text-align: center;\n   vertical-align: middle;\n}\n\n\nThis will also align the #inner vertically. If you don't want to, remove the display and vertical-align properties;\n\nShare\nImprove this answer\nFollow\nedited Oct 16 '13 at 17:08\ncommunity wiki\n\n\nKenneth Palaganas","comments":[]},{"answer":"Flex have more than 97% browser support coverage and might be the best way to solve these kind of problems within few lines:\n\n#outer {\n  display: flex;\n  justify-content: center;\n}\n\nShare\nImprove this answer\nFollow\nedited yesterday\ncommunity wiki\n\n\n3 revs, 3 users 56%\nSandesh Damkondwar","comments":[]},{"answer":"Here is what you want in the shortest way.\n\nJSFIDDLE\n\n#outer {\n  margin - top: 100 px;\n  height: 500 px; /* you can set whatever you want */\n  border: 1 px solid# ccc;\n}\n\n#inner {\n  border: 1 px solid# f00;\n  position: relative;\n  top: 50 % ;\n  transform: translateY(-50 % );\n}\n\nShare\nImprove this answer\nFollow\nedited yesterday\ncommunity wiki\n\n\n3 revs, 3 users 55%\ncaniz","comments":["That centers it vertically."]},{"answer":"You can use display: flex for your outer div and to horizontally center you have to add justify-content: center\n\n#outer{\n    display: flex;\n    justify-content: center;\n}\n\n\nor you can visit w3schools - CSS flex Property for more ideas.\n\nShare\nImprove this answer\nFollow\nedited Aug 20 '18 at 12:57\ncommunity wiki\n\n\n2 revs, 2 users 75%\nMilan Panigrahi","comments":[]},{"answer":"This method also works just fine:\n\ndiv.container {\n  display: flex;\n  justify-content: center; /* For horizontal alignment */\n  align-items: center;     /* For vertical alignment   */\n}\n\n\nFor the inner <div>, the only condition is that its height and width must not be larger than the ones of its container.\n\nShare\nImprove this answer\nFollow\nedited yesterday\ncommunity wiki\n\n\n3 revs, 3 users 55%\nBillal Begueradj","comments":["in regards to edit records this person answered first on the page. Upvoting."]},{"answer":"Well, I managed to find a solution that maybe will fit all situations, but uses JavaScript:\n\nHere's the structure:\n\n<div class=\"container\">\n  <div class=\"content\">Your content goes here!</div>\n  <div class=\"content\">Your content goes here!</div>\n  <div class=\"content\">Your content goes here!</div>\n</div>\n\n\nAnd here's the JavaScript snippet:\n\n$(document).ready(function() {\n  $('.container .content').each( function() {\n    container = $(this).closest('.container');\n    content = $(this);\n\n    containerHeight = container.height();\n    contentHeight = content.height();\n\n    margin = (containerHeight - contentHeight) / 2;\n    content.css('margin-top', margin);\n  })\n});\n\n\nIf you want to use it in a responsive approach, you can add the following:\n\n$(window).resize(function() {\n  $('.container .content').each( function() {\n    container = $(this).closest('.container');\n    content = $(this);\n\n    containerHeight = container.height();\n    contentHeight = content.height();\n\n    margin = (containerHeight - contentHeight) / 2;\n    content.css('margin-top', margin);\n  })\n});\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '18 at 18:47\ncommunity wiki\n\n\n2 revs, 2 users 91%\nMiguel Leite","comments":[]},{"answer":"One option existed that I found:\n\nEverybody says to use:\n\nmargin: auto 0;\n\n\nBut there is another option. Set this property for the parent div. It works perfectly anytime:\n\ntext-align: center;\n\n\nAnd see, child go center.\n\nAnd finally CSS for you:\n\n#outer{\n     text-align: center;\n     display: block; /* Or inline-block - base on your need */\n}\n\n#inner\n{\n     position: relative;\n     margin: 0 auto; /* It is good to be */\n}\n\nShare\nImprove this answer\nFollow\nedited Mar 17 '18 at 18:38\ncommunity wiki\n\n\n3 revs, 2 users 73%\nPnsadeghy","comments":["text-align work for text alignment in its container not for its container to its parent.","i test it , i problem with set child to center , must when you have more one child , more times margin:0 auto font answer , but , text-align center , for parent make this child be center , even if they are element and not be text , test and see what happen","text-align center text only. You right at this time but when you write a container css which contains a child with different width and color your code does't work. Test it again!!!!","See this example jsfiddle.net/uCdPK/2 and tell me what do you think about it!!!!!","this works great. no need for a #inner ."]}]},{"id":"105034","href":"https://stackoverflow.com/questions/105034/how-to-create-a-guid-uuid","title":"How to create a GUID / UUID","description":"\n                \nI'm trying to create globally-unique identifiers in JavaScript.  I'm not sure what routines are available on all browsers, how \"random\" and seeded the built-in random number generator is, etc.\nThe GUID / UUID should be at least 32 characters and should stay in the ASCII range to avoid trouble when passing them around.\n    ","questionComments":["GUIDs when repesented as as strings are at least 36 and no more than 38 characters in length and match the pattern ^\\{?[a-zA-Z0-9]{36}?\\}$ and hence are always ascii.","David Bau provides a much better, seedable random number generator at davidbau.com/archives/2010/01/30/… I wrote up a slightly different approach to generating UUIDs at blogs.cozi.com/tech/2010/04/generating-uuids-in-javascript.html","Weird that no one has mentioned this yet but for completeness, there's a plethora of guid generators on npm I'm willing to bet most of them work in browser too.","If anyone wants more options like different versions of the uuid and non standard guid support, REST based uuid generation services like these [fungenerators.com/api/uuid ] are an attractive option too.","Some 12 years later with BigInt and ES6 classes, other techniques that yield rates of 500,000 uuid/sec can be done. See reference"],"answers":[{"answer":"UUIDs (Universally Unique IDentifier), also known as GUIDs (Globally Unique IDentifier), according to RFC 4122, are identifiers designed to provide certain uniqueness guarantees.\n\nWhile it is possible to implement RFC-compliant UUIDs in a few lines of JavaScript code (e.g., see @broofa's answer, below) there are several common pitfalls:\n\nInvalid id format (UUIDs must be of the form \"xxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx\", where x is one of [0-9, a-f] M is one of [1-5], and N is [8, 9, a, or b]\nUse of a low-quality source of randomness (such as Math.random)\n\nThus, developers writing code for production environments are encouraged to use a rigorous, well-maintained implementation such as the uuid module.\n\nShare\nImprove this answer\nFollow\nedited Dec 21 '20 at 5:33\ncommunity wiki\n\n\n25 revs, 18 users 18%\nbroofa","comments":["Actually, the RFC allows for UUIDs that are created from random numbers. You just have to twiddle a couple of bits to identify it as such. See section 4.4. Algorithms for Creating a UUID from Truly Random or Pseudo-Random Numbers: rfc-archive.org/getrfc.php?rfc=4122","This should not be the accepted answer. It does not actually answer the question - instead encouraging the import of 25,000 lines of code for something you can do with one line of code in any modern browser.","@AbhiBeckert the answer is from 2008 and for node.js projects it might be valid to choose a dependency more over project size","@Phil this is a \"highly active question\", which means it should have an excellent answer with a green tick. Unfortunately that's not the case. There is nothing wrong or incorrect with this answer (if there was, I'd edit the answer) - but another far better answer exists below and I think it should be at the top of the list. Also the question is specifically relating to javascript in a browser, not node.js.","I challenge the claim that Math.random is that low of a quality of randomness. v8.dev/blog/math-random. As you can see, it's passes a good test suite, and the same algorithm is used by v8, FF and Safari. And the RFC states, pseudo-random numbers are acceptable for UUIDs"]},{"answer":"For an RFC4122 version 4 compliant solution, this one-liner(ish) solution is the most compact I could come up with:\n\nfunction uuidv4() {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n    var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);\n    return v.toString(16);\n  });\n}\n\nconsole.log(uuidv4());\n Run code snippetExpand snippet\n\nUpdate, 2015-06-02: Be aware that UUID uniqueness relies heavily on the underlying random number generator (RNG). The solution above uses Math.random() for brevity, however Math.random() is not guaranteed to be a high-quality RNG. See Adam Hyland's excellent writeup on Math.random() for details. For a more robust solution, consider using the uuid module, which uses higher quality RNG APIs.\n\nUpdate, 2015-08-26: As a side-note, this gist describes how to determine how many IDs can be generated before reaching a certain probability of collision. For example, with 3.26x1015 version 4 RFC4122 UUIDs you have a 1-in-a-million chance of collision.\n\nUpdate, 2017-06-28: A good article from Chrome developers discussing the state of Math.random PRNG quality in Chrome, Firefox, and Safari. tl;dr - As of late-2015 it's \"pretty good\", but not cryptographic quality. To address that issue, here's an updated version of the above solution that uses ES6, the crypto API, and a bit of JavaScript wizardry I can't take credit for:\n\nfunction uuidv4() {\n  return ([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g, c =>\n    (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16)\n  );\n}\n\nconsole.log(uuidv4());\n Run code snippetExpand snippet\n\nUpdate, 2020-01-06: There is a proposal in the works for a standard uuid module as part of the JavaScript language\n\nShare\nImprove this answer\nFollow\nedited May 29 at 4:14\ncommunity wiki\n\n\n24 revs, 14 users 48%\nbroofa","comments":["Surely the answer to @Muxa's question is 'no'? It's never truly safe to trust something that came from the client. I guess it depends on how likely your users are to bring up a javascript console and manually change the variable so to something they want. Or they could just POST you back the id that they want. It would also depend on whether the user picking their own ID is going to cause vulnerabilities. Either way, if it's a random number ID that's going into a table, I would probably be generating it server-side, so that I know I have control over the process.","@DrewNoakes - UUIDs aren't just a string of completely random #'s. The \"4\" is the uuid version (4 = \"random\"). The \"y\" marks where the uuid variant (field layout, basically) needs to be embedded. See sections 4.1.1 and 4.1.3 of ietf.org/rfc/rfc4122.txt for more info.","I know you've added a lot of caveats in your post, but you're better off just striking out the first answer now, a lot of noobs will just come to this answer and copy the first thing they see without reading the rest. In reality you can't reliably generate UUIDs from the Math.random API and it would be dangerous to rely on that.","Instead of the \"updates\" sections (that is what the revision history is for), it would be better if this answer is as if it was written today.","If you really want to keep the versioning inline, and not behind revision history, you have to reverse the order : keep the most up to date answer as first."]},{"answer":"I really like how clean Broofa's answer is, but it's unfortunate that poor implementations of Math.random leave the chance for collision.\n\nHere's a similar RFC4122 version 4 compliant solution that solves that issue by offsetting the first 13 hex numbers by a hex portion of the timestamp, and once depleted offsets by a hex portion of the microseconds since pageload. That way, even if Math.random is on the same seed, both clients would have to generate the UUID the exact same number of microseconds since pageload (if high-perfomance time is supported) AND at the exact same millisecond (or 10,000+ years later) to get the same UUID:\n\nfunction generateUUID() { // Public Domain/MIT\n    var d = new Date().getTime();//Timestamp\n    var d2 = (performance && performance.now && (performance.now()*1000)) || 0;//Time in microseconds since page-load or 0 if unsupported\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n        var r = Math.random() * 16;//random number between 0 and 16\n        if(d > 0){//Use timestamp until depleted\n            r = (d + r)%16 | 0;\n            d = Math.floor(d/16);\n        } else {//Use microseconds since page-load if supported\n            r = (d2 + r)%16 | 0;\n            d2 = Math.floor(d2/16);\n        }\n        return (c === 'x' ? r : (r & 0x3 | 0x8)).toString(16);\n    });\n}\n\nvar onClick = function(){\n    document.getElementById('uuid').textContent = generateUUID();\n}\nonClick();\n#uuid { font-family: monospace; font-size: 1.5em; }\n<p id=\"uuid\"></p>\n<button id=\"generateUUID\" onclick=\"onClick();\">Generate UUID</button>\n Run code snippetExpand snippet\n\nHere's a fiddle to test.\n\nModernized snippet for ES6\n\nShow code snippet\n\nShare\nImprove this answer\nFollow\nedited May 29 at 4:33\ncommunity wiki\n\n\n26 revs, 13 users 66%\nBriguy37","comments":["Bear in mind, new Date().getTime() is not updated every millisecond. I'm not sure how this affects the expected randomness of your algorithm.","performance.now would be even better. Unlike Date.now, the timestamps returned by performance.now() are not limited to one-millisecond resolution. Instead, they represent times as floating-point numbers with up to microsecond precision. Also unlike Date.now, the values returned by performance.now() always increase at a constant rate, independent of the system clock which might be adjusted manually or skewed by software such as the Network Time Protocol.","The actual time resolution may or may not be 17 ms (1/60 second), not 1 ms.","Would Crypto.getRandomValues fix the main problems with Math.random??","Note: Zak had made an update to add the following. const { performance } = require('perf_hooks'); to define the performance variable. Thus for node.js strict implementations this may be needed. However, this has been removed from the answer because it broke the snippet and will not work with JavaScript used in most other environments, e.g. in browsers."]},{"answer":"broofa's answer is pretty slick, indeed - impressively clever, really... RFC4122 compliant, somewhat readable, and compact. Awesome!\n\nBut if you're looking at that regular expression, those many replace() callbacks, toString()'s and Math.random() function calls (where he's only using four bits of the result and wasting the rest), you may start to wonder about performance. Indeed, joelpt even decided to toss out an RFC for generic GUID speed with generateQuickGUID.\n\nBut, can we get speed and RFC compliance? I say, YES! Can we maintain readability? Well... Not really, but it's easy if you follow along.\n\nBut first, my results, compared to broofa, guid (the accepted answer), and the non-rfc-compliant generateQuickGuid:\n\n                  Desktop   Android\n           broofa: 1617ms   12869ms\n               e1:  636ms    5778ms\n               e2:  606ms    4754ms\n               e3:  364ms    3003ms\n               e4:  329ms    2015ms\n               e5:  147ms    1156ms\n               e6:  146ms    1035ms\n               e7:  105ms     726ms\n             guid:  962ms   10762ms\ngenerateQuickGuid:  292ms    2961ms\n  - Note: 500k iterations, results will vary by browser/CPU.\n\n\nSo by my 6th iteration of optimizations, I beat the most popular answer by over 12 times, the accepted answer by over 9 times, and the fast-non-compliant answer by 2-3 times. And I'm still RFC 4122 compliant.\n\nInterested in how? I've put the full source on http://jsfiddle.net/jcward/7hyaC/3/ and on http://jsperf.com/uuid-generator-opt/4\n\nFor an explanation, let's start with broofa's code:\n\nfunction broofa() {\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n        var r = Math.random()*16|0, v = c == 'x' ? r : (r&0x3|0x8);\n        return v.toString(16);\n    });\n}\n\nconsole.log(broofa())\n Run code snippetExpand snippet\n\nSo it replaces x with any random hexadecimal digit, y with random data (except forcing the top two bits to 10 per the RFC spec), and the regex doesn't match the - or 4 characters, so he doesn't have to deal with them. Very, very slick.\n\nThe first thing to know is that function calls are expensive, as are regular expressions (though he only uses 1, it has 32 callbacks, one for each match, and in each of the 32 callbacks it calls Math.random() and v.toString(16)).\n\nThe first step toward performance is to eliminate the RegEx and its callback functions and use a simple loop instead. This means we have to deal with the - and 4 characters whereas broofa did not. Also, note that we can use String Array indexing to keep his slick String template architecture:\n\nfunction e1() {\n    var u='',i=0;\n    while(i++<36) {\n        var c='xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'[i-1],r=Math.random()*16|0,v=c=='x'?r:(r&0x3|0x8);\n        u+=(c=='-'||c=='4')?c:v.toString(16)\n    }\n    return u;\n}\n\nconsole.log(e1())\n Run code snippetExpand snippet\n\nBasically, the same inner logic, except we check for - or 4, and using a while loop (instead of replace() callbacks) gets us an almost 3X improvement!\n\nThe next step is a small one on the desktop but makes a decent difference on mobile. Let's make fewer Math.random() calls and utilize all those random bits instead of throwing 87% of them away with a random buffer that gets shifted out each iteration. Let's also move that template definition out of the loop, just in case it helps:\n\nfunction e2() {\n    var u='',m='xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx',i=0,rb=Math.random()*0xffffffff|0;\n    while(i++<36) {\n        var c=m[i-1],r=rb&0xf,v=c=='x'?r:(r&0x3|0x8);\n        u+=(c=='-'||c=='4')?c:v.toString(16);rb=i%8==0?Math.random()*0xffffffff|0:rb>>4\n    }\n    return u\n}\n\nconsole.log(e2())\n Run code snippetExpand snippet\n\nThis saves us 10-30% depending on platform. Not bad. But the next big step gets rid of the toString function calls altogether with an optimization classic - the look-up table. A simple 16-element lookup table will perform the job of toString(16) in much less time:\n\nfunction e3() {\n    var h='0123456789abcdef';\n    var k='xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx';\n    /* same as e4() below */\n}\nfunction e4() {\n    var h=['0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f'];\n    var k=['x','x','x','x','x','x','x','x','-','x','x','x','x','-','4','x','x','x','-','y','x','x','x','-','x','x','x','x','x','x','x','x','x','x','x','x'];\n    var u='',i=0,rb=Math.random()*0xffffffff|0;\n    while(i++<36) {\n        var c=k[i-1],r=rb&0xf,v=c=='x'?r:(r&0x3|0x8);\n        u+=(c=='-'||c=='4')?c:h[v];rb=i%8==0?Math.random()*0xffffffff|0:rb>>4\n    }\n    return u\n}\n\nconsole.log(e4())\n Run code snippetExpand snippet\n\nThe next optimization is another classic. Since we're only handling four bits of output in each loop iteration, let's cut the number of loops in half and process eight bits in each iteration. This is tricky since we still have to handle the RFC compliant bit positions, but it's not too hard. We then have to make a larger lookup table (16x16, or 256) to store 0x00 - 0xFF, and we build it only once, outside the e5() function.\n\nvar lut = []; for (var i=0; i<256; i++) { lut[i] = (i<16?'0':'')+(i).toString(16); }\nfunction e5() {\n    var k=['x','x','x','x','-','x','x','-','4','x','-','y','x','-','x','x','x','x','x','x'];\n    var u='',i=0,rb=Math.random()*0xffffffff|0;\n    while(i++<20) {\n        var c=k[i-1],r=rb&0xff,v=c=='x'?r:(c=='y'?(r&0x3f|0x80):(r&0xf|0x40));\n        u+=(c=='-')?c:lut[v];rb=i%4==0?Math.random()*0xffffffff|0:rb>>8\n    }\n    return u\n}\n\nconsole.log(e5())\n Run code snippetExpand snippet\n\nI tried an e6() that processes 16-bits at a time, still using the 256-element LUT, and it showed the diminishing returns of optimization. Though it had fewer iterations, the inner logic was complicated by the increased processing, and it performed the same on desktop, and only ~10% faster on mobile.\n\nThe final optimization technique to apply - unroll the loop. Since we're looping a fixed number of times, we can technically write this all out by hand. I tried this once with a single random variable, r, that I kept reassigning, and performance tanked. But with four variables assigned random data up front, then using the lookup table, and applying the proper RFC bits, this version smokes them all:\n\nvar lut = []; for (var i=0; i<256; i++) { lut[i] = (i<16?'0':'')+(i).toString(16); }\nfunction e7()\n{\n    var d0 = Math.random()*0xffffffff|0;\n    var d1 = Math.random()*0xffffffff|0;\n    var d2 = Math.random()*0xffffffff|0;\n    var d3 = Math.random()*0xffffffff|0;\n    return lut[d0&0xff]+lut[d0>>8&0xff]+lut[d0>>16&0xff]+lut[d0>>24&0xff]+'-'+\n    lut[d1&0xff]+lut[d1>>8&0xff]+'-'+lut[d1>>16&0x0f|0x40]+lut[d1>>24&0xff]+'-'+\n    lut[d2&0x3f|0x80]+lut[d2>>8&0xff]+'-'+lut[d2>>16&0xff]+lut[d2>>24&0xff]+\n    lut[d3&0xff]+lut[d3>>8&0xff]+lut[d3>>16&0xff]+lut[d3>>24&0xff];\n}\n\nconsole.log(e7())\n Run code snippetExpand snippet\n\nModualized: http://jcward.com/UUID.js - UUID.generate()\n\nThe funny thing is, generating 16 bytes of random data is the easy part. The whole trick is expressing it in string format with RFC compliance, and it's most tightly accomplished with 16 bytes of random data, an unrolled loop and lookup table.\n\nI hope my logic is correct -- it's very easy to make a mistake in this kind of tedious bit work. But the outputs look good to me. I hope you enjoyed this mad ride through code optimization!\n\nBe advised: my primary goal was to show and teach potential optimization strategies. Other answers cover important topics such as collisions and truly random numbers, which are important for generating good UUIDs.\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 14:21\ncommunity wiki\n\n\n13 revs, 4 users 63%\nJeff Ward","comments":["This code still contains a couple of errors: the Math.random()*0xFFFFFFFF lines should be Math.random()*0x100000000 for full randomness, and >>>0 should be used instead of |0 to keep the values unsigned (though with the current code I think it gets away OK even though they are signed). Finally it would be a very good idea these days to use window.crypto.getRandomValues if available, and fall-back to Math.random only if absolutely necessary. Math.random may well have less than 128 bits of entropy, in which case this would be more vulnerable to collisions than necessary.","Can I just say -- I cannot count how many times I've pointed devs to this answer because it so beautifully points out the tradeoffs between performance, code-elegance, and readability. Thank you Jeff.","I don't know if @Broofa's answer has changed since these tests were run (or if the browser engines running the tests have changed - it has been five years), but I just ran them both on two different benchmarking services (jsben.ch and jsbench.github.io), and in each case Broofa's answer (using Math.random) was faster than this e7() version by 30 - 35%.","@Andy is right. Broofa's code is faster as of Aug 2021. I implemented Dave's suggestions and ran the test myself. But I don't imagine the difference should matter all that much in production: jsbench.github.io/#80610cde9bc93d0f3068e5793e60ff11","I feel your comparisons may be unfair as broofa's anwer appears to be for an e4 UUID, and your testing against Ward's e7 implementation here. When you compare broofa's answer to the e4 version presented to here, this answer is faster."]},{"answer":"Use:\n\nlet uniqueId = Date.now().toString(36) + Math.random().toString(36).substring(2);\n\n\nShow code snippet\n\nIf IDs are generated more than 1 millisecond apart, they are 100% unique.\n\nIf two IDs are generated at shorter intervals, and assuming that the random method is truly random, this would generate IDs that are 99.99999999999999% likely to be globally unique (collision in 1 of 10^15).\n\nYou can increase this number by adding more digits, but to generate 100% unique IDs you will need to use a global counter.\n\nIf you need RFC compatibility, this formatting will pass as a valid version 4 GUID:\n\nlet u = Date.now().toString(16) + Math.random().toString(16) + '0'.repeat(16);\nlet guid = [u.substr(0,8), u.substr(8,4), '4000-8' + u.substr(13,3), u.substr(16,12)].join('-');\n\n\nShow code snippet\n\nThe above code follow the intention, but not the letter of the RFC. Among other discrepancies it's a few random digits short. (Add more random digits if you need it) The upside is that this is really fast :) You can test validity of your GUID here\n\nShare\nImprove this answer\nFollow\nedited Aug 12 at 22:52\ncommunity wiki\n\n\n19 revs, 3 users 91%\nSimon Rigét","comments":["This is not UUID though?","No. UUID/GUID's is a 122 bit (+ six reserved bits) number. it might guarantee uniqueness through a global counter service, but often it relays on time, MAC address and randomness. UUID's are not random! The UID I suggest here is not fully compressed. You could compress it, to a 122 bit integer, add the 6 predefined bits and extra random bits (remove a few timer bits) and you end up with a perfectly formed UUID/GUID, that you would then have to convert to hex. To me that doesn't really add anything other than compliance to the length of the ID.","Relaying on MAC addresses for uniqueness on virtual machines is a bad idea!","I do something like this, but with leading characters and some dashes (e.g [slug, date, random].join(\"_\") to create usr_1dcn27itd_hj6onj6phr. It makes it so the id also doubles as a \"created at\" field","Building on @SephReed's comment, I think having the date part first is nice since it sorts chronologically, which may provide benefits later if storing or indexing the IDs."]},{"answer":"Here's some code based on RFC 4122, section 4.4 (Algorithms for Creating a UUID from Truly Random or Pseudo-Random Number).\n\nfunction createUUID() {\n    // http://www.ietf.org/rfc/rfc4122.txt\n    var s = [];\n    var hexDigits = \"0123456789abcdef\";\n    for (var i = 0; i < 36; i++) {\n        s[i] = hexDigits.substr(Math.floor(Math.random() * 0x10), 1);\n    }\n    s[14] = \"4\";  // bits 12-15 of the time_hi_and_version field to 0010\n    s[19] = hexDigits.substr((s[19] & 0x3) | 0x8, 1);  // bits 6-7 of the clock_seq_hi_and_reserved to 01\n    s[8] = s[13] = s[18] = s[23] = \"-\";\n\n    var uuid = s.join(\"\");\n    return uuid;\n}\n\nShare\nImprove this answer\nFollow\nedited Oct 25 '11 at 22:37\ncommunity wiki\n\n\nKevin Hakanson","comments":["You should declare the array size beforehand rather than sizing it dynamically as you build the GUID. var s = new Array(36);","I think there's a very minor bug in the line that sets bits bits 6-7 of the clock_seq_hi_and_reserved to 01. Since s[19] is a character '0'..'f' and not an int 0x0..0xf, (s[19] & 0x3) | 0x8 will not be randomly distributed -- it will tend to produce more '9's and fewer 'b's. This only makes a difference if you care about the random distribution for some reason."]},{"answer":"This is the fastest GUID-like string generator method in the format XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX. It does not generate a standard-compliant GUID.\n\nTen million executions of this implementation take just 32.5 seconds, which is the fastest I've ever seen in a browser (the only solution without loops/iterations).\n\nThe function is as simple as:\n\n/**\n * Generates a GUID string.\n * @returns {string} The generated GUID.\n * @example af8a8416-6e18-a307-bd9c-f2c947bbb3aa\n * @author Slavik Meltser.\n * @link http://slavik.meltser.info/?p=142\n */\nfunction guid() {\n    function _p8(s) {\n        var p = (Math.random().toString(16)+\"000000000\").substr(2,8);\n        return s ? \"-\" + p.substr(0,4) + \"-\" + p.substr(4,4) : p ;\n    }\n    return _p8() + _p8(true) + _p8(true) + _p8();\n}\n\n\nTo test the performance, you can run this code:\n\nconsole.time('t');\nfor (var i = 0; i < 10000000; i++) {\n    guid();\n};\nconsole.timeEnd('t');\n\n\nI'm sure most of you will understand what I did there, but maybe there is at least one person that will need an explanation:\n\nThe algorithm:\n\nThe Math.random() function returns a decimal number between 0 and 1 with 16 digits after the decimal fraction point (for example 0.4363923368509859).\nThen we take this number and convert it to a string with base 16 (from the example above we'll get 0.6fb7687f). Math.random().toString(16).\nThen we cut off the 0. prefix (0.6fb7687f => 6fb7687f) and get a string with eight hexadecimal characters long. (Math.random().toString(16).substr(2,8).\nSometimes the Math.random() function will return shorter number (for example 0.4363), due to zeros at the end (from the example above, actually the number is 0.4363000000000000). That's why I'm appending to this string \"000000000\" (a string with nine zeros) and then cutting it off with substr() function to make it nine characters exactly (filling zeros to the right).\nThe reason for adding exactly nine zeros is because of the worse case scenario, which is when the Math.random() function will return exactly 0 or 1 (probability of 1/10^16 for each one of them). That's why we needed to add nine zeros to it (\"0\"+\"000000000\" or \"1\"+\"000000000\"), and then cutting it off from the second index (third character) with a length of eight characters. For the rest of the cases, the addition of zeros will not harm the result because it is cutting it off anyway. Math.random().toString(16)+\"000000000\").substr(2,8).\n\nThe assembly:\n\nThe GUID is in the following format XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX.\nI divided the GUID into four pieces, each piece divided into two types (or formats): XXXXXXXX and -XXXX-XXXX.\nNow I'm building the GUID using these two types to assemble the GUID with call four pieces, as follows: XXXXXXXX -XXXX-XXXX -XXXX-XXXX XXXXXXXX.\nTo differ between these two types, I added a flag parameter to a pair creator function _p8(s), the s parameter tells the function whether to add dashes or not.\nEventually we build the GUID with the following chaining: _p8() + _p8(true) + _p8(true) + _p8(), and return it.\n\nLink to this post on my blog\n\nEnjoy! :-)\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 14:04\ncommunity wiki\n\n\n14 revs, 4 users 84%\nSlavik Meltser","comments":["This implementation is incorrect. Certain characters of the GUID require special treatment (e.g. the 13th digit needs to be the number 4)."]},{"answer":"Here is a totally non-compliant but very performant implementation to generate an ASCII-safe GUID-like unique identifier.\n\nfunction generateQuickGuid() {\n    return Math.random().toString(36).substring(2, 15) +\n        Math.random().toString(36).substring(2, 15);\n}\n\n\nGenerates 26 [a-z0-9] characters, yielding a UID that is both shorter and more unique than RFC compliant GUIDs. Dashes can be trivially added if human-readability matters.\n\nHere are usage examples and timings for this function and several of this question's other answers. The timing was performed under Chrome m25, 10 million iterations each.\n\n>>> generateQuickGuid()\n\"nvcjf1hs7tf8yyk4lmlijqkuo9\"\n\"yq6gipxqta4kui8z05tgh9qeel\"\n\"36dh5sec7zdj90sk2rx7pjswi2\"\nruntime: 32.5s\n\n>>> GUID() // John Millikin\n\"7a342ca2-e79f-528e-6302-8f901b0b6888\"\nruntime: 57.8s\n\n>>> regexGuid() // broofa\n\"396e0c46-09e4-4b19-97db-bd423774a4b3\"\nruntime: 91.2s\n\n>>> createUUID() // Kevin Hakanson\n\"403aa1ab-9f70-44ec-bc08-5d5ac56bd8a5\"\nruntime: 65.9s\n\n>>> UUIDv4() // Jed Schmidt\n\"f4d7d31f-fa83-431a-b30c-3e6cc37cc6ee\"\nruntime: 282.4s\n\n>>> Math.uuid() // broofa\n\"5BD52F55-E68F-40FC-93C2-90EE069CE545\"\nruntime: 225.8s\n\n>>> Math.uuidFast() // broofa\n\"6CB97A68-23A2-473E-B75B-11263781BBE6\"\nruntime: 92.0s\n\n>>> Math.uuidCompact() // broofa\n\"3d7b7a06-0a67-4b67-825c-e5c43ff8c1e8\"\nruntime: 229.0s\n\n>>> bitwiseGUID() // jablko\n\"baeaa2f-7587-4ff1-af23-eeab3e92\"\nruntime: 79.6s\n\n>>>> betterWayGUID() // Andrea Turri\n\"383585b0-9753-498d-99c3-416582e9662c\"\nruntime: 60.0s\n\n>>>> UUID() // John Fowler\n\"855f997b-4369-4cdb-b7c9-7142ceaf39e8\"\nruntime: 62.2s\n\n\nHere is the timing code.\n\nvar r;\nconsole.time('t'); \nfor (var i = 0; i < 10000000; i++) { \n    r = FuncToTest(); \n};\nconsole.timeEnd('t');\n\nShare\nImprove this answer\nFollow\nedited Jan 21 '13 at 21:52\ncommunity wiki\n\n\njoelpt","comments":[]},{"answer":"Here is a combination of the top voted answer, with a workaround for Chrome's collisions:\n\ngenerateGUID = (typeof(window.crypto) != 'undefined' &&\n                typeof(window.crypto.getRandomValues) != 'undefined') ?\n    function() {\n        // If we have a cryptographically secure PRNG, use that\n        // https://stackoverflow.com/questions/6906916/collisions-when-generating-uuids-in-javascript\n        var buf = new Uint16Array(8);\n        window.crypto.getRandomValues(buf);\n        var S4 = function(num) {\n            var ret = num.toString(16);\n            while(ret.length < 4){\n                ret = \"0\"+ret;\n            }\n            return ret;\n        };\n        return (S4(buf[0])+S4(buf[1])+\"-\"+S4(buf[2])+\"-\"+S4(buf[3])+\"-\"+S4(buf[4])+\"-\"+S4(buf[5])+S4(buf[6])+S4(buf[7]));\n    }\n\n    :\n\n    function() {\n        // Otherwise, just use Math.random\n        // https://stackoverflow.com/questions/105034/how-to-create-a-guid-uuid-in-javascript/2117523#2117523\n        return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n            var r = Math.random()*16|0, v = c == 'x' ? r : (r&0x3|0x8);\n            return v.toString(16);\n        });\n    };\n\n\nIt is on jsbin if you want to test it.\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '20 at 3:35\ncommunity wiki\n\n\n4 revs, 3 users 85%\nripper234","comments":["note that the first version, the one ` window.crypto.getRandomValues, does not keep the Version 4 UUIDs format defined by RFC 4122. That is instead of xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx` it yields xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx."]},{"answer":"From sagi shkedy's technical blog:\n\nfunction generateGuid() {\n  var result, i, j;\n  result = '';\n  for(j=0; j<32; j++) {\n    if( j == 8 || j == 12 || j == 16 || j == 20)\n      result = result + '-';\n    i = Math.floor(Math.random()*16).toString(16).toUpperCase();\n    result = result + i;\n  }\n  return result;\n}\n\n\nThere are other methods that involve using an ActiveX control, but stay away from these!\n\nI thought it was worth pointing out that no GUID generator can guarantee unique keys (check the Wikipedia article). There is always a chance of collisions. A GUID simply offers a large enough universe of keys to reduce the change of collisions to almost nil.\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '20 at 15:20\ncommunity wiki\n\n\n5 revs, 4 users 78%\nPrestaul","comments":["Note that this isn't a GUID in the technical sense, because it does nothing to guarantee uniqueness. That may or may not matter depending on your application.","A quick note about performance. This solution creates 36 strings total to get a single result. If performance is critical, consider creating an array and joining as recommended by: tinyurl.com/y37xtx Further research indicates it may not matter, so YMMV: tinyurl.com/3l7945","Regarding uniqueness, it's worth noting that version 1,3, and 5 UUIDs are deterministic in ways version 4 isn't. If the inputs to these uuid generators - node id in v1, namespace and name in v3 and v5 - are unique (as they're supposed to be), then the resulting UUIDs be unique. In theory, anyway."]},{"answer":"Here's a solution dated Oct. 9, 2011 from a comment by user jed at https://gist.github.com/982883:\n\nUUIDv4 = function b(a){return a?(a^Math.random()*16>>a/4).toString(16):([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g,b)}\n\n\nThis accomplishes the same goal as the current highest-rated answer, but in 50+ fewer bytes by exploiting coercion, recursion, and exponential notation. For those curious how it works, here's the annotated form of an older version of the function:\n\nUUIDv4 =\n\nfunction b(\n  a // placeholder\n){\n  return a // if the placeholder was passed, return\n    ? ( // a random number from 0 to 15\n      a ^ // unless b is 8,\n      Math.random() // in which case\n      * 16 // a random number from\n      >> a/4 // 8 to 11\n      ).toString(16) // in hexadecimal\n    : ( // or otherwise a concatenated string:\n      [1e7] + // 10000000 +\n      -1e3 + // -1000 +\n      -4e3 + // -4000 +\n      -8e3 + // -80000000 +\n      -1e11 // -100000000000,\n      ).replace( // replacing\n        /[018]/g, // zeroes, ones, and eights with\n        b // random hex digits\n      )\n}\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 10:31\ncommunity wiki\n\n\n9 revs, 5 users 63%\nJed Schmidt","comments":[]},{"answer":"You can use node-uuid. It provides simple, fast generation of RFC4122 UUIDS.\n\nFeatures:\n\nGenerate RFC4122 version 1 or version 4 UUIDs\nRuns in Node.js and browsers.\nCryptographically strong random # generation on supporting platforms.\nSmall footprint (Want something smaller? Check this out!)\n\nInstall Using NPM:\n\nnpm install uuid\n\n\nOr using uuid via a browser:\n\nDownload Raw File (uuid v1): https://raw.githubusercontent.com/kelektiv/node-uuid/master/v1.js Download Raw File (uuid v4): https://raw.githubusercontent.com/kelektiv/node-uuid/master/v4.js\n\nWant even smaller? Check this out: https://gist.github.com/jed/982883\n\nUsage:\n\n// Generate a v1 UUID (time-based)\nconst uuidV1 = require('uuid/v1');\nuuidV1(); // -> '6c84fb90-12c4-11e1-840d-7b25c5ee775a'\n\n// Generate a v4 UUID (random)\nconst uuidV4 = require('uuid/v4');\nuuidV4(); // -> '110ec58a-a0f2-4ac4-8393-c866d813b8d1'\n\n// Generate a v5 UUID (namespace)\nconst uuidV5 = require('uuid/v5');\n\n// ... using predefined DNS namespace (for domain names)\nuuidV5('hello.example.com', v5.DNS)); // -> 'fdda765f-fc57-5604-a269-52a7df8164ec'\n\n// ... using predefined URL namespace (for, well, URLs)\nuuidV5('http://example.com/hello', v5.URL); // -> '3bbcee75-cecc-5b56-8031-b6641c1ed1f1'\n\n// ... using a custom namespace\nconst MY_NAMESPACE = '(previously generated unique uuid string)';\nuuidV5('hello', MY_NAMESPACE); // -> '90123e1c-7512-523e-bb28-76fab9f2f73d'\n\n\nECMAScript 2015 (ES6):\n\nimport uuid from 'uuid/v4';\nconst id = uuid();\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 16:45\ncommunity wiki\n\n\n7 revs, 3 users 85%\nKyros Koh","comments":["Note: These imports didn't work for me. Import statements have changed, as stated in the repo: const { v4: uuidv4 } = require('uuid'); and ES6: import { v4 as uuidv4 } from 'uuid';"]},{"answer":"var uuid = function() {\n    var buf = new Uint32Array(4);\n    window.crypto.getRandomValues(buf);\n    var idx = -1;\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n        idx++;\n        var r = (buf[idx>>3] >> ((idx%8)*4))&15;\n        var v = c == 'x' ? r : (r&0x3|0x8);\n        return v.toString(16);\n    });\n};\n\n\nThis version is based on Briguy37's answer and some bitwise operators to extract nibble sized windows from the buffer.\n\nIt should adhere to the RFC Type 4 (random) schema, since I had problems last time parsing non-compliant UUIDs with Java's UUID.\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '20 at 3:14\ncommunity wiki\n\n\n7 revs, 4 users 73%\nsleeplessnerd","comments":[]},{"answer":"This creates a version 4 UUID (created from pseudo random numbers):\n\nfunction uuid()\n{\n   var chars = '0123456789abcdef'.split('');\n\n   var uuid = [], rnd = Math.random, r;\n   uuid[8] = uuid[13] = uuid[18] = uuid[23] = '-';\n   uuid[14] = '4'; // version 4\n\n   for (var i = 0; i < 36; i++)\n   {\n      if (!uuid[i])\n      {\n         r = 0 | rnd()*16;\n\n         uuid[i] = chars[(i == 19) ? (r & 0x3) | 0x8 : r & 0xf];\n      }\n   }\n\n   return uuid.join('');\n}\n\n\nHere is a sample of the UUIDs generated:\n\n682db637-0f31-4847-9cdf-25ba9613a75c\n97d19478-3ab2-4aa1-b8cc-a1c3540f54aa\n2eed04c9-2692-456d-a0fd-51012f947136\n\nShare\nImprove this answer\nFollow\nedited Oct 3 '20 at 15:22\ncommunity wiki\n\n\n3 revs, 3 users 62%\nMathieu Pagé","comments":[]},{"answer":"Simple JavaScript module as a combination of best answers in this question.\n\nvar crypto = window.crypto || window.msCrypto || null; // IE11 fix\n\nvar Guid = Guid || (function() {\n\n  var EMPTY = '00000000-0000-0000-0000-000000000000';\n\n  var _padLeft = function(paddingString, width, replacementChar) {\n    return paddingString.length >= width ? paddingString : _padLeft(replacementChar + paddingString, width, replacementChar || ' ');\n  };\n\n  var _s4 = function(number) {\n    var hexadecimalResult = number.toString(16);\n    return _padLeft(hexadecimalResult, 4, '0');\n  };\n\n  var _cryptoGuid = function() {\n    var buffer = new window.Uint16Array(8);\n    window.crypto.getRandomValues(buffer);\n    return [_s4(buffer[0]) + _s4(buffer[1]), _s4(buffer[2]), _s4(buffer[3]), _s4(buffer[4]), _s4(buffer[5]) + _s4(buffer[6]) + _s4(buffer[7])].join('-');\n  };\n\n  var _guid = function() {\n    var currentDateMilliseconds = new Date().getTime();\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(currentChar) {\n      var randomChar = (currentDateMilliseconds + Math.random() * 16) % 16 | 0;\n      currentDateMilliseconds = Math.floor(currentDateMilliseconds / 16);\n      return (currentChar === 'x' ? randomChar : (randomChar & 0x7 | 0x8)).toString(16);\n    });\n  };\n\n  var create = function() {\n    var hasCrypto = crypto != 'undefined' && crypto !== null,\n      hasRandomValues = typeof(window.crypto.getRandomValues) != 'undefined';\n    return (hasCrypto && hasRandomValues) ? _cryptoGuid() : _guid();\n  };\n\n  return {\n    newGuid: create,\n    empty: EMPTY\n  };\n})();\n\n// DEMO: Create and show GUID\nconsole.log(Guid.newGuid());\n Run code snippetExpand snippet\n\nUsage:\n\nGuid.newGuid()\n\n\"c6c2d12f-d76b-5739-e551-07e6de5b0807\"\n\nGuid.empty\n\n\"00000000-0000-0000-0000-000000000000\"\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '20 at 3:31\ncommunity wiki\n\n\n5 revs, 4 users 70%\nkayz1","comments":["What is bothering about all answers is that it seems ok for JavaScript to store the GUID as a string. Your answer at least tackles the much more efficient storage using a Uint16Array. The toString function should be using the binary representation in an JavaScript object","This UUIDs produced by this code are either weak-but-RFC-compliant (_guid), or strong-but-not-RFC-compliant (_cryptoGuid). The former uses Math.random(), which is now known to be a poor RNG. The latter is failing to set the version and variant fields.","@broofa - What would you suggest to make it strong and RFC-compliant? And why is _cryptoGuid not RFC-compliant?","@Matt _cryptoGuid() sets all 128 bits randomly, meaning it doesn't set the version and variant fields as described in the RFC. See my alternate implementation of uuidv4() that uses crypto.getRandomValues() in my top-voted answer, above, for a strong+compliant implementation."]},{"answer":"The version below is an adaptation of broofa's answer, but updated to include a \"true\" random function that uses crypto libraries where available, and the Alea() function as a fallback.\n\n  Math.log2 = Math.log2 || function(n){ return Math.log(n) / Math.log(2); }\n  Math.trueRandom = (function() {\n  var crypt = window.crypto || window.msCrypto;\n\n  if (crypt && crypt.getRandomValues) {\n      // If we have a crypto library, use it\n      var random = function(min, max) {\n          var rval = 0;\n          var range = max - min;\n          if (range < 2) {\n              return min;\n          }\n\n          var bits_needed = Math.ceil(Math.log2(range));\n          if (bits_needed > 53) {\n            throw new Exception(\"We cannot generate numbers larger than 53 bits.\");\n          }\n          var bytes_needed = Math.ceil(bits_needed / 8);\n          var mask = Math.pow(2, bits_needed) - 1;\n          // 7776 -> (2^13 = 8192) -1 == 8191 or 0x00001111 11111111\n\n          // Create byte array and fill with N random numbers\n          var byteArray = new Uint8Array(bytes_needed);\n          crypt.getRandomValues(byteArray);\n\n          var p = (bytes_needed - 1) * 8;\n          for(var i = 0; i < bytes_needed; i++ ) {\n              rval += byteArray[i] * Math.pow(2, p);\n              p -= 8;\n          }\n\n          // Use & to apply the mask and reduce the number of recursive lookups\n          rval = rval & mask;\n\n          if (rval >= range) {\n              // Integer out of acceptable range\n              return random(min, max);\n          }\n          // Return an integer that falls within the range\n          return min + rval;\n      }\n      return function() {\n          var r = random(0, 1000000000) / 1000000000;\n          return r;\n      };\n  } else {\n      // From https://web.archive.org/web/20120502223108/http://baagoe.com/en/RandomMusings/javascript/\n      // Johannes Baagøe <baagoe@baagoe.com>, 2010\n      function Mash() {\n          var n = 0xefc8249d;\n\n          var mash = function(data) {\n              data = data.toString();\n              for (var i = 0; i < data.length; i++) {\n                  n += data.charCodeAt(i);\n                  var h = 0.02519603282416938 * n;\n                  n = h >>> 0;\n                  h -= n;\n                  h *= n;\n                  n = h >>> 0;\n                  h -= n;\n                  n += h * 0x100000000; // 2^32\n              }\n              return (n >>> 0) * 2.3283064365386963e-10; // 2^-32\n          };\n\n          mash.version = 'Mash 0.9';\n          return mash;\n      }\n\n      // From http://baagoe.com/en/RandomMusings/javascript/\n      function Alea() {\n          return (function(args) {\n              // Johannes BaagÃ¸e <baagoe@baagoe.com>, 2010\n              var s0 = 0;\n              var s1 = 0;\n              var s2 = 0;\n              var c = 1;\n\n              if (args.length == 0) {\n                  args = [+new Date()];\n              }\n              var mash = Mash();\n              s0 = mash(' ');\n              s1 = mash(' ');\n              s2 = mash(' ');\n\n              for (var i = 0; i < args.length; i++) {\n                  s0 -= mash(args[i]);\n                  if (s0 < 0) {\n                      s0 += 1;\n                  }\n                  s1 -= mash(args[i]);\n                  if (s1 < 0) {\n                      s1 += 1;\n                  }\n                  s2 -= mash(args[i]);\n                  if (s2 < 0) {\n                      s2 += 1;\n                  }\n              }\n              mash = null;\n\n              var random = function() {\n                  var t = 2091639 * s0 + c * 2.3283064365386963e-10; // 2^-32\n                  s0 = s1;\n                  s1 = s2;\n                  return s2 = t - (c = t | 0);\n              };\n              random.uint32 = function() {\n                  return random() * 0x100000000; // 2^32\n              };\n              random.fract53 = function() {\n                  return random() +\n                      (random() * 0x200000 | 0) * 1.1102230246251565e-16; // 2^-53\n              };\n              random.version = 'Alea 0.9';\n              random.args = args;\n              return random;\n\n          }(Array.prototype.slice.call(arguments)));\n      };\n      return Alea();\n  }\n}());\n\nMath.guid = function() {\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c)    {\n      var r = Math.trueRandom() * 16 | 0,\n          v = c == 'x' ? r : (r & 0x3 | 0x8);\n      return v.toString(16);\n  });\n};\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 16:14\ncommunity wiki\n\n\n7 revs, 4 users 79%\njvenema","comments":[]},{"answer":"JavaScript project on GitHub - https://github.com/LiosK/UUID.js\n\nUUID.js The RFC-compliant UUID generator for JavaScript.\n\nSee RFC 4122 http://www.ietf.org/rfc/rfc4122.txt.\n\nFeatures Generates RFC 4122 compliant UUIDs.\n\nVersion 4 UUIDs (UUIDs from random numbers) and version 1 UUIDs (time-based UUIDs) are available.\n\nUUID object allows a variety of access to the UUID including access to the UUID fields.\n\nLow timestamp resolution of JavaScript is compensated by random numbers.\n\nShare\nImprove this answer\nFollow\nanswered Jul 2 '12 at 21:00\ncommunity wiki\n\n\nWojciech Bednarski","comments":[]},{"answer":"  // RFC 4122\n  //\n  // A UUID is 128 bits long\n  //\n  // String representation is five fields of 4, 2, 2, 2, and 6 bytes.\n  // Fields represented as lowercase, zero-filled, hexadecimal strings, and\n  // are separated by dash characters\n  //\n  // A version 4 UUID is generated by setting all but six bits to randomly\n  // chosen values\n  var uuid = [\n    Math.random().toString(16).slice(2, 10),\n    Math.random().toString(16).slice(2, 6),\n\n    // Set the four most significant bits (bits 12 through 15) of the\n    // time_hi_and_version field to the 4-bit version number from Section\n    // 4.1.3\n    (Math.random() * .0625 /* 0x.1 */ + .25 /* 0x.4 */).toString(16).slice(2, 6),\n\n    // Set the two most significant bits (bits 6 and 7) of the\n    // clock_seq_hi_and_reserved to zero and one, respectively\n    (Math.random() * .25 /* 0x.4 */ + .5 /* 0x.8 */).toString(16).slice(2, 6),\n\n    Math.random().toString(16).slice(2, 14)].join('-');\n\nShare\nImprove this answer\nFollow\nanswered Jul 14 '10 at 23:30\ncommunity wiki\n\n\njablko","comments":[]},{"answer":"For those wanting an RFC 4122 version 4 compliant solution with speed considerations (few calls to Math.random()):\n\nvar rand = Math.random;\n\nfunction UUID() {\n    var nbr, randStr = \"\";\n    do {\n        randStr += (nbr = rand()).toString(16).substr(3, 6);\n    } while (randStr.length < 30);\n    return (\n        randStr.substr(0, 8) + \"-\" +\n        randStr.substr(8, 4) + \"-4\" +\n        randStr.substr(12, 3) + \"-\" +\n        ((nbr*4|0)+8).toString(16) + // [89ab]\n        randStr.substr(15, 3) + \"-\" +\n        randStr.substr(18, 12)\n    );\n}\n\nconsole.log( UUID() );\n Run code snippetExpand snippet\n\nThe above function should have a decent balance between speed and randomness.\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '20 at 3:30\ncommunity wiki\n\n\n3 revs, 3 users 63%\nJohn Fowler","comments":[]},{"answer":"I wanted to understand broofa's answer, so I expanded it and added comments:\n\nvar uuid = function () {\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(\n        /[xy]/g,\n        function (match) {\n            /*\n            * Create a random nibble. The two clever bits of this code:\n            *\n            * - Bitwise operations will truncate floating point numbers\n            * - For a bitwise OR of any x, x | 0 = x\n            *\n            * So:\n            *\n            * Math.random * 16\n            *\n            * creates a random floating point number\n            * between 0 (inclusive) and 16 (exclusive) and\n            *\n            * | 0\n            *\n            * truncates the floating point number into an integer.\n            */\n            var randomNibble = Math.random() * 16 | 0;\n\n            /*\n            * Resolves the variant field. If the variant field (delineated\n            * as y in the initial string) is matched, the nibble must\n            * match the mask (where x is a do-not-care bit):\n            *\n            * 10xx\n            *\n            * This is achieved by performing the following operations in\n            * sequence (where x is an intermediate result):\n            *\n            * - x & 0x3, which is equivalent to x % 3\n            * - x | 0x8, which is equivalent to x + 8\n            *\n            * This results in a nibble between 8 inclusive and 11 exclusive,\n            * (or 1000 and 1011 in binary), all of which satisfy the variant\n            * field mask above.\n            */\n            var nibble = (match == 'y') ?\n                (randomNibble & 0x3 | 0x8) :\n                randomNibble;\n\n            /*\n            * Ensure the nibble integer is encoded as base 16 (hexadecimal).\n            */\n            return nibble.toString(16);\n        }\n    );\n};\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 16:18\ncommunity wiki\n\n\n5 revs, 2 users 92%\nAndrew","comments":["Thank you for detailed description! Specifically nibble caged between 8 and 11 with equivalents explanation is super helpful."]},{"answer":"I adjusted my own UUID/GUID generator with some extras here.\n\nI'm using the following Kybos random number generator to be a bit more cryptographically sound.\n\nBelow is my script with the Mash and Kybos methods from baagoe.com excluded.\n\n//UUID/Guid Generator\n// use: UUID.create() or UUID.createSequential()\n// convenience:  UUID.empty, UUID.tryParse(string)\n(function(w){\n  // From http://baagoe.com/en/RandomMusings/javascript/\n  // Johannes BaagÃ¸e <baagoe@baagoe.com>, 2010\n  //function Mash() {...};\n\n  // From http://baagoe.com/en/RandomMusings/javascript/\n  //function Kybos() {...};\n\n  var rnd = Kybos();\n\n  //UUID/GUID Implementation from http://frugalcoder.us/post/2012/01/13/javascript-guid-uuid-generator.aspx\n  var UUID = {\n    \"empty\": \"00000000-0000-0000-0000-000000000000\"\n    ,\"parse\": function(input) {\n      var ret = input.toString().trim().toLowerCase().replace(/^[\\s\\r\\n]+|[\\{\\}]|[\\s\\r\\n]+$/g, \"\");\n      if ((/[a-f0-9]{8}\\-[a-f0-9]{4}\\-[a-f0-9]{4}\\-[a-f0-9]{4}\\-[a-f0-9]{12}/).test(ret))\n        return ret;\n      else\n        throw new Error(\"Unable to parse UUID\");\n    }\n    ,\"createSequential\": function() {\n      var ret = new Date().valueOf().toString(16).replace(\"-\",\"\")\n      for (;ret.length < 12; ret = \"0\" + ret);\n      ret = ret.substr(ret.length-12,12); //only least significant part\n      for (;ret.length < 32;ret += Math.floor(rnd() * 0xffffffff).toString(16));\n      return [ret.substr(0,8), ret.substr(8,4), \"4\" + ret.substr(12,3), \"89AB\"[Math.floor(Math.random()*4)] + ret.substr(16,3),  ret.substr(20,12)].join(\"-\");\n    }\n    ,\"create\": function() {\n      var ret = \"\";\n      for (;ret.length < 32;ret += Math.floor(rnd() * 0xffffffff).toString(16));\n      return [ret.substr(0,8), ret.substr(8,4), \"4\" + ret.substr(12,3), \"89AB\"[Math.floor(Math.random()*4)] + ret.substr(16,3),  ret.substr(20,12)].join(\"-\");\n    }\n    ,\"random\": function() {\n      return rnd();\n    }\n    ,\"tryParse\": function(input) {\n      try {\n        return UUID.parse(input);\n      } catch(ex) {\n        return UUID.empty;\n      }\n    }\n  };\n  UUID[\"new\"] = UUID.create;\n\n  w.UUID = w.Guid = UUID;\n}(window || this));\nShare\nImprove this answer\nFollow\nedited Dec 30 '20 at 3:37\ncommunity wiki\n\n\n2 revs, 2 users 94%\nTracker1","comments":[]},{"answer":"ES6 sample\n\nconst guid=()=> {\n  const s4=()=> Math.floor((1 + Math.random()) * 0x10000).toString(16).substring(1);     \n  return `${s4() + s4()}-${s4()}-${s4()}-${s4()}-${s4() + s4() + s4()}`;\n}\n\nShare\nImprove this answer\nFollow\nanswered Jul 9 '17 at 13:01\ncommunity wiki\n\n\nBehnam Mohammadi","comments":["An explanation would be in order. E.g., what ES6 features does it use that previous answers don't? Please respond by editing your answer, not here in comments (without \"Edit:\", \"Update:\", or similar - the answer should appear as if it was written today)."]},{"answer":"If you just need a random 128 bit string in no particular format, you can use:\n\nfunction uuid() {\n    return crypto.getRandomValues(new Uint32Array(4)).join('-');\n}\n\n\nWhich will return something like 2350143528-4164020887-938913176-2513998651.\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 17:23\ncommunity wiki\n\n\n2 revs, 2 users 71%\nJonathan Potter","comments":["BTW, why does it generate only numbers and not characters as well? much less secure","you can also add characters (letters ) like this: Array.from((window.crypto || window.msCrypto).getRandomValues(new Uint32Array(4))).map(n => n.toString(16)).join('-')"]},{"answer":"The native URL.createObjectURL is generating an UUID. You can take advantage of this.\n\nfunction uuid() {\n  const url = URL.createObjectURL(new Blob())\n  const [id] = url.toString().split('/').reverse()\n  URL.revokeObjectURL(url)\n  return id\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 18:09\ncommunity wiki\n\n\n2 revs, 2 users 82%\nAral Roca","comments":["works like a charm. Better than trying to generate manually. Very clever!","The performance is quite worst, but depending on the case it can be enough","For the fastest combined generator that is compliant w/node-clock-seq, monotonic in time, etc. This forms a good basis to seed a uuid4 generator w/60-bits of epoch70 μ-seconds of monotonic time, 4-bit uuid-version, and 48-bit node-id and 13-bit clock-seq with 3-bit uuid-variant. --<br> Combining using BigInt to write ntohl and related conversion this works very fast with the lut approach here. --<br> I can provide code if desired.","Is the inclusion of a UUID here guaranteed, or is it just something that the current browser implementations all happen to do?"]},{"answer":"Just another more readable variant with just two mutations.\n\nfunction uuid4()\n{\n  function hex (s, b)\n  {\n    return s +\n      (b >>> 4   ).toString (16) +  // high nibble\n      (b & 0b1111).toString (16);   // low nibble\n  }\n\n  let r = crypto.getRandomValues (new Uint8Array (16));\n\n  r[6] = r[6] >>> 4 | 0b01000000; // Set type 4: 0100\n  r[8] = r[8] >>> 3 | 0b10000000; // Set variant: 100\n\n  return r.slice ( 0,  4).reduce (hex, '' ) +\n         r.slice ( 4,  6).reduce (hex, '-') +\n         r.slice ( 6,  8).reduce (hex, '-') +\n         r.slice ( 8, 10).reduce (hex, '-') +\n         r.slice (10, 16).reduce (hex, '-');\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 23 '19 at 23:10\ncommunity wiki\n\n\n3 revs, 3 users 88%\nceving","comments":["Well most of the js devs are web developers, and we won't understand what bitwise operators do, because we don't use them most of the times we develop. Actually I never needed any of them, and I am a js dev since '97. So your example code is still totally unreadable to the average web developer who will read it. Not to mention that you still use single letter variable names, which makes it even more cryptic. Probably read Clean Code, maybe that helps: amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/…","@inf3rno don't bash him, all the proposed solutions in this thread are cryptic but they are correct answers considering the question was to have a one-liner of sorts. that's what one-liners are cryptic. they can't afford to be readable to the average developer but they save screen real estate where a simple preceding comment will do. And as a result, ends up being much more readable that way then if it had been in \"readable code\" instead.","@user1529413 Yes. Uniqueness requires an index.","This is my favourite answer, because it's building a UUID as a 16-byte (128 bit) value, and not its serialized, nice to read form. It'd be trivially easy to drop the string stuff and just set the correct bits of a random 128bit, which is all a uuidv4 needs to be. You could base64 it for shorter URLs, pass it back to some webassembly, store it in less memory space than as a string, make it a 4096-size buffer and put 256 uuids in it, store in a browser db, etc. Much better than having everything as a long, lowercase hex-encoded string from the start."]},{"answer":"The better way:\n\nfunction(\n  a, b               // Placeholders\n){\n  for(               // Loop :)\n      b = a = '';    // b - result , a - numeric variable\n      a++ < 36;      //\n      b += a*51&52   // If \"a\" is not 9 or 14 or 19 or 24\n                  ?  //  return a random number or 4\n           (\n               a^15              // If \"a\" is not 15,\n                  ?              // generate a random number from 0 to 15\n               8^Math.random() *\n               (a^20 ? 16 : 4)   // unless \"a\" is 20, in which case a random number from 8 to 11,\n                  :\n               4                 //  otherwise 4\n           ).toString(16)\n                  :\n         '-'                     //  In other cases, (if \"a\" is 9,14,19,24) insert \"-\"\n      );\n  return b\n }\n\n\nMinimized:\n\nfunction(a,b){for(b=a='';a++<36;b+=a*51&52?(a^15?8^Math.random()*(a^20?16:4):4).toString(16):'-');return b}\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '20 at 3:41\ncommunity wiki\n\n\n2 revs, 2 users 78%\nAndrea Turri","comments":["Why is it better?"]},{"answer":"If your environment is SharePoint, there is a utility function called SP.Guid.newGuid (MSDN link which creates a new GUID. This function is inside the sp.init.js file. If you rewrite this function (to remove some other dependencies from other private functions), and it looks like this:\n\nvar newGuid = function () {\n    var result = '';\n    var hexcodes = \"0123456789abcdef\".split(\"\");\n\n    for (var index = 0; index < 32; index++) {\n        var value = Math.floor(Math.random() * 16);\n\n        switch (index) {\n        case 8:\n            result += '-';\n            break;\n        case 12:\n            value = 4;\n            result += '-';\n            break;\n        case 16:\n            value = value & 3 | 8;\n            result += '-';\n            break;\n        case 20:\n            result += '-';\n            break;\n        }\n        result += hexcodes[value];\n    }\n    return result;\n};\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 14:05\ncommunity wiki\n\n\n3 revs, 2 users 87%\nAnatoly Mironov","comments":["The redirected URL says \"Applies to: SharePoint Foundation 2010\""]},{"answer":"The following is simple code that uses crypto.getRandomValues(a) on supported browsers (Internet Explorer 11+, iOS 7+, Firefox 21+, Chrome, and Android Chrome).\n\nIt avoids using Math.random(), because that can cause collisions (for example 20 collisions for 4000 generated UUIDs in a real situation by Muxa).\n\nfunction uuid() {\n    function randomDigit() {\n        if (crypto && crypto.getRandomValues) {\n            var rands = new Uint8Array(1);\n            crypto.getRandomValues(rands);\n            return (rands[0] % 16).toString(16);\n        } else {\n            return ((Math.random() * 16) | 0).toString(16);\n        }\n    }\n\n    var crypto = window.crypto || window.msCrypto;\n    return 'xxxxxxxx-xxxx-4xxx-8xxx-xxxxxxxxxxxx'.replace(/x/g, randomDigit);\n}\n\n\nNotes:\n\nOptimised for code readability, not speed, so it is suitable for, say, a few hundred UUIDs per second. It generates about 10000 uuid() per second in Chromium on my laptop using http://jsbin.com/fuwigo/1 to measure performance.\nIt only uses 8 for \"y\" because that simplifies code readability (y is allowed to be 8, 9, A, or B).\nShare\nImprove this answer\nFollow\nedited Apr 2 at 16:27\ncommunity wiki\n\n\n3 revs, 3 users 69%\nrobocat","comments":[]},{"answer":"This one is based on date, and adds a random suffix to \"ensure\" uniqueness.\n\nIt works well for CSS identifiers, always returns something like, and is easy to hack:\n\nuid-139410573297741\n\nvar getUniqueId = function (prefix) {\n            var d = new Date().getTime();\n            d += (parseInt(Math.random() * 100)).toString();\n            if (undefined === prefix) {\n                prefix = 'uid-';\n            }\n            d = prefix + d;\n            return d;\n        };\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 16:06\ncommunity wiki\n\n\n2 revs, 2 users 77%\nling","comments":[]},{"answer":"OK, using the uuid package, and its support for version 1, 3, 4 and 5 UUIDs, do:\n\nyarn add uuid\n\n\nAnd then:\n\nconst uuidv1 = require('uuid/v1');\nuuidv1(); // ⇨ '45745c60-7b1a-11e8-9c9c-2d42b21b1a3e'\n\n\nYou can also do it with fully-specified options:\n\nconst v1options = {\n  node: [0x01, 0x23, 0x45, 0x67, 0x89, 0xab],\n  clockseq: 0x1234,\n  msecs: new Date('2011-11-01').getTime(),\n  nsecs: 5678\n};\nuuidv1(v1options); // ⇨ '710b962e-041c-11e1-9234-0123456789ab'\n\n\nFor more information, visit the npm page here.\n\nShare\nImprove this answer\nFollow\nedited Apr 2 at 17:47\ncommunity wiki\n\n\n2 revs, 2 users 85%\nAlireza","comments":[]}]},{"id":"176264","href":"https://stackoverflow.com/questions/176264/what-is-the-difference-between-a-uri-a-url-and-a-urn","title":"What is the difference between a URI, a URL and a URN?","description":"\n                \nPeople talk about URLs, URIs, and URNs as if they're different things, but they look the same to the naked eye.\n\nWhat are the distinguishable differences between them?\n    ","questionComments":["URL is more specific than URI.","Tor the webmasters take on this question: What is difference between URI and URL","Mini Venn diagram: ( URIs ( URLs ) )","There still seems to be a lot of confusion about URI vs URL, even by those who attempted to answer the question. It would benefit everyone to see practical examples of URLs that are not URIs, examples of URIs that are not URLs, and examples that are URLs and URIs.","Kathy: \"Is that your dog?\" Bob: \"It would be more correct to call him a canine.\" Kathy: \"No, he's a dog. You, sir, are a pedant.\""],"answers":[{"answer":"From RFC 3986:\n\nA URI can be further classified as a locator, a name, or both. The term \"Uniform Resource Locator\" (URL) refers to the subset of URIs that, in addition to identifying a resource, provide a means of locating the resource by describing its primary access mechanism (e.g., its network \"location\"). The term \"Uniform Resource Name\" (URN) has been used historically to refer to both URIs under the \"urn\" scheme [RFC2141], which are required to remain globally unique and persistent even when the resource ceases to exist or becomes unavailable, and to any other URI with the properties of a name.\n\nSo all URLs are URIs, and all URNs are URIs - but URNs and URLs are different, so you can't say that all URIs are URLs.\n\nIf you haven't already read Roger Pate's answer, I'd advise doing so as well.\n\nShare\nImprove this answer\nFollow\nedited Feb 14 at 23:51\nSamB\n8,3045\n5 gold badges\n44\n44 silver badges\n52\n52 bronze badges\nanswered Oct 6 '08 at 21:29\nJon Skeet\n1.3m800\n800 gold badges\n8772\n8772 silver badges\n8958\n8958 bronze badges","comments":["Only URIs with the urn: scheme are URNs. A URI could be a classic URL, a URN, or just a URI that doesn't start with \"urn:\" and doesn't refer to a location of a resource.","Not \"all URLs are URIs\". It depends on the interpretation of the RFC. For example in Java the URI parser does not like [ or ] and that's because the spec says \"should not\" and not \"shall not\".","@AdamGent: RFC 3986 1.1.3: \"A URI can be further classified as a locator, a name, or both.\" So, if URL is a special kind of URI, that means that every URL is a URI. Doesn't it?","@AdamGent: That sounds like a Java implementation quirk, and not normative. The java.net.URI doc itself says \"every URL is a URI, abstractly speaking, but not every URI is a URL\". And java.net.URL does weird stuff like checking equality of URLs by resolving host names to IP addresses (which seems at odds with RFC 3986 sec 6 in the first place, and breaks w virtual hosts). I think this just means the Java Standard Library has some inconsistent class behavior.","@JonSkeet Maybe just need to differentiate between standards vs implementations? E.g. \"Formally, according to RFCs, all URLs are URIs. (RFC excerpt.) But existing implementations may not match the spec exactly, possibly for interoperability, and may use URLs that are not valid per the RFCs. And because it's a complicated area, some people and documents might use 'URL' to mean something different from the RFC-specified thing.\" Sort of like how most email validation routines don't match the RFC definitions."]},{"answer":"URIs identify and URLs locate; however, locators are also identifiers, so every URL is also a URI, but there are URIs which are not URLs.\n\nExamples\nRoger Pate\n\nThis is my name, which is an identifier. It is like a URI, but cannot be a URL, as it tells you nothing about my location or how to contact me. In this case it also happens to identify at least 5 other people in the USA alone.\n\n4914 West Bay Street, Nassau, Bahamas\n\nThis is a locator, which is an identifier for that physical location. It is like both a URL and URI (since all URLs are URIs), and also identifies me indirectly as \"resident of..\". In this case it uniquely identifies me, but that would change if I get a roommate.\n\nI say \"like\" because these examples do not follow the required syntax.\n\nPopular confusion\n\nFrom Wikipedia:\n\nIn computing, a Uniform Resource Locator (URL) is a subset of the Uniform Resource Identifier (URI) that specifies where an identified resource is available and the mechanism for retrieving it. In popular usage and in many technical documents and verbal discussions it is often incorrectly used as a synonym for URI, ... [emphasis mine]\n\nBecause of this common confusion, many products and documentation incorrectly use one term instead of the other, assign their own distinction, or use them synonymously.\n\nURNs\n\nMy name, Roger Pate, could be like a URN (Uniform Resource Name), except those are much more regulated and intended to be unique across both space and time.\n\nBecause I currently share this name with other people, it's not globally unique and would not be appropriate as a URN. However, even if no other family used this name, I'm named after my paternal grandfather, so it still wouldn't be unique across time. And even if that wasn't the case, the possibility of naming my descendants after me make this unsuitable as a URN.\n\nURNs are different from URLs in this rigid uniqueness constraint, even though they both share the syntax of URIs.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Dec 31 '09 at 6:32\nRoger Pate","comments":["URNs are different from URLs in this rigid uniqueness constraint Does this mean that URLs don't uniquely identify a location?","Roger's answer provides good pragmatic advice. For the official answer I go to the W3C who published \"URIs, URLs, and URNs: Clarifications and Recommendations\" in 2001. In a nutshell, W3C says the contemporary view is that everything is a URI. URL is an informal concept, not a formal concept. And the confusion dates back to a \"classical view\" which tried to rigidly distinguish between categories of URI (of which URL was one category).","..a Uniform Resource Locator (URL).. specifies where an identified resource is available and the mechanism for retrieving it. So in other words, there is no such thing as a \"relative\" URL?","Is \"earth128:Edward-de-Leau/6000000000569063853\" (the unique me over multiple multiverse) a URN, a URL or a URI?","@edelwater: I suppose thats a uri as it only identifies you but says nothing of how to get to you, unless you mean earth128 is some medium of inter-planetary travel :)"]},{"answer":"URI -- Uniform Resource Identifier\n\nURIs are a standard for identifying documents using a short string of numbers, letters, and symbols. They are defined by RFC 3986 - Uniform Resource Identifier (URI): Generic Syntax. URLs, URNs, and URCs are all types of URI.\n\nURL -- Uniform Resource Locator\n\nContains information about how to fetch a resource from its location. For example:\n\nhttp://example.com/mypage.html\nftp://example.com/download.zip\nmailto:user@example.com\nfile:///home/user/file.txt\ntel:1-888-555-5555\nhttp://example.com/resource?foo=bar#fragment\n/other/link.html (A relative URL, only useful in the context of another URL)\n\nURLs always start with a protocol (http) and usually contain information such as the network host name (example.com) and often a document path (/foo/mypage.html). URLs may have query parameters and fragment identifiers.\n\nURN -- Uniform Resource Name\n\nIdentifies a resource by a unique and persistent name, but doesn't necessarily tell you how to locate it on the internet. It usually starts with the prefix urn: For example:\n\nurn:isbn:0451450523 to identify a book by its ISBN number.\nurn:uuid:6e8bc430-9c3a-11d9-9669-0800200c9a66 a globally unique identifier\nurn:publishing:book - An XML namespace that identifies the document as a type of book.\n\nURNs can identify ideas and concepts. They are not restricted to identifying documents. When a URN does represent a document, it can be translated into a URL by a \"resolver\". The document can then be downloaded from the URL.\n\nURC -- Uniform Resource Citation\n\nPoints to meta data about a document rather than to the document itself. An example of a URC is one that points to the HTML source code of a page like: view-source:http://example.com/\n\nData URI\n\nRather than locating it on the internet, or naming it, data can be placed directly into a URI. An example would be data:,Hello%20World.\n\nFrequently Asked Questions\nI've heard that I shouldn't say URL anymore, why?\n\nThe W3 spec for HTML says that the href of an anchor tag can contain a URI, not just a URL. You should be able to put in a URN such as <a href=\"urn:isbn:0451450523\">. Your browser would then resolve that URN to a URL and download the book for you.\n\nDo any browsers actually know how to fetch documents by URN?\n\nNot that I know of, but modern web browser do implement the data URI scheme.\n\nDoes the difference between URL and URI have anything to do with whether it is relative or absolute?\n\nNo. Both relative and absolute URLs are URLs (and URIs.)\n\nDoes the difference between URL and URI have anything to do with whether it has query parameters?\n\nNo. Both URLs with and without query parameters are URLs (and URIs.)\n\nDoes the difference between URL and URI have anything to do with whether it has a fragment identifier?\n\nNo. Both URLs with and without fragment identifiers are URLs (and URIs.)\n\nDoes the difference between URL and URI have anything to do with what characters are permitted?\n\nNo. URLs are defined to be a strict subset of URIs. If a parser allows a character in a URL but not in a URI, there is a bug in the parser. The specs go into great detail about which characters are allowed in which parts of URLs and URIs. Some characters may be allowed only in some parts of the URL, but characters alone are not a difference between URLs and URIs.\n\nBut doesn't the W3C now say that URLs and URIs are the same thing?\n\nYes. The W3C realized that there is a ton of confusion about this. They issued a URI clarification document that says that it is now OK to use the terms URL and URI interchangeably (to mean URI). It is no longer useful to strictly segment URIs into different types such as URL, URN, and URC.\n\nCan a URI be both a URL and a URN?\n\nThe definition of URN is now looser than what I stated above. The latest RFC on URIs says that any URI can now be a URN (regardless of whether it starts with urn:) as long as it has \"the properties of a name.\" That is: It is globally unique and persistent even when the resource ceases to exist or becomes unavailable. An example: The URIs used in HTML doctypes such as http://www.w3.org/TR/html4/strict.dtd. That URI would continue to name the HTML4 transitional doctype even if the page on the w3.org website were deleted.\n\nShare\nImprove this answer\nFollow\nedited Feb 15 '19 at 17:51\nanswered Mar 4 '15 at 21:51\nStephen Ostermiller\n18.8k8\n8 gold badges\n74\n74 silver badges\n95\n95 bronze badges","comments":["is \"C:\\myfile\" an URI,URL or URN ? or none of them.","A file path is not a URL or URI unless you put the file:// prefix on it. Although browsers do generally handle non-URL formatted file paths. Mozilla publishes their test cases for file URLs.","See section 1.1 of the RFC -- \"Uniformity provides several benefits. It allows different types of resource identifiers to be used in the same context, even when the mechanisms used to access those resources may differ. It allows uniform semantic interpretation of common syntactic conventions across different types of resource identifiers...\"","This answer is a lot more easy to understand. I can see the clearly pictures of real example of the URLs & URN. And for anyone to read more about this... danielmiessler.com/study/url-uri","Thank you for making it clear that URIs still have standardized syntax, albeit more flexible than URLs. Daniel Miessler's blog post (linked in the comment above) misses this point."]},{"answer":"In summary: a URI identifies, a URL identifies and locates.\n\nConsider a specific edition of Shakespeare's play Romeo and Juliet, of which you have a digital copy on your home network.\n\nYou could identify the text as urn:isbn:0-486-27557-4.\nThat would be a URI, but more specifically a URN* because it names the text.\n\nYou could also identify the text as file://hostname/sharename/RomeoAndJuliet.pdf.\nThat would also be a URI, but more specifically a URL because it locates the text.\n\n*Uniform Resource Name\n\n(Note that my example is adapted from Wikipedia)\n\nShare\nImprove this answer\nFollow\nedited Apr 17 '16 at 11:53\ntschaible\n7,2901\n1 gold badge\n27\n27 silver badges\n32\n32 bronze badges\nanswered Dec 31 '09 at 6:51\nGreg\n22.1k11\n11 gold badges\n55\n55 silver badges\n77\n77 bronze badges","comments":["It's helpful to note the actual URN (to see how it compares to a URL): urn:isbn:0-486-27557-4","@Michael - It is my understanding that ISBN 0486275574 also names the text and thus qualify as a URN. I choose a format that I believed would be more familiar to readers.","So would it make sense to say that the hash (e.g. SHA1) of a file could be a URN for that file?","@johnsimer Don't think so, as you could have a copy of one file on the same computer, which would result into the same hash and therefore it's not unique."]},{"answer":"These are some very well-written but long-winded answers. Here is the difference as far as CodeIgniter is concerned:\n\nURL - http://example.com/some/page.html\n\nURI - /some/page.html\n\nPut simply, URL is the full way to indentify any resource anywhere and can have different protocols like FTP, HTTP, SCP, etc.\n\nURI is a resource on the current domain, so it needs less information to be found.\n\nIn every instance that CodeIgniter uses the word URL or URI this is the difference they are talking about, though in the grand-scheme of the web, it is not 100% correct.\n\nShare\nImprove this answer\nFollow\nedited Mar 30 '15 at 23:53\nAir\n7,3012\n2 gold badges\n47\n47 silver badges\n81\n81 bronze badges\nanswered Dec 31 '09 at 8:58\nPhil Sturgeon\n29.9k12\n12 gold badges\n75\n75 silver badges\n117\n117 bronze badges","comments":["This answer may be over-simplified but look at the context of his question. It will be more helpful to him that waffling on about XML namespaces!","This answer is not only wrong but actively misleading. Both examples are URLs. And since every URL is also a URI, this means that both examples are URIs. For the purpose of demonstrating the difference between URIs and URLs, this is totally useless.","This is the difference as far as CodeIgniter is concerned. In every instance they use the word URL or URI this is the difference they are talking about. Therefore in the grand-scheme of the web, it is not 100% correct but in the scope of the OP's question (the difference in CodeIgniter), this answer is perfectly correct.","This is wrong. @JörgWMittag is mostly on point. URLs are URIs, and they're \"fully qualified\"; so the \"URL\" in this answer is both. But /some/page.html is not a URI. It is a \"relative-ref\", which is a kind of \"URI-reference\". Combined with a base URI context, it can be resolved to a URI, but is not itself a URI. See Section 4.1 of RFC 3986. CodeIgniter's probably using the terms wrong and that should be called out; the Q (as currently edited) isn't framed as CodeIgniter-specific.","For future people who read these comments and are as confused as I was: This answer wasn't posted for this question. This question never had anything to do with CodeIgniter. There was a duplicate question which specifically mentioned CodeIgniter which was closed and had all of its answers migrated over to this question. This answer was one of those which were moved from the old closed question to this protected question. Even so, I this answer is misleading. I have downvoted it - others should do the same since, in its new home, it is wrong. The author should delete it or the merge be undone."]},{"answer":"First of all get your mind out of confusion and take it simple and you will understand.\n\nURI => Uniform Resource Identifier Identifies a complete address of resource i-e location, name or both.\n\nURL => Uniform Resource Locator Identifies location of the resource.\n\nURN => Uniform Resource Name Identifies the name of the resource\n\nExample\n\nWe have address https://www.google.com/folder/page.html where,\n\nURI(Uniform Resource Identifier) => https://www.google.com/folder/page.html\n\nURL(Uniform Resource Locator) => https://www.google.com/\n\nURN(Uniform Resource Name) => /folder/page.html\n\nURI => (URL + URN) or URL only or URN only\n\nShare\nImprove this answer\nFollow\nedited Feb 24 '18 at 9:40\nEugen Konkov\n16.5k7\n7 gold badges\n75\n75 silver badges\n112\n112 bronze badges\nanswered Jul 21 '17 at 17:50\nuser7987783","comments":[]},{"answer":"A small addition to the answers already posted, here's a Venn's diagram to sum up the theory (from Prateek Joshi's beautiful explanation):\n\nAnd an example (also from Prateek's website):\n\nShare\nImprove this answer\nFollow\nanswered Oct 16 '14 at 17:46\nGustavo Mori\n7,8703\n3 gold badges\n35\n35 silver badges\n51\n51 bronze badges","comments":["I believe the second illustration is incorrect. By the specification url.spec.whatwg.org/#url-writing A URL must be written as either a relative URL or an absolute URL, optionally followed by \"#\" and a fragment. So, #posts fragment identifier could be part of the URL","The two illustrations contradict each other.","Shouldn't url be - thinkzarahatke.com and urn - author/amty.html#posts ? Please explain it to me I am vey confused. :("]},{"answer":"Identity = Name with Location\n\nEvery URL(Uniform Resource Locator) is a URI(Uniform Resource Identifier), abstractly speaking, but every URI is not a URL. There is another subcategory of URI is URN (Uniform Resource Name), which is a named resource but do not specify how to locate them, like mailto, news, ISBN is URIs. Source\n\nURN:\n\nURN Format : urn:[namespace identifier]:[namespace specific string]\nurn: and : stand for themselves.\nExamples:\nurn:uuid:6e8bc430-9c3a-11d9-9669-0800200c9a66\nurn:ISSN:0167-6423\nurn:isbn:096139210x\nAmazon Resource Names (ARNs) is a uniquely identify AWS resources.\nARN Format : arn:partition:service:region:account-id:resource\n\nURL:\n\nURL Format : [scheme]://[Domain][Port]/[path]?[queryString]#[fragmentId]\n:,//,? and # stand for themselves.\nschemes are https,ftp,gopher,mailto,news,telnet,file,man,info,whatis,ldap...\nExamples:\nhttp://ip_server/path?query\nftp://ip_server/path\nmailto:email-address\nnews:newsgroup-name\ntelnet://ip_server/\nfile://ip_server/path_segments\nldap://hostport/dn?attributes?scope?filter?extensions\n\nAnalogy:\nTo reach a person: Driving(protocol others SMS, email, phone), Address(hostname other phone-number, emailid) and person name(object name with a relative path).\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 1:59\nanswered Dec 23 '15 at 11:45\nPremraj\n59k24\n24 gold badges\n216\n216 silver badges\n163\n163 bronze badges","comments":["Minor quibble: There should be a colon between [domain] and [port]. IE: example.com:1234","I have to wonder: how does one retrieve the resource associated with a mailto URL ?"]},{"answer":"This is one of the most confusing and possibly irrelevant topics I've encountered as a web professional.\n\nAs I understand it, a URI is a description of something, following an accepted format, that can define both or either the unique name (identification) of something or its location.\n\nThere are two basic subsets:\n\nURLs, which define location (especially to a browser trying to look up a webpage) and\nURNs, which define the unique name of something.\n\nI tend to think of URNs as being similar to GUIDs. They are simply a standardized methodology for providing unique names for things. As in the namespace declarative that uses a company's name—it's not like there is a resource sitting on a server somewhere to correspond to that line of text—it simply uniquely identifies something.\n\nI also tend to completely avoid the term URI and discuss things only in terms of URL or URN as appropriate, because it causes so much confusion. The question we should really try answering for people isn't so much the semantics, but how to identify when encountering the terms whether or not there is any practical difference in them that will change the approach to a programming situation. For example, if someone corrects me in conversation and says, \"oh, that's not a URL it's a URI\" I know they're full of it. If someone says, \"we're using a URN to define the resource,\" I'm more likely to understand we are only naming it uniquely, not locating it on a server.\n\nIf I'm way off base, please let me know!\n\nShare\nImprove this answer\nFollow\nedited Dec 17 '20 at 19:54\nBrad Turek\n1,6891\n1 gold badge\n24\n24 silver badges\n47\n47 bronze badges\nanswered Dec 1 '11 at 13:07\nKevin Lowe\n6015\n5 silver badges\n2\n2 bronze badges","comments":["No, I think you're right. The semantics of URI vs URL vs URL vs URI-ref etc. are useless to most developers, only because it drives pointless (non-productive, insignificant to decision making) debate. If the Google API used redirect_url instead of redirect_uri, would anyone really care?"]},{"answer":"URI => http://en.wikipedia.org/wiki/Uniform_Resource_Identifier\n\nURL's are a subset of URI's (which also contain URNs).\n\nBasically, a URI is a general identifier, where a URL specifies a location and a URN specifies a name.\n\nShare\nImprove this answer\nFollow\nanswered Oct 6 '08 at 21:30\nCraig Wilson\n10.9k3\n3 gold badges\n37\n37 silver badges\n42\n42 bronze badges","comments":["URLs are not a true subset of URI. You can make vaid URL's with characters [ and ] but not a URI.","Square brackets are not valid in either URIs or URLs. See this question which has many references to the specs: Are square brackets permitted in URLs?. When square brackets appear in either, they should be encoded."]},{"answer":"Another example I like to use when thinking about URIs is the xmlns attribute of an XML document:\n\n<rootElement xmlns:myPrefix=\"com.mycompany.mynode\">\n    <myPrefix:aNode>some text</myPrefix:aNode>\n</rootElement>\n\n\nIn this case com.mycompany.mynode would be a URI that uniquely identifies the \"myPrefix\" namespace for all of the elements that use it within my XML document. This is NOT a URL because it is only used to identify, not to locate something per se.\n\nShare\nImprove this answer\nFollow\nedited Apr 16 '14 at 23:16\nuser41871\nanswered Dec 31 '09 at 7:38\nD.C.\n14.9k18\n18 gold badges\n64\n64 silver badges\n102\n102 bronze badges","comments":[]},{"answer":"They're the same thing. A URI is a generalization of a URL. Originally, URIs were planned to be divided into URLs (addresses) and URNs (names) but then there was little difference between a URL and URI and http URIs were used as namespaces even though they didn't actually locate any resources.\n\nShare\nImprove this answer\nFollow\nedited Oct 6 '08 at 21:45\nanswered Oct 6 '08 at 21:28\nMark Cidade\n94.5k31\n31 gold badges\n220\n220 silver badges\n232\n232 bronze badges","comments":["I thought it was the other way around. A URL refers to a concrete object, and a URI can refer to that or a concept or anything else.","A URL locates a resource and is a kind of URI, which identifies a resource.","It is only true that they are the same thing because the definition of URL has changed over time. URLs used to be a specific type of URI, but because of the confusion that caused, the W3C redefined URL to mean URI."]},{"answer":"Due to difficulties to clearly distinguish between URI and URL, as far as I remember W3C does not make a difference any longer between URI and URL (http://www.w3.org/Addressing/).\n\nShare\nImprove this answer\nFollow\nedited Aug 8 '13 at 19:57\nSFEley\n7,3085\n5 gold badges\n26\n26 silver badges\n31\n31 bronze badges\nanswered Dec 31 '09 at 12:59\nmanuel aldana\n13.4k8\n8 gold badges\n40\n40 silver badges\n49\n49 bronze badges","comments":["Maybe I missed that part, but I don't see any reference in the provided link to them removing the distinction between URL and URI, only acknowledging the confusion and wanting specs that are incorrectly referencing URL to be updated to reference URI instead."]},{"answer":"URI, URL, URN\n\nAs the image above indicates, there are three distinct components at play here. It’s usually best to go to the source when discussing matters like these, so here’s an exerpt from Tim Berners-Lee, et. al. in RFC 3986: Uniform Resource Identifier (URI): Generic Syntax:\n\nA Uniform Resource Identifier (URI) is a compact sequence of characters that identifies an abstract or physical resource.\n\nA URI can be further classified as a locator, a name, or both. The term “Uniform Resource Locator” (URL) refers to the subset of URIs that, in addition to identifying a resource, provide a means of locating the resource by describing its primary access mechanism (e.g., its network “location”).\n\nShare\nImprove this answer\nFollow\nanswered Jun 2 '16 at 11:16\nAdiii\n37.8k6\n6 gold badges\n90\n90 silver badges\n95\n95 bronze badges","comments":[]},{"answer":"URI is kind of the super class of URL's and URN's. Wikipedia has a fine article about them with links to the right set of RFCs.\n\nShare\nImprove this answer\nFollow\nanswered Oct 6 '08 at 21:30\nAndré\n12.2k3\n3 gold badges\n30\n30 silver badges\n44\n44 bronze badges","comments":[]},{"answer":"Wikipedia will give all the information you need here. Quoting from http://en.wikipedia.org/wiki/URI:\n\nA URL is a URI that, in addition to identifying a resource, provides means of acting upon or obtaining a representation of the resource by describing its primary access mechanism or network \"location\".\n\nShare\nImprove this answer\nFollow\nedited Jun 17 '14 at 19:09\nAmal Murali\n71.2k17\n17 gold badges\n121\n121 silver badges\n140\n140 bronze badges\nanswered Oct 6 '08 at 21:30\nPeter Boughton\n103k30\n30 gold badges\n116\n116 silver badges\n173\n173 bronze badges","comments":[]},{"answer":"URL\n\nA URL is a specialization of URI that defines the network location of a specific resource. Unlike a URN, the URL defines how the resource can be obtained. We use URLs every day in the form of http://example.com etc. But a URL doesn't have to be an HTTP URL, it can be ftp://example.com etc., too.\n\nURI\n\nA URI identifies a resource either by location, or a name, or both. More often than not, most of us use URIs that defines a location to a resource. The fact that a URI can identify a resources by both name and location has lead to a lot of the confusion in my opinion. A URI has two specializations known as URL and URN.\n\nDifference between URL and URI\n\nA URI is an identifier for some resource, but a URL gives you specific information as to obtain that resource. A URI is a URL and as one commenter pointed out, it is now considered incorrect to use URL when describing applications. Generally, if the URL describes both the location and name of a resource, the term to use is URI. Since this is generally the case most of us encounter everyday, URI is the correct term.\n\nShare\nImprove this answer\nFollow\nedited Jun 17 '14 at 19:06\nAmal Murali\n71.2k17\n17 gold badges\n121\n121 silver badges\n140\n140 bronze badges\nanswered Sep 8 '12 at 8:17\nSujit\n3,4679\n9 gold badges\n38\n38 silver badges\n50\n50 bronze badges","comments":[]},{"answer":"A URI identifies a resource either by location, or a name, or both. More often than not, most of us use URIs that defines a location to a resource. The fact that a URI can identify a resources by both name and location has lead to a lot of the confusion in my opinion. A URI has two specializations known as URL and URN.\n\nA URL is a specialization of URI that defines the network location of a specific resource. Unlike a URN, the URL defines how the resource can be obtained. We use URLs every day in the form of http://stackoverflow.com, etc. But a URL doesn’t have to be an HTTP URL, it can be ftp://example.com, etc.\n\nShare\nImprove this answer\nFollow\nedited Mar 4 '15 at 21:03\nStephen Ostermiller\n18.8k8\n8 gold badges\n74\n74 silver badges\n95\n95 bronze badges\nanswered Dec 31 '09 at 7:51\nSwapnil\n1912\n2 silver badges\n5\n5 bronze badges","comments":[]},{"answer":"As per RFC 3986, URIs are comprised of the following pieces:\n\nscheme://authority/path?query\n\n\nThe URI describes the protocol for accessing a resource (path) or application (query) on a server (authority).\n\nAll the URLs are URIs, and all the URNs are URIs, but all the URIs are not URLs.\n\nPlease refer for more details:\n\nWikipedia\n\nShare\nImprove this answer\nFollow\nedited Jul 9 '16 at 17:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 28 '14 at 9:29\nPrashanth Sams\n13.5k16\n16 gold badges\n82\n82 silver badges\n109\n109 bronze badges","comments":["This doesn't teach me anything that's not covered by the other answers that are at least 6 years old, and which are much more complete and actually try to explain how to distinguish URIs from URLs.","It is important to note that the image is a Venn diagram even though it doesn't look like a typical one. I've seen people try to interpret it as \"parts of the URL\". This diagram does not say that URIs start with a URL and end with a URN."]},{"answer":"Although the terms URI and URL are strictly defined, many use the terms for other things than they are defined for.\n\nLet’s take Apache for example. If http://example.com/foo is requested from an Apache server, you’ll have the following environment variables set:\n\nREDIRECT_URL: /foo\nREQUEST_URI: /foo\n\nWith mod_rewrite enabled, you will also have these variables:\n\nREDIRECT_SCRIPT_URL: /foo\nREDIRECT_SCRIPT_URI: http://example.com/foo\nSCRIPT_URL: /foo\nSCRIPT_URI: http://example.com/foo\n\nThis might be the reason for some of the confusion.\n\nShare\nImprove this answer\nFollow\nanswered Dec 31 '09 at 9:57\nGumbo\n601k102\n102 gold badges\n743\n743 silver badges\n818\n818 bronze badges","comments":[]},{"answer":"See this document. Specifically,\n\na URL is a type of URI that identifies a resource via a representation of its primary access mechanism (e.g., its network \"location\"), rather than by some other attributes it may have.\n\nIt's not an extremely clear term, really.\n\nShare\nImprove this answer\nFollow\nanswered Dec 31 '09 at 6:33\navpx\n1,82215\n15 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"After reading through the posts, I find some very relevant comments. In short, the confusion between the URL and URI definitions is based in part on which definition depends on which and also informal use of the word URI in software development.\n\nBy definition URL is a subset of URI [RFC2396]. URI contain URN and URL. Both URI and URL each have their own specific syntax that confers upon them the status of being either URI or URL. URN are for uniquely identifying a resource while URL are for locating a resource. Note that a resource can have more than one URL but only a single URN.[RFC2611]\n\nAs web developers and programmers we will almost always be concerned with URL and therefore URI. Now a URL is specifically defined to have all the parts scheme:scheme-specific-part, like for example https://stackoverflow.com/questions. This is a URL and it is also a URI. Now consider a relative link embedded in the page such as ../index.html. This is no longer a URL by definition. It is still what is referred to as a \"URI-reference\" [RFC2396].\n\nI believe that when the word URI is used to refer to relative paths, \"URI-reference\" is actually what is being thought of. So informally, software systems use URI to refer to relative pathing and URL for the absolute address. So in this sense, a relative path is no longer a URL but still URI.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:47\nCommunity♦\n11\n1 silver badge\nanswered Oct 6 '12 at 20:05\npaul r\n1111\n1 silver badge\n3\n3 bronze badges","comments":[]},{"answer":"Here is my simplification:\n\nURN: unique resource name, i.e. \"what\" (eg urn:issn:1234-5678 ). This is meant to be unique .. as in no two different docs can have the same urn. A bit like \"uuid\"\n\nURL: \"where\" to find it ( eg https://google.com/pub?issnid=1234-5678 .. or ftp://somesite.com/doc8.pdf )\n\nURI: can be either a URN or a URL. This fuzzy definition is thanks to RFC 3986 produced by W3C and IETF.\n\nThe definition of URI has changed over the years, so it makes sense for most people to be confused. However, you can now take solace in the fact that you can refer to http://somesite.com/something as either a URL or URI ... an you will be right either way (at least fot the time being anyway...)\n\nShare\nImprove this answer\nFollow\nedited Jan 9 '13 at 14:26\nanswered Aug 29 '12 at 1:31\njjolla\n1011\n1 silver badge\n4\n4 bronze badges","comments":[]},{"answer":"I was wondering about the same thing and I've found this: http://docs.kohanaphp.com/helpers/url.\n\nYou can see a clear example using the url::current() method. If you have this URL: http://example.com/kohana/index.php/welcome/home.html?query=string then using url:current() gives you the URI which, according to the documentation, is: welcome/home\n\nShare\nImprove this answer\nFollow\nedited Apr 17 '15 at 10:08\ncommunity wiki\n\n\n3 revs, 3 users 71%\ndierre","comments":["This answer is wrong. A URI is not a portion of the URL. Rather URLs are a type of URI. Furthermore, the link in this answer is broken (and I can not find a suitable replacement.)"]},{"answer":"In order to answer this I'll lean on an answer I modified to another question. A good example of a URI is how you identify an Amazon S3 resource. Let's take:\n\ns3://www-example-com/index.html [fig. 1]\n\nwhich I created as a cached copy of\n\nhttp://www.example.com/index.html [fig. 2]\n\nin Amazon's S3-US-West-2 datacenter.\n\nEven if StackOverflow would allow me to hyperlink to the s3:// protocol scheme, it wouldn't do you any good in locating the resource. Because it Identifies a Resource, fig. 1 is a valid URI. It is also a valid URN, because Amazon requires that the bucket (their term for the authority portion of the URI) be unique across datacenters. It is helpful in locating it, but it does not indicate the datacenter. Therefore it does not work as a URL.\n\nSo, how do URI, URL, and URN differ in this case?\n\nfig. 1 is a URI\nfig. 1 is a URN\nfig. 2 is a URI\nfig. 2 is a URL\nThe URL for fig. 1 is http://www-example-com.s3-website-us-west-2.amazonaws.com/\nalso http://www-example-com.s3.amazonaws.com/index.html\nbut not http://www-example-com.s3.amazonaws.com/ (no datacenter and no filename is too generic for Amazon S3)\n\nNOTE: RFC 3986 defines URIs as scheme://authority/path?query#fragment\n\nShare\nImprove this answer\nFollow\nedited Oct 2 '17 at 3:16\nanswered Mar 10 '15 at 18:24\nBruno Bronosky\n55.7k10\n10 gold badges\n135\n135 silver badges\n123\n123 bronze badges","comments":[]},{"answer":"URIs came about from the need to identify resources on the Web, and other Internet resources such as electronic mailboxes in a uniform and coherent way. So, one can introduce a new type of widget: URIs to identify widget resources or use tel: URIs to have web links cause telephone calls to be made when invoked.\n\nSome URIs provide information to locate a resource (such as a DNS host name and a path on that machine), while some are used as pure resource names. The URL is reserved for identifiers that are resource locators, including 'http' URLs such as http://stackoverflow.com, which identifies the web page at the given path on the host. Another example is 'mailto' URLs, such as mailto:fred@mail.org, which identifies the mailbox at the given address.\n\nURNs are URIs that are used as pure resource names rather than locators. For example, the URI: mid:0E4FC272-5C02-11D9-B115-000A95B55BC8@stackoverflow.com is a URN that identifies the email message containing it in its 'Message-Id' field. The URI serves to distinguish that message from any other email message. But it does not itself provide the message's address in any store.\n\nShare\nImprove this answer\nFollow\nanswered Mar 10 '12 at 17:30\ndpant\n1,38513\n13 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"The best (technical) summary imo is this one\n\nIRI, URI, URL, URN and their differences from Jan Martin Keil:\n\nIRI, URI, URL, URN and their differences\n\nEverybody dealing with the Semantic Web repeatedly comes across the terms IRI, URI, URL and URN. Nevertheless, I frequently observe that there is some confusion about their exact meaning. And, of course, others noticed that as well (see e.g. RFC3305 or search on Google). To be honest, I even was confused myself at the outset. But actually the issue is not that complex. Let’s have a look on the definitions of the mentioned terms to see what the differences are:\n\nURI\n\nA Uniform Resource Identifier is a compact sequence of characters that identifies an abstract or physical resource. The set of characters is limited to US-ASCII excluding some reserved characters. Characters outside the set of allowed characters can be represented using Percent-Encoding. A URI can be used as a locator, a name, or both. If a URI is a locator, it describes a resource’s primary access mechanism. If a URI is a name, it identifies a resource by giving it a unique name. The exact specifications of syntax and semantics of a URI depend on the used Scheme that is defined by the characters before the first colon. [RFC3986]\n\nURN\n\nA Uniform Resource Name is a URI in the scheme urn intended to serve as persistent, location-independent, resource identifier. Historically, the term also referred to any URI. [RFC3986] A URN consists of a Namespace Identifier (NID) and a Namespace Specific String (NSS): urn:: The syntax and semantics of the NSS is specific specific for each NID. Beside the registered NIDs, there exist several more NIDs, that did not go through the official registration process. [RFC2141]\n\nURL\n\nA Uniform Resource Locator is a URI that, in addition to identifying a resource, provides a means of locating the resource by describing its primary access mechanism [RFC3986]. As there is no exact definition of URL by means of a set of Schemes, \"URL is a useful but informal concept\", usually referring to a subset of URIs that do not contain URNs [RFC3305].\n\nIRI\n\nAn Internationalized Resource Identifier is defined similarly to a URI, but the character set is extended to the Universal Coded Character Set. Therefore, it can contain any Latin and non Latin characters except the reserved characters. Instead of extending the definition of URI, the term IRI was introduced to allow for a clear distinction and avoid incompatibilities. IRIs are meant to replace URIs in identifying resources in situations where the Universal Coded Character Set is supported. By definition, every URI is an IRI. Furthermore, there is a defined surjective mapping of IRIs to URIs: Every IRI can be mapped to exactly one URI, but different IRIs might map to the same URI. Therefore, the conversion back from a URI to an IRI may not produce the original IRI. [RFC3987]\n\nSummarizing we can say:\nIRI is a superset of URI (IRI ⊃ URI)\nURI is a superset of URL (URI ⊃ URL)\nURI is a superset of URN (URI ⊃ URN)\nURL and URN are disjoint (URL ∩ URN = ∅)\n\nConclusions for Semantic Web Issues\n\nRDF explicitly allows to use IRIs to name entities [RFC3987]. This means that we can use almost every character in entity names. On the other hand, we often have to deal with early state software. Thus, it is not unlikely to run into problems using non ASCII characters. Therefore, I suggest to avoid non URI names for entities and recommend to use http URIs [LINKED-DATA]. To put it briefly: only use URLs to name your entities. Of course, we can refer to existing entities named by a URN. However, we should avoid to newly create this kind of identifiers.\n\nShare\nImprove this answer\nFollow\nanswered Apr 5 '20 at 11:37\nMischa\n5486\n6 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"Easy to explain:\n\nLets assume the following\n\nURI is your Name\n\nURL is your address with your name in-order to communicate with you.\n\nmy name is Loyola\n\nLoyola is URI\n\nmy address is TN, Chennai 600001.\n\nTN, Chennai 600 001, Loyola is URL\n\nHope you understand,\n\nNow lets see a precise example\n\nhttp://www.google.com/fistpage.html\n\nin the above you can communicate with a page called firstpage.html (URI) using following http://www.google.com/fistpage.html(URL).\n\nHence URI is subset of URL but not vice-versa.\n\nShare\nImprove this answer\nFollow\nedited Mar 18 '15 at 9:08\nanswered Feb 10 '15 at 10:09\nloyola\n3,4052\n2 gold badges\n21\n21 silver badges\n18\n18 bronze badges","comments":["This answer is misleading. Quote from Wikipedia \"A Uniform Resource Name (URN) functions like a person's name, while a Uniform Resource Locator (URL) resembles that person's street address. In other words: the URN defines an item's identity, while the URL provides a method for finding it.\" Also both URNs and URLs are URIs."]},{"answer":"I found:\n\nA uniform resource identifier(URI) represents something of a big picture. You can split URIs/ URIs can be classified as locators (uniform resource locators- URL), or as names (uniform resource name-URN), or either both. So basically, a URN functions like a person's name and the URL depicts that person's address. So long story short, a URN defines an item's identity, while the URL provides defines the method for finding it, finally encapsulating these two concepts is the URI\n\nShare\nImprove this answer\nFollow\nedited Jul 9 '16 at 17:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 11 '13 at 4:41\nRakeeb Rajbhandari\n4,9036\n6 gold badges\n41\n41 silver badges\n74\n74 bronze badges","comments":[]},{"answer":"The answer is ambiguous. In Java it is frequently used in this way:\n\nAn Uniform Resource Locator (URL) is the term used to identify an Internet resource including the scheme( http, https, ftp, news, etc.). For instance What is the difference between a URI, a URL and a URN?\n\nAn Uniform Resource Identifier (URI) is used to identify a single document in the Web Server: For instance /questions/176264/whats-the-difference-between-a-uri-and-a-url\n\nIn Java servlets, the URI frequently refers to the document without the web application context.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:10\nCommunity♦\n11\n1 silver badge\nanswered Apr 27 '11 at 9:09\nFreeman\n5,2762\n2 gold badges\n41\n41 silver badges\n46\n46 bronze badges","comments":["This is the difference between an absolute and a relative URL. It doesn't explain the relation of URI vs. URL and URN.","Actually, these are accurate examples. On the Web, this is very often the difference."]}]},{"id":"4089430","href":"https://stackoverflow.com/questions/4089430/how-can-i-determine-the-url-that-a-local-git-repository-was-originally-cloned-fr","title":"How can I determine the URL that a local Git repository was originally cloned from?","description":"\n                \nI pulled a project from GitHub a few days ago. I've since discovered that there are several forks on GitHub, and I neglected to note which one I took originally. How can I determine which of those forks I pulled?\n    ","questionComments":["With git 2.7 (Q4 2015), git remote get-url origin will be possible. See my answer below","codingaffairs.blogspot.com/2017/01/…","git remote get-url origin does not work for me--possibly deprecated? git remote show origin worked though.","git remote -v give you a lot of information, including this.","git remote get-url origin --push works fine, apparently not depreciated and provides nice brief info (git remote show origin can be very verbose) q.v. git help remote."],"answers":[{"answer":"If you want only the remote URL, or if your are not connected to a network that can reach the remote repo:\n\ngit config --get remote.origin.url\n\n\nIf you require full output and you are on a network that can reach the remote repo where the origin resides :\n\ngit remote show origin\n\n\nWhen using git clone (from GitHub, or any source repository for that matter) the default name for the source of the clone is \"origin\". Using git remote show will display the information about this remote name. The first few lines should show:\n\nC:\\Users\\jaredpar\\VsVim> git remote show origin\n* remote origin\n  Fetch URL: git@github.com:jaredpar/VsVim.git\n  Push  URL: git@github.com:jaredpar/VsVim.git\n  HEAD branch: master\n  Remote branches:\n\n\nIf you want to use the value in the script, you would use the first command listed in this answer.\n\nShare\nImprove this answer\nFollow\nedited Aug 13 '19 at 8:16\nRob Kielty\n7,5327\n7 gold badges\n36\n36 silver badges\n50\n50 bronze badges\nanswered Nov 3 '10 at 16:50\nJaredPar\n681k139\n139 gold badges\n1192\n1192 silver badges\n1424\n1424 bronze badges","comments":["Use git config as described below instead if using jgit with amazon-s3.","Although not relevant to the purpose of the original question, please note that if attempting to get the \"Push URL\" and multiple URLs are entered for the remote specified, you'll either need to use git remote show origin (optionally with the -n flag provided by @Casey), or with git remote -v as suggested by @Montaro and @rodel.","What file is this written to? I thought the .gitconfig file would have it, but I didn't see it in mine.","@ayjay ´~/.gitconfig is global to all git repositories, this here comes from the local config which usually is in .git/config (however for git-submodules the answer is a bit more difficult). Note that strace git config --get remote.origin.url is your friend.","But the original URL doesn't have to be the URL of the currently used remote. To show the actual used URL, you would need this solution then: stackoverflow.com/a/40630957/1069083"]},{"answer":"Should you want this for scripting purposes, you can get only the URL with\n\ngit config --get remote.origin.url\n\nShare\nImprove this answer\nFollow\nedited Feb 17 '15 at 19:34\nthe Tin Man\n152k39\n39 gold badges\n199\n199 silver badges\n279\n279 bronze badges\nanswered Nov 3 '10 at 19:35\nCascabel\n430k65\n65 gold badges\n358\n358 silver badges\n309\n309 bronze badges","comments":["This is the correct answer. It is way faster and it even works, if the remote url is not available anymore (git remote show origin just shows \"conq: repository does not exist.\").","This is not quite the right answer because of the config option url.<base>.insteadOf. See my answer - git has a command for this purpose.","@arcresu Cool, +1 to you! In my defense, that command wasn't added until March 2011, and it wasn't documented until September 2012.","@Catskul Only --git-dir is relevant (the config is in the git dir, independent of work tree location), and it does work for me. Are you sure you specified the path to the actual .git dir, not its parent directory?"]},{"answer":"You can try:\n\ngit remote -v\n\n\nIt will print all your remotes' fetch/push URLs.\n\nShare\nImprove this answer\nFollow\nedited Feb 24 '15 at 4:19\nanswered Jan 29 '12 at 12:01\nMontaro\n7,7705\n5 gold badges\n26\n26 silver badges\n30\n30 bronze badges","comments":["It's also usually used as short for -verbose","@Montaro exactly, without it, only the name of the remote is printed (e.g. origin)."]},{"answer":"To get the answer:\n\ngit ls-remote --get-url [REMOTE]\n\n\nThis is better than reading the configuration; refer to the man page for git-ls-remote:\n\n--get-url\n\nExpand the URL of the given remote repository taking into account any \"url.<base>.insteadOf\" config setting (See git-config(1)) and exit without talking to the remote.\n\nAs pointed out by @Jefromi, this option was added in v1.7.5 and not documented until v1.7.12.2 (2012-09).\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '18 at 20:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 2 '13 at 5:15\nCarl Suster\n5,1782\n2 gold badges\n20\n20 silver badges\n36\n36 bronze badges","comments":["good one : this also would provide the same for previous versions > git remote -v| grep fetch|awk '{print $2}'","I think most of the other answers are more of a show-and-tell about git commands and exposition about git history. This is the only answer that doesn't assume your upstream is called origin.","This is the most direct replacement for the old remote get-url option. It's a drop-in replacement."]},{"answer":"With Git 2.7 (release January 5th, 2015), you have a more coherent solution using git remote:\n\ngit remote get-url origin\n\n\n(nice pendant of git remote set-url origin <newurl>)\n\nSee commit 96f78d3 (16 Sep 2015) by Ben Boeckel (mathstuf).\n(Merged by Junio C Hamano -- gitster -- in commit e437cbd, 05 Oct 2015):\n\nremote: add get-url subcommand\n\nExpanding insteadOf is a part of ls-remote --url and there is no way to expand pushInsteadOf as well.\nAdd a get-url subcommand to be able to query both as well as a way to get all configured URLs.\n\nget-url:\n\n\nRetrieves the URLs for a remote.\nConfigurations for insteadOf and pushInsteadOf are expanded here.\nBy default, only the first URL is listed.\n\nWith '--push', push URLs are queried rather than fetch URLs.\nWith '--all', all URLs for the remote will be listed.\n\nBefore git 2.7, you had:\n\n git config --get remote.[REMOTE].url\n git ls-remote --get-url [REMOTE]\n git remote show [REMOTE]\n\nShare\nImprove this answer\nFollow\nedited Jan 5 '16 at 8:03\nanswered Oct 7 '15 at 12:07\nVonC\n1.1m448\n448 gold badges\n3731\n3731 silver badges\n4386\n4386 bronze badges","comments":["After 5 years a lot has changed and this should be the accepted answer now. But maybe add the pre-2.7 syntax as well."]},{"answer":"To summarize, there are at least four ways:\n\n(The following was tried for the official Linux repository)\n\nLeast information:\n$ git config --get remote.origin.url\nhttps://github.com/torvalds/linux.git\n\n\nand\n\n$ git ls-remote --get-url\nhttps://github.com/torvalds/linux.git\n\nMore information:\n$ git remote -v\norigin    https://github.com/torvalds/linux.git (fetch)\norigin    https://github.com/torvalds/linux.git (push)\n\nEven more information:\n$ git remote show origin\n* remote origin\n  Fetch URL: https://github.com/torvalds/linux.git\n  Push  URL: https://github.com/torvalds/linux.git\n  HEAD branch: master\n  Remote branch:\n    master tracked\n  Local branch configured for 'git pull':\n    master merges with remote master\n  Local ref configured for 'git push':\n    master pushes to master (up to date)\n\nShare\nImprove this answer\nFollow\nedited Mar 16 at 2:54\nanswered May 15 '14 at 15:28\nnonopolarity\n133k120\n120 gold badges\n419\n419 silver badges\n684\n684 bronze badges","comments":["Note git config --get remote.origin.url retrieves the original URL which was set with git remote add ... or git remote set-url ... while git ls-remote --get-url origin retrieves the URL which is actually used to access the remote - which might be different in presence of git config --global url.XXX.insteadOf YYY. So both outputs may differ! Also note that git ls-remote --get-url (without origin) does not neccessarily retrieve origin, instead it shows the tracked upstream, so it will fail for example in detached HEAD state."]},{"answer":"I think you can find it under .git/config and remote[\"origin\"] if you didn't manipulate that.\n\nShare\nImprove this answer\nFollow\nanswered Nov 3 '10 at 16:50\nmeder omuraliev\n174k65\n65 gold badges\n373\n373 silver badges\n423\n423 bronze badges","comments":[]},{"answer":"For me, this is the easier way (less typing):\n\n$ git remote -v\norigin    https://github.com/torvalds/linux.git (fetch)\norigin    https://github.com/torvalds/linux.git (push)\n\n\nactually, I've that into an alias called s that does:\n\ngit remote -v\ngit status\n\n\nYou can add to your profile with: alias s='git remote -v && git status'\n\nShare\nImprove this answer\nFollow\nanswered Feb 11 '19 at 18:39\nCode Knox\n9548\n8 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"Short answer:\n\n$ git remote show -n origin\n\n\nor, an alternative for pure quick scripts:\n\n$ git config --get remote.origin.url\n\n\nSome info:\n\n$ git remote -v will print all remotes (not what you want). You want origin right?\n$ git remote show origin much better, shows only origin but takes too long (tested on git version 1.8.1.msysgit.1).\n\nI ended up with: $ git remote show -n origin, which seems to be fastest. With -n it will not fetch remote heads (AKA branches). You don't need that type of info, right?\n\nhttp://www.kernel.org/pub//software/scm/git/docs/git-remote.html\n\nYou can apply | grep -i fetch to all three versions to show only the fetch URL.\n\nIf you require pure speed, then use:\n\n$ git config --get remote.origin.url\n\n\nThanks to @Jefromi for pointing that out.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:18\nCommunity♦\n11\n1 silver badge\nanswered Feb 27 '13 at 18:11\nCasey\n1,2621\n1 gold badge\n16\n16 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"I can never remember all the parameters to Git commands, so I just put an alias in the ~/.gitconfig file that makes more sense to me, so I can remember it, and it results in less typing:\n\n[alias]\nurl = ls-remote --get-url\n\n\nAfter reloading the terminal, you can then just type:\n\n> git url\n\n\nHere are a few more of my frequently used ones:\n\n[alias]\ncd = checkout\nls = branch\nlsr = branch --remote\nlst = describe --tags\n\n\nI also highly recommend git-extras which has a git info command which provides much more detailed information on the remote and local branches.\n\nShare\nImprove this answer\nFollow\nedited Oct 4 '19 at 13:56\nanswered Jan 14 '18 at 19:57\nWhat Would Be Cool\n4,7414\n4 gold badges\n42\n42 silver badges\n41\n41 bronze badges","comments":["I like this a lot!","Nice aliases, I love how they meld very naturally with bash commands. I can see this being causing the least amount of mental friction when switching between bash and git. Bravo!"]},{"answer":"I prefer this one as it is easier to remember:\n\ngit config -l\n\n\nIt will list all useful information such as:\n\nuser.name=Your Name\nuser.email=your.name@notexisting.com\ncore.autocrlf=input\ncore.repositoryformatversion=0\ncore.filemode=true\ncore.bare=false\ncore.logallrefupdates=true\nremote.origin.url=https://github.com/mapstruct/mapstruct-examples\nremote.origin.fetch=+refs/heads/*:refs/remotes/origin/*\nbranch.master.remote=origin\nbranch.master.merge=refs/heads/master\n\nShare\nImprove this answer\nFollow\nanswered Feb 12 '20 at 9:55\nWitold Kaczurba\n8,1812\n2 gold badges\n49\n49 silver badges\n55\n55 bronze badges","comments":[]},{"answer":"The Git URL will be inside the Git configuration file. The value corresponds to the key url.\n\nFor Mac and Linux use the commands below:\n\n cd project_dir\n cat .git/config | grep url | awk '{print $3}'\n\n\nFor Windows open the below file in any text editor and find the value for key url.\n\nproject_dir/.git/config\n\n\nNote: This will work even if you are offline or the remote git server has been taken down.\n\nShare\nImprove this answer\nFollow\nedited May 10 '19 at 9:26\nanswered Sep 21 '17 at 10:50\nHarikrishnan\n8,7639\n9 gold badges\n77\n77 silver badges\n121\n121 bronze badges","comments":["This is what worked for me once the remote server that hosted the original checkout was taken down. All the other attempts failed: git remote get-url origin >> fatal: No such remote 'origin', git config --get remote.origin.url >>"]},{"answer":"I basically use:\n\ngit remote get-url origin\n\n\nIt works for Git Bash command console or CMD command console in Windows. That said, it works with version 2.x of Git.\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '18 at 20:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 10 '17 at 19:16\nmaytham-ɯɐɥʇʎɐɯ\n22.4k10\n10 gold badges\n88\n88 silver badges\n110\n110 bronze badges","comments":[]},{"answer":"git config --list\n\n\nThis command will give all information related to your repository.\n\nShare\nImprove this answer\nFollow\nanswered May 28 '19 at 7:20\nKasthuri Shravankumar\n3092\n2 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"The upstream's remote may not be called \"origin\", so here's a variation:\n\nremote=$(git config --get branch.master.remote)\nurl=$(git config --get remote.$remote.url)\nbasename=$(basename \"$url\" .git)\necho $basename\n\n\nOr:\n\nbasename $(git config --get remote.$(git config --get branch.master.remote).url) .git\n\n\nFor more useful variables there's:\n\n$ git config -l\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '18 at 20:05\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 19 '13 at 20:49\ncagney\n4183\n3 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"To get the IP address/hostname of origin\n\nFor ssh:// repositories:\n\ngit ls-remote --get-url origin | cut -f 2 -d @ | cut -f 1 -d \"/\"\n\n\nFor git:// repositories:\n\ngit ls-remote --get-url origin | cut -f 2 -d @ | cut -f 1 -d \":\"\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jun 24 '14 at 20:54\nStephen\n7,9177\n7 gold badges\n38\n38 silver badges\n67\n67 bronze badges","comments":["For ssh this only works in absence of ~/.ssh/config which rewrites the hostname or alias."]},{"answer":"To supplement the other answers: If the remote has for some reason been changed and so doesn't reflect the original origin, the very first entry in the reflog (i.e. the last entry displayed by the command git reflog) should indicate where the repo was originally cloned from.\n\ne.g.\n\n$ git reflog | tail -n 1\nf34be46 HEAD@{0}: clone: from https://github.com/git/git\n$\n\n\n(Bear in mind that the reflog may be purged, so this isn't guaranteed to work.)\n\nShare\nImprove this answer\nFollow\nanswered Nov 16 '15 at 12:58\nJeremy\n4,53724\n24 silver badges\n40\n40 bronze badges","comments":["This is probably the only real way to get the \"original\" remote if it has been changed."]},{"answer":"With git remote show origin you have to be in the projects directory. But if you want to determine the URLs from anywhere else you could use:\n\ncat <path2project>/.git/config | grep url\n\n\nIf you'll need this command often, you could define an alias in your .bashrc or .bash_profile with MacOS.\n\nalias giturl='cat ./.git/config | grep url'\n\n\nSo you just need to call giturl in the Git root folder in order to simply obtain its URL.\n\nIf you extend this alias like this\n\nalias giturl='cat .git/config | grep -i url | cut -d'=' -f 2'\n\n\nyou get only the plain URL without the preceding\n\n\"url=\"\n\nin\n\nurl=http://example.com/repo.git\n\nyou get more possibilities in its usage:\n\nExample\n\nOn Mac you could call open $(giturl) to open the URL in the standard browser.\n\nOr chrome $(giturl) to open it with the Chrome browser on Linux.\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '18 at 8:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 21 '15 at 8:41\nSedat Kilinc\n2,7351\n1 gold badge\n20\n20 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"A simple way is to open the .git/config file:\n\ncat .git/config\n\n\nTo edit:\n\nvim .git/config or\n\nnano .git/config\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '18 at 20:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 1 '17 at 11:05\nOmar Makled\n1,0481\n1 gold badge\n13\n13 silver badges\n16\n16 bronze badges","comments":["This presumes you are on Linux(?)."]},{"answer":"Print arbitrarily named remote fetch URLs:\n\ngit remote -v | grep fetch | awk '{print $2}'\n\nShare\nImprove this answer\nFollow\nedited Sep 1 '15 at 14:34\nanswered Jan 20 '13 at 23:51\nAron\n811\n1 silver badge\n5\n5 bronze badges","comments":[]},{"answer":"You cloned your repo with SSH clone.\n\ngit config --get remote.origin.url\ngit@gitlab.com:company/product/production.git\n\n\nBut you want to get http url to open it in the browser or share it:\n\ngit config --get remote.origin.url | sed -e 's/:/\\//g'| sed -e 's/ssh\\/\\/\\///g'| sed -e 's/git@/https:\\/\\//g'\n\nhttps://gitlab.com/company/product/production.git\n\n\nGitHub or GitLab doesn’t matter.\n\nShare\nImprove this answer\nFollow\nedited Nov 4 '20 at 14:03\nanswered Sep 15 '20 at 18:27\nAidar Gatin\n5296\n6 silver badges\n7\n7 bronze badges","comments":["Useful! Doesn't work on https urls though. This one is universal, works for both git@... and https://...: git config --get remote.origin.url | sed -E 's/:([^\\/])/\\/\\1/g' | sed -e 's/ssh\\/\\/\\///g' | sed -e 's/git@/https:\\/\\//g'","If I want an add /pulls for this regex how can I do this @aidargatin"]},{"answer":"If you do not know the name of the upstream remote for a branch, you can look that up first by inspecting the upstream branch name that the current branch was built upon. Use git rev-parse like this:\n\ngit rev-parse --symbolic-full-name --abbrev-ref @{upstream}\n\n\nThis shows that upstream branch that was the source for the current branch. This can be parsed to get the remote name like this:\n\ngit rev-parse --symbolic-full-name --abbrev-ref @{upstream} | cut -d / -f 1\n\n\nNow take that and pipe it to git ls-remote and you'll get the URL of the upstream remote that is the source of the current branch:\n\ngit ls-remote --get-url \\\n  $(git rev-parse --symbolic-full-name --abbrev-ref @{upstream} | cut -d / -f 1)\n\n\nNow it should be noted, that this is not necessarily the same as the source remote repository that was cloned from. In many cases however it will be enough.\n\nShare\nImprove this answer\nFollow\nanswered Aug 9 '17 at 0:38\nChristopher\n1,79616\n16 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"#!/bin/bash\n\ngit-remote-url() {\n local rmt=$1; shift || { printf \"Usage: git-remote-url [REMOTE]\\n\" >&2; return 1; }\n local url\n\n if ! git config --get remote.${rmt}.url &>/dev/null; then\n  printf \"%s\\n\" \"Error: not a valid remote name\" && return 1\n  # Verify remote using 'git remote -v' command\n fi\n\n url=`git config --get remote.${rmt}.url`\n\n # Parse remote if local clone used SSH checkout\n [[ \"$url\" == git@* ]] \\\n && { url=\"https://github.com/${url##*:}\" >&2; }; \\\n { url=\"${url%%.git}\" >&2; };\n\n printf \"%s\\n\" \"$url\"\n}\n\n\nUsage:\n\n# Either launch a new terminal and copy `git-remote-url` into the current shell process, \n# or create a shell script and add it to the PATH to enable command invocation with bash.\n\n# Create a local clone of your repo with SSH, or HTTPS\ngit clone git@github.com:your-username/your-repository.git\ncd your-repository\n\ngit-remote-url origin\n\n\nOutput:\n\nhttps://github.com/your-username/your-repository\n\nShare\nImprove this answer\nFollow\nedited Feb 1 '18 at 21:56\nanswered Jan 3 '18 at 3:35\necwpz91\n1,01911\n11 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"easy just use this command where you .git folder placed\n\ngit config --get remote.origin.url\n\nif you are connected to network\n\ngit remote show origin\n\nit will show you the URL that a local Git repository was originally cloned from.\n\nhope this help\n\nShare\nImprove this answer\nFollow\nanswered Jan 14 '20 at 10:47\nAli Raza\n4193\n3 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"To get only the remote URL:\n\ngit config --get remote.origin.url\n\n\nIn order to get more details about a particular remote, use the\n\ngit remote show [remote-name] command\n\n\nTo See Remote Url\n\ngit remote show origin\n\n\nTo See where you .git folder placed\n\ngit config --get remote.origin.url\n\nShare\nImprove this answer\nFollow\nanswered Mar 20 at 18:51\nßãlãjî\n3,3073\n3 gold badges\n16\n16 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"alias git-repo=\"git config --get remote.origin.url | sed -e 's/:/\\//g'| sed -e 's/ssh\\/\\/\\///g'| sed -e 's/git@/https:\\/\\//g'\"\nalias git-pr=\"git config --get remote.origin.url | sed -e 's/:/\\//g'| sed -e 's/ssh\\/\\/\\///g'| sed -e 's/git@/https:\\/\\//g' | sed 's/....$//' | sed -ne 's/$/\\/pulls &/p'\"\n\n\nadd this expresion to .zshrc or .bashrcs on main directory\n\nafter you can use like\n\ngit-repo\ngit-pr\n\nShare\nImprove this answer\nFollow\nedited Feb 27 at 3:54\nanswered Feb 27 at 3:36\nHasan Tezcan\n5523\n3 silver badges\n11\n11 bronze badges","comments":[]}]},{"id":"1628088","href":"https://stackoverflow.com/questions/1628088/reset-local-repository-branch-to-be-just-like-remote-repository-head","title":"Reset local repository branch to be just like remote repository HEAD","description":"\n                \nHow do I reset my local branch to be just like the branch on the remote repository?\n\nI did:\n\ngit reset --hard HEAD\n\n\nBut when I run a git status,\n\nOn branch master\nChanges to be committed:\n  (use \"git reset HEAD <file>...\" to unstage)\n      modified:   java/com/mycompany/TestContacts.java\n      modified:   java/com/mycompany/TestParser.java\n\n\nCan you please tell me why I have these 'modified'? I haven't touched these files? If I did, I want to remove those.\n    ","questionComments":["According to the output of git status your second command git reset --hard HEAD failed. You didn’t paste it’s output, though. → Incomplete question.","You are mixing two issues here: 1) how to reset a local branch to the point where the remote is and 2) how to clear your staging area (and possibly the working directory), so that git status says nothing to commit, working directory clean. – Please specify!","Does this answer your question? How do I force \"git pull\" to overwrite local files?","Obviously not an answer if the repo is large, but for small repos you can hit it with a hammer and avoid git entirely: rm -fr ./repo; git clone repo. best way i've found"],"answers":[{"answer":"Setting your branch to exactly match the remote branch can be done in two steps:\n\ngit fetch origin\ngit reset --hard origin/master\n\n\nIf you want to save your current branch's state before doing this (just in case), you can do:\n\ngit commit -a -m \"Saving my work, just in case\"\ngit branch my-saved-work\n\n\nNow your work is saved on the branch \"my-saved-work\" in case you decide you want it back (or want to look at it later or diff it against your updated branch).\n\nNote that the first example assumes that the remote repo's name is \"origin\" and that the branch named \"master\" in the remote repo matches the currently checked-out branch in your local repo.\n\nBTW, this situation that you're in looks an awful lot like a common case where a push has been done into the currently checked out branch of a non-bare repository. Did you recently push into your local repo? If not, then no worries -- something else must have caused these files to unexpectedly end up modified. Otherwise, you should be aware that it's not recommended to push into a non-bare repository (and not into the currently checked-out branch, in particular).\n\nShare\nImprove this answer\nFollow\nedited Aug 11 at 21:07\nHerohtar\n4,5923\n3 gold badges\n28\n28 silver badges\n33\n33 bronze badges\nanswered Oct 27 '09 at 1:44\nDan Moulding\n187k21\n21 gold badges\n89\n89 silver badges\n97\n97 bronze badges","comments":["Thank you for your answer. You said 'Note that the first example assumes that the remote repo's name is \"origin\" and that the branch named \"master\" in the remote repo matches the branch in your local repo.' How can I double check my remote repo's name and my branch name to be sure before I execute 'git reset --hard'? Thanks again.","If you didn't explicitly name the remote, then it's name is likely just \"origin\" (the default). You can use \"git remote\" to get a list of all remote names. You can then use \"git remote <name>\" to see which branches push/pull with each other (e.g. if your \"master\" branch was cloned from \"master\" in the remote named \"origin\", then you'll get a line that says \"master merges with remote master\").","\"it's not recommended to push into a non-bare repository (and not into the currently checked-out branch, in particular\" Why is that?","Just after fetching, I believe you can do git reset FETCH_HEAD --hard instead, as well, that's the same meaning.","It did not remove files I have added."]},{"answer":"I needed to do (the solution in the accepted answer):\n\ngit fetch origin\ngit reset --hard origin/master\n\n\nFollowed by:\n\ngit clean -f\n\n\nto remove local files\n\nTo see what files will be removed (without actually removing them):\n\ngit clean -n -f\n\nShare\nImprove this answer\nFollow\nedited Jun 22 '17 at 17:59\nanswered Dec 27 '14 at 6:20\nAkavall\n69.8k40\n40 gold badges\n182\n182 silver badges\n231\n231 bronze badges","comments":["also, git clean -d -f if there are untracked directories present.","also git clean -fdx","If you want exact copy of remote branch you have to follow by git clean -ffdx. Note that thare are two f.","The git clean -f was the essential piece I needed. Thanks!","be careful using the clean command. it can delete ignored files from other branches."]},{"answer":"First, use git reset to reset to the previously fetched HEAD of the corresponding upstream branch:\n\ngit reset --hard @{u}\n\n\nThe advantage of specifying @{u} or its verbose form @{upstream} is that the name of the remote repo and branch don't have to be explicitly specified. On Windows or with PowerShell, specify \"@{u}\" (with double quotes).\n\nNext, as needed, use git clean to remove untracked files, optionally also with -x:\n\ngit clean -df\n\n\nFinally, as needed, get the latest changes:\n\ngit pull\n\nShare\nImprove this answer\nFollow\nedited Nov 10 '20 at 15:03\nanswered Feb 10 '15 at 20:27\nAsclepius\n43.4k14\n14 gold badges\n122\n122 silver badges\n111\n111 bronze badges","comments":["This seems like a better answer than the accepted one, because it dynamically resets to the current upstream branch rather than always a static one such as origin/master","@GangadharJannu git reset --hard requires a commit, else it wouldn't know what to reset you to. @{u} points to a specific commit – the head of the tracked branch, from when you last did a git fetch.","@KristofferBakkejord Thanks for the explanation but even without commit hash we can do git reset --hard though it will not reset to remote branch","For anyone else who almost opened a new question here, if you git from Powershell, use quotes (git reset --hard \"@{u}\"). Took me a while to figure that out.","@MPStoering using the quotes also worked for me in git bash on Windows. Cheers"]},{"answer":"git reset --hard HEAD actually only resets to the last committed state. In this case HEAD refers to the HEAD of your branch.\n\nIf you have several commits, this won't work..\n\nWhat you probably want to do, is reset to the head of origin or whatever you remote repository is called. I'd probably just do something like\n\ngit reset --hard origin/HEAD\n\n\nBe careful though. Hard resets cannot easily be undone. It is better to do as Dan suggests, and branch off a copy of your changes before resetting.\n\nShare\nImprove this answer\nFollow\nedited Oct 27 '09 at 9:49\nanswered Oct 27 '09 at 1:08\nMikael Ohlson\n2,2131\n1 gold badge\n20\n20 silver badges\n25\n25 bronze badges","comments":["There was an incorrect suggestion in my answer that Dan caught earlier. I edited it away, since I don't want to lead anyone astray. As to the origin/master or origin/HEAD stuff, I expect that depends on whether or not you actually do a fetch first. If you just cloned origin, and it had no other branches, which I find to be quite common, then it should reset it fine. But of course, Dan is right."]},{"answer":"All of the above suggests are right, but often to really reset your project, you also need to remove even files that are in your .gitignore.\n\nTo get the moral equivalent of erasing your project directory and re-cloning from the remote is:\n\ngit fetch\ngit reset --hard\ngit clean -x -d -f\n\n\nWarning: git clean -x -d -f is irreversible and you may lose files and data (e.g. things you have ignored using .gitignore).\n\nShare\nImprove this answer\nFollow\nedited Feb 6 '18 at 21:46\nCharlie Collins\n8,5664\n4 gold badges\n30\n30 silver badges\n41\n41 bronze badges\nanswered Jul 23 '15 at 17:48\nChristopher Smith\n5,0171\n1 gold badge\n30\n30 silver badges\n18\n18 bronze badges","comments":["Warning: \"git clean -x -d -f\" is irreversible and you may loose files and data in .gitignore","A little shorter: git clean -xdf that is equal to git clean -x -d -f.","git clean -ffxd to remove everything not in the repo"]},{"answer":"Use the commands below. These commands will remove all untracked files from local git too\n\ngit fetch origin\ngit reset --hard origin/master\ngit clean -d -f\n\nShare\nImprove this answer\nFollow\nedited Aug 9 '19 at 18:43\nCharlie Wallace\n1,6841\n1 gold badge\n14\n14 silver badges\n17\n17 bronze badges\nanswered Mar 22 '19 at 10:19\nJamsheer\n3,2313\n3 gold badges\n24\n24 silver badges\n50\n50 bronze badges","comments":["This is a more complete response because without the git clean -d -f we'll still had some things of the old branch in local directory. Thanks man.","This is what ACTUALLY makes it to be just like the remote. The clean is important.","git clean -ffxd to truely remove everything","This is exactly what I needed. Thanks"]},{"answer":"The question mixes two issues here:\n\nhow to reset a local branch to the point where the remote is\nhow to clear your staging area (and possibly the working directory), so that git status says nothing to commit, working directory clean.\n\nThe one-stop-answer is:\n\ngit fetch --prune (optional) Updates the local snapshot of the remote repo. Further commands are local only.\ngit reset --hard @{upstream}Puts the local branch pointer to where the snapshot of the remote is, as well as set the index and the working directory to the files of that commit.\ngit clean -d --force Removes untracked files and directories which hinder git to say “working directory clean”.\nShare\nImprove this answer\nFollow\nanswered Jan 31 '16 at 1:29\nRobert Siemer\n27k9\n9 gold badges\n73\n73 silver badges\n85\n85 bronze badges","comments":["The @{upstream} syntax requires upstream to be set which happens by default if you git checkout <branchname>. – Otherwise replace it with origin/<branchname>.","Add -x to git clean to remove everything not in the commit (i.e. even files ignored with the .gitignore mechanism)."]},{"answer":"Provided that the remote repository is origin, and that you're interested in branch_name:\n\ngit fetch origin\ngit reset --hard origin/<branch_name>\n\n\nAlso, you go for reset the current branch of origin to HEAD.\n\ngit fetch origin\ngit reset --hard origin/HEAD\n\n\nHow it works:\n\ngit fetch origin downloads the latest from remote without trying to merge or rebase anything.\n\nThen the git reset resets the <branch_name> branch to what you just fetched. The --hard option changes all the files in your working tree to match the files in origin/branch_name.\n\nShare\nImprove this answer\nFollow\nedited Dec 20 '17 at 2:40\nanswered May 8 '17 at 11:12\neigenharsha\n1,5981\n1 gold badge\n14\n14 silver badges\n30\n30 bronze badges","comments":["I'm not sure I follow origin/HEAD here and I don't think it's correct"]},{"answer":"This is something I face regularly, & I've generalised the script Wolfgang provided above to work with any branch\n\nI also added an \"are you sure\" prompt, & some feedback output\n\n#!/bin/bash\n# reset the current repository\n# WF 2012-10-15\n# AT 2012-11-09\n# see http://stackoverflow.com/questions/1628088/how-to-reset-my-local-repository-to-be-just-like-the-remote-repository-head\ntimestamp=`date \"+%Y-%m-%d-%H_%M_%S\"`\nbranchname=`git rev-parse --symbolic-full-name --abbrev-ref HEAD`\nread -p \"Reset branch $branchname to origin (y/n)? \"\n[ \"$REPLY\" != \"y\" ] || \necho \"about to auto-commit any changes\"\ngit commit -a -m \"auto commit at $timestamp\"\nif [ $? -eq 0 ]\nthen\n  echo \"Creating backup auto-save branch: auto-save-$branchname-at-$timestamp\"\n  git branch \"auto-save-$branchname-at-$timestamp\" \nfi\necho \"now resetting to origin/$branchname\"\ngit fetch origin\ngit reset --hard origin/$branchname\n\nShare\nImprove this answer\nFollow\nedited Jan 30 '16 at 15:32\nWolfgang Fahl\n12.4k9\n9 gold badges\n81\n81 silver badges\n151\n151 bronze badges\nanswered Nov 9 '12 at 13:01\nAndrew Tulloch\n3773\n3 silver badges\n3\n3 bronze badges","comments":["you might want to use \"git remote\" to get the name of the remote. In certain cases, it won't be \"origin\"","The logic in your script is not correct. The [ \"$REPLY\" != \"y\" ] || will only skip the next line echo \"about to auto-commit any changes\" and continue running the rest of the script. The line should read something like [[ \"$REPLY\" != \"y\" ]] && { echo \"Exiting branch reset\"; exit; }."]},{"answer":"I did:\n\ngit branch -D master\ngit checkout master\n\n\nto totally reset branch\n\nnote, you should checkout to another branch to be able to delete required branch\n\nShare\nImprove this answer\nFollow\nedited May 14 '14 at 11:18\nanswered May 14 '14 at 7:48\nuser2846569\n2,3982\n2 gold badges\n20\n20 silver badges\n24\n24 bronze badges","comments":["You should read question once again, there is nothing on affecting remote, but setting to same as remote, so you shouldn't do anything with remote, and this helped in my case and non of above.","If you want to set it to the same as remote, you should at least do a fetch at some point don't you agree?","you should at least try this or read docs: kernel.org/pub/software/scm/git/docs/git-checkout.html","Way to go, I had a corrupt .pck file in the branch and the rest of options didn't work, thanks!!"]},{"answer":"Here is a script that automates what the most popular answer suggests ... See https://stackoverflow.com/a/13308579/1497139 for an improved version that supports branches\n\n#!/bin/bash\n# reset the current repository\n# WF 2012-10-15\n# see https://stackoverflow.com/questions/1628088/how-to-reset-my-local-repository-to-be-just-like-the-remote-repository-head\ntimestamp=`date \"+%Y-%m-%d-%H_%M_%S\"`\ngit commit -a -m \"auto commit at $timestamp\"\nif [ $? -eq 0 ]\nthen\n  git branch \"auto-save-at-$timestamp\" \nfi\ngit fetch origin\ngit reset --hard origin/master\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:55\nCommunity♦\n11\n1 silver badge\nanswered Oct 15 '12 at 8:50\nWolfgang Fahl\n12.4k9\n9 gold badges\n81\n81 silver badges\n151\n151 bronze badges","comments":[]},{"answer":"The answer\n\ngit clean -d -f\n\n\nwas underrated (-d to remove directories). Thanks!\n\nShare\nImprove this answer\nFollow\nanswered Jan 25 '20 at 0:29\nAnael\n3644\n4 silver badges\n9\n9 bronze badges","comments":["And for a full, 100% clean repo folder with no extra files, run git clean -xdf. This will delete any and all files that git is not aware of, and will make your folder match what is in git's object list exactly. Note that you can add -n (e.g. git clean -nxdf) to perform a \"what-if\" and it will tell you what it will delete without actually doing anything. (git clean)","This solved my issue. thanks!"]},{"answer":"If you had a problem as me, that you have already committed some changes, but now, for any reason you want to get rid of it, the quickest way is to use git reset like this:\n\ngit reset --hard HEAD~2\n\n\nI had 2 not needed commits, hence the number 2. You can change it to your own number of commits to reset.\n\nSo answering your question - if you're 5 commits ahead of remote repository HEAD, you should run this command:\n\ngit reset --hard HEAD~5\n\n\nNotice that you will lose the changes you've made, so be careful!\n\nShare\nImprove this answer\nFollow\nedited Feb 23 '17 at 18:15\nAsclepius\n43.4k14\n14 gold badges\n122\n122 silver badges\n111\n111 bronze badges\nanswered Jun 16 '14 at 3:35\nKarol\n7,2325\n5 gold badges\n43\n43 silver badges\n65\n65 bronze badges","comments":[]},{"answer":"Previous answers assume that the branch to be reset is the current branch (checked out). In comments, OP hap497 clarified that the branch is indeed checked out, but this is not explicitly required by the original question. Since there is at least one \"duplicate\" question, Reset branch completely to repository state, which does not assume that the branch is checked out, here's an alternative:\n\nIf branch \"mybranch\" is not currently checked out, to reset it to remote branch \"myremote/mybranch\"'s head, you can use this low-level command:\n\ngit update-ref refs/heads/mybranch myremote/mybranch\n\n\nThis method leaves the checked out branch as it is, and the working tree untouched. It simply moves mybranch's head to another commit, whatever is given as the second argument. This is especially helpful if multiple branches need to be updated to new remote heads.\n\nUse caution when doing this, though, and use gitk or a similar tool to double check source and destination. If you accidentally do this on the current branch (and git will not keep you from this), you may become confused, because the new branch content does not match the working tree, which did not change (to fix, update the branch again, to where it was before).\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:55\nCommunity♦\n11\n1 silver badge\nanswered Jun 25 '16 at 17:13\nRainer Blome\n5115\n5 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"This is what I use often:\n\ngit fetch upstream develop;\ngit reset --hard upstream/develop;\ngit clean -d --force;\n\n\nNote that it is good practice not to make changes to your local master/develop branch, but instead checkout to another branch for any change, with the branch name prepended by the type of change, e.g. feat/, chore/, fix/, etc. Thus you only need to pull changes, not push any changes from master. Same thing for other branches that others contribute to. So the above should only be used if you have happened to commit changes to a branch that others have committed to, and need to reset. Otherwise in future avoid pushing to a branch that others push to, instead checkout and push to the said branch via the checked out branch.\n\nIf you want to reset your local branch to the latest commit in the upstream branch, what works for me so far is:\n\nCheck your remotes, make sure your upstream and origin are what you expect, if not as expected then use git remote add upstream <insert URL>, e.g. of the original GitHub repo that you forked from, and/or git remote add origin <insert URL of the forked GitHub repo>.\n\ngit remote --verbose\n\ngit checkout develop;\ngit commit -m \"Saving work.\";\ngit branch saved-work;\ngit fetch upstream develop;\ngit reset --hard upstream/develop;\ngit clean -d --force\n\n\nOn GitHub, you can also checkout the branch with the same name as the local one, in order to save the work there, although this isn't necessary if origin develop has the same changes as the local saved-work branch. I'm using the develop branch as an example, but it can be any existing branch name.\n\ngit add .\ngit commit -m \"Reset to upstream/develop\"\ngit push --force origin develop\n\n\nThen if you need to merge these changes with another branch while where there are any conflicts, preserving the changes in develop, use:\n\ngit merge -s recursive -X theirs develop\n\n\nWhile use\n\ngit merge -s recursive -X ours develop\n\n\nto preserve branch_name's conflicting changes. Otherwise use a mergetool with git mergetool.\n\nWith all the changes together:\n\ngit commit -m \"Saving work.\";\ngit branch saved-work;\ngit checkout develop;\ngit fetch upstream develop;\ngit reset --hard upstream/develop;\ngit clean -d --force;\ngit add .;\ngit commit -m \"Reset to upstream/develop\";\ngit push --force origin develop;\ngit checkout branch_name;\ngit merge develop;\n\n\nNote that instead of upstream/develop you could use a commit hash, other branch name, etc. Use a CLI tool such as Oh My Zsh to check that your branch is green indicating that there is nothing to commit and the working directory is clean (which is confirmed or also verifiable by git status). Note that this may actually add commits compared to upstream develop if there is anything automatically added by a commit, e.g. UML diagrams, license headers, etc., so in that case, you could then pull the changes on origin develop to upstream develop, if needed.\n\nShare\nImprove this answer\nFollow\nedited Dec 27 '19 at 4:55\nanswered Apr 26 '18 at 1:30\nJames Ray\n3742\n2 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"Only 3 commands will make it work\n\ngit fetch origin\ngit reset --hard origin/HEAD\ngit clean -f\n\nShare\nImprove this answer\nFollow\nanswered Dec 16 '19 at 19:04\nDeep Nirmal\n88510\n10 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"If you want to go back to the HEAD state for both the working directory and the index, then you should git reset --hard HEAD, rather than to HEAD^. (This may have been a typo, just like the single versus double dash for --hard.)\n\nAs for your specific question as to why those files appear in the status as modified, it looks like perhaps you did a soft reset instead of a hard reset. This will cause the files that were changed in the HEAD commit to appear as if they were staged, which is likely what you are seeing here.\n\nShare\nImprove this answer\nFollow\nanswered Oct 27 '09 at 2:10\nEmil Sit\n21.3k6\n6 gold badges\n49\n49 silver badges\n73\n73 bronze badges","comments":[]},{"answer":"No amount of reset and cleaning seemed to have any effect on untracked and modified files in my local git repo (I tried all the options above). My only solution to this was to rm the local repo and re-clone it from the remote.\n\nFortunately I didn't have any other branches I cared about.\n\nxkcd: Git\n\nShare\nImprove this answer\nFollow\nedited Jun 12 '18 at 13:46\nanswered Dec 1 '16 at 10:25\nMartin\n1,45919\n19 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"The only solution that works in all cases that I've seen is to delete and reclone. Maybe there's another way, but obviously this way leaves no chance of old state being left there, so I prefer it. Bash one-liner you can set as a macro if you often mess things up in git:\n\nREPO_PATH=$(pwd) && GIT_URL=$(git config --get remote.origin.url) && cd .. && rm -rf $REPO_PATH && git clone --recursive $GIT_URL $REPO_PATH && cd $REPO_PATH\n\n\n* assumes your .git files aren't corrupt\n\nShare\nImprove this answer\nFollow\nedited Sep 22 '17 at 5:59\nanswered Sep 14 '17 at 19:28\nsudo\n4,6204\n4 gold badges\n32\n32 silver badges\n66\n66 bronze badges","comments":["you can also just reinstall your operating system if you want to be certain!"]},{"answer":"Have you forgotten to create a feature-branch and have committed directly on master by mistake?\n\nYou can create the feature branch now and set master back without affecting the worktree (local filesystem) to avoid triggering builds, tests and trouble with file-locks:\n\ngit checkout -b feature-branch\ngit branch -f master origin/master\n\nShare\nImprove this answer\nFollow\nanswered Oct 17 '19 at 14:38\nGrastveit\n14.6k2\n2 gold badges\n24\n24 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"If you don't mind saving your local changes, yet still want to update your repository to match origin/HEAD, you can simply stash your local changes and then pull:\n\ngit stash\ngit pull\n\nShare\nImprove this answer\nFollow\nanswered Sep 10 '14 at 13:49\nMicah Walter\n7717\n7 silver badges\n18\n18 bronze badges","comments":[]}]},{"id":"14994391","href":"https://stackoverflow.com/questions/14994391/thinking-in-angularjs-if-i-have-a-jquery-background","title":"“Thinking in AngularJS” if I have a jQuery background? [closed]","description":"\n                    \n            \n        \n            \n                \n                    \n                        Closed. This question needs to be more focused. It is not currently accepting answers.\n                        \n                    \n                \n            \n                Closed 6 years ago.\n        \n\n\n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        Locked. This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nSuppose I'm familiar with developing client-side applications in jQuery, but now I'd like to start using AngularJS. Can you describe the paradigm shift that is necessary? Here are a few questions that might help you frame an answer:\n\n\nHow do I architect and design client-side web applications differently? What is the biggest difference?\nWhat should I stop doing/using; What should I start doing/using instead?\nAre there any server-side considerations/restrictions?\n\n\nI'm not looking for a detailed comparison between jQuery and AngularJS.\n    ","questionComments":[],"answers":[{"answer":"1. Don't design your page, and then change it with DOM manipulations\n\nIn jQuery, you design a page, and then you make it dynamic. This is because jQuery was designed for augmentation and has grown incredibly from that simple premise.\n\nBut in AngularJS, you must start from the ground up with your architecture in mind. Instead of starting by thinking \"I have this piece of the DOM and I want to make it do X\", you have to start with what you want to accomplish, then go about designing your application, and then finally go about designing your view.\n\n2. Don't augment jQuery with AngularJS\n\nSimilarly, don't start with the idea that jQuery does X, Y, and Z, so I'll just add AngularJS on top of that for models and controllers. This is really tempting when you're just starting out, which is why I always recommend that new AngularJS developers don't use jQuery at all, at least until they get used to doing things the \"Angular Way\".\n\nI've seen many developers here and on the mailing list create these elaborate solutions with jQuery plugins of 150 or 200 lines of code that they then glue into AngularJS with a collection of callbacks and $applys that are confusing and convoluted; but they eventually get it working! The problem is that in most cases that jQuery plugin could be rewritten in AngularJS in a fraction of the code, where suddenly everything becomes comprehensible and straightforward.\n\nThe bottom line is this: when solutioning, first \"think in AngularJS\"; if you can't think of a solution, ask the community; if after all of that there is no easy solution, then feel free to reach for the jQuery. But don't let jQuery become a crutch or you'll never master AngularJS.\n\n3. Always think in terms of architecture\n\nFirst know that single-page applications are applications. They're not webpages. So we need to think like a server-side developer in addition to thinking like a client-side developer. We have to think about how to divide our application into individual, extensible, testable components.\n\nSo then how do you do that? How do you \"think in AngularJS\"? Here are some general principles, contrasted with jQuery.\n\nThe view is the \"official record\"\n\nIn jQuery, we programmatically change the view. We could have a dropdown menu defined as a ul like so:\n\n<ul class=\"main-menu\">\n    <li class=\"active\">\n        <a href=\"#/home\">Home</a>\n    </li>\n    <li>\n        <a href=\"#/menu1\">Menu 1</a>\n        <ul>\n            <li><a href=\"#/sm1\">Submenu 1</a></li>\n            <li><a href=\"#/sm2\">Submenu 2</a></li>\n            <li><a href=\"#/sm3\">Submenu 3</a></li>\n        </ul>\n    </li>\n    <li>\n        <a href=\"#/home\">Menu 2</a>\n    </li>\n</ul>\n\n\nIn jQuery, in our application logic, we would activate it with something like:\n\n$('.main-menu').dropdownMenu();\n\n\nWhen we just look at the view, it's not immediately obvious that there is any functionality here. For small applications, that's fine. But for non-trivial applications, things quickly get confusing and hard to maintain.\n\nIn AngularJS, though, the view is the official record of view-based functionality. Our ul declaration would look like this instead:\n\n<ul class=\"main-menu\" dropdown-menu>\n    ...\n</ul>\n\n\nThese two do the same thing, but in the AngularJS version anyone looking at the template knows what's supposed to happen. Whenever a new member of the development team comes on board, she can look at this and then know that there is a directive called dropdownMenu operating on it; she doesn't need to intuit the right answer or sift through any code. The view told us what was supposed to happen. Much cleaner.\n\nDevelopers new to AngularJS often ask a question like: how do I find all links of a specific kind and add a directive onto them. The developer is always flabbergasted when we reply: you don't. But the reason you don't do that is that this is like half-jQuery, half-AngularJS, and no good. The problem here is that the developer is trying to \"do jQuery\" in the context of AngularJS. That's never going to work well. The view is the official record. Outside of a directive (more on this below), you never, ever, never change the DOM. And directives are applied in the view, so intent is clear.\n\nRemember: don't design, and then mark up. You must architect, and then design.\n\nData binding\n\nThis is by far one of the most awesome features of AngularJS and cuts out a lot of the need to do the kinds of DOM manipulations I mentioned in the previous section. AngularJS will automatically update your view so you don't have to! In jQuery, we respond to events and then update content. Something like:\n\n$.ajax({\n  url: '/myEndpoint.json',\n  success: function ( data, status ) {\n    $('ul#log').append('<li>Data Received!</li>');\n  }\n});\n\n\nFor a view that looks like this:\n\n<ul class=\"messages\" id=\"log\">\n</ul>\n\n\nApart from mixing concerns, we also have the same problems of signifying intent that I mentioned before. But more importantly, we had to manually reference and update a DOM node. And if we want to delete a log entry, we have to code against the DOM for that too. How do we test the logic apart from the DOM? And what if we want to change the presentation?\n\nThis a little messy and a trifle frail. But in AngularJS, we can do this:\n\n$http( '/myEndpoint.json' ).then( function ( response ) {\n    $scope.log.push( { msg: 'Data Received!' } );\n});\n\n\nAnd our view can look like this:\n\n<ul class=\"messages\">\n    <li ng-repeat=\"entry in log\">{{ entry.msg }}</li>\n</ul>\n\n\nBut for that matter, our view could look like this:\n\n<div class=\"messages\">\n    <div class=\"alert\" ng-repeat=\"entry in log\">\n        {{ entry.msg }}\n    </div>\n</div>\n\n\nAnd now instead of using an unordered list, we're using Bootstrap alert boxes. And we never had to change the controller code! But more importantly, no matter where or how the log gets updated, the view will change too. Automatically. Neat!\n\nThough I didn't show it here, the data binding is two-way. So those log messages could also be editable in the view just by doing this: <input ng-model=\"entry.msg\" />. And there was much rejoicing.\n\nDistinct model layer\n\nIn jQuery, the DOM is kind of like the model. But in AngularJS, we have a separate model layer that we can manage in any way we want, completely independently from the view. This helps for the above data binding, maintains separation of concerns, and introduces far greater testability. Other answers mentioned this point, so I'll just leave it at that.\n\nSeparation of concerns\n\nAnd all of the above tie into this over-arching theme: keep your concerns separate. Your view acts as the official record of what is supposed to happen (for the most part); your model represents your data; you have a service layer to perform reusable tasks; you do DOM manipulation and augment your view with directives; and you glue it all together with controllers. This was also mentioned in other answers, and the only thing I would add pertains to testability, which I discuss in another section below.\n\nDependency injection\n\nTo help us out with separation of concerns is dependency injection (DI). If you come from a server-side language (from Java to PHP) you're probably familiar with this concept already, but if you're a client-side guy coming from jQuery, this concept can seem anything from silly to superfluous to hipster. But it's not. :-)\n\nFrom a broad perspective, DI means that you can declare components very freely and then from any other component, just ask for an instance of it and it will be granted. You don't have to know about loading order, or file locations, or anything like that. The power may not immediately be visible, but I'll provide just one (common) example: testing.\n\nLet's say in our application, we require a service that implements server-side storage through a REST API and, depending on application state, local storage as well. When running tests on our controllers, we don't want to have to communicate with the server - we're testing the controller, after all. We can just add a mock service of the same name as our original component, and the injector will ensure that our controller gets the fake one automatically - our controller doesn't and needn't know the difference.\n\nSpeaking of testing...\n\n4. Test-driven development - always\n\nThis is really part of section 3 on architecture, but it's so important that I'm putting it as its own top-level section.\n\nOut of all of the many jQuery plugins you've seen, used, or written, how many of them had an accompanying test suite? Not very many because jQuery isn't very amenable to that. But AngularJS is.\n\nIn jQuery, the only way to test is often to create the component independently with a sample/demo page against which our tests can perform DOM manipulation. So then we have to develop a component separately and then integrate it into our application. How inconvenient! So much of the time, when developing with jQuery, we opt for iterative instead of test-driven development. And who could blame us?\n\nBut because we have separation of concerns, we can do test-driven development iteratively in AngularJS! For example, let's say we want a super-simple directive to indicate in our menu what our current route is. We can declare what we want in the view of our application:\n\n<a href=\"/hello\" when-active>Hello</a>\n\n\nOkay, now we can write a test for the non-existent when-active directive:\n\nit( 'should add \"active\" when the route changes', inject(function() {\n    var elm = $compile( '<a href=\"/hello\" when-active>Hello</a>' )( $scope );\n\n    $location.path('/not-matching');\n    expect( elm.hasClass('active') ).toBeFalsey();\n\n    $location.path( '/hello' );\n    expect( elm.hasClass('active') ).toBeTruthy();\n}));\n\n\nAnd when we run our test, we can confirm that it fails. Only now should we create our directive:\n\n.directive( 'whenActive', function ( $location ) {\n    return {\n        scope: true,\n        link: function ( scope, element, attrs ) {\n            scope.$on( '$routeChangeSuccess', function () {\n                if ( $location.path() == element.attr( 'href' ) ) {\n                    element.addClass( 'active' );\n                }\n                else {\n                    element.removeClass( 'active' );\n                }\n            });\n        }\n    };\n});\n\n\nOur test now passes and our menu performs as requested. Our development is both iterative and test-driven. Wicked-cool.\n\n5. Conceptually, directives are not packaged jQuery\n\nYou'll often hear \"only do DOM manipulation in a directive\". This is a necessity. Treat it with due deference!\n\nBut let's dive a little deeper...\n\nSome directives just decorate what's already in the view (think ngClass) and therefore sometimes do DOM manipulation straight away and then are basically done. But if a directive is like a \"widget\" and has a template, it should also respect separation of concerns. That is, the template too should remain largely independent from its implementation in the link and controller functions.\n\nAngularJS comes with an entire set of tools to make this very easy; with ngClass we can dynamically update the class; ngModel allows two-way data binding; ngShow and ngHide programmatically show or hide an element; and many more - including the ones we write ourselves. In other words, we can do all kinds of awesomeness without DOM manipulation. The less DOM manipulation, the easier directives are to test, the easier they are to style, the easier they are to change in the future, and the more re-usable and distributable they are.\n\nI see lots of developers new to AngularJS using directives as the place to throw a bunch of jQuery. In other words, they think \"since I can't do DOM manipulation in the controller, I'll take that code put it in a directive\". While that certainly is much better, it's often still wrong.\n\nThink of the logger we programmed in section 3. Even if we put that in a directive, we still want to do it the \"Angular Way\". It still doesn't take any DOM manipulation! There are lots of times when DOM manipulation is necessary, but it's a lot rarer than you think! Before doing DOM manipulation anywhere in your application, ask yourself if you really need to. There might be a better way.\n\nHere's a quick example that shows the pattern I see most frequently. We want a toggleable button. (Note: this example is a little contrived and a skosh verbose to represent more complicated cases that are solved in exactly the same way.)\n\n.directive( 'myDirective', function () {\n    return {\n        template: '<a class=\"btn\">Toggle me!</a>',\n        link: function ( scope, element, attrs ) {\n            var on = false;\n\n            $(element).click( function () {\n                on = !on;\n                $(element).toggleClass('active', on);\n            });\n        }\n    };\n});\n\n\nThere are a few things wrong with this:\n\nFirst, jQuery was never necessary. There's nothing we did here that needed jQuery at all!\nSecond, even if we already have jQuery on our page, there's no reason to use it here; we can simply use angular.element and our component will still work when dropped into a project that doesn't have jQuery.\nThird, even assuming jQuery was required for this directive to work, jqLite (angular.element) will always use jQuery if it was loaded! So we needn't use the $ - we can just use angular.element.\nFourth, closely related to the third, is that jqLite elements needn't be wrapped in $ - the element that is passed to the link function would already be a jQuery element!\nAnd fifth, which we've mentioned in previous sections, why are we mixing template stuff into our logic?\n\nThis directive can be rewritten (even for very complicated cases!) much more simply like so:\n\n.directive( 'myDirective', function () {\n    return {\n        scope: true,\n        template: '<a class=\"btn\" ng-class=\"{active: on}\" ng-click=\"toggle()\">Toggle me!</a>',\n        link: function ( scope, element, attrs ) {\n            scope.on = false;\n\n            scope.toggle = function () {\n                scope.on = !scope.on;\n            };\n        }\n    };\n});\n\n\nAgain, the template stuff is in the template, so you (or your users) can easily swap it out for one that meets any style necessary, and the logic never had to be touched. Reusability - boom!\n\nAnd there are still all those other benefits, like testing - it's easy! No matter what's in the template, the directive's internal API is never touched, so refactoring is easy. You can change the template as much as you want without touching the directive. And no matter what you change, your tests still pass.\n\nw00t!\n\nSo if directives aren't just collections of jQuery-like functions, what are they? Directives are actually extensions of HTML. If HTML doesn't do something you need it to do, you write a directive to do it for you, and then use it just as if it was part of HTML.\n\nPut another way, if AngularJS doesn't do something out of the box, think how the team would accomplish it to fit right in with ngClick, ngClass, et al.\n\nSummary\n\nDon't even use jQuery. Don't even include it. It will hold you back. And when you come to a problem that you think you know how to solve in jQuery already, before you reach for the $, try to think about how to do it within the confines the AngularJS. If you don't know, ask! 19 times out of 20, the best way to do it doesn't need jQuery and to try to solve it with jQuery results in more work for you.\n\nShare\nedited Apr 17 '15 at 20:38\nanswered Feb 21 '13 at 21:26\nJosh David Miller\n120k16\n16 gold badges\n125\n125 silver badges\n95\n95 bronze badges","comments":[]},{"answer":"Imperative → declarative\n\nIn jQuery, selectors are used to find DOM elements and then bind/register event handlers to them. When an event triggers, that (imperative) code executes to update/change the DOM.\n\nIn AngularJS, you want to think about views rather than DOM elements. Views are (declarative) HTML that contain AngularJS directives. Directives set up the event handlers behind the scenes for us and give us dynamic databinding. Selectors are rarely used, so the need for IDs (and some types of classes) is greatly diminished. Views are tied to models (via scopes). Views are a projection of the model. Events change models (that is, data, scope properties), and the views that project those models update \"automatically.\"\n\nIn AngularJS, think about models, rather than jQuery-selected DOM elements that hold your data. Think about views as projections of those models, rather than registering callbacks to manipulate what the user sees.\n\nSeparation of concerns\n\njQuery employs unobtrusive JavaScript - behavior (JavaScript) is separated from the structure (HTML).\n\nAngularJS uses controllers and directives (each of which can have their own controller, and/or compile and linking functions) to remove behavior from the view/structure (HTML). Angular also has services and filters to help separate/organize your application.\n\nSee also https://stackoverflow.com/a/14346528/215945\n\nApplication design\n\nOne approach to designing an AngularJS application:\n\nThink about your models. Create services or your own JavaScript objects for those models.\nThink about how you want to present your models -- your views. Create HTML templates for each view, using the necessary directives to get dynamic databinding.\nAttach a controller to each view (using ng-view and routing, or ng-controller). Have the controller find/get only whatever model data the view needs to do its job. Make controllers as thin as possible.\nPrototypal inheritance\n\nYou can do a lot with jQuery without knowing about how JavaScript prototypal inheritance works. When developing AngularJS applications, you will avoid some common pitfalls if you have a good understanding of JavaScript inheritance. Recommended reading: What are the nuances of scope prototypal / prototypical inheritance in AngularJS?\n\nShare\nedited May 23 '17 at 11:47\nCommunity♦\n11\n1 silver badge\nanswered Feb 21 '13 at 4:09\nMark Rajcok\n351k113\n113 gold badges\n484\n484 silver badges\n483\n483 bronze badges","comments":[]},{"answer":"AngularJS vs. jQuery\n\nAngularJS and jQuery adopt very different ideologies. If you're coming from jQuery you may find some of the differences surprising. Angular may make you angry.\n\nThis is normal, you should push through. Angular is worth it.\n\nThe big difference (TLDR)\n\njQuery gives you a toolkit for selecting arbitrary bits of the DOM and making ad-hoc changes to them. You can do pretty much anything you like piece by piece.\n\nAngularJS instead gives you a compiler.\n\nWhat this means is that AngularJS reads your entire DOM from top to bottom and treats it as code, literally as instructions to the compiler. As it traverses the DOM, It looks for specific directives (compiler directives) that tell the AngularJS compiler how to behave and what to do. Directives are little objects full of JavaScript which can match against attributes, tags, classes or even comments.\n\nWhen the Angular compiler determines that a piece of the DOM matches a particular directive, it calls the directive function, passing it the DOM element, any attributes, the current $scope (which is a local variable store), and some other useful bits. These attributes may contain expressions which can be interpreted by the Directive, and which tell it how to render, and when it should redraw itself.\n\nDirectives can then in turn pull in additional Angular components such as controllers, services, etc. What comes out the bottom of the compiler is a fully formed web application, wired up and ready to go.\n\nThis means that Angular is Template Driven. Your template drives the JavaScript, not the other way around. This is a radical reversal of roles, and the complete opposite of the unobtrusive JavaScript we have been writing for the last 10 years or so. This can take some getting used to.\n\nIf this sounds like it might be over-prescriptive and limiting, nothing could be farther from the truth. Because AngularJS treats your HTML as code, you get HTML level granularity in your web application. Everything is possible, and most things are surprisingly easy once you make a few conceptual leaps.\n\nLet's get down to the nitty gritty.\n\nFirst up, Angular doesn't replace jQuery\n\nAngular and jQuery do different things. AngularJS gives you a set of tools to produce web applications. jQuery mainly gives you tools for modifying the DOM. If jQuery is present on your page, AngularJS will use it automatically. If it isn't, AngularJS ships with jQuery Lite, which is a cut down, but still perfectly usable version of jQuery.\n\nMisko likes jQuery and doesn't object to you using it. However you will find as you advance that you can get a pretty much all of your work done using a combination of scope, templates and directives, and you should prefer this workflow where possible because your code will be more discrete, more configurable, and more Angular.\n\nIf you do use jQuery, you shouldn't be sprinkling it all over the place. The correct place for DOM manipulation in AngularJS is in a directive. More on these later.\n\nUnobtrusive JavaScript with Selectors vs. Declarative Templates\n\njQuery is typically applied unobtrusively. Your JavaScript code is linked in the header (or the footer), and this is the only place it is mentioned. We use selectors to pick out bits of the page and write plugins to modify those parts.\n\nThe JavaScript is in control. The HTML has a completely independent existence. Your HTML remains semantic even without JavaScript. Onclick attributes are very bad practice.\n\nOne of the first things your will notice about AngularJS is that custom attributes are everywhere. Your HTML will be littered with ng attributes, which are essentially onClick attributes on steroids. These are directives (compiler directives), and are one of the main ways in which the template is hooked to the model.\n\nWhen you first see this you might be tempted to write AngularJS off as old school intrusive JavaScript (like I did at first). In fact, AngularJS does not play by those rules. In AngularJS, your HTML5 is a template. It is compiled by AngularJS to produce your web page.\n\nThis is the first big difference. To jQuery, your web page is a DOM to be manipulated. To AngularJS, your HTML is code to be compiled. AngularJS reads in your whole web page and literally compiles it into a new web page using its built in compiler.\n\nYour template should be declarative; its meaning should be clear simply by reading it. We use custom attributes with meaningful names. We make up new HTML elements, again with meaningful names. A designer with minimal HTML knowledge and no coding skill can read your AngularJS template and understand what it is doing. He or she can make modifications. This is the Angular way.\n\nThe template is in the driving seat.\n\nOne of the first questions I asked myself when starting AngularJS and running through the tutorials is \"Where is my code?\". I've written no JavaScript, and yet I have all this behaviour. The answer is obvious. Because AngularJS compiles the DOM, AngularJS is treating your HTML as code. For many simple cases it's often sufficient to just write a template and let AngularJS compile it into an application for you.\n\nYour template drives your application. It's treated as a DSL. You write AngularJS components, and AngularJS will take care of pulling them in and making them available at the right time based on the structure of your template. This is very different to a standard MVC pattern, where the template is just for output.\n\nIt's more similar to XSLT than Ruby on Rails for example.\n\nThis is a radical inversion of control that takes some getting used to.\n\nStop trying to drive your application from your JavaScript. Let the template drive the application, and let AngularJS take care of wiring the components together. This also is the Angular way.\n\nSemantic HTML vs. Semantic Models\n\nWith jQuery your HTML page should contain semantic meaningful content. If the JavaScript is turned off (by a user or search engine) your content remains accessible.\n\nBecause AngularJS treats your HTML page as a template. The template is not supposed to be semantic as your content is typically stored in your model which ultimately comes from your API. AngularJS compiles your DOM with the model to produce a semantic web page.\n\nYour HTML source is no longer semantic, instead, your API and compiled DOM are semantic.\n\nIn AngularJS, meaning lives in the model, the HTML is just a template, for display only.\n\nAt this point you likely have all sorts of questions concerning SEO and accessibility, and rightly so. There are open issues here. Most screen readers will now parse JavaScript. Search engines can also index AJAXed content. Nevertheless, you will want to make sure you are using pushstate URLs and you have a decent sitemap. See here for a discussion of the issue: https://stackoverflow.com/a/23245379/687677\n\nSeparation of concerns (SOC) vs. MVC\n\nSeparation of concerns (SOC) is a pattern that grew up over many years of web development for a variety of reasons including SEO, accessibility and browser incompatibility. It looks like this:\n\nHTML - Semantic meaning. The HTML should stand alone.\nCSS - Styling, without the CSS the page is still readable.\nJavaScript - Behaviour, without the script the content remains.\n\nAgain, AngularJS does not play by their rules. In a stroke, AngularJS does away with a decade of received wisdom and instead implements an MVC pattern in which the template is no longer semantic, not even a little bit.\n\nIt looks like this:\n\nModel - your models contains your semantic data. Models are usually JSON objects. Models exist as attributes of an object called $scope. You can also store handy utility functions on $scope which your templates can then access.\nView - Your views are written in HTML. The view is usually not semantic because your data lives in the model.\nController - Your controller is a JavaScript function which hooks the view to the model. Its function is to initialise $scope. Depending on your application, you may or may not need to create a controller. You can have many controllers on a page.\n\nMVC and SOC are not on opposite ends of the same scale, they are on completely different axes. SOC makes no sense in an AngularJS context. You have to forget it and move on.\n\nIf, like me, you lived through the browser wars, you might find this idea quite offensive. Get over it, it'll be worth it, I promise.\n\nPlugins vs. Directives\n\nPlugins extend jQuery. AngularJS Directives extend the capabilities of your browser.\n\nIn jQuery we define plugins by adding functions to the jQuery.prototype. We then hook these into the DOM by selecting elements and calling the plugin on the result. The idea is to extend the capabilities of jQuery.\n\nFor example, if you want a carousel on your page, you might define an unordered list of figures, perhaps wrapped in a nav element. You might then write some jQuery to select the list on the page and restyle it as a gallery with timeouts to do the sliding animation.\n\nIn AngularJS, we define directives. A directive is a function which returns a JSON object. This object tells AngularJS what DOM elements to look for, and what changes to make to them. Directives are hooked in to the template using either attributes or elements, which you invent. The idea is to extend the capabilities of HTML with new attributes and elements.\n\nThe AngularJS way is to extend the capabilities of native looking HTML. You should write HTML that looks like HTML, extended with custom attributes and elements.\n\nIf you want a carousel, just use a <carousel /> element, then define a directive to pull in a template, and make that sucker work.\n\nLots of small directives vs. big plugins with configuration switches\n\nThe tendency with jQuery is to write great big plugins like lightbox which we then configure by passing in numerous values and options.\n\nThis is a mistake in AngularJS.\n\nTake the example of a dropdown. When writing a dropdown plugin you might be tempted to code in click handlers, perhaps a function to add in a chevron which is either up or down, perhaps change the class of the unfolded element, show hide the menu, all helpful stuff.\n\nUntil you want to make a small change.\n\nSay you have a menu that you want to unfold on hover. Well now we have a problem. Our plugin has wired in our click handler for us, we're going to need to add a configuration option to make it behave differently in this specific case.\n\nIn AngularJS we write smaller directives. Our dropdown directive would be ridiculously small. It might maintain the folded state, and provide methods to fold(), unfold() or toggle(). These methods would simply update $scope.menu.visible which is a boolean holding the state.\n\nNow in our template we can wire this up:\n\n<a ng-click=\"toggle()\">Menu</a>\n<ul ng-show=\"menu.visible\">\n  ...\n</ul>\n\n\nNeed to update on mouseover?\n\n<a ng-mouseenter=\"unfold()\" ng-mouseleave=\"fold()\">Menu</a>\n<ul ng-show=\"menu.visible\">\n  ...\n</ul>\n\n\nThe template drives the application so we get HTML level granularity. If we want to make case by case exceptions, the template makes this easy.\n\nClosure vs. $scope\n\nJQuery plugins are created in a closure. Privacy is maintained within that closure. It's up to you to maintain your scope chain within that closure. You only really have access to the set of DOM nodes passed in to the plugin by jQuery, plus any local variables defined in the closure and any globals you have defined. This means that plugins are quite self contained. This is a good thing, but can get restrictive when creating a whole application. Trying to pass data between sections of a dynamic page becomes a chore.\n\nAngularJS has $scope objects. These are special objects created and maintained by AngularJS in which you store your model. Certain directives will spawn a new $scope, which by default inherits from its wrapping $scope using JavaScript prototypical inheritance. The $scope object is accessible in the controller and the view.\n\nThis is the clever part. Because the structure of $scope inheritance roughly follows the structure of the DOM, elements have access to their own scope, and any containing scopes seamlessly, all the way up to the global $scope (which is not the same as the global scope).\n\nThis makes it much easier to pass data around, and to store data at an appropriate level. If a dropdown is unfolded, only the dropdown $scope needs to know about it. If the user updates their preferences, you might want to update the global $scope, and any nested scopes listening to the user preferences would automatically be alerted.\n\nThis might sound complicated, in fact, once you relax into it, it's like flying. You don't need to create the $scope object, AngularJS instantiates and configures it for you, correctly and appropriately based on your template hierarchy. AngularJS then makes it available to your component using the magic of dependency injection (more on this later).\n\nManual DOM changes vs. Data Binding\n\nIn jQuery you make all your DOM changes by hand. You construct new DOM elements programatically. If you have a JSON array and you want to put it to the DOM, you must write a function to generate the HTML and insert it.\n\nIn AngularJS you can do this too, but you are encouraged to make use of data binding. Change your model, and because the DOM is bound to it via a template your DOM will automatically update, no intervention required.\n\nBecause data binding is done from the template, using either an attribute or the curly brace syntax, it's super easy to do. There's little cognitive overhead associated with it so you'll find yourself doing it all the time.\n\n<input ng-model=\"user.name\" />\n\n\nBinds the input element to $scope.user.name. Updating the input will update the value in your current scope, and vice-versa.\n\nLikewise:\n\n<p>\n  {{user.name}}\n</p>\n\n\nwill output the user name in a paragraph. It's a live binding, so if the $scope.user.name value is updated, the template will update too.\n\nAjax all of the time\n\nIn jQuery making an Ajax call is fairly simple, but it's still something you might think twice about. There's the added complexity to think about, and a fair chunk of script to maintain.\n\nIn AngularJS, Ajax is your default go-to solution and it happens all the time, almost without you noticing. You can include templates with ng-include. You can apply a template with the simplest custom directive. You can wrap an Ajax call in a service and create yourself a GitHub service, or a Flickr service, which you can access with astonishing ease.\n\nService Objects vs Helper Functions\n\nIn jQuery, if we want to accomplish a small non-dom related task such as pulling a feed from an API, we might write a little function to do that in our closure. That's a valid solution, but what if we want to access that feed often? What if we want to reuse that code in another application?\n\nAngularJS gives us service objects.\n\nServices are simple objects that contain functions and data. They are always singletons, meaning there can never be more than one of them. Say we want to access the Stack Overflow API, we might write a StackOverflowService which defines methods for doing so.\n\nLet's say we have a shopping cart. We might define a ShoppingCartService which maintains our cart and contains methods for adding and removing items. Because the service is a singleton, and is shared by all other components, any object that needs to can write to the shopping cart and pull data from it. It's always the same cart.\n\nService objects are self-contained AngularJS components which we can use and reuse as we see fit. They are simple JSON objects containing functions and Data. They are always singletons, so if you store data on a service in one place, you can get that data out somewhere else just by requesting the same service.\n\nDependency injection (DI) vs. Instatiation - aka de-spaghettification\n\nAngularJS manages your dependencies for you. If you want an object, simply refer to it and AngularJS will get it for you.\n\nUntil you start to use this, it's hard to explain just what a massive time boon this is. Nothing like AngularJS DI exists inside jQuery.\n\nDI means that instead of writing your application and wiring it together, you instead define a library of components, each identified by a string.\n\nSay I have a component called 'FlickrService' which defines methods for pulling JSON feeds from Flickr. Now, if I want to write a controller that can access Flickr, I just need to refer to the 'FlickrService' by name when I declare the controller. AngularJS will take care of instantiating the component and making it available to my controller.\n\nFor example, here I define a service:\n\nmyApp.service('FlickrService', function() {\n  return {\n    getFeed: function() { // do something here }\n  }\n});\n\n\nNow when I want to use that service I just refer to it by name like this:\n\nmyApp.controller('myController', ['FlickrService', function(FlickrService) {\n  FlickrService.getFeed()\n}]);\n\n\nAngularJS will recognise that a FlickrService object is needed to instantiate the controller, and will provide one for us.\n\nThis makes wiring things together very easy, and pretty much eliminates any tendency towards spagettification. We have a flat list of components, and AngularJS hands them to us one by one as and when we need them.\n\nModular service architecture\n\njQuery says very little about how you should organise your code. AngularJS has opinions.\n\nAngularJS gives you modules into which you can place your code. If you're writing a script that talks to Flickr for example, you might want to create a Flickr module to wrap all your Flickr related functions in. Modules can include other modules (DI). Your main application is usually a module, and this should include all the other modules your application will depend on.\n\nYou get simple code reuse, if you want to write another application based on Flickr, you can just include the Flickr module and voila, you have access to all your Flickr related functions in your new application.\n\nModules contain AngularJS components. When we include a module, all the components in that module become available to us as a simple list identified by their unique strings. We can then inject those components into each other using AngularJS's dependency injection mechanism.\n\nTo sum up\n\nAngularJS and jQuery are not enemies. It's possible to use jQuery within AngularJS very nicely. If you're using AngularJS well (templates, data-binding, $scope, directives, etc.) you will find you need a lot less jQuery than you might otherwise require.\n\nThe main thing to realise is that your template drives your application. Stop trying to write big plugins that do everything. Instead write little directives that do one thing, then write a simple template to wire them together.\n\nThink less about unobtrusive JavaScript, and instead think in terms of HTML extensions.\n\nMy little book\n\nI got so excited about AngularJS, I wrote a short book on it which you're very welcome to read online http://nicholasjohnson.com/angular-book/. I hope it's helpful.\n\nShare\nedited May 23 '17 at 12:26\nCommunity♦\n11\n1 silver badge\nanswered May 12 '14 at 10:22\nsuperluminary\n39.7k21\n21 gold badges\n142\n142 silver badges\n144\n144 bronze badges","comments":[]},{"answer":"Can you describe the paradigm shift that is necessary?\n\nImperative vs Declarative\n\nWith jQuery you tell the DOM what needs to happen, step by step. With AngularJS you describe what results you want but not how to do it. More on this here. Also, check out Mark Rajcok's answer.\n\nHow do I architect and design client-side web apps differently?\n\nAngularJS is an entire client-side framework that uses the MVC pattern (check out their graphical representation). It greatly focuses on separation of concerns.\n\nWhat is the biggest difference? What should I stop doing/using; what should I start doing/using instead?\n\njQuery is a library\n\nAngularJS is a beautiful client-side framework, highly testable, that combines tons of cool stuff such as MVC, dependency injection, data binding and much more.\n\nIt focuses on separation of concerns and testing (unit testing and end-to-end testing), which facilitates test-driven development.\n\nThe best way to start is going through their awesome tutorial. You can go through the steps in a couple of hours; however, in case you want to master the concepts behind the scenes, they include a myriad of reference for further reading.\n\nAre there any server-side considerations/restrictions?\n\nYou may use it on existing applications where you are already using pure jQuery. However, if you want to fully take advantage of the AngularJS features you may consider coding the server side using a RESTful approach.\n\nDoing so will allow you to leverage their resource factory, which creates an abstraction of your server side RESTful API and makes server-side calls (get, save, delete, etc.) incredibly easy.\n\nShare\nedited May 23 '17 at 12:02\nCommunity♦\n11\n1 silver badge\nanswered Feb 21 '13 at 4:29\nUlises\n13k5\n5 gold badges\n32\n32 silver badges\n49\n49 bronze badges","comments":[]},{"answer":"To describe the \"paradigm shift\", I think a short answer can suffice.\n\nAngularJS changes the way you find elements\n\nIn jQuery, you typically use selectors to find elements, and then wire them up:\n$('#id .class').click(doStuff);\n\nIn AngularJS, you use directives to mark the elements directly, to wire them up:\n<a ng-click=\"doStuff()\">\n\nAngularJS doesn't need (or want) you to find elements using selectors - the primary difference between AngularJS's jqLite versus full-blown jQuery is that jqLite does not support selectors.\n\nSo when people say \"don't include jQuery at all\", it's mainly because they don't want you to use selectors; they want you to learn to use directives instead. Direct, not select!\n\nShare\nedited Nov 29 '14 at 8:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 21 '14 at 7:57\nScott Rippey\n15k5\n5 gold badges\n68\n68 silver badges\n83\n83 bronze badges","comments":[]},{"answer":"jQuery\n\njQuery makes ridiculously long JavaScript commands like getElementByHerpDerp shorter and cross-browser.\n\nAngularJS\n\nAngularJS allows you to make your own HTML tags/attributes that do things which work well with dynamic web applications (since HTML was designed for static pages).\n\nEdit:\n\nSaying \"I have a jQuery background how do I think in AngularJS?\" is like saying \"I have an HTML background how do I think in JavaScript?\" The fact that you're asking the question shows you most likely don't understand the fundamental purposes of these two resources. This is why I chose to answer the question by simply pointing out the fundamental difference rather than going through the list saying \"AngularJS makes use of directives whereas jQuery uses CSS selectors to make a jQuery object which does this and that etc....\". This question does not require a lengthy answer.\n\njQuery is a way to make programming JavaScript in the browser easier. Shorter, cross-browser commands, etc.\n\nAngularJS extends HTML, so you don't have to put <div> all over the place just to make an application. It makes HTML actually work for applications rather than what it was designed for, which is static, educational web pages. It accomplishes this in a roundabout way using JavaScript, but fundamentally it is an extension of HTML, not JavaScript.\n\nShare\nedited Jun 9 '15 at 2:08\nWillem Van Onsem\n339k27\n27 gold badges\n310\n310 silver badges\n423\n423 bronze badges\nanswered Feb 4 '14 at 5:07\nNick Manning\n2,6541\n1 gold badge\n24\n24 silver badges\n40\n40 bronze badges","comments":[]},{"answer":"jQuery: you think a lot about 'QUERYing the DOM' for DOM elements and doing something.\n\nAngularJS: THE model is the truth, and you always think from that ANGLE.\n\nFor example, when you get data from THE server which you intend to display in some format in the DOM, in jQuery, you need to '1. FIND' where in the DOM you want to place this data, the '2. UPDATE/APPEND' it there by creating a new node or just setting its innerHTML. Then when you want to update this view, you then '3. FIND' the location and '4. UPDATE'. This cycle of find and update all done within the same context of getting and formatting data from server is gone in AngularJS.\n\nWith AngularJS you have your model (JavaScript objects you are already used to) and the value of the model tells you about the model (obviously) and about the view, and an operation on the model automatically propagates to the view, so you don't have to think about it. You will find yourself in AngularJS no longer finding things in the DOM.\n\nTo put in another way, in jQuery, you need to think about CSS selectors, that is, where is the div or td that has a class or attribute, etc., so that I can get their HTML or color or value, but in AngularJS, you will find yourself thinking like this: what model am I dealing with, I will set the model's value to true. You are not bothering yourself of whether the view reflecting this value is a checked box or resides in a td element (details you would have often needed to think about in jQuery).\n\nAnd with DOM manipulation in AngularJS, you find yourself adding directives and filters, which you can think of as valid HTML extensions.\n\nOne more thing you will experience in AngularJS: in jQuery you call the jQuery functions a lot, in AngularJS, AngularJS will call your functions, so AngularJS will 'tell you how to do things', but the benefits are worth it, so learning AngularJS usually means learning what AngularJS wants or the way AngularJS requires that you present your functions and it will call it accordingly. This is one of the things that makes AngularJS a framework rather than a library.\n\nShare\nedited Jan 15 '14 at 19:08\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 2 '13 at 16:53\nSamuel\n1,25716\n16 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"Those are some very nice, but lengthy answers.\n\nTo sum up my experiences:\n\nControllers and providers (services, factories, etc.) are for modifying the data model, NOT HTML.\nHTML and directives define the layout and binding to the model.\nIf you need to share data between controllers, create a service or factory - they are singletons that are shared across the application.\nIf you need an HTML widget, create a directive.\nIf you have some data and are now trying to update HTML... STOP! update the model, and make sure your HTML is bound to the model.\nShare\nedited Aug 11 '14 at 20:14\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 16 '14 at 21:50\nDan\n1,14510\n10 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"jQuery is a DOM manipulation library.\n\nAngularJS is an MV* framework.\n\nIn fact, AngularJS is one of the few JavaScript MV* frameworks (many JavaScript MVC tools still fall under the category library).\n\nBeing a framework, it hosts your code and takes ownership of decisions about what to call and when!\n\nAngularJS itself includes a jQuery-lite edition within it. So for some basic DOM selection/manipulation, you really don't have to include the jQuery library (it saves many bytes to run on the network.)\n\nAngularJS has the concept of \"Directives\" for DOM manipulation and designing reusable UI components, so you should use it whenever you feel the need of doing DOM manipulation related stuff (directives are only place where you should write jQuery code while using AngularJS).\n\nAngularJS involves some learning curve (more than jQuery :-).\n\n-->For any developer coming from jQuery background, my first advice would be to \"learn JavaScript as a first class language before jumping onto a rich framework like AngularJS!\" I learned the above fact the hard way.\n\nGood luck.\n\nShare\nedited Jan 15 '14 at 19:11\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 10 '13 at 8:58\nAnand\n4,46110\n10 gold badges\n45\n45 silver badges\n69\n69 bronze badges","comments":[]},{"answer":"They're apples and oranges. You don't want to compare them. They're two different things. AngularJs has already jQuery lite built in which allows you to perform basic DOM manipulation without even including the full blown jQuery version.\n\njQuery is all about DOM manipulation. It solves all the cross browser pain otherwise you will have to deal with but it's not a framework that allows you to divide your app into components like AngularJS.\n\nA nice thing about AngularJs is that it allows you to separate/isolate the DOM manipulation in the directives. There are built-in directives ready for you to use such as ng-click. You can create your own custom directives that will contain all your view logic or DOM manipulation so you don't end up mingle DOM manipulation code in the controllers or services that should take care of the business logic.\n\nAngular breaks down your app into - Controllers - Services - Views - etc.\n\nand there is one more thing, that's the directive. It's an attribute you can attach to any DOM element and you can go nuts with jQuery within it without worrying about your jQuery ever conflicts with AngularJs components or messes up with its architecture.\n\nI heard from a meetup I attended, one of the founders of Angular said they worked really hard to separate out the DOM manipulation so do not try to include them back in.\n\nShare\nanswered Aug 14 '13 at 14:19\nJin\n1,05610\n10 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"Listen to the podcast JavaScript Jabber: Episode #32 that features the original creators of AngularJS: Misko Hevery & Igor Minar. They talk a lot about what it's like to come to AngularJS from other JavaScript backgrounds, especially jQuery.\n\nOne of the points made in the podcast made a lot of things click for me with respects to your question:\n\nMISKO: [...] one of the things we thought about very hardly in Angular is, how do we provide lots of escape hatches so that you can get out and basically figure out a way out of this. So to us, the answer is this thing called “Directives”. And with directives, you essentially become a regular little jQuery JavaScript, you can do whatever you want.\n\nIGOR: So think of directive as the instruction to the compiler that tells it whenever you come across this certain element or this CSS in the template, and you keep this kind of code and that code is in charge of the element and everything below that element in the DOM tree.\n\nA transcript of the entire episode is available at the link provided above.\n\nSo, to directly answer your question: AngularJS is -very- opinionated and is a true MV* framework. However, you can still do all of the really cool stuff you know and love with jQuery inside of directives. It's not a matter of \"How do I do what I used to in jQuery?\" as much as it's a matter of \"How do I supplement AngularJS with all of the stuff I used to do in jQuery?\"\n\nIt's really two very different states of mind.\n\nShare\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Nov 8 '13 at 16:08\ncodevinsky\n1,2731\n1 gold badge\n9\n9 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"I find this question interesting, because my first serious exposure to JavaScript programming was Node.js and AngularJS. I never learned jQuery, and I guess that's a good thing, because I don't have to unlearn anything. In fact, I actively avoid jQuery solutions to my problems, and instead, solely look for an \"AngularJS way\" to solve them. So, I guess my answer to this question would essentially boil down to, \"think like someone who never learned jQuery\" and avoid any temptation to incorporate jQuery directly (obviously AngularJS uses it to some extent behind the scenes).\n\nShare\nedited Jan 15 '14 at 19:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 12 '13 at 23:21\nEvan Zamir\n6,62211\n11 gold badges\n44\n44 silver badges\n68\n68 bronze badges","comments":[]},{"answer":"AngularJS and jQuery:\n\nAngularJs and JQuery are completely different at every level except the JQLite functionality and you will see it once you start learning the AngularJs core features (I explained it below).\n\nAngularJs is a client side framework that offers to build the independent client side application. JQuery is a client side library that play around the DOM.\n\nAngularJs Cool Principle - If you want some changes on your UI think from model data change perspective. Change your data and UI will re-render itself. You need not to play around DOM each time unless and until it is hardly required and that should also be handled through Angular Directives.\n\nTo answer this question, I want to share my experience on the first enterprise application with AngularJS. These are the most awesome features that Angular provide where we start changing our jQuery mindset and we get the Angular like a framework and not the library.\n\nTwo-way data binding is amazing: I had a grid with all functionality UPDATE, DELTE, INSERT. I have a data object that binds the grid's model using ng-repeat. You only need to write a single line of simple JavaScript code for delete and insert and that's it. grid automatically updates as the grid model changes instantly. Update functionality is real time, no code for it. You feel amazing!!!\n\nReusable directives are super: Write directives in one place and use it throughout the application. OMG!!! I used these directive for paging, regex, validations, etc. It is really cool!\n\nRouting is strong: It's up to your implementation how you want to use it, but it requires very few lines of code to route the request to specify HTML and controller (JavaScript)\n\nControllers are great: Controllers take care of their own HTML, but this separation works well for common functionality well as. If you want to call the same function on the click of a button on master HTML, just write the same function name in each controller and write individual code.\n\nPlugins: There are many other similar features like showing an overlay in your app. You don't need to write code for it, just use an overlay plugin available as wc-overlay, and this will automatically take care of all XMLHttpRequest (XHR) requests.\n\nIdeal for RESTful architecture: Being a complete frameworks makes AngularJS great to work with a RESTful architecture. To call REST CRUD APIs is very easier and\n\nServices: Write common codes using services and less code in controllers. Sevices can be used to share common functionalities among the controllers.\n\nExtensibility: Angular has extended the HTML directives using angular directives. Write expressions inside html and evaluate them on runtime. Create your own directives and services and use them in another project without any extra effort.\n\nShare\nedited May 24 '15 at 2:56\nanswered Sep 21 '14 at 16:44\nSanjeev Singh\n3,7202\n2 gold badges\n29\n29 silver badges\n38\n38 bronze badges","comments":[]},{"answer":"As a JavaScript MV* beginner and purely focusing on the application architecture (not the server/client-side matters), I would certainly recommend the following resource (which I am surprised wasn't mentioned yet): JavaScript Design Patterns, by Addy Osmani, as an introduction to different JavaScript Design Patterns. The terms used in this answer are taken from the linked document above. I'm not going to repeat what was worded really well in the accepted answer. Instead, this answer links back to the theoretical backgrounds which power AngularJS (and other libraries).\n\nLike me, you will quickly realize that AngularJS (or Ember.js, Durandal, & other MV* frameworks for that matter) is one complex framework assembling many of the different JavaScript design patterns.\n\nI found it easier also, to test (1) native JavaScript code and (2) smaller libraries for each one of these patterns separately before diving into one global framework. This allowed me to better understand which crucial issues a framework adresses (because you are personally faced with the problem).\n\nFor example:\n\nJavaScript Object-oriented Programming (this is a Google search link). It is not a library, but certainly a prerequisite to any application programming. It taught me the native implementations of the prototype, constructor, singleton & decorator patterns\njQuery/ Underscore for the facade pattern (like WYSIWYG's for manipulating the DOM)\nPrototype.js for the prototype/ constructor/ mixin pattern\nRequireJS/ Curl.js for the module pattern/ AMD\nKnockoutJS for the observable, publish/subscribe pattern\n\nNB: This list is not complete, nor 'the best libraries'; they just happen to be the libraries I used. These libraries also include more patterns, the ones mentioned are just their main focuses or original intents. If you feel something is missing from this list, please do mention it in the comments, and I will be glad to add it.\n\nShare\nedited Nov 29 '14 at 8:54\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 21 '14 at 11:59\nTyblitz\n8,0973\n3 gold badges\n21\n21 silver badges\n49\n49 bronze badges","comments":[]},{"answer":"Actually, if you're using AngularJS, you don't need jQuery anymore. AngularJS itself has the binding and directive, which is a very good \"replacement\" for most things you can do with jQuery.\n\nI usually develop mobile applications using AngularJS and Cordova. The ONLY thing from jQuery I needed is the Selector.\n\nBy googling, I see that there is a standalone jQuery selector module out there. It's Sizzle.\n\nAnd I decided to make a tiny code snippet that help me quickly start a website using AngularJS with the power of jQuery Selector (using Sizzle).\n\nI shared my code here: https://github.com/huytd/Sizzular\n\nShare\nedited Nov 22 '14 at 15:41\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 27 '14 at 6:04\nHuy Tran\n7551\n1 gold badge\n10\n10 silver badges\n22\n22 bronze badges","comments":[]}]},{"id":"237104","href":"https://stackoverflow.com/questions/237104/how-do-i-check-if-an-array-includes-a-value-in-javascript","title":"How do I check if an array includes a value in JavaScript?","description":"\n                \nWhat is the most concise and efficient way to find out if a JavaScript array contains a value?\nThis is the only way I know to do it:\nfunction contains(a, obj) {\n    for (var i = 0; i < a.length; i++) {\n        if (a[i] === obj) {\n            return true;\n        }\n    }\n    return false;\n}\n\nIs there a better and more concise way to accomplish this?\n    ","questionComments":["just tested: your way is actually the fastest for across browsers: jsperf.com/find-element-in-obj-vs-array/2 (apart from pre-saving a.length in a variable) while using indexOf (as in $.inArray) is much slower","many have replied that the Array#indexOf is your best choice here. But if you want something that can be correctly cast to Boolean, use this: ~[1,2,3].indexOf(4) will return 0 which will evaluate as false, whereas ~[1,2,3].indexOf(3) will return -3 which will evaluate as true.","~ is not what you want to use to convert to a boolean, for that you need !. But in this case you want to check equality with -1, s o the function might endreturn [1,2,3].indexOf(3) === -1; ~ is a binary not, it will invert each bit of the value individually.","@Iordvlad [1,2,3].indexOf(4) will actually return -1. As @mcfedr pointed out, ~ is the bitwise-NOT operator, see ES5 11.4.8. Thing is, since the binary representation of -1 consists of only 1's, it's complement is 0, which evaluates as false. The complement of any other number will be non-zero, hence true. So, ~ works just fine and is often used in conjunction with indexOf.","The title is misleading. Where is the [[1,2],[3,4]].includes([3,4]) ?"],"answers":[{"answer":"Modern browsers have Array#includes, which does exactly that and is widely supported by everyone except IE:\n\nconsole.log(['joe', 'jane', 'mary'].includes('jane')); //true\n Run code snippetExpand snippet\n\nYou can also use Array#indexOf, which is less direct, but doesn't require polyfills for outdated browsers.\n\nconsole.log(['joe', 'jane', 'mary'].indexOf('jane') >= 0); //true\n Run code snippetExpand snippet\n\nMany frameworks also offer similar methods:\n\njQuery: $.inArray(value, array, [fromIndex])\nUnderscore.js: _.contains(array, value) (also aliased as _.include and _.includes)\nDojo Toolkit: dojo.indexOf(array, value, [fromIndex, findLast])\nPrototype: array.indexOf(value)\nMooTools: array.indexOf(value)\nMochiKit: findValue(array, value)\nMS Ajax: array.indexOf(value)\nExt: Ext.Array.contains(array, value)\nLodash: _.includes(array, value, [from]) (is _.contains prior 4.0.0)\nRamda: R.includes(value, array)\n\nNotice that some frameworks implement this as a function, while others add the function to the array prototype.\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '20 at 17:51\ncommunity wiki\n\n\n37 revs, 22 users 18%\ncodeape","comments":["MooTools also has Array.contains that returns a boolean, which sounds like the real question here.","prototype also has Array.include that returns a boolean","If you are using a good browser, you can just use array.indexOf(object) != -1","Also, dont use indexOf alone as a condition, because the first element will return 0 and will be evaluated as falsy","inArray is a terrible name for a function that returns the index of the element, and -1 if it doesn't exist. I would expect a boolean to be returned."]},{"answer":"Update from 2019: This answer is from 2008 (11 years old!) and is not relevant for modern JS usage. The promised performance improvement was based on a benchmark done in browsers of that time. It might not be relevant to modern JS execution contexts. If you need an easy solution, look for other answers. If you need the best performance, benchmark for yourself in the relevant execution environments.\n\nAs others have said, the iteration through the array is probably the best way, but it has been proven that a decreasing while loop is the fastest way to iterate in JavaScript. So you may want to rewrite your code as follows:\n\nfunction contains(a, obj) {\n    var i = a.length;\n    while (i--) {\n       if (a[i] === obj) {\n           return true;\n       }\n    }\n    return false;\n}\n\n\nOf course, you may as well extend Array prototype:\n\nArray.prototype.contains = function(obj) {\n    var i = this.length;\n    while (i--) {\n        if (this[i] === obj) {\n            return true;\n        }\n    }\n    return false;\n}\n\n\nAnd now you can simply use the following:\n\nalert([1, 2, 3].contains(2)); // => true\nalert([1, 2, 3].contains('2')); // => false\n\nShare\nImprove this answer\nFollow\nedited Aug 7 '19 at 10:49\nanswered Oct 25 '08 at 23:10\nDamir Zekić\n14.7k2\n2 gold badges\n29\n29 silver badges\n34\n34 bronze badges","comments":["But be careful: stackoverflow.com/questions/237104/javascript-array-containsobj/…","\"Proven\" is a strong word. JS engines constantly improve, and execution time measured 3 years ago is terribly outdated.","@Damir - I agree. Perhaps change the sample to use indexOf if available, just so people copy-pasting this code blindly will get the best performance they can.","@cbmeeks yeah, care is definitely needed. It was probably a case of doing for (o in array) which shouldn't be done when looping through the array generally...","The best way to do this is check if [1, 2, 3].indexOf(1) > -1"]},{"answer":"indexOf maybe, but it's a \"JavaScript extension to the ECMA-262 standard; as such it may not be present in other implementations of the standard.\"\n\nExample:\n\n[1, 2, 3].indexOf(1) => 0\n[\"foo\", \"bar\", \"baz\"].indexOf(\"bar\") => 1\n[1, 2, 3].indexOf(4) => -1\n\n\nAFAICS Microsoft does not offer some kind of alternative to this, but you can add similar functionality to arrays in Internet Explorer (and other browsers that don't support indexOf) if you want to, as a quick Google search reveals (for example, this one).\n\nShare\nImprove this answer\nFollow\nedited Aug 11 '11 at 23:41\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 25 '08 at 22:49\ncic\n6,8983\n3 gold badges\n21\n21 silver badges\n34\n34 bronze badges","comments":["actually, there is an example of the an implementation of the indexOf extension for browsers that do not support it on the developer.mozilla.org page you linked to.","actually, if you add indexof to the prototype of Array for browsers that don't support it (i.e. IE7) they will also try to loop over this function when looping through the items in the array. nasty.","IE9 now supports this","is it applicable to check for the Object .? i don't think it works in case of the Object"]},{"answer":"ECMAScript 7 introduces Array.prototype.includes.\n\nIt can be used like this:\n\n[1, 2, 3].includes(2); // true\n[1, 2, 3].includes(4); // false\n\n\nIt also accepts an optional second argument fromIndex:\n\n[1, 2, 3].includes(3, 3); // false\n[1, 2, 3].includes(3, -1); // true\n\n\nUnlike indexOf, which uses Strict Equality Comparison, includes compares using SameValueZero equality algorithm. That means that you can detect if an array includes a NaN:\n\n[1, 2, NaN].includes(NaN); // true\n\n\nAlso unlike indexOf, includes does not skip missing indices:\n\nnew Array(5).includes(undefined); // true\n\n\nCurrently it's still a draft but can be polyfilled to make it work on all browsers.\n\nShare\nImprove this answer\nFollow\nedited Feb 8 '16 at 16:53\nanswered Jan 1 '15 at 1:40\nOriol\n232k47\n47 gold badges\n378\n378 silver badges\n463\n463 bronze badges","comments":["Not supported for IE and Microsfot Edge (2015) (developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/…)","Also relevant, the ES7 compatibility table (looks like chrome supports it now)","is it applicable to check for the Object .? i don't think it works in case of the Object"]},{"answer":"The top answers assume primitive types but if you want to find out if an array contains an object with some trait, Array.prototype.some() is an elegant solution:\n\nconst items = [ {a: '1'}, {a: '2'}, {a: '3'} ]\n\nitems.some(item => item.a === '3')  // returns true\nitems.some(item => item.a === '4')  // returns false\n\n\nThe nice thing about it is that the iteration is aborted once the element is found so unnecessary iteration cycles are spared.\n\nAlso, it fits nicely in an if statement since it returns a boolean:\n\nif (items.some(item => item.a === '3')) {\n  // do something\n}\n\n\n* As jamess pointed out in the comment, at the time of this answer, September 2018, Array.prototype.some() is fully supported: caniuse.com support table\n\nShare\nImprove this answer\nFollow\nedited Aug 24 '20 at 11:39\nanswered Jul 18 '14 at 14:36\nMichael\n20.2k33\n33 gold badges\n119\n119 silver badges\n174\n174 bronze badges","comments":["As of today, September 2018, Array.prototype.some() is fully supported: caniuse.com support table","Working in Node >=8.10 for AWS Node.js Lambda, so this is great. Very clean and simple solution! 👍🏻","@jamess It may be well supported, but remember that Arrow functions in this example are not so well supported. For more details see here: developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/…","Does some short-circuit? Or does it iterate the entire array even if it's found a value?","@DouglasGaskell it aborts the iteration once found (mentioned in the answer)"]},{"answer":"Let's say you've defined an array like so:\n\nconst array = [1, 2, 3, 4]\n\n\nBelow are three ways of checking whether there is a 3 in there. All of them return either true or false.\n\nNative Array method (since ES2016) (compatibility table)\narray.includes(3) // true\n\nAs custom Array method (pre ES2016)\n// Prefixing the method with '_' to avoid name clashes\nObject.defineProperty(Array.prototype, '_includes', { value: function (v) { return this.indexOf(v) !== -1 }})\narray._includes(3) // true\n\nSimple function\nconst includes = (a, v) => a.indexOf(v) !== -1\nincludes(array, 3) // true\n\nShare\nImprove this answer\nFollow\nedited Nov 13 '19 at 17:09\nGust van de Wal\n4,59619\n19 silver badges\n40\n40 bronze badges\nanswered Mar 24 '12 at 4:59\nwilliam malo\n2,3642\n2 gold badges\n16\n16 silver badges\n18\n18 bronze badges","comments":["It returns true if \"b\" is in the array \"a\"... I don't know how else to explain it...","This part I dont understand \"!!~\". And I think this will not work in IE8 because IE8 doesnt support indexOf() on Array object.","\"~\" is an operator that floors, inverts and subtracts 1 from a number. indexOf returns -1 if it fails, so \"~\" turns -1 into \"0\". using \"!!\" turns numbers into boleans (!!0===false)","Cool, but seriously for the sake of simplicity y not just a.indexOf(b)>-1, since \">-1\".length === \"!!~\".length","I'd call the lack of knowledge about the effects of boolean operators unprofessional. But I agree about the value of readable code, I would certainly wrap this in a clearly labelled function. And that's exactly what most major JS frameworks do."]},{"answer":"Here's a JavaScript 1.6 compatible implementation of Array.indexOf:\n\nif (!Array.indexOf) {\n    Array.indexOf = [].indexOf ?\n        function(arr, obj, from) {\n            return arr.indexOf(obj, from);\n        } :\n        function(arr, obj, from) { // (for IE6)\n            var l = arr.length,\n                i = from ? parseInt((1 * from) + (from < 0 ? l : 0), 10) : 0;\n            i = i < 0 ? 0 : i;\n            for (; i < l; i++) {\n                if (i in arr && arr[i] === obj) {\n                    return i;\n                }\n            }\n            return -1;\n        };\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 30 '19 at 10:23\nNarendra Jadhav\n9,10915\n15 gold badges\n28\n28 silver badges\n39\n39 bronze badges\nanswered Oct 27 '08 at 0:38\nMár Örlygsson\n13.6k3\n3 gold badges\n38\n38 silver badges\n51\n51 bronze badges","comments":["This looks great, but a little confused: * Aren't the tests on lines 1 and 3 equivalent? * Wouldn't it be better to test the prototype, and add the function to Array.prototype if necessary?","They aren't equvialent. [].indexOf is a shorthand for Array.prototype.indexOf. Us paranoid-defensive Javascript programmers avoid extending native prototypes at all cost.","Isn't [].indexOf creating a new array and then accessing indexOf, whilst Array.prototype.indexOf just accesses the prototype directly?","@alex yes [].indexOf === Array.prototype.indexOf (try it out in FireBug), but conversely [].indexOf !== Array.indexOf."]},{"answer":"Use:\n\nfunction isInArray(array, search)\n{\n    return array.indexOf(search) >= 0;\n}\n\n// Usage\nif(isInArray(my_array, \"my_value\"))\n{\n    //...\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 7 '17 at 11:29\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 13 '13 at 17:32\nMatías Cánepa\n5,1824\n4 gold badges\n49\n49 silver badges\n90\n90 bronze badges","comments":["x ? true : false is usually redundant. It is here.","@minitech Why do you say it is redundant?","array.indexOf(search) >= 0 is already a boolean. Just return array.indexOf(search) >= 0.","@minitech well thanks! Actually I didn't know that such a construction could be returned. TIL something new.","Literally any construct in javascript can be returned"]},{"answer":"Extending the JavaScript Array object is a really bad idea because you introduce new properties (your custom methods) into for-in loops which can break existing scripts. A few years ago the authors of the Prototype library had to re-engineer their library implementation to remove just this kind of thing.\n\nIf you don't need to worry about compatibility with other JavaScript running on your page, go for it, otherwise, I'd recommend the more awkward, but safer free-standing function solution.\n\nShare\nImprove this answer\nFollow\nedited Aug 11 '11 at 23:43\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 27 '09 at 16:45\nMason Houtz","comments":["I disagree. For-in loops should not be used for arrays for precisely this reason. Using for-in loops will break when using one of the popular js libraries","Would this be considered monkey patching? lol Some people like that."]},{"answer":"One-liner:\n\nfunction contains(arr, x) {\n    return arr.filter(function(elem) { return elem == x }).length > 0;\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 7 '17 at 11:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 7 '15 at 12:49\nAlonL\n5,4733\n3 gold badges\n30\n30 silver badges\n31\n31 bronze badges","comments":["array.filter(e=>e==x).length > 0 is equivalent to array.some(e=>e==x) but some is more efficient"]},{"answer":"Performance\n\nToday 2020.01.07 I perform tests on MacOs HighSierra 10.13.6 on Chrome v78.0.0, Safari v13.0.4 and Firefox v71.0.0 for 15 chosen solutions. Conclusions\n\nsolutions based on JSON, Set and surprisingly find (K,N,O) are slowest on all browsers\nthe es6 includes (F) is fast only on chrome\nthe solutions based on for (C,D) and indexOf (G,H) are quite-fast on all browsers on small and big arrays so probably they are best choice for efficient solution\nthe solutions where index decrease during loop, (B) is slower probably because the way of CPU cache works.\nI also run test for big array when searched element was on position 66% of array length, and solutions based on for (C,D,E) gives similar results (~630 ops/sec - but the E on safari and firefox was 10-20% slower than C and D)\nResults\n\nDetails\n\nI perform 2 tests cases: for array with 10 elements, and array with 1 milion elements. In both cases we put searched element in the array middle.\n\nShow code snippet\n\nArray small - 10 elements\n\nYou can perform tests in your machine HERE\n\nArray big - 1.000.000 elements\n\nYou can perform tests in your machine HERE\n\nShare\nImprove this answer\nFollow\nedited Mar 11 '20 at 16:26\nanswered Jan 7 '20 at 11:51\nKamil Kiełczewski\n57.6k22\n22 gold badges\n275\n275 silver badges\n253\n253 bronze badges","comments":[]},{"answer":"Thinking out of the box for a second, if you are making this call many many times, it is vastly more efficient to use an associative array a Map to do lookups using a hash function.\n\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map\n\nShare\nImprove this answer\nFollow\nedited May 6 '18 at 18:35\nanswered Dec 23 '09 at 15:59\nMattMcKnight\n7,96526\n26 silver badges\n34\n34 bronze badges","comments":["Although this is obviously helpful to many, it would have been better if a code snippet was added."]},{"answer":"I use the following:\n\nArray.prototype.contains = function (v) {\n    return this.indexOf(v) > -1;\n}\n\nvar a = [ 'foo', 'bar' ];\n\na.contains('foo'); // true\na.contains('fox'); // false\n\nShare\nImprove this answer\nFollow\nanswered Jun 15 '14 at 1:15\nEduardo Cuomo\n14.4k3\n3 gold badges\n95\n95 silver badges\n80\n80 bronze badges","comments":[]},{"answer":"function contains(a, obj) {\n    return a.some(function(element){return element == obj;})\n}\n\n\nArray.prototype.some() was added to the ECMA-262 standard in the 5th edition\n\nShare\nImprove this answer\nFollow\nanswered Sep 12 '14 at 16:55\ndansalmo\n10.5k5\n5 gold badges\n53\n53 silver badges\n49\n49 bronze badges","comments":["if using es6 than it cam be shorten as contains = (a, obj) => a.some((element) => element === obj))","Even IE9 has support for Array.prototype.some() as of ECMAScript 5."]},{"answer":"A hopefully faster bidirectional indexOf / lastIndexOf alternative\n\n2015\n\nWhile the new method includes is very nice, the support is basically zero for now.\n\nIt's long time that I was thinking of way to replace the slow indexOf/lastIndexOf functions.\n\nA performant way has already been found, looking at the top answers. From those I chose the contains function posted by @Damir Zekic which should be the fastest one. But it also states that the benchmarks are from 2008 and so are outdated.\n\nI also prefer while over for, but for not a specific reason I ended writing the function with a for loop. It could be also done with a while --.\n\nI was curious if the iteration was much slower if I check both sides of the array while doing it. Apparently no, and so this function is around two times faster than the top voted ones. Obviously it's also faster than the native one. This in a real world environment, where you never know if the value you are searching is at the beginning or at the end of the array.\n\nWhen you know you just pushed an array with a value, using lastIndexOf remains probably the best solution, but if you have to travel through big arrays and the result could be everywhere, this could be a solid solution to make things faster.\n\nBidirectional indexOf/lastIndexOf\n\nfunction bidirectionalIndexOf(a, b, c, d, e){\n  for(c=a.length,d=c*1; c--; ){\n    if(a[c]==b) return c; //or this[c]===b\n    if(a[e=d-1-c]==b) return e; //or a[e=d-1-c]===b\n  }\n  return -1\n}\n\n//Usage\nbidirectionalIndexOf(array,'value');\n\nPerformance test\n\nhttp://jsperf.com/bidirectionalindexof\n\nAs test I created an array with 100k entries.\n\nThree queries: at the beginning, in the middle & at the end of the array.\n\nI hope you also find this interesting and test the performance.\n\nNote: As you can see I slightly modified the contains function to reflect the indexOf & lastIndexOf output (so basically true with the index and false with -1). That shouldn't harm it.\n\nThe array prototype variant\nObject.defineProperty(Array.prototype,'bidirectionalIndexOf',{value:function(b,c,d,e){\n  for(c=this.length,d=c*1; c--; ){\n    if(this[c]==b) return c; //or this[c]===b\n    if(this[e=d-1-c] == b) return e; //or this[e=d-1-c]===b\n  }\n  return -1\n},writable:false, enumerable:false});\n\n// Usage\narray.bidirectionalIndexOf('value');\n\n\nThe function can also be easily modified to return true or false or even the object, string or whatever it is.\n\nAnd here is the while variant:\n\nfunction bidirectionalIndexOf(a, b, c, d){\n  c=a.length; d=c-1;\n  while(c--){\n    if(b===a[c]) return c;\n    if(b===a[d-c]) return d-c;\n  }\n  return c\n}\n\n// Usage\nbidirectionalIndexOf(array,'value');\n\nHow is this possible?\n\nI think that the simple calculation to get the reflected index in an array is so simple that it's two times faster than doing an actual loop iteration.\n\nHere is a complex example doing three checks per iteration, but this is only possible with a longer calculation which causes the slowdown of the code.\n\nhttp://jsperf.com/bidirectionalindexof/2\n\nShare\nImprove this answer\nFollow\nedited Jan 7 '17 at 11:42\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 19 '15 at 20:23\ncocco\n15.4k6\n6 gold badges\n54\n54 silver badges\n73\n73 bronze badges","comments":[]},{"answer":"If you are using JavaScript 1.6 or later (Firefox 1.5 or later) you can use Array.indexOf. Otherwise, I think you are going to end up with something similar to your original code.\n\nShare\nImprove this answer\nFollow\nanswered Oct 25 '08 at 22:44\nAndru Luvisi\n22.4k6\n6 gold badges\n49\n49 silver badges\n63\n63 bronze badges","comments":[]},{"answer":"function inArray(elem,array)\n{\n    var len = array.length;\n    for(var i = 0 ; i < len;i++)\n    {\n        if(array[i] == elem){return i;}\n    }\n    return -1;\n} \n\n\nReturns array index if found, or -1 if not found\n\nShare\nImprove this answer\nFollow\nedited Sep 6 '14 at 16:22\nmpromonet\n9,20342\n42 gold badges\n48\n48 silver badges\n81\n81 bronze badges\nanswered Jun 27 '12 at 12:32\nLemex\n3,66614\n14 gold badges\n48\n48 silver badges\n82\n82 bronze badges","comments":[]},{"answer":"If you are checking repeatedly for existence of an object in an array you should maybe look into\n\nKeeping the array sorted at all times by doing insertion sort in your array (put new objects in on the right place)\nMake updating objects as remove+sorted insert operation and\nUse a binary search lookup in your contains(a, obj).\nShare\nImprove this answer\nFollow\nanswered Feb 5 '11 at 18:02\nZtyx\n11.8k12\n12 gold badges\n67\n67 silver badges\n107\n107 bronze badges","comments":["Or if possible, stop using an Array entirely, and instead use an Object as a dictionary, as MattMcKnight and ninjagecko have suggested."]},{"answer":"We use this snippet (works with objects, arrays, strings):\n\n/*\n * @function\n * @name Object.prototype.inArray\n * @description Extend Object prototype within inArray function\n *\n * @param {mix}    needle       - Search-able needle\n * @param {bool}   searchInKey  - Search needle in keys?\n *\n */\nObject.defineProperty(Object.prototype, 'inArray',{\n    value: function(needle, searchInKey){\n\n        var object = this;\n\n        if( Object.prototype.toString.call(needle) === '[object Object]' || \n            Object.prototype.toString.call(needle) === '[object Array]'){\n            needle = JSON.stringify(needle);\n        }\n\n        return Object.keys(object).some(function(key){\n\n            var value = object[key];\n\n            if( Object.prototype.toString.call(value) === '[object Object]' || \n                Object.prototype.toString.call(value) === '[object Array]'){\n                value = JSON.stringify(value);\n            }\n\n            if(searchInKey){\n                if(value === needle || key === needle){\n                return true;\n                }\n            }else{\n                if(value === needle){\n                    return true;\n                }\n            }\n        });\n    },\n    writable: true,\n    configurable: true,\n    enumerable: false\n});\n\n\nUsage:\n\nvar a = {one: \"first\", two: \"second\", foo: {three: \"third\"}};\na.inArray(\"first\");          //true\na.inArray(\"foo\");            //false\na.inArray(\"foo\", true);      //true - search by keys\na.inArray({three: \"third\"}); //true\n\nvar b = [\"one\", \"two\", \"three\", \"four\", {foo: 'val'}];\nb.inArray(\"one\");         //true\nb.inArray('foo');         //false\nb.inArray({foo: 'val'})   //true\nb.inArray(\"{foo: 'val'}\") //false\n\nvar c = \"String\";\nc.inArray(\"S\");        //true\nc.inArray(\"s\");        //false\nc.inArray(\"2\", true);  //true\nc.inArray(\"20\", true); //false\n\nShare\nImprove this answer\nFollow\nanswered Sep 10 '14 at 12:12\ndr.dimitru\n2,4691\n1 gold badge\n26\n26 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"Solution that works in all modern browsers:\n\nfunction contains(arr, obj) {\n  const stringifiedObj = JSON.stringify(obj); // Cache our object to not call `JSON.stringify` on every iteration\n  return arr.some(item => JSON.stringify(item) === stringifiedObj);\n}\n\n\nUsage:\n\ncontains([{a: 1}, {a: 2}], {a: 1}); // true\n\n\nIE6+ solution:\n\nfunction contains(arr, obj) {\n  var stringifiedObj = JSON.stringify(obj)\n  return arr.some(function (item) {\n    return JSON.stringify(item) === stringifiedObj;\n  });\n}\n\n// .some polyfill, not needed for IE9+\nif (!('some' in Array.prototype)) {\n  Array.prototype.some = function (tester, that /*opt*/) {\n    for (var i = 0, n = this.length; i < n; i++) {\n      if (i in this && tester.call(that, this[i], i, this)) return true;\n    } return false;\n  };\n}\n\n\nUsage:\n\ncontains([{a: 1}, {a: 2}], {a: 1}); // true\n\nWhy to use JSON.stringify?\n\nArray.indexOf and Array.includes (as well as most of the answers here) only compare by reference and not by value.\n\n[{a: 1}, {a: 2}].includes({a: 1});\n// false, because {a: 1} is a new object\n\nBonus\n\nNon-optimized ES6 one-liner:\n\n[{a: 1}, {a: 2}].some(item => JSON.stringify(item) === JSON.stringify({a: 1));\n// true\n\n\nNote: Comparing objects by value will work better if the keys are in the same order, so to be safe you might sort the keys first with a package like this one: https://www.npmjs.com/package/sort-keys\n\nUpdated the contains function with a perf optimization. Thanks itinance for pointing it out.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 '17 at 23:34\nanswered Jan 25 '17 at 0:22\nIgor Barbashin\n7437\n7 silver badges\n8\n8 bronze badges","comments":["This particular chunk of code may work in IE6 (haven't tested), but IE didn't support ES5 until IE9.","For performance reasons you should avoid stringifying. At least you should avoid to JSON.stringify the \"obj\" on every loop because it is expensive and will slow down you application. Therefor you should capture it before the for-loop in a temp variable","@itinance good point. Updated the includes function with your suggestion. I've ran jsperf with my function. It's about 5x slower than lodash's includes. Though lodash doesn't compare by value and can't find {a: 1} in [{a: 1}]. I don't know if any library does it. But I'm curious if there's any more performant and not insanely complex way of doing it.","Late note: this doesn't work with, say, contains([{ a: 1, b: 2 }], { b: 2, a: 1 }) because the stringified objects maintain the order of the properties.","@HereticMonkey, true. That's why I added the sort-keys note at the bottom"]},{"answer":"Use lodash's some function.\n\nIt's concise, accurate and has great cross platform support.\n\nThe accepted answer does not even meet the requirements.\n\nRequirements: Recommend most concise and efficient way to find out if a JavaScript array contains an object.\n\nAccepted Answer:\n\n$.inArray({'b': 2}, [{'a': 1}, {'b': 2}])\n> -1\n\n\nMy recommendation:\n\n_.some([{'a': 1}, {'b': 2}], {'b': 2})\n> true\n\n\nNotes:\n\n$.inArray works fine for determining whether a scalar value exists in an array of scalars...\n\n$.inArray(2, [1,2])\n> 1\n\n\n... but the question clearly asks for an efficient way to determine if an object is contained in an array.\n\nIn order to handle both scalars and objects, you could do this:\n\n(_.isObject(item)) ? _.some(ary, item) : (_.indexOf(ary, item) > -1)\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '15 at 11:58\nanswered Oct 21 '15 at 10:57\nl3x\n28.2k1\n1 gold badge\n45\n45 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"ECMAScript 6 has an elegant proposal on find.\n\nThe find method executes the callback function once for each element present in the array until it finds one where callback returns a true value. If such an element is found, find immediately returns the value of that element. Otherwise, find returns undefined. callback is invoked only for indexes of the array which have assigned values; it is not invoked for indexes which have been deleted or which have never been assigned values.\n\nHere is the MDN documentation on that.\n\nThe find functionality works like this.\n\nfunction isPrime(element, index, array) {\n    var start = 2;\n    while (start <= Math.sqrt(element)) {\n        if (element % start++ < 1) return false;\n    }\n    return (element > 1);\n}\n\nconsole.log( [4, 6, 8, 12].find(isPrime) ); // Undefined, not found\nconsole.log( [4, 5, 8, 12].find(isPrime) ); // 5\n\n\nYou can use this in ECMAScript 5 and below by defining the function.\n\nif (!Array.prototype.find) {\n  Object.defineProperty(Array.prototype, 'find', {\n    enumerable: false,\n    configurable: true,\n    writable: true,\n    value: function(predicate) {\n      if (this == null) {\n        throw new TypeError('Array.prototype.find called on null or undefined');\n      }\n      if (typeof predicate !== 'function') {\n        throw new TypeError('predicate must be a function');\n      }\n      var list = Object(this);\n      var length = list.length >>> 0;\n      var thisArg = arguments[1];\n      var value;\n\n      for (var i = 0; i < length; i++) {\n        if (i in list) {\n          value = list[i];\n          if (predicate.call(thisArg, value, i, list)) {\n            return value;\n          }\n        }\n      }\n      return undefined;\n    }\n  });\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 7 '17 at 11:27\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 29 '14 at 16:55\nPradeep Mahdevu\n7,5372\n2 gold badges\n29\n29 silver badges\n28\n28 bronze badges","comments":["This is now a standard: ecma-international.org/ecma-262/6.0/#sec-array.prototype.find"]},{"answer":"While array.indexOf(x)!=-1 is the most concise way to do this (and has been supported by non-Internet Explorer browsers for over decade...), it is not O(1), but rather O(N), which is terrible. If your array will not be changing, you can convert your array to a hashtable, then do table[x]!==undefined or ===undefined:\n\nArray.prototype.toTable = function() {\n    var t = {};\n    this.forEach(function(x){t[x]=true});\n    return t;\n}\n\n\nDemo:\n\nvar toRemove = [2,4].toTable();\n[1,2,3,4,5].filter(function(x){return toRemove[x]===undefined})\n\n\n(Unfortunately, while you can create an Array.prototype.contains to \"freeze\" an array and store a hashtable in this._cache in two lines, this would give wrong results if you chose to edit your array later. JavaScript has insufficient hooks to let you keep this state, unlike Python for example.)\n\nShare\nImprove this answer\nFollow\nedited Jan 7 '17 at 11:30\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 22 '12 at 5:17\nninjagecko\n78.9k22\n22 gold badges\n131\n131 silver badges\n140\n140 bronze badges","comments":[]},{"answer":"One can use Set that has the method \"has()\":\n\nfunction contains(arr, obj) {\n      var proxy = new Set(arr);\n      if (proxy.has(obj))\n        return true;\n      else\n        return false;\n    }\n\n    var arr = ['Happy', 'New', 'Year'];\n    console.log(contains(arr, 'Happy'));\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jan 24 '20 at 12:16\nSuper Man\n1,6421\n1 gold badge\n15\n15 silver badges\n25\n25 bronze badges\nanswered Nov 16 '15 at 12:26\nrlib\n5,8963\n3 gold badges\n27\n27 silver badges\n37\n37 bronze badges","comments":["I think return proxy.has(obj) is much cleaner than two lines with if-else statement here","function contains(arr, obj) { return new Set(arr).has(obj); }"]},{"answer":"Use:\n\nvar myArray = ['yellow', 'orange', 'red'] ;\n\nalert(!!~myArray.indexOf('red')); //true\n\n\nDemo\n\nTo know exactly what the tilde ~ do at this point, refer to this question What does a tilde do when it precedes an expression?.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:03\nCommunity♦\n11\n1 silver badge\nanswered Oct 6 '13 at 12:25\nMina Gabriel\n17.7k23\n23 gold badges\n89\n89 silver badges\n120\n120 bronze badges","comments":["This was already posted year and half ago no need to repeat it.","Actually, it hasn't been posted. Not as an answer, but as a comment to an answer, and even then it's not clear and concise. Thanks for posting it, Mina Gabriel."]},{"answer":"Simple solution for this requirement is using find()\n\nIf you're having array of objects like below,\n\nvar users = [{id: \"101\", name: \"Choose one...\"},\n{id: \"102\", name: \"shilpa\"},\n{id: \"103\", name: \"anita\"},\n{id: \"104\", name: \"admin\"},\n{id: \"105\", name: \"user\"}];\n\n\nThen you can check whether the object with your value is already present or not\n\nlet data = users.find(object => object['id'] === '104');\n\n\nif data is null then no admin, else it will return the existing object like below.\n\n{id: \"104\", name: \"admin\"}\n\n\nThen you can find the index of that object in the array and replace the object using below code.\n\nlet indexToUpdate = users.indexOf(data);\nlet newObject = {id: \"104\", name: \"customer\"};\nusers[indexToUpdate] = newObject;//your new object\nconsole.log(users);\n\n\nyou will get value like below\n\n[{id: \"101\", name: \"Choose one...\"},\n{id: \"102\", name: \"shilpa\"},\n{id: \"103\", name: \"anita\"},\n{id: \"104\", name: \"customer\"},\n{id: \"105\", name: \"user\"}];\n\n\nhope this will help anyone.\n\nShare\nImprove this answer\nFollow\nanswered Oct 11 '19 at 17:38\nShiva\n4044\n4 silver badges\n8\n8 bronze badges","comments":[]},{"answer":"OK, you can just optimise your code to get the result!\n\nThere are many ways to do this which are cleaner and better, but I just wanted to get your pattern and apply to that using JSON.stringify, just simply do something like this in your case:\n\nfunction contains(a, obj) {\n    for (var i = 0; i < a.length; i++) {\n        if (JSON.stringify(a[i]) === JSON.stringify(obj)) {\n            return true;\n        }\n    }\n    return false;\n}\n\nShare\nImprove this answer\nFollow\nedited Feb 6 '19 at 14:48\nanswered Jul 2 '17 at 11:31\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":["Late note: this doesn't work with, say, contains([{ a: 1, b: 2 }], { b: 2, a: 1 }) because the stringified objects maintain the order of the properties."]},{"answer":"Surprised that this question still doesn't have latest syntax added, adding my 2 cents.\n\nLet's say we have array of Objects arrObj and we want to search obj in it.\n\nArray.prototype.indexOf -> (returns index or -1) is generally used for finding index of element in array. This can also be used for searching object but only works if you are passing reference to same object.\n\nlet obj = { name: 'Sumer', age: 36 };\nlet arrObj = [obj, { name: 'Kishor', age: 46 }, { name: 'Rupen', age: 26 }];\n\n\nconsole.log(arrObj.indexOf(obj));// 0\nconsole.log(arrObj.indexOf({ name: 'Sumer', age: 36 })); //-1\n\nconsole.log([1, 3, 5, 2].indexOf(2)); //3\n\n\nArray.prototype.includes -> (returns true or false)\n\nconsole.log(arrObj.includes(obj));  //true\nconsole.log(arrObj.includes({ name: 'Sumer', age: 36 })); //false\n\nconsole.log([1, 3, 5, 2].includes(2)); //true\n\n\nArray.prototype.find -> (takes callback, returns first value/object that returns true in CB).\n\nconsole.log(arrObj.find(e => e.age > 40));  //{ name: 'Kishor', age: 46 }\nconsole.log(arrObj.find(e => e.age > 40)); //{ name: 'Kishor', age: 46 }\n\nconsole.log([1, 3, 5, 2].find(e => e > 2)); //3\n\n\nArray.prototype.findIndex -> (takes callback, returns index of first value/object that returns true in CB).\n\nconsole.log(arrObj.findIndex(e => e.age > 40));  //1\nconsole.log(arrObj.findIndex(e => e.age > 40)); //1\n\nconsole.log([1, 3, 5, 2].findIndex(e => e > 2)); //1\n\n\nSince find and findIndex takes a callback, we can be fetch any object(even if we don't have the reference) from array by creatively setting the true condition.\n\nShare\nImprove this answer\nFollow\nanswered Apr 7 '19 at 13:42\nSumer\n1,66916\n16 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"    function countArray(originalArray) {\n     \n    \tvar compressed = [];\n    \t// make a copy of the input array\n    \tvar copyArray = originalArray.slice(0);\n     \n    \t// first loop goes over every element\n    \tfor (var i = 0; i < originalArray.length; i++) {\n     \n    \t\tvar count = 0;\t\n    \t\t// loop over every element in the copy and see if it's the same\n    \t\tfor (var w = 0; w < copyArray.length; w++) {\n    \t\t\tif (originalArray[i] == copyArray[w]) {\n    \t\t\t\t// increase amount of times duplicate is found\n    \t\t\t\tcount++;\n    \t\t\t\t// sets item to undefined\n    \t\t\t\tdelete copyArray[w];\n    \t\t\t}\n    \t\t}\n     \n    \t\tif (count > 0) {\n    \t\t\tvar a = new Object();\n    \t\t\ta.value = originalArray[i];\n    \t\t\ta.count = count;\n    \t\t\tcompressed.push(a);\n    \t\t}\n    \t}\n     \n    \treturn compressed;\n    };\n    \n    // It should go something like this:\n    \n    var testArray = new Array(\"dog\", \"dog\", \"cat\", \"buffalo\", \"wolf\", \"cat\", \"tiger\", \"cat\");\n    var newArray = countArray(testArray);\n    console.log(newArray);\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jan 24 '20 at 12:01\nSuper Man\n1,6421\n1 gold badge\n15\n15 silver badges\n25\n25 bronze badges\nanswered Dec 15 '18 at 10:27\nSanjay Magar\n1011\n1 silver badge\n2\n2 bronze badges","comments":[]},{"answer":"By no means the best, but I was just getting creative and adding to the repertoire.\n\nDo not use this\n\nObject.defineProperty(Array.prototype, 'exists', {\n  value: function(element, index) {\n\n    var index = index || 0\n\n    return index === this.length ? -1 : this[index] === element ? index : this.exists(element, ++index)\n  }\n})\n\n\n// Outputs 1\nconsole.log(['one', 'two'].exists('two'));\n\n// Outputs -1\nconsole.log(['one', 'two'].exists('three'));\n\nconsole.log(['one', 'two', 'three', 'four'].exists('four'));\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jan 9 '16 at 6:38\nsqram\n6,6098\n8 gold badges\n44\n44 silver badges\n61\n61 bronze badges","comments":["What should you use if not this?","@bryc maybe the accepted solution, or another solution from here. If you don't care much for performance, than you can use this"]}]},{"id":"67699","href":"https://stackoverflow.com/questions/67699/how-to-clone-all-remote-branches-in-git","title":"How to clone all remote branches in Git?","description":"\n                \nI have a master and a development branch, both pushed to GitHub. I've cloned, pulled, and fetched, but I remain unable to get anything other than the master branch back.\n\nI'm sure I'm missing something obvious, but I have read the manual and I'm getting no joy at all.\n    ","questionComments":["The accepted answer here (git branch -a) shows you the branches in the remote, but if you attempt to check any of those out you will be in a 'detached HEAD' state. The next answer down (second most upvotes) answers a different question (to wit: how to pull all branches, and, again, this only works for those you're tracking locally). Several of the comments point out that you could parse the git branch -a results with a shell script that would locally track all the remote branches. Summary: There's no git native way to do what you want and it might not be all that great an idea anyway.","Maybe just copy the entire folder the old fashioned way? scp some_user@example.com:/home/some_user/project_folder ~ Not sure if that solution works for github though..","Rather than saying \"I've cloned, pulled, and fetched,\" much better to show us the exact commands that you executed.","It always boggles me why \"clone\" isn't in the sense of an exact copy. If it's an exact clone, shouldn't all the branches be part of the local repository? I mean isn't that one of the point of being distributed? So when something repository is gone you still have a complete copy of everything. Or is it the so called \"remote\" really are part of the local repository already?","Seeing all the upvotes, answers, comments on answers and the mind-boggling number of views, I think it is time git added a command for doing this. And right you are @huggie, my thoughts exactly."],"answers":[{"answer":"First, clone a remote Git repository and cd into it:\n\n$ git clone git://example.com/myproject\n$ cd myproject\n\n\nNext, look at the local branches in your repository:\n\n$ git branch\n* master\n\n\nBut there are other branches hiding in your repository! You can see these using the -a flag:\n\n$ git branch -a\n* master\n  remotes/origin/HEAD\n  remotes/origin/master\n  remotes/origin/v1.0-stable\n  remotes/origin/experimental\n\n\nIf you just want to take a quick peek at an upstream branch, you can check it out directly:\n\n$ git checkout origin/experimental\n\n\nBut if you want to work on that branch, you'll need to create a local tracking branch which is done automatically by:\n\n$ git checkout experimental\n\n\nand you will see\n\nBranch experimental set up to track remote branch experimental from origin.\nSwitched to a new branch 'experimental'\n\n\nHere, \"new branch\" simply means that the branch is taken from the index and created locally for you. As the previous line tells you, the branch is being set up to track the remote branch, which usually means the origin/branch_name branch.\n\nNow, if you look at your local branches, this is what you'll see:\n\n$ git branch\n* experimental\n  master\n\n\nYou can actually track more than one remote repository using git remote.\n\n$ git remote add win32 git://example.com/users/joe/myproject-win32-port\n$ git branch -a\n* master\n  remotes/origin/HEAD\n  remotes/origin/master\n  remotes/origin/v1.0-stable\n  remotes/origin/experimental\n  remotes/win32/master\n  remotes/win32/new-widgets\n\n\nAt this point, things are getting pretty crazy, so run gitk to see what's going on:\n\n$ gitk --all &\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '20 at 17:58\nShreevatsaR\n36.3k16\n16 gold badges\n97\n97 silver badges\n122\n122 bronze badges\nanswered Sep 16 '08 at 13:28\nemk\n56.7k6\n6 gold badges\n40\n40 silver badges\n50\n50 bronze badges","comments":["How can someone create automatically all the remote branches, e.g. experimental for origin/experimental?","Cristian: I used to always create a branch 'foo' for every branch 'origin/foo', but this led to two problems: (1) I wound up with lots of really stale tracking branches that were many commits behind the corresponding remote branch, and (2) in older versions of git, running 'git push' would attempt to push all my local branches to a remote, even when those branches were stale. So now I only keep local branches for things that I'm actively developing, and access the origin/* branches directly if I need information about them. (That said, you could use a shell script to parse 'git branch -a'.)","\"git fetch <origin-name> <branch-name>\" brings the branch down locally for you.","Good answer, but kinda misses the question. I was looking for a one-liner to checkout all the remote branches.","The question was about cloning all remote branches, not checking them out. And, as I noted above, you really don't want to make any more local tracking branches than necessary, because when they get really stale, they can cause headaches."]},{"answer":"If you have many remote branches that you want to fetch at once, do:\n\n$ git pull --all\n\n\nNow you can checkout any branch as you need to, without hitting the remote repository.\n\nNote: This will not create working copies of any non-checked out branches, which is what the question was asking. For that, see\n\nhttps://stackoverflow.com/a/4754797/430062\nhttps://stackoverflow.com/a/7216269/430062\nShare\nImprove this answer\nFollow\nedited Sep 21 '20 at 17:51\nTheodore R. Smith\n19.1k12\n12 gold badges\n52\n52 silver badges\n83\n83 bronze badges\nanswered Jan 13 '11 at 16:42\nGabe Kopley\n15.3k5\n5 gold badges\n43\n43 silver badges\n59\n59 bronze badges","comments":["If I do git clone, I have the master branch locally and 10 branches \"remote\". So THIS answer by Gabe was very helpful and answers the question.","this only fetch remote branches that have been locally added not any remote branch","The first command is redundant. Simply git pull --all will do the same – it just won't fetch twice. And infosec812 is right that this does not answer the question anyway. I wonder how this got so many upvotes.","After I did git remote update, then tried git branch, I only see local branches. But if I do git branch -a I can now see the remote branches and I can do a git pull <branchname> to get the branch I want. -- I landed on this question from a Google search, and this answer solves my problem.","This is not helpful at all, doesn't pull any remote branches other than that is existing."]},{"answer":"This Bash script helped me out:\n\n#!/bin/bash\nfor branch in $(git branch --all | grep '^\\s*remotes' | egrep --invert-match '(:?HEAD|master)$'); do\n    git branch --track \"${branch##*/}\" \"$branch\"\ndone\n\n\nIt will create tracking branches for all remote branches, except master (which you probably got from the original clone command). I think you might still need to do a\n\ngit fetch --all\ngit pull --all\n\n\nto be sure.\n\nOne liner: git branch -a | grep -v HEAD | perl -ne 'chomp($_); s|^\\*?\\s*||; if (m|(.+)/(.+)| && not $d{$2}) {print qq(git branch --track $2 $1/$2\\n)} else {$d{$_}=1}' | csh -xfs\nAs usual: test in your setup before copying rm -rf universe as we know it\n\nCredits for one-liner go to user cfi\n\nShare\nImprove this answer\nFollow\nedited Nov 12 '19 at 14:56\nvinzee\n12k10\n10 gold badges\n35\n35 silver badges\n53\n53 bronze badges\nanswered Jan 21 '11 at 2:18\nbigfish\n5,0431\n1 gold badge\n12\n12 silver badges\n3\n3 bronze badges","comments":["This is really close to being a perfect solution.. The only thing that would make it better is if this functionality were built-in as an option in git.","\"One liner\": git branch -a | grep -v HEAD | perl -ne 'chomp($_); s|^\\*?\\s*||; if (m|(.+)/(.+)| && not $d{$2}) {print qq(git branch --track $2 $1/$2\\n)} else {$d{$_}=1}' | csh -xfs As usual: test in your setup before copying rm -rf universe as we know it","This command creates the feature branches from remote as normal branches (not feature branches) - how to fix this?","if you run into issues with \"/\" in branch names there is a solution below using a git alias. see answer by \"nobody\" on \"answered May 15 '13 at 11:02\"","I'm trimming just remotes/origin/ to preserve namespaces: for BRANCH in $(git branch -a | grep remotes | grep -v HEAD | grep -v master); do git branch --track \"${BRANCH#remotes/origin/}\" \"${BRANCH}\"; done"]},{"answer":"Using the --mirror option seems to copy the remote tracking branches properly. However, it sets up the repository as a bare repository, so you have to turn it back into a normal repository afterwards.\n\ngit clone --mirror path/to/original path/to/dest/.git\ncd path/to/dest\ngit config --bool core.bare false\ngit checkout anybranch\n\n\nReference: Git FAQ: How do I clone a repository with all remotely tracked branches?\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '15 at 9:21\noHo\n42.2k26\n26 gold badges\n142\n142 silver badges\n185\n185 bronze badges\nanswered Aug 27 '11 at 17:49\nDave\n4,0651\n1 gold badge\n11\n11 silver badges\n2\n2 bronze badges","comments":["You know this actually seems to be a pretty good answer even though it has no votes. Are there any pitfalls to doing it that way? I had to explicitly checkout a branch after running those commands.","This combined with git push --mirror are exactly what I needed to create an exact duplicate of a remote git repo when moving from github.com to a github enterprise install. Thanks!","@Dave: Add a final git checkout as last command to finally checkout the head of the current branch on the cloned repo. This is a great answer, by far the best. Be brave, eventually we'll get you to the top :-)","@Dave: Hm. I'm having second thoughts: --mirror does more than just setting up all branches as being tracked. It copies all refs from the origin and subsequent git remote update will do that again. Behaviour of pulls change. I'm back to believing the full copy requires a one-line script.","git clone --mirror is very good for backing up your git repositories ^_^"]},{"answer":"You can easily switch to a branch without using the fancy \"git checkout -b somebranch origin/somebranch\" syntax. You can do:\n\ngit checkout somebranch\n\n\nGit will automatically do the right thing:\n\n$ git checkout somebranch\nBranch somebranch set up to track remote branch somebranch from origin.\nSwitched to a new branch 'somebranch'\n\n\nGit will check whether a branch with the same name exists in exactly one remote, and if it does, it tracks it the same way as if you had explicitly specified that it's a remote branch. From the git-checkout man page of Git 1.8.2.1:\n\nIf <branch> is not found but there does exist a tracking branch in exactly one remote (call it <remote>) with a matching name, treat as equivalent to\n\n$ git checkout -b <branch> --track <remote>/<branch>\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '20 at 14:19\nHarry B\n2,5501\n1 gold badge\n18\n18 silver badges\n40\n40 bronze badges\nanswered May 12 '12 at 12:11\nNikos C.\n47.6k8\n8 gold badges\n59\n59 silver badges\n90\n90 bronze badges","comments":["So, if the name of the branch you checkout is the identical to the name of the remote branch, everything after the \"/\", then git will create a branch of the same name, everything after the \"/\", \"tracking\" that remote? And by tracking, we mean: git push, git pull, etc. will be done on that remote? If this is correct, then expand on your answer with more information, because I aggree with @Daniel, this answer deserves more rep.","@BullfrogBlues, the answer to all your questions appears to be yes (I'm using git v1.7.7.4). I agree this behavior should be better known. (It's not in the manual for this version of git.) I actually don't like this behavior, I'd rather get an error and have to say git checkout --track origin/somebranch explicitly.","@dubiousjim: Actually, this is in the manual. git-checkout(1) says: \"If <branch> is not found but there does exist a tracking branch in exactly one remote (call it <remote>) with a matching name, treat as equivalent to 'git checkout -b <branch> --track <remote>/<branch>' \" (Git V.1.8.1.1).","What we need is $ git pull * <remote>/* - where \"*\" is a wildcard, so it pulls all branches, including those not yet on the local system. How to do this? Are we really supposed to checkout/pull every branch just to get the code pulled to our local system?","Most importantly to me if it doesn't exist it doesn't create one."]},{"answer":"Regarding,\n\n$ git checkout -b experimental origin/experimental\n\nusing\n\n$ git checkout -t origin/experimental\n\n\nor the more verbose but easier to remember\n\n$ git checkout --track origin/experimental\n\n\nmight be better, in terms of tracking a remote repository.\n\nShare\nImprove this answer\nFollow\nedited Jul 9 '13 at 5:05\nxverges\n4,1861\n1 gold badge\n35\n35 silver badges\n58\n58 bronze badges\nanswered Jul 27 '09 at 6:10\nmurphytalk\n1,2531\n1 gold badge\n9\n9 silver badges\n13\n13 bronze badges","comments":["So you mean the second form is only easier to remember and there's no other difference?"]},{"answer":"The fetch that you are doing should get all the remote branches, but it won't create local branches for them. If you use gitk, you should see the remote branches described as \"remotes/origin/dev\" or something similar.\n\nTo create a local branch based on a remote branch, do something like:\n\ngit checkout -b dev refs/remotes/origin/dev\n\nWhich should return something like:\n\nBranch dev set up to track remote branch refs/remotes/origin/dev.\nSwitched to a new branch \"dev\"\n\nNow, when you are on the dev branch, \"git pull\" will update your local dev to the same point as the remote dev branch. Note that it will fetch all branches, but only pull the one you are on to the top of the tree.\n\nShare\nImprove this answer\nFollow\nanswered Sep 15 '08 at 22:52\nLuuk Paulussen\n8931\n1 gold badge\n6\n6 silver badges\n7\n7 bronze badges","comments":["You don't need refs/remotes here. git checkout -b dev origin/dev will work fine.","This will always work: git checkout -b newlocaldev --track origin/dev. If you want the local branch has the same name as the remote one, and the remote one doesn't have a tricky name, you can omit the -b newlocaldev. With the default branch.autosetupmerge config setting, and assuming you don't have a local branch named dev, these two commands may do the same thing: git checkout -b dev origin/dev and just plain git checkout dev. Finally, git checkout origin/dev doesn't create a new branch, but just puts you in detached HEAD state.","What happens when the remote no longer exists but Git is too stupid to acknowledge its been deleted? This assumes you updated and git branch -a continues to lists it as a remote branch.","And we do this for dozens of branches?"]},{"answer":"Use aliases. Though there aren't any native Git one-liners, you can define your own as\n\ngit config --global alias.clone-branches '! git branch -a | sed -n \"/\\/HEAD /d; /\\/master$/d; /remotes/p;\" | xargs -L1 git checkout -t'\n\n\nand then use it as\n\ngit clone-branches\n\nShare\nImprove this answer\nFollow\nedited Jun 16 '13 at 13:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 15 '13 at 11:02\nnobody\n6895\n5 silver badges\n3\n3 bronze badges","comments":["Thanks. This actually clones all remote branches unlike several of the other answers"]},{"answer":"When you do \"git clone git://location\", all branches and tags are fetched.\n\nIn order to work on top of a specific remote branch, assuming it's the origin remote:\n\ngit checkout -b branch origin/branchname\n\nShare\nImprove this answer\nFollow\nanswered Sep 15 '08 at 22:47\nelmarco\n28.3k21\n21 gold badges\n58\n58 silver badges\n68\n68 bronze badges","comments":["I appreciate your note \"all branches and tags are fetched\". I was going to comment on your answer being wrong, but then I checked it and found, you are perfectly right. So in a way, you have provided the shortest answer - if you cloned, you already have it. Nice. One could try to add: try $ git branch -a to learn, what remote branches are already available.","Have a look at the answer I posted as well. This might be helpful if you know you'll want to be working locally on many of the remote branches and not have to check them out one by one.","Can you explain to me what's the difference between git checkout -b master origin/master and git checkout --track origin/master please ?","@aderchox Nowadays, I think none."]},{"answer":"Better late than never, but here is the best way to do this:\n\nmkdir repo\ncd repo\ngit clone --bare path/to/repo.git .git\ngit config --unset core.bare\ngit reset --hard\n\n\nAt this point you have a complete copy of the remote repo with all of it's branches (verify with git branch). You can use --mirror instead of --bare if your remote repo has remotes of its own.\n\nShare\nImprove this answer\nFollow\nedited May 11 '17 at 21:08\nanswered Nov 26 '12 at 23:42\nJacob Fike\n8216\n6 silver badges\n7\n7 bronze badges","comments":["Something went wrong during the edits here. Now this answer doesn't make sense. The \"--bare\" mentioned in the last sentence doesn't exist in the given command list.","taking from Dave's answer below. Using 'git config --bool core.bare false' instead of 'git config unset core.bare' seems to do the job.","It's git config --unset core.bare actually... To me, this seems the cleanest solution of all presented in the answers here. A pity it has so few upvotes...","Thanks @ChrisSim I agree for git config --bool core.bare false. This is why I recommend instead the Dave's answer. What do you think about the Dave's answer? Cheers","This is absolutely the best answer, except that @FedericoCapaldo gave an answer that goes into a little more detail about exactly what these commands are doing."]},{"answer":"Why you only see \"master\"\n\ngit clone downloads all remote branches but still considers them \"remote\", even though the files are located in your new repository. There's one exception to this, which is that the cloning process creates a local branch called \"master\" from the remote branch called \"master\". By default, git branch only shows local branches, which is why you only see \"master\".\n\ngit branch -a shows all branches, including remote branches.\n\nHow to get local branches\n\nIf you actually want to work on a branch, you'll probably want a \"local\" version of it. To simply create local branches from remote branches (without checking them out and thereby changing the contents of your working directory), you can do that like this:\n\ngit branch branchone origin/branchone\ngit branch branchtwo origin/branchtwo\ngit branch branchthree origin/branchthree\n\n\nIn this example, branchone is the name of a local branch you're creating based on origin/branchone; if you instead want to create local branches with different names, you can do this:\n\ngit branch localbranchname origin/branchone\n\n\nOnce you've created a local branch, you can see it with git branch (remember, you don't need -a to see local branches).\n\nShare\nImprove this answer\nFollow\nedited Apr 2 '20 at 18:14\nNiroshan Ratnayake\n1,2951\n1 gold badge\n10\n10 silver badges\n15\n15 bronze badges\nanswered Mar 5 '14 at 13:47\nCerran\n1,8372\n2 gold badges\n19\n19 silver badges\n30\n30 bronze badges","comments":["If origin/branchone exists, you can also just use git checkout branchone to create a local branch with the same name and set it to track remote."]},{"answer":"This isn't too much complicated, very simple and straight forward steps are as follows;\n\ngit fetch origin This will bring all the remote branches to your local.\n\ngit branch -a This will show you all the remote branches.\n\ngit checkout --track origin/<branch you want to checkout>\n\nVerify whether you are in the desired branch by the following command;\n\ngit branch\n\n\nThe output will like this;\n\n*your current branch \nsome branch2\nsome branch3 \n\n\nNotice the * sign that denotes the current branch.\n\nShare\nImprove this answer\nFollow\nedited Jun 9 '16 at 5:16\nanswered Dec 26 '13 at 10:19\nSam\n1,5031\n1 gold badge\n17\n17 silver badges\n30\n30 bronze badges","comments":["Thanks suraj. The reason because its not been voted much. And the ans is not accepted by the questioner.","The \"git fetch origin\" did not bring any of the remote branches to my local - or are they hidden somewhere? Reading all the answers above gave me a headache. We are looking for \"git fetch all branches to local\". There must be a way aside from bash-scripts to do this.","Just after you execute \"git fetch origin\", it will show the output like this in your terminal - \"* [new branch] branch_name -> origin/branch_name\", but when you run \"git branch\" it will show you only your local branches instead, so to see all the branches you can do \"git branch -a\" and then to switch to the remote branch you need to run \" git checkout --track origin/<branch you want to checkout>\". Hope this helps. :-)","Suraj, because the question was, how to \"clone all remote branches\" - not how to manually update one at a time. It appears there is no answer to the actual question - just ways to do a whole lot of typing if you have a lot of branches."]},{"answer":"Just do this:\n\n$ git clone git://example.com/myproject\n$ cd myproject\n$ git checkout branchxyz\nBranch branchxyz set up to track remote branch branchxyz from origin.\nSwitched to a new branch 'branchxyz'\n$ git pull\nAlready up-to-date.\n$ git branch\n* branchxyz\n  master\n$ git branch -a\n* branchxyz\n  master\n  remotes/origin/HEAD -> origin/master\n  remotes/origin/branchxyz\n  remotes/origin/branch123\n\n\nYou see, 'git clone git://example.com/myprojectt' fetches everything, even the branches, you just have to checkout them, then your local branch will be created.\n\nShare\nImprove this answer\nFollow\nedited May 6 '13 at 16:22\nSteven Penny\n1\nanswered May 31 '11 at 11:40\nrapher\n4154\n4 silver badges\n3\n3 bronze badges","comments":[]},{"answer":"You only need to use \"git clone\" to get all branches.\n\ngit clone <your_http_url>\n\n\nEven though you only see master branch, you can use \"git branch -a\" to see all branches.\n\ngit branch -a\n\n\nAnd you can switch to any branch which you already have.\n\ngit checkout <your_branch_name>\n\n\nDon't worry that after you \"git clone\", you don't need to connect with the remote repo, \"git branch -a\" and \"git checkout \" can be run successfully when you close your wifi. So it is proved that when you do \"git clone\", it already has copied all branches from the remote repo. After that, you don't need the remote repo, your local already has all branches' codes.\n\nShare\nImprove this answer\nFollow\nanswered Nov 19 '14 at 15:43\nHaimei\n11.5k3\n3 gold badges\n45\n45 silver badges\n34\n34 bronze badges","comments":["Very clear response here. Lots of folks confused about this topic.","I'd like to second your statement \"can be run successfully when you close your wifi\". \"git clone\" really does result in a repo containing all branches."]},{"answer":"A git clone is supposed to copy the entire repository. Try cloning it, and then run git branch -a. It should list all the branches. If then you want to switch to branch \"foo\" instead of \"master\", use git checkout foo.\n\nShare\nImprove this answer\nFollow\nedited Oct 28 '17 at 15:33\nanswered Sep 15 '08 at 22:46\nMattoxBeckman\n3,6642\n2 gold badges\n18\n18 silver badges\n16\n16 bronze badges","comments":["You can run git commands with or without the hyphen. Both \"git-branch\" and \"git branch\" will work.","Maybe this answer was given a long time ago when git worked differently, but I think it's misleading today. git clone does download all the remote branches, but it only makes a local branch of master. Since git branch only shows local branches, you need git branch -a to see remote branches, too.","Thank you. This is kind of strange default behavior IMO. I'll just chalk it up to more cryptic gitness. If it downloaded the branches, why would it hide them when calling git branch?","@Cerran, thanks; I've updated my answer accordingly.","\"does download all the remote branches, but it only makes a local branch of master\". I need help understanding this. It seems git clone does NOT clone any branches except master, as when you do \"git branch -a\" it shows that the \"develop\" branch is only at \"remotes/origin/develop\". This must be saying that you dont have this branch anywhere locally, it only exists currently on the origin right?"]},{"answer":"all the answers I saw here are valid but there is a much cleaner way to clone a repository and to pull all the branches at once.\n\nWhen you clone a repository all the information of the branches is actually downloaded but the branches are hidden. With the command\n\n$ git branch -a\n\n\nyou can show all the branches of the repository, and with the command\n\n$ git checkout -b branchname origin/branchname\n\n\nyou can then \"download\" them manually one at a time.\n\nHowever, when you want to clone a repo with a lot of branches all the ways illustrated are above are lengthy and tedious in respect to a much cleaner and quicker way that I am going to show, though it's a bit complicated. You need three steps to accomplish this:\n\nFirst step\n\ncreate a new empty folder on your machine and clone a mirror copy of the .git folder from the repository:\n\n$ cd ~/Desktop && mkdir my_repo_folder && cd my_repo_folder\n$ git clone --mirror https://github.com/planetoftheweb/responsivebootstrap.git .git\n\n\nthe local repository inside the folder my_repo_folder is still empty, there is just a hidden .git folder now that you can see with a \"ls -alt\" command from the terminal.\n\nSecond step\n\nswitch this repository from an empty (bare) repository to a regular repository by switching the boolean value \"bare\" of the git configurations to false:\n\n$ git config --bool core.bare false\n\nThird Step\n\nGrab everything that inside the current folder and create all the branches on the local machine, therefore making this a normal repo.\n\n$ git reset --hard\n\n\nSo now you can just type the command \"git branch\" and you can see that all the branches are downloaded.\n\nThis is the quick way in which you can clone a git repository with all the branches at once, but it's not something you wanna do for every single project in this way.\n\nShare\nImprove this answer\nFollow\nanswered Dec 6 '15 at 20:08\nFedericoCapaldo\n1,30017\n17 silver badges\n28\n28 bronze badges","comments":["I don't like your usage of the word \"download\" in ... \"download\" them manually one at a time. All info is, in fact, already downloaded after having cloned the repo. The only thing one needs to do is creating local tracking branches (which is also possible when offline, which proves that all the information is in the repo).","@bvgheluwe that's why it is in quotes."]},{"answer":"Use my tool git_remote_branch (you need Ruby installed on your machine). It's built specifically to make remote branch manipulations dead easy.\n\nEach time it does an operation on your behalf, it prints it in red at the console. Over time, they finally stick into your brain :-)\n\nIf you don't want grb to run commands on your behalf, just use the 'explain' feature. The commands will be printed to your console instead of executed for you.\n\nFinally, all commands have aliases, to make memorization easier.\n\nNote that this is alpha software ;-)\n\nHere's the help when you run grb help:\n\ngit_remote_branch version 0.2.6\n\n  Usage:\n\n  grb create branch_name [origin_server] \n\n  grb publish branch_name [origin_server] \n\n  grb rename branch_name [origin_server] \n\n  grb delete branch_name [origin_server] \n\n  grb track branch_name [origin_server] \n\n\n\n  Notes:\n  - If origin_server is not specified, the name 'origin' is assumed \n    (git's default)\n  - The rename functionality renames the current branch\n\n  The explain meta-command: you can also prepend any command with the \nkeyword 'explain'. Instead of executing the command, git_remote_branch \nwill simply output the list of commands you need to run to accomplish \nthat goal.\n\n  Example: \n    grb explain create\n    grb explain create my_branch github\n\n  All commands also have aliases:\n  create: create, new\n  delete: delete, destroy, kill, remove, rm\n  publish: publish, remotize\n  rename: rename, rn, mv, move\n  track: track, follow, grab, fetch\n\nShare\nImprove this answer\nFollow\nanswered Sep 20 '08 at 13:53\nwebmat\n51.6k12\n12 gold badges\n52\n52 silver badges\n59\n59 bronze badges","comments":["Word to the wise: It looks like this project was abandoned around the time this answer was posted. I can't find any updates after 2008. Caveat emptor and all that. If I'm wrong, I hope someone will edit and provide a current pointer, because I'd love to have a tool like this handy.","@bradheintz check this answer, it sets up a git alias: stackoverflow.com/a/16563327/151841"]},{"answer":"Self-Contained Repository\n\nIf you’re looking for a self-contained clone or backup that includes all remote branches and commit logs, use:\n\ngit clone http://user@repo.url\n\ngit pull --all\n\n\nThe accepted answer of git branch -a only shows the remote branches. If you attempt to checkout the branches you'll be unable to unless you still have network access to the origin server.\n\nCredit: Gabe Kopley's for suggesting using git pull --all.\n\nNote:\nOf course, if you no longer have network access to the remote/origin server, remote/origin branches will not have any updates reflected in them. Their revisions will reflect commits from the date and time you performed the 2 commands above.\n\n\nCheckout a *local* branch in the usual way with `git checkout remote/origin/` Use `git branch -a` to reveal the remote branches saved within your `clone` repository.\n\nTo checkout ALL your clone branches to local branches with one command, use one of the bash commands below:\n\n$ for i in $(git branch -a |grep 'remotes' | awk -F/ '{print $3}' \\ \n| grep -v 'HEAD ->');do git checkout -b $i --track origin/$i; done\n\n\nOR\n\nIf your repo has nested branches then this command will take that into account:\n\nfor i in $(git branch -a |grep 'remotes' |grep -v 'HEAD ->');do \\\nbasename ${i##\\./} | xargs -I {} git checkout -b {} --track origin/{}; done\n\n\n\n\nThe above commands will checkout a local branch into your local git repository, named the same as the remote/origin/<branchname> and set it to --track changes from the remote branch on the remote/origin server should you regain network access to your origin repo server once more and perform a git pull command in the usual way.\n\nShare\nImprove this answer\nFollow\nedited Apr 7 at 16:29\nanswered Sep 25 '19 at 15:03\nTony Barganski\n1,33615\n15 silver badges\n13\n13 bronze badges","comments":["This is what I came her for!"]},{"answer":"Cloning from a local repo will not work with git clone & git fetch: a lot of branches/tags will remain unfetched.\n\nTo get a clone with all branches and tags.\n\ngit clone --mirror git://example.com/myproject myproject-local-bare-repo.git\n\n\nTo get a clone with all branches and tags but also with a working copy:\n\ngit clone --mirror git://example.com/myproject myproject/.git\ncd myproject\ngit config --unset core.bare\ngit config receive.denyCurrentBranch updateInstead\ngit checkout master\n\nShare\nImprove this answer\nFollow\nanswered Feb 23 '17 at 23:55\nraisercostin\n8,0093\n3 gold badges\n60\n60 silver badges\n68\n68 bronze badges","comments":[]},{"answer":"Looking at one of answers to the question I noticed that it's possible to shorten it:\n\nfor branch in  `git branch -r | grep -v 'HEAD\\|master'`; do  \n git branch --track ${branch##*/} $branch;\ndone\n\n\nBut beware, if one of remote branches is named as e.g. admin_master it won't get downloaded!\n\nThanks to bigfish for original idea\n\nShare\nImprove this answer\nFollow\nanswered Feb 19 '15 at 21:33\nTebe\n2,9747\n7 gold badges\n35\n35 silver badges\n56\n56 bronze badges","comments":["You can improve the regex, or maybe use Awk instead of grep, to improve the filter to avoid false positives.","all the branches are 'origin\\my_branch_name', which is not definitely what I want.","I've not seen the construct ${branch##*/} before - looks really useful - any idea where I can find out more on that? can't seem to find under bash anywhere. Thx."]},{"answer":"OK, when you clone your repo, you have all branches there...\n\nIf you just do git branch, they are kind of hidden...\n\nSo if you'd like to see all branches name, just simply add --all flag like this:\n\ngit branch --all or git branch -a\n\nIf you just checkout to the branch, you get all you need.\n\nBut how about if the branch created by someone else after you clone?\n\nIn this case, just do:\n\ngit fetch\n\nand check all branches again...\n\nIf you like to fetch and checkout at the same time, you can do:\n\ngit fetch && git checkout your_branch_name\n\nAlso created the image below for you to simplify what I said:\n\nShare\nImprove this answer\nFollow\nedited Mar 23 '18 at 4:05\nanswered Jul 22 '17 at 18:29\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":["There is a difference between \"you have it\" and \"you see it\". git branch -all will NOT list the remote branches any more when you remove the remote repository."]},{"answer":"#!/bin/bash\nfor branch in `git branch -a | grep remotes | grep -v HEAD | grep -v master `; do\n   git branch --track ${branch#remotes/origin/} $branch\ndone\n\n\nThese code will pull all remote branches code to local repo.\n\nShare\nImprove this answer\nFollow\nanswered Dec 11 '16 at 2:20\nAlbert.Qing\n3,6624\n4 gold badges\n33\n33 silver badges\n46\n46 bronze badges","comments":["ref. coderwall.com/p/0ypmka/git-clone-all-remote-branches-locally"]},{"answer":"For copy-paste into command line:\n\ngit checkout master ; remote=origin ; for brname in `git branch -r | grep $remote | grep -v master | grep -v HEAD | awk '{gsub(/^[^\\/]+\\//,\"\",$1); print $1}'`; do git branch -D $brname ; git checkout -b $brname $remote/$brname ; done ; git checkout master\n\n\nFor more readibility:\n\ngit checkout master ;\nremote=origin ;\nfor brname in `\n    git branch -r | grep $remote | grep -v master | grep -v HEAD \n    | awk '{gsub(/^[^\\/]+\\//,\"\",$1); print $1}'\n`; do\n    git branch -D $brname ;\n    git checkout -b $brname $remote/$brname ;\ndone ;\ngit checkout master\n\n\nThis will:\n\ncheck out master (so that we can delete branch we are on)\nselect remote to checkout (change it to whatever remote you have)\nloop through all branches of the remote except master and HEAD\ndelete local branch (so that we can check out force-updated branches)\ncheck out branch from the remote\ncheck out master (for the sake of it)\n\nBased on answer of VonC.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:47\nCommunity♦\n11\n1 silver badge\nanswered Dec 20 '13 at 6:38\nikaruss\n4714\n4 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"None of these answers cut it, except user nobody is on the right track.\n\nI was having trouble with moving a repo from one server/system to another. When I cloned the repo, it only created a local branch for master so when I pushed to the new remote, only master branch was pushed.\n\nSo I found these two methods VERY useful. Hope they help someone else.\n\nMethod 1:\n\ngit clone --mirror OLD_REPO_URL\ncd new-cloned-project\nmkdir .git\nmv * .git\ngit config --local --bool core.bare false\ngit reset --hard HEAD\ngit remote add newrepo NEW_REPO_URL\ngit push --all newrepo\ngit push --tags newrepo\n\n\nMethod 2:\n\ngit config --global alias.clone-branches '! git branch -a | sed -n \"/\\/HEAD /d; /\\/master$/d; /remotes/p;\" | xargs -L1 git checkout -t'\ngit clone OLD_REPO_URL\ncd new-cloned-project\ngit clone-branches\ngit remote add newrepo NEW_REPO_URL\ngit push --all newrepo\ngit push --tags newrepo\n\nShare\nImprove this answer\nFollow\nanswered Jan 23 '15 at 17:51\nGaui\n8,03513\n13 gold badges\n60\n60 silver badges\n86\n86 bronze badges","comments":[]},{"answer":"I wrote this small Powershell functions to be able to checkout all my git branches, that are on origin remote.\n\nFunction git-GetAllRemoteBranches {\n     iex \"git branch -r\"                       <# get all remote branches #> `\n     | % { $_ -Match \"origin\\/(?'name'\\S+)\" }  <# select only names of the branches #> `\n     | % { Out-Null; $matches['name'] }        <# write does names #>\n}\n\n\nFunction git-CheckoutAllBranches {\n    git-GetAllRemoteBranches `\n        | % { iex \"git checkout $_\" }          <# execute ' git checkout <branch>' #>\n}\n\n\nMore git functions can be found on my git settings repo\n\nShare\nImprove this answer\nFollow\nanswered Jun 19 '16 at 10:54\ngringo_dave\n1,17416\n16 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"Here's an answer that uses awk. This method should suffice if used on a new repo.\n\ngit branch -r | awk -F/ '{ system(\"git checkout \" $NF) }'\n\n\nExisting branches will simply be checked out, or declared as already in it, but filters can be added to avoid the conflicts.\n\nIt can also be modified so it calls an explicit git checkout -b <branch> -t <remote>/<branch> command.\n\nThis answer follows Nikos C.'s idea.\n\nAlternatively we can specify the remote branch instead. This is based on murphytalk's answer.\n\ngit branch -r | awk '{ system(\"git checkout -t \" $NF) }'\n\n\nIt throws fatal error messages on conflicts but I see them harmless.\n\nBoth commands can be aliased.\n\nUsing nobody's answer as reference, we can have the following commands to create the aliases:\n\ngit config --global alias.clone-branches '! git branch -r | awk -F/ \"{ system(\\\"git checkout \\\" \\$NF) }\"'\ngit config --global alias.clone-branches '! git branch -r | awk \"{ system(\\\"git checkout -t \\\" \\$NF) }\"'\n\n\nPersonally I'd use track-all or track-all-branches.\n\nShare\nImprove this answer\nFollow\nanswered Jun 20 '19 at 14:05\nkonsolebox\n62.1k9\n9 gold badges\n87\n87 silver badges\n95\n95 bronze badges","comments":["Just wanted to thank you. This worked perfectly and it doesn't suffer from various problems related to cloning a bare repo such as some pull behaviour changing etc."]},{"answer":"git clone --mirror on the original repo works well for this.\n\ngit clone --mirror /path/to/original.git\ngit remote set-url origin /path/to/new-repo.git\ngit push -u origin\n\nShare\nImprove this answer\nFollow\nanswered May 25 '18 at 17:34\nBernd Jungblut\n3192\n2 silver badges\n5\n5 bronze badges","comments":["The simplest way of cloning all branches!"]},{"answer":"I needed to do exactly the same. Here is my Ruby script.\n\n#!/usr/bin/env ruby\n\nlocal = []\nremote = {}\n\n# Prepare\n%x[git reset --hard HEAD]\n%x[git checkout master] # Makes sure that * is on master.\n%x[git branch -a].each_line do |line|\n  line.strip!\n  if /origin\\//.match(line)\n     remote[line.gsub(/origin\\//, '')] = line\n   else\n     local << line\n   end\nend\n# Update \nremote.each_pair do |loc, rem|\n  next if local.include?(loc)\n  %x[git checkout --track -b #{loc} #{rem}]\nend\n%x[git fetch]\n\nShare\nImprove this answer\nFollow\nedited Jun 16 '13 at 13:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 10 '10 at 23:12\nuser43685\n1,3563\n3 gold badges\n16\n16 silver badges\n21\n21 bronze badges","comments":["See answer I posted further down to avoid having to run this script at all."]},{"answer":"Here is another short one-liner command which creates local branches for all remote branches:\n\n(git branch -r | sed -n '/->/!s#^  origin/##p' && echo master) | xargs -L1 git checkout\n\n\nIt works also properly if tracking local branches are already created. You can call it after the first git clone or any time later.\n\nIf you do not need to have master branch checked out after cloning, use\n\ngit branch -r | sed -n '/->/!s#^  origin/##p'| xargs -L1 git checkout\n\nShare\nImprove this answer\nFollow\nanswered Sep 10 '15 at 12:04\njofel\n3,03214\n14 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"Git usually (when not specified) fetches all branches and/or tags (refs, see: git ls-refs) from one or more other repositories along with the objects necessary to complete their histories. In other words it fetches the objects which are reachable by the objects that are already downloaded. See: What does git fetch really do?\n\nSometimes you may have branches/tags which aren't directly connected to the current one, so git pull --all/git fetch --all won't help in that case, but you can list them by:\n\ngit ls-remote -h -t origin\n\n\nand fetch them manually by knowing the ref names.\n\nSo to fetch them all, try:\n\ngit fetch origin --depth=10000 $(git ls-remote -h -t origin)\n\n\nThe --depth=10000 parameter may help if you've shallowed repository.\n\nThen check all your branches again:\n\ngit branch -avv\n\n\nIf above won't help, you need to add missing branches manually to the tracked list (as they got lost somehow):\n\n$ git remote -v show origin\n...\n  Remote branches:\n    master      tracked\n\n\nby git remote set-branches like:\n\ngit remote set-branches --add origin missing_branch\n\n\nso it may appear under remotes/origin after fetch:\n\n$ git remote -v show origin\n...\n  Remote branches:\n    missing_branch new (next fetch will store in remotes/origin)\n$ git fetch\nFrom github.com:Foo/Bar\n * [new branch]      missing_branch -> origin/missing_branch\n\nTroubleshooting\n\nIf you still cannot get anything other than the master branch, check the followings:\n\nDouble check your remotes (git remote -v), e.g.\nValidate that git config branch.master.remote is origin.\nCheck if origin points to the right URL via: git remote show origin (see this post).\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:26\nCommunity♦\n11\n1 silver badge\nanswered Mar 31 '16 at 0:48\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges","comments":[]}]},{"id":"11828270","href":"https://stackoverflow.com/questions/11828270/how-do-i-exit-the-vim-editor","title":"How do I exit the Vim editor?","description":"\n                \nI'm stuck and cannot escape. It says:\n\n\"type :quit<Enter> to quit VIM\"\n\n\nBut when I type that it simply appears in the object body.\n    ","questionComments":["Are you just trying to quit VIM ? If this is the case, press \"escape\" and then type ':q'","Don't forget the colon! You should type :quit and then hit the [ENTER] key.","It's really easy to learn the basics of vim, and it's built right into your system. In terminal type \"vimtutor\". 25 minutes later you will be going faster than your usual text editor!","Check here more commands.","To prevent git commit sending you to vim in the future: git config --global core.editor=\"nano\""],"answers":[{"answer":"Hit the Esc key to enter \"Normal mode\". Then you can type : to enter \"Command-line mode\". A colon (:) will appear at the bottom of the screen and you can type in one of the following commands. To execute a command, press the Enter key.\n\n:q to quit (short for :quit)\n:q! to quit without saving (short for :quit!)\n:wq to write and quit\n:wq! to write and quit even if file has only read permission (if file does not have write permission: force write)\n:x to write and quit (similar to :wq, but only write if there are changes)\n:exit to write and exit (same as :x)\n:qa to quit all (short for :quitall)\n:cq to quit without saving and make Vim return non-zero error (i.e. exit with error)\n\nYou can also exit Vim directly from \"Normal mode\" by typing ZZ to save and quit (same as :x) or ZQ to just quit (same as :q!). (Note that case is important here. ZZ and zz do not mean the same thing.)\n\nVim has extensive help - that you can access with the :help command - where you can find answers to all your questions and a tutorial for beginners.\n\nShare\nImprove this answer\nFollow\nedited Apr 2 '19 at 1:22\nandrybak\n1,7862\n2 gold badges\n16\n16 silver badges\n35\n35 bronze badges\nanswered Aug 6 '12 at 12:46\ndirvine\n50.4k2\n2 gold badges\n14\n14 silver badges\n19\n19 bronze badges","comments":["Unless you have remapped esc or have a weird mapping in your .vimrc then it definitely should. If on linux type xev and make sure escape is the keytype you get when you hit escape.","Remember you can use ctrl+c if you can't use Esc (like me because my shell is in TotalTerminal). vim.wikia.com/wiki/Avoid_the_escape_key",":x == ZZ but :x != :wq. :x write file iff file has changed, :wq write file always (matter i.e. when using inotify).","To be honest, I have a harder time using vim's help system than using vim itself, and mostly rely on quick ref cards and online documentation.","if you don't have permissions on the file but have sudo permissions :w ! sudo tee %"]},{"answer":"Pictures are worth a thousand Unix commands and options:\n\nI draw this to my students each semester and they seem to grasp vi afterwards.\n\nVi is a finite state machine with only three states.\n\nUpon starting, vi goes into COMMAND mode, where you can type short, few character commands, blindly. You know what you are doing; this isn't for amateurs.\n\nWhen you want to actually edit text, you should go to INSERT mode with some one-character command:\n\ni: go to INSERT in the place of the cursor\nI: go to INSERT mode at the beginning of the line\na: append after the cursor\nA: append at the end of line\no: open a new line below the current line\nO: open a new line in the place of the current line\n\nNow, answering the question: exiting.\n\nYou can exit vi from EX mode:\n\nq: if you haven't made any modifications, or saved them beforehand\nq!: ignores any modifications and quit\nwq: save and quit\nx: this is equal to wq\n\nw and x accept a file name parameter. If you started vi with a filename, you need not give it here again.\n\nAt last, the most important: how can you reach EX mode?\n\nEX mode is for long commands that you can see typing at the bottom line of the screen. From COMMAND mode, you push colon, :, and a colon will appear at the bottom line, where you can type the above commands.\n\nFrom INSERT mode, you need to push ESC, i.e. the Escape button, going to COMMAND mode, and then: to go to EX mode.\n\nIf you are unsure, push ESC and that will bring you to command mode.\n\nThe robust method is ESC-:-x-Enter which saves your file and quits.\n\nShare\nImprove this answer\nFollow\nedited Jul 29 at 20:32\nZoe\n23.9k16\n16 gold badges\n101\n101 silver badges\n139\n139 bronze badges\nanswered May 26 '17 at 12:24\nGergely\n5,0032\n2 gold badges\n21\n21 silver badges\n30\n30 bronze badges","comments":["Thank you, the image is very helpful. However, for me w doesn't change from Ex to Command mode, but Esc does. What am I doing wrong?","If you write w-Enter that saves your file and goes back to COMMAND mode. I wrote it to have a full picture of save & quit commands.","oh, so you mean :w. Then it makes perfect sense. By the way, is there a command to reload from disk (that is, to revert changes but not close the file)? If so, it could be next to w in the diagram.","What you've labeled command mode is actually normal mode. What you've labeled ex mode is actually command mode. Ex mode is a different beast altogether!","@Gergely Well, I finally found the vim documentation: :help vim-modes."]},{"answer":"Before you enter a command, hit the Esc key. After you enter it, hit the Return to confirm.\n\nEsc finishes the current command and switches Vim to normal mode. Now if you press :, the : will appear at the bottom of the screen. This confirms that you're actually typing a command and not editing the file.\n\nMost commands have abbreviations, with optional part enclosed in brackets: c[ommand].\n\nCommands marked with '*' are Vim-only (not implemented in Vi).\n\nSafe-quit (fails if there are unsaved changes):\n\n:q[uit] Quit the current window. Quit Vim if this is the last window. This fails when changes have been made in current buffer.\n:qa[ll]* Quit all windows and Vim, unless there are some buffers which have been changed.\n\nPrompt-quit (prompts if there are unsaved changes)\n\n:conf[irm] q[uit]* Quit, but give prompt when there are some buffers which have been changed.\n:conf[irm] xa[ll]* Write all changed buffers and exit Vim. Bring up a prompt when some buffers cannot be written.\n\nWrite (save) changes and quit:\n\n:wq Write the current file (even if it was not changed) and quit. Writing fails when the file is read-only or the buffer does not have a name. :wqa[ll]* for all windows.\n:wq! The same, but writes even read-only files. :wqa[ll]!* for all windows.\n:x[it], ZZ(with details). Write the file only if it was changed and quit, :xa[ll]* for all windows.\n\nDiscard changes and quit:\n\n:q[uit]! ZQ* Quit without writing, also when visible buffers have changes. Does not exit when there are changed hidden buffers.\n:qa[ll]!*, :quita[ll][!]* Quit Vim, all changes to the buffers (including hidden) are lost.\n\nPress Return to confirm the command.\n\nThis answer doesn't reference all Vim write and quit commands and arguments. Indeed, they are referenced in the Vim documentation.\n\nVim has extensive built-in help, type Esc:helpReturn to open it.\n\nThis answer was inspired by the other one, originally authored by @dirvine and edited by other SO users. I've included more information from Vim reference, SO comments and some other sources. Differences for Vi and Vim are reflected too.\n\nShare\nImprove this answer\nFollow\nedited Mar 12 '18 at 18:33\nL3viathan\n24.2k2\n2 gold badges\n46\n46 silver badges\n66\n66 bronze badges\nanswered Jun 8 '15 at 13:34\nNick Volynkin\n12.1k6\n6 gold badges\n39\n39 silver badges\n63\n63 bronze badges","comments":[]},{"answer":"If you want to quit without saving in Vim and have Vim return a non-zero exit code, you can use :cq.\n\nI use this all the time because I can't be bothered to pinky shift for !. I often pipe things to Vim which don't need to be saved in a file. We also have an odd SVN wrapper at work which must be exited with a non-zero value in order to abort a checkin.\n\nShare\nImprove this answer\nFollow\nedited Jul 30 '18 at 16:53\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 28 '14 at 10:59\nSue Spence\n1,1278\n8 silver badges\n14\n14 bronze badges","comments":["I also use this to abort a git commit, or visudo, or crontab, …","Aborting a git commit with :q! works fine, since git's checking for a non-empty message and not a non-zero exit code.","I know it works, it's just that :cq doesn't require the shift key. :-)"]},{"answer":"This is for the worst-case scenario of exiting Vim if you just want out, have no idea what you've done and you don't care what will happen to the files you opened.\n\nCtrl-cEnterEnterviEnterCtrl-</kbd>Ctrl-n:qa!Enter\n\nThis should get you out most of the time.\n\nSome interesting cases where you need something like this:\n\niCtrl-ovg (you enter insert mode, then visual mode and then operator pending mode)\n\nQappendEnter\n\niCtrl-ogQCtrl-r=Ctrl-k (thanks to porges for this case)\n\n:set insertmode (this is a case when Ctrl-</kbd>Ctrl-n returns you to normal mode)\n\nThis answer was corrected due to cases above. It used to be:\n\nEscEscEsc:qa!Enter\n\nHowever, that doesn't work if you have entered Ex mode. In that case you would need to do:\n\nviEnter:qa!Enter\n\nSo a complete command for \"I don't want to know what I've done and I don't want to save anything, I just want out now!\" would be\n\nviEnterEscEscEsc:qa!Enter\n\nShare\nImprove this answer\nFollow\nedited Jul 29 at 18:57\nZoe\n23.9k16\n16 gold badges\n101\n101 silver badges\n139\n139 bronze badges\nanswered Jun 24 '15 at 13:38\nHeikki Naski\n2,1101\n1 gold badge\n17\n17 silver badges\n13\n13 bronze badges","comments":["@cavalcade This is an extremely general method of ensuring the editor is in normal mode then safely quitting. In normal usage all you need is :q or :wq","Not general enough! What about if I (a beginner) typed i<Ctrl-O>gQ<Ctrl-R>=<Ctrl-K>?","@porges thanks for the test case! There are also some other test cases which prove that the original method was woeful. I edited the answer to be more general now.","@HeikkiNaski at least for me I need Enter after Ctrl-C as well (to escape the expression register)"]},{"answer":"In case you need to exit Vim in easy mode (while using -y option) you can enter normal Vim mode by hitting Ctrl + L and then any of the normal exiting options will work.\n\nShare\nImprove this answer\nFollow\nedited Mar 30 '18 at 19:26\nK.Dᴀᴠɪs\n9,44911\n11 gold badges\n31\n31 silver badges\n39\n39 bronze badges\nanswered Jul 18 '14 at 13:48\nwsams\n2,1707\n7 gold badges\n32\n32 silver badges\n43\n43 bronze badges","comments":["Yet another option: you can use Ctrl+O to leave INSERT mode temporarily then enter :q. Trick with this combination is useful in normal vim as well to execute single command and return back to INSERT mode."]},{"answer":"Vim has three modes of operation: Input mode, Command mode & Ex mode.\n\nInput mode - everything that you type, all keystrokes are echoed on the screen.\n\nCommand mode or Escape mode - everything that you type in this mode is interpreted as a command.\n\nEx mode - this is another editor, ex. It is a line editor. It works per line or based on a range of lines. In this mode, a : appears at the bottom of the screen. This is the ex editor.\n\nIn order to exit Vim, you can exit while you are in either the ex mode or in the command mode. You cannot exit Vim when you are in input mode.\n\nExiting from ex mode\n\nYou need to be sure that you are in the Command mode. To do that, simply press the Esc key.\n\nGo to the ex mode by pressing the : key\n\nUse any of the following combinations in ex mode to exit:\n\n:q - quit :q! - quit without saving :wq - save & quit or write & quit :wq! - same as wq, but force write in case file permissions are readonly :x - write & quit :qa - quit all. useful when multiple files are opened like: vim abc.txt xyz.txt\n\nExiting from command mode\n\nPress the escape key. You probably have done this already if you are in command mode.\n\nPress capital ZZ (shift zz) - save & exit\n\nPress capital ZQ (shift zq) - exit without saving.\n\nShare\nImprove this answer\nFollow\nedited Jul 30 '18 at 19:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 24 '17 at 2:46\ntovishalck\n8708\n8 silver badges\n16\n16 bronze badges","comments":["What you're calling \"ex mode\" is actually called command-line mode. It allows you to enter ex commands, but with some important differences.","Hmm no. You're forgetting visual mode."]},{"answer":"After hitting ESC (or cmd + C on my computer) you must hit : for the command prompt to appear. Then, you may enter quit.\n\nYou may find that the machine will not allow you to quit because your information hasn't been saved. If you'd like to quit anyway, enter ! directly after the quit (i.e. :quit!).\n\nShare\nImprove this answer\nFollow\nedited Jun 27 '16 at 15:24\nmtb\n1,26814\n14 silver badges\n29\n29 bronze badges\nanswered Nov 28 '14 at 15:25\ndeleteMe\n3233\n3 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"I got Vim by installing a Git client on Windows. :q wouldn't exit Vim for me. :exit did however...\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '16 at 20:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 5 '15 at 11:30\nBjørn van Dommelen\n9575\n5 silver badges\n13\n13 bronze badges","comments":["Similarly for vim doing git on a macintosh this worked.","@Joel just checked this on my mac, both commands are legit (vim -version 7.3).","For Git Bash on windows, in Vim sometimes ESC not working. use CTRL + [ instead.","@Val That looks strangely familiar. Iirc that's because the two do the same thing. As in ^[ is the same as ESC. That's interesting that Windows makes it more complicated. And amusing."]},{"answer":"The q command with a number closes the given split in that position.\n\n:q<split position> or :<split position>q will close the split in that position.\n\nLet's say your Vim window layout is as follows:\n\n-------------------------------------------------\n|               |               |               |\n-------------------------------------------------\n|               |               |               |\n|               |               |               |\n|    Split 1    |    Split 2    |     Split 3   |\n|               |               |               |\n-------------------------------------------------\n\n\nIf you run the q1 command, it will close the first split. q2 will close the second split and vice versa.\n\nThe order of split position in the quit command does not matter. :2q or :q2 will close the second split.\n\nIf the split position you pass to the command is greater than the number of current splits, it will simply close the last split.\n\nFor example, if you run the q100 on the above window setup where there are only three splits, it will close the last split (Split 3).\n\nThe question has been asked here.\n\nShare\nImprove this answer\nFollow\nedited Nov 27 '20 at 2:37\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 12 '18 at 23:41\nSubash\n6,5387\n7 gold badges\n41\n41 silver badges\n66\n66 bronze badges","comments":[]},{"answer":"One guaranteed way is to kill the port that runs vim\n\n! kill - 9 $(ps | grep vim | cut -d \" \" -f 1)\n\nShare\nImprove this answer\nFollow\nedited Jul 29 at 20:32\nZoe\n23.9k16\n16 gold badges\n101\n101 silver badges\n139\n139 bronze badges\nanswered Jul 29 at 18:55\nTilak Maddy\n3,1092\n2 gold badges\n26\n26 silver badges\n45\n45 bronze badges","comments":[]}]},{"id":"309424","href":"https://stackoverflow.com/questions/309424/how-do-i-read-convert-an-inputstream-into-a-string-in-java","title":"How do I read / convert an InputStream into a String in Java?","description":"\n                \nIf you have a java.io.InputStream object, how should you process that object and produce a String?\n\n\n\nSuppose I have an InputStream that contains text data, and I want to convert it to a String, so for example I can write that to a log file.\n\nWhat is the easiest way to take the InputStream and convert it to a String?\n\npublic String convertStreamToString(InputStream is) {\n    // ???\n}\n\n    ","questionComments":["Does this answer your question? Scanner is skipping nextLine() after using next() or nextFoo()?","Remember that you need to take the encoding of the input stream in consideration. The system default is not necessarily always the one you wan.t","Most of these answers were written pre-Java 9, but now you can get a byte array from the InputStream using .readAllBytes. So, simply \"new String(inputStream.readAllBytes())\" works using String's byte[] constructor."],"answers":[{"answer":"A nice way to do this is using Apache commons IOUtils to copy the InputStream into a StringWriter... something like\n\nStringWriter writer = new StringWriter();\nIOUtils.copy(inputStream, writer, encoding);\nString theString = writer.toString();\n\n\nor even\n\n// NB: does not close inputStream, you'll have to use try-with-resources for that\nString theString = IOUtils.toString(inputStream, encoding); \n\n\nAlternatively, you could use ByteArrayOutputStream if you don't want to mix your Streams and Writers\n\nShare\nImprove this answer\nFollow\nedited May 21 '18 at 13:09\nMarko Zajc\n1801\n1 silver badge\n14\n14 bronze badges\nanswered Nov 21 '08 at 16:54\nHarry Lime\n28.9k4\n4 gold badges\n28\n28 silver badges\n35\n35 bronze badges","comments":["Did the toString get deprecated? I see IOUtils.convertStreamToString()","I added an edit to include a searchable link to the actual source code itself as a reference. I believe this augments the answer for those who want to see how the command works."]},{"answer":"Summarize other answers I found 11 main ways to do this (see below). And I wrote some performance tests (see results below):\n\nWays to convert an InputStream to a String:\n\nUsing IOUtils.toString (Apache Utils)\n\n String result = IOUtils.toString(inputStream, StandardCharsets.UTF_8);\n\n\nUsing CharStreams (Guava)\n\n String result = CharStreams.toString(new InputStreamReader(\n       inputStream, Charsets.UTF_8));\n\n\nUsing Scanner (JDK)\n\n Scanner s = new Scanner(inputStream).useDelimiter(\"\\\\A\");\n String result = s.hasNext() ? s.next() : \"\";\n\n\nUsing Stream API (Java 8). Warning: This solution converts different line breaks (like \\r\\n) to \\n.\n\n String result = new BufferedReader(new InputStreamReader(inputStream))\n   .lines().collect(Collectors.joining(\"\\n\"));\n\n\nUsing parallel Stream API (Java 8). Warning: This solution converts different line breaks (like \\r\\n) to \\n.\n\n String result = new BufferedReader(new InputStreamReader(inputStream))\n    .lines().parallel().collect(Collectors.joining(\"\\n\"));\n\n\nUsing InputStreamReader and StringBuilder (JDK)\n\n int bufferSize = 1024;\n char[] buffer = new char[bufferSize];\n StringBuilder out = new StringBuilder();\n Reader in = new InputStreamReader(stream, StandardCharsets.UTF_8);\n for (int numRead; (numRead = in.read(buffer, 0, buffer.length)) > 0; ) {\n     out.append(buffer, 0, numRead);\n }\n return out.toString();\n\n\nUsing StringWriter and IOUtils.copy (Apache Commons)\n\n StringWriter writer = new StringWriter();\n IOUtils.copy(inputStream, writer, \"UTF-8\");\n return writer.toString();\n\n\nUsing ByteArrayOutputStream and inputStream.read (JDK)\n\n ByteArrayOutputStream result = new ByteArrayOutputStream();\n byte[] buffer = new byte[1024];\n for (int length; (length = inputStream.read(buffer)) != -1; ) {\n     result.write(buffer, 0, length);\n }\n // StandardCharsets.UTF_8.name() > JDK 7\n return result.toString(\"UTF-8\");\n\n\nUsing BufferedReader (JDK). Warning: This solution converts different line breaks (like \\n\\r) to line.separator system property (for example, in Windows to \"\\r\\n\").\n\n String newLine = System.getProperty(\"line.separator\");\n BufferedReader reader = new BufferedReader(\n         new InputStreamReader(inputStream));\n StringBuilder result = new StringBuilder();\n for (String line; (line = reader.readLine()) != null; ) {\n     if (result.length() > 0) {\n         result.append(newLine);\n     }\n     result.append(line);\n }\n return result.toString();\n\n\nUsing BufferedInputStream and ByteArrayOutputStream (JDK)\n\nBufferedInputStream bis = new BufferedInputStream(inputStream);\nByteArrayOutputStream buf = new ByteArrayOutputStream();\nfor (int result = bis.read(); result != -1; result = bis.read()) {\n    buf.write((byte) result);\n}\n// StandardCharsets.UTF_8.name() > JDK 7\nreturn buf.toString(\"UTF-8\");\n\n\nUsing inputStream.read() and StringBuilder (JDK). Warning: This solution has problems with Unicode, for example with Russian text (works correctly only with non-Unicode text)\n\nStringBuilder sb = new StringBuilder();\nfor (int ch; (ch = inputStream.read()) != -1; ) {\n    sb.append((char) ch);\n}\nreturn sb.toString();\n\n\nWarning:\n\nSolutions 4, 5 and 9 convert different line breaks to one.\n\nSolution 11 can't work correctly with Unicode text\n\nPerformance tests\n\nPerformance tests for small String (length = 175), url in github (mode = Average Time, system = Linux, score 1,343 is the best):\n\n              Benchmark                         Mode  Cnt   Score   Error  Units\n 8. ByteArrayOutputStream and read (JDK)        avgt   10   1,343 ± 0,028  us/op\n 6. InputStreamReader and StringBuilder (JDK)   avgt   10   6,980 ± 0,404  us/op\n10. BufferedInputStream, ByteArrayOutputStream  avgt   10   7,437 ± 0,735  us/op\n11. InputStream.read() and StringBuilder (JDK)  avgt   10   8,977 ± 0,328  us/op\n 7. StringWriter and IOUtils.copy (Apache)      avgt   10  10,613 ± 0,599  us/op\n 1. IOUtils.toString (Apache Utils)             avgt   10  10,605 ± 0,527  us/op\n 3. Scanner (JDK)                               avgt   10  12,083 ± 0,293  us/op\n 2. CharStreams (guava)                         avgt   10  12,999 ± 0,514  us/op\n 4. Stream Api (Java 8)                         avgt   10  15,811 ± 0,605  us/op\n 9. BufferedReader (JDK)                        avgt   10  16,038 ± 0,711  us/op\n 5. parallel Stream Api (Java 8)                avgt   10  21,544 ± 0,583  us/op\n\n\nPerformance tests for big String (length = 50100), url in github (mode = Average Time, system = Linux, score 200,715 is the best):\n\n               Benchmark                        Mode  Cnt   Score        Error  Units\n 8. ByteArrayOutputStream and read (JDK)        avgt   10   200,715 ±   18,103  us/op\n 1. IOUtils.toString (Apache Utils)             avgt   10   300,019 ±    8,751  us/op\n 6. InputStreamReader and StringBuilder (JDK)   avgt   10   347,616 ±  130,348  us/op\n 7. StringWriter and IOUtils.copy (Apache)      avgt   10   352,791 ±  105,337  us/op\n 2. CharStreams (guava)                         avgt   10   420,137 ±   59,877  us/op\n 9. BufferedReader (JDK)                        avgt   10   632,028 ±   17,002  us/op\n 5. parallel Stream Api (Java 8)                avgt   10   662,999 ±   46,199  us/op\n 4. Stream Api (Java 8)                         avgt   10   701,269 ±   82,296  us/op\n10. BufferedInputStream, ByteArrayOutputStream  avgt   10   740,837 ±    5,613  us/op\n 3. Scanner (JDK)                               avgt   10   751,417 ±   62,026  us/op\n11. InputStream.read() and StringBuilder (JDK)  avgt   10  2919,350 ± 1101,942  us/op\n\n\nGraphs (performance tests depending on Input Stream length in Windows 7 system)\n\n\nPerformance test (Average Time) depending on Input Stream length in Windows 7 system:\n\n length  182    546     1092    3276    9828    29484   58968\n\n test8  0.38    0.938   1.868   4.448   13.412  36.459  72.708\n test4  2.362   3.609   5.573   12.769  40.74   81.415  159.864\n test5  3.881   5.075   6.904   14.123  50.258  129.937 166.162\n test9  2.237   3.493   5.422   11.977  45.98   89.336  177.39\n test6  1.261   2.12    4.38    10.698  31.821  86.106  186.636\n test7  1.601   2.391   3.646   8.367   38.196  110.221 211.016\n test1  1.529   2.381   3.527   8.411   40.551  105.16  212.573\n test3  3.035   3.934   8.606   20.858  61.571  118.744 235.428\n test2  3.136   6.238   10.508  33.48   43.532  118.044 239.481\n test10 1.593   4.736   7.527   20.557  59.856  162.907 323.147\n test11 3.913   11.506  23.26   68.644  207.591 600.444 1211.545\n\nShare\nImprove this answer\nFollow\nedited Feb 28 at 2:07\nLuke Hutchison\n6,3592\n2 gold badges\n32\n32 silver badges\n27\n27 bronze badges\nanswered Feb 17 '16 at 0:58\nSlava Vedenin\n50.9k13\n13 gold badges\n36\n36 silver badges\n57\n57 bronze badges","comments":["Nice work. Could be useful to provide a tl;dr summary at the bottom, i.e. throwing out the solutions that have problems with line breaks / unicode and then (out of those that remain) saying which is fastest with or without external libraries.","It seems this answer is incomplete","I was curious about the Java 9 InputStream.transferTo and Java 10 Reader.transferTo solutions that were added since this answer was posted, so I checked out the linked code and added benchmarks for them. I only tested the \"big string\" benchmarks. InputStream.transferTo was the fastest of all the solutions tested, running in 60% of the time as test8 did on my machine. Reader.transferTo was slower than test8, but faster than all the other tests. That said, it ran in 95% of the time as test1, so it's not a significant improvement.","I converted all the while loops to for loops in an edit to this post, to avoid polluting the namespace with a variable that isn't used outside the loop. It's a neat trick that works in most Java reader/writer loops.","With Java 9 you can get a byte array from the InputStream using .readAllBytes. So \"new String(inputStream.readAllBytes())\" works using String's byte[] constructor."]},{"answer":"Here's a way using only the standard Java library (note that the stream is not closed, your mileage may vary).\n\nstatic String convertStreamToString(java.io.InputStream is) {\n    java.util.Scanner s = new java.util.Scanner(is).useDelimiter(\"\\\\A\");\n    return s.hasNext() ? s.next() : \"\";\n}\n\n\nI learned this trick from \"Stupid Scanner tricks\" article. The reason it works is because Scanner iterates over tokens in the stream, and in this case we separate tokens using \"beginning of the input boundary\" (\\A), thus giving us only one token for the entire contents of the stream.\n\nNote, if you need to be specific about the input stream's encoding, you can provide the second argument to Scanner constructor that indicates what character set to use (e.g. \"UTF-8\").\n\nHat tip goes also to Jacob, who once pointed me to the said article.\n\nShare\nImprove this answer\nFollow\nedited Jan 5 '19 at 10:33\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 26 '11 at 20:40\nPavel Repin\n30k1\n1 gold badge\n32\n32 silver badges\n39\n39 bronze badges","comments":["Shouldn't we close the scanner before returning the value?","@OlegMarkelov probably."]},{"answer":"Apache Commons allows:\n\nString myString = IOUtils.toString(myInputStream, \"UTF-8\");\n\n\nOf course, you could choose other character encodings besides UTF-8.\n\nAlso see: (documentation)\n\nShare\nImprove this answer\nFollow\nedited Jan 5 '19 at 10:29\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 8 '08 at 20:13\nChinnery\n9,9692\n2 gold badges\n21\n21 silver badges\n25\n25 bronze badges","comments":["Trying to get back InputStream, not working stackoverflow.com/q/66349701/3425489"]},{"answer":"Taking into account file one should first get a java.io.Reader instance. This can then be read and added to a StringBuilder (we don't need StringBuffer if we are not accessing it in multiple threads, and StringBuilder is faster). The trick here is that we work in blocks, and as such don't need other buffering streams. The block size is parameterized for run-time performance optimization.\n\npublic static String slurp(final InputStream is, final int bufferSize) {\n    final char[] buffer = new char[bufferSize];\n    final StringBuilder out = new StringBuilder();\n    try (Reader in = new InputStreamReader(is, \"UTF-8\")) {\n        for (;;) {\n            int rsz = in.read(buffer, 0, buffer.length);\n            if (rsz < 0)\n                break;\n            out.append(buffer, 0, rsz);\n        }\n    }\n    catch (UnsupportedEncodingException ex) {\n        /* ... */\n    }\n    catch (IOException ex) {\n        /* ... */\n    }\n    return out.toString();\n}\n\nShare\nImprove this answer\nFollow\nedited Jul 15 '15 at 10:23\ncommunity wiki\n\n\n11 revs, 8 users 39%\nPaul de Vrieze","comments":[]},{"answer":"Use:\n\nInputStream in = /* Your InputStream */;\nStringBuilder sb = new StringBuilder();\nBufferedReader br = new BufferedReader(new InputStreamReader(in));\nString read;\n\nwhile ((read=br.readLine()) != null) {\n    //System.out.println(read);\n    sb.append(read);\n}\n\nbr.close();\nreturn sb.toString();\n\nShare\nImprove this answer\nFollow\nedited Jan 5 '19 at 10:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 4 '11 at 8:29\nsampathpremarathna\n3,9155\n5 gold badges\n22\n22 silver badges\n35\n35 bronze badges","comments":["readLine() removes the line feed character so the resulting string will contain no line breaks unless you add a line separator between each line you add to the builder."]},{"answer":"If you are using Google-Collections/Guava you could do the following:\n\nInputStream stream = ...\nString content = CharStreams.toString(new InputStreamReader(stream, Charsets.UTF_8));\nCloseables.closeQuietly(stream);\n\n\nNote that the second parameter (i.e. Charsets.UTF_8) for the InputStreamReader isn't necessary, but it is generally a good idea to specify the encoding if you know it (which you should!)\n\nShare\nImprove this answer\nFollow\nedited Jan 30 '13 at 16:35\nralfoide\n2,0773\n3 gold badges\n19\n19 silver badges\n21\n21 bronze badges\nanswered Jul 13 '10 at 15:56\nSakuraba\n2,5411\n1 gold badge\n18\n18 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"This is the best pure Java solution that fits perfectly for Android and any other JVM.\n\nThis solution works amazingly well... it is simple, fast, and works on small and large streams just the same!! (see benchmark above.. No. 8)\n\npublic String readFullyAsString(InputStream inputStream, String encoding)\n        throws IOException {\n    return readFully(inputStream).toString(encoding);\n}\n\npublic byte[] readFullyAsBytes(InputStream inputStream)\n        throws IOException {\n    return readFully(inputStream).toByteArray();\n}\n\nprivate ByteArrayOutputStream readFully(InputStream inputStream)\n        throws IOException {\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] buffer = new byte[1024];\n    int length = 0;\n    while ((length = inputStream.read(buffer)) != -1) {\n        baos.write(buffer, 0, length);\n    }\n    return baos;\n}\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '19 at 20:38\nanswered May 8 '12 at 20:24\nTacB0sS\n9,56611\n11 gold badges\n67\n67 silver badges\n113\n113 bronze badges","comments":[]},{"answer":"For completeness here is Java 9 solution:\n\npublic static String toString(InputStream input) throws IOException {\n    return new String(input.readAllBytes(), StandardCharsets.UTF_8);\n}\n\n\nThis uses the readAllBytes method which was added to Java 9.\n\nShare\nImprove this answer\nFollow\nedited Nov 18 '20 at 22:50\nM. Justin\n5,9363\n3 gold badges\n46\n46 silver badges\n68\n68 bronze badges\nanswered Sep 2 '15 at 11:50\nTagir Valeev\n88.8k18\n18 gold badges\n198\n198 silver badges\n310\n310 bronze badges","comments":["I benchmarked this here, and found this to be the fastest solution on my machine, running in about 60% the time of the next-fastest solution benchmarked."]},{"answer":"Use:\n\nimport java.io.BufferedInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.InputStream;\nimport java.io.IOException;\n\npublic static String readInputStreamAsString(InputStream in)\n    throws IOException {\n\n    BufferedInputStream bis = new BufferedInputStream(in);\n    ByteArrayOutputStream buf = new ByteArrayOutputStream();\n    int result = bis.read();\n    while(result != -1) {\n      byte b = (byte)result;\n      buf.write(b);\n      result = bis.read();\n    }\n    return buf.toString();\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 5 '19 at 10:30\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 10 '09 at 21:07\nJon Moore\n1,28010\n10 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"Here's the most elegant, pure-Java (no library) solution I came up with after some experimentation:\n\npublic static String fromStream(InputStream in) throws IOException\n{\n    BufferedReader reader = new BufferedReader(new InputStreamReader(in));\n    StringBuilder out = new StringBuilder();\n    String newLine = System.getProperty(\"line.separator\");\n    String line;\n    while ((line = reader.readLine()) != null) {\n        out.append(line);\n        out.append(newLine);\n    }\n    return out.toString();\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 7 '13 at 16:39\nanswered Jan 1 '13 at 3:43\nDrew Noakes\n271k145\n145 gold badges\n621\n621 silver badges\n708\n708 bronze badges","comments":[]},{"answer":"I did a benchmark upon 14 distinct answers here (sorry for not providing credits but there are too many duplicates).\n\nThe result is very surprising. It turns out that Apache IOUtils is the slowest and ByteArrayOutputStream is the fastest solutions:\n\nSo first here is the best method:\n\npublic String inputStreamToString(InputStream inputStream) throws IOException {\n    try(ByteArrayOutputStream result = new ByteArrayOutputStream()) {\n        byte[] buffer = new byte[1024];\n        int length;\n        while ((length = inputStream.read(buffer)) != -1) {\n            result.write(buffer, 0, length);\n        }\n\n        return result.toString(UTF_8);\n    }\n}\n\nBenchmark results, of 20 MB random bytes in 20 cycles\n\nTime in milliseconds\n\nByteArrayOutputStreamTest: 194\nNioStream: 198\nJava9ISTransferTo: 201\nJava9ISReadAllBytes: 205\nBufferedInputStreamVsByteArrayOutputStream: 314\nApacheStringWriter2: 574\nGuavaCharStreams: 589\nScannerReaderNoNextTest: 614\nScannerReader: 633\nApacheStringWriter: 1544\nStreamApi: Error\nParallelStreamApi: Error\nBufferReaderTest: Error\nInputStreamAndStringBuilder: Error\nBenchmark source code\nimport com.google.common.io.CharStreams;\nimport org.apache.commons.io.IOUtils;\n\nimport java.io.*;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.Channels;\nimport java.nio.channels.ReadableByteChannel;\nimport java.nio.channels.WritableByteChannel;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Random;\nimport java.util.stream.Collectors;\n\n/**\n * Created by Ilya Gazman on 2/13/18.\n */\npublic class InputStreamToString {\n\n\n    private static final String UTF_8 = \"UTF-8\";\n\n    public static void main(String... args) {\n        log(\"App started\");\n        byte[] bytes = new byte[1024 * 1024];\n        new Random().nextBytes(bytes);\n        log(\"Stream is ready\\n\");\n\n        try {\n            test(bytes);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    private static void test(byte[] bytes) throws IOException {\n        List<Stringify> tests = Arrays.asList(\n                new ApacheStringWriter(),\n                new ApacheStringWriter2(),\n                new NioStream(),\n                new ScannerReader(),\n                new ScannerReaderNoNextTest(),\n                new GuavaCharStreams(),\n                new StreamApi(),\n                new ParallelStreamApi(),\n                new ByteArrayOutputStreamTest(),\n                new BufferReaderTest(),\n                new BufferedInputStreamVsByteArrayOutputStream(),\n                new InputStreamAndStringBuilder(),\n                new Java9ISTransferTo(),\n                new Java9ISReadAllBytes()\n        );\n\n        String solution = new String(bytes, \"UTF-8\");\n\n        for (Stringify test : tests) {\n            try (ByteArrayInputStream inputStream = new ByteArrayInputStream(bytes)) {\n                String s = test.inputStreamToString(inputStream);\n                if (!s.equals(solution)) {\n                    log(test.name() + \": Error\");\n                    continue;\n                }\n            }\n            long startTime = System.currentTimeMillis();\n            for (int i = 0; i < 20; i++) {\n                try (ByteArrayInputStream inputStream = new ByteArrayInputStream(bytes)) {\n                    test.inputStreamToString(inputStream);\n                }\n            }\n            log(test.name() + \": \" + (System.currentTimeMillis() - startTime));\n        }\n    }\n\n    private static void log(String message) {\n        System.out.println(message);\n    }\n\n    interface Stringify {\n        String inputStreamToString(InputStream inputStream) throws IOException;\n\n        default String name() {\n            return this.getClass().getSimpleName();\n        }\n    }\n\n    static class ApacheStringWriter implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            StringWriter writer = new StringWriter();\n            IOUtils.copy(inputStream, writer, UTF_8);\n            return writer.toString();\n        }\n    }\n\n    static class ApacheStringWriter2 implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            return IOUtils.toString(inputStream, UTF_8);\n        }\n    }\n\n    static class NioStream implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream in) throws IOException {\n            ReadableByteChannel channel = Channels.newChannel(in);\n            ByteBuffer byteBuffer = ByteBuffer.allocate(1024 * 16);\n            ByteArrayOutputStream bout = new ByteArrayOutputStream();\n            WritableByteChannel outChannel = Channels.newChannel(bout);\n            while (channel.read(byteBuffer) > 0 || byteBuffer.position() > 0) {\n                byteBuffer.flip();  //make buffer ready for write\n                outChannel.write(byteBuffer);\n                byteBuffer.compact(); //make buffer ready for reading\n            }\n            channel.close();\n            outChannel.close();\n            return bout.toString(UTF_8);\n        }\n    }\n\n    static class ScannerReader implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream is) throws IOException {\n            java.util.Scanner s = new java.util.Scanner(is).useDelimiter(\"\\\\A\");\n            return s.hasNext() ? s.next() : \"\";\n        }\n    }\n\n    static class ScannerReaderNoNextTest implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream is) throws IOException {\n            java.util.Scanner s = new java.util.Scanner(is).useDelimiter(\"\\\\A\");\n            return s.next();\n        }\n    }\n\n    static class GuavaCharStreams implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream is) throws IOException {\n            return CharStreams.toString(new InputStreamReader(\n                    is, UTF_8));\n        }\n    }\n\n    static class StreamApi implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            return new BufferedReader(new InputStreamReader(inputStream))\n                    .lines().collect(Collectors.joining(\"\\n\"));\n        }\n    }\n\n    static class ParallelStreamApi implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            return new BufferedReader(new InputStreamReader(inputStream)).lines()\n                    .parallel().collect(Collectors.joining(\"\\n\"));\n        }\n    }\n\n    static class ByteArrayOutputStreamTest implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            try(ByteArrayOutputStream result = new ByteArrayOutputStream()) {\n                byte[] buffer = new byte[1024];\n                int length;\n                while ((length = inputStream.read(buffer)) != -1) {\n                    result.write(buffer, 0, length);\n                }\n\n                return result.toString(UTF_8);\n            }\n        }\n    }\n\n    static class BufferReaderTest implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            String newLine = System.getProperty(\"line.separator\");\n            BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream));\n            StringBuilder result = new StringBuilder(UTF_8);\n            String line;\n            boolean flag = false;\n            while ((line = reader.readLine()) != null) {\n                result.append(flag ? newLine : \"\").append(line);\n                flag = true;\n            }\n            return result.toString();\n        }\n    }\n\n    static class BufferedInputStreamVsByteArrayOutputStream implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            BufferedInputStream bis = new BufferedInputStream(inputStream);\n            ByteArrayOutputStream buf = new ByteArrayOutputStream();\n            int result = bis.read();\n            while (result != -1) {\n                buf.write((byte) result);\n                result = bis.read();\n            }\n\n            return buf.toString(UTF_8);\n        }\n    }\n\n    static class InputStreamAndStringBuilder implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            int ch;\n            StringBuilder sb = new StringBuilder(UTF_8);\n            while ((ch = inputStream.read()) != -1)\n                sb.append((char) ch);\n            return sb.toString();\n        }\n    }\n\n    static class Java9ISTransferTo implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            ByteArrayOutputStream bos = new ByteArrayOutputStream();\n            inputStream.transferTo(bos);\n            return bos.toString(UTF_8);\n        }\n    }\n\n    static class Java9ISReadAllBytes implements Stringify {\n\n        @Override\n        public String inputStreamToString(InputStream inputStream) throws IOException {\n            return new String(inputStream.readAllBytes(), UTF_8);\n        }\n    }\n\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 6 '19 at 0:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 13 '18 at 21:30\nIlya Gazman\n28.3k19\n19 gold badges\n121\n121 silver badges\n197\n197 bronze badges","comments":["Making benchmarks in Java is not easy (especially because of JIT). After reading Benchmark source code, I'm convinced that those values above are not precise and everyone should be careful by believing them.","@Dalibor you probably should provide more reasoning for your claim rather than just a link.","I think that it is really known fact that it is not easy to make your own benchmark. For those who do not know that, there is link ;)","@Dalibor I am perhaps not the best, but I have a good understanding of Java benchmarks, so unless you can point out a specific problem, you are just misleading, and I will not continue the conversation with you under those conditions.","Mostly I agree with Dalibor. You say you have a \"good understanding of Java benchmarks\", but you seem to have implemented the most naive approach while being apparently ignorant of the well known issues of this approach. For starters, read every post on this question: stackoverflow.com/questions/504103/…"]},{"answer":"I'd use some Java 8 tricks.\n\npublic static String streamToString(final InputStream inputStream) throws Exception {\n    // buffering optional\n    try\n    (\n        final BufferedReader br\n           = new BufferedReader(new InputStreamReader(inputStream))\n    ) {\n        // parallel optional\n        return br.lines().parallel().collect(Collectors.joining(\"\\n\"));\n    } catch (final IOException e) {\n        throw new RuntimeException(e);\n        // whatever.\n    }\n}\n\n\nEssentially the same as some other answers except more succinct.\n\nShare\nImprove this answer\nFollow\nedited Jul 15 '15 at 11:03\nIan2thedv\n2,6262\n2 gold badges\n22\n22 silver badges\n44\n44 bronze badges\nanswered Jul 17 '14 at 17:58\nSimon Kuang\n3,7264\n4 gold badges\n24\n24 silver badges\n53\n53 bronze badges","comments":[]},{"answer":"I ran some timing tests because time matters, always.\n\n\nI attempted to get the response into a String 3 different ways. (shown below)\nI left out try/catch blocks for the sake readability.\n\n\nTo give context, this is the preceding code for all 3 approaches:\n\n\n   String response;\n   String url = \"www.blah.com/path?key=value\";\n   GetMethod method = new GetMethod(url);\n   int status = client.executeMethod(method);\n\n\n1)\n\n\n response = method.getResponseBodyAsString();\n\n\n2)\n\n\nInputStream resp = method.getResponseBodyAsStream();\nInputStreamReader is=new InputStreamReader(resp);\nBufferedReader br=new BufferedReader(is);\nString read = null;\nStringBuffer sb = new StringBuffer();\nwhile((read = br.readLine()) != null) {\n    sb.append(read);\n}\nresponse = sb.toString();\n\n\n3)\n\n\nInputStream iStream  = method.getResponseBodyAsStream();\nStringWriter writer = new StringWriter();\nIOUtils.copy(iStream, writer, \"UTF-8\");\nresponse = writer.toString();\n\n\nSo, after running 500 tests on each approach with the same request/response data, here are the numbers. Once again, these are my findings and your findings may not be exactly the same, but I wrote this to give some indication to others of the efficiency differences of these approaches.\n\nRanks:\nApproach #1\nApproach #3 - 2.6% slower than #1\nApproach #2 - 4.3% slower than #1\n\n\nAny of these approaches is an appropriate solution for grabbing a response and creating a String from it.\n\nShare\nImprove this answer\nFollow\nedited Oct 17 '17 at 8:55\nmartijnn2008\n3,2664\n4 gold badges\n27\n27 silver badges\n38\n38 bronze badges\nanswered Oct 12 '11 at 17:23\nBrett Holt\n1,10910\n10 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"Pure Java solution using Streams, works since Java 8.\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.InputStreamReader;\nimport java.util.stream.Collectors;\n\n// ...\npublic static String inputStreamToString(InputStream is) throws IOException {\n    try (BufferedReader br = new BufferedReader(new InputStreamReader(is))) {\n        return br.lines().collect(Collectors.joining(System.lineSeparator()));\n    }\n}\n\n\nAs mentioned by Christoffer Hammarström below other answer it is safer to explicitly specify the Charset. I.e. The InputStreamReader constructor can be changes as follows:\n\nnew InputStreamReader(is, Charset.forName(\"UTF-8\"))\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Feb 26 '15 at 18:39\nczerny\n11.8k13\n13 gold badges\n58\n58 silver badges\n80\n80 bronze badges","comments":[]},{"answer":"Here's more-or-less sampath's answer, cleaned up a bit and represented as a function:\n\nString streamToString(InputStream in) throws IOException {\n  StringBuilder out = new StringBuilder();\n  BufferedReader br = new BufferedReader(new InputStreamReader(in));\n  for(String line = br.readLine(); line != null; line = br.readLine()) \n    out.append(line);\n  br.close();\n  return out.toString();\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 12 '12 at 18:31\nanswered Mar 30 '12 at 19:52\nTKH\n7585\n5 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"If you were feeling adventurous, you could mix Scala and Java and end up with this:\n\nscala.io.Source.fromInputStream(is).mkString(\"\")\n\n\nMixing Java and Scala code and libraries has it's benefits.\n\nSee full description here: Idiomatic way to convert an InputStream to a String in Scala\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:18\nCommunity♦\n11\n1 silver badge\nanswered Mar 7 '12 at 7:32\nJack\n15.7k17\n17 gold badges\n88\n88 silver badges\n163\n163 bronze badges","comments":[]},{"answer":"If you can't use Commons IO (FileUtils/IOUtils/CopyUtils), here's an example using a BufferedReader to read the file line by line:\n\npublic class StringFromFile {\n    public static void main(String[] args) /*throws UnsupportedEncodingException*/ {\n        InputStream is = StringFromFile.class.getResourceAsStream(\"file.txt\");\n        BufferedReader br = new BufferedReader(new InputStreamReader(is/*, \"UTF-8\"*/));\n        final int CHARS_PER_PAGE = 5000; //counting spaces\n        StringBuilder builder = new StringBuilder(CHARS_PER_PAGE);\n        try {\n            for(String line=br.readLine(); line!=null; line=br.readLine()) {\n                builder.append(line);\n                builder.append('\\n');\n            }\n        } \n        catch (IOException ignore) { }\n\n        String text = builder.toString();\n        System.out.println(text);\n    }\n}\n\n\nOr if you want raw speed I'd propose a variation on what Paul de Vrieze suggested (which avoids using a StringWriter (which uses a StringBuffer internally):\n\npublic class StringFromFileFast {\n    public static void main(String[] args) /*throws UnsupportedEncodingException*/ {\n        InputStream is = StringFromFileFast.class.getResourceAsStream(\"file.txt\");\n        InputStreamReader input = new InputStreamReader(is/*, \"UTF-8\"*/);\n        final int CHARS_PER_PAGE = 5000; //counting spaces\n        final char[] buffer = new char[CHARS_PER_PAGE];\n        StringBuilder output = new StringBuilder(CHARS_PER_PAGE);\n        try {\n            for(int read = input.read(buffer, 0, buffer.length);\n                    read != -1;\n                    read = input.read(buffer, 0, buffer.length)) {\n                output.append(buffer, 0, read);\n            }\n        } catch (IOException ignore) { }\n\n        String text = output.toString();\n        System.out.println(text);\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 5 '19 at 10:31\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 18 '10 at 12:57\nDJDaveMark\n2,07516\n16 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"Make sure to close the streams at end if you use Stream Readers\n\nprivate String readStream(InputStream iStream) throws IOException {\n    //build a Stream Reader, it can read char by char\n    InputStreamReader iStreamReader = new InputStreamReader(iStream);\n    //build a buffered Reader, so that i can read whole line at once\n    BufferedReader bReader = new BufferedReader(iStreamReader);\n    String line = null;\n    StringBuilder builder = new StringBuilder();\n    while((line = bReader.readLine()) != null) {  //Read till end\n        builder.append(line);\n        builder.append(\"\\n\"); // append new line to preserve lines\n    }\n    bReader.close();         //close all opened stuff\n    iStreamReader.close();\n    //iStream.close(); //EDIT: Let the creator of the stream close it!\n                       // some readers may auto close the inner stream\n    return builder.toString();\n}\n\n\nEDIT: On JDK 7+, you can use try-with-resources construct.\n\n/**\n * Reads the stream into a string\n * @param iStream the input stream\n * @return the string read from the stream\n * @throws IOException when an IO error occurs\n */\nprivate String readStream(InputStream iStream) throws IOException {\n\n    //Buffered reader allows us to read line by line\n    try (BufferedReader bReader =\n                 new BufferedReader(new InputStreamReader(iStream))){\n        StringBuilder builder = new StringBuilder();\n        String line;\n        while((line = bReader.readLine()) != null) {  //Read till end\n            builder.append(line);\n            builder.append(\"\\n\"); // append new line to preserve lines\n        }\n        return builder.toString();\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Feb 24 '17 at 19:28\nanswered Nov 17 '12 at 12:39\nThamme Gowda\n9,6392\n2 gold badges\n42\n42 silver badges\n51\n51 bronze badges","comments":[]},{"answer":"This is an answer adapted from org.apache.commons.io.IOUtils source code, for those who want to have the apache implementation but do not want the whole library.\n\nprivate static final int BUFFER_SIZE = 4 * 1024;\n\npublic static String inputStreamToString(InputStream inputStream, String charsetName)\n        throws IOException {\n    StringBuilder builder = new StringBuilder();\n    InputStreamReader reader = new InputStreamReader(inputStream, charsetName);\n    char[] buffer = new char[BUFFER_SIZE];\n    int length;\n    while ((length = reader.read(buffer)) != -1) {\n        builder.append(buffer, 0, length);\n    }\n    return builder.toString();\n}\n\nShare\nImprove this answer\nFollow\nedited Oct 10 '15 at 4:37\nanswered Aug 3 '14 at 9:47\nHai Zhang\n5,11640\n40 silver badges\n50\n50 bronze badges","comments":[]},{"answer":"Use the java.io.InputStream.transferTo(OutputStream) supported in Java 9 and the ByteArrayOutputStream.toString(String) which takes the charset name:\n\npublic static String gobble(InputStream in, String charsetName) throws IOException {\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    in.transferTo(bos);\n    return bos.toString(charsetName);\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 28 '17 at 14:47\nanswered Jan 28 '16 at 15:55\njmehrens\n9,1391\n1 gold badge\n31\n31 silver badges\n43\n43 bronze badges","comments":[]},{"answer":"This one is nice because:\n\nIt safely handles the Charset.\nYou control the read buffer size.\nYou can provision the length of the builder and it doesn't have to be an exact value.\nIs free from library dependencies.\nIs for Java 7 or higher.\n\nHow to do it?\n\npublic static String convertStreamToString(InputStream is) throws IOException {\n   StringBuilder sb = new StringBuilder(2048); // Define a size if you have an idea of it.\n   char[] read = new char[128]; // Your buffer size.\n   try (InputStreamReader ir = new InputStreamReader(is, StandardCharsets.UTF_8)) {\n     for (int i; -1 != (i = ir.read(read)); sb.append(read, 0, i));\n   }\n   return sb.toString();\n}\n\n\nFor JDK 9\n\npublic static String inputStreamString(InputStream inputStream) throws IOException {\n    try (inputStream) {\n        return new String(inputStream.readAllBytes(), StandardCharsets.UTF_8);\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '19 at 5:57\nanswered Jun 8 '14 at 7:46\nDaniel De León\n11.9k5\n5 gold badges\n76\n76 silver badges\n66\n66 bronze badges","comments":[]},{"answer":"Another one, for all the Spring users:\n\nimport java.nio.charset.StandardCharsets;\nimport org.springframework.util.FileCopyUtils;\n\npublic String convertStreamToString(InputStream is) throws IOException { \n    return new String(FileCopyUtils.copyToByteArray(is), StandardCharsets.UTF_8);\n}\n\n\nThe utility methods in org.springframework.util.StreamUtils are similar to the ones in FileCopyUtils, but they leave the stream open when done.\n\nShare\nImprove this answer\nFollow\nedited Jul 21 '17 at 10:24\nanswered Jul 29 '16 at 20:58\nJames\n10.5k4\n4 gold badges\n47\n47 silver badges\n78\n78 bronze badges","comments":[]},{"answer":"Here is the complete method for converting InputStream into String without using any third party library. Use StringBuilder for single threaded environment otherwise use StringBuffer.\n\npublic static String getString( InputStream is) throws IOException {\n    int ch;\n    StringBuilder sb = new StringBuilder();\n    while((ch = is.read()) != -1)\n        sb.append((char)ch);\n    return sb.toString();\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 16 '15 at 9:20\nrtruszk\n3,86613\n13 gold badges\n33\n33 silver badges\n53\n53 bronze badges\nanswered Apr 9 '14 at 10:37\nlaksys\n3,0384\n4 gold badges\n23\n23 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"Here's how to do it using just the JDK using byte array buffers. This is actually how the commons-io IOUtils.copy() methods all work. You can replace byte[] with char[] if you're copying from a Reader instead of an InputStream.\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.InputStream;\n\n...\n\nInputStream is = ....\nByteArrayOutputStream baos = new ByteArrayOutputStream(8192);\nbyte[] buffer = new byte[8192];\nint count = 0;\ntry {\n  while ((count = is.read(buffer)) != -1) {\n    baos.write(buffer, 0, count);\n  }\n}\nfinally {\n  try {\n    is.close();\n  }\n  catch (Exception ignore) {\n  }\n}\n\nString charset = \"UTF-8\";\nString inputStreamAsString = baos.toString(charset);\n\nShare\nImprove this answer\nFollow\nedited Aug 13 '14 at 4:30\nMatt\n6173\n3 silver badges\n9\n9 bronze badges\nanswered Nov 2 '12 at 12:37\nMatt Shannon\n1591\n1 silver badge\n2\n2 bronze badges","comments":[]},{"answer":"Kotlin users simply do:\n\nprintln(InputStreamReader(is).readText())\n\n\nwhereas\n\nreadText()\n\n\nis Kotlin standard library’s built-in extension method.\n\nShare\nImprove this answer\nFollow\nanswered Feb 4 '15 at 1:12\nAlex\n7,6208\n8 gold badges\n40\n40 silver badges\n51\n51 bronze badges","comments":[]},{"answer":"String inputStreamToString(InputStream inputStream, Charset charset) throws IOException {\n    try (\n            final StringWriter writer = new StringWriter();\n            final InputStreamReader reader = new InputStreamReader(inputStream, charset)\n        ) {\n        reader.transferTo(writer);\n        return writer.toString();\n    }\n}\n\npure Java standard library solution - no libs\nsince Java 10 - Reader#transferTo(java.io.Writer)\nloopless solution\nno new line character handling\nShare\nImprove this answer\nFollow\nanswered Apr 5 '20 at 0:03\nczerny\n11.8k13\n13 gold badges\n58\n58 silver badges\n80\n80 bronze badges","comments":[]},{"answer":"The easiest way in JDK is with the following code snipplets.\n\nString convertToString(InputStream in){\n    String resource = new Scanner(in).useDelimiter(\"\\\\Z\").next();\n    return resource;\n}\n\nShare\nImprove this answer\nFollow\nanswered Aug 9 '16 at 20:18\nRaghu K Nair\n3,5181\n1 gold badge\n24\n24 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"Here's my Java 8 based solution, which uses the new Stream API to collect all lines from an InputStream:\n\npublic static String toString(InputStream inputStream) {\n    BufferedReader reader = new BufferedReader(\n        new InputStreamReader(inputStream));\n    return reader.lines().collect(Collectors.joining(\n        System.getProperty(\"line.separator\")));\n}\n\nShare\nImprove this answer\nFollow\nanswered Sep 2 '15 at 11:19\nChristian Rädel\n5711\n1 gold badge\n5\n5 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"In terms of reduce, and concat it can be expressed in Java 8 as:\n\nString fromFile = new BufferedReader(new   \nInputStreamReader(inputStream)).lines().reduce(String::concat).get();\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '18 at 7:37\nDerlin\n8,6382\n2 gold badges\n23\n23 silver badges\n43\n43 bronze badges\nanswered Jan 21 '16 at 14:28\nlibnull-dev\n8311\n1 gold badge\n7\n7 silver badges\n19\n19 bronze badges","comments":[]}]},{"id":"221294","href":"https://stackoverflow.com/questions/221294/how-do-you-get-a-timestamp-in-javascript","title":"How do you get a timestamp in JavaScript?","description":"\n                \nSomething similar to Unix's timestamp, that is a single number that represents the current time and date. Either as a number or a string.\n    ","questionComments":["var timeStampInMs = window.performance && window.performance.now && window.performance.timing && window.performance.timing.navigationStart ? window.performance.now() + window.performance.timing.navigationStart : Date.now(); console.log(timeStampInMs, Date.now());"],"answers":[{"answer":"Short & Snazzy:\n+ new Date()\n\n\nA unary operator like plus triggers the valueOf method in the Date object and it returns the timestamp (without any alteration).\n\nDetails:\n\nOn almost all current browsers you can use Date.now() to get the UTC timestamp in milliseconds; a notable exception to this is IE8 and earlier (see compatibility table).\n\nYou can easily make a shim for this, though:\n\nif (!Date.now) {\n    Date.now = function() { return new Date().getTime(); }\n}\n\n\nTo get the timestamp in seconds, you can use:\n\nMath.floor(Date.now() / 1000)\n\n\nOr alternatively you could use:\n\nDate.now() / 1000 | 0\n\n\nWhich should be slightly faster, but also less readable.\n(also see this answer or this with further explaination to bitwise operators).\n\nI would recommend using Date.now() (with compatibility shim). It's slightly better because it's shorter & doesn't create a new Date object. However, if you don't want a shim & maximum compatibility, you could use the \"old\" method to get the timestamp in milliseconds:\n\nnew Date().getTime()\n\n\nWhich you can then convert to seconds like this:\n\nMath.round(new Date().getTime()/1000)\n\n\nAnd you can also use the valueOf method which we showed above:\n\nnew Date().valueOf()\n\n\nTimestamp in Milliseconds\n\nvar timeStampInMs = window.performance && window.performance.now && window.performance.timing && window.performance.timing.navigationStart ? window.performance.now() + window.performance.timing.navigationStart : Date.now();\n\nconsole.log(timeStampInMs, Date.now());\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited May 29 at 4:13\nmeagar♦\n213k39\n39 gold badges\n308\n308 silver badges\n317\n317 bronze badges\nanswered Oct 21 '08 at 9:32\ndaveb\n67.8k6\n6 gold badges\n42\n42 silver badges\n50\n50 bronze badges","comments":["In case you wonder about the logic of plus sign is: + is used as toInt() where it will neglect all the characters and return only numbers"]},{"answer":"I like this, because it is small:\n\n+new Date\n\n\nI also like this, because it is just as short and is compatible with modern browsers, and over 500 people voted that it is better:\n\nDate.now()\n\nShare\nImprove this answer\nFollow\nedited Nov 30 '17 at 19:23\nanswered Feb 18 '11 at 0:33\nxer0x\n12.1k5\n5 gold badges\n30\n30 silver badges\n28\n28 bronze badges","comments":["This option is a bad idea. It's easily overlooked, looks like a typo, and is in reality relying on a language side-effect. I see bad code.","@Billy As I recall it, I computed the timestamp in the two suggested solutions 1M times each, and calculated the average runtime. I ran it in Firefox and Chrome, with getTime being faster in both browsers. That said, even if it were (marginally) slower I'd choose new Date().getTime(). Luckily for me, the faster solution is already the legible solution!","Agreed with @FabrícioMatté. Unary operator behavior may not be rudimentary, but if you haven't brushed up on it, don't expect to be able to function effectively in a lot of teams.","@Niklaus That's because you're concatenating it to another string. In that case, new Date().toString() is called.","out of curiosity what is the +operator doing to make it come out like a string?"]},{"answer":"JavaScript works with the number of milliseconds since the epoch whereas most other languages work with the seconds. You could work with milliseconds but as soon as you pass a value to say PHP, the PHP native functions will probably fail. So to be sure I always use the seconds, not milliseconds.\n\nThis will give you a Unix timestamp (in seconds):\n\nvar unix = Math.round(+new Date()/1000);\n\n\nThis will give you the milliseconds since the epoch (not Unix timestamp):\n\nvar milliseconds = new Date().getTime();\n\nShare\nImprove this answer\nFollow\nedited May 30 '11 at 21:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 11 '11 at 22:27\nDaithí\n4,3794\n4 gold badges\n24\n24 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"var time = Date.now || function() {\n  return +new Date;\n};\n\ntime();\n\nShare\nImprove this answer\nFollow\nedited Dec 16 '14 at 13:31\nMartin Tournoij\n24k24\n24 gold badges\n94\n94 silver badges\n130\n130 bronze badges\nanswered Oct 21 '08 at 10:05\nStaale\n24.9k22\n22 gold badges\n63\n63 silver badges\n85\n85 bronze badges","comments":[]},{"answer":"I provide multiple solutions with descriptions in this answer. Feel free to ask questions if anything is unclear\n\nQuick and dirty solution:\n\nDate.now() /1000 |0\n\n\nWarning: it might break in 2038 and return negative numbers if you do the |0 magic. Use Math.floor() instead by that time\n\nMath.floor() solution:\n\nMath.floor(Date.now() /1000);\n\n\nSome nerdy alternative by Derek 朕會功夫 taken from the comments below this answer:\n\nnew Date/1e3|0\n\n\nPolyfill to get Date.now() working:\n\nTo get it working in IE you could do this (Polyfill from MDN):\n\nif (!Date.now) {\n    Date.now = function now() {\n        return new Date().getTime();\n    };\n}\n\n\nIf you do not care about the year / day of week / daylight saving time you need to remember this for dates after 2038:\n\nBitwise operations will cause usage of 32 Bit Integers instead of 64 Bit Floating Point.\n\nYou will need to properly use it as:\n\nMath.floor(Date.now() / 1000)\n\n\nIf you just want to know the relative time from the point of when the code was run through first you could use something like this:\n\nconst relativeTime = (() => {\n    const start = Date.now();\n    return () => Date.now() - start;\n})();\n\n\nIn case you are using jQuery you could use $.now() as described in jQuery's Docs which makes the polyfill obsolete since $.now() internally does the same thing: (new Date).getTime()\n\nIf you are just happy about jQuery's version, consider upvoting this answer since I did not find it myself.\n\nNow a tiny explaination of what |0 does:\n\nBy providing |, you tell the interpreter to do a binary OR operation.\nBit operations require absolute numbers which turns the decimal result from Date.now() / 1000 into an integer.\n\nDuring that conversion, decimals are removed, resulting in a similar result to what using Math.floor() would output.\n\nBe warned though: it will convert a 64 bit double to a 32 bit integer.\nThis will result in information loss when dealing with huge numbers.\nTimestamps will break after 2038 due to 32 bit integer overflow unless Javascript moves to 64 Bit Integers in Strict Mode.\n\nFor further information about Date.now follow this link: Date.now() @ MDN\n\nShare\nImprove this answer\nFollow\nedited May 22 at 4:34\nanswered Jul 12 '12 at 7:15\nGottZ\n4,3781\n1 gold badge\n32\n32 silver badges\n42\n42 bronze badges","comments":[]},{"answer":"var timestamp = Number(new Date()); // current time as number\n\nShare\nImprove this answer\nFollow\nanswered Oct 21 '08 at 13:00\naemkei\n10.7k6\n6 gold badges\n34\n34 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"jQuery provides its own method to get the timestamp:\n\nvar timestamp = $.now();\n\n\n(besides it just implements (new Date).getTime() expression)\n\nREF: http://api.jquery.com/jQuery.now/\n\nShare\nImprove this answer\nFollow\nanswered Mar 15 '13 at 14:19\nVisioN\n134k28\n28 gold badges\n255\n255 silver badges\n265\n265 bronze badges","comments":[]},{"answer":"In addition to the other options, if you want a dateformat ISO, you can get it directly\n\nconsole.log(new Date().toISOString());\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Mar 16 at 9:02\nanswered Jan 29 '16 at 15:08\nJoaquinglezsantos\n1,04211\n11 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"console.log(new Date().valueOf()); // returns the number of milliseconds since the epoch\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '16 at 18:48\nRuslan López\n4,1301\n1 gold badge\n19\n19 silver badges\n34\n34 bronze badges\nanswered Apr 30 '09 at 16:53\nTom Viner\n6,1457\n7 gold badges\n35\n35 silver badges\n39\n39 bronze badges","comments":[]},{"answer":"Date, a native object in JavaScript is the way we get all data about time.\n\nJust be careful in JavaScript the timestamp depends on the client computer set, so it's not 100% accurate timestamp. To get the best result, you need to get the timestamp from the server-side.\n\nAnyway, my preferred way is using vanilla. This is a common way of doing it in JavaScript:\n\nDate.now(); //return 1495255666921\n\n\nIn MDN it's mentioned as below:\n\nThe Date.now() method returns the number of milliseconds elapsed since 1 January 1970 00:00:00 UTC.\nBecause now() is a static method of Date, you always use it as Date.now().\n\nIf you using a version below ES5, Date.now(); not works and you need to use:\n\nnew Date().getTime();\n\nShare\nImprove this answer\nFollow\nedited Jul 5 '19 at 17:58\nanswered May 20 '17 at 4:49\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"Just to add up, here's a function to return a timestamp string in Javascript. Example: 15:06:38 PM\n\nfunction displayTime() {\n    var str = \"\";\n\n    var currentTime = new Date()\n    var hours = currentTime.getHours()\n    var minutes = currentTime.getMinutes()\n    var seconds = currentTime.getSeconds()\n\n    if (minutes < 10) {\n        minutes = \"0\" + minutes\n    }\n    if (seconds < 10) {\n        seconds = \"0\" + seconds\n    }\n    str += hours + \":\" + minutes + \":\" + seconds + \" \";\n    if(hours > 11){\n        str += \"PM\"\n    } else {\n        str += \"AM\"\n    }\n    return str;\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 21 '12 at 19:46\nanswered Sep 21 '12 at 19:12\nlive-love\n36k18\n18 gold badges\n173\n173 silver badges\n160\n160 bronze badges","comments":[]},{"answer":"Performance\n\nToday - 2020.04.23 I perform tests for chosen solutions. I tested on MacOs High Sierra 10.13.6 on Chrome 81.0, Safari 13.1, Firefox 75.0\n\nConclusions\nSolution Date.now() (E) is fastest on Chrome and Safari and second fast on Firefox and this is probably best choice for fast cross-browser solution\nSolution performance.now() (G), what is surprising, is more than 100x faster than other solutions on Firefox but slowest on Chrome\nSolutions C,D,F are quite slow on all browsers\n\nDetails\n\nResults for chrome\n\nYou can perform test on your machine HERE\n\nCode used in tests is presented in below snippet\n\nShow code snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jun 27 '18 at 16:33\nKamil Kiełczewski\n57.6k22\n22 gold badges\n275\n275 silver badges\n253\n253 bronze badges","comments":[]},{"answer":"One I haven't seen yet\n\nMath.floor(Date.now() / 1000); // current time in seconds\n\n\nAnother one I haven't seen yet is\n\nvar _ = require('lodash'); // from here https://lodash.com/docs#now\n_.now();\n\nShare\nImprove this answer\nFollow\nedited Apr 4 '18 at 16:10\nmgthomas99\n3,2081\n1 gold badge\n17\n17 silver badges\n20\n20 bronze badges\nanswered Mar 31 '14 at 8:18\nBelldandu\n1,71013\n13 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"The Date.getTime() method can be used with a little tweak:\n\nThe value returned by the getTime method is the number of milliseconds since 1 January 1970 00:00:00 UTC.\n\nDivide the result by 1000 to get the Unix timestamp, floor if necessary:\n\n(new Date).getTime() / 1000\n\n\nThe Date.valueOf() method is functionally equivalent to Date.getTime(), which makes it possible to use arithmetic operators on date object to achieve identical results. In my opinion, this approach affects readability.\n\nShare\nImprove this answer\nFollow\nedited May 7 '15 at 9:10\nanswered May 3 '12 at 9:02\nSalman A\n233k77\n77 gold badges\n399\n399 silver badges\n493\n493 bronze badges","comments":[]},{"answer":"The code Math.floor(new Date().getTime() / 1000) can be shortened to new Date / 1E3 | 0.\n\nConsider to skip direct getTime() invocation and use | 0 as a replacement for Math.floor() function. It's also good to remember 1E3 is a shorter equivalent for 1000 (uppercase E is preferred than lowercase to indicate 1E3 as a constant).\n\nAs a result you get the following:\n\nvar ts = new Date / 1E3 | 0;\n\nconsole.log(ts);\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Mar 27 '18 at 6:08\nanswered Oct 14 '15 at 16:41\nValentin Podkamennyi\n6,6174\n4 gold badges\n24\n24 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"For a timestamp with microsecond resolution, there's performance.now:\n\nfunction time() { \n  return performance.now() + performance.timing.navigationStart;\n}\n\n\nThis could for example yield 1436140826653.139, while Date.now only gives 1436140826653.\n\nShare\nImprove this answer\nFollow\nanswered Jul 6 '15 at 0:01\niter\n3782\n2 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"I highly recommend using moment.js. To get the number of milliseconds since UNIX epoch, do\n\nmoment().valueOf()\n\n\nTo get the number of seconds since UNIX epoch, do\n\nmoment().unix()\n\n\nYou can also convert times like so:\n\nmoment('2015-07-12 14:59:23', 'YYYY-MM-DD HH:mm:ss').valueOf()\n\n\nI do that all the time. No pun intended.\n\nTo use moment.js in the browser:\n\n<script src=\"moment.js\"></script>\n<script>\n    moment().valueOf();\n</script>\n\n\nFor more details, including other ways of installing and using MomentJS, see their docs\n\nShare\nImprove this answer\nFollow\nedited Oct 1 '15 at 7:28\nanswered Jul 14 '15 at 8:29\nFullStack\n5,3804\n4 gold badges\n35\n35 silver badges\n71\n71 bronze badges","comments":[]},{"answer":"You can only use\n\n    var timestamp = new Date().getTime();\n    console.log(timestamp);\n Run code snippetExpand snippet\n\nto get the current timestamp. No need to do anything extra.\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '16 at 18:48\nRuslan López\n4,1301\n1 gold badge\n19\n19 silver badges\n34\n34 bronze badges\nanswered Mar 16 '16 at 5:45\nJitendra Pawar\n1,04913\n13 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"Here is a simple function to generate timestamp in the format: mm/dd/yy hh:mi:ss\n\nfunction getTimeStamp() {\n    var now = new Date();\n    return ((now.getMonth() + 1) + '/' +\n            (now.getDate()) + '/' +\n             now.getFullYear() + \" \" +\n             now.getHours() + ':' +\n             ((now.getMinutes() < 10)\n                 ? (\"0\" + now.getMinutes())\n                 : (now.getMinutes())) + ':' +\n             ((now.getSeconds() < 10)\n                 ? (\"0\" + now.getSeconds())\n                 : (now.getSeconds())));\n}\n\nShare\nImprove this answer\nFollow\nedited Jul 3 '13 at 15:10\nVisioN\n134k28\n28 gold badges\n255\n255 silver badges\n265\n265 bronze badges\nanswered May 21 '13 at 9:22\ndeepakssn\n4,7132\n2 gold badges\n20\n20 silver badges\n19\n19 bronze badges","comments":["@b123400 - Here's the Lisp version: (new (chain (-date) (to-i-s-o-string)))."]},{"answer":"// The Current Unix Timestamp\n// 1443534720 seconds since Jan 01 1970. (UTC)\n\n// seconds\nconsole.log(Math.floor(new Date().valueOf() / 1000)); // 1443534720\nconsole.log(Math.floor(Date.now() / 1000)); // 1443534720\nconsole.log(Math.floor(new Date().getTime() / 1000)); // 1443534720\n\n// milliseconds\nconsole.log(Math.floor(new Date().valueOf())); // 1443534720087\nconsole.log(Math.floor(Date.now())); // 1443534720087\nconsole.log(Math.floor(new Date().getTime())); // 1443534720087\n\n// jQuery\n// seconds\nconsole.log(Math.floor($.now() / 1000)); // 1443534720\n// milliseconds\nconsole.log($.now()); // 1443534720087\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 24 '16 at 18:47\nRuslan López\n4,1301\n1 gold badge\n19\n19 silver badges\n34\n34 bronze badges\nanswered Sep 29 '15 at 13:55\nblueberry0xff\n3,38528\n28 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"If it is for logging purposes, you can use ISOString\n\nnew Date().toISOString()\n\n\"2019-05-18T20:02:36.694Z\"\n\nShare\nImprove this answer\nFollow\nanswered May 18 '19 at 20:43\ncenkarioz\n4817\n7 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"Any browsers not supported Date.now, you can use this for get current date time:\n\ncurrentTime = Date.now() || +new Date()\n\nShare\nImprove this answer\nFollow\nanswered May 9 '13 at 6:53\nmr.boyfox\n13.1k6\n6 gold badges\n53\n53 silver badges\n75\n75 bronze badges","comments":["(Rephrasing my comment) Your code has a problem: it executes Date.now method instead of checking its support first. On older browsres it will cause Date.now is not a function error.","Perhaps a better alternative would be to use a ternary operator to assert that Date.now actually exists (and is a function), before attempting to invoke it: currentTime = typeof Date.now === \"function\" ? Date.now() : +new Date()."]},{"answer":"This seems to work.\n\nconsole.log(clock.now);\n// returns 1444356078076\n\nconsole.log(clock.format(clock.now));\n//returns 10/8/2015 21:02:16\n\nconsole.log(clock.format(clock.now + clock.add(10, 'minutes'))); \n//returns 10/8/2015 21:08:18\n\nvar clock = {\n    now:Date.now(),\n    add:function (qty, units) {\n            switch(units.toLowerCase()) {\n                case 'weeks'   :  val = qty * 1000 * 60 * 60 * 24 * 7;  break;\n                case 'days'    :  val = qty * 1000 * 60 * 60 * 24;  break;\n                case 'hours'   :  val = qty * 1000 * 60 * 60;  break;\n                case 'minutes' :  val = qty * 1000 * 60;  break;\n                case 'seconds' :  val = qty * 1000;  break;\n                default       :  val = undefined;  break;\n                }\n            return val;\n            },\n    format:function (timestamp){\n            var date = new Date(timestamp);\n            var year = date.getFullYear();\n            var month = date.getMonth() + 1;\n            var day = date.getDate();\n            var hours = date.getHours();\n            var minutes = \"0\" + date.getMinutes();\n            var seconds = \"0\" + date.getSeconds();\n            // Will display time in xx/xx/xxxx 00:00:00 format\n            return formattedTime = month + '/' + \n                                day + '/' + \n                                year + ' ' + \n                                hours + ':' + \n                                minutes.substr(-2) + \n                                ':' + seconds.substr(-2);\n            }\n};\n\nShare\nImprove this answer\nFollow\nanswered Oct 9 '15 at 2:03\nRonnie Royston\n12.5k5\n5 gold badges\n59\n59 silver badges\n76\n76 bronze badges","comments":[]},{"answer":"This one has a solution : which converts unixtime stamp to tim in js try this\n\nvar a = new Date(UNIX_timestamp*1000);\nvar hour = a.getUTCHours();\nvar min = a.getUTCMinutes();\nvar sec = a.getUTCSeconds();\n\nShare\nImprove this answer\nFollow\nanswered Jul 1 '13 at 6:47\nAnoop P S\n6321\n1 gold badge\n9\n9 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"I learned a really cool way of converting a given Date object to a Unix timestamp from the source code of JQuery Cookie the other day.\n\nHere's an example:\n\nvar date = new Date();\nvar timestamp = +date;\n\nShare\nImprove this answer\nFollow\nanswered Mar 11 '15 at 9:52\ngeorgez\n7278\n8 silver badges\n20\n20 bronze badges","comments":["I was about to write the new Date() Object .You can console log(new Date()) and then skim through the related methods under the new Date() object/ function"]},{"answer":"If want a basic way to generate a timestamp in Node.js this works well.\n\nvar time = process.hrtime();\nvar timestamp = Math.round( time[ 0 ] * 1e3 + time[ 1 ] / 1e6 );\n\n\nOur team is using this to bust cache in a localhost environment. The output is /dist/css/global.css?v=245521377 where 245521377 is the timestamp generated by hrtime().\n\nHopefully this helps, the methods above can work as well but I found this to be the simplest approach for our needs in Node.js.\n\nShare\nImprove this answer\nFollow\nanswered May 29 '15 at 13:40\nKevin Leary\n7,0321\n1 gold badge\n47\n47 silver badges\n42\n42 bronze badges","comments":[]},{"answer":"For lodash and underscore users, use _.now.\n\nvar timestamp = _.now(); // in milliseconds\n\nShare\nImprove this answer\nFollow\nanswered Mar 30 '15 at 8:40\nMuhammad Reda\n24.6k13\n13 gold badges\n86\n86 silver badges\n99\n99 bronze badges","comments":[]},{"answer":"Moment.js can abstract away a lot of the pain in dealing with Javascript Dates.\n\nSee: http://momentjs.com/docs/#/displaying/unix-timestamp/\n\nmoment().unix();\n\nShare\nImprove this answer\nFollow\nanswered Mar 6 '15 at 0:33\nRimian\n33k13\n13 gold badges\n106\n106 silver badges\n109\n109 bronze badges","comments":["Note that this gives the number of seconds (not milliseconds) since UNIX epoch. If you want the milliseconds, use moment().valueOf(). See my answer."]},{"answer":"As of writing this, the top answer is 9 years old, and a lot has changed since then - not least, we have near universal support for a non-hacky solution:\n\nDate.now()\n\n\nIf you want to be absolutely certain that this won't break in some ancient (pre ie9) browser, you can put it behind a check, like so:\n\nconst currentTimestamp = (!Date.now ? +new Date() : Date.now());\n\n\nThis will return the milliseconds since epoch time, of course, not seconds.\n\nMDN Documentation on Date.now\n\nShare\nImprove this answer\nFollow\nanswered Dec 14 '17 at 10:09\nOlemak\n1,6051\n1 gold badge\n13\n13 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"more simpler way:\n\nvar timeStamp=event.timestamp || new Date().getTime();\n\nShare\nImprove this answer\nFollow\nanswered Oct 26 '13 at 3:51\nVicky Gonsalves\n10.8k2\n2 gold badges\n35\n35 silver badges\n55\n55 bronze badges","comments":["Do know where event comes from. You need to give a better explanation of the way you resolve it instead of you writing an answer. Please!","I was about to write the new Date() Object .You can console log(new Date()) and then skim through the related methods under the new Date() object/ function"]}]},{"id":"426258","href":"https://stackoverflow.com/questions/426258/setting-checked-for-a-checkbox-with-jquery","title":"Setting “checked” for a checkbox with jQuery","description":"\n                \nI'd like to do something like this to tick a checkbox using jQuery:\n\n$(\".myCheckBox\").checked(true);\n\n\nor\n\n$(\".myCheckBox\").selected(true);\n\n\nDoes such a thing exist?\n    ","questionComments":["A more specific (and very useful!) question, \"How do I check a item in a checkbox-set BY VALUE?\", I think we can also discuss here, and I posted an answer below.","Check other ways to do this using jQuery here stackoverflow.com/a/22019103/1868660","If you need the onchange event triggered, it's $(\"#mycheckbox\").click();","\"Checking something\" suggests testing it, so I think 'Making a checkbox checked' is a more clear and better title.","prop(); function is the perfect answer. See the function definition - api.jquery.com/prop"],"answers":[{"answer":"Modern jQuery\n\nUse .prop():\n\n$('.myCheckbox').prop('checked', true);\n$('.myCheckbox').prop('checked', false);\n\nDOM API\n\nIf you're working with just one element, you can always just access the underlying HTMLInputElement and modify its .checked property:\n\n$('.myCheckbox')[0].checked = true;\n$('.myCheckbox')[0].checked = false;\n\n\nThe benefit to using the .prop() and .attr() methods instead of this is that they will operate on all matched elements.\n\njQuery 1.5.x and below\n\nThe .prop() method is not available, so you need to use .attr().\n\n$('.myCheckbox').attr('checked', true);\n$('.myCheckbox').attr('checked', false);\n\n\nNote that this is the approach used by jQuery's unit tests prior to version 1.6 and is preferable to using $('.myCheckbox').removeAttr('checked'); since the latter will, if the box was initially checked, change the behaviour of a call to .reset() on any form that contains it – a subtle but probably unwelcome behaviour change.\n\nFor more context, some incomplete discussion of the changes to the handling of the checked attribute/property in the transition from 1.5.x to 1.6 can be found in the version 1.6 release notes and the Attributes vs. Properties section of the .prop() documentation.\n\nShare\nImprove this answer\nFollow\nedited Aug 18 '19 at 19:04\nMultiplyByZer0\n4,5393\n3 gold badges\n28\n28 silver badges\n46\n46 bronze badges\nanswered Jan 8 '09 at 22:25\nXian\n74k12\n12 gold badges\n41\n41 silver badges\n49\n49 bronze badges","comments":["@Xian removing the the checked attribute makes it impossible to reset the form","As a side note, jQuery 1.6.1 should be fixing the issue I mentioned, so we can tehcnically all still go back to using $(...).prop(...)","\"If you're working with just one element, it will always be fastest to use DOMElement.checked = true\". But it would be negligible, because it's only one element...","As Tyler says, it is a negligible improvement in performance. To me, coding using a common API makes it more readable than mixing native API and jQuery APIs. I'd stick with jQuery.","@TylerCrompton - Of course, its not entirely about performance, but doing $(element).prop('checked') is a complete waste of typing. element.checked exists and should be used in the cases where you already have element"]},{"answer":"Use:\n\n$(\".myCheckbox\").attr('checked', true); // Deprecated\n$(\".myCheckbox\").prop('checked', true);\n\n\nAnd if you want to check if a checkbox is checked or not:\n\n$('.myCheckbox').is(':checked');\n\nShare\nImprove this answer\nFollow\nedited Mar 18 '15 at 18:34\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 8 '09 at 22:25\nbchhun\n17k5\n5 gold badges\n26\n26 silver badges\n30\n30 bronze badges","comments":["also $(selector).checked to check is checked","I tried this exact code and it didn't work for me in the case of a select all / select none checkbox that needs to check and uncheck all as well as check their state. Instead, I tried @Christopher Harris' answer and that did the trick.","Why using \"form #mycheckbox\" instead of simply \"#mycheckbox\"? The id is already unique in the whole document, it is faster and simpler to pick it directly.","@YuriAlbuquerque it was an example. you can use whatever selector you want.","$(selector).checked does not work. There is no 'checked' method in jQuery."]},{"answer":"This is the correct way of checking and unchecking checkboxes with jQuery, as it is cross-platform standard, and will allow form reposts.\n\n$('.myCheckBox').each(function(){ this.checked = true; });\n\n$('.myCheckBox').each(function(){ this.checked = false; });\n\n\nBy doing this, you are using JavaScript standards for checking and unchecking checkboxes, so any browser that properly implements the \"checked\" property of the checkbox element will run this code flawlessly. This should be all major browsers, but I am unable to test previous to Internet Explorer 9.\n\nThe Problem (jQuery 1.6):\n\nOnce a user clicks on a checkbox, that checkbox stops responding to the \"checked\" attribute changes.\n\nHere is an example of the checkbox attribute failing to do the job after someone has clicked the checkbox (this happens in Chrome).\n\nFiddle\n\nThe Solution:\n\nBy using JavaScript's \"checked\" property on the DOM elements, we are able to solve the problem directly, instead of trying to manipulate the DOM into doing what we want it to do.\n\nFiddle\n\nThis plugin will alter the checked property of any elements selected by jQuery, and successfully check and uncheck checkboxes under all circumstances. So, while this may seem like an over-bearing solution, it will make your site's user experience better, and help prevent user frustration.\n\n(function( $ ) {\n    $.fn.checked = function(value) {\n        if(value === true || value === false) {\n            // Set the value of the checkbox\n            $(this).each(function(){ this.checked = value; });\n        } \n        else if(value === undefined || value === 'toggle') {\n            // Toggle the checkbox\n            $(this).each(function(){ this.checked = !this.checked; });\n        }\n\n        return this;\n    };\n})( jQuery );\n\n\nAlternatively, if you do not want to use a plugin, you can use the following code snippets:\n\n// Check\n$(':checkbox').prop('checked', true);\n\n// Un-check\n$(':checkbox').prop('checked', false);\n\n// Toggle\n$(':checkbox').prop('checked', function (i, value) {\n    return !value;\n});\n\nShare\nImprove this answer\nFollow\nedited Jul 31 '15 at 13:43\nRevanthKrishnaKumar V.\n1,7891\n1 gold badge\n19\n19 silver badges\n33\n33 bronze badges\nanswered May 6 '11 at 19:31\ncwharris\n17k4\n4 gold badges\n42\n42 silver badges\n63\n63 bronze badges","comments":["In your first JSFiddle example you should be using removeAttr('checked') rather than attr('checked', false)","@DanielXMoore, You're skirting around the issue. The example was to show that once the check-box was clicked by the user, the browser no longer responds to checked attribute changes, regardless of the method used to change them.","@ChristopherHarris Ok, you're right, I missed that. As of jQuery 1.6 shouldn't you use the .prop method though?$('.myCheckBox').prop('checked', true) That way it will automatically apply to the entire set of matched elements (only when setting though, getting is still only the first)","Yes. prop is definitely the appropriate way to set attributes on an element.","@ChristopherHarris, I have added what I needed to the plugin to allow some parameter flexibility. This made inline processing easier without the type conversion. Esp from disparate databases with 'ideas' about what \"true\" is. Fiddle: jsfiddle.net/Cyberjetx/vcp96"]},{"answer":"You can do\n\n$('.myCheckbox').attr('checked',true) //Standards compliant\n\n\nor\n\n$(\"form #mycheckbox\").attr('checked', true)\n\n\nIf you have custom code in the onclick event for the checkbox that you want to fire, use this one instead:\n\n$(\"#mycheckbox\").click();\n\n\nYou can uncheck by removing the attribute entirely:\n\n$('.myCheckbox').removeAttr('checked')\n\n\nYou can check all checkboxes like this:\n\n$(\".myCheckbox\").each(function(){\n    $(\"#mycheckbox\").click()\n});\n\nShare\nImprove this answer\nFollow\nedited Dec 29 '11 at 18:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 8 '09 at 22:24\nMicah\n103k81\n81 gold badges\n223\n223 silver badges\n320\n320 bronze badges","comments":["you can also go $(\"#myTable input:checkbox\").each(...);","You can also go $(\".myCheckbox\").click()","@Michah removing the the checked attribute makes it impossible to reset the form","This answer is out-of-date because it uses .attr instead of .prop.","$(\"#mycheckbox\").click(); worked for me as I was listening to change event too and .attr & .prop didn't fire change event."]},{"answer":"You can also extend the $.fn object with new methods:\n\n(function($)  {\n   $.fn.extend({\n      check : function()  {\n         return this.filter(\":radio, :checkbox\").attr(\"checked\", true);\n      },\n      uncheck : function()  {\n         return this.filter(\":radio, :checkbox\").removeAttr(\"checked\");\n      }\n   });\n}(jQuery));\n\n\nThen you can just do:\n\n$(\":checkbox\").check();\n$(\":checkbox\").uncheck();\n\n\nOr you may want to give them more unique names like mycheck() and myuncheck() in case you use some other library that uses those names.\n\nShare\nImprove this answer\nFollow\nanswered Aug 20 '10 at 18:19\nlivefree75\n8536\n6 silver badges\n2\n2 bronze badges","comments":["@livfree75 removing the the checked attribute makes it impossible to reset the form","This answer is out-of-date because it uses .attr instead of .prop."]},{"answer":"$(\"#mycheckbox\")[0].checked = true;\n$(\"#mycheckbox\").attr('checked', true);\n$(\"#mycheckbox\").click();\n\n\nThe last one will fire the click event for the checkbox, the others will not. So if you have custom code in the onclick event for the checkbox that you want to fire, use the last one.\n\nShare\nImprove this answer\nFollow\nedited Feb 3 '09 at 17:06\nanswered Jan 8 '09 at 22:36\nChris Brandsma\n11.4k5\n5 gold badges\n47\n47 silver badges\n58\n58 bronze badges","comments":["top one will fail...checked is not a jquery object member","This answer is out-of-date because it uses .attr instead of .prop.","IMO the click event is unreliable in Firefox and Edge."]},{"answer":"To check a checkbox you should use\n\n $('.myCheckbox').attr('checked',true);\n\n\nor\n\n $('.myCheckbox').attr('checked','checked');\n\n\nand to uncheck a check box you should always set it to false:\n\n $('.myCheckbox').attr('checked',false);\n\n\nIf you do\n\n  $('.myCheckbox').removeAttr('checked')\n\n\nit removes the attribute all together and therefore you will not be able to reset the form.\n\nBAD DEMO jQuery 1.6. I think this is broken. For 1.6 I am going to make a new post on that.\n\nNEW WORKING DEMO jQuery 1.5.2 works in Chrome.\n\nBoth demos use\n\n$('#tc').click(function() {\n    if ( $('#myCheckbox').attr('checked')) {\n        $('#myCheckbox').attr('checked', false);\n    } else {\n        $('#myCheckbox').attr('checked', 'checked');\n    }\n});\n\nShare\nImprove this answer\nFollow\nedited Dec 29 '11 at 18:21\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 23 '11 at 15:22\nmcgrailm\n16.8k21\n21 gold badges\n80\n80 silver badges\n128\n128 bronze badges","comments":["This is inaccurate. setting the 'checked' attribute to '' will not uncheck check boxes in at least chrome.","@xixonia I did test before I posted your fiddle doesn't work because you didn't change the menu on the left to include jquery","mcgralim - in 1.6 its even easier.... $(\".mycheckbox\").prop(\"checked\", true/false)","@MarkAmery you mentioned that my post added nothing at the time of post but that is in accurate. If you look at the history of the accepted answer you'll find they suggest removing the element. Which makes it impossible to reset the form, which was why I posted to begin with.","@mcgrailm I've gone ahead and modified the accepted answer in light of your remarks. If you'd like to cast an eye over it and check that it looks good in its current state, I'd appreciate that. My apologies again for offering up sharp criticism that was, at least in part, highly misguided."]},{"answer":"This selects elements that have the specified attribute with a value containing the given substring \"ckbItem\":\n\n$('input[name *= ckbItem]').prop('checked', true);\n\n\nIt will select all elements that contain ckbItem in its name attribute.\n\nShare\nImprove this answer\nFollow\nedited Jul 18 '18 at 13:44\nanswered Sep 20 '10 at 11:43\nAbou-Emish\n1,8931\n1 gold badge\n19\n19 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"Assuming that the question is...\n\nHow do I check a checkbox-set BY VALUE?\n\nRemember that in a typical checkbox set, all input tags have the same name, they differ by the attribute value: there are no ID for each input of the set.\n\nXian's answer can be extended with a more specific selector, using the following line of code:\n\n$(\"input.myclass[name='myname'][value='the_value']\").prop(\"checked\", true);\n\nShare\nImprove this answer\nFollow\nedited Jun 9 '14 at 15:07\ncommunity wiki\n\n\n5 revs, 3 users 74%\nPeter Krauss","comments":[]},{"answer":"I'm missing the solution. I'll always use:\n\nif ($('#myCheckBox:checked').val() !== undefined)\n{\n    //Checked\n}\nelse\n{\n    //Not checked\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '14 at 16:43\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 24 '12 at 11:33\nOverbeeke\n1,9443\n3 gold badges\n21\n21 silver badges\n23\n23 bronze badges","comments":["This doesn't answer the question (the question is about setting whether a checkbox is checked, not determining whether a checkbox is checked). It's also a pretty ugly way of determining if the checkbox is checked (for one thing, you're exploiting the non-self-evident fact that .val() will always return undefined when called on 0 elements to detect that a jQuery object is empty, when you could simply check its .length instead) - see stackoverflow.com/questions/901712/… for more readable approaches."]},{"answer":"To check a checkbox using jQuery 1.6 or higher just do this:\n\ncheckbox.prop('checked', true);\n\n\nTo uncheck, use:\n\ncheckbox.prop('checked', false);\n\n\nHere' s what I like to use to toggle a checkbox using jQuery:\n\ncheckbox.prop('checked', !checkbox.prop('checked'));\n\n\nIf you're using jQuery 1.5 or lower:\n\ncheckbox.attr('checked', true);\n\n\nTo uncheck, use:\n\ncheckbox.attr('checked', false);\n\nShare\nImprove this answer\nFollow\nedited May 9 '17 at 13:23\nanswered Mar 14 '13 at 9:40\nRamon de Jesus\n7416\n6 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"Here is a way to do it without jQuery\n\nfunction addOrAttachListener(el, type, listener, useCapture) {\n  if (el.addEventListener) {\n    el.addEventListener(type, listener, useCapture);\n  } else if (el.attachEvent) {\n    el.attachEvent(\"on\" + type, listener);\n  }\n};\n\naddOrAttachListener(window, \"load\", function() {\n  var cbElem = document.getElementById(\"cb\");\n  var rcbElem = document.getElementById(\"rcb\");\n  addOrAttachListener(cbElem, \"click\", function() {\n    rcbElem.checked = cbElem.checked;\n  }, false);\n}, false);\n<label>Click Me!\n  <input id=\"cb\" type=\"checkbox\" />\n</label>\n<label>Reflection:\n  <input id=\"rcb\" type=\"checkbox\" />\n</label>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited May 10 '16 at 9:58\nanswered Oct 23 '12 at 0:41\nXitalogy\n1,5261\n1 gold badge\n14\n14 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"Here is code for checked and unchecked with a button:\n\nvar set=1;\nvar unset=0;\njQuery( function() {\n    $( '.checkAll' ).live('click', function() {\n        $( '.cb-element' ).each(function () {\n            if(set==1){ $( '.cb-element' ).attr('checked', true) unset=0; }\n            if(set==0){ $( '.cb-element' ).attr('checked', false); unset=1; }\n        });\n        set=unset;\n    });\n});\n\n\nUpdate: Here is the same code block using the newer Jquery 1.6+ prop method, which replaces attr:\n\nvar set=1;\nvar unset=0;\njQuery( function() {\n    $( '.checkAll' ).live('click', function() {\n        $( '.cb-element' ).each(function () {\n            if(set==1){ $( '.cb-element' ).prop('checked', true) unset=0; }\n            if(set==0){ $( '.cb-element' ).prop('checked', false); unset=1; }\n        });\n        set=unset;\n    });\n});\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '17 at 15:55\nMrBoJangles\n11.6k16\n16 gold badges\n60\n60 silver badges\n79\n79 bronze badges\nanswered Oct 25 '11 at 8:51\nstarjahid\n3373\n3 silver badges\n2\n2 bronze badges","comments":["This answer is out-of-date because it uses .attr instead of .prop."]},{"answer":"Try this:\n\n$('#checkboxid').get(0).checked = true;  //For checking\n\n$('#checkboxid').get(0).checked = false; //For unchecking\n\nShare\nImprove this answer\nFollow\nedited Feb 16 '13 at 10:33\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 10 '12 at 10:26\nprashanth\n3193\n3 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"We can use elementObject with jQuery for getting the attribute checked:\n\n$(objectElement).attr('checked');\n\n\nWe can use this for all jQuery versions without any error.\n\nUpdate: Jquery 1.6+ has the new prop method which replaces attr, e.g.:\n\n$(objectElement).prop('checked');\n\nShare\nImprove this answer\nFollow\nedited Apr 11 '17 at 15:53\nMrBoJangles\n11.6k16\n16 gold badges\n60\n60 silver badges\n79\n79 bronze badges\nanswered Jun 24 '11 at 8:27\nPrasanth P\n7052\n2 gold badges\n9\n9 silver badges\n24\n24 bronze badges","comments":["This answer is out-of-date because it uses .attr instead of .prop."]},{"answer":"If you are using PhoneGap doing application development, and you have a value on the button that you want to show instantly, remember to do this\n\n$('span.ui-[controlname]',$('[id]')).text(\"the value\");\n\n\nI found that without the span, the interface will not update no matter what you do.\n\nShare\nImprove this answer\nFollow\nedited Feb 16 '13 at 10:32\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 17 '12 at 6:34\nClement Ho\n3093\n3 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"Here is the code and demo for how to check multiple check boxes...\n\nhttp://jsfiddle.net/tamilmani/z8TTt/\n\n$(\"#check\").on(\"click\", function () {\n\n    var chk = document.getElementById('check').checked;\n    var arr = document.getElementsByTagName(\"input\");\n\n    if (chk) {\n        for (var i in arr) {\n            if (arr[i].name == 'check') arr[i].checked = true;\n        }\n    } else {\n        for (var i in arr) {\n            if (arr[i].name == 'check') arr[i].checked = false;\n        }\n    }\n});\n\nShare\nImprove this answer\nFollow\nedited Feb 10 '16 at 13:18\nJoaquinglezsantos\n1,04211\n11 silver badges\n24\n24 bronze badges\nanswered Aug 16 '13 at 6:17\ntamilmani\n5635\n5 silver badges\n13\n13 bronze badges","comments":["-​1; mixing jQuery selectors like $(\"#check\") with raw DOM API calls like document.getElementsByTagName(\"input\") seems inelegant to me, especially given that the for loops here could be avoided by using .prop(). Regardless this is yet another late answer that adds nothing new."]},{"answer":"Another possible solution:\n\n    var c = $(\"#checkboxid\");\n    if (c.is(\":checked\")) {\n         $('#checkboxid').prop('checked', false);\n    } else {\n         $('#checkboxid').prop('checked', true);\n    }\n\nShare\nImprove this answer\nFollow\nedited Jul 21 '14 at 9:34\nGetz\n3,8476\n6 gold badges\n33\n33 silver badges\n52\n52 bronze badges\nanswered Oct 12 '13 at 8:23\nMuhammad Aamir Ali\n19k9\n9 gold badges\n64\n64 silver badges\n55\n55 bronze badges","comments":[]},{"answer":"As @livefree75 said:\n\njQuery 1.5.x and below\n\nYou can also extend the $.fn object with new methods:\n\n(function($)  {\n   $.fn.extend({\n      check : function()  {\n         return this.filter(\":radio, :checkbox\").attr(\"checked\", true);\n      },\n      uncheck : function()  {\n         return this.filter(\":radio, :checkbox\").removeAttr(\"checked\");\n      }\n   });\n}(jQuery));\n\n\nBut in new versions of jQuery, we have to use something like this:\n\njQuery 1.6+\n\n    (function($)  {\n       $.fn.extend({\n          check : function()  {\n             return this.filter(\":radio, :checkbox\").prop(\"checked\", true);\n          },\n          uncheck : function()  {\n             return this.filter(\":radio, :checkbox\").prop(\"checked\",false);\n          }\n       });\n    }(jQuery));\n\n\nThen you can just do:\n\n    $(\":checkbox\").check();\n    $(\":checkbox\").uncheck();\n\nShare\nImprove this answer\nFollow\nedited May 21 '17 at 11:00\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 23 '16 at 18:43\nArdalan Shahgholi\n10.3k13\n13 gold badges\n95\n95 silver badges\n124\n124 bronze badges","comments":[]},{"answer":"If using mobile and you want the interface to update and show the checkbox as unchecked, use the following:\n\n$(\"#checkbox1\").prop('checked', false).checkboxradio(\"refresh\");\n\nShare\nImprove this answer\nFollow\nanswered Jan 11 '13 at 13:05\nMatt Peacock\n1991\n1 silver badge\n2\n2 bronze badges","comments":[]},{"answer":"For jQuery 1.6+\n\n$('.myCheckbox').prop('checked', true);\n$('.myCheckbox').prop('checked', false);\n\n\nFor jQuery 1.5.x and below\n\n$('.myCheckbox').attr('checked', true);\n$('.myCheckbox').attr('checked', false);\n\n\nTo check,\n\n$('.myCheckbox').removeAttr('checked');\n\nShare\nImprove this answer\nFollow\nanswered Apr 21 '15 at 10:29\nlogan\n7,10834\n34 gold badges\n99\n99 silver badges\n173\n173 bronze badges","comments":[]},{"answer":"To check and uncheck\n\n$('.myCheckbox').prop('checked', true);\n$('.myCheckbox').prop('checked', false);\n\nShare\nImprove this answer\nFollow\nedited Dec 3 '13 at 2:18\nTheraot\n19.6k4\n4 gold badges\n46\n46 silver badges\n74\n74 bronze badges\nanswered Nov 14 '13 at 6:34\njj2422\n3725\n5 silver badges\n20\n20 bronze badges","comments":["-​1; this adds no value at all to an already bloated thread. The code here is exactly the same as the accepted answer."]},{"answer":"Be aware of memory leaks in Internet Explorer prior to Internet Explorer 9, as the jQuery documentation states:\n\nIn Internet Explorer prior to version 9, using .prop() to set a DOM element property to anything other than a simple primitive value (number, string, or boolean) can cause memory leaks if the property is not removed (using .removeProp()) before the DOM element is removed from the document. To safely set values on DOM objects without memory leaks, use .data().\n\nShare\nImprove this answer\nFollow\nedited Nov 22 '14 at 15:33\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 22 '13 at 7:25\nnaor\n2,7702\n2 gold badges\n16\n16 silver badges\n11\n11 bronze badges","comments":["This is irrelevant, since all the (correct) answers use .prop('checked',true).","Not sure I understood your comment.This still exists in jQuery documentation. Are you implying there is no memory leak in IE < 9 ?","There is no memory leak in this case, since we are setting it to a simple primitive value (Boolean)."]},{"answer":"$('controlCheckBox').click(function(){\n    var temp = $(this).prop('checked');\n    $('controlledCheckBoxes').prop('checked', temp);\n});\n\nShare\nImprove this answer\nFollow\nedited Jul 16 '13 at 2:57\nanswered Jul 16 '13 at 2:10\nmahmoh\n7627\n7 silver badges\n14\n14 bronze badges","comments":["-​1 for being a code-only answer, not answering the question directly, and adding nothing that other answers hadn't already covered."]},{"answer":"This is probably the shortest and easiest solution:\n\n$(\".myCheckBox\")[0].checked = true;\n\n\nor\n\n$(\".myCheckBox\")[0].checked = false;\n\n\nEven shorter would be:\n\n$(\".myCheckBox\")[0].checked = !0;\n$(\".myCheckBox\")[0].checked = !1;\n\n\nHere is a jsFiddle as well.\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '14 at 16:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 27 '14 at 15:11\nFriedrich\n1,63016\n16 silver badges\n33\n33 bronze badges","comments":[]},{"answer":"Plain JavaScript is very simple and much less overhead:\n\nvar elements = document.getElementsByClassName('myCheckBox');\nfor(var i = 0; i < elements.length; i++)\n{\n    elements[i].checked = true;\n}\n\n\nExample here\n\nShare\nImprove this answer\nFollow\nedited Sep 23 '13 at 1:12\nanswered Sep 18 '13 at 1:14\nAlex W\n33.8k9\n9 gold badges\n92\n92 silver badges\n99\n99 bronze badges","comments":["@MarkAmery The accepted answer does not cover how to do it without jQuery. My answer adds supplementary benefit to the accepted answer."]},{"answer":"I couldn't get it working using:\n\n$(\"#cb\").prop('checked', 'true');\n$(\"#cb\").prop('checked', 'false');\n\n\nBoth true and false would check the checkbox. What worked for me was:\n\n$(\"#cb\").prop('checked', 'true'); // For checking\n$(\"#cb\").prop('checked', '');     // For unchecking\n\nShare\nImprove this answer\nFollow\nedited Dec 15 '14 at 18:44\nMark Amery\n115k61\n61 gold badges\n361\n361 silver badges\n414\n414 bronze badges\nanswered Jan 5 '12 at 13:26\nfredcrs\n3,3787\n7 gold badges\n30\n30 silver badges\n53\n53 bronze badges","comments":["shouldn't it be true and false and not 'true' and 'false'?","It \"didn't work\" because 'false' was converted to boolean value which resulted in true - empty string evaluates to false thus it \"worked\". See this fiddle for example of what I mean.","@chris97ong I've rolled back your edit; when someone says \"Don't use the code below because it doesn't work\", fixing that code while leaving the comment saying that it doesn't work is harmful - especially when it breaks the explanation in the comments of why the code isn't working. That said, this answer is still somewhat confused and deserves a downvote for the reasons given by tpower and ShadowWizard.","use true and false values for boolean, do not use 'true' or 'false' (strings)."]},{"answer":"When you checked a checkbox like;\n\n$('.className').attr('checked', 'checked')\n\n\nit might not be enough. You should also call the function below;\n\n$('.className').prop('checked', 'true')\n\n\nEspecially when you removed the checkbox checked attribute.\n\nShare\nImprove this answer\nFollow\nanswered Mar 5 '15 at 13:10\nSerhat Koroglu\n1,1613\n3 gold badges\n17\n17 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"Here's the complete answer using jQuery\n\nI test it and it works 100% :D\n\n    // when the button (select_unit_button) is clicked it returns all the checed checkboxes values \n    $(\"#select_unit_button\").on(\"click\", function(e){\n\n             var arr = [];\n\n             $(':checkbox:checked').each(function(i){\n                 arr[i] = $(this).val(); // u can get id or anything else\n             });\n\n              //console.log(arr); // u can test it using this in google chrome\n    });\n\nShare\nImprove this answer\nFollow\nanswered Feb 27 '13 at 15:49\nuser1477929","comments":[]},{"answer":"In case you use ASP.NET MVC, generate many checkboxes and later have to select/unselect all using JavaScript you can do the following.\n\nHTML\n\n@foreach (var item in Model)\n{\n    @Html.CheckBox(string.Format(\"ProductId_{0}\", @item.Id), @item.IsSelected)\n}\n\n\nJavaScript\n\nfunction SelectAll() {       \n        $('input[id^=\"ProductId_\"]').each(function () {          \n            $(this).prop('checked', true);\n        });\n    }\n\n    function UnselectAll() {\n        $('input[id^=\"ProductId_\"]').each(function () {\n            $(this).prop('checked', false);\n        });\n    }\n\nShare\nImprove this answer\nFollow\nedited Nov 22 '14 at 15:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 8 '14 at 18:22\nDmitryBoyko\n33.4k69\n69 gold badges\n288\n288 silver badges\n461\n461 bronze badges","comments":["Why is the each needed here?"]}]},{"id":"2389361","href":"https://stackoverflow.com/questions/2389361/undo-a-git-merge-that-hasnt-been-pushed-yet","title":"Undo a Git merge that hasn't been pushed yet","description":"\n                \nWithin my master branch, I did a git merge some-other-branch locally, but never pushed the changes to origin master. I didn't mean to merge, so I'd like to undo it. When doing a git status after my merge, I was getting this message:\n\n# On branch master\n# Your branch is ahead of 'origin/master' by 4 commits.\n\n\nBased upon some instructions I found, I tried running\n\ngit revert HEAD -m 1\n\n\nbut now I'm getting this message with git status:\n\n# On branch master\n# Your branch is ahead of 'origin/master' by 5 commits.\n\n\nI don't want my branch to be ahead by any number of commits. How do I get back to that point?\n    ","questionComments":["If you need to preserve the history, in other words there is a change that anyone has ever pulled from you or you have pushed it somewhere use the solution in Yuri Ushakov answer down below!","Please unselect the current winning answer, it's unsafe (as many pointed out) though still gathering votes. To me \"MBO\"-s looks the best, although it has way fewer points.","If you need to preserve history, use Yuri's solution down below! (just adding a link to @Sedrik comment)","Related: Revert to a previous Git commit.","This is a great resource straight from Github: How to undo (almost) anything with Git"],"answers":[{"answer":"With git reflog check which commit is one prior the merge (git reflog will be a better option than git log). Then you can reset it using:\n\ngit reset --hard commit_sha\n\n\nThere's also another way:\n\ngit reset --hard HEAD~1\n\n\nIt will get you back 1 commit.\n\nBe aware that any modified and uncommitted/unstashed files will be reset to their unmodified state. To keep them either stash changes away or see --merge option below.\n\nAs @Velmont suggested below in his answer, in this direct case using:\n\ngit reset --hard ORIG_HEAD\n\n\nmight yield better results, as it should preserve your changes. ORIG_HEAD will point to a commit directly before merge has occurred, so you don't have to hunt for it yourself.\n\nA further tip is to use the --merge switch instead of --hard since it doesn't reset files unnecessarily:\n\ngit reset --merge ORIG_HEAD\n\n\n--merge\n\nResets the index and updates the files in the working tree that are different between <commit> and HEAD, but keeps those which are different between the index and working tree (i.e. which have changes which have not been added).\n\nShare\nImprove this answer\nFollow\nedited Nov 30 '18 at 2:00\nEric Platon\n8,9066\n6 gold badges\n38\n38 silver badges\n45\n45 bronze badges\nanswered Mar 5 '10 at 19:34\nMarcin Gil\n63.4k8\n8 gold badges\n57\n57 silver badges\n60\n60 bronze badges","comments":["I don't think this will (always?) work -- the \"one prior the merge\" will be the most recent commit that was merged in from the other branch -- it won't be the most recent commit on the current branch. Right? (This might just be a result of what git log chooses to show by default -- maybe there is a different output of git log or git reflog could be used for this)","I think it might depend whether you squash merge.","@JohnBachir is right. In the git log output, you want to look at the two parent commits. One is the latest commit in your branch, one is the latest commit in the branch you merged into. You want to git reset --hard to the parent commit on the branch you merged into.","@JohnBachir: As long as the \"merge\" isn't really a fast forward, it will result in a new commit that is at the top of the log, and this commit has two parents (or more than 2 if you do an octopus merge). If you remove this one merge commit, then all of the older commits that came in from the merge will disappear, too. To be safe, though, after a reset git will tell you where the new head is: \"HEAD is now at 88a04de <commit message>\". I always look at that to make sure that I ended up where I expected to be. My project uses a standard branch naming scheme to keep things memorable.","What i found useful was to look at \"git reflog\" and look for the last commit that i did in master. Then do git reset --hard <commit_sha>"]},{"answer":"Assuming your local master was not ahead of origin/master, you should be able to do\n\ngit reset --hard origin/master\n\n\nThen your local master branch should look identical to origin/master.\n\nShare\nImprove this answer\nFollow\nedited Jan 16 '12 at 18:07\nSridhar Ratnakumar\n70.3k61\n61 gold badges\n141\n141 silver badges\n172\n172 bronze badges\nanswered Mar 17 '11 at 18:06\nrandomguy3\n15.8k1\n1 gold badge\n12\n12 silver badges\n2\n2 bronze badges","comments":["@Carter it actually is not the best answer. It is possible that origin/master may be ahead of your local master just previous to the merge by some commits, in that case this might not give the desired results","@dhruva-sagar Yes, but as long as git doesn't say you're behind, and you don't fetch, you should be fine.","Thanks! This is perfect if (and only if) you have a remote repository.","No it's not the perfect one for this question, see the \"assume\" clause. MBO's answer actually covers this case, and the case where the merge is not the only local commit.","Once again, maybe this warning should go into the answer itself: Always avoid rewriting git history!"]},{"answer":"See chapter 4 in the Git book and the original post by Linus Torvalds.\n\nTo undo a merge that was already pushed:\n\ngit revert -m 1 commit_hash\n\n\nBe sure to revert the revert if you're committing the branch again, like Linus said.\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:24\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 2 '11 at 16:31\nYuri Geinish\n15.8k5\n5 gold badges\n31\n31 silver badges\n35\n35 bronze badges","comments":["@perfectionist agreed :) Kind of wish there was a way to migrate this answer to another question-- (maybe there is?)","for more information about revert: link","To be confident that this revert has worked, you can do git diff hash1 hash2 where hash1 is the committed revert, and hash2 is the old commit whose state you were trying to get back to. No output == success! I was able to roll back multiple commits by doing this multiple times, starting by reverting the most recent merge and working backwards. git diff showed me that I ended up in the state I wanted.","Notice that this does not actually solve the original poster's question. The original poster already used git revert -m 1 <commit>. The problem is that doing that doesn't erase the accidental merge that he did (and hasn't pushed yet). The other answers involving hard resets are better for the original poster's problem.","This is a great resource straight from Github: How to undo (almost) anything with Git"]},{"answer":"It is strange that the simplest command was missing. Most answers work, but undoing the merge you just did, this is the easy and safe way:\n\ngit reset --merge ORIG_HEAD\n\n\nThe ref ORIG_HEAD will point to the original commit from before the merge.\n\n(The --merge option has nothing to do with the merge. It's just like git reset --hard ORIG_HEAD, but safer since it doesn't touch uncommitted changes.)\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:33\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 29 '13 at 15:46\nodinho - Velmont\n18.6k6\n6 gold badges\n38\n38 silver badges\n30\n30 bronze badges","comments":["If you've dirtied your working tree since, git reset --merge ORIG_HEAD preserves those changes.","This is the only correct answer (I'm not saying this is the best answer - note the difference). Let's say, on master, I did 3 commits at t1, t3, and t5. Let's say, on branch1, I did 3 comments at t2, t4 and t6 (assume t1, t2, t3, t4, t5 and t6 are in chronological order). Any command similar to git reset --hard HEAD~5 will only reset HEAD (may remove commits in both master and branch1). Only the --merge option removes the merge.","@Manu The --merge option doesn't actually remove the merge, you can use --hard it will also work well. It's the reference ORIG_HEAD that's the clue here, it is set before you do a merge to where you are standing at that point. :)","@yingted what do u mean by \"If you've dirtied your working tree since, git reset --merge ORIG_HEAD preserves those changes.\" Did u mean changing the files after merging ? Anyway i did the merge and then did some of resolving conflicts. But then i wanted to reset the merge and did as instructed in this answer. Everything was ok and it has not preserved my changes done after the merge. My local repo is just similar to the position before I did the merge.","The git reset --hard ORIG_HEAD command worked perfectly for me – it may have been helped by the fact that I didn't make any other changes to the repository after the local git merge I was trying to undo. The command simply reset the state of the repository back to how it was before the merge. Thanks for the great tip!"]},{"answer":"With newer Git versions, if you have not committed the merge yet and you have a merge conflict, you can simply do:\n\ngit merge --abort\n\n\nFrom man git merge:\n\n[This] can only be run after the merge has resulted in conflicts. git merge --abort will abort the merge process and try to reconstruct the pre-merge state.\n\nShare\nImprove this answer\nFollow\nedited Apr 20 '17 at 11:18\nStefan van den Akker\n5,8327\n7 gold badges\n41\n41 silver badges\n58\n58 bronze badges\nanswered Feb 12 '13 at 2:13\nTravis Reeder\n32.1k12\n12 gold badges\n80\n80 silver badges\n80\n80 bronze badges","comments":["His merge is committed but not pushed (see title), he has already merged, your command works only when he is still in the middle of a merge"]},{"answer":"You should reset to the previous commit. This should work:\n\ngit reset --hard HEAD^\n\n\nOr even HEAD^^ to revert that revert commit. You can always give a full SHA reference if you're not sure how many steps back you should take.\n\nIn case when you have problems and your master branch didn't have any local changes, you can reset to origin/master.\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 5 '10 at 19:31\nMBO\n28.2k5\n5 gold badges\n47\n47 silver badges\n52\n52 bronze badges","comments":["The best answer IMHO, incorporates the OP's own one (assuming only 1 step to revert, which seemed to be the case in the Q), as well as randomguy3's shortcut one(which works when \"your master branch didn't had any local changes\")","You commenters, @Inger and @Konstantin, why? You came here after my answer was created, and it is more correct. Just going up the HEAD one step is often wrong, and you'd have to actually count how far up you need to go. Git already sets ORIG_HEAD for you, why not use it?","will it reset local changes as well ? #PleaseUpdate.","This worked perfectly for me, resetting head like that makes much more sense than half the answers here.","HEAD^ equals commit prior to HEAD? and ^^ is two commits prior? Guessing this won't work with fast forward merges?"]},{"answer":"Lately, I've been using git reflog to help with this. This mostly only works if the merge JUST happened, and it was on your machine.\n\ngit reflog might return something like:\n\nfbb0c0f HEAD@{0}: commit (merge): Merge branch 'master' into my-branch\n43b6032 HEAD@{1}: checkout: moving from master to my-branch\ne3753a7 HEAD@{2}: rebase finished: returning to refs/heads/master\ne3753a7 HEAD@{3}: pull --rebase: checkout e3753a71d92b032034dcb299d2df2edc09b5830e\nb41ea52 HEAD@{4}: reset: moving to HEAD^\n8400a0f HEAD@{5}: rebase: aborting\n\n\nThe first line indicates that a merge occurred. The 2nd line is the time before my merge. I simply git reset --hard 43b6032 to force this branch to track from before the merge, and carry-on.\n\nShare\nImprove this answer\nFollow\nanswered Dec 19 '14 at 17:51\nParris\n16.5k15\n15 gold badges\n84\n84 silver badges\n128\n128 bronze badges","comments":["Great answer, thank you! Needed to undo a merge but the other answers just messed it up more, using reflog to get the SHA and pass that into git reset worked.","Thanks a lot :) saved my day."]},{"answer":"With modern Git, you can:\n\ngit merge --abort\n\n\nOlder syntax:\n\ngit reset --merge\n\n\nOld-school:\n\ngit reset --hard\n\n\nBut actually, it is worth noticing that git merge --abort is only equivalent to git reset --merge given that MERGE_HEAD is present. This can be read in the Git help for merge command.\n\ngit merge --abort is equivalent to git reset --merge when MERGE_HEAD is present.\n\n\nAfter a failed merge, when there is no MERGE_HEAD, the failed merge can be undone with git reset --merge, but not necessarily with git merge --abort, so they are not only old and new syntax for the same thing.\n\nPersonally I find git reset --merge much more powerful and useful in everyday work, so that's the one I always use.\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:37\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 8 '15 at 19:13\nMartin G\n14.6k9\n9 gold badges\n72\n72 silver badges\n84\n84 bronze badges","comments":["Worked great for me. Every other post says this is so complicated, but this did exactly what is expected. I suppose it only worked because there were conflicts, which doesn't exactly answer the original question.","This answer doesn't focus on the OP's situation, and leaves out important context."]},{"answer":"Okay, the answers other people here gave me were close, but it didn't work. Here's what I did.\n\nDoing this...\n\ngit reset --hard HEAD^\ngit status\n\n\n...gave me the following status.\n\n# On branch master\n# Your branch and 'origin/master' have diverged,\n# and have 3 and 3 different commit(s) each, respectively.\n\n\nI then had to type in the same git reset command several more times. Each time I did that, the message changed by one as you can see below.\n\n> git reset --hard HEAD^\nHEAD is now at [...truncated...]\n> git status\n# On branch master\n# Your branch and 'origin/master' have diverged,\n# and have 3 and 3 different commit(s) each, respectively.\n> git reset --hard HEAD^\nHEAD is now at [...truncated...]\n> git status\n# On branch master\n# Your branch and 'origin/master' have diverged,\n# and have 2 and 3 different commit(s) each, respectively.\n> git reset --hard HEAD^\nHEAD is now at [...truncated...]\n> git status\n# On branch master\n# Your branch and 'origin/master' have diverged,\n# and have 1 and 3 different commit(s) each, respectively.\n> git reset --hard HEAD^\nHEAD is now at [...truncated...]\n> git status\n# On branch master\n# Your branch is behind 'origin/master' by 3 commits, and can be fast-forwarded.\n\n\nAt this point, I saw the status message changed, so I tried doing a git pull, and that seemed to work:\n\n> git pull\nUpdating 2df6af4..12bbd2f\nFast forward\n app/views/truncated |    9 ++++++---\n app/views/truncated |   13 +++++++++++++\n app/views/truncated |    2 +-\n 3 files changed, 20 insertions(+), 4 deletions(-)\n> git status\n# On branch master\n\n\nSo long story short, my commands came down to this:\n\ngit reset --hard HEAD^\ngit reset --hard HEAD^\ngit reset --hard HEAD^\ngit reset --hard HEAD^\ngit pull\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 5 '10 at 19:54\nMatt Huggins\n74.7k32\n32 gold badges\n140\n140 silver badges\n214\n214 bronze badges","comments":["or you could've used HEAD^^^^","maybe even reset to origin/master ;)"]},{"answer":"If you are in a middle of merging you can always abort it\n\ngit merge --abort\n\nShare\nImprove this answer\nFollow\nedited May 24 at 5:12\nturivishal\n25.3k7\n7 gold badges\n20\n20 silver badges\n47\n47 bronze badges\nanswered Dec 13 '18 at 14:05\nllioor\n4,2742\n2 gold badges\n32\n32 silver badges\n38\n38 bronze badges","comments":["thanks bro and i was about to do that scary stuff correct answer. lucky i scrolled down. i just want to delete merge head"]},{"answer":"You have to change your HEAD, Not yours of course but git HEAD....\n\nSo before answering let's add some background, explaining what is this HEAD.\n\nFirst of all what is HEAD?\n\nHEAD is simply a reference to the current commit (latest) on the current branch.\nThere can only be a single HEAD at any given time. (excluding git worktree)\n\nThe content of HEAD is stored inside .git/HEAD and it contains the 40 bytes SHA-1 of the current commit.\n\ndetached HEAD\n\nIf you are not on the latest commit - meaning that HEAD is pointing to a prior commit in history its called detached HEAD.\n\nOn the command line, it will look like this- SHA-1 instead of the branch name since the HEAD is not pointing to the tip of the current branch\n\nA few options on how to recover from a detached HEAD:\ngit checkout\ngit checkout <commit_id>\ngit checkout -b <new branch> <commit_id>\ngit checkout HEAD~X // x is the number of commits t go back\n\n\nThis will checkout new branch pointing to the desired commit.\nThis command will checkout to a given commit.\nAt this point, you can create a branch and start to work from this point on.\n\n# Checkout a given commit. \n# Doing so will result in a `detached HEAD` which mean that the `HEAD`\n# is not pointing to the latest so you will need to checkout branch\n# in order to be able to update the code.\ngit checkout <commit-id>\n\n# create a new branch forked to the given commit\ngit checkout -b <branch name>\n\ngit reflog\n\nYou can always use the reflog as well.\ngit reflog will display any change which updated the HEAD and checking out the desired reflog entry will set the HEAD back to this commit.\n\nEvery time the HEAD is modified there will be a new entry in the reflog\n\ngit reflog\ngit checkout HEAD@{...}\n\n\nThis will get you back to your desired commit\n\ngit reset --hard <commit_id>\n\n\"Move\" your HEAD back to the desired commit.\n\n# This will destroy any local modifications.\n# Don't do it if you have uncommitted work you want to keep.\ngit reset --hard 0d1d7fc32\n\n# Alternatively, if there's work to keep:\ngit stash\ngit reset --hard 0d1d7fc32\ngit stash pop\n# This saves the modifications, then reapplies that patch after resetting.\n# You could get merge conflicts if you've modified things which were\n# changed since the commit you reset to.\n\nNote: (Since Git 2.7)\nyou can also use the git rebase --no-autostash as well.\ngit revert <sha-1>\n\n\"Undo\" the given commit or commit range.\nThe reset command will \"undo\" any changes made in the given commit.\nA new commit with the undo patch will be committed while the original commit will remain in the history as well.\n\n# add new commit with the undo of the original one.\n# the <sha-1> can be any commit(s) or commit range\ngit revert <sha-1>\n\n\nThis schema illustrates which command does what.\nAs you can see there reset && checkout modify the HEAD.\n\nShare\nImprove this answer\nFollow\nanswered Jul 31 '19 at 15:38\nCodeWizard\n96.8k19\n19 gold badges\n113\n113 silver badges\n139\n139 bronze badges","comments":["This is treasure 🐱‍👤🐱‍👤🐱‍👤"]},{"answer":"You could use git reflog to find the previous checkout. Sometimes that's a good state you want to return back to.\n\nConcretely,\n\n$ git reflog\n$ git reset --hard HEAD@{0}\n\nShare\nImprove this answer\nFollow\nanswered Jan 17 '14 at 22:36\nstephjang\n8491\n1 gold badge\n8\n8 silver badges\n12\n12 bronze badges","comments":["Thank you! You saved half a day of my work. However I could not exit reflog mode with any command.","@Katarzyna use the \"q\" key to exit from reflog"]},{"answer":"It can be done multiple ways.\n\n1) Abort Merge\n\nIf you are in-between a bad merge (mistakenly done with wrong branch), and wanted to avoid the merge to go back to the branch latest as below:\n\ngit merge --abort\n\n\n2) Reset HEAD to remote branch\n\nIf you are working from remote develop branch, you can reset HEAD to the last commit on remote branch as below:\n\ngit reset --hard origin/develop\n\n\n3) Delete current branch, and checkout again from the remote repository\n\nConsidering, you are working on develop branch in local repo, that syncs with remote/develop branch, you can do as below:\n\ngit checkout master \n##to delete one branch, you need to be on another branch, otherwise you will fall with the branch :) \n\ngit branch -D develop\ngit checkout -b develop origin/develop\n\nShare\nImprove this answer\nFollow\nanswered Jul 25 '19 at 15:06\nAmit Kaneria\n4,5382\n2 gold badges\n29\n29 silver badges\n35\n35 bronze badges","comments":["that \"1) Abort Merge\" was pretty enough. Upvoting.","Be careful! git merge --abort \"can only be run after the merge has resulted in conflicts. git merge --abort will abort the merge process and try to reconstruct the pre-merge state\"","git reset --hard origin/develop this was what I was looking for, thank you!"]},{"answer":"I was able to resolve this problem with a single command that doesn't involve looking up a commit id.\n\ngit reset --hard remotes/origin/HEAD\n\n\nThe accepted answer didn't work for me but this command achieved the results I was looking for.\n\nShare\nImprove this answer\nFollow\nanswered Jul 25 '18 at 9:55\nRalph Ritoch\n3,03723\n23 silver badges\n34\n34 bronze badges","comments":["Exactly! It resets your changes to the HEAD of the branch! Not doing one by one","didn't work for me. actually ended up sending local branch back a month or two. Thankfully this is all local so i can always destroy the branch and fetch it again. Just wanted to point that out in case others tried this.","@MattPengelly this method is largely undocumented and usually works if your branch is in sync with the remote branch before you did the merge. Has it been months since your branch was in sync with the remote branch?","@MattPengelly it also depends on what branch the HEAD is pointed to. I'm using gitflow on one of my projects, and even though I'm on the develop branch, the remotes/origin/HEAD is pointed to origin/master so if I needed to undo a merge I would probably need to reset to remotes/origin/develop"]},{"answer":"If you didn't commit it yet, you can only use\n\n$ git checkout -f\n\n\nIt will undo the merge (and everything that you did).\n\nShare\nImprove this answer\nFollow\nanswered Jan 18 '13 at 15:25\nIdealmind\n1,23815\n15 silver badges\n8\n8 bronze badges","comments":["Tried this and it actually increased the number of commits that my local branch is ahead."]},{"answer":"Got to this question also looking to revert to match origin (ie, NO commits ahead of origin). Researching further, found there's a reset command for exactly that:\n\ngit reset --hard @{u}\n\nNote: @{u} is shorthand for origin/master. (And, of course, you need that remote repository for this to work.)\n\nShare\nImprove this answer\nFollow\nanswered Feb 16 '17 at 21:54\nleanne\n6,14138\n38 silver badges\n67\n67 bronze badges","comments":[]},{"answer":"If branches are merged and not pushed, then git reset command given below will work to undo the merge:\n\ngit reset --merge ORIG_HEAD\n\nShare\nImprove this answer\nFollow\nedited May 24 at 5:12\nturivishal\n25.3k7\n7 gold badges\n20\n20 silver badges\n47\n47 bronze badges\nanswered Oct 9 '20 at 5:41\nbunny patel\n2313\n3 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"The simplest answer is the one given by odinho - Velmont\n\nFirst do git reset --merge ORIG_HEAD\n\nFor those looking to reset after changes are pushed, do this (Because this is the first post seen for any git reset merge questions)\n\ngit push origin HEAD --force\n\nThis will reset in a way that you won't get the merged changes back again after pull.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '17 at 23:28\nanswered Nov 2 '17 at 23:22\nHarsha\n71710\n10 silver badges\n22\n22 bronze badges","comments":[]},{"answer":"You can use only two commands to revert a merge or restart by a specific commit:\n\ngit reset --hard commitHash (you should use the commit that you want to restart, eg. 44a587491e32eafa1638aca7738)\ngit push origin HEAD --force (Sending the new local master branch to origin/master)\n\nGood luck and go ahead!\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '14 at 0:27\nanswered Dec 12 '14 at 23:16\nMatheus Abreu\n2,8471\n1 gold badge\n15\n15 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"Just for an extra option to look at, I've been mostly following the branching model described here: http://nvie.com/posts/a-successful-git-branching-model/ and as such have been merging with --no-ff (no fast forward) usually.\n\nI just read this page as I'd accidentally merged a testing branch instead of my release branch with master for deploying (website, master is what is live). The testing branch has two other branches merged to it and totals about six commits.\n\nSo to revert the whole commit I just needed one git reset --hard HEAD^ and it reverted the whole merge. Since the merges weren't fast forwarded the merge was a block and one step back is \"branch not merged\".\n\nShare\nImprove this answer\nFollow\nanswered Jun 9 '11 at 0:54\nDamien Byrne\n1011\n1 silver badge\n2\n2 bronze badges","comments":[]},{"answer":"If your merge and the corresponding commits were not pushed yet, you can always switch to another branch, delete the original one and re-create it.\n\nFor example, I accidentally merged a develop branch into master and wanted to undo that. Using the following steps:\n\ngit checkout develop\ngit branch -D master\ngit branch -t master origin/master\n\n\nVoila! Master is at the same stage as origin, and your mis-merged state is erased.\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 26 '12 at 11:15\nStephan\n1261\n1 silver badge\n1\n1 bronze badge","comments":["Note: This not only undoes the merge but also any local commits that were made since the latest push to origin."]},{"answer":"If you want a command-line solution, I suggest to just go with MBO's answer.\n\nIf you're a newbie, you might like the graphical approach:\n\nKick off gitk (from the command line, or right click in file browser if you have that)\nYou can easily spot the merge commit there - the first node from the top with two parents\nFollow the link to the first/left parent (the one on your current branch before the merge, usually red for me)\nOn the selected commit, right-click \"Reset branch to here\", pick the hard reset there\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 21 '13 at 14:38\ninger\n17.6k9\n9 gold badges\n45\n45 silver badges\n51\n51 bronze badges","comments":[]},{"answer":"Strategy: Create a new branch from where everything was good.\n\nRationale: Reverting a merge is hard. There are too many solutions, depending on many factors such as whether you've committed or pushed your merge or if there were new commits since your merge. Also you still need to have a relatively deep understanding of git to adapt these solutions to your case. If you blindly follow some instructions, you can end up with an \"empty merge\" where nothing will be merged, and further merge attempts will make Git tell you \"Already up to date\".\n\nSolution:\n\nLet's say you want to merge dev into feature-1.\n\nFind the revision that you want to receive the merge:\n\ngit log --oneline feature-1\na1b2c3d4 Merge branch 'dev' into 'feature-1' <-- the merge you want to undo\ne5f6g7h8 Fix NPE in the Zero Point Module <-- the one before the merge, you probably want this one\n\n\nCheck it out (go back in time):\n\ngit checkout e5f6g7h8\n\n\nCreate a new branch from there and check it out:\n\ngit checkout -b feature-1\n\n\nNow you can restart your merge:\n\nMerge: git merge dev\n\nFix your merge conflicts.\n\nCommit: git commit\n\nWhen you're satisfied with the results, delete the old branch: git branch --delete feature-1\n\nShare\nImprove this answer\nFollow\nedited Jan 18 '17 at 18:24\nanswered Jun 11 '15 at 15:42\npyb\n3,5961\n1 gold badge\n22\n22 silver badges\n37\n37 bronze badges","comments":[]},{"answer":"I think you can do git rebase -i [hash] [branch_name] where [hash] is the identifying hash for however far back you want to rewind plus one (or however many commits back you want to go) and then delete the lines for the commits in the editor that you don't want any more. Save the file. Exit. Pray. And it should be rewound. You might have to do a git reset --hard, but it should be good at this point. You can also use this to pull specific commits out of a stack, if you don't want to keep them in your history, but that can leave your repository in a state that you probably don't want.\n\nShare\nImprove this answer\nFollow\nedited Mar 10 '10 at 18:48\nanswered Mar 8 '10 at 2:55\ntychoish\n6414\n4 silver badges\n7\n7 bronze badges","comments":["Just one detail, interactive rebase lets drop commits by deleting lines, but if you remove everything, rebase will be simply aborted. Easiest trick here is removing all lines but one, and label this last one as \"drop\" so everything is discarded."]},{"answer":"Just create new branch, then cherry-pick desired commits to it.\n\nIts saver and simpler then resets described in many answers above\n\nShare\nImprove this answer\nFollow\nanswered Aug 15 '19 at 13:41\ngdbdable\n4,1353\n3 gold badges\n27\n27 silver badges\n42\n42 bronze badges","comments":["I agree with this suggestion, especially if you are not entirely comfortable with the git commands listed. This may be slower with more \"toil\", but if it doesn't come up much and you are concerned with losing your work, it's worth the effort."]},{"answer":"Answering the question \"Undo a Git merge that hasn't been pushed yet\"\n\nYou can use git reset --hard HEAD~1\n\nConsider the following situation where there are 2 branches master and feature-1:\n\n$ git log --graph --oneline --all\n\n\nDo Git merge\n\n$ git merge feature-1\n\n$ git log --graph --oneline --all\n\n\nUndo Git merge\n\n$ git reset --hard HEAD~1\n\n$ git log --graph --oneline --all\n\n\nShare\nImprove this answer\nFollow\nanswered Aug 18 '20 at 7:12\nblessed\n1571\n1 silver badge\n8\n8 bronze badges","comments":[]},{"answer":"If you committed the merge:\n\ngit reset HEAD~1\n# Make sure what you are reverting is in fact the merge files\ngit add .\ngit reset --hard\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:40\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 10 '16 at 15:57\nDorian\n19.3k8\n8 gold badges\n111\n111 silver badges\n111\n111 bronze badges","comments":[]},{"answer":"First, make sure that you've committed everything.\n\nThen reset your repository to the previous working state:\n\n$ git reset f836e4c1fa51524658b9f026eb5efa24afaf3a36\n\n\nor using --hard (this will remove all local, not committed changes!):\n\n$ git reset f836e4c1fa51524658b9f026eb5efa24afaf3a36 --hard\n\n\nUse the hash which was there before your wrongly merged commit.\n\nCheck which commits you'd like to re-commit on the top of the previous correct version by:\n\n$ git log 4c3e23f529b581c3cbe95350e84e66e3cb05704f\n\ncommit 4c3e23f529b581c3cbe95350e84e66e3cb05704f\n\n...\n\ncommit 16b373a96b0a353f7454b141f7aa6f548c979d0a\n\n...\n\n\nApply your right commits on the top of the right version of your repository by:\n\nBy using cherry-pick (the changes introduced by some existing commits)\n\n    git cherry-pick ec59ab844cf504e462f011c8cc7e5667ebb2e9c7\n\n\nOr by cherry-picking the range of commits by:\n\nFirst checking the right changes before merging them:\n\ngit diff 5216b24822ea1c48069f648449997879bb49c070..4c3e23f529b581c3cbe95350e84e66e3cb05704f\n\n\nFirst checking the right changes before merging them:\n\ngit cherry-pick 5216b24822ea1c48069f648449997879bb49c070..4c3e23f529b581c3cbe95350e84e66e3cb05704f\n\n\nwhere this is the range of the correct commits which you've committed (excluding wrongly committed merge).\n\nShare\nImprove this answer\nFollow\nedited Jan 14 '17 at 15:50\nanswered Jan 29 '13 at 15:09\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges","comments":[]},{"answer":"git stash\n\ngit branch -d the_local_branch\n\ngit checkout -t <name of remote>\n\ngit stash apply\n\nThis worked for me..!!\n\nShare\nImprove this answer\nFollow\nanswered Mar 15 '19 at 5:53\nSiva Kumar\n5406\n6 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"If you notice that you need to revert immediately after the merge and you haven't done anything else after the merge attempt, you can just issue this command: git reset --hard HEAD@{1}.\n\nEssentially, your merge sha will be pointing to HEAD@{0} if nothing else was committed after the merge and so HEAD@{1} will be the previous point before the merge.\n\nShare\nImprove this answer\nFollow\nanswered Apr 26 '16 at 18:52\nDaniel Dut\n7637\n7 silver badges\n18\n18 bronze badges","comments":[]}]},{"id":"1026069","href":"https://stackoverflow.com/questions/1026069/how-do-i-make-the-first-letter-of-a-string-uppercase-in-javascript","title":"How do I make the first letter of a string uppercase in JavaScript?","description":"\n                \nHow do I make the first letter of a string uppercase, but not change the case of any of the other letters?\nFor example:\n\n\"this is a test\" → \"This is a test\"\n\"the Eiffel Tower\" → \"The Eiffel Tower\"\n\"/index.html\" → \"/index.html\"\n\n    ","questionComments":["Underscore has a plugin called underscore.string that includes this and a bunch of other great tools.","Simpler: string[0].toUpperCase() + string.substring(1)","`${s[0].toUpperCase()}${s.slice(1)}`","([initial, ...rest]) => [initial.toUpperCase(), ...rest].join(\"\")","Capitalize every word: str.replace(/(^\\w|\\s\\w)/g, m => m.toUpperCase())"],"answers":[{"answer":"The basic solution is:\n\nfunction capitalizeFirstLetter(string) {\n  return string.charAt(0).toUpperCase() + string.slice(1);\n}\n\nconsole.log(capitalizeFirstLetter('foo')); // Foo\n Run code snippetExpand snippet\n\nSome other answers modify String.prototype (this answer used to as well), but I would advise against this now due to maintainability (hard to find out where the function is being added to the prototype and could cause conflicts if other code uses the same name / a browser adds a native function with that same name in future).\n\n...and then, there is so much more to this question when you consider internationalisation, as this astonishingly good answer (buried below) shows.\n\nIf you want to work with Unicode code points instead of code units (for example to handle Unicode characters outside of the Basic Multilingual Plane) you can leverage the fact that String#[@iterator] works with code points, and you can use toLocaleUpperCase to get locale-correct uppercasing:\n\nconst capitalizeFirstLetter = ([ first, ...rest ], locale = navigator.language) =>\n  first.toLocaleUpperCase(locale) + rest.join('')\n\nconsole.log(\n  capitalizeFirstLetter('foo'), // Foo\n  capitalizeFirstLetter(\"𐐶𐐲𐑌𐐼𐐲𐑉\"), // \"𐐎𐐲𐑌𐐼𐐲𐑉\" (correct!)\n  capitalizeFirstLetter(\"italya\", 'tr') // İtalya\" (correct in Turkish Latin!)\n)\n Run code snippetExpand snippet\n\nFor even more internationalization options, please see the original answer below.\n\nShare\nImprove this answer\nFollow\nedited Dec 19 '20 at 9:40\nvsync\n91.5k47\n47 gold badges\n255\n255 silver badges\n331\n331 bronze badges\nanswered Jun 22 '09 at 8:30\nSteve Harrison\n105k15\n15 gold badges\n83\n83 silver badges\n71\n71 bronze badges","comments":[]},{"answer":"Here's a more object-oriented approach:\n\nString.prototype.capitalize = function() {\n    return this.charAt(0).toUpperCase() + this.slice(1);\n}\n\n\nYou'd call the function, like this:\n\n\"hello, world!\".capitalize();\n\n\nWith the expected output being:\n\n\"Hello, world!\"\n\nShare\nImprove this answer\nFollow\nedited May 29 at 0:57\ndthree\n17.5k9\n9 gold badges\n67\n67 silver badges\n102\n102 bronze badges\nanswered Jul 20 '10 at 15:51\nSteve Hansell\n16k1\n1 gold badge\n14\n14 silver badges\n13\n13 bronze badges","comments":["Polluting prototypes is not a good idea.","@aggregate1166877 can you explain why? almost 1500 upvotes for this answer. So without an explanation, people will just ignore you. Like me, cause I am gonna do this.","@NielsLucas Fair enough. It has the potential to break future additions to JS. If it's code that only you will use, then it's not so bad - you just update your code and move on. The real issue here is when you start publishing libraries with code like this: your code modifies the built-in behavior for every library using your code. The consequence is that if you and another library author both override the same built-ins with your own implementations, you create bugs in the other library's code (or whichever is loaded last) leaving the user with debugging hell of unreproducible bug reports.","@aggregate1166877 Thank you for the explanation. I totally agree with you that this way is NOT gonna be a good practice for creating a library and I also agree that this way is fine for a project. Hope people will read this, cause I think this is a good attention to the original answer."]},{"answer":"In CSS:\n\np:first-letter {\n    text-transform:capitalize;\n}\n\nShare\nImprove this answer\nFollow\nedited Aug 12 '16 at 22:36\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 17 '12 at 14:06\nsam6ber\n7,7051\n1 gold badge\n11\n11 silver badges\n3\n3 bronze badges","comments":["$('#mystring_id').text(string).css('text-transform','capitalize');","Additionally, this only affects the display of the string - not the actual value. If it's in a form, e.g., the value will still be submitted as-is."]},{"answer":"Here is a shortened version of the popular answer that gets the first letter by treating the string as an array:\n\nfunction capitalize(s)\n{\n    return s[0].toUpperCase() + s.slice(1);\n}\n\nUpdate\n\nAccording to the comments below this doesn't work in IE 7 or below.\n\nUpdate 2:\n\nTo avoid undefined for empty strings (see @njzk2's comment below), you can check for an empty string:\n\nfunction capitalize(s)\n{\n    return s && s[0].toUpperCase() + s.slice(1);\n}\n\nES version\nconst capitalize = s => s && s[0].toUpperCase() + s.slice(1)\n\n// to always return type string event when s may be falsy other than empty-string\nconst capitalize = s => (s && s[0].toUpperCase() + s.slice(1)) || \"\"\n\nShare\nImprove this answer\nFollow\nedited May 30 at 7:40\nAakash\n14.8k5\n5 gold badges\n79\n79 silver badges\n67\n67 bronze badges\nanswered Aug 28 '11 at 23:03\njoelvh\n15.1k4\n4 gold badges\n26\n26 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"If you're interested in the performance of a few different methods posted:\n\nHere are the fastest methods based on this jsperf test (ordered from fastest to slowest).\n\nAs you can see, the first two methods are essentially comparable in terms of performance, whereas altering the String.prototype is by far the slowest in terms of performance.\n\n// 10,889,187 operations/sec\nfunction capitalizeFirstLetter(string) {\n    return string[0].toUpperCase() + string.slice(1);\n}\n\n// 10,875,535 operations/sec\nfunction capitalizeFirstLetter(string) {\n    return string.charAt(0).toUpperCase() + string.slice(1);\n}\n\n// 4,632,536 operations/sec\nfunction capitalizeFirstLetter(string) {\n    return string.replace(/^./, string[0].toUpperCase());\n}\n\n// 1,977,828 operations/sec\nString.prototype.capitalizeFirstLetter = function() {\n    return this.charAt(0).toUpperCase() + this.slice(1);\n}\n\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Nov 14 '15 at 3:26\nJosh Crozier\n206k50\n50 gold badges\n348\n348 silver badges\n278\n278 bronze badges","comments":[]},{"answer":"For another case I need it to capitalize the first letter and lowercase the rest. The following cases made me change this function:\n\n//es5\nfunction capitalize(string) {\n    return string.charAt(0).toUpperCase() + string.slice(1).toLowerCase();\n}\ncapitalize(\"alfredo\")  // => \"Alfredo\"\ncapitalize(\"Alejandro\")// => \"Alejandro\ncapitalize(\"ALBERTO\")  // => \"Alberto\"\ncapitalize(\"ArMaNdO\")  // => \"Armando\"\n\n// es6 using destructuring \nconst capitalize = ([first,...rest]) => first.toUpperCase() + rest.join('').toLowerCase();\n\nShare\nImprove this answer\nFollow\nedited Jun 5 '18 at 21:49\nanswered Jul 19 '13 at 18:17\nalejandro\n2,6281\n1 gold badge\n15\n15 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"I didn’t see any mention in the existing answers of issues related to astral plane code points or internationalization. “Uppercase” doesn’t mean the same thing in every language using a given script.\n\nInitially I didn’t see any answers addressing issues related to astral plane code points. There is one, but it’s a bit buried (like this one will be, I guess!)\n\nMost of the proposed functions look like this:\n\nfunction capitalizeFirstLetter(str) {\n  return str[0].toUpperCase() + str.slice(1);\n}\n\n\nHowever, some cased characters fall outside the BMP (basic multilingual plane, code points U+0 to U+FFFF). For example take this Deseret text:\n\ncapitalizeFirstLetter(\"𐐶𐐲𐑌𐐼𐐲𐑉\"); // \"𐐶𐐲𐑌𐐼𐐲𐑉\"\n\n\nThe first character here fails to capitalize because the array-indexed properties of strings don’t access “characters” or code points*. They access UTF-16 code units. This is true also when slicing — the index values point at code units.\n\nIt happens to be that UTF-16 code units are 1:1 with USV code points within two ranges, U+0 to U+D7FF and U+E000 to U+FFFF inclusive. Most cased characters fall into those two ranges, but not all of them.\n\nFrom ES2015 on, dealing with this became a bit easier. String.prototype[@@iterator] yields strings corresponding to code points**. So for example, we can do this:\n\nfunction capitalizeFirstLetter([ first, ...rest ]) {\n  return [ first.toUpperCase(), ...rest ].join('');\n}\n\ncapitalizeFirstLetter(\"𐐶𐐲𐑌𐐼𐐲𐑉\") // \"𐐎𐐲𐑌𐐼𐐲𐑉\"\n\n\nFor longer strings, this is probably not terribly efficient*** — we don’t really need to iterate the remainder. We could use String.prototype.codePointAt to get at that first (possible) letter, but we’d still need to determine where the slice should begin. One way to avoid iterating the remainder would be to test whether the first codepoint is outside the BMP; if it isn’t, the slice begins at 1, and if it is, the slice begins at 2.\n\nfunction capitalizeFirstLetter(str) {\n  const firstCP = str.codePointAt(0);\n  const index = firstCP > 0xFFFF ? 2 : 1;\n\n  return String.fromCodePoint(firstCP).toUpperCase() + str.slice(index);\n}\n\ncapitalizeFirstLetter(\"𐐶𐐲𐑌𐐼𐐲𐑉\") // \"𐐎𐐲𐑌𐐼𐐲𐑉\"\n\n\nYou could use bitwise math instead of > 0xFFFF there, but it’s probably easier to understand this way and either would achieve the same thing.\n\nWe can also make this work in ES5 and below by taking that logic a bit further if necessary. There are no intrinsic methods in ES5 for working with codepoints, so we have to manually test whether the first code unit is a surrogate****:\n\nfunction capitalizeFirstLetter(str) {\n  var firstCodeUnit = str[0];\n\n  if (firstCodeUnit < '\\uD800' || firstCodeUnit > '\\uDFFF') {\n    return str[0].toUpperCase() + str.slice(1);\n  }\n\n  return str.slice(0, 2).toUpperCase() + str.slice(2);\n}\n\ncapitalizeFirstLetter(\"𐐶𐐲𐑌𐐼𐐲𐑉\") // \"𐐎𐐲𐑌𐐼𐐲𐑉\"\n\n\nAt the start I also mentioned internationalization considerations. Some of these are very difficult to account for because they require knowledge not only of what language is being used, but also may require specific knowledge of the words in the language. For example, the Irish digraph \"mb\" capitalizes as \"mB\" at the start of a word. Another example, the German eszett, never begins a word (afaik), but still helps illustrate the problem. The lowercase eszett (“ß”) capitalizes to “SS,” but “SS” could lowercase to either “ß” or “ss” — you require out-of-band knowledge of the German language to know which is correct!\n\nThe most famous example of these kinds of issues, probably, is Turkish. In Turkish Latin, the capital form of i is İ, while the lowercase form of I is ı — they’re two different letters. Fortunately we do have a way to account for this:\n\nfunction capitalizeFirstLetter([ first, ...rest ], locale) {\n  return [ first.toLocaleUpperCase(locale), ...rest ].join('');\n}\n\ncapitalizeFirstLetter(\"italy\", \"en\") // \"Italy\"\ncapitalizeFirstLetter(\"italya\", \"tr\") // \"İtalya\"\n\n\nIn a browser, the user’s most-preferred language tag is indicated by navigator.language, a list in order of preference is found at navigator.languages, and a given DOM element’s language can be obtained (usually) with Object(element.closest('[lang]')).lang || YOUR_DEFAULT_HERE in multilanguage documents.\n\nIn agents which support Unicode property character classes in RegExp, which were introduced in ES2018, we can clean stuff up further by directly expressing what characters we’re interested in:\n\nfunction capitalizeFirstLetter(str, locale=navigator.language) {\n  return str.replace(/^\\p{CWU}/u, char => char.toLocaleUpperCase(locale));\n}\n\n\nThis could be tweaked a bit to also handle capitalizing multiple words in a string with fairly good accuracy. The CWU or Changes_When_Uppercased character property matches all code points which, well, change when uppercased. We can try this out with a titlecased digraph characters like the Dutch ĳ for example:\n\ncapitalizeFirstLetter('ĳsselmeer'); // \"Ĳsselmeer\"\n\n\nAs of January 2021, all major engines have implemented the Unicode property character class feature, but depending on your target support range you may not be able to use it safely yet. The last browser to introduce support was Firefox (78; June 30, 2020). You can check for support of this feature with the Kangax compat table. Babel can be used to compile RegExp literals with property references to equivalent patterns without them, but be aware that the resulting code can sometimes be enormous. You probably would not want to do this unless you’re certain the tradeoff is justified for your use case.\n\nIn all likelihood, people asking this question will not be concerned with Deseret capitalization or internationalization. But it’s good to be aware of these issues because there’s a good chance you’ll encounter them eventually even if they aren’t concerns presently. They’re not “edge” cases, or rather, they’re not by-definition edge cases — there’s a whole country where most people speak Turkish, anyway, and conflating code units with codepoints is a fairly common source of bugs (especially with regard to emoji). Both strings and language are pretty complicated!\n\n* The code units of UTF-16 / UCS2 are also Unicode code points in the sense that e.g. U+D800 is technically a code point, but that’s not what it “means” here ... sort of ... though it gets pretty fuzzy. What the surrogates definitely are not, though, is USVs (Unicode scalar values).\n\n** Though if a surrogate code unit is “orphaned” — i.e., not part of a logical pair — you could still get surrogates here, too.\n\n*** maybe. I haven’t tested it. Unless you have determined capitalization is a meaningful bottleneck, I probably wouldn’t sweat it — choose whatever you believe is most clear and readable.\n\n**** such a function might wish to test both the first and second code units instead of just the first, since it’s possible that the first unit is an orphaned surrogate. For example the input \"\\uD800x\" would capitalize the X as-is, which may or may not be expected.\n\nShare\nImprove this answer\nFollow\nedited Jan 5 at 19:16\nanswered Dec 26 '18 at 10:33\nSemicolon\n5,0231\n1 gold badge\n24\n24 silver badges\n35\n35 bronze badges","comments":["I had been wondering for a while why toUpperCase didn't really do much for some languages... but didn't quite care enough to find out. Glad I finally did, this was a very interesting read!"]},{"answer":"This is the 2018 ECMAScript 6+ Solution:\n\nconst str = 'the Eiffel Tower';\nconst newStr = `${str[0].toUpperCase()}${str.slice(1)}`;\nconsole.log('Original String:', str); // the Eiffel Tower\nconsole.log('New String:', newStr); // The Eiffel Tower\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 13 '19 at 23:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 19 '18 at 15:32\nSterling Bourne\n2,45921\n21 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"If you're already (or considering) using Lodash, the solution is easy:\n\n_.upperFirst('fred');\n// => 'Fred'\n\n_.upperFirst('FRED');\n// => 'FRED'\n\n_.capitalize('fred') //=> 'Fred'\n\n\nSee their documentation: https://lodash.com/docs#capitalize\n\n_.camelCase('Foo Bar'); //=> 'fooBar'\n\nhttps://lodash.com/docs/4.15.0#camelCase\n\n_.lowerFirst('Fred');\n// => 'fred'\n\n_.lowerFirst('FRED');\n// => 'fRED'\n\n_.snakeCase('Foo Bar');\n// => 'foo_bar'\n\n\nVanilla JavaScript for first upper case:\n\nfunction upperCaseFirst(str){\n    return str.charAt(0).toUpperCase() + str.substring(1);\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 6 at 23:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 29 '15 at 8:13\nchovy\n60.8k44\n44 gold badges\n188\n188 silver badges\n238\n238 bronze badges","comments":["I think the preference should be for vanilla Js as most people will not download an entire framework only to capitalize a string.","In all my projects so far I've never used lodash. Don't forget either that most people on google will end on this page, and listing a framework as an alternative is fine, but not as a main answer.","@GGG In all my projects so far I've used lodash","Vanilla js is better than lodash. Nobody uses it anymore."]},{"answer":"Capitalize the first letter of all words in a string:\n\nfunction ucFirstAllWords( str )\n{\n    var pieces = str.split(\" \");\n    for ( var i = 0; i < pieces.length; i++ )\n    {\n        var j = pieces[i].charAt(0).toUpperCase();\n        pieces[i] = j + pieces[i].substr(1);\n    }\n    return pieces.join(\" \");\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '16 at 6:09\nGAMITG\n3,6707\n7 gold badges\n30\n30 silver badges\n50\n50 bronze badges\nanswered Nov 30 '11 at 17:16\nDan\n7575\n5 silver badges\n2\n2 bronze badges","comments":["Re-read question: I want to capitalize the first character of a string, but not change the case of any of the other letters.","I know I did. I'd add one thing, in case the entire string starts capitalized: pieces[i] = j + pieces[i].substr(1).toLowerCase();","Another solution to this case: function capitaliseFirstLetters(s) { return s.split(\" \").map(function(w) { return w.charAt(0).toUpperCase() + w.substr(1) }).join(\" \") } Can be a nice one-liner if it's not put into a function.","Would be better to first lowercase the whole string","Other than this function not answering the question, it's actually also overcomplicated. s => s.split(' ').map(x => x[0].toUpperCase() + x.slice(1)).join(' ')"]},{"answer":"CSS only\n\nIf the transformation is needed only for displaying on a web page:\n\np::first-letter {\n  text-transform: uppercase;\n}\n\nDespite being called \"::first-letter\", it applies to the first character, i.e. in case of string %a, this selector would apply to % and as such a would not be capitalized.\nIn IE9+ or IE5.5+ it's supported in legacy notation with only one colon (:first-letter).\nES2015 one-liner\nconst capitalizeFirstChar = str => str.charAt(0).toUpperCase() + str.substring(1);\n\nRemarks\nIn the benchmark I performed, there was no significant difference between string.charAt(0) and string[0]. Note however, that string[0] would be undefined for an empty string, so the function would have to be rewritten to use \"string && string[0]\", which is way too verbose, compared to the alternative.\nstring.substring(1) is faster than string.slice(1).\nBenchmark between substring() and slice()\n\nThe difference is rather minuscule nowadays (run the test yourself):\n\n21,580,613.15 ops/s ±1.6% for substring(),\n21,096,394.34 ops/s ±1.8% (2.24% slower) for slice().\n\nShare\nImprove this answer\nFollow\nedited Feb 21 at 17:39\nanswered Apr 5 '17 at 17:21\nPrzemek\n3,3931\n1 gold badge\n22\n22 silver badges\n33\n33 bronze badges","comments":["You actually don't want to use the plus sign (+) as a concatenation method in ES6. You'll want to use template literals: eslint.org/docs/rules/prefer-template"]},{"answer":"String.prototype.capitalize = function(allWords) {\n   return (allWords) ? // If all words\n      this.split(' ').map(word => word.capitalize()).join(' ') : // Break down the phrase to words and then recursive\n                                                                 // calls until capitalizing all words\n      this.charAt(0).toUpperCase() + this.slice(1); // If allWords is undefined, capitalize only the first word,\n                                                    // meaning the first character of the whole string\n}\n\n\nAnd then:\n\n \"capitalize just the first word\".capitalize(); ==> \"Capitalize just the first word\"\n \"capitalize all words\".capitalize(true); ==> \"Capitalize All Words\"\n\nUpdate November 2016 (ES6), just for fun:\nconst capitalize = (string = '') => [...string].map(    // Convert to array with each item is a char of\n                                                        // string by using spread operator (...)\n    (char, index) => index ? char : char.toUpperCase()  // Index true means not equal 0, so (!index) is\n                                                        // the first character which is capitalized by\n                                                        // the `toUpperCase()` method\n ).join('')                                             // Return back to string\n\n\nthen capitalize(\"hello\") // Hello\n\nShare\nImprove this answer\nFollow\nedited Jan 6 at 23:43\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 29 '13 at 20:01\nAbdennour TOUMI\n67.7k29\n29 gold badges\n206\n206 silver badges\n212\n212 bronze badges","comments":["I think this is a poor solution for 2 reasons: Modifying the prototype of a primitive is a bad idea. If the spec changes and they decide to pick 'capitalize' as a new proto property name, you're breaking core language functionality. Also, The method name chosen is poor. At first glance, I would think this will capitalize the entire string. Using a more descriptive name such as PHP's ucFirst or something similar might be a better idea.","The other ES6 answer is simpler: const capitalize = ([first,...rest]) => first.toUpperCase() + rest.join('').toLowerCase();.","@dudewad in css, capitalizing of first letter of a word is call 'capitalize', and if you want to capitalize all characters u use 'uppercase', hence it's not really bad choice."]},{"answer":"There is a very simple way to implement it by replace. For ECMAScript 6:\n\n'foo'.replace(/^./, str => str.toUpperCase())\n\n\nResult:\n\n'Foo'\n\nShare\nImprove this answer\nFollow\nedited Jun 13 '19 at 23:02\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 8 '18 at 8:31\nLittle Roys\n4,2253\n3 gold badges\n23\n23 silver badges\n26\n26 bronze badges","comments":["Best answer by far, and extra points for showing the regex lambda syntax. I especially like this one as it can be a fluent cut-and-paste anywhere.","Using /^[a-z]/i will be better than using . as the prior one will not try to replace any character other than alphabets","Very clever indeed!"]},{"answer":"We could get the first character with one of my favorite RegExp, looks like a cute smiley: /^./\n\nString.prototype.capitalize = function () {\n  return this.replace(/^./, function (match) {\n    return match.toUpperCase();\n  });\n};\n\n\nAnd for all coffee-junkies:\n\nString::capitalize = ->\n  @replace /^./, (match) ->\n    match.toUpperCase()\n\n\n...and for all guys who think that there's a better way of doing this, without extending native prototypes:\n\nvar capitalize = function (input) {\n  return input.replace(/^./, function (match) {\n    return match.toUpperCase();\n  });\n};\n\nShare\nImprove this answer\nFollow\nedited Jun 12 '15 at 23:11\nanswered Feb 15 '13 at 6:55\nyckart\n28.7k7\n7 gold badges\n112\n112 silver badges\n122\n122 bronze badges","comments":["There is a better way of doing this without modifying the String prototype.","@davidkennedy85 Sure! But this is the simple way, not the best way... ;-)","Dear lordy there's a million answers to this question! Your solution looks even nicer in es6. 'Answer'.replace(/^./, v => v.toLowerCase())","What are you referring to by \"coffee\"? \"CoffeeScript\"?"]},{"answer":"SHORTEST 3 solutions, 1 and 2 handle cases when s string is \"\", null and undefined:\n\n s&&s[0].toUpperCase()+s.slice(1)        // 32 char\n\n s&&s.replace(/./,s[0].toUpperCase())    // 36 char - using regexp\n\n'foo'.replace(/./,x=>x.toUpperCase())    // 31 char - direct on string, ES6\n\n\nShow code snippet\n\nShare\nImprove this answer\nFollow\nedited Jun 17 '19 at 11:45\nanswered Sep 19 '18 at 6:21\nKamil Kiełczewski\n57.6k22\n22 gold badges\n275\n275 silver badges\n253\n253 bronze badges","comments":[]},{"answer":"Use:\n\nvar str = \"ruby java\";\n\nconsole.log(str.charAt(0).toUpperCase() + str.substring(1));\n Run code snippetExpand snippet\n\nIt will output \"Ruby java\" to the console.\n\nShare\nImprove this answer\nFollow\nedited Jun 13 '19 at 23:11\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 25 '14 at 16:13\nAMIC MING\n6,1506\n6 gold badges\n44\n44 silver badges\n61\n61 bronze badges","comments":["One line solution."]},{"answer":"Here is a function called ucfirst()(short for \"upper case first letter\"):\n\nfunction ucfirst(str) {\n    var firstLetter = str.substr(0, 1);\n    return firstLetter.toUpperCase() + str.substr(1);\n}\n\n\nYou can capitalise a string by calling ucfirst(\"some string\") -- for example,\n\nucfirst(\"this is a test\") --> \"This is a test\"\n\n\nIt works by splitting the string into two pieces. On the first line it pulls out firstLetter and then on the second line it capitalises firstLetter by calling firstLetter.toUpperCase() and joins it with the rest of the string, which is found by calling str.substr(1).\n\nYou might think this would fail for an empty string, and indeed in a language like C you would have to cater for this. However in JavaScript, when you take a substring of an empty string, you just get an empty string back.\n\nShare\nImprove this answer\nFollow\nedited Mar 9 at 16:51\nWebDevLearner\n3683\n3 silver badges\n14\n14 bronze badges\nanswered Jun 22 '09 at 8:33\nRobert Wills\n43.4k3\n3 gold badges\n16\n16 silver badges\n6\n6 bronze badges","comments":["Use String.substring() or String.slice() ... Don't use substr() - it's deprecated.","@999: where does it say that substr() is deprecated? It's not, even now, three years later, let alone back in 2009 when you made this comment.","substr() may not be marked as deprecated by any popular ECMAScript implementation (I doubt it's not going to disappear anytime soon), but it's not part of the ECMAScript spec. The 3rd edition of the spec mentions it in the non-normative annex in order to \"suggests uniform semantics for such properties without making the properties or their semantics part of this standard\".","Having 3 methods that do the same thing (substring, substr and slice) is too many, IMO. I always use slice because it supports negative indexes, it doesn't have the confusing arg-swapping behavior and its API is similar to slice in other languages."]},{"answer":"If you use Underscore.js or Lodash, the underscore.string library provides string extensions, including capitalize:\n\n_.capitalize(string) Converts first letter of the string to uppercase.\n\nExample:\n\n_.capitalize(\"foo bar\") == \"Foo bar\"\n\nShare\nImprove this answer\nFollow\nedited Jan 6 at 23:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 12 '14 at 8:00\nandersh\n7,0395\n5 gold badges\n36\n36 silver badges\n28\n28 bronze badges","comments":["Since, version 3.0.0, Lo-Dash has this string method available by default. Just like described in this answer: _.capitalize(\"foo\") === \"Foo\".","Also there are usefull underscore.js function called humanize. It converts an underscored, camelized, or dasherized string into a humanized one. Also removes beginning and ending whitespace, and removes the postfix '_id'.","From version 4*, Lodash also lowercase() every other letter, be careful!"]},{"answer":"It's always better to handle these kinds of stuff using CSS first, in general, if you can solve something using CSS, go for that first, then try JavaScript to solve your problems, so in this case try using :first-letter in CSS and apply text-transform:capitalize;\n\nSo try creating a class for that, so you can use it globally, for example: .first-letter-uppercase and add something like below in your CSS:\n\n.first-letter-uppercase:first-letter {\n    text-transform:capitalize;\n}\n\n\nAlso the alternative option is JavaScript, so the best gonna be something like this:\n\nfunction capitalizeTxt(txt) {\n  return txt.charAt(0).toUpperCase() + txt.slice(1); //or if you want lowercase the rest txt.slice(1).toLowerCase();\n}\n\n\nand call it like:\n\ncapitalizeTxt('this is a test'); // return 'This is a test'\ncapitalizeTxt('the Eiffel Tower'); // return 'The Eiffel Tower'\ncapitalizeTxt('/index.html');  // return '/index.html'\ncapitalizeTxt('alireza');  // return 'Alireza'\ncapitalizeTxt('dezfoolian');  // return 'Dezfoolian'\n\n\nIf you want to reuse it over and over, it's better attach it to javascript native String, so something like below:\n\nString.prototype.capitalizeTxt = String.prototype.capitalizeTxt || function() {\n    return this.charAt(0).toUpperCase() + this.slice(1);\n}\n\n\nand call it as below:\n\n'this is a test'.capitalizeTxt(); // return 'This is a test'\n'the Eiffel Tower'.capitalizeTxt(); // return 'The Eiffel Tower'\n'/index.html'.capitalizeTxt();  // return '/index.html'\n'alireza'.capitalizeTxt();  // return 'Alireza'\n\nShare\nImprove this answer\nFollow\nedited Aug 15 at 3:45\nanswered May 14 '17 at 8:12\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"var capitalized = yourstring[0].toUpperCase() + yourstring.substr(1);\n\nShare\nImprove this answer\nFollow\nanswered Aug 25 '16 at 12:29\nzianwar\n3,0322\n2 gold badges\n26\n26 silver badges\n37\n37 bronze badges","comments":[]},{"answer":"It seems to be easier in CSS:\n\n<style type=\"text/css\">\n    p.capitalize {text-transform:capitalize;}\n</style>\n<p class=\"capitalize\">This is some text.</p>\n\n\nThis is from CSS text-transform Property (at W3Schools).\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '16 at 6:09\nGAMITG\n3,6707\n7 gold badges\n30\n30 silver badges\n50\n50 bronze badges\nanswered Dec 9 '11 at 0:27\nRyan\n1,0477\n7 silver badges\n2\n2 bronze badges","comments":["@Simon It's not stated that the string is necessarily going to be output as part of a HTML document - CSS is only going to be of use if it is.","Adam, true, but I'd guess that over 95% of the Javascript out there is used with HTML & CSS. Unfortunately, the \"capitalize\" statement actually capitalizes every word, so you'd still need JS to capitalize only the first letter of the string.","Incorrect, Dinesh. He said the first character of the string.","This answer, despite having a ridiculous number of upvotes, is just wrong, as it will capitalize the first letter of every word. @Ryan, you'll earn a Disciplined badge if you delete it. Please do so.","It's now javascript: $('.capitalize').css('text-transform', 'capitalize')"]},{"answer":"If you are wanting to reformat all-caps text, you might want to modify the other examples as such:\n\nfunction capitalize (text) {\n    return text.charAt(0).toUpperCase() + text.slice(1).toLowerCase();\n}\n\n\nThis will ensure that the following text is changed:\n\nTEST => Test\nThis Is A TeST => This is a test\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '16 at 6:09\nGAMITG\n3,6707\n7 gold badges\n30\n30 silver badges\n50\n50 bronze badges\nanswered Aug 8 '11 at 16:55\nmonokrome\n1,32513\n13 silver badges\n20\n20 bronze badges","comments":["Probably worth noting that this will also convert things like acronyms to lowercase, so maybe not the best idea in most cases","Also,did GAMITG really make an edit just to remove a piece of whitespace from a non-code portion of the post? O_O","btw, this will break uppercasing acronyms so be careful y'all <3"]},{"answer":"function capitalize(s) {\n    // returns the first letter capitalized + the string from index 1 and out aka. the rest of the string\n    return s[0].toUpperCase() + s.substr(1);\n}\n\n\n// examples\ncapitalize('this is a test');\n=> 'This is a test'\n\ncapitalize('the Eiffel Tower');\n=> 'The Eiffel Tower'\n\ncapitalize('/index.html');\n=> '/index.html'\n\nShare\nImprove this answer\nFollow\nedited Jul 14 '15 at 19:41\nanswered Jul 13 '15 at 20:34\nFredrik A.\n8507\n7 silver badges\n20\n20 bronze badges","comments":["Done @Ram. Also included examples.","How is this any better than the 2009 answer?.","It isn't @DanDascalescu. I suppose you could argue that substr/substring is a bit more semantic as opposed to slice, but that's just a matter of preference. I did however include examples with the strings provided in the question, which is a nice touch not present in the '09 example. I honestly think it boils down to 15 year old me wanting karma on StackOverflow ;)"]},{"answer":"String.prototype.capitalize = function(){\n    return this.replace(/(^|\\s)([a-z])/g, \n                        function(m, p1, p2) {\n                            return p1 + p2.toUpperCase();\n                        });\n};\n\n\nUsage:\n\ncapitalizedString = someString.capitalize();\n\n\nThis is a text string => This Is A Text String\n\nShare\nImprove this answer\nFollow\nedited Jan 6 at 23:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 15 '10 at 10:15\nMurat Kucukosman\n6175\n5 silver badges\n9\n9 bronze badges","comments":["+1, this is what I was really looking for. There is a minor bug though, it ought to be return.this.toLocaleLowerCase().replace( ...","+1, I found this page looking for a javascript version of phps ucfirst, which I suspect is how most people find it.","@DanDascalescu I found this useful, so +1 utilitarianism, and -1 anal-retentiveness. He included an example, so its function is clear.","String.prototype.capitalize = function(){ return this.replace( /(^|\\s)[a-z]/g , function(m){  return m.toUpperCase();  }); }; I refactor your code a bit, you need only a first match.","Firstly, it does something else than OP asked for, secondly regex is an inefficient overkill in this case, lastly don't modify prototypes of something you don't own"]},{"answer":"var str = \"test string\";\nstr = str.substring(0,1).toUpperCase() + str.substring(1);\n\nShare\nImprove this answer\nFollow\nedited Jun 5 '14 at 4:26\nanswered May 6 '14 at 5:15\nMaxEcho\n13.5k6\n6 gold badges\n73\n73 silver badges\n85\n85 bronze badges","comments":[]},{"answer":"yourString.replace(/\\w/, c => c.toUpperCase())\n\n\nI found this arrow function easiest. Replace matches the first letter character (\\w) of your string and converts it to uppercase. Nothing fancier is necessary.\n\nShare\nImprove this answer\nFollow\nedited Jan 6 at 23:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 14 '18 at 19:40\nWolf\n4717\n7 silver badges\n9\n9 bronze badges","comments":["This should be the accepted answer, instead it's almost the last since SO keeps awarding outdated questions. Btw, it's better using /./ for two reason: /\\w/ will skip all the previous not letter characters (so @@abc will become @@Abc), and then it doesn't work with not-latin characters"]},{"answer":"Only because this is really a one-liner I will include this answer. It's an ES6-based interpolated string one-liner.\n\nlet setStringName = 'the Eiffel Tower';\nsetStringName = `${setStringName[0].toUpperCase()}${setStringName.substring(1)}`;\n\nShare\nImprove this answer\nFollow\nedited Jan 6 at 22:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 7 '20 at 6:10\nChristian Matthew\n3,1453\n3 gold badges\n26\n26 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"Check out this solution:\n\nvar stringVal = 'master';\nstringVal.replace(/^./, stringVal[0].toUpperCase()); // Returns Master\n\nShare\nImprove this answer\nFollow\nedited Jan 6 at 23:24\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 23 '15 at 12:51\nRaju Bera\n9227\n7 silver badges\n14\n14 bronze badges","comments":["Save some keystrokes ;) stringVal.replace(/^./, stringVal[0].toUpperCase());","Regex shouldn't be used where not necessary. It's greatly inefficient and it doesn't make code any more concise either. Moreover, stringVal[0] would be undefined for empty stringVal, and as such attempt to access property .toUpperCase() would throw an error."]},{"answer":"yourString.replace(/^[a-z]/, function(m){ return m.toUpperCase() });\n\n\n(You may encapsulate it in a function or even add it to the String prototype if you use it frequently.)\n\nShare\nImprove this answer\nFollow\nedited Aug 12 '16 at 22:38\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 19 '12 at 18:33\nSimon\n1,8161\n1 gold badge\n16\n16 silver badges\n29\n29 bronze badges","comments":["Even though this has quite some votes, this is by far the slowest solution posted here. I've put together a little speedtest with the most popular answers from this post, here: forwebonly.com/…","Regexp is overkill for this, prefer the simpler : str.charAt(0).toUpperCase() + str.slice(1)","Often times, if you want to solve your problem with regex, you end up with two problems."]},{"answer":"You can do it in one line like this\n\nstring[0].toUpperCase() + string.substring(1)\n\nShare\nImprove this answer\nFollow\nanswered Jan 22 '18 at 18:27\nQwerty\n1,1441\n1 gold badge\n8\n8 silver badges\n21\n21 bronze badges","comments":["This answer was already given in 2009."]}]},{"id":"2669690","href":"https://stackoverflow.com/questions/2669690/why-does-google-prepend-while1-to-their-json-responses","title":"Why does Google prepend while(1); to their JSON responses?","description":"\n                \nWhy does Google prepend while(1); to their (private) JSON responses?\n\nFor example, here's a response while turning a calendar on and off in Google Calendar:\n\nwhile (1);\n[\n  ['u', [\n    ['smsSentFlag', 'false'],\n    ['hideInvitations', 'false'],\n    ['remindOnRespondedEventsOnly', 'true'],\n    ['hideInvitations_remindOnRespondedEventsOnly', 'false_true'],\n    ['Calendar ID stripped for privacy', 'false'],\n    ['smsVerifiedFlag', 'true']\n  ]]\n]\n\n\nI would assume this is to prevent people from doing an eval() on it, but all you'd really have to do is replace the while and then you'd be set. I would assume the eval prevention is to make sure people write safe JSON parsing code.\n\nI've seen this used in a couple of other places, too, but a lot more so with Google (Mail, Calendar, Contacts, etc.) Strangely enough, Google Docs starts with &&&START&&& instead, and Google Contacts seems to start with while(1); &&&START&&&.\n\nWhat's going on here?\n    ","questionComments":["I believe that your first impression is correct. If you start looking for code and try to trim the input stream depending on the source, you'd reconsider and do it the safe (and because of Google's actions, easier) way.","probably a follow-up question: Why does google prepend )]}' now instead of while(1);? Would the answers be the same?","Would prevent eval, but not with an infinite loop.","This )]}' may also be to save bytes, like facebook used for(;;); which saves one byte :)"],"answers":[{"answer":"It prevents JSON hijacking, a major JSON security issue that is formally fixed in all major browsers since 2011 with ECMAScript 5.\n\nContrived example: say Google has a URL like mail.google.com/json?action=inbox which returns the first 50 messages of your inbox in JSON format. Evil websites on other domains can't make AJAX requests to get this data due to the same-origin policy, but they can include the URL via a <script> tag. The URL is visited with your cookies, and by overriding the global array constructor or accessor methods they can have a method called whenever an object (array or hash) attribute is set, allowing them to read the JSON content.\n\nThe while(1); or &&&BLAH&&& prevents this: an AJAX request at mail.google.com will have full access to the text content, and can strip it away. But a <script> tag insertion blindly executes the JavaScript without any processing, resulting in either an infinite loop or a syntax error.\n\nThis does not address the issue of cross-site request forgery.\n\nShare\nImprove this answer\nFollow\nedited Mar 10 '19 at 18:30\nPaulMest\n7,7214\n4 gold badges\n41\n41 silver badges\n43\n43 bronze badges\nanswered Apr 19 '10 at 18:11\nrjh\n46.6k3\n3 gold badges\n47\n47 silver badges\n61\n61 bronze badges","comments":["Why doesn't the request to obtain this data require a CSRF-token instead?","Wouldn't returning an object containing the array, instead of the array directly, also solve the problem?","@PedroFelix No, that wouldn't solve the problem since the same attacks mentioned in the post could still be performed. Overriding the accessor methods to retrieve the info.","@JakubP. Storing and maintaining CSRF-tokens at Google's scale requires a large amount of infrastructure and cost.","@JakubP. anti-CSRF tokens mess with caching, and require some amount of cryptographic evaluation server-side. At Google scale, that would require a lot of CPU. This sort of offloads it to the client."]},{"answer":"It prevents disclosure of the response through JSON hijacking.\n\nIn theory, the content of HTTP responses are protected by the Same Origin Policy: pages from one domain cannot get any pieces of information from pages on the other domain (unless explicitly allowed).\n\nAn attacker can request pages on other domains on your behalf, e.g. by using a <script src=...> or <img> tag, but it can't get any information about the result (headers, contents).\n\nThus, if you visit an attacker's page, it couldn't read your email from gmail.com.\n\nExcept that when using a script tag to request JSON content, the JSON is executed as JavaScript in an attacker's controlled environment. If the attacker can replace the Array or Object constructor or some other method used during object construction, anything in the JSON would pass through the attacker's code, and be disclosed.\n\nNote that this happens at the time the JSON is executed as JavaScript, not at the time it's parsed.\n\nThere are multiple countermeasures:\n\nMaking sure the JSON never executes\n\nBy placing a while(1); statement before the JSON data, Google makes sure that the JSON data is never executed as JavaScript.\n\nOnly a legitimate page could actually get the whole content, strip the while(1);, and parse the remainder as JSON.\n\nThings like for(;;); have been seen at Facebook for instance, with the same results.\n\nMaking sure the JSON is not valid JavaScript\n\nSimilarly, adding invalid tokens before the JSON, like &&&START&&&, makes sure that it is never executed.\n\nAlways return JSON with an Object on the outside\n\nThis is OWASP recommended way to protect from JSON hijacking and is the less intrusive one.\n\nSimilarly to the previous counter-measures, it makes sure that the JSON is never executed as JavaScript.\n\nA valid JSON object, when not enclosed by anything, is not valid in JavaScript:\n\neval('{\"foo\":\"bar\"}')\n// SyntaxError: Unexpected token :\n\n\nThis is however valid JSON:\n\nJSON.parse('{\"foo\":\"bar\"}')\n// Object {foo: \"bar\"}\n\n\nSo, making sure you always return an Object at the top level of the response makes sure that the JSON is not valid JavaScript, while still being valid JSON.\n\nAs noted by @hvd in the comments, the empty object {} is valid JavaScript, and knowing the object is empty may itself be valuable information.\n\nComparison of above methods\n\nThe OWASP way is less intrusive, as it needs no client library changes, and transfers valid JSON. It is unsure whether past or future browser bugs could defeat this, however. As noted by @oriadam, it is unclear whether data could be leaked in a parse error through an error handling or not (e.g. window.onerror).\n\nGoogle's way requires a client library in order for it to support automatic de-serialization and can be considered to be safer with regard to browser bugs.\n\nBoth methods require server side changes in order to avoid developers accidentally sending vulnerable JSON.\n\nShare\nImprove this answer\nFollow\nedited Oct 19 '20 at 2:14\nRy-♦\n202k52\n52 gold badges\n409\n409 silver badges\n421\n421 bronze badges\nanswered Feb 2 '14 at 12:09\nArnaud Le Blanc\n92.1k22\n22 gold badges\n193\n193 silver badges\n189\n189 bronze badges","comments":["OWASP recommendation is interesting because of its simplicity. Anyone know a reason Google's way is more secure?","I believe it isn't more secure in any way. Providing OWASP here seems a good enough reason for +1.","I supposed if you must use JSONP you could try to use CSRF tokens in some clever (probably insecure) way."]},{"answer":"This is to ensure some other site can't do nasty tricks to try to steal your data. For example, by replacing the array constructor, then including this JSON URL via a <script> tag, a malicious third-party site could steal the data from the JSON response. By putting a while(1); at the start, the script will hang instead.\n\nA same-site request using XHR and a separate JSON parser, on the other hand, can easily ignore the while(1); prefix.\n\nShare\nImprove this answer\nFollow\nedited Jan 31 '14 at 23:43\nhippietrail\n13.9k15\n15 gold badges\n89\n89 silver badges\n135\n135 bronze badges\nanswered May 16 '09 at 2:08\nbdonlan\n207k28\n28 gold badges\n245\n245 silver badges\n317\n317 bronze badges","comments":[]},{"answer":"That would be to make it difficult for a third-party to insert the JSON response into an HTML document with the <script> tag. Remember that the <script> tag is exempt from the Same Origin Policy.\n\nShare\nImprove this answer\nFollow\nedited Dec 30 '13 at 3:10\nGeorge Stocker\n55.4k29\n29 gold badges\n169\n169 silver badges\n231\n231 bronze badges\nanswered Apr 19 '10 at 18:04\nDaniel Vassallo\n316k70\n70 gold badges\n489\n489 silver badges\n433\n433 bronze badges","comments":[]},{"answer":"Note: as of 2019, many of the old vulnerabilities that lead to the preventative measures discussed in this question are no longer an issue in modern browsers. I'll leave the answer below as a historical curiosity, but really the whole topic has changed radically since 2010 (!!) when this was asked.\n\nIt prevents it from being used as the target of a simple <script> tag. (Well, it doesn't prevent it, but it makes it unpleasant.) That way bad guys can't just put that script tag in their own site and rely on an active session to make it possible to fetch your content.\n\nedit — note the comment (and other answers). The issue has to do with subverted built-in facilities, specifically the Object and Array constructors. Those can be altered such that otherwise innocuous JSON, when parsed, could trigger attacker code.\n\nShare\nImprove this answer\nFollow\nedited Mar 18 '19 at 2:52\nanswered Apr 19 '10 at 18:02\nPointy\n376k55\n55 gold badges\n542\n542 silver badges\n589\n589 bronze badges","comments":[]},{"answer":"Since the <script> tag is exempted from the Same Origin Policy which is a security necessity in the web world, while(1) when added to the JSON response prevents misuse of it in the <script> tag.\n\nShare\nImprove this answer\nFollow\nedited Aug 28 '18 at 9:45\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered Aug 18 '17 at 4:14\nKrishna Ganeriwal\n1,61515\n15 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"As this is a High traffic post I hope to provide here an answer slightly more undetermined to the original question and thus to provide further background on a JSON Hijacking attack and its consequences\n\nJSON Hijacking as the name suggests is an attack similar to Cross-Site Request Forgery where an attacker can access cross-domain sensitive JSON data from applications that return sensitive data as array literals to GET requests. An example of a JSON call returning an array literal is shown below:\n\n[{\"id\":\"1001\",\"ccnum\":\"4111111111111111\",\"balance\":\"2345.15\"}, \n{\"id\":\"1002\",\"ccnum\":\"5555555555554444\",\"balance\":\"10345.00\"}, \n{\"id\":\"1003\",\"ccnum\":\"5105105105105100\",\"balance\":\"6250.50\"}]\n\n\nThis attack can be achieved in 3 major steps:\n\nStep 1: Get an authenticated user to visit a malicious page. Step 2: The malicious page will try and access sensitive data from the application that the user is logged into.This can be done by embedding a script tag in an HTML page since the same-origin policy does not apply to script tags.\n\n<script src=\"http://<jsonsite>/json_server.php\"></script>\n\n\nThe browser will make a GET request to json_server.php and any authentication cookies of the user will be sent along with the request. Step 3: At this point while the malicious site has executed the script it does not have access to any sensitive data. Getting access to the data can be achieved by using an object prototype setter. In the code below an object prototypes property is being bound to the defined function when an attempt is being made to set the \"ccnum\" property.\n\nObject.prototype.__defineSetter__('ccnum',function(obj){\n    secrets =secrets.concat(\" \", obj);\n});\n\n\nAt this point the malicious site has successfully hijacked the sensitive financial data (ccnum) returned byjson_server.php JSON\n\nIt should be noted that not all browsers support this method; the proof of concept was done on Firefox 3.x.This method has now been deprecated and replaced by the useObject.defineProperty There is also a variation of this attack that should work on all browsers where full named JavaScript (e.g. pi=3.14159) is returned instead of a JSON array.\n\nThere are several ways in which JSON Hijacking can be prevented:\n\nSince SCRIPT tags can only generate HTTP GET requests, only return JSON objects to POST requests.\n\nPrevent the web browser from interpreting the JSON object as valid JavaScript code.\n\nImplement Cross-Site Request Forgery protection by requiring that a predefined random value be required for all JSON requests.\n\nso as you can see While(1) comes under the last option. In the most simple terms, while(1) is an infinite loop that will run till a break statement is issued explicitly. And thus what would be described as a lock for the key to be applied (google break statement). Therefore a JSON hijacking, in which the Hacker has no key will be consistently dismissed.Alas, If you read the JSON block with a parser, the while(1) loop is ignored.\n\nSo in conclusion, the while(1) loop can more easily be visualized as a simple break statement cipher that google can use to control the flow of data.\n\nHowever the keyword in that statement is the word 'simple'. The usage of authenticated infinite loops has been thankfully removed from basic practice in the years since 2010 due to its absolute decimation of CPU usage when isolated (and the fact the internet has moved away from forcing through crude 'quick-fixes'). Today instead the codebase has preventative measures embedded and the system is not crucial nor effective anymore. (part of this is the move away from JSON Hijacking to more fruitful data farming techniques that I wont go into at present)\n\nShare\nImprove this answer\nFollow\nedited May 4 at 15:51\nnp_6\n5126\n6 silver badges\n17\n17 bronze badges\nanswered Dec 24 '20 at 11:43\nMontresorXPL\n3541\n1 silver badge\n15\n15 bronze badges","comments":[]},{"answer":"After authentication is in place, JSON hijacking protection can take a variety of forms. Google appends while(1) into their JSON data, so that if any malicious script evaluates it, the malicious script enters an infinite loop.\n\nReference: Web Security Testing Cookbook: Systematic Techniques to Find Problems Fast\n\nShare\nImprove this answer\nFollow\nanswered Mar 2 '20 at 1:24\nJSON C11\n9,0906\n6 gold badges\n69\n69 silver badges\n62\n62 bronze badges","comments":[]}]},{"id":"522563","href":"https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops","title":"Accessing the index in 'for' loops?","description":"\n                \nHow do I access the index in a for loop like the following?\n\nints = [8, 23, 45, 12, 78]\nfor i in ints:\n    print('item #{} = {}'.format(???, i))\n\n\nI want to get this output:\n\nitem #1 = 8\nitem #2 = 23\nitem #3 = 45\nitem #4 = 12\nitem #5 = 78\n\n\nWhen I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?\n    ","questionComments":["Note that indexes in python start from 0, so the indexes for your example list are 0 to 4 not 1 to 5","@JoanVenge this is a great question I've had MANY TIMES. And the comment above is saying it's zero-indexed-based (so, we humans count 1 to 3 as 1,2,3, but computers count as 0,1,2 (so, a size of 3 e.g is [0,1,2] (0 counts as 1)) And, this questions answers below are also, Brilliant. Thanks for this!"],"answers":[{"answer":"Using an additional state variable, such as an index variable (which you would normally use in languages such as C or PHP), is considered non-pythonic.\n\nThe better option is to use the built-in function enumerate(), available in both Python 2 and 3:\n\nfor idx, val in enumerate(ints):\n    print(idx, val)\n\n\nCheck out PEP 279 for more.\n\nShare\nImprove this answer\nFollow\nedited Sep 17 '16 at 10:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 6 '09 at 22:52\nMike Hordecki\n76.7k3\n3 gold badges\n23\n23 silver badges\n26\n26 bronze badges","comments":["As Aaron points out below, use start=1 if you want to get 1-5 instead of 0-4.","Does enumerate not incur another overhead?","@TheRealChx101 according to my tests (Python 3.6.3) the difference is negligible and sometimes even in favour of enumerate.","@TheRealChx101: It's lower than the overhead of looping over a range and indexing each time, and lower than manually tracking and updating the index separately. enumerate with unpacking is heavily optimized (if the tuples are unpacked to names as in the provided example, it reuses the same tuple each loop to avoid even the cost of freelist lookup, it has an optimized code path for when the index fits in ssize_t that performs cheap in-register math, bypassing Python level math operations, and it avoids indexing the list at the Python level, which is more expensive than you'd think).","@MikeHordecki This is just a ## Brilliant Answer! Thanks for this! Question is 12+years old and this answer is working flawlessly."]},{"answer":"Using a for loop, how do I access the loop index, from 1 to 5 in this case?\n\nUse enumerate to get the index with the element as you iterate:\n\nfor index, item in enumerate(items):\n    print(index, item)\n\n\nAnd note that Python's indexes start at zero, so you would get 0 to 4 with the above. If you want the count, 1 to 5, do this:\n\ncount = 0 # in case items is empty and you need it after the loop\nfor count, item in enumerate(items, start=1):\n    print(count, item)\n\nUnidiomatic control flow\n\nWhat you are asking for is the Pythonic equivalent of the following, which is the algorithm most programmers of lower-level languages would use:\n\nindex = 0            # Python's indexing starts at zero\nfor item in items:   # Python's for loops are a \"for each\" loop \n    print(index, item)\n    index += 1\n\n\nOr in languages that do not have a for-each loop:\n\nindex = 0\nwhile index < len(items):\n    print(index, items[index])\n    index += 1\n\n\nor sometimes more commonly (but unidiomatically) found in Python:\n\nfor index in range(len(items)):\n    print(index, items[index])\n\nUse the Enumerate Function\n\nPython's enumerate function reduces the visual clutter by hiding the accounting for the indexes, and encapsulating the iterable into another iterable (an enumerate object) that yields a two-item tuple of the index and the item that the original iterable would provide. That looks like this:\n\nfor index, item in enumerate(items, start=0):   # default is zero\n    print(index, item)\n\n\nThis code sample is fairly well the canonical example of the difference between code that is idiomatic of Python and code that is not. Idiomatic code is sophisticated (but not complicated) Python, written in the way that it was intended to be used. Idiomatic code is expected by the designers of the language, which means that usually this code is not just more readable, but also more efficient.\n\nGetting a count\n\nEven if you don't need indexes as you go, but you need a count of the iterations (sometimes desirable) you can start with 1 and the final number will be your count.\n\ncount = 0 # in case items is empty\nfor count, item in enumerate(items, start=1):   # default is zero\n    print(item)\n\nprint('there were {0} items printed'.format(count))\n\n\nThe count seems to be more what you intend to ask for (as opposed to index) when you said you wanted from 1 to 5.\n\nBreaking it down - a step by step explanation\n\nTo break these examples down, say we have a list of items that we want to iterate over with an index:\n\nitems = ['a', 'b', 'c', 'd', 'e']\n\n\nNow we pass this iterable to enumerate, creating an enumerate object:\n\nenumerate_object = enumerate(items) # the enumerate object\n\n\nWe can pull the first item out of this iterable that we would get in a loop with the next function:\n\niteration = next(enumerate_object) # first iteration from enumerate\nprint(iteration)\n\n\nAnd we see we get a tuple of 0, the first index, and 'a', the first item:\n\n(0, 'a')\n\n\nwe can use what is referred to as \"sequence unpacking\" to extract the elements from this two-tuple:\n\nindex, item = iteration\n#   0,  'a' = (0, 'a') # essentially this.\n\n\nand when we inspect index, we find it refers to the first index, 0, and item refers to the first item, 'a'.\n\n>>> print(index)\n0\n>>> print(item)\na\n\nConclusion\nPython indexes start at zero\nTo get these indexes from an iterable as you iterate over it, use the enumerate function\nUsing enumerate in the idiomatic way (along with tuple unpacking) creates code that is more readable and maintainable:\n\nSo do this:\n\nfor index, item in enumerate(items, start=0):   # Python indexes start at zero\n    print(index, item)\n\nShare\nImprove this answer\nFollow\nedited yesterday\nanswered Jan 21 '15 at 17:11\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":["Does the \"Getting a count\" example work when items is empty?","I am sending data using ajax to Django views as an array in the form of two values in a variable legData with values as [1406, 1409]. If I print to the console using print(legData), the output is [1406,1409]. However, if I try to parse the individual values of the list like for idx, xLeg in enumerate(legData): print(idx, xLeg), it gets me an output of individual integers such as [, 1, 4, 0, 6, and so on against the indices 0, 1, 2, 3, 4 etc. (yes, the square brackets & comma are also being output as if they were part of the data itself). What is going wrong here?","@user12379095 you probably have the data in the wrong type (a string) and you need to convert it to an actual list of numbers instead of a string. That is somewhat off topic here, please delete your comment and flag mine to be deleted as no longer needed when you see this.","@Bergi: It won't, but you can just add count = 0 before the loop to ensure it has a value (and it's the correct one when the loop never assigns to count, since by definition there were no items)."]},{"answer":"It's pretty simple to start it from 1 other than 0:\n\nfor index, item in enumerate(iterable, start=1):\n   print index, item  # Used to print in python<3.x\n   print(index, item) # Mirate print() after 3.x+\n   \n\nShare\nImprove this answer\nFollow\nedited Feb 5 at 12:29\nmhhabib\n2,4781\n1 gold badge\n9\n9 silver badges\n20\n20 bronze badges\nanswered May 27 '14 at 10:04\nA.J.\n6,91210\n10 gold badges\n56\n56 silver badges\n75\n75 bronze badges","comments":["The question was about list indexes; since they start from 0 there is little point in starting from other number since the indexes would be wrong (yes, the OP said it wrong in the question as well). Otherwise, calling the variable that is tuple of index, item just index is very misleading, as you noted. Just use for index, item in enumerate(ints).","Better is to enclose index inside parenthesis pairs as (index), it will work on both the Python versions 2 and 3.","@AnttiHaapala The reason, I presume, is that the question's expected output starts at index 1 instead 0","@hygull: Turning index into (index) won't change a thing on either Py2 or Py3. I feel like maybe you're thinking of the change to print; the only way to make that work on both Py2 and Py3 is to add from __future__ import print_function to the top of your file to get consistent Py3-style print, and change the print to print(index, item). Or you read an earlier edit of the question when index was the original tuple, not unpacked to two names, but the parentheses still don't change anything if you fail to unpack."]},{"answer":"for i in range(len(ints)):\n   print(i, ints[i]) # print updated to print() in Python 3.x+ \n\nShare\nImprove this answer\nFollow\nedited Apr 22 at 10:04\nmhhabib\n2,4781\n1 gold badge\n9\n9 silver badges\n20\n20 bronze badges\nanswered Feb 6 '09 at 22:49\nDavid Hanak\n10k3\n3 gold badges\n29\n29 silver badges\n38\n38 bronze badges","comments":["That should probably be xrange for pre-3.0.","Use enumerate instead","For Python 2.3 above, use enumerate built-in function since it is more Pythonic.","Enumerate is not always better - it depends on the requirements of the application. In my current situation the relationships between the object lengths is meaningful to my application. Although I started out using enumerate, I switched to this approach to avoid having to write logic to select which object to enumerate.","@adg I don't see how avoid enumerate saves any logic; you still have to select which object to index with i, no?"]},{"answer":"As is the norm in Python there are several ways to do this. In all examples assume: lst = [1, 2, 3, 4, 5]\n\n1. Using enumerate (considered most idiomatic)\nfor index, element in enumerate(lst):\n    # do the things that need doing here\n\n\nThis is also the safest option in my opinion because the chance of going into infinite recursion has been eliminated. Both the item and its index are held in variables and there is no need to write any further code to access the item.\n\n2. Creating a variable to hold the index (using for)\nfor index in range(len(lst)):   # or xrange\n    # you will have to write extra code to get the element\n\n3. Creating a variable to hold the index (using while)\nindex = 0\nwhile index < len(lst):\n    # you will have to write extra code to get the element\n    index += 1  # escape infinite recursion\n\n4. There is always another way\n\nAs explained before, there are other ways to do this that have not been explained here and they may even apply more in other situations. e.g using itertools.chain with for. It handles nested loops better than the other examples.\n\nShare\nImprove this answer\nFollow\nedited Feb 10 '18 at 20:05\njamylak\n114k27\n27 gold badges\n219\n219 silver badges\n223\n223 bronze badges\nanswered Aug 15 '17 at 2:17\nCharitoo\n1,32412\n12 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"Old fashioned way:\n\nfor ix in range(len(ints)):\n    print(ints[ix])\n\n\nList comprehension:\n\n[ (ix, ints[ix]) for ix in range(len(ints))]\n\n>>> ints\n[1, 2, 3, 4, 5]\n>>> for ix in range(len(ints)): print ints[ix]\n... \n1\n2\n3\n4\n5\n>>> [ (ix, ints[ix]) for ix in range(len(ints))]\n[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n>>> lc = [ (ix, ints[ix]) for ix in range(len(ints))]\n>>> for tup in lc:\n...     print(tup)\n... \n(0, 1)\n(1, 2)\n(2, 3)\n(3, 4)\n(4, 5)\n>>> \n\nShare\nImprove this answer\nFollow\nedited Apr 22 at 10:06\nmhhabib\n2,4781\n1 gold badge\n9\n9 silver badges\n20\n20 bronze badges\nanswered Feb 6 '09 at 22:52\nCharlie Martin\n104k22\n22 gold badges\n181\n181 silver badges\n253\n253 bronze badges","comments":["This is not wrong and is used in C/C++ and others. It's considered as non-pythonic, but can also be used in python. Like simple solutions that break it down to the source :+","Some python extremists would say, don't do this. But I said it only to indicate that there is more than one possible way","niiice, something c users can understand","\"Old-fashioned\" doesn't actually mean \"wrong\"","@CharlieMartin THIS was a GENIUS Answer! Thanks SO MUCH for posting this; It helped A LOT ! [+10/10]"]},{"answer":"Accessing indexes & Performance Benchmarking of approaches\n\nThe fastest way to access indexes of list within loop in Python 3.7 is to use the enumerate method for small, medium and huge lists.\n\nPlease see different approaches which can be used to iterate over list and access index value and their performance metrics (which I suppose would be useful for you) in code samples below:\n\n# Using range\ndef range_loop(iterable):\n    for i in range(len(iterable)):\n        1 + iterable[i]\n\n# Using enumerate\ndef enumerate_loop(iterable):\n    for i, val in enumerate(iterable):\n        1 + val\n\n# Manual indexing\ndef manual_indexing_loop(iterable):\n    index = 0\n    for item in iterable:\n        1 + item\n        index += 1\n\n\nSee performance metrics for each method below:\n\nfrom timeit import timeit\n\ndef measure(l, number=10000):\n    print(\"Measure speed for list with %d items\" % len(l))\n    print(\"range: \", timeit(lambda :range_loop(l), number=number))\n    print(\"enumerate: \", timeit(lambda :enumerate_loop(l), number=number))\n    print(\"manual_indexing: \", timeit(lambda :manual_indexing_loop(l), number=number))\n\n# Measure speed for list with 1000 items\nmeasure(range(1000))\n# range:  1.161622366\n# enumerate:  0.5661940879999996\n# manual_indexing:  0.610455682\n\n# Measure speed for list with 100000 items\nmeasure(range(10000))\n# range:  11.794482958\n# enumerate:  6.197628574000001\n# manual_indexing:  6.935181098000001\n\n# Measure speed for list with 10000000 items\nmeasure(range(10000000), number=100)\n# range:  121.416859069\n# enumerate:  62.718909123\n# manual_indexing:  69.59575057400002\n\n\nAs the result, using enumerate method is the fastest method for iteration when the index needed.\n\nAdding some useful links below:\n\nWhat is the difference between range and xrange functions in Python 2.X?\n\nWhat is faster for loop using enumerate or for loop using xrange in Python?\n\nrange(len(list)) or enumerate(list)?\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Aug 4 '16 at 9:49\nAndriy Ivaneyko\n16.4k4\n4 gold badges\n46\n46 silver badges\n66\n66 bronze badges","comments":["\"readability counts\" The speed difference in the small <1000 range is insignificant. It is 3% slower on an already small time metric.","How about updating the answer to Python 3?","@Georgy makes sense, on python 3.7 enumerate is total winner :)"]},{"answer":"Here's what you get when you're accessing index in for loops:\n\nfor i in enumerate(items): print(i)\n\nitems = [8, 23, 45, 12, 78]\n\nfor i in enumerate(items):\n    print(\"index/value\", i)\n\n\nResult:\n\n# index/value (0, 8)\n# index/value (1, 23)\n# index/value (2, 45)\n# index/value (3, 12)\n# index/value (4, 78)\n\n\nfor i, val in enumerate(items): print(i, val)\n\nitems = [8, 23, 45, 12, 78]\n\nfor i, val in enumerate(items):\n    print(\"index\", i, \"for value\", val)\n\n\nResult:\n\n# index 0 for value 8\n# index 1 for value 23\n# index 2 for value 45\n# index 3 for value 12\n# index 4 for value 78\n\n\nfor i, val in enumerate(items): print(i)\n\nitems = [8, 23, 45, 12, 78]\n\nfor i, val in enumerate(items):\n    print(\"index\", i)\n\n\nResult:\n\n# index 0\n# index 1\n# index 2\n# index 3\n# index 4\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jan 17 '19 at 1:07\nAndy Fedoroff\n29.2k10\n10 gold badges\n94\n94 silver badges\n146\n146 bronze badges","comments":[]},{"answer":"First of all, the indexes will be from 0 to 4. Programming languages start counting from 0; don't forget that or you will come across an index out of bounds exception. All you need in the for loop is a variable counting from 0 to 4 like so:\n\nfor x in range(0, 5):\n\n\nKeep in mind that I wrote 0 to 5 because the loop stops one number before the max. :)\n\nTo get the value of an index use\n\nlist[index]\n\nShare\nImprove this answer\nFollow\nedited May 25 '15 at 23:05\nThorsten S.\n3,79425\n25 silver badges\n41\n41 bronze badges\nanswered May 25 '15 at 15:08\nytpillai\n3,2321\n1 gold badge\n25\n25 silver badges\n43\n43 bronze badges","comments":[]},{"answer":"According to this discussion: http://bytes.com/topic/python/answers/464012-objects-list-index\n\nLoop counter iteration\n\nThe current idiom for looping over the indices makes use of the built-in range function:\n\nfor i in range(len(sequence)):\n    # work with index i\n\n\nLooping over both elements and indices can be achieved either by the old idiom or by using the new zip built-in function:\n\nfor i in range(len(sequence)):\n    e = sequence[i]\n    # work with index i and element e\n\n\nor\n\nfor i, e in zip(range(len(sequence)), sequence):\n    # work with index i and element e\n\n\nvia http://www.python.org/dev/peps/pep-0212/\n\nShare\nImprove this answer\nFollow\nedited May 22 '19 at 14:29\nGeorgy\n6,8417\n7 gold badges\n49\n49 silver badges\n59\n59 bronze badges\nanswered May 5 '12 at 7:10\nthinker007\n4474\n4 silver badges\n6\n6 bronze badges","comments":["This won't work for iterating through generators. Just use enumerate().","Nowadays, the current idiom is enumerate, not the range call.","and it's the same as the older answer: stackoverflow.com/a/522576/6451573"]},{"answer":"You can do it with this code:\n\nints = [8, 23, 45, 12, 78]\nindex = 0\n\nfor value in (ints):\n    index +=1\n    print index, value\n\n\nUse this code if you need to reset the index value at the end of the loop:\n\nints = [8, 23, 45, 12, 78]\nindex = 0\n\nfor value in (ints):\n    index +=1\n    print index, value\n    if index >= len(ints)-1:\n        index = 0\n\nShare\nImprove this answer\nFollow\nedited May 26 '15 at 10:39\nanswered May 25 '15 at 15:26\nLiam\n4,6103\n3 gold badges\n29\n29 silver badges\n47\n47 bronze badges","comments":[]},{"answer":"If I were to iterate nums = [1, 2, 3, 4, 5] I would do\n\nfor i, num in enumerate(nums, start=1):\n    print(i, num)\n\n\nOr get the length as l = len(nums)\n\nfor i in range(l):\n    print(i+1, nums[i])\n\nShare\nImprove this answer\nFollow\nedited May 26 '20 at 1:51\nso2\n17212\n12 bronze badges\nanswered Jun 4 '18 at 2:10\nAnkur Kothari\n5356\n6 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"The best solution for this problem is to use the enumerate builtin function.\n\nenumerate returns a tuple, where the first value is the index and the second value is the element of the list at that index.\n\nIn [1]: ints = [8, 23, 45, 12, 78]\n\nIn [2]: for idx, val in enumerate(ints):\n   ...:         print(idx, val)\n   ...:     \n(0, 8)\n(1, 23)\n(2, 45)\n(3, 12)\n(4, 78)\n\nShare\nImprove this answer\nFollow\nedited Mar 1 at 3:37\nSuperStormer\n3,6824\n4 gold badges\n16\n16 silver badges\n29\n29 bronze badges\nanswered Aug 24 '17 at 6:15\nAnurag Misra\n1,24615\n15 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"In your question, you write \"how do I access the loop index, from 1 to 5 in this case?\"\n\nHowever, the index for a list runs from zero. So, then we need to know if what you actually want is the index and item for each item in a list, or whether you really want numbers starting from 1. Fortunately, in Python, it is easy to do either or both.\n\nFirst, to clarify, the enumerate function iteratively returns the index and corresponding item for each item in a list.\n\nalist = [1, 2, 3, 4, 5]\n\nfor n, a in enumerate(alist):\n    print(\"%d %d\" % (n, a))\n\n\nThe output for the above is then,\n\n0 1\n1 2\n2 3\n3 4\n4 5\n\n\nNotice that the index runs from 0. This kind of indexing is common among modern programming languages including Python and C.\n\nIf you want your loop to span a part of the list, you can use the standard Python syntax for a part of the list. For example, to loop from the second item in a list up to but not including the last item, you could use\n\nfor n, a in enumerate(alist[1:-1]):\n    print(\"%d %d\" % (n, a))\n\n\nNote that once again, the output index runs from 0,\n\n0 2\n1 3\n2 4\n\n\nThat brings us to the start=n switch for enumerate(). This simply offsets the index, you can equivalently simply add a number to the index inside the loop.\n\nfor n, a in enumerate(alist, start=1):\n    print(\"%d %d\" % (n, a))\n\n\nfor which the output is\n\n1 1\n2 2\n3 3\n4 4\n5 5\n\nShare\nImprove this answer\nFollow\nedited May 22 '19 at 15:10\nGeorgy\n6,8417\n7 gold badges\n49\n49 silver badges\n59\n59 bronze badges\nanswered Aug 15 '18 at 17:52\nDrM\n1,89611\n11 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"You can also try this:\n\ndata = ['itemA.ABC', 'itemB.defg', 'itemC.drug', 'itemD.ashok']\nx = []\nfor (i, item) in enumerate(data):\n      a = (i, str(item).split('.'))\n      x.append(a)\nfor index, value in x:\n     print(index, value)\n\n\nThe output is\n\n0 ['itemA', 'ABC']\n1 ['itemB', 'defg']\n2 ['itemC', 'drug']\n3 ['itemD', 'ashok']\n\nShare\nImprove this answer\nFollow\nanswered Feb 7 '18 at 14:04\nAshok Kumar Jayaraman\n2,2792\n2 gold badges\n24\n24 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"If there is no duplicate value in the list:\n\nfor i in ints:\n    indx = ints.index(i)\n    print(i, indx)\n\nShare\nImprove this answer\nFollow\nedited May 22 '19 at 15:02\nGeorgy\n6,8417\n7 gold badges\n49\n49 silver badges\n59\n59 bronze badges\nanswered Jun 10 '18 at 3:59\nRIshu\n1392\n2 silver badges\n10\n10 bronze badges","comments":["Note that the first option should not be used, since it only works correctly only when each item in the sequence is unique.","First option is O(n²), a terrible idea. If your list is 1000 elements long, it'll take literally a 1000 times longer than using enumerate. You should delete this answer."]},{"answer":"You can use the index method\n\nints = [8, 23, 45, 12, 78]\ninds = [ints.index(i) for i in ints]\n\n\nEDIT Highlighted in the comment that this method doesn’t work if there are duplicates in ints, the method below should work for any values in ints:\n\nints = [8, 8, 8, 23, 45, 12, 78]\ninds = [tup[0] for tup in enumerate(ints)]\n\n\nOr alternatively\n\nints = [8, 8, 8, 23, 45, 12, 78]\ninds = [tup for tup in enumerate(ints)]\n\n\nif you want to get both the index and the value in ints as a list of tuples.\n\nIt uses the method of enumerate in the selected answer to this question, but with list comprehension, making it faster with less code.\n\nShare\nImprove this answer\nFollow\nedited May 31 '18 at 6:09\nanswered May 30 '18 at 21:34\nPyRsquared\n5,2276\n6 gold badges\n37\n37 silver badges\n66\n66 bronze badges","comments":[]},{"answer":"Simple answer using While Loop:\n\narr = [8, 23, 45, 12, 78]\ni = 0\nwhile i < len(arr):\n    print(\"Item \", i + 1, \" = \", arr[i])\n    i += 1\n\n\nOutput:\n\nShare\nImprove this answer\nFollow\nedited Sep 7 '20 at 8:07\nkabirbaidhya\n2,7002\n2 gold badges\n30\n30 silver badges\n52\n52 bronze badges\nanswered Apr 18 '20 at 20:25\nAmar Kumar\n1,6412\n2 gold badges\n11\n11 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"To print tuple of (index, value) in list comprehension using a for loop:\n\nints = [8, 23, 45, 12, 78]\nprint [(i,ints[i]) for i in range(len(ints))]\n\n\nOutput:\n\n[(0, 8), (1, 23), (2, 45), (3, 12), (4, 78)]\n\nShare\nImprove this answer\nFollow\nanswered Apr 24 '18 at 10:53\nlola\n756\n6 bronze badges","comments":[]},{"answer":"This serves the purpose well enough:\n\nlist1 = [10, 'sumit', 43.21, 'kumar', '43', 'test', 3]\nfor x in list1:\n    print('index:', list1.index(x), 'value:', x)\n\nShare\nImprove this answer\nFollow\nedited May 15 '18 at 5:41\nChallenger5\n7894\n4 silver badges\n22\n22 bronze badges\nanswered Apr 24 '18 at 10:45\nSumit Kumar\n951\n1 silver badge\n4\n4 bronze badges","comments":["This will break down if there are repeated elements in the list as index() will search for the first occurrence of x, not mentioning the O( n^2 ) time required to look up each element.","totally agreed that it won't work for duplicate elements in the list. afterall I'm also learning python."]},{"answer":"You can simply use a variable such as count to count the number of elements in the list:\n\nints = [8, 23, 45, 12, 78]\ncount = 0\nfor i in ints:\n    count = count + 1\n    print('item #{} = {}'.format(count, i))\n\nShare\nImprove this answer\nFollow\nedited Jul 21 at 11:38\nSam\n217\n7 bronze badges\nanswered May 9 at 19:19\nRahul\n791\n1 silver badge\n3\n3 bronze badges","comments":[]},{"answer":"You can use enumerate to iterate over list and use start=1 since it will default to 0, meaning it would start counting at 0.\n\nHere is an example:\n\nfor index,val in enumerate(ints,start=1):\n     print(f\"item #{index} = {val}\")\n\n\nAlso, use of f-strings is a fast way to get your requested output and it is more readable as you can pass index and val into {}-placeholder directly.\n\nOutput:\n\nitem #1 = 8\nitem #2 = 23\nitem #3 = 45\nitem #4 = 12\nitem #5 = 78\n\nShare\nImprove this answer\nFollow\nedited Jul 22 at 9:32\nSam\n217\n7 bronze badges\nanswered Jun 10 at 4:17\nPurnima\n313\n3 bronze badges","comments":["While this correctly answers the question, it just replicates information already provided in this highly upvoted, six-year-old answer: stackoverflow.com/a/28072982/3216427 If you're trying to add new information to this old question, please explain what it is you are trying to contribute, and how this answer improves on information already found here.","yes did it...i wanted to show use f string here","Ah, OK, then that's worth adding here. I suggest you add an intro sentence saying so. You'll be less likely to get downvotes if you do, or get your answer deleted.","For reference, see What is print(f“…”).","ok...added explanation."]},{"answer":"Use enumerate to iterate over the list\n\nints = [8, 23, 45, 12, 78]\nfor idx,val in enumerate(ints):\n    print('item #{} = {}'.format(idx+1, val))\n\n\nOutput:\n\nitem #1 = 8\nitem #2 = 23\nitem #3 = 45\nitem #4 = 12\nitem #5 = 78\n\nShare\nImprove this answer\nFollow\nanswered Mar 30 at 17:30\nprashant sachdeva\n242\n2 bronze badges","comments":[]}]},{"id":"134845","href":"https://stackoverflow.com/questions/134845/which-href-value-should-i-use-for-javascript-links-or-javascriptvoid0","title":"Which “href” value should I use for JavaScript links, “#” or “javascript:void(0)”?","description":"\n                \nThe following are two methods of building a link that has the sole purpose of running JavaScript code. Which is better, in terms of functionality, page load speed, validation purposes, etc.?\n\n\n\nfunction myJsFunc() {\n    alert(\"myJsFunc\");\n}\n<a href=\"#\" onclick=\"myJsFunc();\">Run JavaScript Code</a>\n Run code snippetHide resultsExpand snippet\n\n\n\nor\n\n\n\nfunction myJsFunc() {\n    alert(\"myJsFunc\");\n}\n <a href=\"javascript:void(0)\" onclick=\"myJsFunc();\">Run JavaScript Code</a>\n Run code snippetHide resultsExpand snippet\n\n\n    ","questionComments":[],"answers":[{"answer":"I use javascript:void(0).\n\nThree reasons. Encouraging the use of # amongst a team of developers inevitably leads to some using the return value of the function called like this:\n\nfunction doSomething() {\n    //Some code\n    return false;\n}\n\n\nBut then they forget to use return doSomething() in the onclick and just use doSomething().\n\nA second reason for avoiding # is that the final return false; will not execute if the called function throws an error. Hence the developers have to also remember to handle any error appropriately in the called function.\n\nA third reason is that there are cases where the onclick event property is assigned dynamically. I prefer to be able to call a function or assign it dynamically without having to code the function specifically for one method of attachment or another. Hence my onclick (or on anything) in HTML markup look like this:\n\nonclick=\"someFunc.call(this)\"\n\n\nOR\n\nonclick=\"someFunc.apply(this, arguments)\"\n\n\nUsing javascript:void(0) avoids all of the above headaches, and I haven't found any examples of a downside.\n\nSo if you're a lone developer then you can clearly make your own choice, but if you work as a team you have to either state:\n\nUse href=\"#\", make sure onclick always contains return false; at the end, that any called function does not throw an error and if you attach a function dynamically to the onclick property make sure that as well as not throwing an error it returns false.\n\nOR\n\nUse href=\"javascript:void(0)\"\n\nThe second is clearly much easier to communicate.\n\nShare\nImprove this answer\nFollow\nedited Feb 20 '16 at 2:02\ncommunity wiki\n\n\n6 revs, 5 users 76%\nAnthonyWJones","comments":["Fast-forward to 2013: javascript:void(0) violates Content Security Policy on CSP-enabled HTTPS pages. One option would be then to use href='#' and event.preventDefault() in the handler, but I don't like this much. Perhaps you can establish a convention to use href='#void' and make sure no element on the page has id=\"void\". That way, clicking a link to non-existing anchor will not scroll the page.","You can use \"#\" and then bind a click event to all links with \"#\" as the href. This would be done in jQuery with: $('a[href=\"#\"]').click(function(e) { e.preventDefault ? e.preventDefault() : e.returnValue = false; });","#void would add an entry to the browser history nonetheless. Another way would be to use the URL of a resource that returns HTTP status 204 (and still use preventDefault - the 204 is just a fallback).","@Nathan Non-jquery: const voidLinks = document.querySelectorAll('a[href=\"#\"') for (const voidLink of voidLinks) { voidLink.addEventListener('click', e => { e.preventDefault ? e.preventDefault() : e.returnValue = false }) voidLink.addEventListener('keypress', e => { if (e.keyCode === 13) e.preventDefault ? e.preventDefault() : e.returnValue = false }) } That is including event listener on keypress Enter (code 13) for people navigation through page with keyboard.","@s3c The enter keypress already triggers the click event, so is that last listener necessary?"]},{"answer":"Neither.\n\nIf you can have an actual URL that makes sense use that as the HREF. The onclick won't fire if someone middle-clicks on your link to open a new tab or if they have JavaScript disabled.\n\nIf that is not possible, then you should at least inject the anchor tag into the document with JavaScript and the appropriate click event handlers.\n\nI realize this isn't always possible, but in my opinion it should be striven for in developing any public website.\n\nCheck out Unobtrusive JavaScript and Progressive enhancement (both Wikipedia).\n\nShare\nImprove this answer\nFollow\nedited Mar 11 '12 at 8:30\ncommunity wiki\n\n\n3 revs, 2 users 76%\nAaron Wagner","comments":["“If that is not possible, then” use a button instead. That’s how this answer should’ve ended."]},{"answer":"Doing <a href=\"#\" onclick=\"myJsFunc();\">Link</a> or <a href=\"javascript:void(0)\" onclick=\"myJsFunc();\">Link</a> or whatever else that contains an onclick attribute - was okay back five years ago, though now it can be a bad practice. Here's why:\n\nIt promotes the practice of obtrusive JavaScript - which has turned out to be difficult to maintain and difficult to scale. More on this in Unobtrusive JavaScript.\n\nYou're spending your time writing incredibly overly verbose code - which has very little (if any) benefit to your codebase.\n\nThere are now better, easier, and more maintainable and scalable ways of accomplishing the desired result.\n\nThe unobtrusive JavaScript way\n\nJust don't have a href attribute at all! Any good CSS reset would take care of the missing default cursor style, so that is a non-issue. Then attach your JavaScript functionality using graceful and unobtrusive best practices - which are more maintainable as your JavaScript logic stays in JavaScript, instead of in your markup - which is essential when you start developing large scale JavaScript applications which require your logic to be split up into blackboxed components and templates. More on this in Large-scale JavaScript Application Architecture\n\nSimple code example\n\n// Cancel click event\n$('.cancel-action').click(function(){\n    alert('Cancel action occurs!');\n});\n\n// Hover shim for Internet Explorer 6 and Internet Explorer 7.\n$(document.body).on('hover','a',function(){\n    $(this).toggleClass('hover');\n});\na { cursor: pointer; color: blue; }\na:hover,a.hover { text-decoration: underline; }\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<a class=\"cancel-action\">Cancel this action</a>\n Run code snippetExpand snippet\n\nA blackboxed Backbone.js example\n\nFor a scalable, blackboxed, Backbone.js component example - see this working jsfiddle example here. Notice how we utilize unobtrusive JavaScript practices, and in a tiny amount of code have a component that can be repeated across the page multiple times without side-effects or conflicts between the different component instances. Amazing!\n\nNotes\n\nOmitting the href attribute on the a element will cause the element to not be accessible using tab key navigation. If you wish for those elements to be accessible via the tab key, you can set the tabindex attribute, or use button elements instead. You can easily style button elements to look like normal links as mentioned in Tracker1's answer.\n\nOmitting the href attribute on the a element will cause Internet Explorer 6 and Internet Explorer 7 to not take on the a:hover styling, which is why we have added a simple JavaScript shim to accomplish this via a.hover instead. Which is perfectly okay, as if you don't have a href attribute and no graceful degradation then your link won't work anyway - and you'll have bigger issues to worry about.\n\nIf you want your action to still work with JavaScript disabled, then using an a element with a href attribute that goes to some URL that will perform the action manually instead of via an Ajax request or whatever should be the way to go. If you are doing this, then you want to ensure you do an event.preventDefault() on your click call to make sure when the button is clicked it does not follow the link. This option is called graceful degradation.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:10\ncommunity wiki\n\n\n17 revs, 5 users 69%\nbalupton","comments":["I use an actual hash not just # to open a lightbox. I have specifically made code that also open the lightbox when the url is assessed with that hash and manually add history events to the browser with the changed hash on the url. I consider this actually good practice and something expected that needed extra work on my part. However, my code just came in conflict with some 3rd party smooth scroll code that fucked up my event entirely. I am unsure if I just blame their code or if this approach is not so great after all. Again my case the #hash is actually not just to keep the style ..."]},{"answer":"'#' will take the user back to the top of the page, so I usually go with void(0).\n\njavascript:; also behaves like javascript:void(0);\n\nShare\nImprove this answer\nFollow\nedited May 11 '17 at 4:33\ncommunity wiki\n\n\n4 revs, 4 users 43%\nGabe Rogan","comments":["The way to avoid that is to return false in the onclick event handler.","Returning false in the event handler doesn't avoid that if JavaScript the JS doesn't run successfully.","using \"#someNonExistantAnchorName\" works well because it has nowhere to jump to.","If you have a base href, then # or #something will take you to that anchor on the base href page, instead of on the current page.","The shebang (#!) does the trick but it's definitely bad practice."]},{"answer":"I would honestly suggest neither. I would use a stylized <button></button> for that behavior.\n\nbutton.link {\n  display: inline-block;\n  position: relative;\n  background-color: transparent;\n  cursor: pointer;\n  border: 0;\n  padding: 0;\n  color: #00f;\n  text-decoration: underline;\n  font: inherit;\n}\n<p>A button that looks like a <button type=\"button\" class=\"link\">link</button>.</p>\n Run code snippetExpand snippet\n\nThis way you can assign your onclick. I also suggest binding via script, not using the onclick attribute on the element tag. The only gotcha is the psuedo 3d text effect in older IEs that cannot be disabled.\n\nIf you MUST use an A element, use javascript:void(0); for reasons already mentioned.\n\nWill always intercept in case your onclick event fails.\nWill not have errant load calls happen, or trigger other events based on a hash change\nThe hash tag can cause unexpected behavior if the click falls through (onclick throws), avoid it unless it's an appropriate fall-through behavior, and you want to change the navigation history.\n\nNOTE: You can replace the 0 with a string such as javascript:void('Delete record 123') which can serve as an extra indicator that will show what the click will actually do.\n\nShare\nImprove this answer\nFollow\nedited May 6 '18 at 20:40\ncommunity wiki\n\n\n5 revs, 4 users 58%\nTracker1","comments":["This answer should be up top. If you are having this dilemma, chances are you are actually in need of a button. And IE9 is quickly losing market shares, fortunately, and the 1px active effect should not prevent us to use semantic markup. <a> is a link, it's meant to send you somewhere, for actions we have <button>'s."]},{"answer":"The first one, ideally with a real link to follow in case the user has JavaScript disabled. Just make sure to return false to prevent the click event from firing if the JavaScript executes.\n\n<a href=\"#\" onclick=\"myJsFunc(); return false;\">Link</a>\n\n\nIf you use Angular2, this way works:\n\n<a [routerLink]=\"\" (click)=\"passTheSalt()\">Click me</a>.\n\nSee here https://stackoverflow.com/a/45465728/2803344\n\nShare\nImprove this answer\nFollow\nedited Oct 12 '17 at 12:00\ncommunity wiki\n\n\n3 revs, 2 users 55%\nBelter","comments":["So in user agents with JavaScript enabled and the function supported this run a JavaScript function, falling back (for user agents where the JS fails for whatever reason) to a link to the top of the page? This is rarely a sensible fallback.","\"ideally with a real link to follow in case the user has JavaScript disabled\", it should be going to a useful page not #, even if it's just an explanation that the site needs JS to work. as for failing, I would expect the developer to use proper browser feature detection, etc before deploying."]},{"answer":"Neither if you ask me;\n\nIf your \"link\" has the sole purpose of running some JavaScript code it doesn't qualify as a link; rather a piece of text with a JavaScript function coupled to it. I would recommend to use a <span> tag with an onclick handler attached to it and some basic CSS to immitate a link. Links are made for navigation, and if your JavaScript code isn't for navigation it should not be an <a> tag.\n\nExample:\n\nfunction callFunction() { console.log(\"function called\"); }\n.jsAction {\n    cursor: pointer;\n    color: #00f;\n    text-decoration: underline;\n}\n<p>I want to call a JavaScript function <span class=\"jsAction\" onclick=\"callFunction();\">here</span>.</p>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Nov 5 '17 at 13:52\ncommunity wiki\n\n\n4 revs, 4 users 52%\nfijter","comments":["This approach restricts the 'link' to a mouse only operation. An anchor can be visited via the keyboard and its 'onclick' event is fired when the enter key is pressed.","Hardcoding colors in your CSS would prevent the browser from using custom colors the user may define, which can be a problem with accessibility.","<span>s are not meant to do anything. <A>nchors and <buttons> are used for that!","Using buttons is a better choice here while using a span is not.","“Links are made for navigation, and if your JavaScript code isn't for navigation it should not be an <a> tag.” — Even if the JavaScript code is “for navigation”, a link may not be appropriate every time."]},{"answer":"Ideally you'd do this:\n\n<a href=\"javascriptlessDestination.html\" onclick=\"myJSFunc(); return false;\">Link text</a>\n\n\nOr, even better, you'd have the default action link in the HTML, and you'd add the onclick event to the element unobtrusively via JavaScript after the DOM renders, thus ensuring that if JavaScript is not present/utilized you don't have useless event handlers riddling your code and potentially obfuscating (or at least distracting from) your actual content.\n\nShare\nImprove this answer\nFollow\nedited May 31 '11 at 8:04\ncommunity wiki\n\n\n2 revs, 2 users 80%\nSteve Paulo","comments":[]},{"answer":"Using just # makes some funny movements, so I would recommend to use #self if you would like to save on typing efforts of JavaScript bla, bla,.\n\nShare\nImprove this answer\nFollow\nedited Nov 10 '15 at 4:10\ncommunity wiki\n\n\n3 revs, 3 users 40%\nSpammer Joe","comments":["For reference, #self doesn't appear to be special. Any fragment identifier that doesn't match the name or id of any element in the document (and isn't blank or \"top\") should have the same effect."]},{"answer":"I use the following\n\n<a href=\"javascript:;\" onclick=\"myJsFunc();\">Link</a>\n\n\ninstead\n\n<a href=\"javascript:void(0);\" onclick=\"myJsFunc();\">Link</a>\n\nShare\nImprove this answer\nFollow\nedited Aug 9 '18 at 11:14\ncommunity wiki\n\n\n4 revs, 4 users 70%\nse_pavel","comments":["href=\"javascript:\" and href=\"javascript:void 0;\" are all equivalent as well, but they’re all equally bad."]},{"answer":"I recommend using a <button> element instead, especially if the control is supposed to produce a change in the data. (Something like a POST.)\n\nIt's even better if you inject the elements unobtrusively, a type of progressive enhancement. (See this comment.)\n\nShare\nImprove this answer\nFollow\nedited Nov 29 '19 at 8:14\ncommunity wiki\n\n\n3 revs, 2 users 93%\ntreat your mods well","comments":["this depend if you need button on your bem ( block element model) of html."]},{"answer":"I agree with suggestions elsewhere stating that you should use regular URL in href attribute, then call some JavaScript function in onclick. The flaw is, that they automaticaly add return false after the call.\n\nThe problem with this approach is, that if the function will not work or if there will be any problem, the link will become unclickable. Onclick event will always return false, so the normal URL will not be called.\n\nThere's very simple solution. Let function return true if it works correctly. Then use the returned value to determine if the click should be cancelled or not:\n\nJavaScript\n\nfunction doSomething() {\n    alert( 'you clicked on the link' );\n    return true;\n}\n\n\nHTML\n\n<a href=\"path/to/some/url\" onclick=\"return !doSomething();\">link text</a>\n\n\nNote, that I negate the result of the doSomething() function. If it works, it will return true, so it will be negated (false) and the path/to/some/URL will not be called. If the function will return false (for example, the browser doesn't support something used within the function or anything else goes wrong), it is negated to true and the path/to/some/URL is called.\n\nShare\nImprove this answer\nFollow\nedited Mar 11 '12 at 8:36\ncommunity wiki\n\n\n2 revs, 2 users 93%\nFczbkk","comments":[]},{"answer":"# is better than javascript:anything, but the following is even better:\n\nHTML:\n\n<a href=\"/gracefully/degrading/url/with/same/functionality.ext\" class=\"some-selector\">For great justice</a>\n\n\nJavaScript:\n\n$(function() {\n    $(\".some-selector\").click(myJsFunc);\n});\n\n\nYou should always strive for graceful degradation (in the event that the user doesn't have JavaScript enabled...and when it is with specs. and budget). Also, it is considered bad form to use JavaScript attributes and protocol directly in HTML.\n\nShare\nImprove this answer\nFollow\nanswered Nov 23 '09 at 20:38\ncommunity wiki\n\n\nJustin Johnson","comments":["@Muhd: Return should activate click on links…"]},{"answer":"Unless you're writing out the link using JavaScript (so that you know it's enabled in the browser), you should ideally be providing a proper link for people who are browsing with JavaScript disabled and then prevent the default action of the link in your onclick event handler. This way those with JavaScript enabled will run the function and those with JavaScript disabled will jump to an appropriate page (or location within the same page) rather than just clicking on the link and having nothing happen.\n\nShare\nImprove this answer\nFollow\nanswered Sep 25 '08 at 18:02\ncommunity wiki\n\n\nSimon Forrest","comments":[]},{"answer":"Definitely hash (#) is better because in JavaScript it is a pseudoscheme:\n\npollutes history\ninstantiates new copy of engine\nruns in global scope and doesn't respect event system.\n\nOf course \"#\" with an onclick handler which prevents default action is [much] better. Moreover, a link that has the sole purpose to run JavaScript is not really \"a link\" unless you are sending user to some sensible anchor on the page (just # will send to top) when something goes wrong. You can simply simulate look and feel of link with stylesheet and forget about href at all.\n\nIn addition, regarding cowgod's suggestion, particularly this: ...href=\"javascript_required.html\" onclick=\"... This is good approach, but it doesn't distinguish between \"JavaScript disabled\" and \"onclick fails\" scenarios.\n\nShare\nImprove this answer\nFollow\nedited Feb 20 '17 at 6:52\ncommunity wiki\n\n\n5 revs, 4 users 45%\nFree Consulting","comments":[]},{"answer":"I usually go for\n\n<a href=\"javascript:;\" onclick=\"yourFunction()\">Link description</a>\n\n\nIt's shorter than javascript:void(0) and does the same.\n\nShare\nImprove this answer\nFollow\nanswered Aug 13 '15 at 1:01\ncommunity wiki\n\n\ndnetix","comments":[]},{"answer":"I would use:\n\n<a href=\"#\" onclick=\"myJsFunc();return false;\">Link</a>\n\n\nReasons:\n\nThis makes the href simple, search engines need it. If you use anything else ( such as a string), it may cause a 404 not found error.\nWhen mouse hovers over the link, it doesn't show that it is a script.\nBy using return false;, the page doesn't jump to the top or break the back button.\nShare\nImprove this answer\nFollow\nedited Aug 22 '13 at 11:37\ncommunity wiki\n\n\n2 revs, 2 users 73%\nEric Yin","comments":["i dont agree with \"1.\" cause it gives error when u put ur script link when scripts are not allowed. so that kind of links should be added with the js code. that way people can avoid those links while script is not allowed and see no errors at all."]},{"answer":"I choose use javascript:void(0), because use this could prevent right click to open the content menu. But javascript:; is shorter and does the same thing.\n\nShare\nImprove this answer\nFollow\nedited Aug 9 '18 at 11:16\ncommunity wiki\n\n\n3 revs, 3 users 40%\nuser564706","comments":[]},{"answer":"So, when you are doing some JavaScript things with an <a /> tag and if you put href=\"#\" as well, you can add return false at the end of the event (in case of inline event binding) like:\n\n<a href=\"#\" onclick=\"myJsFunc(); return false;\">Run JavaScript Code</a>\n\n\nOr you can change the href attribute with JavaScript like:\n\n<a href=\"javascript://\" onclick=\"myJsFunc();\">Run JavaScript Code</a>\n\n\nor\n\n<a href=\"javascript:void(0)\" onclick=\"myJsFunc();\">Run JavaScript Code</a>\n\n\nBut semantically, all the above ways to achieve this are wrong (it works fine though). If any element is not created to navigate the page and that have some JavaScript things associated with it, then it should not be a <a> tag.\n\nYou can simply use a <button /> instead to do things or any other element like b, span or whatever fits there as per your need, because you are allowed to add events on all the elements.\n\nSo, there is one benefit to use <a href=\"#\">. You get the cursor pointer by default on that element when you do a href=\"#\". For that, I think you can use CSS for this like cursor:pointer; which solves this problem also.\n\nAnd at the end, if you are binding the event from the JavaScript code itself, there you can do event.preventDefault() to achieve this if you are using <a> tag, but if you are not using a <a> tag for this, there you get an advantage, you don't need to do this.\n\nSo, if you see, it's better not to use a tag for this kind of stuff.\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '14 at 12:32\ncommunity wiki\n\n\n2 revs, 2 users 84%\nAshish Kumar","comments":[]},{"answer":"Don't use links for the sole purpose of running JavaScript.\n\nThe use of href=\"#\" scrolls the page to the top; the use of void(0) creates navigational problems within the browser.\n\nInstead, use an element other than a link:\n\n<span onclick=\"myJsFunc()\" class=\"funcActuator\">myJsFunc</span>\n\n\nAnd style it with CSS:\n\n.funcActuator { \n  cursor: default;\n}\n\n.funcActuator:hover { \n  color: #900;\n}\n\nShare\nImprove this answer\nFollow\nanswered Jan 26 '16 at 19:54\ncommunity wiki\n\n\nGarrett","comments":["Use a button, not a span. Buttons naturally fall in the focus order so can be accessed without a mouse / trackpad / etc.","Adding ton Quentin's comment: as currently written, keyboard users won't reach the span element because it is a non-focusable element. That's why you need a button.","You can make it focusable by adding tabindex=\"0\" to the span. That said, using button is better because it gives you the desired functionality for free. To make it accessible using a span you not only need to attach a click handler, but a keyboard event handler that looks for presses of space bar or enter key and then fires the normal click handler. You would also want to change the second CSS selector to .funcActuator:hover, .funcActuator:focus so the fact that the element has focus is apparent."]},{"answer":"It would be better to use jQuery,\n\n$(document).ready(function() {\n    $(\"a\").css(\"cursor\", \"pointer\");\n});\n\n\nand omit both href=\"#\" and href=\"javascript:void(0)\".\n\nThe anchor tag markup will be like\n\n<a onclick=\"hello()\">Hello</a>\n\n\nSimple enough!\n\nShare\nImprove this answer\nFollow\nedited Mar 9 '14 at 10:43\ncommunity wiki\n\n\n3 revs, 3 users 88%\nnaveen","comments":["This is what I was going to say. If a link has a fallback url that makes sense, use that. Otherwise, just omit the href or use something more semantically appropriate than an <a>. If the only reason everyone is advocating including the href is to get the finger on hover, a simple \"a { cursor: pointer; }\" will do the trick.","May I say this is the option that SO decided to go with. Check the \"flag\" links, for instance.","That gives terrible accessibility. Try it in SO: you can't flag a post without using the mouse. The \"link\" and \"edit\" links are accessible by tabbing, but \"flag\" isn't.","I agree with this option. If the anchor has no purpose other than JavaScript, it shouldn't have a href. @Fatih: Using jQuery means that if JavaScript is disabled, the link will NOT have a pointer.","If you are going to go this route, why not bind the click using jQuery as well? Part of the great thing about using jQuery is the ability to seperate your javascript from your markup."]},{"answer":"Usually, you should always have a fall back link to make sure that clients with JavaScript disabled still has some functionality. This concept is called unobtrusive JavaScript.\n\nExample... Let's say you have the following search link:\n\n<a href=\"search.php\" id=\"searchLink\">Search</a>\n\n\nYou can always do the following:\n\nvar link = document.getElementById('searchLink');\n\nlink.onclick = function() {\n    try {\n        // Do Stuff Here        \n    } finally {\n        return false;\n    }\n};\n\n\nThat way, people with JavaScript disabled are directed to search.php while your viewers with JavaScript view your enhanced functionality.\n\nShare\nImprove this answer\nFollow\nedited Feb 20 '17 at 6:54\ncommunity wiki\n\n\n3 revs, 3 users 86%\nAndrew Moore","comments":[]},{"answer":"If you happen to be using AngularJS, you can use the following:\n\n<a href=\"\">Do some fancy JavaScript</a>\n\n\nWhich will not do anything.\n\nIn addition\n\nIt will not take you to the top of the page, as with (#)\nTherefore, you don't need to explicitly return false with JavaScript\nIt is short an concise\nShare\nImprove this answer\nFollow\nedited Jul 30 '13 at 10:45\ncommunity wiki\n\n\n2 revs\nwhirlwin","comments":["But this would cause the page to reload, and since we're always using javascript to modify the page, this is unacceptable.","@HenryHu I figured out that the reason it did not reload was because of AngularJS. See my updated answer."]},{"answer":"Depending on what you want to accomplish, you could forget the onclick and just use the href:\n\n<a href=\"javascript:myJsFunc()\">Link Text</a>\n\n\nIt gets around the need to return false. I don't like the # option because, as mentioned, it will take the user to the top of the page. If you have somewhere else to send the user if they don't have JavaScript enabled (which is rare where I work, but a very good idea), then Steve's proposed method works great.\n\n<a href=\"javascriptlessDestination.html\" onclick=\"myJSFunc(); return false;\">Link text</a>\n\n\nLastly, you can use javascript:void(0) if you do not want anyone to go anywhere and if you don't want to call a JavaScript function. It works great if you have an image you want a mouseover event to happen with, but there's not anything for the user to click on.\n\nShare\nImprove this answer\nFollow\nedited Mar 11 '12 at 8:57\ncommunity wiki\n\n\n3 revs, 3 users 80%\nWill Read","comments":["The only downside with this (from memory, I may be wrong) is that IE doesn't consider an A to be an A if you don't have a href inside it. (So CSS rules won't work)"]},{"answer":"I believe you are presenting a false dichotomy. These are not the only two options.\n\nI agree with Mr. D4V360 who suggested that, even though you are using the anchor tag, you do not truly have an anchor here. All you have is a special section of a document that should behave slightly different. A <span> tag is far more appropriate.\n\nShare\nImprove this answer\nFollow\nedited May 21 '15 at 0:56\ncommunity wiki\n\n\n2 revs, 2 users 80%\nClever Human","comments":["Also if you were to replace an a with a span, you'll need to remember to make it focusable via keyboard."]},{"answer":"I personally use them in combination. For example:\n\nHTML\n\n<a href=\"#\">Link</a>\n\n\nwith little bit of jQuery\n\n$('a[href=\"#\"]').attr('href','javascript:void(0);');\n\n\nor\n\n$('a[href=\"#\"]').click(function(e) {\n   e.preventDefault();\n});\n\n\nBut I'm using that just for preventing the page jumping to the top when the user clicks on an empty anchor. I'm rarely using onClick and other on events directly in HTML.\n\nMy suggestion would be to use <span> element with the class attribute instead of an anchor. For example:\n\n<span class=\"link\">Link</span>\n\n\nThen assign the function to .link with a script wrapped in the body and just before the </body> tag or in an external JavaScript document.\n\n<script>\n    (function($) {\n        $('.link').click(function() {\n            // do something\n        });\n    })(jQuery);\n</script>\n\n\n*Note: For dynamically created elements, use:\n\n$('.link').on('click', function() {\n    // do something\n});\n\n\nAnd for dynamically created elements which are created with dynamically created elements, use:\n\n$(document).on('click','.link', function() {\n    // do something\n});\n\n\nThen you can style the span element to look like an anchor with a little CSS:\n\n.link {\n    color: #0000ee;\n    text-decoration: underline;\n    cursor: pointer;\n}\n.link:active {\n    color: red;\n}\n\n\nHere's a jsFiddle example of above aforementioned.\n\nShare\nImprove this answer\nFollow\nedited Jan 24 '19 at 23:25\ncommunity wiki\n\n\n4 revs, 3 users 82%\nmdesdev","comments":[]},{"answer":"When I've got several faux-links, I prefer to give them a class of 'no-link'.\n\nThen in jQuery, I add the following code:\n\n$(function(){\n   $('.no-link').click(function(e){\n       e.preventDefault();\n   });\n});\n\n\nAnd for the HTML, the link is simply\n\n<a href=\"/\" class=\"no-link\">Faux-Link</a>\n\n\nI don't like using Hash-Tags unless they're used for anchors, and I only do the above when I've got more than two faux-links, otherwise I go with javascript:void(0).\n\n<a href=\"javascript:void(0)\" class=\"no-link\">Faux-Link</a>\n\n\nTypically, I like to just avoid using a link at all and just wrap something around in a span and use that as a way to active some JavaScript code, like a pop-up or a content-reveal.\n\nShare\nImprove this answer\nFollow\nedited Oct 26 '14 at 12:28\ncommunity wiki\n\n\n2 revs, 2 users 88%\nStacks on Stacks on Stacks","comments":[]},{"answer":"I tried both in google chrome with the developer tools, and the id=\"#\" took 0.32 seconds. While the javascript:void(0) method took only 0.18 seconds. So in google chrome, javascript:void(0) works better and faster.\n\nShare\nImprove this answer\nFollow\nedited Feb 20 '17 at 15:46\ncommunity wiki\n\n\n2 revs, 2 users 67%\nuser6460587","comments":["Actually they don't do the same. # makes you jump to top of the page."]},{"answer":"It's nice to have your site be accessible by users with JavaScript disabled, in which case the href points to a page that performs the same action as the JavaScript being executed. Otherwise I use \"#\" with a \"return false;\" to prevent the default action (scroll to top of the page) as others have mentioned.\n\nGoogling for \"javascript:void(0)\" provides a lot of information on this topic. Some of them, like this one mention reasons to NOT use void(0).\n\nShare\nImprove this answer\nFollow\nedited Aug 15 '18 at 9:38\ncommunity wiki\n\n\n4 revs, 4 users 42%\nPeter Mortensen","comments":["The blog entry does not cite the reference as to why javascript:void(0) should be avoided.","The link is (effectively) broken now.","Not good solution for accessibility: dequeuniversity.com/rules/axe/3.0/href-no-hash","javascript:void(0); is also not good if you want to use a strict Content Security Policy that disables inline JavaScript."]},{"answer":"I'm basically paraphrasing from this practical article using progressive enhancement. The short answer is that you never use javascript:void(0); or # unless your user interface has already inferred that JavaScript is enabled, in which case you should use javascript:void(0);. Also, do not use span as links, since that is semantically false to begin with.\n\nUsing SEO friendly URL routes in your application, such as /Home/Action/Parameters is a good practice as well. If you have a link to a page that works without JavaScript first, you can enhance the experience afterward. Use a real link to a working page, then add an onlick event to enhance the presentation.\n\nHere is a sample. Home/ChangePicture is a working link to a form on a page complete with user interface and standard HTML submit buttons, but it looks nicer injected into a modal dialog with jQueryUI buttons. Either way works, depending on the browser, which satisfies mobile first development.\n\n<p><a href=\"Home/ChangePicture\" onclick=\"return ChangePicture_onClick();\" title=\"Change Picture\">Change Picture</a></p>\n\n<script type=\"text/javascript\">\n    function ChangePicture_onClick() {\n        $.get('Home/ChangePicture',\n              function (htmlResult) {\n                  $(\"#ModalViewDiv\").remove(); //Prevent duplicate dialogs\n                  $(\"#modalContainer\").append(htmlResult);\n                  $(\"#ModalViewDiv\").dialog({\n                      width: 400,\n                      modal: true,\n                      buttons: {\n                          \"Upload\": function () {\n                              if(!ValidateUpload()) return false;\n                              $(\"#ModalViewDiv\").find(\"form\").submit();\n                          },\n                          Cancel: function () { $(this).dialog(\"close\"); }\n                      },\n                      close: function () { }\n                  });\n              }\n        );\n        return false;\n    }\n</script>\n\nShare\nImprove this answer\nFollow\nedited Mar 11 '12 at 9:41\ncommunity wiki\n\n\n3 revs, 2 users 62%\nJosh Simerman","comments":["In term of SEO I would prefer this way. Using as many friendly URL shall definitely improve page value factor."]}]},{"id":"388242","href":"https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list","title":"The Definitive C++ Book Guide and List","description":"\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nThis question attempts to collect the few pearls among the dozens of bad C++ books that are published every year.\nUnlike many other programming languages, which are often picked up on the go from tutorials found on the Internet, few are able to quickly pick up C++ without studying a well-written C++ book. It is way too big and complex for doing this. In fact, it is so big and complex, that there are very many very bad C++ books out there. And we are not talking about bad style, but things like sporting glaringly obvious factual errors and promoting abysmally bad programming styles.\nPlease edit the accepted answer to provide quality books and an approximate skill level — preferably after discussing your addition in the C++ chat room. (The regulars might mercilessly undo your work if they disagree with a recommendation.) Add a short blurb/description about each book that you have personally read/benefited from. Feel free to debate quality, headings, etc. Books that meet the criteria will be added to the list.  Books that have reviews by the Association of C and C++ Users (ACCU) have links to the review.\n*Note: FAQs and other resources can be found in the C++ tag info and under c++-faq. \n    ","questionComments":[],"answers":[{"answer":"Beginner\nIntroductory, no previous programming experience\n\nC++ Primer * (Stanley Lippman, Josée Lajoie, and Barbara E. Moo) (updated for C++11) Coming at 1k pages, this is a very thorough introduction into C++ that covers just about everything in the language in a very accessible format and in great detail. The fifth edition (released August 16, 2012) covers C++11. [Review]\n\n* Not to be confused with C++ Primer Plus (Stephen Prata), with a significantly less favorable review.\n\nProgramming: Principles and Practice Using C++ (Bjarne Stroustrup, 2nd Edition - May 25, 2014) (updated for C++11/C++14) An introduction to programming using C++ by the creator of the language. A good read, that assumes no previous programming experience, but is not only for beginners.\n\nIntroductory, with previous programming experience\n\nA Tour of C++ (Bjarne Stroustrup) (2nd edition for C++17) The “tour” is a quick (about 180 pages and 14 chapters) tutorial overview of all of standard C++ (language and standard library, and using C++11) at a moderately high level for people who already know C++ or at least are experienced programmers. This book is an extended version of the material that constitutes Chapters 2-5 of The C++ Programming Language, 4th edition.\n\nAccelerated C++ (Andrew Koenig and Barbara Moo, 1st Edition - August 24, 2000) This basically covers the same ground as the C++ Primer, but does so in a quarter of its space. This is largely because it does not attempt to be an introduction to programming, but an introduction to C++ for people who've previously programmed in some other language. It has a steeper learning curve, but, for those who can cope with this, it is a very compact introduction to the language. (Historically, it broke new ground by being the first beginner's book to use a modern approach to teaching the language.) Despite this, the C++ it teaches is purely C++98. [Review]\n\nBest practices\n\nEffective C++ (Scott Meyers, 3rd Edition - May 22, 2005) This was written with the aim of being the best second book C++ programmers should read, and it succeeded. Earlier editions were aimed at programmers coming from C, the third edition changes this and targets programmers coming from languages like Java. It presents ~50 easy-to-remember rules of thumb along with their rationale in a very accessible (and enjoyable) style. For C++11 and C++14 the examples and a few issues are outdated and Effective Modern C++ should be preferred. [Review]\n\nEffective Modern C++ (Scott Meyers) This is basically the new version of Effective C++, aimed at C++ programmers making the transition from C++03 to C++11 and C++14.\n\nEffective STL (Scott Meyers) This aims to do the same to the part of the standard library coming from the STL what Effective C++ did to the language as a whole: It presents rules of thumb along with their rationale. [Review]\n\nIntermediate\n\nMore Effective C++ (Scott Meyers) Even more rules of thumb than Effective C++. Not as important as the ones in the first book, but still good to know.\n\nExceptional C++ (Herb Sutter) Presented as a set of puzzles, this has one of the best and thorough discussions of the proper resource management and exception safety in C++ through Resource Acquisition is Initialization (RAII) in addition to in-depth coverage of a variety of other topics including the pimpl idiom, name lookup, good class design, and the C++ memory model. [Review]\n\nMore Exceptional C++ (Herb Sutter) Covers additional exception safety topics not covered in Exceptional C++, in addition to discussion of effective object-oriented programming in C++ and correct use of the STL. [Review]\n\nExceptional C++ Style (Herb Sutter) Discusses generic programming, optimization, and resource management; this book also has an excellent exposition of how to write modular code in C++ by using non-member functions and the single responsibility principle. [Review]\n\nC++ Coding Standards (Herb Sutter and Andrei Alexandrescu) “Coding standards” here doesn't mean “how many spaces should I indent my code?” This book contains 101 best practices, idioms, and common pitfalls that can help you to write correct, understandable, and efficient C++ code. [Review]\n\nC++ Templates: The Complete Guide (David Vandevoorde and Nicolai M. Josuttis) This is the book about templates as they existed before C++11. It covers everything from the very basics to some of the most advanced template metaprogramming and explains every detail of how templates work (both conceptually and at how they are implemented) and discusses many common pitfalls. Has excellent summaries of the One Definition Rule (ODR) and overload resolution in the appendices. A second edition covering C++11, C++14 and C++17 has been already published. [Review]\n\nC++ 17 - The Complete Guide (Nicolai M. Josuttis) This book describes all the new features introduced in the C++17 Standard covering everything from the simple ones like 'Inline Variables', 'constexpr if' all the way up to 'Polymorphic Memory Resources' and 'New and Delete with overaligned Data'. [Review]\n\nC++ in Action (Bartosz Milewski). This book explains C++ and its features by building an application from ground up. [Review]\n\nFunctional Programming in C++ (Ivan Čukić). This book introduces functional programming techniques to modern C++ (C++11 and later). A very nice read for those who want to apply functional programming paradigms to C++.\n\nAdvanced\n\nModern C++ Design (Andrei Alexandrescu) A groundbreaking book on advanced generic programming techniques. Introduces policy-based design, type lists, and fundamental generic programming idioms then explains how many useful design patterns (including small object allocators, functors, factories, visitors, and multi-methods) can be implemented efficiently, modularly, and cleanly using generic programming. [Review]\n\nC++ Template Metaprogramming (David Abrahams and Aleksey Gurtovoy)\n\nC++ Concurrency In Action (Anthony Williams) A book covering C++11 concurrency support including the thread library, the atomics library, the C++ memory model, locks and mutexes, as well as issues of designing and debugging multithreaded applications. A second edition covering C++14 and C++17 has already been published. [Review]\n\nAdvanced C++ Metaprogramming (Davide Di Gennaro) A pre-C++11 manual of TMP techniques, focused more on practice than theory. There are a ton of snippets in this book, some of which are made obsolete by type traits, but the techniques, are nonetheless useful to know. If you can put up with the quirky formatting/editing, it is easier to read than Alexandrescu, and arguably, more rewarding. For more experienced developers, there is a good chance that you may pick up something about a dark corner of C++ (a quirk) that usually only comes about through extensive experience.\n\nLarge Scale C++ volume I, Process and architecture (John Lakos). Part one of a three part series extending the older book 'Large Scale C++ Design'. Lakos explains battle tested techniques to manage very big C++ software projects. If you work in big C++ software project this is a great read, detailing the relation between physical and logical structure, strategies for components and their reuse.\n\nReference Style - All Levels\n\nThe C++ Programming Language (Bjarne Stroustrup) (updated for C++11) The classic introduction to C++ by its creator. Written to parallel the classic K&R, this indeed reads very much like it and covers just about everything from the core language to the standard library, to programming paradigms to the language's philosophy. [Review] Note: All releases of the C++ standard are tracked in the question \"Where do I find the current C or C++ standard documents?\".\n\nC++ Standard Library Tutorial and Reference (Nicolai Josuttis) (updated for C++11) The introduction and reference for the C++ Standard Library. The second edition (released on April 9, 2012) covers C++11. [Review]\n\nThe C++ IO Streams and Locales (Angelika Langer and Klaus Kreft) There's very little to say about this book except that, if you want to know anything about streams and locales, then this is the one place to find definitive answers. [Review]\n\nC++11/14/17/… References:\n\nThe C++11/14/17 Standard (INCITS/ISO/IEC 14882:2011/2014/2017) This, of course, is the final arbiter of all that is or isn't C++. Be aware, however, that it is intended purely as a reference for experienced users willing to devote considerable time and effort to its understanding. The C++17 standard is released in electronic form for 198 Swiss Francs.\n\nThe C++17 standard is available, but seemingly not in an economical form – directly from the ISO it costs 198 Swiss Francs (about $200 US). For most people, the final draft before standardization is more than adequate (and free). Many will prefer an even newer draft, documenting new features that are likely to be included in C++20.\n\nOverview of the New C++ (C++11/14) (PDF only) (Scott Meyers) (updated for C++14) These are the presentation materials (slides and some lecture notes) of a three-day training course offered by Scott Meyers, who's a highly respected author on C++. Even though the list of items is short, the quality is high.\n\nThe C++ Core Guidelines (C++11/14/17/…) (edited by Bjarne Stroustrup and Herb Sutter) is an evolving online document consisting of a set of guidelines for using modern C++ well. The guidelines are focused on relatively higher-level issues, such as interfaces, resource management, memory management and concurrency affecting application architecture and library design. The project was announced at CppCon'15 by Bjarne Stroustrup and others and welcomes contributions from the community. Most guidelines are supplemented with a rationale and examples as well as discussions of possible tool support. Many rules are designed specifically to be automatically checkable by static analysis tools.\n\nThe C++ Super-FAQ (Marshall Cline, Bjarne Stroustrup and others) is an effort by the Standard C++ Foundation to unify the C++ FAQs previously maintained individually by Marshall Cline and Bjarne Stroustrup and also incorporating new contributions. The items mostly address issues at an intermediate level and are often written with a humorous tone. Not all items might be fully up to date with the latest edition of the C++ standard yet.\n\ncppreference.com (C++03/11/14/17/…) (initiated by Nate Kohl) is a wiki that summarizes the basic core-language features and has extensive documentation of the C++ standard library. The documentation is very precise but is easier to read than the official standard document and provides better navigation due to its wiki nature. The project documents all versions of the C++ standard and the site allows filtering the display for a specific version. The project was presented by Nate Kohl at CppCon'14.\n\nClassics / Older\n\nNote: Some information contained within these books may not be up-to-date or no longer considered best practice.\n\nThe Design and Evolution of C++ (Bjarne Stroustrup) If you want to know why the language is the way it is, this book is where you find answers. This covers everything before the standardization of C++.\n\nRuminations on C++ - (Andrew Koenig and Barbara Moo) [Review]\n\nAdvanced C++ Programming Styles and Idioms (James Coplien) A predecessor of the pattern movement, it describes many C++-specific “idioms”. It's certainly a very good book and might still be worth a read if you can spare the time, but quite old and not up-to-date with current C++.\n\nLarge Scale C++ Software Design (John Lakos) Lakos explains techniques to manage very big C++ software projects. Certainly, a good read, if it only was up to date. It was written long before C++ 98 and misses on many features (e.g. namespaces) important for large-scale projects. If you need to work in a big C++ software project, you might want to read it, although you need to take more than a grain of salt with it. Not to be confused with the extended and later book series Large Scale C++ volume I-III.\n\nInside the C++ Object Model (Stanley Lippman) If you want to know how virtual member functions are commonly implemented and how base objects are commonly laid out in memory in a multi-inheritance scenario, and how all this affects performance, this is where you will find thorough discussions of such topics.\n\nThe Annotated C++ Reference Manual (Bjarne Stroustrup, Margaret A. Ellis) This book is quite outdated in the fact that it explores the 1989 C++ 2.0 version - Templates, exceptions, namespaces and new casts were not yet introduced. Saying that however, this book goes through the entire C++ standard of the time explaining the rationale, the possible implementations, and features of the language. This is not a book to learn programming principles and patterns on C++, but to understand every aspect of the C++ language.\n\nThinking in C++ (Bruce Eckel, 2nd Edition, 2000). Two volumes; is a tutorial style free set of intro level books. Downloads: vol 1, vol 2. Unfortunately they're marred by a number of trivial errors (e.g. maintaining that temporaries are automatically const), with no official errata list. A partial 3rd party errata list is available at http://www.computersciencelab.com/Eckel.htm, but it is apparently not maintained.\n\nScientific and Engineering C++: An Introduction to Advanced Techniques and Examples (John Barton and Lee Nackman) It is a comprehensive and very detailed book that tried to explain and make use of all the features available in C++, in the context of numerical methods. It introduced at the time several new techniques, such as the Curiously Recurring Template Pattern (CRTP, also called Barton-Nackman trick). It pioneered several techniques such as dimensional analysis and automatic differentiation. It came with a lot of compilable and useful code, ranging from an expression parser to a Lapack wrapper. The code is still available online. Unfortunately, the books have become somewhat outdated in the style and C++ features, however, it was an incredible tour-de-force at the time (1994, pre-STL). The chapters on dynamics inheritance are a bit complicated to understand and not very useful. An updated version of this classic book that includes move semantics and the lessons learned from the STL would be very nice.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 22:53\ncommunity wiki\n\n\n100 revs, 77 users 16%\nGeorge Stocker","comments":["@G Rassovsky: All books which promise to teach X in Y hours. For example Learn C++ in 24 hours. I believe all such books are better avoided.","I hate to step on anybody's shoes, but I do not recommend Bruce Eckel's \"Thinking in C++\" even though I respect the author for publishing his materials online for free. The book's perspective suggests relatively poor or ineffective use of C++ and \"object oriented\" programming, akin to poor application of the GoF Design Patterns. I found it an interesting introductory book to programming in general, but as someone becomes more familiarized with programming and (especially) computer science as a whole, I find books which think purely in \"classic\" OOP terms detrimental to education.","@G.Rassovsky on the accu.org website, there's a book reviews section with ratings. You can search for the C++ ones. Many of them are rated \"not recommended\".","Accelerated C++ is from 2000. Should I worry that it's out of date?","I think it would be good to put the dates published for the edition (with the edition number where applicable)."]}]},{"id":"7244321","href":"https://stackoverflow.com/questions/7244321/how-do-i-update-or-sync-a-forked-repository-on-github","title":"How do I update or sync a forked repository on GitHub?","description":"\n                \nI forked a project, applied several fixes and created a pull request which was accepted. A few days later, another change was made by another contributor. So my fork doesn't contain that change.\nHow can I get that change into my fork? Do I need to delete and re-create my fork when I have further changes to contribute? Or is there an update button?\n    ","questionComments":["This can also be done from the github UI. I'd like to give credit [to this other poster][1]. [1]: stackoverflow.com/a/21131381/728141","Another good blog post on this - Keeping A GitHub Fork Updated","Found this in Github help articles: help.github.com/articles/syncing-a-fork","Is this a duplicate of stackoverflow.com/questions/3903817/… ?","Here you go - github.com/KirstieJane/STEMMRoleModels/wiki/…. Simple and easy"],"answers":[{"answer":"In your local clone of your forked repository, you can add the original GitHub repository as a \"remote\". (\"Remotes\" are like nicknames for the URLs of repositories - origin is one, for example.) Then you can fetch all the branches from that upstream repository, and rebase your work to continue working on the upstream version. In terms of commands that might look like:\n\n# Add the remote, call it \"upstream\":\n\ngit remote add upstream https://github.com/whoever/whatever.git\n\n# Fetch all the branches of that remote into remote-tracking branches\n\ngit fetch upstream\n\n# Make sure that you're on your master branch:\n\ngit checkout master\n\n# Rewrite your master branch so that any commits of yours that\n# aren't already in upstream/master are replayed on top of that\n# other branch:\n\ngit rebase upstream/master\n\n\nIf you don't want to rewrite the history of your master branch, (for example because other people may have cloned it) then you should replace the last command with git merge upstream/master. However, for making further pull requests that are as clean as possible, it's probably better to rebase.\n\nIf you've rebased your branch onto upstream/master you may need to force the push in order to push it to your own forked repository on GitHub. You'd do that with:\n\ngit push -f origin master\n\n\nYou only need to use the -f the first time after you've rebased.\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '20 at 10:50\nCommunity♦\n11\n1 silver badge\nanswered Aug 30 '11 at 14:01\nMark Longair\n393k68\n68 gold badges\n396\n396 silver badges\n320\n320 bronze badges","comments":["As your fork only exists on github, and github does not have tools for doing merges through the web interface, then the right answer is to do the upstream merge locally and push the changes back to your fork.","Here is a great tutorial I found on working with github: gun.io/blog/how-to-github-fork-branch-and-pull-request","A quick note that rather than having to rebase your own master branch to ensure you are starting with clean state, you should probably work on a separate branch and make a pull request from that. This keeps your master clean for any future merges and it stops you from having to rewrite history with -f which messes up everyone that could have cloned your version.","Another Git failure. If this tools is supposed to support distributed collaboration, then why is it so difficult to perform a basic workflow? 4 million people and 2200 upvotes mean the tool failed. \"you can add the original GitHub repository as a \"remote\" - Why does one even have to do this? Why is it not done during the fork? What is so broken about this tool?","@jww: You ask why Git needs to be told about the original GitHub repository. It is because Git is a decentralized version control system and is not tied to GitHub in any way; it is probably obvious that Git was created before GitHub. When you create a forked repository on GitHub and clone it, GitHub knows that the repository is a fork; Git has no reason to, and does not. (Why doesn't the clone copy the Git remotes? Git is decentralized; different people will want different remotes; it would make no sense to do this.) See github.com/github/hub for GitHub integration in Git."]},{"answer":"Starting in May 2014, it is possible to update a fork directly from GitHub. This still works as of September 2017, BUT it will lead to a dirty commit history.\n\nOpen your fork on GitHub.\nClick on Pull Requests.\nClick on New Pull Request. By default, GitHub will compare the original with your fork, and there shouldn't be anything to compare if you didn't make any changes.\nClick switching the base if you see that link. Otherwise, manually set the base fork drop down to your fork, and the head fork to the upstream. Now GitHub will compare your fork with the original, and you should see all the latest changes. \nCreate pull request and assign a predictable name to your pull request (e.g., Update from original).\nScroll down to Merge pull request, but don't click anything yet.\n\nNow you have three options, but each will lead to a less-than-clean commit history.\n\nThe default will create an ugly merge commit.\nIf you click the dropdown and choose \"Squash and merge\", all intervening commits will be squashed into one. This is most often something you don't want.\nIf you click Rebase and merge, all commits will be made \"with\" you, the original PRs will link to your PR, and GitHub will display This branch is X commits ahead, Y commits behind <original fork>.\n\nSo yes, you can keep your repo updated with its upstream using the GitHub web UI, but doing so will sully your commit history. Stick to the command line instead - it's easy.\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '17 at 20:41\nMD XF\n7,1807\n7 gold badges\n34\n34 silver badges\n64\n64 bronze badges\nanswered May 25 '14 at 7:31\nlobzik\n10.5k1\n1 gold badge\n25\n25 silver badges\n32\n32 bronze badges","comments":["This worked great one time. The second time this process did not work the same way: the \"Switching the base\" link did not show up. And when I hit \"Click to create a pull request\" it created a PR on the SOURCE repo. NOT what I wanted..","Still works (Marchi 2015), all though the \"Switching the base\" link is no longer there. You have to change the \"Base\" drop down's so both point to your fork and then you'll get a prompt to \"Compare across repos\", which will take you to where you want.","April 2015. Works. Thanks. I did get \"Switching to base\". However, step 6 was \"Create pull request\" -> enter comment -> \"Create pull request\". End up with 1 commit ahead of original.","@cartland (or others) - yes, it says \"This branch is 1 commit ahead of ...\" Is this something to worry about? Is it possible to get rid of that message?","wouldnt it be better, with a simply update or sync button!"]},{"answer":"Here is GitHub's official document on Syncing a fork:\n\nSyncing a fork\nThe Setup\n\nBefore you can sync, you need to add a remote that points to the upstream repository. You may have done this when you originally forked.\n\nTip: Syncing your fork only updates your local copy of the repository; it does not update your repository on GitHub.\n\n$ git remote -v\n# List the current remotes\norigin  https://github.com/user/repo.git (fetch)\norigin  https://github.com/user/repo.git (push)\n\n$ git remote add upstream https://github.com/otheruser/repo.git\n# Set a new remote\n\n$ git remote -v\n# Verify new remote\norigin    https://github.com/user/repo.git (fetch)\norigin    https://github.com/user/repo.git (push)\nupstream  https://github.com/otheruser/repo.git (fetch)\nupstream  https://github.com/otheruser/repo.git (push)\n\nSyncing\n\nThere are two steps required to sync your repository with the upstream: first you must fetch from the remote, then you must merge the desired branch into your local branch.\n\nFetching\n\nFetching from the remote repository will bring in its branches and their respective commits. These are stored in your local repository under special branches.\n\n$ git fetch upstream\n# Grab the upstream remote's branches\nremote: Counting objects: 75, done.\nremote: Compressing objects: 100% (53/53), done.\nremote: Total 62 (delta 27), reused 44 (delta 9)\nUnpacking objects: 100% (62/62), done.\nFrom https://github.com/otheruser/repo\n * [new branch]      master     -> upstream/master\n\n\nWe now have the upstream's master branch stored in a local branch, upstream/master\n\n$ git branch -va\n# List all local and remote-tracking branches\n* master                  a422352 My local commit\n  remotes/origin/HEAD     -> origin/master\n  remotes/origin/master   a422352 My local commit\n  remotes/upstream/master 5fdff0f Some upstream commit\n\nMerging\n\nNow that we have fetched the upstream repository, we want to merge its changes into our local branch. This will bring that branch into sync with the upstream, without losing our local changes.\n\n$ git checkout master\n# Check out our local master branch\nSwitched to branch 'master'\n\n$ git merge upstream/master\n# Merge upstream's master into our own\nUpdating a422352..5fdff0f\nFast-forward\n README                    |    9 -------\n README.md                 |    7 ++++++\n 2 files changed, 7 insertions(+), 9 deletions(-)\n delete mode 100644 README\n create mode 100644 README.md\n\n\nIf your local branch didn't have any unique commits, git will instead perform a \"fast-forward\":\n\n$ git merge upstream/master\nUpdating 34e91da..16c56ad\nFast-forward\n README.md                 |    5 +++--\n 1 file changed, 3 insertions(+), 2 deletions(-)\n\n\nTip: If you want to update your repository on GitHub, follow the instructions here\n\nShare\nImprove this answer\nFollow\nedited Sep 21 '15 at 19:38\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 21 '13 at 23:04\njumpnett\n6,1871\n1 gold badge\n17\n17 silver badges\n24\n24 bronze badges","comments":["This updates my local fork, but my fork on Github.com still says \"43 commits behind\". I had to use lobzik's technique to create a pull request for myself to merge the master changes into my Github.com fork.","@MichaelMcGinnis After merging locally, you would have to push your changes to github. git push origin master","Might be smart to push with --follow-tags: stackoverflow.com/a/26438076/667847","I have to do it for all branches separately git merge upstream/master, then check out to develop branch and do git merge upstream/develop","This helped. The merging chapter ist important for me."]},{"answer":"A lot of answers end up moving your fork one commit ahead of the parent repository. This answer summarizes the steps found here which will move your fork to the same commit as the parent.\n\nChange directory to your local repository.\n\nSwitch to master branch if you are not git checkout master\n\nAdd the parent as a remote repository, git remote add upstream <repo-location>\n\nIssue git fetch upstream\n\nIssue git rebase upstream/master\n\nAt this stage you check that commits what will be merged by typing git status\n\nIssue git push origin master\n\nFor more information about these commands, refer to step 3.\n\nShare\nImprove this answer\nFollow\nedited Apr 19 '16 at 4:49\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 5 '15 at 14:59\nSahar Rabinoviz\n1,8191\n1 gold badge\n14\n14 silver badges\n26\n26 bronze badges","comments":["@MT: Where do you enter these commands, though? The gist of the question, as I understand it, is how to resynchronize your personal GitHub fork with the main project, and do this all from GitHub. In other words, how can you update your remote fork without a local repository?","@JohnY Using GitHub will always create an extra commit. You need to do all this in a shell on a local repo to avoid that extra commit."]},{"answer":"If, like me, you never commit anything directly to master, which you should really, you can do the following.\n\nFrom the local clone of your fork, create your upstream remote. You only need to do that once:\n\ngit remote add upstream https://github.com/whoever/whatever.git\n\n\nThen whenever you want to catch up with the upstream repository master branch you need to:\n\ngit checkout master\ngit pull upstream master\n\n\nAssuming you never committed anything on master yourself you should be done already. Now you can push your local master to your origin remote GitHub fork. You could also rebase your development branch on your now up-to-date local master.\n\nPast the initial upstream setup and master checkout, all you need to do is run the following command to sync your master with upstream: git pull upstream master.\n\nShare\nImprove this answer\nFollow\nedited May 18 '19 at 16:55\nanswered Jan 3 '17 at 16:59\nSlion\n1,52716\n16 silver badges\n19\n19 bronze badges","comments":["\"You could also rebase your development branch on your now up-to-date local master.\" How can I do this?","First run git checkout my-dev-branch to switch to your dev branch then git rebase master. You could also just run git rebase master my-dev-branch which basically combine those two commands. See git rebase docs."]},{"answer":"Foreword: Your fork is the \"origin\" and the repository you forked from is the \"upstream\".\n\nLet's assume that you cloned already your fork to your computer with a command like this:\n\ngit clone git@github.com:your_name/project_name.git\ncd project_name\n\n\nIf that is given then you need to continue in this order:\n\nAdd the \"upstream\" to your cloned repository (\"origin\"):\n\ngit remote add upstream git@github.com:original_author/project_name.git\n\n\nFetch the commits (and branches) from the \"upstream\":\n\ngit fetch upstream\n\n\nSwitch to the \"master\" branch of your fork (\"origin\"):\n\ngit checkout master\n\n\nStash the changes of your \"master\" branch:\n\ngit stash\n\n\nMerge the changes from the \"master\" branch of the \"upstream\" into your the \"master\" branch of your \"origin\":\n\ngit merge upstream/master\n\n\nResolve merge conflicts if any and commit your merge\n\ngit commit -am \"Merged from upstream\"\n\n\nPush the changes to your fork\n\ngit push\n\n\nGet back your stashed changes (if any)\n\ngit stash pop\n\n\nYou're done! Congratulations!\n\nGitHub also provides instructions for this topic: Syncing a fork\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '16 at 13:53\nanswered Mar 16 '16 at 12:24\nBenny Neugebauer\n41.8k21\n21 gold badges\n200\n200 silver badges\n181\n181 bronze badges","comments":["Helped partly: Is git remote add upstream git@github.com:original_author/project_name.git just an alias for git remote add upstream https://github.com/original_author/project_name.git ?","Wolf, guessing you know this by now, but for posterity... It is the format for ssh. help.github.com/articles/configuring-a-remote-for-a-fork","Thank you very much. git stash and git stash pop part very helpful","This worked. After git merge upstream/master, auto merge failed due to unmerged paths which I had to run git add -A then git commit -m \"message\" then it was up to date."]},{"answer":"Since November 2013 there has been an unofficial feature request open with GitHub to ask them to add a very simple and intuitive method to keep a local fork in sync with upstream:\n\nhttps://github.com/isaacs/github/issues/121\n\nNote: Since the feature request is unofficial it is also advisable to contact support@github.com to add your support for a feature like this to be implemented. The unofficial feature request above could be used as evidence of the amount of interest in this being implemented.\n\nShare\nImprove this answer\nFollow\nedited Apr 19 '16 at 4:50\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 21 '16 at 10:42\nisedwards\n2,10716\n16 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"As of the date of this answer, GitHub has not (or shall I say no longer?) this feature in the web interface. You can, however, ask support@github.com to add your vote for that.\n\nIn the meantime, GitHub user bardiharborow has created a tool to do just this: https://upriver.github.io/\n\nSource is here: https://github.com/upriver/upriver.github.io\n\nShare\nImprove this answer\nFollow\nanswered Sep 14 '16 at 14:22\nLucero\n56.9k6\n6 gold badges\n112\n112 silver badges\n151\n151 bronze badges","comments":["While I do find the tool a good idea the reality is that's BROKEN. It did load only 20 repos from my account and even the footer redirects to a website that does not exists. If that's fixed I will be a big advocate.","As of today, I have successfully used upriver to sync a fork with the upstream repo, so it's working for my purposes and I will continue to use it.","@sorin These 20 repo/branch limitation (rather, it is 30 now) comes from the GitHub default paging settings. There needs to be some adaptions to the code in order to handle this."]},{"answer":"If you are using GitHub for Windows or Mac then now they have a one-click feature to update forks:\n\nSelect the repository in the UI.\nClick \"Update from user/branch\" button the top.\nShare\nImprove this answer\nFollow\nedited Nov 21 '19 at 1:51\nanswered Mar 31 '16 at 21:45\nShital Shah\n49.5k10\n10 gold badges\n196\n196 silver badges\n162\n162 bronze badges","comments":["Step by step: github.com/desktop/desktop/issues/1785#issuecomment-483011281"]},{"answer":"There's a way to do it from GitHub's webapp.\n\nLet's go through the following example.\n\nTo start with, open the repo that you want to update.\n\nOne can see the warning\n\nThis branch is 157 commits behind GoogleCloudPlatform:master.\n\nOn the right there are two buttons Pull request and Compare. Press Compare.\n\nAs there is probably nothing to compare, press switching the base\n\nA list of all the changes will appear and one can create a pull request by pressing the button Create pull request\n\nGive it a title, let's say \"Update repo\"\n\nAnd create the pull request.\n\nOnce the request is created, scroll to the bottom and press Merge pull request.\n\nConfirm the merge and that's it!\n\nShare\nImprove this answer\nFollow\nanswered Dec 22 '20 at 0:46\nGonçalo Peres 龚燿禄\n4,6273\n3 gold badges\n24\n24 silver badges\n52\n52 bronze badges","comments":["Thanks a lot ! Its as simple as that !","Be aware of the above, and take a look here: github.community/t/…"]},{"answer":"Actually, it is possible to create a branch in your fork from any commit of the upstream in the browser:\n\nOpen https://github.com/<repo>/commits/<hash>, where repo is your fork, and hash is full hash of commit which you can find in the upstream web interface. For example, I can open https://github.com/max630/linux/commits/0aa0313f9d576affd7747cc3f179feb097d28990, which points to linux master as time of writing.\nClick on the \"Tree: ....\" button.\nType name of the new branch and press Enter\n\nYou can then fetch that branch to your local clone, and you won't have to push all that data back to GitHub when you push edits on top of that commit. Or use the web interface to change something in that branch.\n\nHow it works (it is a guess, I don't know how exactly GitHub does it): forks share object storage and use namespaces to separate users' references. So you can access all commits through your fork, even if they did not exist by the time of forking.\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '18 at 3:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 18 '17 at 6:41\nmax630\n7,4662\n2 gold badges\n24\n24 silver badges\n49\n49 bronze badges","comments":["This is great! This avoids the totally pointless upload of those commits to github."]},{"answer":"I update my forked repos with this one line:\n\ngit pull https://github.com/forkuser/forkedrepo.git branch\n\n\nUse this if you dont want to add another remote endpoint to your project, as other solutions posted here.\n\nShare\nImprove this answer\nFollow\nanswered Sep 8 '17 at 2:00\nRafael Z. B. Bravo\n8938\n8 silver badges\n17\n17 bronze badges","comments":["Are there limitations on this? i.e. does it apply only to cases where you have not added commits, merges, pull requests, or had pull requests merged into upstream since the last update?","it does work like a normal pull from a remote branch. If you did X commits on your local repo and now you are Y commits behind the original repo, it will bring the Y commits to your local branch and, probably, get you some conflicts to resolve.","@LightCC This is not different than pulling from a previously added remote at all, except for the fact that you haven't added a remote. So the disadvantage is that you'll have to enter the full repository URL everytime you want to pull.","This is a perfect solution if you don't have to pull many times from the original repo, or the project forked is relatively simple."]},{"answer":"GitHub has now introduced a feature to sync a fork with the click of a button.\n\nGo to your fork, click on Fetch upstream and then click on Fetch and merge to directly sync your fork with its parent repo.\n\nYou may also click on the Compare button to compare the changes before merging.\n\nReference: GitHub's tweet\n\nShare\nImprove this answer\nFollow\nanswered May 6 at 21:10\nMadhu Bhat\n9,0651\n1 gold badge\n19\n19 silver badges\n44\n44 bronze badges","comments":["I tried this and no PR was created, cool! And if your branch can be synced with a fast-forward merge, no divergence will occur.","For now, this function will first compare the branch name between the original and the forked repos. If the same name is found, the upstream of the branch in the fork is the branch with the same name in the original; if it is not found, the upstream will be the default branch (HEAD) of the original. This works fine in most cases, but if some branch modification has occurred in the original repo (e.g., adding or deleting a branch with the same name which already exists in the forked repo, or changing the default branch), the result of the sync may not match you expectations."]},{"answer":"Follow the below steps. I tried them and it helped me.\n\nCheckout to your branch\n\nSyntax: git branch yourDevelopmentBranch\nExample: git checkout master\n\nPull source repository branch for getting the latest code\n\nSyntax: git pull https://github.com/tastejs/awesome-app-ideas master\nExample: git pull https://github.com/ORIGINAL_OWNER/ORIGINAL_REPO.git BRANCH_NAME\n\nShare\nImprove this answer\nFollow\nedited Apr 19 '16 at 4:49\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 15 '16 at 12:31\nVenkat.R\n6,7165\n5 gold badges\n35\n35 silver badges\n57\n57 bronze badges","comments":["If you're using GitHub, you might also want to push your changes to your GitHub branch. git push HttpsForYourForkOfTheRepo BRANCH_NAME"]},{"answer":"As a complement to this answer, I was looking for a way to update all remote branches of my cloned repo (origin) from upstream branches in one go. This is how I did it.\n\nThis assumes you have already configured an upstream remote pointing at the source repository (where origin was forked from) and have synced it with git fetch upstream.\n\nThen run:\n\nfor branch in $(git ls-remote --heads upstream|sed 's#^.*refs/heads/##'); do git push origin refs/remotes/upstream/$branch:refs/heads/$branch; done\n\n\nThe first part of this command lists all heads in the upstream remote repo and removes the SHA-1 followed by refs/heads/ branch name prefix.\n\nThen for each of these branches, it pushes the local copy of the upstream remote tracking branch (refs/remotes/upstream/<branch> on local side) directly to the remote branch on origin (refs/heads/<branch> on remote side).\n\nAny of these branch sync commands may fail for one of two reasons: either the upstream branch have been rewritten, or you have pushed commits on that branch to your fork. In the first case where you haven't committed anything to the branch on your fork it is safe to push forcefully (Add the -f switch; i.e. git push -f in the command above). In the other case this is normal as your fork branch have diverged and you can't expect the sync command to work until your commits have been merged back into upstream.\n\nShare\nImprove this answer\nFollow\nedited Jun 8 '18 at 4:31\nanswered Jun 12 '17 at 20:17\nThomas Guyot-Sionnest\n1,67217\n17 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"The \"Pull\" app is an automatic set-up-and-forget solution. It will sync the default branch of your fork with the upstream repository.\n\nVisit the URL, click the green \"Install\" button and select the repositories where you want to enable automatic synchronization.\n\nThe branch is updated once per hour directly on GitHub, on your local machine you need to pull the master branch to ensure that your local copy is in sync.\n\nShare\nImprove this answer\nFollow\nanswered Nov 20 '19 at 23:53\nkrlmlr\n22.5k13\n13 gold badges\n108\n108 silver badges\n194\n194 bronze badges","comments":["Please note that with the basic setup, you can lose the changes made in your forked repository. To keep the changes, set up a config file and specify a mergemethod. More on this here","I did note that the basic setup sends pull requests and merges them (as opposed to what's stated in the documentation). This is slightly annoying but solves the data loss problem?"]},{"answer":"If you set your upstream. Check with git remote -v, then this will suffice.\n\ngit fetch upstream\ngit checkout master\ngit merge --no-edit upstream/master\ngit push\n\nShare\nImprove this answer\nFollow\nanswered Jun 11 '19 at 5:32\nprosti\n28.7k8\n8 gold badges\n136\n136 silver badges\n126\n126 bronze badges","comments":[]},{"answer":"When you have cloned your forked repository, go to the directory path where your clone resides and the few lines in your Git Bash Terminal.\n\n$ cd project-name\n\n$ git remote add upstream https://github.com/user-name/project-name.git\n # Adding the upstream -> the main repo with which you wanna sync\n\n$ git remote -v # you will see the upstream here \n\n$ git checkout master # see if you are already on master branch\n\n$ git fetch upstream\n\n\nAnd there you are good to go. All updated changes in the main repository will be pushed into your fork repository.\n\nThe \"fetch\" command is indispensable for staying up-to-date in a project: only when performing a \"git fetch\" will you be informed about the changes your colleagues pushed to the remote server.\n\nYou can still visit here for further queries\n\nShare\nImprove this answer\nFollow\nanswered Mar 10 '18 at 2:21\nPrateek Chanda\n1413\n3 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"Android Studio now has learned to work with GitHub fork repositories (you don't even have to add \"upstream\" remote repository by console command).\n\nOpen menu VCS → Git\n\nAnd pay attention to the two last popup menu items:\n\nRebase my GitHub fork\n\nCreate Pull Request\n\nTry them. I use the first one to synchronize my local repository. Anyway the branches from the parent remote repository (\"upstream\") will be accessible in Android Studio after you click \"Rebase my GitHub fork\", and you will be able to operate with them easily.\n\n(I use Android Studio 3.0 with \"Git integration\" and \"GitHub\" plugins.)\n\nShare\nImprove this answer\nFollow\nedited Jan 19 '18 at 3:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 13 '17 at 20:03\nalexshr\n9398\n8 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"That depends on the size of your repository and how you forked it.\n\nIf it's quite a big repository you may have wanted to manage it in a special way (e.g. drop history). Basically, you can get differences between current and upstream versions, commit them and then cherry pick back to master.\n\nTry reading this one. It describes how to handle big Git repositories and how to upstream them with latest changes.\n\nShare\nImprove this answer\nFollow\nedited Nov 3 '18 at 19:35\nitsmysterybox\n2,3383\n3 gold badges\n18\n18 silver badges\n25\n25 bronze badges\nanswered Apr 23 '17 at 12:47\ns0nicYouth\n3582\n2 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"I would like to add on to @krlmlr's answer.\n\nInitially, the forked repository has one branch named : master. If you are working on a new feature or a fix, you would generally create a new branch feature and make the changes.\n\nIf you want the forked repository to be in sync with the parent repository, you could set up a config file(pull.yml) for the Pull app (in the feature branch), like this:\n\nversion: \"1\"\nrules:\n  - base: feature\n    upstream: master\n    mergeMethod: merge\n  - base: master\n    upstream: parent_repo:master\n    mergeMethod: hardreset\n\n\nThis keeps the master branch of the forked repo up-to-date with the parent repo. It keeps the feature branch of the forked repo updated via the master branch of the forked repo by merging the same. This assumes that the feature branch is the default branch which contains the config file.\n\nHere two mergemethods are into play, one is hardreset which helps force sync changes in the master branch of the forked repo with the parent repo and the other method is merge. This method is used to merge changes done by you in the feature branch and changes done due to force sync in the master branch. In case of merge conflict, the pull app will allow you to choose the next course of action during the pull request.\n\nYou can read about basic and advanced configs and various mergemethods here.\n\nI am currently using this configuration in my forked repo here to make sure an enhancement requested here stays updated.\n\nShare\nImprove this answer\nFollow\nanswered Nov 21 '19 at 2:44\nSaurabh P Bhandari\n4,5361\n1 gold badge\n10\n10 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"Assuming your fork is https://github.com/me/foobar and original repository is https://github.com/someone/foobar\n\nVisit https://github.com/me/foobar/compare/master...someone:master\n\nIf you see green text Able to merge then press Create pull request\n\nOn the next page, scroll to the bottom of the page and click Merge pull request and Confirm merge.\n\nShare\nImprove this answer\nFollow\nanswered Feb 18 at 16:31\nIlyich\n2,5121\n1 gold badge\n22\n22 silver badges\n20\n20 bronze badges","comments":["You deserve an award. Nice answer. This worked for me and I think is pretty normal. I went and did a git pull after on my local repo and updated. Your instructions are good. To someone new, you will have to play with the dropdown lists on the compare screen first to get the arrow to go the correct direction. This gives you the github.com/myside...theirside correct link in the address bar.","Nobel Prize for this man & solution!"]},{"answer":"There are two main things on keeping a forked repository always update for good.\n\n1. Create the branches from the fork master and do changes there.\n\nSo when your Pull Request is accepted then you can safely delete the branch as your contributed code will be then live in your master of your forked repository when you update it with the upstream. By this your master will always be in clean condition to create a new branch to do another change.\n\n2. Create a scheduled job for the fork master to do update automatically.\n\nThis can be done with cron. Here is for an example code if you do it in linux.\n\n$ crontab -e\n\n\nput this code on the crontab file to execute the job in hourly basis.\n\n0 * * * * sh ~/cron.sh\n\n\nthen create the cron.sh script file and a git interaction with ssh-agent and/or expect as below\n\n#!/bin/sh\nWORKDIR=/path/to/your/dir   \nREPOSITORY=<name of your repo>\nMASTER=\"git@github.com:<username>/$REPOSITORY.git\"   \nUPSTREAM=git@github.com:<upstream>/<name of the repo>.git  \n\ncd $WORKDIR && rm -rf $REPOSITORY\neval `ssh-agent` && expect ~/.ssh/agent && ssh-add -l\ngit clone $MASTER && cd $REPOSITORY && git checkout master\ngit remote add upstream $UPSTREAM && git fetch --prune upstream\nif [ `git rev-list HEAD...upstream/master --count` -eq 0 ]\nthen\n    echo \"all the same, do nothing\"\nelse\n    echo \"update exist, do rebase!\"\n    git reset --hard upstream/master\n    git push origin master --force\nfi\ncd $WORKDIR && rm -rf $REPOSITORY\neval `ssh-agent -k`\n\n\nCheck your forked repository. From time to time it will always show this notification:\n\nThis branch is even with <upstream>:master.\n\nShare\nImprove this answer\nFollow\nedited Jun 8 '19 at 13:34\nanswered Jun 8 '19 at 7:33\nChetabahana\n8,0743\n3 gold badges\n53\n53 silver badges\n71\n71 bronze badges","comments":[]},{"answer":"Use these commands (in lucky case)\n\ngit remote -v\ngit pull\ngit fetch upstream\ngit checkout master\ngit merge upstream/master --no-ff\ngit add .\ngit commit -m\"Sync with upstream repository.\"\ngit push -v\n\nShare\nImprove this answer\nFollow\nanswered Feb 9 '20 at 2:20\nDo Nhu Vy\n34.7k37\n37 gold badges\n151\n151 silver badges\n209\n209 bronze badges","comments":["If there's a conflict then one'd only need to resolve those after the merge command and mark the resolves by git add command for the conflicted files. Also, if the repo in question is a forked one someone has to first define the upstream: git remote add upstream https://...git where the git is for the repo which got forked.","Also, GitHub's PR (the UI Fetch button creates the PR against the fork repo) is a shitshow if there's a conflict. I'd rather just go with these manual steps."]},{"answer":"rm -rf oldrepository\ngit clone ...\n\n\nThere may be subtler options, but it is the only way that I have any confidence that my local repository is the same as upstream.\n\nShare\nImprove this answer\nFollow\nanswered Sep 29 '20 at 3:37\nTuntable\n2,2791\n1 gold badge\n19\n19 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"Try this, Click on \"Fetch upstream\" to sync your forked repo from upstream master. \n\nShare\nImprove this answer\nFollow\nanswered May 25 at 6:46\nKumar Gaurav\n8694\n4 gold badges\n18\n18 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"If you use GitHub Desktop, you can do it easily in just 6 steps (actually only 5).\n\nOnce you open Github Desktop and choose your repository,\n\nGo to History tab\nClick on the search bar. It will show you all the available branches (including upstream branches from parent repository)\nSelect the respective upstream branch (it will be upstream/master to sync master branch)\n(OPTIONAL) It will show you all the commits in the upstream branch. You can click on any commit to see the changes.\nClick Merge in master / branch-name, based on your active branch.\nWait for GitHub Desktop to do the magic.\n\nCheckout the GIF below as an example:\n\nShare\nImprove this answer\nFollow\nanswered Nov 17 '20 at 12:03\nGangula\n1,4591\n1 gold badge\n7\n7 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"If you want to keep your GitHub forks up to date with the respective upstreams, there also exists this probot program for GitHub specifically: https://probot.github.io/apps/pull/ which does the job. You would need to allow installation in your account and it will keep your forks up to date.\n\nShare\nImprove this answer\nFollow\nanswered Jan 18 at 17:36\nmetanerd\n5451\n1 gold badge\n5\n5 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"How to update your forked repo on your local machine?\n\nFirst, check your remote/master\n\ngit remote -v\n\n\nYou should have origin and upstream. For example:\n\norigin  https://github.com/your___name/kredis.git (fetch)\norigin  https://github.com/your___name/kredis.git (push)\nupstream    https://github.com/rails/kredis.git (fetch)\nupstream    https://github.com/rails/kredis.git (push)\n\n\nAfter that go to main:\n\ngit checkout main\n\n\nand merge from upstream to main:\n\ngit merge upstream/main\n\nShare\nImprove this answer\nFollow\nanswered Feb 4 at 18:57\nAlexSh\n1,02311\n11 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"$ git remote add upstream https://github.com/....\n\n$ git pull upstream main\n\n$ git push\n\nShare\nImprove this answer\nFollow\nedited Mar 4 at 13:03\nanswered Mar 3 at 20:14\nDavid Odhiambo\n5695\n5 silver badges\n14\n14 bronze badges","comments":[]}]},{"id":"5189560","href":"https://stackoverflow.com/questions/5189560/squash-my-last-x-commits-together-using-git","title":"Squash my last X commits together using Git","description":"\n                \nHow can I squash my last X commits together into one commit using Git?\n    ","questionComments":["Related: Git - combining multiple commits before pushing.","@matt TortoiseGit is your tool. It provides a single function \"Combine to one commit\" which will call all steps automatically in the background. Unfortunately only available for Windows. See my answer below.","For squashing upto THE first commit see this - stackoverflow.com/questions/1657017/…","post squash one need to do force push stackoverflow.com/questions/10298291/…","In addition to the posted answers, GUI clients can do this easily. I can squash dozens of commits in GitKraken with only four clicks."],"answers":[{"answer":"Use git rebase -i <after-this-commit> and replace \"pick\" on the second and subsequent commits with \"squash\" or \"fixup\", as described in the manual.\n\nIn this example, <after-this-commit> is either the SHA1 hash or the relative location from the HEAD of the current branch from which commits are analyzed for the rebase command. For example, if the user wishes to view 5 commits from the current HEAD in the past the command is git rebase -i HEAD~5.\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '16 at 6:16\nJ4cK\n28.7k8\n8 gold badges\n39\n39 silver badges\n54\n54 bronze badges\nanswered Mar 4 '11 at 4:18\nAnomie\n87.3k13\n13 gold badges\n122\n122 silver badges\n143\n143 bronze badges","comments":["This, I think, answers this question a bit better stackoverflow.com/a/5201642/295797","What is meant by <after-this-commit>?","<after-this-commit> is commit X+1 i.e. parent of the oldest commit you want to squash.","The difference between this rebase -i approach and reset --soft is, rebase -iallows me to retain the commit author, while reset --soft allows me to recommit. Sometimes i need to squash commits of pull requests yet maintaining the author information. Sometimes i need to reset soft on my own commits. Upvotes to both great answers anyways.","Use git rebase -i <after-this-commit> and replace \"pick\" on the second and subsequent commits with \"squash\" or \"fixup\", as described in the manual. uhhhh... wut?"]},{"answer":"You can do this fairly easily without git rebase or git merge --squash. In this example, we'll squash the last 3 commits.\n\nIf you want to write the new commit message from scratch, this suffices:\n\ngit reset --soft HEAD~3 &&\ngit commit\n\n\nIf you want to start editing the new commit message with a concatenation of the existing commit messages (i.e. similar to what a pick/squash/squash/…/squash git rebase -i instruction list would start you with), then you need to extract those messages and pass them to git commit:\n\ngit reset --soft HEAD~3 && \ngit commit --edit -m\"$(git log --format=%B --reverse HEAD..HEAD@{1})\"\n\n\nBoth of those methods squash the last three commits into a single new commit in the same way. The soft reset just re-points HEAD to the last commit that you do not want to squash. Neither the index nor the working tree are touched by the soft reset, leaving the index in the desired state for your new commit (i.e. it already has all the changes from the commits that you are about to “throw away”).\n\nShare\nImprove this answer\nFollow\nedited Mar 19 '15 at 14:40\niwasrobbed\n45.3k20\n20 gold badges\n143\n143 silver badges\n191\n191 bronze badges\nanswered Mar 5 '11 at 4:19\nChris Johnsen\n192k24\n24 gold badges\n198\n198 silver badges\n183\n183 bronze badges","comments":["Ha! I like this method. It is the one closes to the spirit of the problem. It's a pity that it requires so much voodoo. Something like this should be added to one of the basic commands. Possibly git rebase --squash-recent, or even git commit --amend-many.","@A-B-B: If your branch has an “upstream” set, then you may be able to use branch@{upstream} (or just @{upstream} for the current branch; in both cases, the last part can be abbreviated to @{u}; see gitrevisions). This may differ from your “last pushed commit” (e.g. if someone else pushed something that built atop your most recent push and then you fetched that), but seems like it might be close to what you want.","This kinda-sorta required me to push -f but otherwise it was lovely, thanks.","@2rs2ts git push -f sound dangerous. Take care to only squash local commits. Never touch pushed commits!","I also need to use git push --force afterwards so that it takes the commit"]},{"answer":"You can use git merge --squash for this, which is slightly more elegant than git rebase -i. Suppose you're on master and you want to squash the last 12 commits into one.\n\nWARNING: First make sure you commit your work—check that git status is clean (since git reset --hard will throw away staged and unstaged changes)\n\nThen:\n\n# Reset the current branch to the commit just before the last 12:\ngit reset --hard HEAD~12\n\n# HEAD@{1} is where the branch was just before the previous command.\n# This command sets the state of the index to be as it would just\n# after a merge from that commit:\ngit merge --squash HEAD@{1}\n\n# Commit those squashed changes.  The commit message will be helpfully\n# prepopulated with the commit messages of all the squashed commits:\ngit commit\n\n\nThe documentation for git merge describes the --squash option in more detail.\n\nUpdate: the only real advantage of this method over the simpler git reset --soft HEAD~12 && git commit suggested by Chris Johnsen in his answer is that you get the commit message prepopulated with every commit message that you're squashing.\n\nShare\nImprove this answer\nFollow\nedited Jun 1 '18 at 15:53\nErikE\n44.2k21\n21 gold badges\n140\n140 silver badges\n182\n182 bronze badges\nanswered Mar 4 '11 at 6:10\nMark Longair\n393k68\n68 gold badges\n396\n396 silver badges\n320\n320 bronze badges","comments":["You say this is more 'elegant' than git rebase -i, but you don't give a reason why. Tentatively -1ing this because it seems to me that in fact the opposite is true and this is a hack; aren't you performing more commands than necessary just in order to force git merge into doing one of the things that git rebase is specifically designed for?","@Mark Amery: There are various reasons that I said that this is more elegant. For example, it doesn't involve unnecessarily spawning an editor and then searching and replacing for a string in the \"to-do\" file. Using git merge --squash is also easier to use in a script. Essentially, the reasoning was that you don't need the \"interactivity\" of git rebase -i at all for this.","Another advantage is that git merge --squash is less likely to produce merge conflicts in the face of moves/deletes/renames compared to rebasing, especially if you're merging from a local branch. (disclaimer: based on only one experience, correct me if this isn't true in the general case!)","I'm always very reluctant when it comes to hard resets - I'd use a temporal tag instead of HEAD@{1} just to be on the safe side e.g. when your workflow is interrupted for an hour by a power outage etc.","@B T: Destroyed your commit? :( I'm not sure what you mean by that. Anything that you committed you'll easily be able to get back to from git's reflog. If you had uncommitted work, but the files were staged, you should still be able to get their contents back, although that will be more work. If your work wasn't even staged, however, I'm afraid there's little that can be done; that's why the answer says up-front: \"First check that git status is clean (since git reset --hard will throw away staged and unstaged changes)\"."]},{"answer":"I recommend avoiding git reset when possible -- especially for Git-novices. Unless you really need to automate a process based on a number of commits, there is a less exotic way...\n\nPut the to-be-squashed commits on a working branch (if they aren't already) -- use gitk for this\nCheck out the target branch (e.g. 'master')\ngit merge --squash (working branch name)\ngit commit\n\nThe commit message will be prepopulated based on the squash.\n\nShare\nImprove this answer\nFollow\nanswered Mar 14 '14 at 23:24\nBrent Bradburn\n42.1k13\n13 gold badges\n130\n130 silver badges\n140\n140 bronze badges","comments":["This is the safest method : no reset soft / hard (!!), or reflog used !","It would be great if you expanded on (1).","@Adam: Basically, this means use the GUI interface of gitk to label the line of code that you are squashing and also label the base upon which to squash to. In the normal case, both of these labels will already exist, so step (1) can be skipped.","Note that this method doesn't mark the working branch as being fully merged, so removing it requires forcing deletion. :(","For (1), I've found git branch your-feature && git reset --hard HEAD~N the most convenient way. However, it does involve git reset again, which this answer tried to avoid."]},{"answer":"Thanks to this handy blog post I found that you can use this command to squash the last 3 commits:\n\ngit rebase -i HEAD~3\n\n\nThis is handy as it works even when you are on a local branch with no tracking information/remote repo.\n\nThe command will open the interactive rebase editor which then allows you to reorder, squash, reword, etc as per normal.\n\nUsing the interactive rebase editor:\n\nThe interactive rebase editor shows the last three commits. This constraint was determined by HEAD~3 when running the command git rebase -i HEAD~3.\n\nThe most recent commit, HEAD, is displayed first on line 1. The lines starting with a # are comments/documentation.\n\nThe documentation displayed is pretty clear. On any given line you can change the command from pick to a command of your choice.\n\nI prefer to use the command fixup as this \"squashes\" the commit's changes into the commit on the line above and discards the commit's message.\n\nAs the commit on line 1 is HEAD, in most cases you would leave this as pick. You cannot use squash or fixup as there is no other commit to squash the commit into.\n\nYou may also change the order of the commits. This allows you to squash or fixup commits that are not adjacent chronologically.\n\nA practical everyday example\n\nI've recently committed a new feature. Since then, I have committed two bug fixes. But now I have discovered a bug (or maybe just a spelling error) in the new feature I committed. How annoying! I don't want a new commit polluting my commit history!\n\nThe first thing I do is fix the mistake and make a new commit with the comment squash this into my new feature!.\n\nI then run git log or gitk and get the commit SHA of the new feature (in this case 1ff9460).\n\nNext, I bring up the interactive rebase editor with git rebase -i 1ff9460~. The ~ after the commit SHA tells the editor to include that commit in the editor.\n\nNext, I move the commit containing the fix (fe7f1e0) to underneath the feature commit, and change pick to fixup.\n\nWhen closing the editor, the fix will get squashed into the feature commit and my commit history will look nice and clean!\n\nThis works well when all the commits are local, but if you try to change any commits already pushed to the remote you can really cause problems for other devs that have checked out the same branch!\n\nShare\nImprove this answer\nFollow\nedited Jan 16 '20 at 23:27\nanswered May 17 '16 at 6:19\nbr3nt\n7,3403\n3 gold badges\n36\n36 silver badges\n57\n57 bronze badges","comments":["do you have to pick the top one and squash the rest? You should edit your answer to explain how to use the interactive rebase editor in more detail","Yes, leave pick in line 1. If you choose squash or fixup for the commit on line 1, git will show a message saying \"error: cannot 'fixup' without a previous commit\". Then it will give you the option to fix it: \"You can fix this with 'git rebase --edit-todo' and then run 'git rebase --continue'.\" or you can just abort and start over: \"Or you can abort the rebase with 'git rebase --abort'.\".","I am constantly using this command. I recommend to add an alias for that called gr3: alias gr3='git rebase -i  HEAD~3'","@Timo, correct. Oldest at the top, newest at the bottom. That's why you need to pick the first line. And when you choose squash or fixup on a line, it will put the changes into the commit on the line above.","This feels like the best answer when you know that you want to squash a certain amount of commits or at least see the commits you can squash by entering some arbitrary number. Generally, I use this ."]},{"answer":"Based on Chris Johnsen's answer,\n\nAdd a global \"squash\" alias from bash: (or Git Bash on Windows)\n\ngit config --global alias.squash '!f(){ git reset --soft HEAD~${1} && git commit --edit -m\"$(git log --format=%B --reverse HEAD..HEAD@{1})\"; };f'\n\n\n... or using Windows' Command Prompt:\n\ngit config --global alias.squash \"!f(){ git reset --soft HEAD~${1} && git commit --edit -m\\\"$(git log --format=%B --reverse HEAD..HEAD@{1})\\\"; };f\"\n\n\n\nYour ~/.gitconfig should now contain this alias:\n\n[alias]\n    squash = \"!f(){ git reset --soft HEAD~${1} && git commit --edit -m\\\"$(git log --format=%B --reverse HEAD..HEAD@{1})\\\"; };f\"\n\n\n\nUsage:\n\ngit squash N\n\n\n... Which automatically squashes together the last N commits, inclusive.\n\nNote: The resultant commit message is a combination of all the squashed commits, in order. If you are unhappy with that, you can always git commit --amend to modify it manually. (Or, edit the alias to match your tastes.)\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:26\nCommunity♦\n11\n1 silver badge\nanswered Feb 19 '14 at 19:21\nEthanB\n4,0361\n1 gold badge\n25\n25 silver badges\n45\n45 bronze badges","comments":["Interesting, but I'd much rather type the squashed commit message myself, as a descriptive summary of my multiple commits, than have it auto-entered for me. So I'd rather specify git squash -m \"New summary.\" and have N determined automatically as the number of unpushed commits.","@A-B-B, This sounds like a separate question. (I don't think it's exactly what the OP was asking; I've never felt a need for it in my git squash workflow.)","This is pretty sweet. Personally I'd like a version that uses the commit message from the first of the squashed-together commits. Would be good for things like whitespace tweaks.","@funroll Agreed. Just dropping the last commit msg is a super common need for me. We should be able to devise that...","@A-B-B you can use git commit --amend to further change the message, but this alias lets you have a good start on what should be in the commit message."]},{"answer":"2020 Simple solution without rebase :\n\ngit reset --soft HEAD~2 \n\ngit commit -m \"new commit message\"\n\ngit push -f\n\n2 means the last two commits will be squashed. You can replace it by any number\n\nShare\nImprove this answer\nFollow\nedited Sep 30 '20 at 8:39\nanswered Apr 12 '20 at 12:14\nXys\n4,1511\n1 gold badge\n28\n28 silver badges\n39\n39 bronze badges","comments":["This solution shouldn't be encouraged. Using the-f   (force) option in push is a dangerous practice, particularly if you're pushing to a shared repo (i.e public history) that'll make life dfficult for contributors","works good for the personal feature branches, should not be used on the branches where multiple people work, but I'd say latter may be in some cases just bad organization.","if the goal is to add this new commit to master as part of an ongoing pr, you could use git reset --soft $(git merge-base feature master) and then git commit.","@FXQuantTrader when you git rebase -i you have to force-push too, don't you? Unless you're not using --force-with-lease I don't think there's any harm in that solution.","@FXQuantTrader: If everybody force-pushes, the opposite the case. Almost always there is need to push with --force. Doing this aligns you well with the rest of the team and different remote locations as you know what is going on. Also you know which part of the history has stabilized already. No need to hide that."]},{"answer":"To do this you can use following git command.\n\n git rebase -i HEAD~n\n\n\nn(=4 here) is the number of last commit. Then you got following options,\n\npick 01d1124 Message....\npick 6340aaa Message....\npick ebfd367 Message....\npick 30e0ccb Message....\n\n\nUpdate like below pick one commit and squash the others into the most recent,\n\np 01d1124 Message....\ns 6340aaa Message....\ns ebfd367 Message....\ns 30e0ccb Message....\n\n\nFor details click on the Link\n\nShare\nImprove this answer\nFollow\nedited Feb 29 '20 at 22:02\nThis\n39k16\n16 gold badges\n126\n126 silver badges\n167\n167 bronze badges\nanswered Apr 6 '17 at 5:26\nJakir Hosen Khan\n1,3091\n1 gold badge\n13\n13 silver badges\n17\n17 bronze badges","comments":["More details on SO on the git rebase -interactive here"]},{"answer":"If you use TortoiseGit, you can the function Combine to one commit:\n\nOpen TortoiseGit context menu\nSelect Show Log\nMark the relevant commits in the log view\nSelect Combine to one commit from the context menu\n\nThis function automatically executes all necessary single git steps. Unfortunatly only available for Windows.\n\nShare\nImprove this answer\nFollow\nanswered Nov 6 '15 at 12:51\nMatthias M\n8,51011\n11 gold badges\n68\n68 silver badges\n85\n85 bronze badges","comments":["As far as I am aware, this will not work for merge commits.","Although it's not commented by any others, this even works for commits which are not at the HEAD. For instance, my need was to squash some WIP commits I did with a more sane description before pushing. Worked beautifully. Of course, I still hope I can learn how to do it by commands.","This is awesome! Thank you","This is superb! Everything will be done by just couple of mouse clicks and I could merge 200 commits of old repo before archiving! Thanks. Really useful to make branch tree clean and easily review code changes at once."]},{"answer":"Based on this article I found this method easier for my usecase.\n\nMy 'dev' branch was ahead of 'origin/dev' by 96 commits (so these commits were not pushed to the remote yet).\n\nI wanted to squash these commits into one before pushing the change. I prefere to reset the branch to the state of 'origin/dev' (this will leave all changes from the 96 commits unstaged) and then commit the changes at once:\n\ngit reset origin/dev\ngit add --all\ngit commit -m 'my commit message'\n\nShare\nImprove this answer\nFollow\nanswered May 22 '14 at 0:41\ntrudolf\n1,27913\n13 silver badges\n11\n11 bronze badges","comments":["Just what I needed. Squash down commits from my feature branch, and then I git cherry pick that commit into my master.","This does not squash previous commits!","could you elaborate that a bit further @igorGanapolsky ?","@trudolf This isn't really squashing (picking individual commits to squash). This is more of committing all of your changes at once.","yes, hence it squashes all of your commits into one. congratulations!"]},{"answer":"In the branch you would like to combine the commits on, run:\n\ngit rebase -i HEAD~(n number of commits back to review)\n\n\nexample:\n\ngit rebase -i HEAD~1\n\n\nThis will open the text editor and you must switch the 'pick' in front of each commit with 'squash' if you would like these commits to be merged together. From documentation:\n\np, pick = use commit\ns, squash = use commit, but meld into previous commit\n\nFor example, if you are looking to merge all the commits into one, the 'pick' is the first commit you made and all future ones (placed below the first) should be set to 'squash'. If using vim, use :x in insert mode to save and exit the editor.\n\nThen to continue the rebase:\n\ngit rebase --continue\n\n\nFor more on this and other ways to rewrite your commit history see this helpful post\n\nShare\nImprove this answer\nFollow\nedited May 15 '19 at 14:40\nanswered Jul 10 '18 at 22:28\naabiro\n1,8421\n1 gold badge\n17\n17 silver badges\n28\n28 bronze badges","comments":["Please also explain what the --continue and vim :x does.","The rebase will happen in blocks as it goes through the commits on your branch, after you git add the correct configuration in your files you use git rebase --continue to move to the next commit and start to merge. :x is one command that will save the changes of the file when using vim see this"]},{"answer":"Anomies answer is good, but I felt insecure about this so I decided to add a couple of screenshots.\n\nStep 0: git log\n\nSee where you are with git log. Most important, find the commit hash of the first commit you don't want to squash. So only the :\n\nStep 1: git rebase\n\nExecute git rebase -i [your hash], in my case:\n\n$ git rebase -i 2d23ea524936e612fae1ac63c95b705db44d937d\n\nStep 2: pick / squash what you want\n\nIn my case, I want to squash everything on the commit that was first in time. The ordering is from first to last, so exactly the other way as in git log. In my case, I want:\n\nStep 3: Adjust message(s)\n\nIf you have picked only one commit and squashed the rest, you can adjust one commit message:\n\nThat's it. Once you save this (:wq), you're done. Have a look at it with git log.\n\nShare\nImprove this answer\nFollow\nanswered Jun 26 '18 at 18:03\nMartin Thoma\n95.3k120\n120 gold badges\n512\n512 silver badges\n782\n782 bronze badges","comments":["would be nice to see the final result, e.g., git log","@Axalix Did you remove all your lines? That's how you lose your commits."]},{"answer":"Procedure 1\n\n1) Identify the commit short hash\n\n# git log --pretty=oneline --abbrev-commit\nabcd1234 Update to Fix for issue B\ncdababcd Fix issue B\ndeab3412 Fix issue A\n....\n\n\nHere even git log --oneline also can be used to get short hash.\n\n2) If you want to squash (merge) last two commit\n\n# git rebase -i deab3412 \n\n\n3) This opens up a nano editor for merging. And it looks like below\n\n....\npick cdababcd Fix issue B\npick abcd1234 Update to Fix for issue B\n....\n\n\n4) Rename the word pick to squash which is present before abcd1234. After rename it should be like below.\n\n....\npick cdababcd Fix issue B\nsquash abcd1234 Update to Fix for issue B\n....\n\n\n5) Now save and close the nano editor. Press ctrl + o and press Enter to save. And then press ctrl + x to exit the editor.\n\n6) Then nano editor again opens for updating comments, if necessary update it.\n\n7) Now its squashed successfully, you can verify it by checking logs.\n\n# git log --pretty=oneline --abbrev-commit\n1122abcd Fix issue B\ndeab3412 Fix issue A\n....\n\n\n8) Now push to repo. Note to add + sign before the branch name. This means forced push.\n\n# git push origin +master\n\n\nNote : This is based on using git on ubuntu shell. If you are using different os (Windows or Mac) then above commands are same except editor. You might get different editor.\n\nProcedure 2\nFirst add the required files for commit\ngit add <files>\n\nThen commit using --fixup option and the OLDCOMMIT should be on which we need to merge(squash) this commit.\ngit commit --fixup=OLDCOMMIT\n\n\nNow this creates a new commit on top of HEAD with fixup1 <OLDCOMMIT_MSG>.\n\nThen execute below command to merge(squash) the new commit to the OLDCOMMIT.\ngit rebase --interactive --autosquash OLDCOMMIT^\n\n\nHere ^ means the previous commit to OLDCOMMIT. This rebase command opens interactive window on a editor (vim or nano) on that we no need to do anything just save and exiting is sufficient. Because the option passed to this will automatically move the latest commit to next to old commit and change the operation to fixup (equivalent to squash). Then rebase continues and finishes.\n\nProcedure 3\nIf need to add new changes to the last commit means --amend can be used with git-commit.\n    # git log --pretty=oneline --abbrev-commit\n    cdababcd Fix issue B\n    deab3412 Fix issue A\n    ....\n    # git add <files> # New changes\n    # git commit --amend\n    # git log --pretty=oneline --abbrev-commit\n    1d4ab2e1 Fix issue B\n    deab3412 Fix issue A\n    ....  \n\n\nHere --amend merges the new changes to last commit cdababcd and generates new commit ID 1d4ab2e1\n\nConclusion\nAdvantage of 1st procedure is to squash multiple commits and to reorder. But this procedure will be difficult if we need to merge a fix to very old commit.\nSo the 2nd procedure helps to merge the commit to very old commit easily.\nAnd the 3rd procedure is useful in a case to squash a new changes to last commit.\nShare\nImprove this answer\nFollow\nedited Apr 10 '20 at 9:29\nanswered Jan 10 '18 at 14:19\nrashok\n10.8k11\n11 gold badges\n78\n78 silver badges\n90\n90 bronze badges","comments":["It only updates the last two commits even I reset to a commit Id to the 6th last commit, do not know why","Even you can rearrange the commit order. It works fine."]},{"answer":"If you are on a remote branch(called feature-branch) cloned from a Golden Repository(golden_repo_name), then here's the technique to squash your commits into one:\n\nCheckout the golden repo\n\ngit checkout golden_repo_name\n\n\nCreate a new branch from it(golden repo) as follows\n\ngit checkout -b dev-branch\n\n\nSquash merge with your local branch that you have already\n\ngit merge --squash feature-branch\n\n\nCommit your changes (this will be the only commit that goes in dev-branch)\n\ngit commit -m \"My feature complete\"\n\n\nPush the branch to your local repository\n\ngit push origin dev-branch\n\nShare\nImprove this answer\nFollow\nedited Mar 18 '16 at 12:10\nMachavity♦\n29k26\n26 gold badges\n82\n82 silver badges\n91\n91 bronze badges\nanswered Sep 9 '15 at 15:58\nSandesh Kumar\n5015\n5 silver badges\n4\n4 bronze badges","comments":["Since I was just squashing ~100 commits (for syncing svn branches via git-svn), this is far faster than interactively rebasing!","Reading down, I see @Chris's comment, which is what I used to do (rebase --soft...) - too bad that stackoverflow is no longer putting the answer with hundreds of upvotes at the top...","agree with you @sage, lets hope they might do it sometime in the future","This is the right way. Rebase approach is good, but should only be used for squash as a last resort solution.","I'm getting everything up to date"]},{"answer":"I think the easiest way to do this is by making a new branch based on master and doing a merge --squash of the feature branch.\n\ngit checkout master\ngit checkout -b feature_branch_squashed\ngit merge --squash feature_branch\n\n\nThen you have all of the changes ready to commit.\n\nShare\nImprove this answer\nFollow\nedited Jun 10 '20 at 14:42\nWolfson\n5815\n5 silver badges\n14\n14 bronze badges\nanswered Mar 20 '18 at 15:28\nuser1376350\n4434\n4 silver badges\n4\n4 bronze badges","comments":["This is a nice alternative to achieve a similar end result. I came looking on how to do it using rebase, but I chose this way better. I keep forgetting about the existence of git merge","I was trying to do other solutions, but for w/e reason they weren't working. This one did."]},{"answer":"If for example, you want to squash the last 3 commits to a single commit in a branch (remote repository) in for example: https://bitbucket.org\n\nWhat I did is\n\ngit reset --soft HEAD~3\ngit commit\ngit push origin <branch_name> --force\nShare\nImprove this answer\nFollow\nedited Jul 27 '20 at 19:15\nIvan Kaloyanov\n1,7536\n6 gold badges\n15\n15 silver badges\n22\n22 bronze badges\nanswered May 16 '19 at 7:55\nAlbert Ruelan\n7076\n6 silver badges\n18\n18 bronze badges","comments":["Just be careful, Since if you use force then there is no way to retrieve the previous commits since you removed it","Nice and quick solution, as for me.","Force is destructive. This is not squashing commits rather removing the last three commits and adding them back as a fourth (now new) commit, essentially rewriting the history which can break the repo for other users until they also force pull. This will also remove any other commits your team has pushed meanwhile."]},{"answer":"To squash the last 10 commits into 1 single commit:\n\ngit reset --soft HEAD~10 && git commit -m \"squashed commit\"\n\n\nIf you also want to update the remote branch with the squashed commit:\n\ngit push -f\n\nShare\nImprove this answer\nFollow\nedited Oct 15 '19 at 2:43\nanswered Aug 21 '18 at 19:25\nAyan\n5,9223\n3 gold badges\n31\n31 silver badges\n40\n40 bronze badges","comments":["--force is dangerous when multiple people are working on a shared branch as it blindly updates remote with your local copy. --force-with-lease could have been better as it makes sure that remote has no commits from others since you last fetched it."]},{"answer":"Here is another visual example of what would follow after executing: git rebase -i HEAD~3\n\nSource: https://www.git-tower.com/learn/git/faq/git-squash/\n\nShare\nImprove this answer\nFollow\nedited Apr 20 at 17:38\nanswered Mar 19 at 14:59\nana\n5074\n4 silver badges\n9\n9 bronze badges","comments":[]},{"answer":"What can be really convenient:\nFind the commit hash you want to squash on top of, say d43e15.\n\nNow use\n\ngit reset d43e15\ngit commit -am 'new commit name'\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '18 at 4:38\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered Sep 14 '17 at 10:33\nAriel Gabizon\n2,0631\n1 gold badge\n13\n13 silver badges\n20\n20 bronze badges","comments":["This. Why don't more people use this? It's way faster than rebasing and squashing individual commits."]},{"answer":"If you want to squish every commit into a single commit (e.g. when releasing a project publicly for the first time), try:\n\ngit checkout --orphan <new-branch>\ngit commit\n\nShare\nImprove this answer\nFollow\nanswered Aug 20 '16 at 20:39\nWilliam Denniss\n15.1k6\n6 gold badges\n76\n76 silver badges\n118\n118 bronze badges","comments":[]},{"answer":"Simple one-liner that always works, given that you are currently on the branch you want to squash, master is the branch it originated from, and the latest commit contains the commit message and author you wish to use:\n\ngit reset --soft $(git merge-base HEAD master) && git commit --reuse-message=HEAD@{1}\n\nShare\nImprove this answer\nFollow\nanswered Feb 14 '19 at 19:20\nColinM\n12.1k2\n2 gold badges\n39\n39 silver badges\n45\n45 bronze badges","comments":["I have been absolutely livid with frustration about squashing commits and how stupidly complicated it is - just effing use the last message and squash them all to one commit! Why is it that hard???? This one liner does that for me. Thank you from the bottom of my angry heart."]},{"answer":"This is super-duper kludgy, but in a kind of cool way, so I'll just toss it into the ring:\n\nGIT_EDITOR='f() { if [ \"$(basename $1)\" = \"git-rebase-todo\" ]; then sed -i \"2,\\$s/pick/squash/\" $1; else vim $1; fi }; f' git rebase -i foo~5 foo\n\n\nTranslation: provide a new \"editor\" for git which, if the filename to be edited is git-rebase-todo (the interactive rebase prompt) changes all but the first \"pick\" to \"squash\", and otherwise spawns vim - so that when you're prompted to edit the squashed commit message, you get vim. (And obviously I was squashing the last five commits on branch foo, but you could change that however you like.)\n\nI'd probably do what Mark Longair suggested, though.\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:47\nCommunity♦\n11\n1 silver badge\nanswered Mar 4 '11 at 16:12\nCascabel\n430k65\n65 gold badges\n358\n358 silver badges\n309\n309 bronze badges","comments":["+1: that's fun and instructive, in that it's wasn't at all obvious to me that you can put anything more complex than the name of a program in the GIT_EDITOR environment variable.","You could simplify this using gawk. git -c core.editor=\"gawk -i inplace '{if(NR>1 && \\$1==\\\"pick\\\"){\\$1=\\\"squash\\\"} print \\$0}'\" rebase -i --autosquash HEAD~5."]},{"answer":"⚠️ WARNING: \"My last X commits\" might be ambiguous.\n  (MASTER)  \nFleetwood Mac            Fritz\n      ║                    ║\n  Add Danny  Lindsey     Stevie       \n    Kirwan  Buckingham    Nicks                                              \n      ║         ╚═══╦══════╝     \nAdd Christine       ║          \n   Perfect      Buckingham\n      ║           Nicks            \n    LA1974══════════╝                                    \n      ║                  \n      ║                  \n    Bill <══════ YOU ARE EDITING HERE\n  Clinton        (CHECKED OUT, CURRENT WORKING DIRECTORY)              \n\n\nIn this very abbreviated history of the https://github.com/fleetwood-mac/band-history repository you have opened a pull request to merge in the the Bill Clinton commit into the original (MASTER) Fleetwood Mac commit.\n\nYou opened a pull request and on GitHub you see this:\n\nFour commits:\n\nAdd Danny Kirwan\nAdd Christine Perfect\nLA1974\nBill Clinton\n\nThinking that nobody would ever care to read the full repository history. (There actually is a repository, click the link above!) You decide to squash these commits. So you go and run git reset --soft HEAD~4 && git commit. Then you git push --force it onto GitHub to clean up your PR.\n\nAnd what happens? You just made single commit that get from Fritz to Bill Clinton. Because you forgot that yesterday you were working on the Buckingham Nicks version of this project. And git log doesn't match what you see on GitHub.\n\n🐻 MORAL OF THE STORY\nFind the exact files you want to get to, and git checkout them\nFind the exact prior commit you want to keep in history, and git reset --soft that\nMake a git commit that warps directly from the from to the to\nShare\nImprove this answer\nFollow\nedited Nov 4 '19 at 14:50\nanswered Nov 2 '18 at 4:34\nWilliam Entriken\n31.4k17\n17 gold badges\n129\n129 silver badges\n175\n175 bronze badges","comments":["This is 100% the easiest way to do this. If your current HEAD is the correct state you want, then you can skip #1.","This is the only way I know that allows to rewrite the first commit history."]},{"answer":"Many answers are based on git rebase command, but in my experience it is somewhat complex and advanced for git-beginners.\n\nLet's say you want to squish last 3 commits. Then following are the steps:\n\nNote down current commit id: Use git log -1 --oneline and note the commit-id of the present state (just in case you do something wrong with git reset)\nGo back 3 commits: Using git reset --soft HEAD~3 you'll go back 3 commits (and sort of forget that you've had made these three commits earlier)\nDo a new commit: Now simply do git commit -m <NEW_SINGLE_MESSAGE> which will automatically combine the three commits under your message\n\nIn case something goes wrong with git reset, you can again return to the original state by git reset --soft <ORIGINAL_COMMIT>\n\nShare\nImprove this answer\nFollow\nedited Jun 27 at 13:58\nanswered Feb 23 at 11:37\nPulkit Bansal\n1,0939\n9 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"If you don't care about the commit messages of the in-between commits, you can use\n\ngit reset --mixed <commit-hash-into-which-you-want-to-squash>\ngit commit -a --amend\n\nShare\nImprove this answer\nFollow\nanswered Jul 8 '19 at 13:16\nZsolt Z.\n5036\n6 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"If you're working with GitLab, you can just click the Squash option in the Merge Request as shown below. The commit message will be the title of the Merge Request.\n\nShare\nImprove this answer\nFollow\nanswered Mar 12 '19 at 10:00\narush436\n1,39416\n16 silver badges\n17\n17 bronze badges","comments":["With GitLab Enterprise Edition 12.8.6-ee it just randomly took a commit message for the squashed commit..."]},{"answer":"What about an answer for the question related to a workflow like this?\n\nmany local commits, mixed with multiple merges FROM master,\nfinally a push to remote,\nPR and merge TO master by reviewer. (Yes, it would be easier for the developer to merge --squash after the PR, but the team thought that would slow down the process.)\n\nI haven't seen a workflow like that on this page. (That may be my eyes.) If I understand rebase correctly, multiple merges would require multiple conflict resolutions. I do NOT want even to think about that!\n\nSo, this seems to work for us.\n\ngit pull master\ngit checkout -b new-branch\ngit checkout -b new-branch-temp\nedit and commit a lot locally, merge master regularly\ngit checkout new-branch\ngit merge --squash new-branch-temp // puts all changes in stage\ngit commit 'one message to rule them all'\ngit push\nReviewer does PR and merges to master.\nShare\nImprove this answer\nFollow\nanswered Jun 20 '18 at 19:28\nallenjom\n1092\n2 silver badges\n5\n5 bronze badges","comments":["From many opinions I like your approach. It's very convenient and fast"]},{"answer":"I find a more generic solution is not to specify 'N' commits, but rather the branch/commit-id you want to squash on top of. This is less error-prone than counting the commits up to a specific commit—just specify the tag directly, or if you really want to count you can specify HEAD~N.\n\nIn my workflow, I start a branch, and my first commit on that branch summarizes the goal (i.e. it's usually what I will push as the 'final' message for the feature to the public repository.) So when I'm done, all I want to do is git squash master back to the first message and then I'm ready to push.\n\nI use the alias:\n\nsquash = !EDITOR=\"\\\"_() { sed -n 's/^pick //p' \\\"\\\\$1\\\"; sed -i .tmp '2,\\\\$s/^pick/f/' \\\"\\\\$1\\\"; }; _\\\"\" git rebase -i\n\n\nThis will dump the history being squashed before it does so—this gives you a chance to recover by grabbing an old commit ID off the console if you want to revert. (Solaris users note it uses the GNU sed -i option, Mac and Linux users should be fine with this.)\n\nShare\nImprove this answer\nFollow\nanswered Nov 4 '14 at 20:40\nEthan\n4985\n5 silver badges\n6\n6 bronze badges","comments":["I tried the alias but I'm not sure if the sed replaces are having any effect. What should they do?","The first sed just dumps the history to the console. The second sed replaces all the 'pick' with 'f' (fixup) and rewrites the editor file in-place (the -i option). So the second one does all the work.","You are right, counting N-number of specific commits is very error prone. It has screwed me up several times and wasted hours trying to undo the rebase.","Hi Ethan, I would like to know if this workflow will hide possible conflicts on the merge. So please consider if you have two branches master and slave. If the slave has a conflict with the master and we use git squash master when we are checked out on the slave. what will it happen? will we hide the conflict?","@Sergio This is a case of rewriting history, so you probably will have conflicts if you squash commits that have already been pushed, and then try to merge/rebase the squashed version back. (Some trivial cases might get away with it.)"]},{"answer":"git rebase -i HEAD^^\n\n\nwhere the number of ^'s is X\n\n(in this case, squash the two last commits)\n\nShare\nImprove this answer\nFollow\nanswered Feb 19 '18 at 12:32\nYoaz Menda\n1,2432\n2 gold badges\n16\n16 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"In addition to other excellent answers, I'd like to add how git rebase -i always confuses me with the commit order - older to newer one or vice versa? So this is my workflow:\n\ngit rebase -i HEAD~[N] , where N is the number of commits I want to join, starting from the most recent one. So git rebase -i HEAD~5 would mean \"squash the last 5 commits into a new one\";\nthe editor pops up, showing the list of commits I want to merge. Now they are displayed in reverse order: the older commit is on top. Mark as \"squash\" or \"s\" all the commits in there except the first/older one: it will be used as a starting point. Save and close the editor;\nthe editor pops up again with a default message for the new commit: change it to your needs, save and close. Squash completed!\n\nSources & additional reads: #1, #2.\n\nShare\nImprove this answer\nFollow\nanswered Mar 9 '18 at 9:51\nIgnorant\n1,8513\n3 gold badges\n21\n21 silver badges\n36\n36 bronze badges","comments":[]}]},{"id":"271526","href":"https://stackoverflow.com/questions/271526/avoiding-nullpointerexception-in-java","title":"Avoiding NullPointerException in Java","description":"\n                \nI use object != null a lot to avoid NullPointerException.\nWhat is an alternative to:\nif (someobject != null) {\n    someobject.doCalc();\n}\n\n    ","questionComments":["@Shervin Encouraging nulls makes the code less understandable and less reliable.","Not using null is superior to most other suggestions here. Throw exceptions, don't return or allow nulls. BTW - 'assert' keyword is useless, because it's disabled by default. Use an always-enabled failure mechanism","Isn't there are Design Pattern that speaks about making a null-object? So when instantiating a new object, you always use this null object (same super class, same [but empty] methods) and later on you set the object to the full object when you need it. You might want to check out a similar question: stackoverflow.com/questions/9162371/… and this info about the Null Object Pattern: en.wikipedia.org/wiki/Null_Object_pattern","Nulls should be avoided in high-level code. Tony Hoare, who invented null references, calls them \"a billion-dollar mistake\". Take a look here for some ideas.","Seems to be in Java 8: static Objects.isNull(Object o) docs.oracle.com/javase/8/docs/api/java/util/Objects.html"],"answers":[{"answer":"This to me sounds like a reasonably common problem that junior to intermediate developers tend to face at some point: they either don't know or don't trust the contracts they are participating in and defensively overcheck for nulls. Additionally, when writing their own code, they tend to rely on returning nulls to indicate something thus requiring the caller to check for nulls.\n\nTo put this another way, there are two instances where null checking comes up:\n\nWhere null is a valid response in terms of the contract; and\n\nWhere it isn't a valid response.\n\n(2) is easy. Either use assert statements (assertions) or allow failure (for example, NullPointerException). Assertions are a highly-underused Java feature that was added in 1.4. The syntax is:\n\nassert <condition>\n\n\nor\n\nassert <condition> : <object>\n\n\nwhere <condition> is a boolean expression and <object> is an object whose toString() method's output will be included in the error.\n\nAn assert statement throws an Error (AssertionError) if the condition is not true. By default, Java ignores assertions. You can enable assertions by passing the option -ea to the JVM. You can enable and disable assertions for individual classes and packages. This means that you can validate code with the assertions while developing and testing, and disable them in a production environment, although my testing has shown next to no performance impact from assertions.\n\nNot using assertions in this case is OK because the code will just fail, which is what will happen if you use assertions. The only difference is that with assertions it might happen sooner, in a more-meaningful way and possibly with extra information, which may help you to figure out why it happened if you weren't expecting it.\n\n(1) is a little harder. If you have no control over the code you're calling then you're stuck. If null is a valid response, you have to check for it.\n\nIf it's code that you do control, however (and this is often the case), then it's a different story. Avoid using nulls as a response. With methods that return collections, it's easy: return empty collections (or arrays) instead of nulls pretty much all the time.\n\nWith non-collections it might be harder. Consider this as an example: if you have these interfaces:\n\npublic interface Action {\n  void doSomething();\n}\n\npublic interface Parser {\n  Action findAction(String userInput);\n}\n\n\nwhere Parser takes raw user input and finds something to do, perhaps if you're implementing a command line interface for something. Now you might make the contract that it returns null if there's no appropriate action. That leads the null checking you're talking about.\n\nAn alternative solution is to never return null and instead use the Null Object pattern:\n\npublic class MyParser implements Parser {\n  private static Action DO_NOTHING = new Action() {\n    public void doSomething() { /* do nothing */ }\n  };\n\n  public Action findAction(String userInput) {\n    // ...\n    if ( /* we can't find any actions */ ) {\n      return DO_NOTHING;\n    }\n  }\n}\n\n\nCompare:\n\nParser parser = ParserFactory.getParser();\nif (parser == null) {\n  // now what?\n  // this would be an example of where null isn't (or shouldn't be) a valid response\n}\nAction action = parser.findAction(someInput);\nif (action == null) {\n  // do nothing\n} else {\n  action.doSomething();\n}\n\n\nto\n\nParserFactory.getParser().findAction(someInput).doSomething();\n\n\nwhich is a much better design because it leads to more concise code.\n\nThat said, perhaps it is entirely appropriate for the findAction() method to throw an Exception with a meaningful error message -- especially in this case where you are relying on user input. It would be much better for the findAction method to throw an Exception than for the calling method to blow up with a simple NullPointerException with no explanation.\n\ntry {\n    ParserFactory.getParser().findAction(someInput).doSomething();\n} catch(ActionNotFoundException anfe) {\n    userConsole.err(anfe.getMessage());\n}\n\n\nOr if you think the try/catch mechanism is too ugly, rather than Do Nothing your default action should provide feedback to the user.\n\npublic Action findAction(final String userInput) {\n    /* Code to return requested Action if found */\n    return new Action() {\n        public void doSomething() {\n            userConsole.err(\"Action not found: \" + userInput);\n        }\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Jun 26 '15 at 22:32\ncommunity wiki\n\n\n13 revs, 11 users 77%\ncletus","comments":[]},{"answer":"If you use (or planning to use) a Java IDE like JetBrains IntelliJ IDEA, Eclipse or Netbeans or a tool like findbugs then you can use annotations to solve this problem.\n\nBasically, you've got @Nullable and @NotNull.\n\nYou can use in method and parameters, like this:\n\n@NotNull public static String helloWorld() {\n    return \"Hello World\";\n}\n\n\nor\n\n@Nullable public static String helloWorld() {\n    return \"Hello World\";\n}\n\n\nThe second example won't compile (in IntelliJ IDEA).\n\nWhen you use the first helloWorld() function in another piece of code:\n\npublic static void main(String[] args)\n{\n    String result = helloWorld();\n    if(result != null) {\n        System.out.println(result);\n    }\n}\n\n\nNow the IntelliJ IDEA compiler will tell you that the check is useless, since the helloWorld() function won't return null, ever.\n\nUsing parameter\n\nvoid someMethod(@NotNull someParameter) { }\n\n\nif you write something like:\n\nsomeMethod(null);\n\n\nThis won't compile.\n\nLast example using @Nullable\n\n@Nullable iWantToDestroyEverything() { return null; }\n\n\nDoing this\n\niWantToDestroyEverything().something();\n\n\nAnd you can be sure that this won't happen. :)\n\nIt's a nice way to let the compiler check something more than it usually does and to enforce your contracts to be stronger. Unfortunately, it's not supported by all the compilers.\n\nIn IntelliJ IDEA 10.5 and on, they added support for any other @Nullable @NotNull implementations.\n\nSee blog post More flexible and configurable @Nullable/@NotNull annotations.\n\nShare\nImprove this answer\nFollow\nedited Jan 3 '19 at 21:03\ncommunity wiki\n\n\n9 revs, 8 users 77%\nLuca Molteni","comments":["@NotNull, @Nullable and other nullness annotations are part of JSR 305. You can also use them to detect potential problems with tools like FindBugs.","I find it strangely annoying that the @NotNull & @Nullable interfaces live in the package com.sun.istack.internal. (I guess I associate com.sun with warnings about using a proprietary API.)","code portability goes null with jetbrains.I would think twice(square) before tying down to ide level.Like Jacek S said they are part of JSR any way which I thought was JSR303 by the way.","I really don't think that using a custom compiler is a viable solution to this problem.","The good thing about annotations, which @NotNull and @Nullable are is that they nicely degrade when the source code is built by a system that doesn't understand them. So, in effect, the argument that the code is not portable may be invalid - if you use a system that supports and understands these annotations, you get the added benefit of stricter error checking, otherwise you get less of it but your code should still build fine, and the quality of your running program is THE SAME, because these annotations were not enforced at runtime anyway. Besides, all compilers are custom ;-)"]},{"answer":"If null-values are not allowed\n\nIf your method is called externally, start with something like this:\n\npublic void method(Object object) {\n  if (object == null) {\n    throw new IllegalArgumentException(\"...\");\n  }\n\n\nThen, in the rest of that method, you'll know that object is not null.\n\nIf it is an internal method (not part of an API), just document that it cannot be null, and that's it.\n\nExample:\n\npublic String getFirst3Chars(String text) {\n  return text.subString(0, 3);\n}\n\n\nHowever, if your method just passes the value on, and the next method passes it on etc. it could get problematic. In that case you may want to check the argument as above.\n\nIf null is allowed\n\nThis really depends. If find that I often do something like this:\n\nif (object == null) {\n  // something\n} else {\n  // something else\n}\n\n\nSo I branch, and do two completely different things. There is no ugly code snippet, because I really need to do two different things depending on the data. For example, should I work on the input, or should I calculate a good default value?\n\nIt's actually rare for me to use the idiom \"if (object != null && ...\".\n\nIt may be easier to give you examples, if you show examples of where you typically use the idiom.\n\nShare\nImprove this answer\nFollow\nedited Jul 19 '16 at 9:02\ncommunity wiki\n\n\n2 revs, 2 users 90%\nmyplacedk","comments":["What's the point in throwing IllegalArgumentException? I think NullPointerException would be clearer, and that would also be thrown if you don't do the null-check yourself. I'd either use assert or nothing at all.","It's unlikely that every other value than null is acceptable. You could have IllegalArgumentException, OutOfRageException etc etc. Sometimes this makes sense. Other times you end up creating a lot of exception classes that doesn't add any value, then you just use IllegalArgumentException. It doesn't makes sense to have one exception for null-input, and another one for everything else.","Yes, I agree to fail-fast-principle, but in the example given above, the value is not passed on, but is the object on which a method shall be called. So it fails equallys fast, and adding a null check just to throw an exception that would be thrown anyway at the same time and place doesn't seem to make debugging any easier.","A security hole? The JDK is full of code like this. If you don't want the user to see stacktraces, then just disable them. No one implied that the behaviour is not documented. MySQL is written in C where dereferencing null pointers is undefined behaviour, nothing like throwing an exception.","throw new IllegalArgumentException(\"object==null\")"]},{"answer":"Wow, I almost hate to add another answer when we have 57 different ways to recommend the NullObject pattern, but I think that some people interested in this question may like to know that there is a proposal on the table for Java 7 to add \"null-safe handling\"—a streamlined syntax for if-not-equal-null logic.\n\nThe example given by Alex Miller looks like this:\n\npublic String getPostcode(Person person) {  \n  return person?.getAddress()?.getPostcode();  \n}  \n\n\nThe ?. means only de-reference the left identifier if it is not null, otherwise evaluate the remainder of the expression as null. Some people, like Java Posse member Dick Wall and the voters at Devoxx really love this proposal, but there is opposition too, on the grounds that it will actually encourage more use of null as a sentinel value.\n\nUpdate: An official proposal for a null-safe operator in Java 7 has been submitted under Project Coin. The syntax is a little different than the example above, but it's the same notion.\n\nUpdate: The null-safe operator proposal didn't make it into Project Coin. So, you won't be seeing this syntax in Java 7.\n\nShare\nImprove this answer\nFollow\nedited Sep 20 '15 at 23:12\ncommunity wiki\n\n\n5 revs, 3 users 82%\nerickson","comments":["I think this is wrong. There should be a way to specify that a given variable is ALWAYS non-null.","Update: the proposal will not make Java7. See blogs.sun.com/darcy/entry/project_coin_final_five .","Interesting idea but the choice of syntax is absurd; I don't want a codebase full of question marks pinned into every joint.","This operator exists in Groovy, so those who want to use it still have that as an option.","This is the most ingenious idea I've seen. It should be added to every sensible language of the C syntax. I'd rather \"pin question marks\" everywhere than scroll through screenful of lines or dodge \"guard clauses\" all day."]},{"answer":"If undefined values are not permitted:\n\nYou might configure your IDE to warn you about potential null dereferencing. E.g. in Eclipse, see Preferences > Java > Compiler > Errors/Warnings/Null analysis.\n\nIf undefined values are permitted:\n\nIf you want to define a new API where undefined values make sense, use the Option Pattern (may be familiar from functional languages). It has the following advantages:\n\nIt is stated explicitly in the API whether an input or output exists or not.\nThe compiler forces you to handle the \"undefined\" case.\nOption is a monad, so there is no need for verbose null checking, just use map/foreach/getOrElse or a similar combinator to safely use the value (example).\n\nJava 8 has a built-in Optional class (recommended); for earlier versions, there are library alternatives, for example Guava's Optional or FunctionalJava's Option. But like many functional-style patterns, using Option in Java (even 8) results in quite some boilerplate, which you can reduce using a less verbose JVM language, e.g. Scala or Xtend.\n\nIf you have to deal with an API which might return nulls, you can't do much in Java. Xtend and Groovy have the Elvis operator ?: and the null-safe dereference operator ?., but note that this returns null in case of a null reference, so it just \"defers\" the proper handling of null.\n\nShare\nImprove this answer\nFollow\nedited Oct 24 '17 at 10:38\ncommunity wiki\n\n\n10 revs, 3 users 87%\nthSoft","comments":["Indeed, the Option pattern is awesome. Some Java equivalents exist. Guava contains a limited version of this called Optional which leaves out most of the functional stuff. In Haskell, this pattern is called Maybe.","@Luca Molteni: You're absolutely right, I already commented on the post to request expanding it. :)","An Optional class will be available in Java 8","...and it doesn't (yet) have map nor flatMap: download.java.net/jdk8/docs/api/java/util/Optional.html","The Optional pattern doesn't solve anything; instead of one potentially null object, now you have two."]},{"answer":"Only for this situation -\n\nNot checking if a variable is null before invoking an equals method (a string compare example below):\n\nif ( foo.equals(\"bar\") ) {\n // ...\n}\n\n\nwill result in a NullPointerException if foo doesn't exist.\n\nYou can avoid that if you compare your Strings like this:\n\nif ( \"bar\".equals(foo) ) {\n // ...\n}\n\nShare\nImprove this answer\nFollow\nedited May 25 '18 at 15:33\ncommunity wiki\n\n\n3 revs, 3 users 68%\nechox","comments":["I agree - only in that situation. I can't stand programmers that have taken this to the next unnecessary level and write if (null != myVar)... just looks ugly to me and serves no purpose!","This is a particular example, probably the most used, of a general good practice: if you know it, always do <object that you know that is not null>.equals(<object that might be null>);. It works for other methods other than equals if you know the contract and those methods can handle null parameters.","This is the first example I have seen of Yoda Conditions that actually makes sense","NullPointerExceptions are thrown for a reason. They are thrown because an object is null where it shouldn't be. It is the programmers job to FIX this, not HIDE the problem.","This only hides the problem. What if you are using foo later on? If a variable shouldn't be null, but is...your app needs to get a NPE so you as the developer can actually fix the underlying reason."]},{"answer":"With Java 8 comes the new java.util.Optional class that arguably solves some of the problem. One can at least say that it improves the readability of the code, and in the case of public APIs make the API's contract clearer to the client developer.\n\nThey work like that:\n\nAn optional object for a given type (Fruit) is created as the return type of a method. It can be empty or contain a Fruit object:\n\npublic static Optional<Fruit> find(String name, List<Fruit> fruits) {\n   for (Fruit fruit : fruits) {\n      if (fruit.getName().equals(name)) {\n         return Optional.of(fruit);\n      }\n   }\n   return Optional.empty();\n}\n\n\nNow look at this code where we search a list of Fruit (fruits) for a given Fruit instance:\n\nOptional<Fruit> found = find(\"lemon\", fruits);\nif (found.isPresent()) {\n   Fruit fruit = found.get();\n   String name = fruit.getName();\n}\n\n\nYou can use the map() operator to perform a computation on--or extract a value from--an optional object. orElse() lets you provide a fallback for missing values.\n\nString nameOrNull = find(\"lemon\", fruits)\n    .map(f -> f.getName())\n    .orElse(\"empty-name\");\n\n\nOf course, the check for null/empty value is still necessary, but at least the developer is conscious that the value might be empty and the risk of forgetting to check is limited.\n\nIn an API built from scratch using Optional whenever a return value might be empty, and returning a plain object only when it cannot be null (convention), the client code might abandon null checks on simple object return values...\n\nOf course Optional could also be used as a method argument, perhaps a better way to indicate optional arguments than 5 or 10 overloading methods in some cases.\n\nOptional offers other convenient methods, such as orElse that allow the use of a default value, and ifPresent that works with lambda expressions.\n\nI invite you to read this article (my main source for writing this answer) in which the NullPointerException (and in general null pointer) problematic as well as the (partial) solution brought by Optional are well explained: Java Optional Objects.\n\nShare\nImprove this answer\nFollow\nedited Sep 29 '16 at 7:39\ncommunity wiki\n\n\n4 revs, 4 users 72%\nPierre Henry","comments":["Google's guava has an optional implimention for Java 6+.","It's very important to emphasise that using Optional only with ifPresent() does not add much value above normal null checking. It's core value is that it is a monad that can be used in function chains of map/flapMap, which achieves results similar to the Elvis operator in Groovy mentioned elsewhere. Even without this usage, though, I find the orElse/orElseThrow syntax also very useful.","This blog has a good entry on Optional winterbe.com/posts/2015/03/15/avoid-null-checks-in-java","Why people have tendency to do this if(optional.isPresent()){ optional.get(); } instead of optional.ifPresent(o -> { ...})","So, other than the API contractual hints, it's really just about catering to functional programmers who enjoy chaining methods endlessly."]},{"answer":"Depending on what kind of objects you are checking you may be able to use some of the classes in the apache commons such as: apache commons lang and apache commons collections\n\nExample:\n\nString foo;\n...\nif( StringUtils.isBlank( foo ) ) {\n   ///do something\n}\n\n\nor (depending on what you need to check):\n\nString foo;\n...\nif( StringUtils.isEmpty( foo ) ) {\n   ///do something\n}\n\n\nThe StringUtils class is only one of many; there are quite a few good classes in the commons that do null safe manipulation.\n\nHere follows an example of how you can use null vallidation in JAVA when you include apache library(commons-lang-2.4.jar)\n\npublic DOCUMENT read(String xml, ValidationEventHandler validationEventHandler) {\n    Validate.notNull(validationEventHandler,\"ValidationHandler not Injected\");\n    return read(new StringReader(xml), true, validationEventHandler);\n}\n\n\nAnd if you are using Spring, Spring also has the same functionality in its package, see library(spring-2.4.6.jar)\n\nExample on how to use this static classf from spring(org.springframework.util.Assert)\n\nAssert.notNull(validationEventHandler,\"ValidationHandler not Injected\");\n\nShare\nImprove this answer\nFollow\nedited Feb 23 '16 at 12:14\ncommunity wiki\n\n\n3 revs, 3 users 68%\njavamonkey79","comments":["Also you can use the more generic version from Apache Commons, quite useful at the start of methods to check params I find. Validate.notNull( object, \"object must not be null\"); commons.apache.org/lang/apidocs/org/apache/commons/lang/…","@monojohnny does Validate use Assert statements into?. i ask that because Assert may be activate / deactivate on JVM and it's suggest do not use in production.","Don't think so - I believe it just throws a RuntimeException if validation fails"]},{"answer":"If you consider an object should not be null (or it is a bug) use an assert.\nIf your method doesn't accept null params say it in the javadoc and use an assert.\n\nYou have to check for object != null only if you want to handle the case where the object may be null...\n\nThere is a proposal to add new annotations in Java7 to help with null / notnull params: http://tech.puredanger.com/java7/#jsr308\n\nShare\nImprove this answer\nFollow\nedited Aug 14 '09 at 14:44\ncommunity wiki\n\n\n2 revs, 2 users 100%\npgras","comments":["No, do not use assertions in production code."]},{"answer":"I'm a fan of \"fail fast\" code. Ask yourself - are you doing something useful in the case where the parameter is null? If you don't have a clear answer for what your code should do in that case... I.e. it should never be null in the first place, then ignore it and allow a NullPointerException to be thrown. The calling code will make just as much sense of an NPE as it would an IllegalArgumentException, but it'll be easier for the developer to debug and understand what went wrong if an NPE is thrown rather than your code attempting to execute some other unexpected contingency logic - which ultimately results in the application failing anyway.\n\nShare\nImprove this answer\nFollow\nedited Apr 23 '12 at 19:09\ncommunity wiki\n\n\n2 revs\nAlex Worden","comments":["better to use assertions, i.e Contract.notNull(abc, \"abc must be non-null, did it fail to load during xyz?\"); - this is a more compact way than doing an if (abc!=null) { throw new RuntimeException...}"]},{"answer":"Rather than Null Object Pattern -- which has its uses -- you might consider situations where the null object is a bug.\n\nWhen the exception is thrown, examine the stack trace and work through the bug.\n\nShare\nImprove this answer\nFollow\nanswered Nov 7 '08 at 8:50\ncommunity wiki\n\n\nJim Nelson","comments":["Problem is that usually you loose context as the NullPointerException does not indicate WHICH variable was null, and you may have several \".\"-operations on the line. Using \"if (foo == null) throw new RuntimeException(\"foo == null\")\" allows you to state explicitly WHAT was wrong, giving your stack trace much more value to those who have to fix it.","With Andersen - I would love Java's exception system to be able to include the name of a variable that's being worked upon, so that NullPointerExceptions would not only indicate the line the exception occurred on, but also the variable name. This should work just fine in unobfuscated software.","I had a professor that preached against method call chaining. His theory was that you should be wary of call chains that were longer than 2 methods. I don't know if that's a hard rule, but it definitely removes most of the problems with NPE stack traces."]},{"answer":"The Google collections framework offers a good and elegant way to achieve the null check.\n\nThere is a method in a library class like this:\n\nstatic <T> T checkNotNull(T e) {\n   if (e == null) {\n      throw new NullPointerException();\n   }\n   return e;\n}\n\n\nAnd the usage is (with import static):\n\n...\nvoid foo(int a, Person p) {\n   if (checkNotNull(p).getAge() > a) {\n      ...\n   }\n   else {\n      ...\n   }\n}\n...\n\n\nOr in your example:\n\ncheckNotNull(someobject).doCalc();\n\nShare\nImprove this answer\nFollow\nedited Sep 19 '15 at 16:05\ncommunity wiki\n\n\n3 revs, 3 users 83%\nuser2427","comments":["mmm, what is the difference? p.getAge() would throw the same NPE with less overhead and a clearer stack trace. What am I missing?","It is better to throw an IllegalArgumentException(\"e == null\") in your example as it clearly indicates that it is a programmer-intended exception (along with enough information to actually allow the maintainer to identify the problem). NullPointerExceptions should be reserved for the JVM, as it then clearly indicates that this was unintentional (and usually happens somewhere hard to identify)","This is now part of Google Guava.","Smells like over-engineering to me. Just let the JVM throw an NPE and don't clutter your code with this junk.","I like it and open most methods and constructors with explicit checks on the arguments; if there is an error, methods always fail on the first few lines and I know the offending reference without finding something like getThing().getItsThing().getOtherThing().wowEncapsulationIsBroken().setLol(\"hi\");"]},{"answer":"Sometimes, you have methods that operate on its parameters that define a symmetric operation:\n\na.f(b); <-> b.f(a);\n\n\nIf you know b can never be null, you can just swap it. It is most useful for equals: Instead of foo.equals(\"bar\"); better do \"bar\".equals(foo);.\n\nShare\nImprove this answer\nFollow\nedited Dec 15 '15 at 19:02\ncommunity wiki\n\n\n4 revs, 4 users 50%\nJohannes Schaub - litb","comments":["But then you have to assume equals (could be any method) will handle null correctly. Really all this is doing is passing the responsibility to someone else (or another method).","@Supericy Basically yes, but equals (or whatever method) has to check for null anyway. Or state explicitly that it does not."]},{"answer":"Null is not a 'problem'. It is an integral part of a complete modeling tool set. Software aims to model the complexity of the world and null bears its burden. Null indicates 'No data' or 'Unknown' in Java and the like. So it is appropriate to use nulls for these purposes. I don't prefer the 'Null object' pattern; I think it rise the 'who will guard the guardians' problem.\nIf you ask me what is the name of my girlfriend I'll tell you that I have no girlfriend. In the Java language I'll return null. An alternative would be to throw meaningful exception to indicate some problem that can't be (or don't want to be) solved right there and delegate it somewhere higher in the stack to retry or report data access error to the user.\n\nFor an 'unknown question' give 'unknown answer'. (Be null-safe where this is correct from business point of view) Checking arguments for null once inside a method before usage relieves multiple callers from checking them before a call.\n\npublic Photo getPhotoOfThePerson(Person person) {\n    if (person == null)\n        return null;\n    // Grabbing some resources or intensive calculation\n    // using person object anyhow.\n}\n\n\nPrevious leads to normal logic flow to get no photo of a non-existent girlfriend from my photo library.\n\ngetPhotoOfThePerson(me.getGirlfriend())\n\n\nAnd it fits with new coming Java API (looking forward)\n\ngetPhotoByName(me.getGirlfriend()?.getName())\n\n\nWhile it is rather 'normal business flow' not to find photo stored into the DB for some person, I used to use pairs like below for some other cases\n\npublic static MyEnum parseMyEnum(String value); // throws IllegalArgumentException\npublic static MyEnum parseMyEnumOrNull(String value);\n\n\nAnd don't loathe to type <alt> + <shift> + <j> (generate javadoc in Eclipse) and write three additional words for you public API. This will be more than enough for all but those who don't read documentation.\n\n/**\n * @return photo or null\n */\n\n\nor\n\n/**\n * @return photo, never null\n */\n\n\nThis is rather theoretical case and in most cases you should prefer java null safe API (in case it will be released in another 10 years), but NullPointerException is subclass of an Exception. Thus it is a form of Throwable that indicates conditions that a reasonable application might want to catch (javadoc)! To use the first most advantage of exceptions and separate error-handling code from 'regular' code (according to creators of Java) it is appropriate, as for me, to catch NullPointerException.\n\npublic Photo getGirlfriendPhoto() {\n    try {\n        return appContext.getPhotoDataSource().getPhotoByName(me.getGirlfriend().getName());\n    } catch (NullPointerException e) {\n        return null;\n    }\n}\n\n\nQuestions could arise:\n\nQ. What if getPhotoDataSource() returns null?\nA. It is up to business logic. If I fail to find a photo album I'll show you no photos. What if appContext is not initialized? This method's business logic puts up with this. If the same logic should be more strict then throwing an exception it is part of the business logic and explicit check for null should be used (case 3). The new Java Null-safe API fits better here to specify selectively what implies and what does not imply to be initialized to be fail-fast in case of programmer errors.\n\nQ. Redundant code could be executed and unnecessary resources could be grabbed.\nA. It could take place if getPhotoByName() would try to open a database connection, create PreparedStatement and use the person name as an SQL parameter at last. The approach for an unknown question gives an unknown answer (case 1) works here. Before grabbing resources the method should check parameters and return 'unknown' result if needed.\n\nQ. This approach has a performance penalty due to the try closure opening.\nA. Software should be easy to understand and modify firstly. Only after this, one could think about performance, and only if needed! and where needed! (source), and many others).\n\nPS. This approach will be as reasonable to use as the separate error-handling code from \"regular\" code principle is reasonable to use in some place. Consider the next example:\n\npublic SomeValue calculateSomeValueUsingSophisticatedLogic(Predicate predicate) {\n    try {\n        Result1 result1 = performSomeCalculation(predicate);\n        Result2 result2 = performSomeOtherCalculation(result1.getSomeProperty());\n        Result3 result3 = performThirdCalculation(result2.getSomeProperty());\n        Result4 result4 = performLastCalculation(result3.getSomeProperty());\n        return result4.getSomeProperty();\n    } catch (NullPointerException e) {\n        return null;\n    }\n}\n\npublic SomeValue calculateSomeValueUsingSophisticatedLogic(Predicate predicate) {\n    SomeValue result = null;\n    if (predicate != null) {\n        Result1 result1 = performSomeCalculation(predicate);\n        if (result1 != null && result1.getSomeProperty() != null) {\n            Result2 result2 = performSomeOtherCalculation(result1.getSomeProperty());\n            if (result2 != null && result2.getSomeProperty() != null) {\n                Result3 result3 = performThirdCalculation(result2.getSomeProperty());\n                if (result3 != null && result3.getSomeProperty() != null) {\n                    Result4 result4 = performLastCalculation(result3.getSomeProperty());\n                    if (result4 != null) {\n                        result = result4.getSomeProperty();\n                    }\n                }\n            }\n        }\n    }\n    return result;\n}\n\n\nPPS. For those fast to downvote (and not so fast to read documentation) I would like to say that I've never caught a null-pointer exception (NPE) in my life. But this possibility was intentionally designed by the Java creators because NPE is a subclass of Exception. We have a precedent in Java history when ThreadDeath is an Error not because it is actually an application error, but solely because it was not intended to be caught! How much NPE fits to be an Error than ThreadDeath! But it is not.\n\nCheck for 'No data' only if business logic implies it.\n\npublic void updatePersonPhoneNumber(Long personId, String phoneNumber) {\n    if (personId == null)\n        return;\n    DataSource dataSource = appContext.getStuffDataSource();\n    Person person = dataSource.getPersonById(personId);\n    if (person != null) {\n        person.setPhoneNumber(phoneNumber);\n        dataSource.updatePerson(person);\n    } else {\n        Person = new Person(personId);\n        person.setPhoneNumber(phoneNumber);\n        dataSource.insertPerson(person);\n    }\n}\n\n\nand\n\npublic void updatePersonPhoneNumber(Long personId, String phoneNumber) {\n    if (personId == null)\n        return;\n    DataSource dataSource = appContext.getStuffDataSource();\n    Person person = dataSource.getPersonById(personId);\n    if (person == null)\n        throw new SomeReasonableUserException(\"What are you thinking about ???\");\n    person.setPhoneNumber(phoneNumber);\n    dataSource.updatePerson(person);\n}\n\n\nIf appContext or dataSource is not initialized unhandled runtime NullPointerException will kill current thread and will be processed by Thread.defaultUncaughtExceptionHandler (for you to define and use your favorite logger or other notification mechanizm). If not set, ThreadGroup#uncaughtException will print stacktrace to system err. One should monitor application error log and open Jira issue for each unhandled exception which in fact is application error. Programmer should fix bug somewhere in initialization stuff.\n\nShare\nImprove this answer\nFollow\nedited Feb 23 '18 at 22:03\ncommunity wiki\n\n\n45 revs, 2 users 73%\nMykhaylo Adamovych","comments":["Catching NullPointerException and returning null is horrible to debug. You end up with NPE later on anyway, and it's really hard to figure out what was originally null.","I'd downvote if I had the reputation. Not only is null not necessary, it's a hole in the type system. Assigning a Tree to a List is a type error because trees are not values of type List; by that same logic, assigning null should be a type error because null is not a value of type Object, or any useful type for that matter. Even the man that invented null considers it his \"billion-dollar mistake\". The notion of \"a value that might be a value of type T OR nothing\" is its own type, and should be represented as such (e.g. Maybe<T> or Optional<T>).","As of \"Maybe<T> or Optional<T>\" you still need to write code like if (maybeNull.hasValue()) {...} so what is the difference with if (maybeNull != null)) {...}?","As of \"catching NullPointerException and returning null is horrible to debug. You end up with NPE later on anyway, and it's really hard to figure out what was originally null\". I'm totally agree! In those cases you should write a dozen of 'if' statements or throw NPE if business logic imply data in-place, or use null-safe operator from new Java. But there are cases when I don't care about what exact step give me null. For example calculating some values for the user just before showing on the screen when you do expect data could be missing.","@MykhayloAdamovych: The benefit of Maybe<T> or Optional<T> isn't in the case where your T might be null, but in the case where it should never be null. If you have a type that explicitly means \"this value might be null -- use with caution\", and you use and return such a type consistently, then whenever you see a plain old T in your code, you can assume it is never null. (Course, this would be a lot more useful if enforceable by the compiler.)"]},{"answer":"Java 7 has a new java.util.Objects utility class on which there is a requireNonNull() method. All this does is throw a NullPointerException if its argument is null, but it cleans up the code a bit. Example:\n\nObjects.requireNonNull(someObject);\nsomeObject.doCalc();\n\n\nThe method is most useful for checking just before an assignment in a constructor, where each use of it can save three lines of code:\n\nParent(Child child) {\n   if (child == null) {\n      throw new NullPointerException(\"child\");\n   }\n   this.child = child;\n}\n\n\nbecomes\n\nParent(Child child) {\n   this.child = Objects.requireNonNull(child, \"child\");\n}\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:18\ncommunity wiki\n\n\n3 revs, 2 users 67%\nRaedwald","comments":["Actually, your example constitutes code bloat: the first line is superfluous because the NPE would be thrown in the second line. ;-)","True. A better example would be if the second line were doCalc(someObject).","Depends. If you are the author of doCalc(), I'd suggest putting the check into that method's body (if possible). And then you most likely will call someObject.someMethod() where again there is no need to check for null. :-)","Well, if you are not the author of doCalc(), and it doesn't immediately throw NPE when given null, you'd need to check for null and throw NPE yourself. That's what Objects.requireNonNull() is for.","It's not just code bloat. Better to check up front than halfway through a method that causes side effects or uses time/space."]},{"answer":"Ultimately, the only way to completely solve this problem is by using a different programming language:\n\nIn Objective-C, you can do the equivalent of invoking a method on nil, and absolutely nothing will happen. This makes most null checks unnecessary, but it can make errors much harder to diagnose.\nIn Nice, a Java-derived language, there are two versions of all types: a potentially-null version and a not-null version. You can only invoke methods on not-null types. Potentially-null types can be converted to not-null types through explicit checking for null. This makes it much easier to know where null checks are necessary and where they aren't.\nShare\nImprove this answer\nFollow\nedited Sep 19 '15 at 16:09\ncommunity wiki\n\n\n2 revs, 2 users 75%\nMichael Borgwardt","comments":["I am not familiar with Nice, but Kotlin implements the same idea, have nullable and not-null types build into the language's type system. A lot more concise than Optionals or null Object pattern."]},{"answer":"Common \"problem\" in Java indeed.\n\nFirst, my thoughts on this:\n\nI consider that it is bad to \"eat\" something when NULL was passed where NULL isn't a valid value. If you're not exiting the method with some sort of error then it means nothing went wrong in your method which is not true. Then you probably return null in this case, and in the receiving method you again check for null, and it never ends, and you end up with \"if != null\", etc..\n\nSo, IMHO, null must be a critical error which prevents further execution (that is, where null is not a valid value).\n\nThe way I solve this problem is this:\n\nFirst, I follow this convention:\n\nAll public methods / API always check its arguments for null\nAll private methods do not check for null since they are controlled methods (just let die with nullpointer exception in case it wasn't handled above)\nThe only other methods which do not check for null are utility methods. They are public, but if you call them for some reason, you know what parameters you pass. This is like trying to boil water in the kettle without providing water...\n\nAnd finally, in the code, the first line of the public method goes like this:\n\nValidationUtils.getNullValidator().addParam(plans, \"plans\").addParam(persons, \"persons\").validate();\n\n\nNote that addParam() returns self, so that you can add more parameters to check.\n\nMethod validate() will throw checked ValidationException if any of the parameters is null (checked or unchecked is more a design/taste issue, but my ValidationException is checked).\n\nvoid validate() throws ValidationException;\n\n\nThe message will contain the following text if, for example, \"plans\" is null:\n\n\"Illegal argument value null is encountered for parameter [plans]\"\n\nAs you can see, the second value in the addParam() method (string) is needed for the user message, because you cannot easily detect passed-in variable name, even with reflection (not subject of this post anyway...).\n\nAnd yes, we know that beyond this line we will no longer encounter a null value so we just safely invoke methods on those objects.\n\nThis way, the code is clean, easy maintainable and readable.\n\nShare\nImprove this answer\nFollow\nedited Sep 19 '15 at 19:00\ncommunity wiki\n\n\n3 revs, 3 users 79%\nOleg","comments":["Absolutely. Applications that just throw the error and crash are of higher quality because there is no doubt when they are not working. Applications that swallow the errors at best degrade gracefully but usually don't work in ways that are difficult to notice and don't get fixed. And when the problem is noticed they are much harder to debug."]},{"answer":"In addition to using assert you can use the following:\n\nif (someobject == null) {\n    // Handle null here then move on.\n}\n\n\nThis is slightly better than:\n\nif (someobject != null) {\n    .....\n    .....\n\n\n\n    .....\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 19 '15 at 17:14\ncommunity wiki\n\n\n2 revs, 2 users 91%\nfastcodejava","comments":["Mh, why that? Please don't feel any defensive, I'd just like to learn more about Java :)","@Mudu As a general rule, I prefer the expression in an if statement to be a more \"positive\" statement, rather than a \"negative\" one. So if I saw if (!something) { x(); } else { y(); } I would be inclined to refactor it as if (something) { y(); } else { x(); } (though one could argue that != null is the more positive option...). But more importantly, the important part of the code is not wrapped inside {}s and you have one level less of indentation for most of the method. I don't know if that was fastcodejava's reasoning but that would be mine.","This is what I tend to do as well.. Keeps the code clean in my opinon.","@MatrixFrog Yeah that makes the code cleaner and easily readable, as you see the important code (when everything function without errors) first."]},{"answer":"Asking that question points out that you may be interested in error handling strategies. How and where to handle errors is a pervasive architectural question. There are several ways to do this.\n\nMy favorite: allow the Exceptions to ripple through - catch them at the 'main loop' or in some other function with the appropriate responsibilities. Checking for error conditions and handling them appropriately can be seen as a specialized responsibility.\n\nSure do have a look at Aspect Oriented Programming, too - they have neat ways to insert if( o == null ) handleNull() into your bytecode.\n\nShare\nImprove this answer\nFollow\nedited Jun 25 '20 at 12:24\ncommunity wiki\n\n\n2 revs\nxtofl","comments":[]},{"answer":"Just don't ever use null. Don't allow it.\n\nIn my classes, most fields and local variables have non-null default values, and I add contract statements (always-on asserts) everywhere in the code to make sure this is being enforced (since it's more succinct, and more expressive than letting it come up as an NPE and then having to resolve the line number, etc.).\n\nOnce I adopted this practice, I noticed that the problems seemed to fix themselves. You'd catch things much earlier in the development process just by accident and realize you had a weak spot.. and more importantly.. it helps encapsulate different modules' concerns, different modules can 'trust' each other, and no more littering the code with if = null else constructs!\n\nThis is defensive programming and results in much cleaner code in the long run. Always sanitize the data, e.g. here by enforcing rigid standards, and the problems go away.\n\nclass C {\n    private final MyType mustBeSet;\n    public C(MyType mything) {\n       mustBeSet=Contract.notNull(mything);\n    }\n   private String name = \"<unknown>\";\n   public void setName(String s) {\n      name = Contract.notNull(s);\n   }\n}\n\n\nclass Contract {\n    public static <T> T notNull(T t) { if (t == null) { throw new ContractException(\"argument must be non-null\"); return t; }\n}\n\n\nThe contracts are like mini-unit tests which are always running, even in production, and when things fail, you know why, rather than a random NPE you have to somehow figure out.\n\nShare\nImprove this answer\nFollow\nedited Sep 19 '15 at 19:42\ncommunity wiki\n\n\n3 revs, 3 users 68%\niangreen","comments":["why would this be downvoted? in my experience, this is far superior to the other approaches, would love to know why not","I agree, this approach prevents problems related to nulls, rather than fixing them by speckling code null checks everywhere.","The problem with this approach is that if name is never set, it has the value \"<unknown>\", which behaves like a set value. Now let's say I need to check if name was never set (unknown), I have to do a string comparison against the special value \"<unknown>\".","True good point Steve. What I often do is have that value as a constant, e.g. public static final String UNSET=\"__unset\" ... private String field = UNSET ... then private boolean isSet() { return UNSET.equals(field); }","IMHO, This is a implementation of Null Object Pattern with a yourself implementation of Optional (Contract). How it behaves on persistence class class? I do not see applicable in that case."]},{"answer":"Guava, a very useful core library by Google, has a nice and useful API to avoid nulls. I find UsingAndAvoidingNullExplained very helpful.\n\nAs explained in the wiki:\n\nOptional<T> is a way of replacing a nullable T reference with a non-null value. An Optional may either contain a non-null T reference (in which case we say the reference is \"present\"), or it may contain nothing (in which case we say the reference is \"absent\"). It is never said to \"contain null.\"\n\nUsage:\n\nOptional<Integer> possible = Optional.of(5);\npossible.isPresent(); // returns true\npossible.get(); // returns 5\n\nShare\nImprove this answer\nFollow\nedited Aug 7 '14 at 21:03\ncommunity wiki\n\n\n2 revs\nMurat","comments":["@CodyGuldner Right, Cody. I provided a relevant quote from the link to give more context."]},{"answer":"This is a very common problem for every Java developer. So there is official support in Java 8 to address these issues without cluttered code.\n\nJava 8 has introduced java.util.Optional<T>. It is a container that may or may not hold a non-null value. Java 8 has given a safer way to handle an object whose value may be null in some of the cases. It is inspired from the ideas of Haskell and Scala.\n\nIn a nutshell, the Optional class includes methods to explicitly deal with the cases where a value is present or absent. However, the advantage compared to null references is that the Optional<T> class forces you to think about the case when the value is not present. As a consequence, you can prevent unintended null pointer exceptions.\n\nIn above example we have a home service factory that returns a handle to multiple appliances available in the home. But these services may or may not be available/functional; it means it may result in a NullPointerException. Instead of adding a null if condition before using any service, let's wrap it in to Optional<Service>.\n\nWRAPPING TO OPTION<T>\n\nLet's consider a method to get a reference of a service from a factory. Instead of returning the service reference, wrap it with Optional. It lets the API user know that the returned service may or may not available/functional, use defensively\n\npublic Optional<Service> getRefrigertorControl() {\n      Service s = new  RefrigeratorService();\n       //...\n      return Optional.ofNullable(s);\n   }\n\n\nAs you see Optional.ofNullable() provides an easy way to get the reference wrapped. There are another ways to get the reference of Optional, either Optional.empty() & Optional.of(). One for returning an empty object instead of retuning null and the other to wrap a non-nullable object, respectively.\n\nSO HOW EXACTLY IT HELPS TO AVOID A NULL CHECK?\n\nOnce you have wrapped a reference object, Optional provides many useful methods to invoke methods on a wrapped reference without NPE.\n\nOptional ref = homeServices.getRefrigertorControl();\nref.ifPresent(HomeServices::switchItOn);\n\n\nOptional.ifPresent invokes the given Consumer with a reference if it is a non-null value. Otherwise, it does nothing.\n\n@FunctionalInterface\npublic interface Consumer<T>\n\n\nRepresents an operation that accepts a single input argument and returns no result. Unlike most other functional interfaces, Consumer is expected to operate via side-effects. It is so clean and easy to understand. In the above code example, HomeService.switchOn(Service) gets invoked if the Optional holding reference is non-null.\n\nWe use the ternary operator very often for checking null condition and return an alternative value or default value. Optional provides another way to handle the same condition without checking null. Optional.orElse(defaultObj) returns defaultObj if the Optional has a null value. Let's use this in our sample code:\n\npublic static Optional<HomeServices> get() {\n    service = Optional.of(service.orElse(new HomeServices()));\n    return service;\n}\n\n\nNow HomeServices.get() does same thing, but in a better way. It checks whether the service is already initialized of not. If it is then return the same or create a new New service. Optional<T>.orElse(T) helps to return a default value.\n\nFinally, here is our NPE as well as null check-free code:\n\nimport java.util.Optional;\npublic class HomeServices {\n    private static final int NOW = 0;\n    private static Optional<HomeServices> service;\n\npublic static Optional<HomeServices> get() {\n    service = Optional.of(service.orElse(new HomeServices()));\n    return service;\n}\n\npublic Optional<Service> getRefrigertorControl() {\n    Service s = new  RefrigeratorService();\n    //...\n    return Optional.ofNullable(s);\n}\n\npublic static void main(String[] args) {\n    /* Get Home Services handle */\n    Optional<HomeServices> homeServices = HomeServices.get();\n    if(homeServices != null) {\n        Optional<Service> refrigertorControl = homeServices.get().getRefrigertorControl();\n        refrigertorControl.ifPresent(HomeServices::switchItOn);\n    }\n}\n\npublic static void switchItOn(Service s){\n         //...\n    }\n}\n\n\nThe complete post is NPE as well as Null check-free code … Really?.\n\nShare\nImprove this answer\nFollow\nedited Sep 19 '15 at 20:39\ncommunity wiki\n\n\n2 revs, 2 users 87%\nYogesh Devatraj","comments":["There's a null check in above code - if(homeServices != null) { which can be changed to homeServices.ifPresent(h -> //action);"]},{"answer":"I like articles from Nat Pryce. Here are the links:\n\nAvoiding Nulls with Polymorphic Dispatch\nAvoiding Nulls with \"Tell, Don't Ask\" Style\n\nIn the articles there is also a link to a Git repository for a Java Maybe Type which I find interesting, but I don't think it alone could decrease the checking code bloat. After doing some research on the Internet, I think != null code bloat could be decreased mainly by careful design.\n\nShare\nImprove this answer\nFollow\nedited May 12 '16 at 2:49\ncommunity wiki\n\n\n2 revs, 2 users 74%\nMr Palo","comments":["Michael Feathers has written an short and interesthing text about approaches like the one you mentioned: manuelp.newsblur.com/site/424","If there's anything I appreciated most about this answer, it's the \"careful design\" tip. Whether it boils down to writing code, fixing bugs or checking for nullity, it's DAMN CRUCIAL to make an overall good design and organisation in code, to avoid many redundancies that we still have to deal with today because of bad design choices made a long time ago..."]},{"answer":"I've tried the NullObjectPattern but for me is not always the best way to go. There are sometimes when a \"no action\" is not appropiate.\n\nNullPointerException is a Runtime exception that means it's developers fault and with enough experience it tells you exactly where is the error.\n\nNow to the answer:\n\nTry to make all your attributes and its accessors as private as possible or avoid to expose them to the clients at all. You can have the argument values in the constructor of course, but by reducing the scope you don't let the client class pass an invalid value. If you need to modify the values, you can always create a new object. You check the values in the constructor only once and in the rest of the methods you can be almost sure that the values are not null.\n\nOf course, experience is the better way to understand and apply this suggestion.\n\nByte!\n\nShare\nImprove this answer\nFollow\nedited Sep 30 '13 at 22:06\ncommunity wiki\n\n\n3 revs, 2 users 91%\nOscarRyz","comments":[]},{"answer":"Probably the best alternative for Java 8 or newer is to use the Optional class.\n\nOptional stringToUse = Optional.of(\"optional is there\");\nstringToUse.ifPresent(System.out::println);\n\n\nThis is especially handy for long chains of possible null values. Example:\n\nOptional<Integer> i = Optional.ofNullable(wsObject.getFoo())\n    .map(f -> f.getBar())\n    .map(b -> b.getBaz())\n    .map(b -> b.getInt());\n\n\nExample on how to throw exception on null:\n\nOptional optionalCarNull = Optional.ofNullable(someNull);\noptionalCarNull.orElseThrow(IllegalStateException::new);\n\n\nJava 7 introduced the Objects.requireNonNull method which can be handy when something should be checked for non-nullness. Example:\n\nString lowerVal = Objects.requireNonNull(someVar, \"input cannot be null or empty\").toLowerCase();\n\nShare\nImprove this answer\nFollow\nedited Sep 29 '16 at 7:35\ncommunity wiki\n\n\n3 revs, 2 users 74%\nRaghu K Nair","comments":["you said, \"This is especially handy for long chains of possible null values\". Can you please explain how?"]},{"answer":"May I answer it more generally!\n\nWe usually face this issue when the methods get the parameters in the way we not expected (bad method call is programmer's fault). For example: you expect to get an object, instead you get a null. You expect to get an String with at least one character, instead you get an empty String ...\n\nSo there is no difference between:\n\nif(object == null){\n   //you called my method badly!\n\n\n}\n\nor\n\nif(str.length() == 0){\n   //you called my method badly again!\n}\n\n\nThey both want to make sure that we received valid parameters, before we do any other functions.\n\nAs mentioned in some other answers, to avoid above problems you can follow the Design by contract pattern. Please see http://en.wikipedia.org/wiki/Design_by_contract.\n\nTo implement this pattern in java, you can use core java annotations like javax.annotation.NotNull or use more sophisticated libraries like Hibernate Validator.\n\nJust a sample:\n\ngetCustomerAccounts(@NotEmpty String customerId,@Size(min = 1) String accountType)\n\n\nNow you can safely develop the core function of your method without needing to check input parameters, they guard your methods from unexpected parameters.\n\nYou can go a step further and make sure that only valid pojos could be created in your application. (sample from hibernate validator site)\n\npublic class Car {\n\n   @NotNull\n   private String manufacturer;\n\n   @NotNull\n   @Size(min = 2, max = 14)\n   private String licensePlate;\n\n   @Min(2)\n   private int seatCount;\n\n   // ...\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 24 '14 at 14:48\ncommunity wiki\n\n\n2 revs, 2 users 96%\nAlireza Fattahi","comments":["javax is, by definition, not \"core Java\"."]},{"answer":"I highly disregard answers that suggest using the null objects in every situation. This pattern may break the contract and bury problems deeper and deeper instead of solving them, not mentioning that used inappropriately will create another pile of boilerplate code that will require future maintenance.\n\nIn reality if something returned from a method can be null and the calling code has to make decision upon that, there should an earlier call that ensures the state.\n\nAlso keep in mind, that null object pattern will be memory hungry if used without care. For this - the instance of a NullObject should be shared between owners, and not be an unigue instance for each of these.\n\nAlso I would not recommend using this pattern where the type is meant to be a primitive type representation - like mathematical entities, that are not scalars: vectors, matrices, complex numbers and POD(Plain Old Data) objects, which are meant to hold state in form of Java built-in types. In the latter case you would end up calling getter methods with arbitrary results. For example what should a NullPerson.getName() method return?\n\nIt's worth considering such cases in order to avoid absurd results.\n\nShare\nImprove this answer\nFollow\nedited Feb 4 '16 at 11:24\ncommunity wiki\n\n\n4 revs\nluke1985","comments":["The solution with \"hasBackground()\" has one drawback - it's not thread-safe. If you need to call two methods instead of one, you need to synchronize the whole sequence in multi-threaded environment.","@pkalinow You made a contrived example only to point out that this solution has a drawback. If code is not meant to run in multithreaded application then there is no drawback. I could put at you probably 90% of your code that is not thread safe. We're not speaking here about this aspect of code, we're speaking about design pattern. And multithreading is a topic on its own.","Of course in a single-thread application it's not a problem. I've given that comment because sometimes it is a problem.","@pkalinow If you study this topic closer you will find out that Null Object design pattern won't fix the multithreading problems. So it's irrelevant. And to be honest, I've found places where this pattern would fit in nicely, so my original answer is a bit wrong, actually."]},{"answer":"Never initialise variables to null.\nIf (1) is not possible, initialise all collections and arrays to empty collections/arrays.\n\nDoing this in your own code and you can avoid != null checks.\n\nMost of the time null checks seem to guard loops over collections or arrays, so just initialise them empty, you won't need any null checks.\n\n// Bad\nArrayList<String> lemmings;\nString[] names;\n\nvoid checkLemmings() {\n    if (lemmings != null) for(lemming: lemmings) {\n        // do something\n    }\n}\n\n\n\n// Good\nArrayList<String> lemmings = new ArrayList<String>();\nString[] names = {};\n\nvoid checkLemmings() {\n    for(lemming: lemmings) {\n        // do something\n    }\n}\n\n\nThere is a tiny overhead in this, but it's worth it for cleaner code and less NullPointerExceptions.\n\nShare\nImprove this answer\nFollow\nedited Oct 2 '13 at 13:50\ncommunity wiki\n\n\n2 revs\nStuart Axon","comments":["stackoverflow.com/questions/1386275/…","+1 This I agree with. You should never return half initialized objects. Jaxb related code and bean code is notiroius for this. It is bad practice. All collections should be initialized, and all objects should exist with (ideally) no null references. Consider a object that has a collection in it. Checking that the object is not null, that the collection is not null and that the collection does not contain null objects is unreasonable and foolish."]},{"answer":"This is the most common error occurred for most of the developers.\n\nWe have number of ways to handle this.\n\nApproach 1:\n\norg.apache.commons.lang.Validate //using apache framework\n\n\nnotNull(Object object, String message)\n\nApproach 2:\n\nif(someObject!=null){ // simply checking against null\n}\n\n\nApproach 3:\n\n@isNull @Nullable  // using annotation based validation\n\n\nApproach 4:\n\n// by writing static method and calling it across whereever we needed to check the validation\n\nstatic <T> T isNull(someObject e){  \n   if(e == null){\n      throw new NullPointerException();\n   }\n   return e;\n}\n\nShare\nImprove this answer\nFollow\nedited Mar 24 '15 at 17:13\ncommunity wiki\n\n\n2 revs, 2 users 81%\nSireesh Yarlagadda","comments":["Ad. 4. It is not very useful - when you check if a pointer is null, you probably want to call a method on it. Calling a method on null gives you the same behavior - NullPointerException."]},{"answer":"public static <T> T ifNull(T toCheck, T ifNull) {\n    if (toCheck == null) {\n           return ifNull;\n    }\n    return toCheck;\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 19 '15 at 17:17\ncommunity wiki\n\n\n2 revs, 2 users 67%\ntltester","comments":["What's wrong with this method, I think @tltester just want to give a default value if the it's null, which make sense.","There is such a method in Apache commons-lang: ObjectUtils.defaultIfNull(). There is one more general: ObjectUtils.firstNonNull(), which can be used to implement a degrading strategy: firstNonNull(bestChoice, secondBest, thirdBest, fallBack);"]}]},{"id":"952914","href":"https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-a-list-of-lists","title":"How to make a flat list out of a list of lists","description":"\n                \nIs there a shortcut to make a simple list out of a list of lists in Python?\nI can do it in a for loop, but is there some cool \"one-liner\"?\nI tried it with functools.reduce():\nfrom functools import reduce\nl = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\nreduce(lambda x, y: x.extend(y), l)\n\nBut I get this error:\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<stdin>\", line 1, in <lambda>\nAttributeError: 'NoneType' object has no attribute 'extend'\n\n    ","questionComments":["There's an in-depth discussion of this here: rightfootin.blogspot.com/2006/09/more-on-python-flatten.html, discussing several methods of flattening arbitrarily nested lists of lists. An interesting read!","Some other answers are better but the reason yours fails is that the 'extend' method always returns None. For a list with length 2, it will work but return None. For a longer list, it will consume the first 2 args, which returns None. It then continues with None.extend(<third arg>), which causes this erro","@shawn-chin solution is the more pythonic here, but if you need to preserve the sequence type, say you have a tuple of tuples rather than a list of lists, then you should use reduce(operator.concat, tuple_of_tuples). Using operator.concat with tuples seems to perform faster than chain.from_iterables with list.","stackoverflow.com/questions/50259290/… (this article explain the difference between an np.flatten() and a tf.flatten() use (static vs dynamic) ndarray.","Is your list-of-lists a perfectly two-level list? by which I mean, is every integer in a list which is in another list - so exactly two levels? (as opposed to having some integers in a nested list and some integers directly in the first list). The fact that you have [7] in your list (instead of 7) indicates that yes, it is a perfectly two-level list. So wouldn't sthg very simple like l2=[] followed by [l2.extend(i) for i in l] do the trick?"],"answers":[{"answer":"Given a list of lists t,\n\nflat_list = [item for sublist in t for item in sublist]\n\n\nwhich means:\n\nflat_list = []\nfor sublist in t:\n    for item in sublist:\n        flat_list.append(item)\n\n\nis faster than the shortcuts posted so far. (t is the list to flatten.)\n\nHere is the corresponding function:\n\ndef flatten(t):\n    return [item for sublist in t for item in sublist]\n\n\nAs evidence, you can use the timeit module in the standard library:\n\n$ python -mtimeit -s't=[[1,2,3],[4,5,6], [7], [8,9]]*99' '[item for sublist in t for item in sublist]'\n10000 loops, best of 3: 143 usec per loop\n$ python -mtimeit -s't=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'sum(t, [])'\n1000 loops, best of 3: 969 usec per loop\n$ python -mtimeit -s't=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'reduce(lambda x,y: x+y,t)'\n1000 loops, best of 3: 1.1 msec per loop\n\n\nExplanation: the shortcuts based on + (including the implied use in sum) are, of necessity, O(T**2) when there are T sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have T sublists of k items each: the first k items are copied back and forth T-1 times, the second k items T-2 times, and so on; total number of copies is k times the sum of x for x from 1 to T excluded, i.e., k * (T**2)/2.\n\nThe list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 18:40\nwjandrea\n18.1k5\n5 gold badges\n31\n31 silver badges\n55\n55 bronze badges\nanswered Jun 4 '09 at 20:37\nAlex Martelli\n774k158\n158 gold badges\n1171\n1171 silver badges\n1352\n1352 bronze badges","comments":["I tried a test with the same data, using itertools.chain.from_iterable : $ python -mtimeit -s'from itertools import chain; l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'list(chain.from_iterable(l))'. It runs a bit more than twice as fast as the nested list comprehension that's the fastest of the alternatives shown here.","I found the syntax hard to understand until I realized you can think of it exactly like nested for loops. for sublist in l: for item in sublist: yield item","[leaf for tree in forest for leaf in tree] might be easier to comprehend and apply.","@RobCrowell Same here. To me the list comprehension one doesn't read right, something feels off about it - I always seem to get it wrong and end up googling. To me this reads right [leaf for leaf in tree for tree in forest]. I wish this is how it was. I am sure I am missing something about the grammar here, and I would appreciate if anyone could point that out.","I kept looking here every time I wanted to flatten a list, but this gif is what drove it home: i.stack.imgur.com/0GoV5.gif"]},{"answer":"You can use itertools.chain():\n\nimport itertools\n\nlist2d = [[1,2,3], [4,5,6], [7], [8,9]]\nmerged = list(itertools.chain(*list2d))\n\n\nOr you can use itertools.chain.from_iterable() which doesn't require unpacking the list with the * operator:\n\nmerged = list(itertools.chain.from_iterable(list2d))\n\nShare\nImprove this answer\nFollow\nedited Mar 11 at 11:25\niacob\n9,3584\n4 gold badges\n32\n32 silver badges\n60\n60 bronze badges\nanswered Jun 4 '09 at 21:06\nShawn Chin\n75.5k17\n17 gold badges\n154\n154 silver badges\n185\n185 bronze badges","comments":["The * is the tricky thing that makes chain less straightforward than the list comprehension. You have to know that chain only joins together the iterables passed as parameters, and the * causes the top-level list to be expanded into parameters, so chain joins together all those iterables, but doesn't descend further. I think this makes the comprehension more readable than the use of chain in this case.","@TimDierks: I'm not sure \"this requires you to understand Python syntax\" is an argument against using a given technique in Python. Sure, complex usage could confuse, but the \"splat\" operator is generally useful in many circumstances, and this isn't using it in a particularly obscure way; rejecting all language features that aren't necessarily obvious to beginning users means you're tying one hand behind your back. May as well throw out list comprehensions too while you're at it; users from other backgrounds would find a for loop that repeatedly appends more obvious."]},{"answer":"Note from the author: This is inefficient. But fun, because monoids are awesome. It's not appropriate for production Python code.\n\n>>> l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\n>>> sum(l, [])\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nThis just sums the elements of iterable passed in the first argument, treating second argument as the initial value of the sum (if not given, 0 is used instead and this case will give you an error).\n\nBecause you are summing nested lists, you actually get [1,3]+[2,4] as a result of sum([[1,3],[2,4]],[]), which is equal to [1,3,2,4].\n\nNote that only works on lists of lists. For lists of lists of lists, you'll need another solution.\n\nShare\nImprove this answer\nFollow\nedited May 19 at 10:17\nFlimm\n102k33\n33 gold badges\n206\n206 silver badges\n223\n223 bronze badges\nanswered Jun 4 '09 at 20:35\nTriptych\n191k32\n32 gold badges\n145\n145 silver badges\n168\n168 bronze badges","comments":["that's pretty neat and clever but I wouldn't use it because it's confusing to read.","This is a Shlemiel the painter's algorithm joelonsoftware.com/articles/fog0000000319.html -- unnecessarily inefficient as well as unnecessarily ugly.","The append operation on lists forms a Monoid, which is one of the most convenient abstractions for thinking of a + operation in a general sense (not limited to numbers only). So this answer deserves a +1 from me for (correct) treatment of lists as a monoid. The performance is concerning though...","@andrewrk Well, some people think that this is the cleanest way of doing it : youtube.com/watch?v=IOiZatlZtGU the ones who do not get why this is cool just need to wait a few decades until everybody does it this way :) let's use programming languages (and abstractions) that are discovered and not invented, Monoid is discovered.","this is a very inefficient way because of the quadratic aspect of the sum."]},{"answer":"I tested most suggested solutions with perfplot (a pet project of mine, essentially a wrapper around timeit), and found\n\nimport functools\nimport operator\nfunctools.reduce(operator.iconcat, a, [])\n\n\nto be the fastest solution, both when many small lists and few long lists are concatenated. (operator.iadd is equally fast.)\n\nCode to reproduce the plot:\n\nimport functools\nimport itertools\nimport numpy\nimport operator\nimport perfplot\n\n\ndef forfor(a):\n    return [item for sublist in a for item in sublist]\n\n\ndef sum_brackets(a):\n    return sum(a, [])\n\n\ndef functools_reduce(a):\n    return functools.reduce(operator.concat, a)\n\n\ndef functools_reduce_iconcat(a):\n    return functools.reduce(operator.iconcat, a, [])\n\n\ndef itertools_chain(a):\n    return list(itertools.chain.from_iterable(a))\n\n\ndef numpy_flat(a):\n    return list(numpy.array(a).flat)\n\n\ndef numpy_concatenate(a):\n    return list(numpy.concatenate(a))\n\n\nperfplot.show(\n    setup=lambda n: [list(range(10))] * n,\n    # setup=lambda n: [list(range(n))] * 10,\n    kernels=[\n        forfor,\n        sum_brackets,\n        functools_reduce,\n        functools_reduce_iconcat,\n        itertools_chain,\n        numpy_flat,\n        numpy_concatenate,\n    ],\n    n_range=[2 ** k for k in range(16)],\n    xlabel=\"num lists (of length 10)\",\n    # xlabel=\"len lists (10 lists total)\"\n)\n\nShare\nImprove this answer\nFollow\nedited Jul 16 at 5:39\nanswered Jul 26 '17 at 9:38\nNico Schlömer\n39.1k21\n21 gold badges\n144\n144 silver badges\n194\n194 bronze badges","comments":["For huge nested lists,' list(numpy.array(a).flat)' is the fastest among all functions above.","Tried using regex: 'list(map(int, re.findall(r\"[\\w]+\", str(a))))'. Speed is bit slower that numpy_concatenate","Is there a way to do a 3-d perfplot? number of arrays by average size of array?","@Sara can you define \"huge\" please?","Tried numpy_flat on the test example from Rossetta Code (link) and got VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray"]},{"answer":"Don't reinvent the wheel\nIf you use -\n\n...Django:\n\n>>> from django.contrib.admin.utils import flatten\n>>> l = [[1,2,3], [4,5], [6]]\n>>> flatten(l)\n>>> [1, 2, 3, 4, 5, 6]\n\n\n...Pandas:\n\n>>> from pandas.core.common import flatten\n>>> list(flatten(l))\n\n\n...Itertools:\n\n>>> import itertools\n>>> flatten = itertools.chain.from_iterable\n>>> list(flatten(l))\n\n\n...Matplotlib\n\n>>> from matplotlib.cbook import flatten\n>>> list(flatten(l))\n\n\n...Unipath:\n\n>>> from unipath.path import flatten\n>>> list(flatten(l))\n\n\n...Setuptools:\n\n>>> from setuptools.namespaces import flatten\n>>> list(flatten(l))\n\nShare\nImprove this answer\nFollow\nedited Mar 6 at 13:10\nDeekshant\n1113\n3 silver badges\n11\n11 bronze badges\nanswered Jul 26 '19 at 18:34\nMax Malysh\n23.3k16\n16 gold badges\n93\n93 silver badges\n105\n105 bronze badges","comments":["flatten = itertools.chain.from_iterable should be the right answer","I like the Pandas solution. If you have something like: list_of_menuitems = [1, 2, [3, [4, 5, [6]]]], it will result on: [1, 2, 3, 4, 5, 6]. What I miss is the flatten level.","now there is also more_itertools.flatten","how is this not the correct answer","don't forget numpy! np.array([[1,2], [3,4]]).flatten() becomes np.array([1,2,3,4])"]},{"answer":">>> from functools import reduce\n>>> l = [[1,2,3], [4,5,6], [7], [8,9]]\n>>> reduce(lambda x, y: x+y, l)\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nThe extend() method in your example modifies x instead of returning a useful value (which functools.reduce() expects).\n\nA faster way to do the reduce version would be\n\n>>> import operator\n>>> l = [[1,2,3], [4,5,6], [7], [8,9]]\n>>> reduce(operator.concat, l)\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nShare\nImprove this answer\nFollow\nedited Mar 18 at 12:33\nBoris\n7,6557\n7 gold badges\n66\n66 silver badges\n67\n67 bronze badges\nanswered Jun 4 '09 at 20:35\nGreg Hewgill\n843k170\n170 gold badges\n1107\n1107 silver badges\n1243\n1243 bronze badges","comments":["reduce(operator.add, l) would be the correct way to do the reduce version. Built-ins are faster than lambdas."]},{"answer":"Here is a general approach that applies to numbers, strings, nested lists and mixed containers. This can flatten both simple and complicated containers (see also Demo).\n\nCode\n\nfrom typing import Iterable \n#from collections import Iterable                            # < py38\n\n\ndef flatten(items):\n    \"\"\"Yield items from any nested iterable; see Reference.\"\"\"\n    for x in items:\n        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n            for sub_x in flatten(x):\n                yield sub_x\n        else:\n            yield x\n\n\nNotes:\n\nIn Python 3, yield from flatten(x) can replace for sub_x in flatten(x): yield sub_x\nIn Python 3.8, abstract base classes are moved from collection.abc to the typing module.\n\nDemo\n\nsimple = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\nlist(flatten(simple))\n# [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\ncomplicated = [[1, [2]], (3, 4, {5, 6}, 7), 8, \"9\"]              # numbers, strs, nested & mixed\nlist(flatten(complicated))\n# [1, 2, 3, 4, 5, 6, 7, 8, '9']\n\n\nReference\n\nThis solution is modified from a recipe in Beazley, D. and B. Jones. Recipe 4.14, Python Cookbook 3rd Ed., O'Reilly Media Inc. Sebastopol, CA: 2013.\nFound an earlier SO post, possibly the original demonstration.\nShare\nImprove this answer\nFollow\nedited Jun 11 at 13:46\nanswered Nov 29 '16 at 4:14\npylang\n29.6k10\n10 gold badges\n100\n100 silver badges\n100\n100 bronze badges","comments":["I just wrote pretty much the same, because I didn't see your solution ... here is what I looked for \"recursively flatten complete multiple lists\" ... (+1)","@MartinThoma Much appreciated. FYI, if flattening nested iterables is a common practice for you, there are some third-party packages that handle this well. This may save from reinventing the wheel. I've mentioned more_itertools among others discussed in this post. Cheers.","Maybe traverse could also be a good name for this way of a tree, whereas I'd keep it less universal for this answer by sticking to nested lists.","You can check if hasattr(x, '__iter__') instead of importing/checking against Iterable and that will exclude strings as well.","the above code doesnt seem to work for if one of the nested lists is having a list of strings. [1, 2, [3, 4], [4], [], 9, 9.5, 'ssssss', ['str', 'sss', 'ss'], [3, 4, 5]] output:- [1, 2, 3, 4, 4, 9, 9.5, 'ssssss', 3, 4, 5]"]},{"answer":"If you want to flatten a data-structure where you don't know how deep it's nested you could use iteration_utilities.deepflatten1\n\n>>> from iteration_utilities import deepflatten\n\n>>> l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\n>>> list(deepflatten(l, depth=1))\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n>>> l = [[1, 2, 3], [4, [5, 6]], 7, [8, 9]]\n>>> list(deepflatten(l))\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nIt's a generator so you need to cast the result to a list or explicitly iterate over it.\n\nTo flatten only one level and if each of the items is itself iterable you can also use iteration_utilities.flatten which itself is just a thin wrapper around itertools.chain.from_iterable:\n\n>>> from iteration_utilities import flatten\n>>> l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\n>>> list(flatten(l))\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nJust to add some timings (based on Nico Schlömer's answer that didn't include the function presented in this answer):\n\nIt's a log-log plot to accommodate for the huge range of values spanned. For qualitative reasoning: Lower is better.\n\nThe results show that if the iterable contains only a few inner iterables then sum will be fastest, however for long iterables only the itertools.chain.from_iterable, iteration_utilities.deepflatten or the nested comprehension have reasonable performance with itertools.chain.from_iterable being the fastest (as already noticed by Nico Schlömer).\n\nfrom itertools import chain\nfrom functools import reduce\nfrom collections import Iterable  # or from collections.abc import Iterable\nimport operator\nfrom iteration_utilities import deepflatten\n\ndef nested_list_comprehension(lsts):\n    return [item for sublist in lsts for item in sublist]\n\ndef itertools_chain_from_iterable(lsts):\n    return list(chain.from_iterable(lsts))\n\ndef pythons_sum(lsts):\n    return sum(lsts, [])\n\ndef reduce_add(lsts):\n    return reduce(lambda x, y: x + y, lsts)\n\ndef pylangs_flatten(lsts):\n    return list(flatten(lsts))\n\ndef flatten(items):\n    \"\"\"Yield items from any nested iterable; see REF.\"\"\"\n    for x in items:\n        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n            yield from flatten(x)\n        else:\n            yield x\n\ndef reduce_concat(lsts):\n    return reduce(operator.concat, lsts)\n\ndef iteration_utilities_deepflatten(lsts):\n    return list(deepflatten(lsts, depth=1))\n\n\nfrom simple_benchmark import benchmark\n\nb = benchmark(\n    [nested_list_comprehension, itertools_chain_from_iterable, pythons_sum, reduce_add,\n     pylangs_flatten, reduce_concat, iteration_utilities_deepflatten],\n    arguments={2**i: [[0]*5]*(2**i) for i in range(1, 13)},\n    argument_name='number of inner lists'\n)\n\nb.plot()\n\n\n1 Disclaimer: I'm the author of that library\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 18:29\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 26 '16 at 0:20\nMSeifert\n122k30\n30 gold badges\n278\n278 silver badges\n301\n301 bronze badges","comments":[]},{"answer":"I take my statement back. sum is not the winner. Although it is faster when the list is small. But the performance degrades significantly with larger lists.\n\n>>> timeit.Timer(\n        '[item for sublist in l for item in sublist]',\n        'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]] * 10000'\n    ).timeit(100)\n2.0440959930419922\n\n\nThe sum version is still running for more than a minute and it hasn't done processing yet!\n\nFor medium lists:\n\n>>> timeit.Timer(\n        '[item for sublist in l for item in sublist]',\n        'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]] * 10'\n    ).timeit()\n20.126545906066895\n>>> timeit.Timer(\n        'reduce(lambda x,y: x+y,l)',\n        'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]] * 10'\n    ).timeit()\n22.242258071899414\n>>> timeit.Timer(\n        'sum(l, [])',\n        'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]] * 10'\n    ).timeit()\n16.449732065200806\n\n\nUsing small lists and timeit: number=1000000\n\n>>> timeit.Timer(\n        '[item for sublist in l for item in sublist]',\n        'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]]'\n    ).timeit()\n2.4598159790039062\n>>> timeit.Timer(\n        'reduce(lambda x,y: x+y,l)',\n        'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]]'\n    ).timeit()\n1.5289170742034912\n>>> timeit.Timer(\n        'sum(l, [])',\n        'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]]'\n    ).timeit()\n1.0598428249359131\n\nShare\nImprove this answer\nFollow\nedited Dec 23 '13 at 9:14\ndevsaw\n9501\n1 gold badge\n12\n12 silver badges\n25\n25 bronze badges\nanswered Jun 4 '09 at 20:46\nNadia Alramli\n101k33\n33 gold badges\n168\n168 silver badges\n151\n151 bronze badges","comments":["for a truly miniscule list, e.g. one with 3 sublists, maybe -- but since sum's performance goes with O(N**2) while the list comprehension's goes with O(N), just growing the input list a little will reverse things -- indeed the LC will be \"infinitely faster\" than sum at the limit as N grows. I was responsible for designing sum and doing its first implementation in the Python runtime, and I still wish I had found a way to effectively restrict it to summing numbers (what it's really good at) and block the \"attractive nuisance\" it offers to people who want to \"sum\" lists;-)."]},{"answer":"There seems to be confusion with operator.add! When you add two lists together, the correct term for that is concat, not add. operator.concat is what you need to use.\n\nIf you're thinking functional, it is as easy as this:\n\n>>> from functools import reduce\n>>> list2d = ((1, 2, 3), (4, 5, 6), (7,), (8, 9))\n>>> reduce(operator.concat, list2d)\n(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n\nYou see reduce respects the sequence type, so when you supply a tuple, you get back a tuple. Let's try with a list:\n\n>>> list2d = [[1, 2, 3],[4, 5, 6], [7], [8, 9]]\n>>> reduce(operator.concat, list2d)\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nAha, you get back a list.\n\nHow about performance:\n\n>>> list2d = [[1, 2, 3],[4, 5, 6], [7], [8, 9]]\n>>> %timeit list(itertools.chain.from_iterable(list2d))\n1000000 loops, best of 3: 1.36 µs per loop\n\n\nfrom_iterable is pretty fast! But it's no comparison to reduce with concat.\n\n>>> list2d = ((1, 2, 3),(4, 5, 6), (7,), (8, 9))\n>>> %timeit reduce(operator.concat, list2d)\n1000000 loops, best of 3: 492 ns per loop\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 18:21\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 14 '16 at 15:09\nMeitham\n7,6234\n4 gold badges\n30\n30 silver badges\n42\n42 bronze badges","comments":["Hmm to be fair second example should be list also (or first tuple ?)","Using such small inputs isn't much of a fair comparison. For 1000 sequences of length 1000, I get 0.037 seconds for list(chain.from_iterable(...)) and 2.5 seconds for reduce(concat, ...). The problem is that reduce(concat, ...) has quadratic runtime, whereas chain is linear."]},{"answer":"You don't need extend. This should work fine:\n\nreduce(lambda x, y: x+y, l)\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 18:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 4 '09 at 20:38\nAndrea Ambu\n34.8k14\n14 gold badges\n51\n51 silver badges\n76\n76 bronze badges","comments":["for python3 from functools import reduce","Sorry that's really slow see rest of answers","This is by far the easiest to understand yet short solution that works on Python 2 and 3. I realise that a lot of Python folks are in data processing where there's huge amounts of data to process and thus care a lot about speed, but when you are writing a shell script and only have a few dozen elements in a few sub-lists, then this is perfect."]},{"answer":"Consider installing the more_itertools package.\n\n> pip install more_itertools\n\n\nIt ships with an implementation for flatten (source, from the itertools recipes):\n\nimport more_itertools\n\n\nlst = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\nlist(more_itertools.flatten(lst))\n# [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nNote: as mentioned in the docs, flatten requires a list of lists. See below on flattening more irregular inputs.\n\nAs of version 2.4, you can flatten more complicated, nested iterables with more_itertools.collapse (source, contributed by abarnet).\n\nlst = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\nlist(more_itertools.collapse(lst)) \n# [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nlst = [[1, 2, 3], [[4, 5, 6]], [[[7]]], 8, 9]              # complex nesting\nlist(more_itertools.collapse(lst))\n# [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nShare\nImprove this answer\nFollow\nedited Sep 8 '20 at 19:44\nanswered Dec 2 '16 at 18:35\npylang\n29.6k10\n10 gold badges\n100\n100 silver badges\n100\n100 bronze badges","comments":["If you can afford adding a package to your project - this answer is best","it fails when all elements are not list. (e.g. lst=[1, [2,3]]). of course integer is not iterable.","also, mind that list of strings will be flattened to a list of characters"]},{"answer":"The reason your function didn't work is because the extend extends an array in-place and doesn't return it. You can still return x from lambda, using something like this:\n\nreduce(lambda x,y: x.extend(y) or x, l)\n\n\nNote: extend is more efficient than + on lists.\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '19 at 16:26\nShan-mk\n366\n6 bronze badges\nanswered Jun 4 '09 at 20:47\nIgor Krivokon\n9,7771\n1 gold badge\n35\n35 silver badges\n41\n41 bronze badges","comments":["extend is better used as newlist = [], extend = newlist.extend, for sublist in l: extend(l) as it avoids the (rather large) overhead of the lambda, the attribute lookup on x, and the or.","for python 3 add from functools import reduce"]},{"answer":"Recursive version\n\nx = [1,2,[3,4],[5,[6,[7]]],8,9,[10]]\n\ndef flatten_list(k):\n    result = list()\n    for i in k:\n        if isinstance(i,list):\n\n            #The isinstance() function checks if the object (first argument) is an \n            #instance or subclass of classinfo class (second argument)\n\n            result.extend(flatten_list(i)) #Recursive call\n        else:\n            result.append(i)\n    return result\n\nflatten_list(x)\n#result = [1,2,3,4,5,6,7,8,9,10]\n\nShare\nImprove this answer\nFollow\nanswered Dec 14 '18 at 10:51\nSaurabh Singh\n2764\n4 silver badges\n8\n8 bronze badges","comments":["nice, no imports needed and it's clear as to what it's doing ... flattening a list, period :)","This works well with nested lists, I had something similar I had something similar recurser but without the extend..."]},{"answer":"def flatten(l, a):\n    for i in l:\n        if isinstance(i, list):\n            flatten(i, a)\n        else:\n            a.append(i)\n    return a\n\nprint(flatten([[[1, [1,1, [3, [4,5,]]]], 2, 3], [4, 5],6], []))\n\n# [1, 1, 1, 3, 4, 5, 2, 3, 4, 5, 6]\n\nShare\nImprove this answer\nFollow\nedited Nov 28 '16 at 8:48\nGuillaume Jacquenot\n9,3565\n5 gold badges\n40\n40 silver badges\n47\n47 bronze badges\nanswered Oct 26 '16 at 1:12\nAnil\n94810\n10 silver badges\n20\n20 bronze badges","comments":["def flatten(l, a=None): if a is None: a = [] [...]"]},{"answer":"The accepted answer did not work for me when dealing with text-based lists of variable lengths. Here is an alternate approach that did work for me.\n\nl = ['aaa', 'bb', 'cccccc', ['xx', 'yyyyyyy']]\n\nAccepted answer that did not work:\nflat_list = [item for sublist in l for item in sublist]\nprint(flat_list)\n['a', 'a', 'a', 'b', 'b', 'c', 'c', 'c', 'c', 'c', 'c', 'xx', 'yyyyyyy']\n\nNew proposed solution that did work for me:\nflat_list = []\n_ = [flat_list.extend(item) if isinstance(item, list) else flat_list.append(item) for item in l if item]\nprint(flat_list)\n['aaa', 'bb', 'cccccc', 'xx', 'yyyyyyy']\n\nShare\nImprove this answer\nFollow\nedited Oct 12 '18 at 1:32\nanswered Sep 24 '18 at 2:08\nuser9074332\n1,6301\n1 gold badge\n13\n13 silver badges\n33\n33 bronze badges","comments":["OP asks specifically asks for a solution for a list of lists, i.e., all list elements are themselves lists. Accepted answer does work for a list of lists."]},{"answer":"A bad feature of Anil's function above is that it requires the user to always manually specify the second argument to be an empty list []. This should instead be a default. Due to the way Python objects work, these should be set inside the function, not in the arguments.\n\nHere's a working function:\n\ndef list_flatten(l, a=None):\n    #check a\n    if a is None:\n        #initialize with empty list\n        a = []\n\n    for i in l:\n        if isinstance(i, list):\n            list_flatten(i, a)\n        else:\n            a.append(i)\n    return a\n\n\nTesting:\n\nIn [2]: lst = [1, 2, [3], [[4]],[5,[6]]]\n\nIn [3]: lst\nOut[3]: [1, 2, [3], [[4]], [5, [6]]]\n\nIn [11]: list_flatten(lst)\nOut[11]: [1, 2, 3, 4, 5, 6]\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 18:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 11 '16 at 11:53\nCoderGuy123\n5,3093\n3 gold badges\n48\n48 silver badges\n77\n77 bronze badges","comments":["instead of a=None and if statement you could use a=[]"]},{"answer":"The following seems simplest to me:\n\n>>> import numpy as np\n>>> l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\n>>> print (np.concatenate(l))\n[1 2 3 4 5 6 7 8 9]\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 18:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 5 '17 at 5:14\ndevil in the detail\n1,72512\n12 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"matplotlib.cbook.flatten() will work for nested lists even if they nest more deeply than the example.\n\nimport matplotlib\nl = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\nprint(list(matplotlib.cbook.flatten(l)))\nl2 = [[1, 2, 3], [4, 5, 6], [7], [8, [9, 10, [11, 12, [13]]]]]\nprint list(matplotlib.cbook.flatten(l2))\n\n\nResult:\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n\n\nThis is 18x faster than underscore._.flatten:\n\nAverage time over 1000 trials of matplotlib.cbook.flatten: 2.55e-05 sec\nAverage time over 1000 trials of underscore._.flatten: 4.63e-04 sec\n(time for underscore._)/(time for matplotlib.cbook) = 18.1233394636\n\nShare\nImprove this answer\nFollow\nedited Jul 20 '18 at 18:16\nanswered Feb 1 '18 at 18:22\nEL_DON\n1,1641\n1 gold badge\n14\n14 silver badges\n30\n30 bronze badges","comments":[]},{"answer":"One can also use NumPy's flat:\n\nimport numpy as np\nlist(np.array(l).flat)\n\n\nIt only works when sublists have identical dimensions.\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 18:20\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 17 '16 at 12:57\nmdh\n4,1062\n2 gold badges\n21\n21 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"I personally find it hard to remember all the modules that needed to be imported. Thus I tend to use a simple method, even though I don't know how its performance is compared to other answers.\n\nIf you just want to flatten nested lists, then the following will do the job:\n\ndef flatten(lst):\n    for item in lst:\n        if isinstance(item, list):\n            yield from flatten(item)\n        else:\n            yield item\n\n# test case:\na =[0, [], \"fun\", [1, 2, 3], [4, [5], 6], 3, [7], [8, 9]]\nlist(flatten(a))\n# output \n# [0, 'fun', 1, 2, 3, 4, 5, 6, 3, 7, 8, 9]\n\n\n\nHowever, if you want to flatten a list of iterables (list and/or tuples), it can also do the job with a slight modification:\n\nfrom collections.abc import Iterable\ndef flatten(lst):\n    for item in lst:\n        if isinstance(item,Iterable) and not isinstance(item,str):\n            yield from flatten(item)\n        else:\n            yield item\n\n# test case:\na =[0, [], \"fun\", (1, 2, 3), [4, [5], (6)], 3, [7], [8, 9]]\nlist(flatten(a))\n# output: \n# [0, 'fun', 1, 2, 3, 4, 5, 6, 3, 7, 8, 9]\n\nShare\nImprove this answer\nFollow\nedited Dec 25 '20 at 6:49\nanswered Jul 21 '20 at 17:13\nAlbert G Lieu\n5354\n4 silver badges\n10\n10 bronze badges","comments":["I like this one, it works no matter how many dimensions the list has."]},{"answer":"you can use list extend method, it shows to be the fastest:\n\nflat_list = []\nfor sublist in l:\n    flat_list.extend(sublist)\n\n\nperformance:\n\nimport functools\nimport itertools\nimport numpy\nimport operator\nimport perfplot\n\n\n\ndef functools_reduce_iconcat(a):\n    return functools.reduce(operator.iconcat, a, [])\n\n\ndef itertools_chain(a):\n    return list(itertools.chain.from_iterable(a))\n\n\ndef numpy_flat(a):\n    return list(numpy.array(a).flat)\n\n\ndef extend(a):\n    n = []\n\n    list(map(n.extend, a))\n\n    return n \n\n\nperfplot.show(\n    setup=lambda n: [list(range(10))] * n,\n    kernels=[\n        functools_reduce_iconcat, extend,itertools_chain, numpy_flat\n        ],\n    n_range=[2**k for k in range(16)],\n    xlabel='num lists',\n    )\n\n\noutput: \n\nShare\nImprove this answer\nFollow\nedited Jan 28 '20 at 13:06\nanswered Jan 25 '20 at 21:08\nkederrac\n15.2k5\n5 gold badges\n26\n26 silver badges\n47\n47 bronze badges","comments":[]},{"answer":"from nltk import flatten\n\nl = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\nflatten(l)\n\n\nThe advantage of this solution over most others here is that if you have a list like:\n\nl = [1, [2, 3], [4, 5, 6], [7], [8, 9]]\n\n\nwhile most other solutions throw an error this solution handles them.\n\nShare\nImprove this answer\nFollow\nanswered Sep 30 '19 at 10:49\nAlijy\n1471\n1 silver badge\n7\n7 bronze badges","comments":["The question states a \"list of lists\", but your example list includes a non-list item. Most other solutions are sticking to the original question. Your solution solves a wider problem, but it also requires a non-base Python package (nltk) that must be installed first."]},{"answer":"This is a play on the original poster's code. (He wasn't far off)\n\nf = []\nlist(map(f.extend, l))\n\nShare\nImprove this answer\nFollow\nanswered Jan 10 at 19:27\nDaniel Braun\n1,26814\n14 silver badges\n18\n18 bronze badges","comments":["This is the one. Works for number and strings. Does not require numpy, which is not really relevant here. This is closest to the OP's try.","You should use map for side effects like this"]},{"answer":"Note: Below applies to Python 3.3+ because it uses yield_from. six is also a third-party package, though it is stable. Alternately, you could use sys.version.\n\nIn the case of obj = [[1, 2,], [3, 4], [5, 6]], all of the solutions here are good, including list comprehension and itertools.chain.from_iterable.\n\nHowever, consider this slightly more complex case:\n\n>>> obj = [[1, 2, 3], [4, 5], 6, 'abc', [7], [8, [9, 10]]]\n\n\nThere are several problems here:\n\nOne element, 6, is just a scalar; it's not iterable, so the above routes will fail here.\nOne element, 'abc', is technically iterable (all strs are). However, reading between the lines a bit, you don't want to treat it as such--you want to treat it as a single element.\nThe final element, [8, [9, 10]] is itself a nested iterable. Basic list comprehension and chain.from_iterable only extract \"1 level down.\"\n\nYou can remedy this as follows:\n\n>>> from collections import Iterable\n>>> from six import string_types\n\n>>> def flatten(obj):\n...     for i in obj:\n...         if isinstance(i, Iterable) and not isinstance(i, string_types):\n...             yield from flatten(i)\n...         else:\n...             yield i\n\n\n>>> list(flatten(obj))\n[1, 2, 3, 4, 5, 6, 'abc', 7, 8, 9, 10]\n\n\nHere, you check that the sub-element (1) is iterable with Iterable, an ABC from itertools, but also want to ensure that (2) the element is not \"string-like.\"\n\nShare\nImprove this answer\nFollow\nedited Jun 19 '18 at 19:38\nanswered Feb 1 '18 at 18:33\nBrad Solomon\n30.6k21\n21 gold badges\n108\n108 silver badges\n186\n186 bronze badges","comments":["If you are still interested in Python 2 compatibility, change yield from to a for loop, e.g. for x in flatten(i): yield x"]},{"answer":"You can use numpy :\nflat_list = list(np.concatenate(list_of_list))\n\nShare\nImprove this answer\nFollow\nanswered Jul 24 '18 at 9:11\nA. Attia\n1,2313\n3 gold badges\n16\n16 silver badges\n27\n27 bronze badges","comments":["This works for numerical, strings and mixed lists also","Fails for unevenly nested data, like [1, 2, [3], [[4]], [5, [6]]]"]},{"answer":"If you are willing to give up a tiny amount of speed for a cleaner look, then you could use numpy.concatenate().tolist() or numpy.concatenate().ravel().tolist():\n\nimport numpy\n\nl = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] * 99\n\n%timeit numpy.concatenate(l).ravel().tolist()\n1000 loops, best of 3: 313 µs per loop\n\n%timeit numpy.concatenate(l).tolist()\n1000 loops, best of 3: 312 µs per loop\n\n%timeit [item for sublist in l for item in sublist]\n1000 loops, best of 3: 31.5 µs per loop\n\n\nYou can find out more here in the documentation, numpy.concatenate and numpy.ravel.\n\nShare\nImprove this answer\nFollow\nedited Jul 31 at 18:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 27 '16 at 3:24\nmkultra\n1732\n2 silver badges\n8\n8 bronze badges","comments":["Doesn't work for unevenly nested lists like [1, 2, [3], [[4]], [5, [6]]]","@EL_DON of course, that isn't what this question is asking, there is another question that deals with that case","@juanpa.arrivillaga it's a simple and natural extension of the question, though. Answers that can handle greater depth of nesting are more likely to be useful to someone who finds this question."]},{"answer":"Simple code for underscore.py package fan\n\nfrom underscore import _\n_.flatten([[1, 2, 3], [4, 5, 6], [7], [8, 9]])\n# [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nIt solves all flatten problems (none list item or complex nesting)\n\nfrom underscore import _\n# 1 is none list item\n# [2, [3]] is complex nesting\n_.flatten([1, [2, [3]], [4, 5, 6], [7], [8, 9]])\n# [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nYou can install underscore.py with pip\n\npip install underscore.py\n\nShare\nImprove this answer\nFollow\nanswered Mar 25 '17 at 5:09\nVu Anh\n85715\n15 silver badges\n26\n26 bronze badges","comments":["Similarly, you can use pydash. I find this version to be much more readable than the list comprehension or any other answers.","This is super slow.","Why does it have a module named _? That seems like a bad name. See stackoverflow.com/a/5893946/6605826","@EL_DON: From underscore.py readme page \"Underscore.py is a python port of excellent javascript library underscore.js\". I think it's the reason for this name. And yes, It's not a good name for python"]},{"answer":"def flatten(alist):\n    if alist == []:\n        return []\n    elif type(alist) is not list:\n        return [alist]\n    else:\n        return flatten(alist[0]) + flatten(alist[1:])\n\nShare\nImprove this answer\nFollow\nanswered Aug 8 '17 at 14:59\nenglealuze\n1,0969\n9 silver badges\n14\n14 bronze badges","comments":["Fails for python2.7 for the example nested list in the question: [[1, 2, 3], [4, 5, 6], [7], [8, 9]]"]},{"answer":"flat_list = []\nfor i in list_of_list:\n    flat_list+=i\n\n\nThis Code also works fine as it just extend the list all the way. Although it is much similar but only have one for loop. So It have less complexity than adding 2 for loops.\n\nShare\nImprove this answer\nFollow\nanswered Jun 20 '18 at 11:12\nDeepak Yadav\n5546\n6 silver badges\n12\n12 bronze badges","comments":[]}]},{"id":"2610497","href":"https://stackoverflow.com/questions/2610497/change-a-html5-inputs-placeholder-color-with-css","title":"Change a HTML5 input's placeholder color with CSS","description":"\n                \nChrome supports the placeholder attribute on input[type=text] elements (others probably do too).\nBut the following CSS doesn't do anything to the placeholder's value:\n\n\ninput[placeholder], [placeholder], *[placeholder] {\n    color: red !important;\n}\n<input type=\"text\" placeholder=\"Value\">\n Run code snippetHide resultsExpand snippet\n\n\nBut Value will still remain grey instead of red.\nIs there a way to change the color of the placeholder text?\n    ","questionComments":["Quick heads-up (not a solution, just a FYI): if I recall correctly, input[placeholder] just matches <input> tags that have a placeholder attribute, it doesn't match the placeholder attribute itself.","Yah, the thought crossed my mind that this may be like trying to style an element's \"title\" attribute. So +1 for thinking alike!","@MathiasBynens The :placeholder-shown pseudo-class matches an input element that is showing such placeholder text. So it matches <input> tag, like input selector, but showing placeholder text just now. It also doesn't match the placeholder attribute itself.","@HEX It’s not like the input selector because that selects all input elements. :placeholder-shown only selects input elements that are currently showing the placeholder, allowing you to style those elements only, and effectively style the placeholder text. What are you trying to say?","@HEX (Of course, it also selected textarea elements that are showing placeholder text.)"],"answers":[{"answer":"Implementation\n\nThere are three different implementations: pseudo-elements, pseudo-classes, and nothing.\n\nWebKit, Blink (Safari, Google Chrome, Opera 15+) and Microsoft Edge are using a pseudo-element: ::-webkit-input-placeholder. [Ref]\nMozilla Firefox 4 to 18 is using a pseudo-class: :-moz-placeholder (one colon). [Ref]\nMozilla Firefox 19+ is using a pseudo-element: ::-moz-placeholder, but the old selector will still work for a while. [Ref]\nInternet Explorer 10 and 11 are using a pseudo-class: :-ms-input-placeholder. [Ref]\nApril 2017: Most modern browsers support the simple pseudo-element ::placeholder [Ref]\n\nInternet Explorer 9 and lower does not support the placeholder attribute at all, while Opera 12 and lower do not support any CSS selector for placeholders.\n\nThe discussion about the best implementation is still going on. Note the pseudo-elements act like real elements in the Shadow DOM. A padding on an input will not get the same background color as the pseudo-element.\n\nCSS selectors\n\nUser agents are required to ignore a rule with an unknown selector. See Selectors Level 3:\n\na group of selectors containing an invalid selector is invalid.\n\nSo we need separate rules for each browser. Otherwise the whole group would be ignored by all browsers.\n\n::-webkit-input-placeholder { /* WebKit, Blink, Edge */\n    color:    #909;\n}\n:-moz-placeholder { /* Mozilla Firefox 4 to 18 */\n   color:    #909;\n   opacity:  1;\n}\n::-moz-placeholder { /* Mozilla Firefox 19+ */\n   color:    #909;\n   opacity:  1;\n}\n:-ms-input-placeholder { /* Internet Explorer 10-11 */\n   color:    #909;\n}\n::-ms-input-placeholder { /* Microsoft Edge */\n   color:    #909;\n}\n\n::placeholder { /* Most modern browsers support this now. */\n   color:    #909;\n}\n<input placeholder=\"Stack Snippets are awesome!\">\n Run code snippetExpand snippet\n\nUsage notes\nBe careful to avoid bad contrasts. Firefox's placeholder appears to be defaulting with a reduced opacity, so needs to use opacity: 1 here.\nNote that placeholder text is just cut off if it doesn’t fit – size your input elements in em and test them with big minimum font size settings. Don’t forget translations: some languages need more room for the same word.\nBrowsers with HTML support for placeholder but without CSS support for that (like Opera) should be tested too.\nSome browsers use additional default CSS for some input types (email, search). These might affect the rendering in unexpected ways. Use the properties -webkit-appearance and -moz-appearance to change that. Example:\n    [type=\"search\"] {\n        -moz-appearance:    textfield;\n        -webkit-appearance: textfield;\n        appearance: textfield;\n    }\n\nShare\nImprove this answer\nFollow\nedited Jan 7 '18 at 14:00\nhitautodestruct\n18k13\n13 gold badges\n60\n60 silver badges\n88\n88 bronze badges\nanswered Apr 9 '10 at 20:36\nfuxia\n61k5\n5 gold badges\n48\n48 silver badges\n59\n59 bronze badges","comments":[]},{"answer":"/* do not group these rules */\n*::-webkit-input-placeholder {\n    color: red;\n}\n*:-moz-placeholder {\n    /* FF 4-18 */\n    color: red;\n    opacity: 1;\n}\n*::-moz-placeholder {\n    /* FF 19+ */\n    color: red;\n    opacity: 1;\n}\n*:-ms-input-placeholder {\n    /* IE 10+ */\n    color: red;\n}\n*::-ms-input-placeholder {\n    /* Microsoft Edge */\n    color: red;\n}\n*::placeholder {\n    /* modern browser */\n    color: red;\n}\n<input placeholder=\"hello\"/> <br />\n<textarea placeholder=\"hello\"></textarea>\n Run code snippetExpand snippet\n\nThis will style all input and textarea placeholders.\n\nImportant Note: Do not group these rules. Instead, make a separate rule for every selector (one invalid selector in a group makes the whole group invalid).\n\nShare\nImprove this answer\nFollow\nedited Jul 19 '18 at 15:14\ncommunity wiki\n\n\n23 revs, 9 users 65%\nbrillout","comments":[]},{"answer":"You may also want to style textareas:\n\ninput::-webkit-input-placeholder, textarea::-webkit-input-placeholder {\n  color: #636363;\n}\ninput:-moz-placeholder, textarea:-moz-placeholder {\n  color: #636363;\n}\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '13 at 20:45\ncommunity wiki\n\n\n7 revs, 7 users 56%\nMatt","comments":[]},{"answer":"For Bootstrap and Less users, there is a mixin .placeholder:\n\n// Placeholder text\n// -------------------------\n.placeholder(@color: @placeholderText) {\n  &:-moz-placeholder {\n    color: @color;\n  }\n  &:-ms-input-placeholder {\n    color: @color;\n  }\n  &::-webkit-input-placeholder {\n    color: @color;\n  }\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '16 at 7:52\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 6 '13 at 8:47\nEIIPII\n1,6511\n1 gold badge\n16\n16 silver badges\n10\n10 bronze badges","comments":["For changing Bootstrap CSS"]},{"answer":"In addition to toscho's answer I've noticed some webkit inconsistencies between Chrome 9-10 and Safari 5 with the CSS properties supported that are worth noting.\n\nSpecifically Chrome 9 and 10 do not support background-color, border, text-decoration and text-transform when styling the placeholder.\n\nThe full cross-browser comparison is here.\n\nShare\nImprove this answer\nFollow\nedited Sep 25 '13 at 13:04\nanswered Feb 9 '11 at 16:44\najcw\n22.7k6\n6 gold badges\n28\n28 silver badges\n47\n47 bronze badges","comments":[]},{"answer":"For Sass users:\n\n// Create placeholder mixin\n@mixin placeholder($color, $size:\"\") {\n  &::-webkit-input-placeholder {\n    color: $color;\n    @if $size != \"\" {\n      font-size: $size;\n    }\n  }\n  &:-moz-placeholder {\n    color: $color;\n    @if $size != \"\" {\n      font-size: $size;\n    }\n  }\n  &::-moz-placeholder {\n    color: $color;\n    @if $size != \"\" {\n      font-size: $size;\n    }\n  }\n  &:-ms-input-placeholder {\n    color: $color;\n    @if $size != \"\" {\n      font-size: $size;\n    }\n  }\n}\n\n// Use placeholder mixin (the size parameter is optional)\n[placeholder] {\n  @include placeholder(red, 10px);\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '16 at 7:54\ncommunity wiki\n\n\n3 revs, 2 users 92%\nKonst_","comments":[]},{"answer":"This will work fine. DEMO HERE:\n\ninput::-webkit-input-placeholder,\ntextarea::-webkit-input-placeholder {\n  color: #666;\n}\ninput:-moz-placeholder,\ntextarea:-moz-placeholder {\n  color: #666;\n}\ninput::-moz-placeholder,\ntextarea::-moz-placeholder {\n  color: #666;\n}\ninput:-ms-input-placeholder,\ntextarea:-ms-input-placeholder {\n  color: #666;\n}\n<input type=\"text\" placeholder=\"Value\" />\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Sep 12 '16 at 8:08\nuser6696028\nanswered Sep 14 '13 at 12:52\nLove Trivedi\n3,5493\n3 gold badges\n18\n18 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"In Firefox and Internet Explorer, the normal input text color overrides the color property of placeholders. So, we need to\n\n::-webkit-input-placeholder { \n    color: red; text-overflow: ellipsis; \n}\n:-moz-placeholder { \n    color: #acacac !important; text-overflow: ellipsis; \n}\n::-moz-placeholder { \n    color: #acacac !important; text-overflow: ellipsis; \n} /* For the future */\n:-ms-input-placeholder { \n    color: #acacac !important; text-overflow: ellipsis; \n}\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '16 at 7:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 14 '13 at 21:11\nDionysios Arvanitis\n1,0059\n9 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"Use the new ::placeholder if you use autoprefixer.\n\nNote that the .placeholder mixin from Bootstrap is deprecated in favor of this.\n\nExample:\n\ninput::placeholder { color: black; }\n\n\nWhen using autoprefixer the above will be converted to the correct code for all browsers.\n\nShare\nImprove this answer\nFollow\nedited Feb 13 '17 at 8:19\ncommunity wiki\n\n\n3 revs, 3 users 65%\nhitautodestruct","comments":[]},{"answer":"Cross-browser solution:\n\n/* all elements */\n::-webkit-input-placeholder { color:#f00; }\n::-moz-placeholder { color:#f00; } /* firefox 19+ */\n:-ms-input-placeholder { color:#f00; } /* ie */\ninput:-moz-placeholder { color:#f00; }\n\n/* individual elements: webkit */\n#field2::-webkit-input-placeholder { color:#00f; }\n#field3::-webkit-input-placeholder { color:#090; background:lightgreen; text-transform:uppercase; }\n#field4::-webkit-input-placeholder { font-style:italic; text-decoration:overline; letter-spacing:3px; color:#999; }\n\n/* individual elements: mozilla */\n#field2::-moz-placeholder { color:#00f; }\n#field3::-moz-placeholder { color:#090; background:lightgreen; text-transform:uppercase; }\n#field4::-moz-placeholder { font-style:italic; text-decoration:overline; letter-spacing:3px; color:#999; }\n\n\nCredit: David Walsh\n\nShare\nImprove this answer\nFollow\nanswered Jan 2 '14 at 23:27\ncommunity wiki\n\n\nKristian","comments":[]},{"answer":"Now we have a standard way to apply CSS to an input's placeholder : ::placeholder pseudo-element from this CSS Module Level 4 Draft.\n\nShare\nImprove this answer\nFollow\nedited Aug 12 '15 at 3:11\ncommunity wiki\n\n\n2 revs, 2 users 86%\nuser3790069","comments":["This works in Firefox 51. I'm just going to use this method; the other browsers will catch up soon enough for me (given that no functionality is broken if the to-be-standard style is not applied)."]},{"answer":"I don't remember where I've found this code snippet on the Internet (it wasn't written by me, don't remember where I've found it, nor who wrote it).\n\n$('[placeholder]').focus(function() {\n        var input = $(this);\n        if (input.val() == input.attr('placeholder')) {\n            input.val('');\n            input.removeClass('placeholder');\n        }\n    }).blur(function() {\n        var input = $(this);\n        if (input.val() == '' || input.val() == input.attr('placeholder')) {\n            input.addClass('placeholder');\n            input.val(input.attr('placeholder'));\n        }\n    }).blur();\n    $('[placeholder]').parents('form').submit(function() {\n        $(this).find('[placeholder]').each(function() {\n            var input = $(this);\n            if (input.val() == input.attr('placeholder')) {\n                input.val('');\n            }\n        })\n    });\n\n\nJust load this JavaScript code and then edit your placeholder with CSS by calling this rule:\n\nform .placeholder {\n   color: #222;\n   font-size: 25px;\n   /* etc. */\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '16 at 7:50\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 14 '13 at 2:28\nDragos Rizescu\n3,0905\n5 gold badges\n28\n28 silver badges\n41\n41 bronze badges","comments":["This is the old way of doing it, which I've used quite a bit. The disadvantage is that the placeholder text disappears when you focus. I've found this to be annoying when the UI doesn't also include labels next to the input. Over the past several months I've started replacing this method with using placeholder text, which I think is a UX improvement.","The other problem with code like this is your serverside code has to deal with placeholder text as empty input, which has problems with edge cases where you want to enter a town called \"Town\". Instead of checking values against the placeholder text you should really use a data-modified flag on the input, and then clear the input on form submit if the flag is not set. And for AJAX interfaces you may not even have a form, so you should be able to associate an arbitrary submission event with the input. This is one of those really simple situations that isn't."]},{"answer":"I think this code will work because a placeholder is needed only for input type text. So this one line CSS will be enough for your need:\n\ninput[type=\"text\"]::-webkit-input-placeholder {\n    color: red;\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '16 at 7:57\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 25 '15 at 9:01\nAlias Varghese\n2,0502\n2 gold badges\n17\n17 silver badges\n47\n47 bronze badges","comments":["Don't use this one anymore. There are several more elements with placeholder and more prefixes. See solutions above or use ::placeholder together with autoprefixer."]},{"answer":"I just realize something for Mozilla Firefox 19+ that the browser gives an opacity value for the placeholder, so the color will not be what you really want.\n\ninput::-webkit-input-placeholder, textarea::-webkit-input-placeholder {\n    color: #eee; opacity:1;\n}\ninput:-moz-placeholder, textarea:-moz-placeholder {\n    color: #eee; opacity:1;\n}\ninput::-moz-placeholder, textarea::-moz-placeholder {\n    color: #eee; opacity:1;\n}\ninput:-ms-input-placeholder, textarea:-ms-input-placeholder {\n    color: #eee; opacity:1;\n}\n\n\nI overwrite the opacity for 1, so it will be good to go.\n\nShare\nImprove this answer\nFollow\nedited yesterday\ncommunity wiki\n\n\n4 revs, 4 users 54%\nBurak Tokak","comments":[]},{"answer":"For Bootstrap users, if you are using class=\"form-control\", there may be a CSS specificity issue. You should get a higher priority:\n\n.form-control::-webkit-input-placeholder {\n    color: red;\n}\n//.. and other browsers\n\n\nOr if you are using Less:\n\n.form-control{\n    .placeholder(red);\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '16 at 7:53\ncommunity wiki\n\n\n2 revs, 2 users 77%\ngfaceless","comments":[]},{"answer":"If you are using Bootstrap and couldn't get this working then probably you missed the fact that Bootstrap itself adds these selectors. This is Bootstrap v3.3 we are talking about.\n\nIf you are trying to change the placeholder inside a .form-control CSS class then you should override it like this:\n\n.form-control::-webkit-input-placeholder { /* WebKit, Blink, Edge */\n    color:    #777;\n}\n.form-control:-moz-placeholder { /* Mozilla Firefox 4 to 18 */\n    color:    #777;\n    opacity:  1;\n}\n.form-control::-moz-placeholder { /* Mozilla Firefox 19+ */\n    color:    #777;\n    opacity:  1;\n}\n.form-control:-ms-input-placeholder { /* Internet Explorer 10-11 */\n    color:    #777;\n}\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '16 at 8:01\ncommunity wiki\n\n\n2 revs, 2 users 95%\nsteady_daddy","comments":[]},{"answer":"How about this\n\n<input type=\"text\" value=\"placeholder text\" onfocus=\"this.style.color='#000'; \n    this.value='';\" style=\"color: #f00;\" />\n Run code snippetExpand snippet\n\nNo CSS or placeholder, but you get the same functionality.\n\nShare\nImprove this answer\nFollow\nedited May 15 '19 at 16:15\nMobarak Ali\n6915\n5 silver badges\n17\n17 bronze badges\nanswered Oct 8 '12 at 19:21\nuser1729061\n4873\n3 silver badges\n4\n4 bronze badges","comments":["what happens if someone clicks again after writing something.. the original text they wrote will be gone!","@LuckySoni you could do this, but I personally prefer the first one. <input type=\"text\" value=\"placeholder text\" onfocus=\"if(!this.haswriting){this.style.color='#000'; this.value='';}\" onblur=\"if(!this.value){this.style.color='#f00'; this.value='placeholder text'; this.haswriting=false;}else{this.haswriting=true};\" style=\"color: #f00;\"/>","Even your second version doesn't provide the same functionality. If the user submits the <form> with this input the placeholder text will be sent to the server. I seen so many sites do this wrong.","This is dangerous! If you come back again to the form you lost everything!"]},{"answer":"This short and clean code:\n\n::-webkit-input-placeholder {color: red;}\n:-moz-placeholder           {color: red; /* For Firefox 18- */}\n::-moz-placeholder          {color: red; /* For Firefox 19+ */}\n:-ms-input-placeholder      {color: red;}\n\nShare\nImprove this answer\nFollow\nedited yesterday\ncommunity wiki\n\n\n5 revs, 5 users 37%\nBanti Mathur","comments":[]},{"answer":"I have tried every combination here to change the color, on my mobile platform, and eventually it was:\n\n-webkit-text-fill-color: red;\n\n\nwhich did the trick.\n\nShare\nImprove this answer\nFollow\nedited Sep 24 '16 at 7:58\ncommunity wiki\n\n\n2 revs, 2 users 80%\naviram83","comments":["This property allows you to specify a fill color for text. If it is not set, then the color property will be used to do the fill. It sounds to me like you've got some other CSS rule that is setting the color property."]},{"answer":"For SASS/SCSS user using Bourbon, it has a built-in function.\n\n//main.scss\n@import 'bourbon';\n\ninput {\n  width: 300px;\n\n  @include placeholder {\n    color: red;\n  }\n}\n\n\nCSS Output, you can also grab this portion and paste into your code.\n\n//main.css\n\ninput {\n  width: 300px;\n}\n\ninput::-webkit-input-placeholder {\n  color: red;\n}\ninput:-moz-placeholder {\n  color: red;\n}\ninput::-moz-placeholder {\n  color: red;\n}\ninput:-ms-input-placeholder {\n  color: red;\n}\n\nShare\nImprove this answer\nFollow\nanswered Oct 4 '16 at 7:50\ncommunity wiki\n\n\ntrungk18","comments":[]},{"answer":"try this code for different input element different style\n\nyour css selector::-webkit-input-placeholder { /*for webkit */\n    color:#909090;\n    opacity:1;\n}\n your css selector:-moz-placeholder { /*for mozilla */\n    color:#909090;\n    opacity:1;\n}\n your css selector:-ms-input-placeholder { /*for for internet exprolar */ \n   color:#909090;\n   opacity:1;\n}\n\n\nexample 1:\n\ninput[type=\"text\"]::-webkit-input-placeholder { /*for webkit */\n    color: red;\n    opacity:1;\n}\n input[type=\"text\"]:-moz-placeholder { /*for mozilla */\n    color: red;\n    opacity:1;\n}\n input[type=\"text\"]:-ms-input-placeholder { /*for for internet exprolar */ \n   color: red;\n   opacity:1;\n}\n\n\nexample 2:\n\ninput[type=\"email\"]::-webkit-input-placeholder { /*for webkit */\n    color: gray;\n    opacity:1;\n}\n input[type=\"email\"]:-moz-placeholder { /*for mozilla */\n    color: gray;\n    opacity:1;\n}\n input[type=\"email\"]:-ms-input-placeholder { /*for for internet exprolar */ \n   color: gray;\n   }\n\nShare\nImprove this answer\nFollow\nanswered Oct 13 '17 at 6:47\ncommunity wiki\n\n\nMd. Abu Sayed","comments":[]},{"answer":"Adding an actual very nice and simple possibility: css filters!\n\nIt will style everything, including the placeholder.\n\nThe following will set both input elements on the same palette, using the hue filter for color changes. It render very well now in browsers (except ie...)\n\ninput {\n  filter: sepia(100%) saturate(400%) grayscale(0) contrast(200%) hue-rotate(68deg) invert(18%);\n}\n<input placeholder=\"Hello world!\" />\n<input type=\"date\" /><br>\n<input type=\"range\" />\n<input type=\"color\" />\n Run code snippetExpand snippet\n\nTo allow users to change it dynamically, using an input type color for changes, or to find nuances, check out this snippet:\n\nFrom: https://codepen.io/Nico_KraZhtest/pen/bWExEB\n\nfunction stylElem() {\n  stylo.dataset.hue = ((parseInt(stylo.value.substring(1), 16))/46666).toFixed(0)\n  Array.from(document.querySelectorAll('input, audio, video')).forEach(function(e){\n      e.style.cssText += \";filter:sepia(100%) saturate(400%)grayscale(0)contrast(200%)hue-rotate(\"+ stylo.dataset.hue+\"deg)invert(\"+(stylo.dataset.hue/3.6)+\"%)\"\n  out.innerText = e.style.cssText\n})()}\n\nstylElem()\nbody {background: black; color: white}\nChoose a color!\n<input type=\"color\" id=\"stylo\" oninput=\"stylElem()\">\n<br>\n<div id=\"out\"></div> <p>\n  <input placeholder=\"Hello world!\" />\n  <input type=\"date\" /><br>\n  <input type=\"range\" />\n <br>\n<audio controls src=\"#\"></audio> <br><br> \n<video controls src=\"#\"></video>\n Run code snippetExpand snippet\n\nCss filters docs: https://developer.mozilla.org/en-US/docs/Web/CSS/filter\n\nShare\nImprove this answer\nFollow\nedited Sep 2 '20 at 15:06\ncommunity wiki\n\n\n5 revs\nNVRM","comments":[]},{"answer":"Here is one more example:\n\n.form-control::-webkit-input-placeholder {\n  color: red;\n  width: 250px;\n}\nh1 {\n  color: red;\n}\n<div class=\"col-sm-4\">\n  <input class=\"form-control\" placeholder=\"Enter text here..\" ng-model=\"Email\" required/>\n</div>\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nanswered May 31 '16 at 9:21\ncommunity wiki\n\n\nMahendra Kulkarni","comments":[]},{"answer":"OK, placeholders behave differently in different browsers, so you need using browser prefix in your CSS to make them identical, for example Firefox gives a transparency to placeholder by default, so need to add opacity 1 to your css, plus the color, it's not a big concern most of the times, but good to have them consistent:\n\n*::-webkit-input-placeholder { /* WebKit browsers */\n    color:    #ccc;\n}\n*:-moz-placeholder { /* Mozilla Firefox <18 */\n    color:    #ccc;\n    opacity:  1;\n}\n*::-moz-placeholder { /* Mozilla Firefox 19+ */\n    color:    #ccc;\n    opacity:  1;\n}\n*:-ms-input-placeholder { /* Internet Explorer 10-11 */\n    color:    #ccc;\n}\n\nShare\nImprove this answer\nFollow\nanswered May 11 '17 at 12:41\ncommunity wiki\n\n\nAlireza","comments":[]},{"answer":"You can change an HTML5 input's placeholder color with CSS. If by chance, your CSS conflict, this code note working , you can use (!important) like below.\n\n::-webkit-input-placeholder { /* WebKit, Blink, Edge */\n    color:#909 !important;\n}\n:-moz-placeholder { /* Mozilla Firefox 4 to 18 */\n   color:#909 !important;\n   opacity:1 !important;\n}\n::-moz-placeholder { /* Mozilla Firefox 19+ */\n   color:#909 !important;\n   opacity:1 !important;\n}\n:-ms-input-placeholder { /* Internet Explorer 10-11 */\n   color:#909 !important;\n}\n::-ms-input-placeholder { /* Microsoft Edge */\n   color:#909 !important;\n}\n\n<input placeholder=\"Stack Snippets are awesome!\">\n\n\nHope this will help.\n\nShare\nImprove this answer\nFollow\nedited Dec 21 '17 at 8:10\ncommunity wiki\n\n\n2 revs, 2 users 93%\nDeepak Kumar","comments":[]},{"answer":"You can use this for input and focus style:\n\ninput::-webkit-input-placeholder  { color:#666;}\ninput:-moz-placeholder  { color:#666;}\ninput::-moz-placeholder { color:#666;}\ninput:-ms-input-placeholder  { color:#666;}\n/* focus */\ninput:focus::-webkit-input-placeholder { color:#eee; }\ninput:focus:-moz-placeholder { color:#eee } /* FF 4-18 */\ninput:focus::-moz-placeholder { color:#eee } /* FF 19+ */\ninput:focus:-ms-input-placeholder { color:#eee } /* IE 10+ */\n\nShare\nImprove this answer\nFollow\nedited May 13 '18 at 15:19\ncommunity wiki\n\n\n2 revs, 2 users 92%\nfraweb","comments":[]},{"answer":"Here is the solution with CSS selectors\n\n::-webkit-input-placeholder { /* WebKit, Blink, Edge */\n    color:    #909;\n}\n\n:-moz-placeholder { /* Mozilla Firefox 4 to 18 */\n   color:    #909;\n   opacity:  1;\n}\n\n::-moz-placeholder { /* Mozilla Firefox 19+ */\n   color:    #909;\n   opacity:  1;\n}\n\n::-ms-input-placeholder { /* Microsoft Edge */\n   color:    #909;\n}\n\n:-ms-input-placeholder { /* Internet Explorer 10-11 */\n   color:    #909;\n}\n\nWebKit, Blink (Safari, Google Chrome, Opera 15+) and Microsoft Edge are using a pseudo-element:\n::-webkit-input-placeholder.\nMozilla Firefox 4 to 18 is using a pseudo-class:\n:-moz-placeholder (one colon).\nMozilla Firefox 19+ is using a pseudo-element:\n::-moz-placeholder, but the old selector will still work for a while.\nInternet Explorer 10 and 11 are using a pseudo-class:\n:-ms-input-placeholder.\nInternet Explorer 9 and lower does not support the placeholder attribute at all, while Opera 12 and lower do not support any CSS selector for placeholders.\nShare\nImprove this answer\nFollow\nanswered Sep 4 '19 at 6:09\ncommunity wiki\n\n\nMohammad Ayoub Khan","comments":[]},{"answer":"The easiest way would be:\n\n#yourInput::placeholder {\n    color: red;/*As an example*/\n}\n/* if that would not work, you can always try styling the attribute itself: */\n#myInput[placeholder] {\n    color: red;\n}\n\nShare\nImprove this answer\nFollow\nanswered Oct 27 '18 at 20:41\ncommunity wiki\n\n\ncodeWithMe","comments":[]},{"answer":"Compass has a mixin for this out of the box.\n\nTake your example:\n\n<input type=\"text\" placeholder=\"Value\">\n\n\nAnd in SCSS using compass:\n\ninput[type='text'] {\n  @include input-placeholder {\n    color: #616161;\n  }\n}\n\n\nSee docs for the input-placeholder mixin.\n\nShare\nImprove this answer\nFollow\nanswered Sep 20 '16 at 12:37\ncommunity wiki\n\n\nbendav91","comments":[]},{"answer":"A part of HTML:\n\n <form action=\"www.anything.com\">\n <input type=\"text\" name=\"name\"\n  placeholder=\"Enter sentence\"/>\n  </form>\n\n\nI gonna show how to change color of expression of 'Enter sentence' by CSS:\n\n  ::placeholder{\n  color:blue;\n   }\n\nShare\nImprove this answer\nFollow\nanswered Jul 18 '19 at 3:35\ncommunity wiki\n\n\ndev_cc","comments":[]}]},{"id":"1109022","href":"https://stackoverflow.com/questions/1109022/how-do-you-close-hide-the-android-soft-keyboard-programmatically","title":"How do you close/hide the Android soft keyboard programmatically?","description":"\n                \nI have an EditText and a Button in my layout.\nAfter writing in the edit field and clicking on the Button, I want to hide the virtual keyboard when touching outside the keyboard. I assume that this is a simple piece of code, but where can I find an example of it?\n    ","questionComments":["What if you have only one EditText and several buttons, like check boxes and radios? The only place you need the keyboard is in the single EditText. How do you register to know that something else was chosen/clicked in order to hide the keyboard?","i feel stupid. I am unable to hide the keyboard on ICS. Tried all methods here and combinations of them. No way. The method to show it works, but I cant hide it no matter what windw token, hide flags, manifest settings or candles to any saints. On keyboard show I always see this: I/LatinIME( 396): InputType.TYPE_NULL is specified W/LatinIME( 396): Unexpected input class: inputType=0x00000000 imeOptions=0x00000000","/** * This method is used to hide soft keyboard. * @param activity */ public void hideSoftKeyboard(Activity activity) { InputMethodManager inputMethodManager = (InputMethodManager)activity.getSystemService(Activity.INPUT_METHOD_SERVICE); inputMethodManager.hideSoftInputFromWindow(activity.getCurrentFocus().getWindowToken(), 0); }","this worked for me","With devices increasing screen size and resolution, virtual keyboard hiding is becoming less important."],"answers":[{"answer":"To help clarify this madness, I'd like to begin by apologizing on behalf of all Android users for Google's downright ridiculous treatment of the soft keyboard. The reason there are so many answers, each different, for the same simple question is that this API, like many others in Android, is horribly designed. I can think of no polite way to state it.\n\nI want to hide the keyboard. I expect to provide Android with the following statement: Keyboard.hide(). The end. Thank you very much. But Android has a problem. You must use the InputMethodManager to hide the keyboard. OK, fine, this is Android's API to the keyboard. BUT! You are required to have a Context in order to get access to the IMM. Now we have a problem. I may want to hide the keyboard from a static or utility class that has no use or need for any Context. or And FAR worse, the IMM requires that you specify what View (or even worse, what Window) you want to hide the keyboard FROM.\n\nThis is what makes hiding the keyboard so challenging. Dear Google: When I'm looking up the recipe for a cake, there is no RecipeProvider on Earth that would refuse to provide me with the recipe unless I first answer WHO the cake will be eaten by AND where it will be eaten!!\n\nThis sad story ends with the ugly truth: to hide the Android keyboard, you will be required to provide 2 forms of identification: a Context and either a View or a Window.\n\nI have created a static utility method that can do the job VERY solidly, provided you call it from an Activity.\n\npublic static void hideKeyboard(Activity activity) {\n    InputMethodManager imm = (InputMethodManager) activity.getSystemService(Activity.INPUT_METHOD_SERVICE);\n    //Find the currently focused view, so we can grab the correct window token from it.\n    View view = activity.getCurrentFocus();\n    //If no view currently has focus, create a new one, just so we can grab a window token from it\n    if (view == null) {\n        view = new View(activity);\n    }\n    imm.hideSoftInputFromWindow(view.getWindowToken(), 0);\n}\n\n\nBe aware that this utility method ONLY works when called from an Activity! The above method calls getCurrentFocus of the target Activity to fetch the proper window token.\n\nBut suppose you want to hide the keyboard from an EditText hosted in a DialogFragment? You can't use the method above for that:\n\nhideKeyboard(getActivity()); //won't work\n\n\nThis won't work because you'll be passing a reference to the Fragment's host Activity, which will have no focused control while the Fragment is shown! Wow! So, for hiding the keyboard from fragments, I resort to the lower-level, more common, and uglier:\n\npublic static void hideKeyboardFrom(Context context, View view) {\n    InputMethodManager imm = (InputMethodManager) context.getSystemService(Activity.INPUT_METHOD_SERVICE);\n    imm.hideSoftInputFromWindow(view.getWindowToken(), 0);\n}\n\n\nBelow is some additional information gleaned from more time wasted chasing this solution:\n\nAbout windowSoftInputMode\n\nThere's yet another point of contention to be aware of. By default, Android will automatically assign initial focus to the first EditText or focusable control in your Activity. It naturally follows that the InputMethod (typically the soft keyboard) will respond to the focus event by showing itself. The windowSoftInputMode attribute in AndroidManifest.xml, when set to stateAlwaysHidden, instructs the keyboard to ignore this automatically-assigned initial focus.\n\n<activity\n    android:name=\".MyActivity\"\n    android:windowSoftInputMode=\"stateAlwaysHidden\"/>\n\n\nAlmost unbelievably, it appears to do nothing to prevent the keyboard from opening when you touch the control (unless focusable=\"false\" and/or focusableInTouchMode=\"false\" are assigned to the control). Apparently, the windowSoftInputMode setting applies only to automatic focus events, not to focus events triggered by touch events.\n\nTherefore, stateAlwaysHidden is VERY poorly named indeed. It should perhaps be called ignoreInitialFocus instead.\n\nUPDATE: More ways to get a window token\n\nIf there is no focused view (e.g. can happen if you just changed fragments), there are other views that will supply a useful window token.\n\nThese are alternatives for the above code if (view == null)   view = new View(activity); These don't refer explicitly to your activity.\n\nInside a fragment class:\n\nview = getView().getRootView().getWindowToken();\n\n\nGiven a fragment fragment as a parameter:\n\nview = fragment.getView().getRootView().getWindowToken();\n\n\nStarting from your content body:\n\nview = findViewById(android.R.id.content).getRootView().getWindowToken();\n\n\nUPDATE 2: Clear focus to avoid showing keyboard again if you open the app from the background\n\nAdd this line to the end of the method:\n\nview.clearFocus();\n\nShare\nImprove this answer\nFollow\nedited Mar 12 at 2:41\ncommunity wiki\n\n\n15 revs, 10 users 60%\nrmirabelle","comments":["Why need getRootView() , why not getView() only?","One liner: ((InputMethodManager)getContext().getSystemService(Activity.INPUT_METHOD_SERVICE)).hideSoftInputFromWindow(getView().getWindowToken(), 0);","Recently we finally got an official, backwards compatible way to do this","Finally there is an official way stackoverflow.com/a/67683124/4985958","Thanks it is helpful."]},{"answer":"You can force Android to hide the virtual keyboard using the InputMethodManager, calling hideSoftInputFromWindow, passing in the token of the window containing your focused view.\n\n// Check if no view has focus:\nView view = this.getCurrentFocus();\nif (view != null) {  \n    InputMethodManager imm = (InputMethodManager)getSystemService(Context.INPUT_METHOD_SERVICE);\n    imm.hideSoftInputFromWindow(view.getWindowToken(), 0);\n}\n\n\nThis will force the keyboard to be hidden in all situations. In some cases, you will want to pass in InputMethodManager.HIDE_IMPLICIT_ONLY as the second parameter to ensure you only hide the keyboard when the user didn't explicitly force it to appear (by holding down the menu).\n\nNote: If you want to do this in Kotlin, use: context?.getSystemService(Context.INPUT_METHOD_SERVICE) as InputMethodManager\n\nKotlin Syntax\n\n// Only runs if there is a view that is currently focused\nthis.currentFocus?.let { view ->\n    val imm = getSystemService(Context.INPUT_METHOD_SERVICE) as? InputMethodManager\n    imm?.hideSoftInputFromWindow(view.windowToken, 0)\n}\n\nShare\nImprove this answer\nFollow\nedited Feb 21 at 9:44\ncommunity wiki\n\n\n15 revs, 15 users 21%\nReto Meier","comments":["now getSystemService() requires a Context and a serviceClass Class. For the context I can call requiredContext but what about for the serviceClass?"]},{"answer":"Also useful for hiding the soft-keyboard is:\n\ngetWindow().setSoftInputMode(\n    WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_HIDDEN\n);\n\n\nThis can be used to suppress the soft-keyboard until the user actually touches the editText View.\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '14 at 16:07\ncommunity wiki\n\n\n5 revs, 4 users 50%\nGarnet Ulrich","comments":["This was the only one that worked for in 2020. I have a edit text on the main activity and don't want the keyboard to come up when starting the app."]},{"answer":"I got one more solution to hide keyboard:\n\nInputMethodManager imm = (InputMethodManager) getSystemService(Activity.INPUT_METHOD_SERVICE);\nimm.toggleSoftInput(InputMethodManager.HIDE_IMPLICIT_ONLY, 0);\n\n\nHere pass HIDE_IMPLICIT_ONLY at the position of showFlag and 0 at the position of hiddenFlag. It will forcefully close soft Keyboard.\n\nShare\nImprove this answer\nFollow\nedited Jun 27 '16 at 15:26\ncommunity wiki\n\n\n3 revs, 3 users 80%\nSaurabh Pareek","comments":["You're using a hide flag in the showflags parameter. This only works because the constants use the same integers. Example using the correct flags","tested on Android 4.0, I like this solution, because I have multiple edit texts, buttons on that activity, which can have focus","This works for me, I dont have any textboxes or anything that really has focus.","@Mark: Because the method is called \"toggleSoftInput\", not \"hideSoftInput\" :)"]},{"answer":"Meier's solution works for me too. In my case, the top level of my App is a tab host and I want to hide the keyword when switching tabs - I get the window token from the tab host View.\n\ntabHost.setOnTabChangedListener(new OnTabChangeListener() {\n    public void onTabChanged(String tabId) {\n        InputMethodManager imm = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);\n        imm.hideSoftInputFromWindow(tabHost.getApplicationWindowToken(), 0);\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Jun 11 '20 at 4:18\ncommunity wiki\n\n\n3 revs, 3 users 64%\nmckoss","comments":["I got this to work with SearchView too. See below for my answer. Thanks mckoss!"]},{"answer":"Please try this below code in onCreate()\n\nEditText edtView = (EditText) findViewById(R.id.editTextConvertValue);\nedtView.setInputType(InputType.TYPE_NULL);\n\nShare\nImprove this answer\nFollow\nedited Oct 8 '20 at 22:15\ncommunity wiki\n\n\n4 revs, 4 users 62%\nJeyavel","comments":["This method works as a means of getting around the \"can't hide the soft keyboard\" bug in 2.0 and 2.1 as described in code.google.com/p/android/issues/detail?id=7115 ... the hideSoftInputFromWindow method listed above did not work when I tried it, but editView.setInputType(0) did.","This is legit per Javadoc (not a hack) though I would rewrite the method as editView.setInputType(InputType.TYPE_NULL);","this works, however, it hides the android:hint. i'm using Android 1.5","this is great for when you need to close the keyboard from a dialog, don't need to get an instance or anything and can assign this to all edit texts when user presses a button that closes the dialog","It works, but it's also hiding the cursor. I need the cursor, but no system keyboard."]},{"answer":"Update: I don't know why this solution is not work any more ( I just tested on Android 23). Please use the solution of Saurabh Pareek instead. Here it is:\n\nInputMethodManager imm = (InputMethodManager) getSystemService(Activity.INPUT_METHOD_SERVICE);\n//Hide:\nimm.toggleSoftInput(InputMethodManager.HIDE_IMPLICIT_ONLY, 0);\n//Show\nimm.toggleSoftInput(InputMethodManager.SHOW_IMPLICIT, 0);\n\n\nOld answer:\n\n//Show soft-keyboard:\ngetWindow().setSoftInputMode(WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_VISIBLE);\n//hide keyboard :\n getWindow().setSoftInputMode(WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_HIDDEN);\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:10\ncommunity wiki\n\n\n3 revs\nNguyen Minh Binh","comments":["Where should i place this code? I've tried to paste getWindow().setSoftInputMode(WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_HIDDEN); in onCreate() but the keyboard is never hidden","does not work, tested in radioGroup.setOnCheckedChangeListener, API 23","If you look closer, InputMethodManager.HIDE_IMPLICIT_ONLY and InputMethodManager.SHOW_IMPLICIT have the same value, which is \"1\", so there is no difference between these calls. => not working","if calling imm.toggleSoftInput(InputMethodManager.HIDE_IMPLICIT_ONLY, 0); then keyboard will show on screen :) Best implementation is: github.com/ravindu1024/android-keyboardlistener Shame on Android SDK","I don't know why this solution is not work any more - because it's Android, everything will be able to change, maybe partly of bad design... We write carelessly, then we strike out all and rewrite everything."]},{"answer":"protected void hideSoftKeyboard(EditText input) {\n    InputMethodManager imm = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);\n    imm.hideSoftInputFromWindow(input.getWindowToken(), 0);    \n}\n\nShare\nImprove this answer\nFollow\nedited Nov 28 '18 at 10:55\ncommunity wiki\n\n\n5 revs, 5 users 43%\nSreedev R","comments":["This worked for me! But why did you put input.setInputType(0) ? I couldn't interact with the EditTextView when I had that line of code (It worked when I removed it).","Probably input.getContext().getSystemService(Context.INPUT_METHOD_SERVICE).","I removed input.setInputType(0); from this code. It changed a keyboard behaviour and inputType for the EditText."]},{"answer":"If all the other answers here don't work for you as you would like them to, there's another way of manually controlling the keyboard.\n\nCreate a function with that will manage some of the EditText's properties:\n\npublic void setEditTextFocus(boolean isFocused) {\n    searchEditText.setCursorVisible(isFocused);\n    searchEditText.setFocusable(isFocused);\n    searchEditText.setFocusableInTouchMode(isFocused);\n\n    if (isFocused) {\n        searchEditText.requestFocus();\n    }\n}\n\n\nThen, make sure that onFocus of the EditText you open/close the keyboard:\n\nsearchEditText.setOnFocusChangeListener(new OnFocusChangeListener() {\n    @Override\n    public void onFocusChange(View v, boolean hasFocus) {\n        if (v == searchEditText) {\n            if (hasFocus) {\n                // Open keyboard\n                ((InputMethodManager) context.getSystemService(Context.INPUT_METHOD_SERVICE)).showSoftInput(searchEditText, InputMethodManager.SHOW_FORCED);\n            } else {\n                // Close keyboard\n                ((InputMethodManager) context.getSystemService(Context.INPUT_METHOD_SERVICE)).hideSoftInputFromWindow(searchEditText.getWindowToken(), 0);\n            }\n        }\n    }\n});\n\n\nNow, whenever you want to open the keyboard manually call:\n\nsetEditTextFocus(true);\n\n\nAnd for closing call:\n\nsetEditTextFocus(false);\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '14 at 15:55\ncommunity wiki\n\n\n3 revs, 2 users 81%\nRotemmiz","comments":["+1 - If you want to start an activity with closed keyboard use this solution and add an onclicklistener which sets setEditTextFocus(true). Works like charme!","I got 'Cannot resolve symbol context', on 7th and 10th line of second block of code.","Use getContext() instead"]},{"answer":"Saurabh Pareek has the best answer so far.\n\nMight as well use the correct flags, though.\n\n/* hide keyboard */\n((InputMethodManager) getSystemService(Activity.INPUT_METHOD_SERVICE))\n    .toggleSoftInput(InputMethodManager.SHOW_IMPLICIT, 0);\n\n/* show keyboard */\n((InputMethodManager) getSystemService(Activity.INPUT_METHOD_SERVICE))\n    .toggleSoftInput(0, InputMethodManager.HIDE_IMPLICIT_ONLY);\n\n\nExample of real use\n\n/* click button */\npublic void onClick(View view) {      \n  /* hide keyboard */\n  ((InputMethodManager) getSystemService(Activity.INPUT_METHOD_SERVICE))\n      .toggleSoftInput(InputMethodManager.SHOW_IMPLICIT, 0);\n\n  /* start loader to check parameters ... */\n}\n\n/* loader finished */\npublic void onLoadFinished(Loader<Object> loader, Object data) {\n    /* parameters not valid ... */\n\n    /* show keyboard */\n    ((InputMethodManager) getSystemService(Activity.INPUT_METHOD_SERVICE))\n        .toggleSoftInput(0, InputMethodManager.HIDE_IMPLICIT_ONLY);\n\n    /* parameters valid ... */\n}\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 11:55\ncommunity wiki\n\n\n2 revs\nAlex","comments":["This is the most efficient for the latest version. One will always need to tweak it for older versions. Especially before v3.","@Mazen: use fragment.getActivity().getSystemService();","This is the most comprehensive answer, covering both show and hide.","No. On my Samsung Tab, Android 5.0, The so-called \"hide keyboard\" code above will TOGGLE the soft keyboard -- if it is already hidden, it will show it. There is a reason this function has TOGGLE in the name.","Would you please provide your guidance on following question :stackoverflow.com/questions/67985653/…"]},{"answer":"from so searching, here I found an answer that works for me\n\n// Show soft-keyboard:\nInputMethodManager imm = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);\nimm.toggleSoftInput(InputMethodManager.SHOW_FORCED, 0);\n\n// Hide soft-keyboard:\ngetWindow().setSoftInputMode(WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_HIDDEN);\n\nShare\nImprove this answer\nFollow\nedited Apr 24 '15 at 21:09\ncommunity wiki\n\n\n2 revs, 2 users 80%\nshontauro","comments":["The only one that worked for me for a Motorola with Android 5.1"]},{"answer":"The short answer\n\nIn your OnClick listener call the onEditorAction of the EditText with IME_ACTION_DONE\n\nbutton.setOnClickListener(new OnClickListener() {\n\n    @Override\n    public void onClick(View v) {\n        someEditText.onEditorAction(EditorInfo.IME_ACTION_DONE)\n    }\n});\n\nThe drill-down\n\nI feel this method is better, simpler and more aligned with Android's design pattern. In the simple example above (and usually in most of the common cases) you'll have an EditText that has/had focus and it also usually was the one to invoke the keyboard in the first place (it is definitely able to invoke it in many common scenarios). In that same way, it should be the one to release the keyboard, usually that can be done by an ImeAction. Just see how an EditText with android:imeOptions=\"actionDone\" behaves, you want to achieve the same behavior by the same means.\n\nCheck this related answer\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:10\ncommunity wiki\n\n\n3 revs\nAlex.F","comments":["This IS the answer. Only method that works cross version. I came back to this question to post this answer cause I didnt think anyone else knew","This should be the correct answer. Instead of tricking Android into hiding the keyboard when it really should be there, we tell it that the user is done, which in turn triggers the same ImeAction [stupid name, I admit] as if the user had clicked \"DONE\" on the keyboard. This way it makes no difference if the user confirms input on the keyboard or taps the UI button."]},{"answer":"This should work:\n\npublic class KeyBoard {\n\n    public static void show(Activity activity){\n        InputMethodManager imm = (InputMethodManager) activity.getSystemService(Activity.INPUT_METHOD_SERVICE);\n        imm.toggleSoftInput(0, InputMethodManager.HIDE_IMPLICIT_ONLY); // show\n    }\n\n    public static void hide(Activity activity){\n        InputMethodManager imm = (InputMethodManager) activity.getSystemService(Activity.INPUT_METHOD_SERVICE);\n        imm.toggleSoftInput(InputMethodManager.HIDE_IMPLICIT_ONLY, 0); // hide\n    }\n\n    public static void toggle(Activity activity){\n        InputMethodManager imm = (InputMethodManager) activity.getSystemService(Activity.INPUT_METHOD_SERVICE);\n        if (imm.isActive()){\n            hide(activity); \n        } else {\n            show(activity); \n        }\n    }\n}\n\nKeyBoard.toggle(activity);\n\nShare\nImprove this answer\nFollow\nedited Jul 15 '16 at 14:51\ncommunity wiki\n\n\n3 revs\nslinden77","comments":["Worked partly, even if keyboard was hided \"isActive()\" returns false!","Ofcourse it does, it's supposed to. Or maybe I don't understand you. Anyway, you could supplement the class with hide() and show() methods to have more control over when it should show and when not. Works for me, I did it too :) I will edit example","@YoushaAleayoub yes it will. KeyBoard.toggle(fragment.getActivity())","@slinden77, lol, I'm talking about your Answer... not this one you have commented. So that answer still WONT work.","@YoushaAleayoub uhm yes it will. The original question doesn't mention fragments, you are the one who mentioned fragments. So my answer is perfectly valid. To use it with fragments, call the method differently from a Fragment, like a commented. Learn how to use methods please and then come back. You're confusing people with your silly replies"]},{"answer":"I'm using a custom keyboard to input an Hex number so I can't have the IMM keyboard show up...\n\nIn v3.2.4_r1 setSoftInputShownOnFocus(boolean show) was added to control weather or not to display the keyboard when a TextView gets focus, but its still hidden so reflection must be used:\n\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.HONEYCOMB_MR2) {\n    try {\n        Method method = TextView.class.getMethod(\"setSoftInputShownOnFocus\", boolean.class);\n        method.invoke(mEditText, false);\n    } catch (Exception e) {\n        // Fallback to the second method\n    }\n}\n\n\nFor older versions, I got very good results (but far from perfect) with a OnGlobalLayoutListener, added with the aid of a ViewTreeObserver from my root view and then checking if the keyboard is shown like this:\n\n@Override\npublic void onGlobalLayout() {\n    Configuration config = getResources().getConfiguration();\n\n    // Dont allow the default keyboard to show up\n    if (config.keyboardHidden != Configuration.KEYBOARDHIDDEN_YES) {\n        InputMethodManager imm = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);\n        imm.hideSoftInputFromWindow(mRootView.getWindowToken(), 0);\n    }\n}\n\n\nThis last solution may show the keyboard for a split second and messes with the selection handles.\n\nWhen in the keyboard enters full screen, onGlobalLayout isn't called. To avoid that, use TextView#setImeOptions(int) or in the TextView XML declaration:\n\nandroid:imeOptions=\"actionNone|actionUnspecified|flagNoFullscreen|flagNoExtractUi\"\n\n\nUpdate: Just found what dialogs use to never show the keyboard and works in all versions:\n\ngetWindow().setFlags(WindowManager.LayoutParams.FLAG_ALT_FOCUSABLE_IM,\n        WindowManager.LayoutParams.FLAG_ALT_FOCUSABLE_IM);\n\nShare\nImprove this answer\nFollow\nedited May 28 '12 at 20:48\ncommunity wiki\n\n\nsergio91pt","comments":["Thank you. The two flags FLAG_ALT_FOCUSABLE_IM and FLAG_ALT_FOCUSABLE_IM are actualy the only thing that helped in my case. I did not want a keyboard to be shown in my activity - not even when the user clicked an edittext. (I made my own \"keypad\").","Cool solution, however, if your front activity is not fullscreen, the keyboard is visible behind it. Also the keyboard's cursor movement aid is also still visible. And it's not skinnable.","I second that. Of all the possible ways only the getWindow().setFlags() method works, at least on stock Android 5.1. Note that setSoftInputShownOnFocus() is now setShowSoftInputOnFocus() and no longer hidden but does not work, at least not when the user touches the field.","Your \"update\" was the only working solution for me. I'm looking for a solution at least two hours :)","I wish I could upvote you more than once - the last line was the only one that worked for me!!!!"]},{"answer":"public void setKeyboardVisibility(boolean show) {\n    InputMethodManager imm = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);\n    if(show){\n        imm.toggleSoftInput(InputMethodManager.SHOW_FORCED, 0);\n    }else{\n        imm.hideSoftInputFromWindow(getCurrentFocus().getWindowToken(),0);\n    }\n}\n\nShare\nImprove this answer\nFollow\nanswered Jun 1 '15 at 13:36\ncommunity wiki\n\n\nshobhan","comments":[]},{"answer":"I have spent more than two days working through all of the solutions posted in the thread and have found them lacking in one way or another. My exact requirement is to have a button that will with 100% reliability show or hide the on screen keyboard. When the keyboard is in its hidden state is should not re-appear, no matter what input fields the user clicks on. When it is in its visible state the keyboard should not disappear no matter what buttons the user clicks. This needs to work on Android 2.2+ all the way up to the latest devices.\n\nYou can see a working implementation of this in my app clean RPN.\n\nAfter testing many of the suggested answers on a number of different phones (including froyo and gingerbread devices) it became apparent that android apps can reliably:\n\nTemporarily hide the keyboard. It will re-appear again when a user focuses a new text field.\nShow the keyboard when an activity starts and set a flag on the activity indicating that they keyboard should always be visible. This flag can only be set when an activity is initialising.\nMark an activity to never show or allow the use of the keyboard. This flag can only be set when an activity is initialising.\n\nFor me, temporarily hiding the keyboard is not enough. On some devices it will re-appear as soon as a new text field is focused. As my app uses multiple text fields on one page, focusing a new text field will cause the hidden keyboard to pop back up again.\n\nUnfortunately item 2 and 3 on the list only work reliability when an activity is being started. Once the activity has become visible you cannot permanently hide or show the keyboard. The trick is to actually restart your activity when the user presses the keyboard toggle button. In my app when the user presses on the toggle keyboard button, the following code runs:\n\nprivate void toggleKeyboard(){\n\n    if(keypadPager.getVisibility() == View.VISIBLE){\n        Intent i = new Intent(this, MainActivity.class);\n        i.addFlags(Intent.FLAG_ACTIVITY_NO_ANIMATION);\n        Bundle state = new Bundle();\n        onSaveInstanceState(state);\n        state.putBoolean(SHOW_KEYBOARD, true);\n        i.putExtras(state);\n\n        startActivity(i);\n    }\n    else{\n        Intent i = new Intent(this, MainActivity.class);\n        i.addFlags(Intent.FLAG_ACTIVITY_NO_ANIMATION);\n        Bundle state = new Bundle();\n        onSaveInstanceState(state);\n        state.putBoolean(SHOW_KEYBOARD, false);\n        i.putExtras(state);\n\n        startActivity(i);\n    }\n}\n\n\nThis causes the current activity to have its state saved into a Bundle, and then the activity is started, passing through an boolean which indicates if the keyboard should be shown or hidden.\n\nInside the onCreate method the following code is run:\n\nif(bundle.getBoolean(SHOW_KEYBOARD)){\n    ((InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE)).showSoftInput(newEquationText,0);\n    getWindow().setSoftInputMode(LayoutParams.SOFT_INPUT_STATE_ALWAYS_VISIBLE);\n}\nelse{\n    getWindow().setFlags(WindowManager.LayoutParams.FLAG_ALT_FOCUSABLE_IM,\n            WindowManager.LayoutParams.FLAG_ALT_FOCUSABLE_IM);\n}\n\n\nIf the soft keyboard should be shown, then the InputMethodManager is told to show the keyboard and the window is instructed to make the soft input always visible. If the soft keyboard should be hidden then the WindowManager.LayoutParams.FLAG_ALT_FOCUSABLE_IM is set.\n\nThis approach works reliably on all devices I have tested on - from a 4 year old HTC phone running android 2.2 up to a nexus 7 running 4.2.2. The only disadvantage with this approach is you need to be careful with handling the back button. As my app essentially only has one screen (its a calculator) I can override onBackPressed() and return to the devices home screen.\n\nShare\nImprove this answer\nFollow\nedited Mar 6 '18 at 7:10\ncommunity wiki\n\n\n2 revs, 2 users 93%\nLuke Sleeman","comments":["elaborate workaround, but i think it's just too much , to recreate thousands of objects just to hide the Keyboard. I dont know who designed the IMM for android, but it smells like a Windows APi. In my opinion, a good IME should have two methods: hide and show :-)","Its all true, but my workaround does have one advantage - it always works! There is no other solution I could find that would always toggle the keyboard, regardless of of what fields in the UI have the focus, what the user has done to toggle and keyboard and what version of android they are running :-\\","Man, I'm totally desperate to hide the keyboard. Tried thousands of things and noooone works. But your workaround is too much for me, I'd have to recreate like 10 fragments, initialize services, delete a lot of WeakReferences .... you know? the GC would just throw away like 25mb :S ... Still looking for a reliable way to do it :(","@Dmitry well it's not a hello world...it's a complex application for tablets. I refuse to totally unload it from memory just to hide a silly keyboard... Anyway I found something that works combining the thousand solutions proposed here :)"]},{"answer":"Alternatively to this all around solution, if you wanted to close the soft keyboard from anywhere without having a reference to the (EditText) field that was used to open the keyboard, but still wanted to do it if the field was focused, you could use this (from an Activity):\n\nif (getCurrentFocus() != null) {\n    InputMethodManager imm = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);\n    imm.hideSoftInputFromWindow(getCurrentFocus().getWindowToken(), 0);\n}\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:10\ncommunity wiki\n\n\n4 revs, 2 users 82%\nSaran","comments":[]},{"answer":"Thanks to this SO answer, I derived the following which, in my case, works nicely when scrolling through the the fragments of a ViewPager...\n\nprivate void hideKeyboard() {   \n    // Check if no view has focus:\n    View view = this.getCurrentFocus();\n    if (view != null) {\n        InputMethodManager inputManager = (InputMethodManager) this.getSystemService(Context.INPUT_METHOD_SERVICE);\n        inputManager.hideSoftInputFromWindow(view.getWindowToken(), InputMethodManager.HIDE_NOT_ALWAYS);\n    }\n}\n\nprivate void showKeyboard() {   \n    // Check if no view has focus:\n    View view = this.getCurrentFocus();\n    if (view != null) {\n        InputMethodManager inputManager = (InputMethodManager) this.getSystemService(Context.INPUT_METHOD_SERVICE);\n        inputManager.showSoftInput(view, InputMethodManager.SHOW_IMPLICIT);\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\ncommunity wiki\n\n\n2 revs\nban-geoengineering","comments":[]},{"answer":"Above answers work for different scenario's but If you want to hide the keyboard inside a view and struggling to get the right context try this:\n\nsetOnClickListener(new OnClickListener() {\n    @Override\n    public void onClick(View v) {\n        hideSoftKeyBoardOnTabClicked(v);\n    }\n}\n\nprivate void hideSoftKeyBoardOnTabClicked(View v) {\n    if (v != null && context != null) {\n        InputMethodManager imm = (InputMethodManager) context.getSystemService(Context.INPUT_METHOD_SERVICE);\n        imm.hideSoftInputFromWindow(v.getApplicationWindowToken(), InputMethodManager.HIDE_NOT_ALWAYS);\n    }\n}\n\n\nand to get the context fetch it from constructor:)\n\npublic View/RelativeLayout/so and so (Context context, AttributeSet attrs, int defStyle) {\n    super(context, attrs, defStyle);\n    this.context = context;\n    init();\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 24 '15 at 21:10\ncommunity wiki\n\n\n2 revs, 2 users 76%\nAsh","comments":[]},{"answer":"If you want to close the soft keyboard during a unit or functional test, you can do so by clicking the \"back button\" from your test:\n\n// Close the soft keyboard from a Test\ngetInstrumentation().sendKeyDownUpSync(KeyEvent.KEYCODE_BACK);\n\n\nI put \"back button\" in quotes, since the above doesn't trigger the onBackPressed() for the Activity in question. It just closes the keyboard.\n\nMake sure to pause for a little while before moving on, since it takes a little while to close the back button, so subsequent clicks to Views, etc., won't be registered until after a short pause (1 second is long enough ime).\n\nShare\nImprove this answer\nFollow\nedited Dec 13 '11 at 21:55\ncommunity wiki\n\n\nPeter Ajtai","comments":[]},{"answer":"Here's how you do it in Mono for Android (AKA MonoDroid)\n\nInputMethodManager imm = GetSystemService (Context.InputMethodService) as InputMethodManager;\nif (imm != null)\n    imm.HideSoftInputFromWindow (searchbox.WindowToken , 0);\n\nShare\nImprove this answer\nFollow\nanswered May 15 '12 at 1:36\ncommunity wiki\n\n\nIan Vink","comments":["What is searchbox in the snippet?"]},{"answer":"This worked for me for all the bizarre keyboard behavior\n\nprivate boolean isKeyboardVisible() {\n    Rect r = new Rect();\n    //r will be populated with the coordinates of your view that area still visible.\n    mRootView.getWindowVisibleDisplayFrame(r);\n\n    int heightDiff = mRootView.getRootView().getHeight() - (r.bottom - r.top);\n    return heightDiff > 100; // if more than 100 pixels, its probably a keyboard...\n}\n\nprotected void showKeyboard() {\n    if (isKeyboardVisible())\n        return;\n    InputMethodManager inputMethodManager = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);\n    if (getCurrentFocus() == null) {\n        inputMethodManager.toggleSoftInput(InputMethodManager.SHOW_FORCED, 0);\n    } else {\n        View view = getCurrentFocus();\n        inputMethodManager.showSoftInput(view, InputMethodManager.SHOW_FORCED);\n    }\n}\n\nprotected void hideKeyboard() {\n    if (!isKeyboardVisible())\n        return;\n    InputMethodManager inputMethodManager = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);\n    View view = getCurrentFocus();\n    if (view == null) {\n        if (inputMethodManager.isAcceptingText())\n            inputMethodManager.toggleSoftInput(InputMethodManager.HIDE_NOT_ALWAYS, 0);\n    } else {\n        if (view instanceof EditText)\n            ((EditText) view).setText(((EditText) view).getText().toString()); // reset edit text bug on some keyboards bug\n        inputMethodManager.hideSoftInputFromInputMethod(view.getWindowToken(), InputMethodManager.HIDE_NOT_ALWAYS);\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 24 '15 at 21:11\ncommunity wiki\n\n\n4 revs, 3 users 89%\nPinhassi","comments":["Think I tried 10 answers before this one. Had given up hope. Thanks man.","What is mRootView?"]},{"answer":"Simple and Easy to use method, just call hideKeyboardFrom(YourActivity.this); to hide keyboard\n\n/**\n * This method is used to hide keyboard\n * @param activity\n */\npublic static void hideKeyboardFrom(Activity activity) {\n    InputMethodManager imm = (InputMethodManager) activity.getSystemService(Activity.INPUT_METHOD_SERVICE);\n    imm.hideSoftInputFromWindow(activity.getCurrentFocus().getWindowToken(), 0);\n}\n\nShare\nImprove this answer\nFollow\nanswered Feb 21 '17 at 6:52\ncommunity wiki\n\n\nNaveed Ahmad","comments":[]},{"answer":"Add to your activity android:windowSoftInputMode=\"stateHidden\" in Manifest file. Example:\n\n<activity\n            android:name=\".ui.activity.MainActivity\"\n            android:label=\"@string/mainactivity\"\n            android:windowSoftInputMode=\"stateHidden\"/>\n\nShare\nImprove this answer\nFollow\nanswered Feb 4 '16 at 12:21\ncommunity wiki\n\n\nNickUnuchek","comments":[]},{"answer":"For Open Keyboard :\n\nInputMethodManager imm = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);\nimm.showSoftInput(edtView, InputMethodManager.SHOW_IMPLICIT);\n\n\nFor Close/Hide Keyboard :\n\n InputMethodManager imm = (InputMethodManager)getSystemService(Context.INPUT_METHOD_SERVICE);\n imm.hideSoftInputFromWindow(edtView.getWindowToken(), 0);\n\nShare\nImprove this answer\nFollow\nanswered Feb 5 '15 at 12:39\ncommunity wiki\n\n\nGirish Patel","comments":[]},{"answer":"Just use this optimized code in your activity:\n\nif (this.getCurrentFocus() != null) {\n    InputMethodManager inputManager = (InputMethodManager) this.getSystemService(Context.INPUT_METHOD_SERVICE);\n    inputManager.hideSoftInputFromWindow(this.getCurrentFocus().getWindowToken(), InputMethodManager.HIDE_NOT_ALWAYS);\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 24 '15 at 21:11\ncommunity wiki\n\n\n2 revs, 2 users 75%\nHamid FzM","comments":["Works fine. Thanks"]},{"answer":"I have the case, where my EditText can be located also in an AlertDialog, so the keyboard should be closed on dismiss. The following code seems to be working anywhere:\n\npublic static void hideKeyboard( Activity activity ) {\n    InputMethodManager imm = (InputMethodManager)activity.getSystemService( Context.INPUT_METHOD_SERVICE );\n    View f = activity.getCurrentFocus();\n    if( null != f && null != f.getWindowToken() && EditText.class.isAssignableFrom( f.getClass() ) )\n        imm.hideSoftInputFromWindow( f.getWindowToken(), 0 );\n    else \n        activity.getWindow().setSoftInputMode( WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_HIDDEN );\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 24 '15 at 21:12\ncommunity wiki\n\n\n3 revs, 2 users 78%\ninjecteer","comments":["This solution is better because you have not to control which EditText pass as a parameter to hideSoftInputFromWindow() method. It works great!!"]},{"answer":"Works like magic touch every time\n\nprivate void closeKeyboard() {\n    InputMethodManager inputManager = (InputMethodManager)getActivity().getSystemService(Context.INPUT_METHOD_SERVICE);\n    inputManager.hideSoftInputFromWindow(getActivity().getCurrentFocus().getWindowToken(), InputMethodManager.HIDE_NOT_ALWAYS);\n\n}\n\nprivate void openKeyboard() {\n    InputMethodManager imm = (InputMethodManager) getActivity().getSystemService(Context.INPUT_METHOD_SERVICE);\n    if(imm != null){\n        imm.toggleSoftInput(InputMethodManager.SHOW_IMPLICIT, 0);\n    }\n}\n\nShare\nImprove this answer\nFollow\nanswered Jul 3 '17 at 13:18\ncommunity wiki\n\n\nGiedrius Šlikas","comments":[]},{"answer":"• Kotlin Version via Extension Function\n\nUsing kotlin extension functions, it'd be so simple to show and hide the soft keyboard.\n\nExtensionFunctions.kt\n\nimport android.app.Activity\nimport android.view.View\nimport android.view.inputmethod.InputMethodManager\nimport android.widget.EditText\nimport androidx.fragment.app.Fragment\n\nfun Activity.hideKeyboard(): Boolean {\n    return (getSystemService(Activity.INPUT_METHOD_SERVICE) as InputMethodManager)\n        .hideSoftInputFromWindow((currentFocus ?: View(this)).windowToken, 0)\n}\n\nfun Fragment.hideKeyboard(): Boolean {\n    return (context?.getSystemService(Activity.INPUT_METHOD_SERVICE) as InputMethodManager)\n        .hideSoftInputFromWindow((activity?.currentFocus ?: View(context)).windowToken, 0)\n}\n\nfun EditText.hideKeyboard(): Boolean {\n    return (context.getSystemService(Activity.INPUT_METHOD_SERVICE) as InputMethodManager)\n        .hideSoftInputFromWindow(windowToken, 0)\n}\n\nfun EditText.showKeyboard(): Boolean {\n    return (context.getSystemService(Activity.INPUT_METHOD_SERVICE) as InputMethodManager)\n        .showSoftInput(this, 0)\n}\n\n• Usage\n\nNow in your Activity or Fragment, hideKeyboard() is clearly accessible as well as calling it from an instance of EditText like:\n\neditText.hideKeyboard()\n\nShare\nImprove this answer\nFollow\nanswered Jul 4 '20 at 12:45\ncommunity wiki\n\n\naminography","comments":[]},{"answer":"public static void hideSoftKeyboard(Activity activity) {\n    InputMethodManager inputMethodManager = (InputMethodManager)  activity.getSystemService(Activity.INPUT_METHOD_SERVICE);\n    inputMethodManager.hideSoftInputFromWindow(activity.getCurrentFocus().getWindowToken(), 0);\n}\n\n\nafter that call on onTouchListener:\n\nfindViewById(android.R.id.content).setOnTouchListener(new OnTouchListener() {\n    @Override\n    public boolean onTouch(View v, MotionEvent event) {\n        Utils.hideSoftKeyboard(activity);\n        return false;\n    }\n});\n\nShare\nImprove this answer\nFollow\nanswered May 18 '13 at 4:40\ncommunity wiki\n\n\nSagar Maiyad","comments":["Try this as well - this worked for me: InputMethodManager imm = ((InputMethodManager) getSystemService(Activity.INPUT_METHOD_SERVICE)); imm.hideSoftInputFromWindow(getWindow().getCurrentFocus().getWindowToken(), 0);"]}]},{"id":"671118","href":"https://stackoverflow.com/questions/671118/what-exactly-is-restful-programming","title":"What exactly is RESTful programming?","description":"\n                \nWhat exactly is RESTful programming?\n\n\n    ","questionComments":["see also the answer at the following link stackoverflow.com/a/37683965/3762855","REST might be getting a bit old now ;) youtu.be/WQLzZf34FJ8","Also, refer this link for some more information news.ycombinator.com/item?id=3538585","Corrections to accepted answer here. stackoverflow.com/questions/19843480/… Or here roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven Or here web.archive.org/web/20130116005443/http://tomayko.com/writings/…","@OLIVER.KOO nice observation. It's just that I asked it at a time when it was kind of a new thing. It was getting thrown around a lot but not many people knew what it was about. At least I didn't, and it seems that me asking this has helped them because they also wanted to know."],"answers":[{"answer":"An architectural style called REST (Representational State Transfer) advocates that web applications should use HTTP as it was originally envisioned. Lookups should use GET requests. PUT, POST, and DELETE requests should be used for mutation, creation, and deletion respectively.\n\nREST proponents tend to favor URLs, such as\n\nhttp://myserver.com/catalog/item/1729\n\n\nbut the REST architecture does not require these \"pretty URLs\". A GET request with a parameter\n\nhttp://myserver.com/catalog?item=1729\n\n\nis every bit as RESTful.\n\nKeep in mind that GET requests should never be used for updating information. For example, a GET request for adding an item to a cart\n\nhttp://myserver.com/addToCart?cart=314159&item=1729\n\n\nwould not be appropriate. GET requests should be idempotent. That is, issuing a request twice should be no different from issuing it once. That's what makes the requests cacheable. An \"add to cart\" request is not idempotent—issuing it twice adds two copies of the item to the cart. A POST request is clearly appropriate in this context. Thus, even a RESTful web application needs its share of POST requests.\n\nThis is taken from the excellent book Core JavaServer faces book by David M. Geary.\n\nShare\nImprove this answer\nFollow\nedited Jul 4 at 12:27\nZulkifil\n2573\n3 silver badges\n4\n4 bronze badges\nanswered Apr 15 '15 at 11:26\nFarhan Shirgill Ansari\n13.3k7\n7 gold badges\n51\n51 silver badges\n97\n97 bronze badges","comments":["Lisiting Available Idempotent Operations: GET(Safe), PUT & DELETE (Exception is mentioned in this link restapitutorial.com/lessons/idempotency.html). Additional Reference for Safe & Idempotent Methods w3.org/Protocols/rfc2616/rfc2616-sec9.html","a) the important point about GET is safeness, not idempotence, b) @Abhijeet: RFC 2616 has been obsoleted in 2014; see RF 7230ff.","This is wrong. Read this for correct interpretation of REST roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven or this stackoverflow.com/questions/19843480/…","@kushalvm That academic definition of REST is not used in practice.","Effectively we can wonder if a concept is operational since we fail to simple give it a stable and understandable definition for all"]},{"answer":"REST is the underlying architectural principle of the web. The amazing thing about the web is the fact that clients (browsers) and servers can interact in complex ways without the client knowing anything beforehand about the server and the resources it hosts. The key constraint is that the server and client must both agree on the media used, which in the case of the web is HTML.\n\nAn API that adheres to the principles of REST does not require the client to know anything about the structure of the API. Rather, the server needs to provide whatever information the client needs to interact with the service. An HTML form is an example of this: The server specifies the location of the resource and the required fields. The browser doesn't know in advance where to submit the information, and it doesn't know in advance what information to submit. Both forms of information are entirely supplied by the server. (This principle is called HATEOAS: Hypermedia As The Engine Of Application State.)\n\nSo, how does this apply to HTTP, and how can it be implemented in practice? HTTP is oriented around verbs and resources. The two verbs in mainstream usage are GET and POST, which I think everyone will recognize. However, the HTTP standard defines several others such as PUT and DELETE. These verbs are then applied to resources, according to the instructions provided by the server.\n\nFor example, Let's imagine that we have a user database that is managed by a web service. Our service uses a custom hypermedia based on JSON, for which we assign the mimetype application/json+userdb (There might also be an application/xml+userdb and application/whatever+userdb - many media types may be supported). The client and the server have both been programmed to understand this format, but they don't know anything about each other. As Roy Fielding points out:\n\nA REST API should spend almost all of its descriptive effort in defining the media type(s) used for representing resources and driving application state, or in defining extended relation names and/or hypertext-enabled mark-up for existing standard media types.\n\nA request for the base resource / might return something like this:\n\nRequest\n\nGET /\nAccept: application/json+userdb\n\n\nResponse\n\n200 OK\nContent-Type: application/json+userdb\n\n{\n    \"version\": \"1.0\",\n    \"links\": [\n        {\n            \"href\": \"/user\",\n            \"rel\": \"list\",\n            \"method\": \"GET\"\n        },\n        {\n            \"href\": \"/user\",\n            \"rel\": \"create\",\n            \"method\": \"POST\"\n        }\n    ]\n}\n\n\nWe know from the description of our media that we can find information about related resources from sections called \"links\". This is called Hypermedia controls. In this case, we can tell from such a section that we can find a user list by making another request for /user:\n\nRequest\n\nGET /user\nAccept: application/json+userdb\n\n\nResponse\n\n200 OK\nContent-Type: application/json+userdb\n\n{\n    \"users\": [\n        {\n            \"id\": 1,\n            \"name\": \"Emil\",\n            \"country: \"Sweden\",\n            \"links\": [\n                {\n                    \"href\": \"/user/1\",\n                    \"rel\": \"self\",\n                    \"method\": \"GET\"\n                },\n                {\n                    \"href\": \"/user/1\",\n                    \"rel\": \"edit\",\n                    \"method\": \"PUT\"\n                },\n                {\n                    \"href\": \"/user/1\",\n                    \"rel\": \"delete\",\n                    \"method\": \"DELETE\"\n                }\n            ]\n        },\n        {\n            \"id\": 2,\n            \"name\": \"Adam\",\n            \"country: \"Scotland\",\n            \"links\": [\n                {\n                    \"href\": \"/user/2\",\n                    \"rel\": \"self\",\n                    \"method\": \"GET\"\n                },\n                {\n                    \"href\": \"/user/2\",\n                    \"rel\": \"edit\",\n                    \"method\": \"PUT\"\n                },\n                {\n                    \"href\": \"/user/2\",\n                    \"rel\": \"delete\",\n                    \"method\": \"DELETE\"\n                }\n            ]\n        }\n    ],\n    \"links\": [\n        {\n            \"href\": \"/user\",\n            \"rel\": \"create\",\n            \"method\": \"POST\"\n        }\n    ]\n}\n\n\nWe can tell a lot from this response. For instance, we now know we can create a new user by POSTing to /user:\n\nRequest\n\nPOST /user\nAccept: application/json+userdb\nContent-Type: application/json+userdb\n\n{\n    \"name\": \"Karl\",\n    \"country\": \"Austria\"\n}\n\n\nResponse\n\n201 Created\nContent-Type: application/json+userdb\n\n{\n    \"user\": {\n        \"id\": 3,\n        \"name\": \"Karl\",\n        \"country\": \"Austria\",\n        \"links\": [\n            {\n                \"href\": \"/user/3\",\n                \"rel\": \"self\",\n                \"method\": \"GET\"\n            },\n            {\n                \"href\": \"/user/3\",\n                \"rel\": \"edit\",\n                \"method\": \"PUT\"\n            },\n            {\n                \"href\": \"/user/3\",\n                \"rel\": \"delete\",\n                \"method\": \"DELETE\"\n            }\n        ]\n    },\n    \"links\": {\n       \"href\": \"/user\",\n       \"rel\": \"list\",\n       \"method\": \"GET\"\n    }\n}\n\n\nWe also know that we can change existing data:\n\nRequest\n\nPUT /user/1\nAccept: application/json+userdb\nContent-Type: application/json+userdb\n\n{\n    \"name\": \"Emil\",\n    \"country\": \"Bhutan\"\n}\n\n\nResponse\n\n200 OK\nContent-Type: application/json+userdb\n\n{\n    \"user\": {\n        \"id\": 1,\n        \"name\": \"Emil\",\n        \"country\": \"Bhutan\",\n        \"links\": [\n            {\n                \"href\": \"/user/1\",\n                \"rel\": \"self\",\n                \"method\": \"GET\"\n            },\n            {\n                \"href\": \"/user/1\",\n                \"rel\": \"edit\",\n                \"method\": \"PUT\"\n            },\n            {\n                \"href\": \"/user/1\",\n                \"rel\": \"delete\",\n                \"method\": \"DELETE\"\n            }\n        ]\n    },\n    \"links\": {\n       \"href\": \"/user\",\n       \"rel\": \"list\",\n       \"method\": \"GET\"\n    }\n}\n\n\nNotice that we are using different HTTP verbs (GET, PUT, POST, DELETE etc.) to manipulate these resources, and that the only knowledge we presume on the client's part is our media definition.\n\nFurther reading:\n\nThe many much better answers on this very page.\nHow I explained REST to my wife.\nHow I explained REST to my wife.\nMartin Fowler's thoughts\nPayPal's API has hypermedia controls\n\n(This answer has been the subject of a fair amount of criticism for missing the point. For the most part, that has been a fair critique. What I originally described was more in line with how REST was usually implemented a few years ago when I first wrote this, rather than its true meaning. I've revised the answer to better represent the real meaning.)\n\nShare\nImprove this answer\nFollow\nedited Apr 10 '19 at 15:31\ncommunity wiki\n\n\n22 revs, 15 users 88%\nEmil H","comments":["No. REST didn't just pop up as another buzzword. It came about as a means of describing an alternative to SOAP-based data exchange. The term REST helps frame the discussion about how to transfer and access data.","Nonetheless, the heart of REST (in practical application) is \"don't use GET to make changes, use POST/PUT/DELETE\", which is advice I've been hearing (and following) since long before SOAP appeared. REST has always been there, it just didn't get a name beyond \"the way to do it\" until recently.","Don't forget \"Hypertext as the engine of application state\".","This answer misses the point. HTTP is barely mentioned in Fielding's thesis.","This answer doesn't mention the purpose of REST, and makes it seem like it's all about clean URIs. While this might be the popular perception of REST, D.Shawley's and oluies answers are more accurate - it's about being able to take advantage of features built into the architecture, like caching, by working with it instead of against it. Prettier URIs are mostly a common side effect."]},{"answer":"RESTful programming is about:\n\nresources being identified by a persistent identifier: URIs are the ubiquitous choice of identifier these days\nresources being manipulated using a common set of verbs: HTTP methods are the commonly seen case - the venerable Create, Retrieve, Update, Delete becomes POST, GET, PUT, and DELETE. But REST is not limited to HTTP, it is just the most commonly used transport right now.\nthe actual representation retrieved for a resource is dependent on the request and not the identifier: use Accept headers to control whether you want XML, HTTP, or even a Java Object representing the resource\nmaintaining the state in the object and representing the state in the representation\nrepresenting the relationships between resources in the representation of the resource: the links between objects are embedded directly in the representation\nresource representations describe how the representation can be used and under what circumstances it should be discarded/refetched in a consistent manner: usage of HTTP Cache-Control headers\n\nThe last one is probably the most important in terms of consequences and overall effectiveness of REST. Overall, most of the RESTful discussions seem to center on HTTP and its usage from a browser and what not. I understand that R. Fielding coined the term when he described the architecture and decisions that lead to HTTP. His thesis is more about the architecture and cache-ability of resources than it is about HTTP.\n\nIf you are really interested in what a RESTful architecture is and why it works, read his thesis a few times and read the whole thing not just Chapter 5! Next look into why DNS works. Read about the hierarchical organization of DNS and how referrals work. Then read and consider how DNS caching works. Finally, read the HTTP specifications (RFC2616 and RFC3040 in particular) and consider how and why the caching works the way that it does. Eventually, it will just click. The final revelation for me was when I saw the similarity between DNS and HTTP. After this, understanding why SOA and Message Passing Interfaces are scalable starts to click.\n\nI think that the most important trick to understanding the architectural importance and performance implications of a RESTful and Shared Nothing architectures is to avoid getting hung up on the technology and implementation details. Concentrate on who owns resources, who is responsible for creating/maintaining them, etc. Then think about the representations, protocols, and technologies.\n\nShare\nImprove this answer\nFollow\nedited Nov 2 '16 at 21:23\nEspen\n2,2451\n1 gold badge\n13\n13 silver badges\n22\n22 bronze badges\nanswered Mar 22 '09 at 19:37\nD.Shawley\n55.3k9\n9 gold badges\n92\n92 silver badges\n110\n110 bronze badges","comments":["An answer providing a reading list is very appropriate for this question.","Thanks for the update. PUT and POST don't really map one-to-one with update and create. PUT can be used to create if the client is dictating what the URI will be. POST creates if the server is assigning the new URI.","A URN is a URI that uses the urn: scheme. Conceptually there is no difference; however, a URN does require that you have a separately defined method to \"locate\" the resource identified (named) by the URN. Care must be taken to ensure that you don't introduce implicit coupling when relating named resources and their location.","@ellisbben Agreed. If I understand correctly this is the dissertation that gave rise to REST: ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm","One doubt on this point: \"the actual representation retrieved for a resource is dependent on the request and not the identifier: use HTTP Accept headers to control whether you want XML, HTTP, or even a Java Object representing the resource\" --Here, should it be \"...whether you want XML, HTML, or even a Java Object representing the resource...\" I am thinking that HTTP Accept headers tells the format for data exchanged. And HTTP is the protocol used in RESTel web APIs"]},{"answer":"This is what it might look like.\n\nCreate a user with three properties:\n\nPOST /user\nfname=John&lname=Doe&age=25\n\n\nThe server responds:\n\n200 OK\nLocation: /user/123\n\n\nIn the future, you can then retrieve the user information:\n\nGET /user/123\n\n\nThe server responds:\n\n200 OK\n<fname>John</fname><lname>Doe</lname><age>25</age>\n\n\nTo modify the record (lname and age will remain unchanged):\n\nPATCH /user/123\nfname=Johnny\n\n\nTo update the record (and consequently lname and age will be NULL):\n\nPUT /user/123\nfname=Johnny\n\nShare\nImprove this answer\nFollow\nedited Feb 6 '17 at 20:23\nKyle Baker\n2,6522\n2 gold badges\n20\n20 silver badges\n25\n25 bronze badges\nanswered Jul 4 '09 at 5:47\npbreitenbach\n10.9k3\n3 gold badges\n31\n31 silver badges\n24\n24 bronze badges","comments":["For me this answer captured the essence of the desired answer. Simple and pragmatic. Granted there are lots of other criteria, but the example provided is a great launch pad.","In the last example, @pbreitenbach uses PUT fname=Jonny. This would set lname and age to default values (probably NULL or the empty string, and integer 0), because a PUT overwrites the whole resource with data from the representation provided. This is not what is implied by \"update\", to do a real update, use the PATCH method as this does not alter fields which are not specified in the representation.","Nicholas is right. Also, the URI for the first POST creating a user should be called users because /user/1 makes no sense and there should be a listing at /users. The response should be a 201 Created and not just OK in that case.","This is just an example of an API not necessarily a RESTful api. A RESTful has constraints it adheres to. Client-Server Architecture, Stateless, Cache-ability, Layered System, Uniform Interface.","Thats a very compact answer that covered all http servlet access methods"]},{"answer":"A great book on REST is REST in Practice.\n\nMust reads are Representational State Transfer (REST) and REST APIs must be hypertext-driven\n\nSee Martin Fowlers article the Richardson Maturity Model (RMM) for an explanation on what an RESTful service is.\n\nTo be RESTful a Service needs to fulfill the Hypermedia as the Engine of Application State. (HATEOAS), that is, it needs to reach level 3 in the RMM, read the article for details or the slides from the qcon talk.\n\nThe HATEOAS constraint is an acronym for Hypermedia as the Engine of Application State. This principle is the key differentiator between a REST and most other forms of client server system.\n\n...\n\nA client of a RESTful application need only know a single fixed URL to access it. All future actions should be discoverable dynamically from hypermedia links included in the representations of the resources that are returned from that URL. Standardized media types are also expected to be understood by any client that might use a RESTful API. (From Wikipedia, the free encyclopedia)\n\nREST Litmus Test for Web Frameworks is a similar maturity test for web frameworks.\n\nApproaching pure REST: Learning to love HATEOAS is a good collection of links.\n\nREST versus SOAP for the Public Cloud discusses the current levels of REST usage.\n\nREST and versioning discusses Extensibility, Versioning, Evolvability, etc. through Modifiability\n\nShare\nImprove this answer\nFollow\nedited Sep 8 '13 at 17:43\ncommunity wiki\n\n\n14 revs, 4 users 94%\noluies","comments":["I think this answer touches the key point of understanding REST: what does the word representational mean. Level 1 - Resources says about state. Level 2 - HTTP Verbs says about transfer (read change). Level 3 - HATEOAS says driving future transfers via representation (JSON/XML/HTML returned), which means you've got known how to say the next round of talk with the information returned. So REST reads: \"(representational (state transfer))\", instead of \"((representational state) transfer)\".","Difference between REST and POX"]},{"answer":"What is REST?\n\nREST stands for Representational State Transfer. (It is sometimes spelled \"ReST\".) It relies on a stateless, client-server, cacheable communications protocol -- and in virtually all cases, the HTTP protocol is used.\n\nREST is an architecture style for designing networked applications. The idea is that, rather than using complex mechanisms such as CORBA, RPC or SOAP to connect between machines, simple HTTP is used to make calls between machines.\n\nIn many ways, the World Wide Web itself, based on HTTP, can be viewed as a REST-based architecture. RESTful applications use HTTP requests to post data (create and/or update), read data (e.g., make queries), and delete data. Thus, REST uses HTTP for all four CRUD (Create/Read/Update/Delete) operations.\n\nREST is a lightweight alternative to mechanisms like RPC (Remote Procedure Calls) and Web Services (SOAP, WSDL, et al.). Later, we will see how much more simple REST is.\n\nDespite being simple, REST is fully-featured; there's basically nothing you can do in Web Services that can't be done with a RESTful architecture. REST is not a \"standard\". There will never be a W3C recommendataion for REST, for example. And while there are REST programming frameworks, working with REST is so simple that you can often \"roll your own\" with standard library features in languages like Perl, Java, or C#.\n\nOne of the best reference I found when I try to find the simple real meaning of rest.\n\nhttp://rest.elkstein.org/\n\nShare\nImprove this answer\nFollow\nedited Oct 28 '13 at 23:07\njball\n23.8k9\n9 gold badges\n65\n65 silver badges\n91\n91 bronze badges\nanswered Nov 18 '12 at 20:46\nRavi\n3,0065\n5 gold badges\n21\n21 silver badges\n34\n34 bronze badges","comments":["This is a really concise answer. Can you also describe why the REST is called stateless?"]},{"answer":"REST is using the various HTTP methods (mainly GET/PUT/DELETE) to manipulate data.\n\nRather than using a specific URL to delete a method (say, /user/123/delete), you would send a DELETE request to the /user/[id] URL, to edit a user, to retrieve info on a user you send a GET request to /user/[id]\n\nFor example, instead a set of URLs which might look like some of the following..\n\nGET /delete_user.x?id=123\nGET /user/delete\nGET /new_user.x\nGET /user/new\nGET /user?id=1\nGET /user/id/1\n\n\nYou use the HTTP \"verbs\" and have..\n\nGET /user/2\nDELETE /user/2\nPUT /user\n\nShare\nImprove this answer\nFollow\nanswered Mar 22 '09 at 15:20\ndbr\n155k65\n65 gold badges\n270\n270 silver badges\n335\n335 bronze badges","comments":["That's \"using HTTP properly\", which is not the same as \"restful\" (although it's related to it)","You could also use /user/del/2 and /user/remove/2 or... GET/DELETE/PUT/POST are just the standardised, \"proper\" way to do such things (and as Julian says, that's not all there is to REST)","Sure, but that's no reason to avoid them.. REST just saves you reinventing the wheel each time. For an API, REST is great (consistency!), but for structuring a random website it doesn't really matter I'd say (it can be more hassle than it's worth)","Vadim, that would be simply RPC. It's also dangerous to use GET for modifying data since (among other reasons) a search engine may spider your deletion links and visit them all.","@aehlke - I think the real question there would be \"Why does an anonymous user have the ability to delete records from your system?\""]},{"answer":"It's programming where the architecture of your system fits the REST style laid out by Roy Fielding in his thesis. Since this is the architectural style that describes the web (more or less), lots of people are interested in it.\n\nBonus answer: No. Unless you're studying software architecture as an academic or designing web services, there's really no reason to have heard the term.\n\nShare\nImprove this answer\nFollow\nedited Mar 22 '09 at 15:56\nanswered Mar 22 '09 at 14:53\nHank Gay\n66k31\n31 gold badges\n150\n150 silver badges\n218\n218 bronze badges","comments":["but not straight-forward .. makes it more complicated that it needs to be.","Also, even though the terms REST and RESTful are used almost exclusively in the realm of web applications right now, technically there's nothing tying REST to HTTP.","Fielding's blog has some good, easier to comprehend articles on REST and common misconceptions: roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven","@HankGay I think the reason it's not more esoteric is that most web service developers see REST as a wonderful simplification over alternatives like SOAP. They don't necessarily stick to getting all the REST technicalities correct - and that probably drives the REST fanatics mad - but in most cases they probably don't need to worry about things like making sure their results are \"hypermedia-enabled\"."]},{"answer":"I would say RESTful programming would be about creating systems (API) that follow the REST architectural style.\n\nI found this fantastic, short, and easy to understand tutorial about REST by Dr. M. Elkstein and quoting the essential part that would answer your question for the most part:\n\nLearn REST: A Tutorial\n\nREST is an architecture style for designing networked applications. The idea is that, rather than using complex mechanisms such as CORBA, RPC or SOAP to connect between machines, simple HTTP is used to make calls between machines.\n\nIn many ways, the World Wide Web itself, based on HTTP, can be viewed as a REST-based architecture.\n\nRESTful applications use HTTP requests to post data (create and/or update), read data (e.g., make queries), and delete data. Thus, REST uses HTTP for all four CRUD (Create/Read/Update/Delete) operations.\n\nI don't think you should feel stupid for not hearing about REST outside Stack Overflow..., I would be in the same situation!; answers to this other SO question on Why is REST getting big now could ease some feelings.\n\nShare\nImprove this answer\nFollow\nedited Feb 14 '19 at 16:55\nnsandersen\n7362\n2 gold badges\n13\n13 silver badges\n32\n32 bronze badges\nanswered Jul 12 '13 at 16:33\nOnly You\n2,0111\n1 gold badge\n20\n20 silver badges\n33\n33 bronze badges","comments":["This article explains the relationship between HTTP and REST freecodecamp.org/news/…"]},{"answer":"I apologize if I'm not answering the question directly, but it's easier to understand all this with more detailed examples. Fielding is not easy to understand due to all the abstraction and terminology.\n\nThere's a fairly good example here:\n\nExplaining REST and Hypertext: Spam-E the Spam Cleaning Robot\n\nAnd even better, there's a clean explanation with simple examples here (the powerpoint is more comprehensive, but you can get most of it in the html version):\n\nhttp://www.xfront.com/REST.ppt or http://www.xfront.com/REST.html\n\nAfter reading the examples, I could see why Ken is saying that REST is hypertext-driven. I'm not actually sure that he's right though, because that /user/123 is a URI that points to a resource, and it's not clear to me that it's unRESTful just because the client knows about it \"out-of-band.\"\n\nThat xfront document explains the difference between REST and SOAP, and this is really helpful too. When Fielding says, \"That is RPC. It screams RPC.\", it's clear that RPC is not RESTful, so it's useful to see the exact reasons for this. (SOAP is a type of RPC.)\n\nShare\nImprove this answer\nFollow\nedited Sep 6 '17 at 20:26\nwomp\n112k24\n24 gold badges\n229\n229 silver badges\n262\n262 bronze badges\nanswered Mar 23 '09 at 17:11\ntompark\n6284\n4 silver badges\n7\n7 bronze badges","comments":["cool links, thanks. I'm tired of these REST guys that say some example is not \"REST-ful\", but then refuse to say how to change the example to be REST-ful."]},{"answer":"What is REST?\n\nREST in official words, REST is an architectural style built on certain principles using the current “Web” fundamentals. There are 5 basic fundamentals of web which are leveraged to create REST services.\n\nPrinciple 1: Everything is a Resource In the REST architectural style, data and functionality are considered resources and are accessed using Uniform Resource Identifiers (URIs), typically links on the Web.\nPrinciple 2: Every Resource is Identified by a Unique Identifier (URI)\nPrinciple 3: Use Simple and Uniform Interfaces\nPrinciple 4: Communication is Done by Representation\nPrinciple 5: Be Stateless\nShare\nImprove this answer\nFollow\nedited Jul 31 '14 at 17:11\nAliaksandr Belik\n11.9k6\n6 gold badges\n58\n58 silver badges\n86\n86 bronze badges\nanswered Jul 25 '13 at 9:05\nSuresh Gupta\n5556\n6 silver badges\n4\n4 bronze badges","comments":["What does Communication is Done by Representation mean?"]},{"answer":"I see a bunch of answers that say putting everything about user 123 at resource \"/user/123\" is RESTful.\n\nRoy Fielding, who coined the term, says REST APIs must be hypertext-driven. In particular, \"A REST API must not define fixed resource names or hierarchies\".\n\nSo if your \"/user/123\" path is hardcoded on the client, it's not really RESTful. A good use of HTTP, maybe, maybe not. But not RESTful. It has to come from hypertext.\n\nShare\nImprove this answer\nFollow\nanswered Mar 22 '09 at 16:36\nKen\n5013\n3 silver badges\n4\n4 bronze badges","comments":["so .... how would that example be restful? how would you change the url to make it restful?","hasen: Using one resource for all operations might be necessary for RESTfulness, but isn't sufficient.","ok well .. could you explain further? What's the point of saying \"no these guys are wrong .. I know what's right\" without saying what you know (or think) to be right?","I gave the link to Fielding's description. I thought I said exactly the relevant diff to the other responses: needs to be driven by hypertext. If \"/user/123\" comes from some out-of-band API documentation, then it's not RESTful. If it comes from a resource identifier in your hypertext, then it is.","@Andy: A client stops being RESTful when you put a hardcoded URL in it. In particular, the RESTful service may decide to renumber users on a whim which breaks that non-RESTful client. The service stops being RESTful when there's no way to discover /user/123/ from a documented entry point, which indeed means all clients have to hardcode that URL."]},{"answer":"The answer is very simple, there is a dissertation written by Roy Fielding.]1 In that dissertation he defines the REST principles. If an application fulfills all of those principles, then that is a REST application.\n\nThe term RESTful was created because ppl exhausted the word REST by calling their non-REST application as REST. After that the term RESTful was exhausted as well. Nowadays we are talking about Web APIs and Hypermedia APIs, because the most of the so called REST applications did not fulfill the HATEOAS part of the uniform interface constraint.\n\nThe REST constraints are the following:\n\nclient-server architecture\n\nSo it does not work with for example PUB/SUB sockets, it is based on REQ/REP.\n\nstateless communication\n\nSo the server does not maintain the states of the clients. This means that you cannot use server a side session storage and you have to authenticate every request. Your clients possibly send basic auth headers through an encrypted connection. (By large applications it is hard to maintain many sessions.)\n\nusage of cache if you can\n\nSo you don't have to serve the same requests again and again.\n\nuniform interface as common contract between client and server\n\nThe contract between the client and the server is not maintained by the server. In other words the client must be decoupled from the implementation of the service. You can reach this state by using standard solutions, like the IRI (URI) standard to identify resources, the HTTP standard to exchange messages, standard MIME types to describe the body serialization format, metadata (possibly RDF vocabs, microformats, etc.) to describe the semantics of different parts of the message body. To decouple the IRI structure from the client, you have to send hyperlinks to the clients in hypermedia formats like (HTML, JSON-LD, HAL, etc.). So a client can use the metadata (possibly link relations, RDF vocabs) assigned to the hyperlinks to navigate the state machine of the application through the proper state transitions in order to achieve its current goal.\n\nFor example when a client wants to send an order to a webshop, then it have to check the hyperlinks in the responses sent by the webshop. By checking the links it founds one described with the http://schema.org/OrderAction. The client know the schema.org vocab, so it understands that by activating this hyperlink it will send the order. So it activates the hyperlink and sends a POST https://example.com/api/v1/order message with the proper body. After that the service processes the message and responds with the result having the proper HTTP status header, for example 201 - created by success. To annotate messages with detailed metadata the standard solution to use an RDF format, for example JSON-LD with a REST vocab, for example Hydra and domain specific vocabs like schema.org or any other linked data vocab and maybe a custom application specific vocab if needed. Now this is not easy, that's why most ppl use HAL and other simple formats which usually provide only a REST vocab, but no linked data support.\n\nbuild a layered system to increase scalability\n\nThe REST system is composed of hierarchical layers. Each layer contains components which use the services of components which are in the next layer below. So you can add new layers and components effortless.\n\nFor example there is a client layer which contains the clients and below that there is a service layer which contains a single service. Now you can add a client side cache between them. After that you can add another service instance and a load balancer, and so on... The client code and the service code won't change.\n\ncode on demand to extend client functionality\n\nThis constraint is optional. For example you can send a parser for a specific media type to the client, and so on... In order to do this you might need a standard plugin loader system in the client, or your client will be coupled to the plugin loader solution.\n\nREST constraints result a highly scalable system in where the clients are decoupled from the implementations of the services. So the clients can be reusable, general just like the browsers on the web. The clients and the services share the same standards and vocabs, so they can understand each other despite the fact that the client does not know the implementation details of the service. This makes possible to create automated clients which can find and utilize REST services to achieve their goals. In long term these clients can communicate to each other and trust each other with tasks, just like humans do. If we add learning patterns to such clients, then the result will be one or more AI using the web of machines instead of a single server park. So at the end the dream of Berners Lee: the semantic web and the artificial intelligence will be reality. So in 2030 we end up terminated by the Skynet. Until then ... ;-)\n\nShare\nImprove this answer\nFollow\nedited Sep 19 '14 at 1:30\nanswered Nov 22 '13 at 22:49\ninf3rno\n21.1k9\n9 gold badges\n98\n98 silver badges\n173\n173 bronze badges","comments":[]},{"answer":"RESTful (Representational state transfer) API programming is writing web applications in any programming language by following 5 basic software architectural style principles:\n\nResource (data, information).\nUnique global identifier (all resources are unique identified by URI).\nUniform interface - use simple and standard interface (HTTP).\nRepresentation - all communication is done by representation (e.g. XML/JSON)\nStateless (every request happens in complete isolation, it's easier to cache and load-balance),\n\nIn other words you're writing simple point-to-point network applications over HTTP which uses verbs such as GET, POST, PUT or DELETE by implementing RESTful architecture which proposes standardization of the interface each “resource” exposes. It is nothing that using current features of the web in a simple and effective way (highly successful, proven and distributed architecture). It is an alternative to more complex mechanisms like SOAP, CORBA and RPC.\n\nRESTful programming conforms to Web architecture design and, if properly implemented, it allows you to take the full advantage of scalable Web infrastructure.\n\nShare\nImprove this answer\nFollow\nedited Jun 15 '14 at 19:08\nanswered Jun 15 '14 at 19:02\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges","comments":[]},{"answer":"Here is my basic outline of REST. I tried to demonstrate the thinking behind each of the components in a RESTful architecture so that understanding the concept is more intuitive. Hopefully this helps demystify REST for some people!\n\nREST (Representational State Transfer) is a design architecture that outlines how networked resources (i.e. nodes that share information) are designed and addressed. In general, a RESTful architecture makes it so that the client (the requesting machine) and the server (the responding machine) can request to read, write, and update data without the client having to know how the server operates and the server can pass it back without needing to know anything about the client. Okay, cool...but how do we do this in practice?\n\nThe most obvious requirement is that there needs to be a universal language of some sort so that the server can tell the client what it is trying to do with the request and for the server to respond.\n\nBut to find any given resource and then tell the client where that resource lives, there needs to be a universal way of pointing at resources. This is where Universal Resource Identifiers (URIs) come in; they are basically unique addresses to find the resources.\n\nBut the REST architecture doesn’t end there! While the above fulfills the basic needs of what we want, we also want to have an architecture that supports high volume traffic since any given server usually handles responses from a number of clients. Thus, we don’t want to overwhelm the server by having it remember information about previous requests.\n\nTherefore, we impose the restriction that each request-response pair between the client and the server is independent, meaning that the server doesn’t have to remember anything about previous requests (previous states of the client-server interaction) to respond to a new request. This means that we want our interactions to be stateless.\n\nTo further ease the strain on our server from redoing computations that have already been recently done for a given client, REST also allows caching. Basically, caching means to take a snapshot of the initial response provided to the client. If the client makes the same request again, the server can provide the client with the snapshot rather than redo all of the computations that were necessary to create the initial response. However, since it is a snapshot, if the snapshot has not expired--the server sets an expiration time in advance--and the response has been updated since the initial cache (i.e. the request would give a different answer than the cached response), the client will not see the updates until the cache expires (or the cache is cleared) and the response is rendered from scratch again.\n\nThe last thing that you’ll often here about RESTful architectures is that they are layered. We have actually already been implicitly discussing this requirement in our discussion of the interaction between the client and server. Basically, this means that each layer in our system interacts only with adjacent layers. So in our discussion, the client layer interacts with our server layer (and vice versa), but there might be other server layers that help the primary server process a request that the client does not directly communicate with. Rather, the server passes on the request as necessary.\n\nNow, if all of this sounds familiar, then great. The Hypertext Transfer Protocol (HTTP), which defines the communication protocol via the World Wide Web is an implementation of the abstract notion of RESTful architecture (or an implementation of the abstract REST class if you're an OOP fanatic like me). In this implementation of REST, the client and server interact via GET, POST, PUT, DELETE, etc., which are part of the universal language and the resources can be pointed to using URLs.\n\nShare\nImprove this answer\nFollow\nedited Nov 17 '20 at 21:56\nanswered Mar 31 '17 at 3:12\nKal\n96014\n14 silver badges\n19\n19 bronze badges","comments":["Great explanation."]},{"answer":"If I had to reduce the original dissertation on REST to just 3 short sentences, I think the following captures its essence:\n\nResources are requested via URLs.\nProtocols are limited to what you can communicate by using URLs.\nMetadata is passed as name-value pairs (post data and query string parameters).\n\nAfter that, it's easy to fall into debates about adaptations, coding conventions, and best practices.\n\nInterestingly, there is no mention of HTTP POST, GET, DELETE, or PUT operations in the dissertation. That must be someone's later interpretation of a \"best practice\" for a \"uniform interface\".\n\nWhen it comes to web services, it seems that we need some way of distinguishing WSDL and SOAP based architectures which add considerable overhead and arguably much unnecessary complexity to the interface. They also require additional frameworks and developer tools in order to implement. I'm not sure if REST is the best term to distinguish between common-sense interfaces and overly engineered interfaces such as WSDL and SOAP. But we need something.\n\nShare\nImprove this answer\nFollow\nanswered Feb 1 '12 at 17:23\nNathan Andelin\n1891\n1 silver badge\n2\n2 bronze badges","comments":[]},{"answer":"REST is an architectural pattern and style of writing distributed applications. It is not a programming style in the narrow sense.\n\nSaying you use the REST style is similar to saying that you built a house in a particular style: for example Tudor or Victorian. Both REST as an software style and Tudor or Victorian as a home style can be defined by the qualities and constraints that make them up. For example REST must have Client Server separation where messages are self-describing. Tudor style homes have Overlapping gables and Roofs that are steeply pitched with front facing gables. You can read Roy's dissertation to learn more about the constraints and qualities that make up REST.\n\nREST unlike home styles has had a tough time being consistently and practically applied. This may have been intentional. Leaving its actual implementation up to the designer. So you are free to do what you want so as long as you meet the constraints set out in the dissertation you are creating REST Systems.\n\nBonus:\n\nThe entire web is based on REST (or REST was based on the web). Therefore as a web developer you might want aware of that although it's not necessary to write good web apps.\n\nShare\nImprove this answer\nFollow\nanswered Feb 1 '12 at 21:20\nsuing\n2,5421\n1 gold badge\n14\n14 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"I think the point of restful is the separation of the statefulness into a higher layer while making use of the internet (protocol) as a stateless transport layer. Most other approaches mix things up.\n\nIt's been the best practical approach to handle the fundamental changes of programming in internet era. Regarding the fundamental changes, Erik Meijer has a discussion on show here: http://www.infoq.com/interviews/erik-meijer-programming-language-design-effects-purity#view_93197 . He summarizes it as the five effects, and presents a solution by designing the solution into a programming language. The solution, could also be achieved in the platform or system level, regardless of the language. The restful could be seen as one of the solutions that has been very successful in the current practice.\n\nWith restful style, you get and manipulate the state of the application across an unreliable internet. If it fails the current operation to get the correct and current state, it needs the zero-validation principal to help the application to continue. If it fails to manipulate the state, it usually uses multiple stages of confirmation to keep things correct. In this sense, rest is not itself a whole solution, it needs the functions in other part of the web application stack to support its working.\n\nGiven this view point, the rest style is not really tied to internet or web application. It's a fundamental solution to many of the programming situations. It is not simple either, it just makes the interface really simple, and copes with other technologies amazingly well.\n\nJust my 2c.\n\nEdit: Two more important aspects:\n\nStatelessness is misleading. It is about the restful API, not the application or system. The system needs to be stateful. Restful design is about designing a stateful system based on a stateless API. Some quotes from another QA:\n\nREST, operates on resource representations, each one identified by an URL. These are typically not data objects, but complex objects abstractions.\nREST stands for \"representational state transfer\", which means it's all about communicating and modifying the state of some resource in a system.\n\nIdempotence: An often-overlooked part of REST is the idempotency of most verbs. That leads to robust systems and less interdependency of exact interpretations of the semantics.\n\nShare\nImprove this answer\nFollow\nedited Apr 30 '18 at 16:18\nanswered Jul 3 '14 at 17:30\nminghua\n4,6244\n4 gold badges\n32\n32 silver badges\n64\n64 bronze badges","comments":["A MVC viewpoint: The blog Rest Worst Practices suggested not to conflating models and resources. The book Two Scoops of django suggests that the Rest API is the view, and not to mix business logic into the view. The code for the app should remain in the app.","Another good article: WikiPedia about Resource-Oriented Architecture"]},{"answer":"Old question, newish way of answering. There's a lot of misconception out there about this concept. I always try to remember:\n\nStructured URLs and Http Methods/Verbs are not the definition of restful programming.\nJSON is not restful programming\nRESTful programming is not for APIs\n\nI define restful programming as\n\nAn application is restful if it provides resources (being the combination of data + state transitions controls) in a media type the client understands\n\nTo be a restful programmer you must be trying to build applications that allow actors to do things. Not just exposing the database.\n\nState transition controls only make sense if the client and server agree upon a media type representation of the resource. Otherwise there's no way to know what's a control and what isn't and how to execute a control. IE if browsers didn't know <form> tags in html then there'd be nothing for you to submit to transition state in your browser.\n\nI'm not looking to self promote, but i expand on these ideas to great depth in my talk http://techblog.bodybuilding.com/2016/01/video-what-is-restful-200.html .\n\nAn excerpt from my talk is about the often referred to richardson maturity model, i don't believe in the levels, you either are RESTful (level 3) or you are not, but what i like to call out about it is what each level does for you on your way to RESTful\n\nShare\nImprove this answer\nFollow\nedited Feb 28 '19 at 9:03\nanswered Nov 30 '16 at 20:05\nChris DaMour\n3,06122\n22 silver badges\n31\n31 bronze badges","comments":[]},{"answer":"This is amazingly long \"discussion\" and yet quite confusing to say the least.\n\nIMO:\n\n1) There is no such a thing as restful programing, without a big joint and lots of beer :)\n\n2) Representational State Transfer (REST) is an architectural style specified in the dissertation of Roy Fielding. It has a number of constraints. If your Service/Client respect those then it is RESTful. This is it.\n\nYou can summarize(significantly) the constraints to :\n\nstateless communication\nrespect HTTP specs (if HTTP is used)\nclearly communicates the content formats transmitted\nuse hypermedia as the engine of application state\n\nThere is another very good post which explains things nicely.\n\nA lot of answers copy/pasted valid information mixing it and adding some confusion. People talk here about levels, about RESTFul URIs(there is not such a thing!), apply HTTP methods GET,POST,PUT ... REST is not about that or not only about that.\n\nFor example links - it is nice to have a beautifully looking API but at the end the client/server does not really care of the links you get/send it is the content that matters.\n\nIn the end any RESTful client should be able to consume to any RESTful service as long as the content format is known.\n\nShare\nImprove this answer\nFollow\nedited Jan 24 '17 at 10:54\nanswered Jan 13 '17 at 14:02\nkalin\n3,4282\n2 gold badges\n23\n23 silver badges\n31\n31 bronze badges","comments":[]},{"answer":"REST defines 6 architectural constraints which make any web service – a true RESTful API.\n\nUniform interface\nClient–server\nStateless\nCacheable\nLayered system\nCode on demand (optional)\n\nhttps://restfulapi.net/rest-architectural-constraints/\n\nShare\nImprove this answer\nFollow\nanswered Oct 2 '17 at 21:23\nJaider\n12.6k5\n5 gold badges\n61\n61 silver badges\n77\n77 bronze badges","comments":["Fielding added some further rules RESTful APIs/clients have to adhere"]},{"answer":"REST === HTTP analogy is not correct until you do not stress to the fact that it \"MUST\" be HATEOAS driven.\n\nRoy himself cleared it here.\n\nA REST API should be entered with no prior knowledge beyond the initial URI (bookmark) and set of standardized media types that are appropriate for the intended audience (i.e., expected to be understood by any client that might use the API). From that point on, all application state transitions must be driven by client selection of server-provided choices that are present in the received representations or implied by the user’s manipulation of those representations. The transitions may be determined (or limited by) the client’s knowledge of media types and resource communication mechanisms, both of which may be improved on-the-fly (e.g., code-on-demand).\n\n[Failure here implies that out-of-band information is driving interaction instead of hypertext.]\n\nShare\nImprove this answer\nFollow\nedited Aug 23 '17 at 10:00\nPriyantha\n3,8174\n4 gold badges\n22\n22 silver badges\n40\n40 bronze badges\nanswered Jun 3 '16 at 11:35\nlokesh\n4534\n4 silver badges\n8\n8 bronze badges","comments":["doesn't answer the question as wel as the others, but +1 for information that is relevant!","I think this answers the question too, but for example statelessness is missing from it. Every constraint is important... The standard media type part is not always true. I mean there are layers of understanding. For example if you use RDF, then the media type can be understood, but the meaning of the content not. So the client needs to know the vocabulary as well. Some people are experimenting with this kind of REST APIs and a general REST vocab to describe hyperlinks, etc. hydra-cg.com"]},{"answer":"REST is an architectural style which is based on web-standards and the HTTP protocol (introduced in 2000).\n\nIn a REST based architecture, everything is a resource(Users, Orders, Comments). A resource is accessed via a common interface based on the HTTP standard methods(GET, PUT, PATCH, DELETE etc).\n\nIn a REST based architecture you have a REST server which provides access to the resources. A REST client can access and modify the REST resources.\n\nEvery resource should support the HTTP common operations. Resources are identified by global IDs (which are typically URIs).\n\nREST allows that resources have different representations, e.g., text, XML, JSON etc. The REST client can ask for a specific representation via the HTTP protocol (content negotiation).\n\nHTTP methods:\n\nThe PUT, GET, POST and DELETE methods are typical used in REST based architectures. The following table gives an explanation of these operations.\n\nGET defines a reading access of the resource without side-effects. The resource is never changed via a GET request, e.g., the request has no side effects (idempotent).\nPUT creates a new resource. It must also be idempotent.\nDELETE removes the resources. The operations are idempotent. They can get repeated without leading to different results.\nPOST updates an existing resource or creates a new resource.\nShare\nImprove this answer\nFollow\nedited May 26 '18 at 18:08\nanswered Sep 15 '17 at 19:47\nImran Ahmad\n5,9243\n3 gold badges\n34\n34 silver badges\n44\n44 bronze badges","comments":["Several quotes, but not a single source mentioned. Where did you get this?"]},{"answer":"REST stands for Representational state transfer.\n\nIt relies on a stateless, client-server, cacheable communications protocol -- and in virtually all cases, the HTTP protocol is used.\n\nREST is often used in mobile applications, social networking Web sites, mashup tools and automated business processes. The REST style emphasizes that interactions between clients and services is enhanced by having a limited number of operations (verbs). Flexibility is provided by assigning resources (nouns) their own unique universal resource indicators (URIs).\n\nIntroduction about Rest\n\nShare\nImprove this answer\nFollow\nanswered Nov 10 '14 at 13:37\nGowriShankar\n1,57216\n16 silver badges\n29\n29 bronze badges","comments":[]},{"answer":"Talking is more than simply exchanging information. A Protocol is actually designed so that no talking has to occur. Each party knows what their particular job is because it is specified in the protocol. Protocols allow for pure information exchange at the expense of having any changes in the possible actions. Talking, on the other hand, allows for one party to ask what further actions can be taken from the other party. They can even ask the same question twice and get two different answers, since the State of the other party may have changed in the interim. Talking is RESTful architecture. Fielding's thesis specifies the architecture that one would have to follow if one wanted to allow machines to talk to one another rather than simply communicate.\n\nShare\nImprove this answer\nFollow\nanswered Dec 6 '14 at 6:54\nqmckinsey\n1851\n1 gold badge\n2\n2 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"There is not such notion as \"RESTful programming\" per se. It would be better called RESTful paradigm or even better RESTful architecture. It is not a programming language. It is a paradigm.\n\nFrom Wikipedia:\n\nIn computing, representational state transfer (REST) is an architectural style used for web development.\n\nShare\nImprove this answer\nFollow\nedited Aug 26 '16 at 20:35\nanswered Aug 24 '16 at 17:57\nACV\n8,2154\n4 gold badges\n57\n57 silver badges\n73\n73 bronze badges","comments":[]},{"answer":"The point of rest is that if we agree to use a common language for basic operations (the http verbs), the infrastructure can be configured to understand them and optimize them properly, for example, by making use of caching headers to implement caching at all levels.\n\nWith a properly implemented restful GET operation, it shouldn't matter if the information comes from your server's DB, your server's memcache, a CDN, a proxy's cache, your browser's cache or your browser's local storage. The fasted, most readily available up to date source can be used.\n\nSaying that Rest is just a syntactic change from using GET requests with an action parameter to using the available http verbs makes it look like it has no benefits and is purely cosmetic. The point is to use a language that can be understood and optimized by every part of the chain. If your GET operation has an action with side effects, you have to skip all HTTP caching or you'll end up with inconsistent results.\n\nShare\nImprove this answer\nFollow\nanswered Feb 1 '12 at 23:52\nBenoit Essiambre\n1681\n1 silver badge\n7\n7 bronze badges","comments":["\"Saying that Rest is just a syntactic change... makes it look like it has no benefits and is purely cosmetic\" --- that's exactly why I am reading answers here on SO. Note that you did not explain, why REST is not purely cosmetic."]},{"answer":"This answer is for absolute beginners, let's know about most used API architecture today.\n\nTo understand Restful programming or Restful API. First, you have to understand what API is, on a very high-level API stands for Application Programming Interface, it's basically a piece of software that can be used by another piece of software in order to allow applications to talk to each other.\n\nThe most widely used type of API in the globe is web APIs while an app that sends data to a client whenever a request comes in.\n\nIn fact, APIs aren't only used to send data and aren't always related to web development or javascript or python or any programming language or framework.\n\nThe application in API can actually mean many different things as long as the pice of software is relatively stand-alone. Take for example, the File System or the HTTP Modules we can say that they are small pieces of software and we can use them, we can interact with them by using their API. For example when we use the read file function for a file system module of any programming language, we are actually using the file_system_reading API. Or when we do DOM manipulation in the browser, we're are not really using the JavaScript language itself, but rather, the DOM API that browser exposes to us, so it gives us access to it. Or even another example let's say we create a class in any programming language like Java and then add some public methods or properties to it, these methods will then be the API of each object created from that class because we are giving other pieces of software the possibility of interacting with our initial piece of software, the objects in this case. S0, API has actually a broader meaning than just building web APIs.\n\nNow let's take a look at the REST Architecture to build APIs.\n\nREST which stands for Representational State Transfer is basically a way of building web APIs in a logical way, making them easy to consume for ourselves or for others.\n\nTo build Restful APIs following the REST Architecture, we just need to follow a couple of principles. 1. We need to separate our API into logical resources. 2. These resources should then be exposed by using resource-based URLs. 3. To perform different actions on data like reading, creating, or deleting data the API should use the right HTTP methods and not the URL. 4. Now the data that we actually send back to the client or that we received from the client should usually use the JSON data format, were some formatting standard applied to it. 5. Finally, another important principle of EST APIs is that they must be stateless.\n\nSeparate APIs into logical resources: The key abstraction of information in REST is a resource, and therefore all the data that we wanna share in the API should be divided into logical resources. What actually is a resource? Well, in the context of REST it is an object or a representation of something which has some data associated to it. For example, applications like tour-guide tours, or users, places, or revies are of the example of logical resources. So basically any information that can be named can be a resource. Just has to name, though, not a verb. \n\nExpose Structure: Now we need to expose, which means to make available, the data using some structured URLs, that the client can send a request to. For example something like this entire address is called the URL. and this / addNewTour is called and API Endpoint. \n\nOur API will have many different endpoints just like bellow\n\nhttps://www.tourguide.com/addNewTour\nhttps://www.tourguide.com/getTour\nhttps://www.tourguide.com/updateTour\nhttps://www.tourguide.com/deleteTour\nhttps://www.tourguide.com/getRoursByUser\nhttps://www.tourguide.com/deleteToursByUser\n\n\nEach of these API will send different data back to the client on also perform different actions. Now there is something very wrong with these endpoints here because they really don't follow the third rule which says that we should only use the HTTP methods in order to perform actions on data. So endpoints should only contain our resources and not the actions that we are performed on them because they will quickly become a nightmare to maintain.\n\nHow should we use these HTTP methods in practice? Well let's see how these endpoints should actually look like starting with /getTour. So this getTour endpoint is to get data about a tour and so we should simply name the endpoint /tours and send the data whenever a get request is made to this endpoint. So in other words, when a client uses a GET HTTP method to access the endpoint, \n\n(we only have resources in the endpoint or in the URL and no verbs because the verb is now in the HTTP method, right? The common practice to always use the resource name in the plural which is why I wrote /tours nor /tour.) The convention is that when calling endpoint /tours will get back all the tours that are in a database, but if we only want the tour with one ID, let's say seven, we add that seven after another slash(/tours/7) or in a search query (/tours?id=7), And of course, it could also be the name of a tour instead of the ID.\n\nHTTP Methods: What's really important here is how the endpoint name is the exact same name for all.\n\nGET: (for requesting data from the server.)\n\nhttps://www.tourguide.com/tours/7\nPOST: (for sending data to the server.)\nhttps://www.tourguide.com/tours\nPUT/PATCH: (for updating requests for data to the server.) https://www.tourguide.com/tours/7\nDELETE: (for deleting request for data to the server.)\nhttps://www.tourguide.com/tours/7\n\n\nThe difference between PUT and PATCH-> By using PUT, the client is supposed to send the entire updated object, while with PATCH it is supposed to send only the part of the object that has been changed.\n\nBy using HTTP methods users can perform basic four CRUD operations, CRUD stands for Create, Read, Update, and Delete.\n\nNow there could be a situation like a bellow:\n\nSo, /getToursByUser can simply be translated to /users/tours, for user number 3 end point will be like /users/3/tours.\n\nif we want to delete a particular tour of a particular user then the URL should be like /users/3/tours/7, here user id:3 and tour id: 7.\n\nSo there really are tons of possibilities of combining resources like this.\n\nSend data as JSON: Now about data that the client actually receives, or that the server receives from the client, usually we use the JSON Data Format. A typical JSON might look like below:  Before sending JSON Data we usually do some simple response formatting, there are a couple of standards for this, but one of the very simple ones called Jsend. We simply create a new object, then add a status message to it in order to inform the client whether the request was a success, fail, or error. And then we put our original data into a new object called Data.\n\nWrapping the data into an additional object like we did here is called Enveloping, and it's a common practice to mitigate some security issues and other problems.\n\nRestful API should always be stateless: Finally a RESTful API should always be stateless meaning that, in a stateless RESTful API all state is handled on the client side no on the server. And state simply refers to a piece of data in the application that might change over time. For example, whether a certain user is logged in or on a page with a list with several pages what the current page is? Now the fact that the state should be handled on the client means that each request must contain all the information that is necessary to process a certain request on the server. So the server should never ever have to remember the previous request in order to process the current request.\n\nLet's say that currently we are on page five and we want to move forward to page six. Sow we could have a simple endpoint called /tours/nextPage and submit a request to server, but the server would then have to figure out what the current page is, and based on that server will send the next page to the client. In other words, the server would have to remember the previous request. This is what exactly we want to avoid in RESTful APIs.\n\nInstead of this case, we should create a /tours/page endpoint and paste the number six to it in order to request page number six /tours/page/6 . So the server doesn't have to remember anything in, all it has to do is to send back data for page number six as we requested.\n\nStatelessness and Statefulness which is the opposite are very important concepts in computer science and applications in general\n\nShare\nImprove this answer\nFollow\nanswered May 21 '20 at 11:09\nLord\n3,5372\n2 gold badges\n15\n15 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"This is very less mentioned everywhere but the Richardson's Maturity Model is one of the best methods to actually judge how Restful is one's API. More about it here:\n\nRichardson's Maturity Model\n\nShare\nImprove this answer\nFollow\nanswered Aug 29 '17 at 11:55\nKrishna Ganeriwal\n1,61515\n15 silver badges\n15\n15 bronze badges","comments":["If you look at the constraints Fielding put on REST you will clearly see that an API needs to have reached Layer 3 of the RMM in order to be viewed as RESTful, though this is simply not enough actually as there are still enough possibilities to fail the REST idea - the decoupling of clients from server APIs. Sure, Layer 3 fulfills the HATEOAS constraint but it is still easy to break the requirements and to couple clients tightly to a server (i.e. by using typed resources)"]},{"answer":"What is API Testing?\n\nAPI testing utilizes programming to send calls to the API and get the yield. It testing regards the segment under test as a black box. The objective of API testing is to confirm right execution and blunder treatment of the part preceding its coordination into an application.\n\nREST API\n\nREST: Representational State Transfer.\n\nIt’s an arrangement of functions on which the testers performs requests and receive responses. In REST API interactions are made via HTTP protocol.\nREST also permits communication between computers with each other over a network.\nFor sending and receiving messages, it involves using HTTP methods, and it does not require a strict message definition, unlike Web services.\nREST messages often accepts the form either in form of XML, or JavaScript Object Notation (JSON).\n\n4 Commonly Used API Methods:-\n\nGET: – It provides read only access to a resource.\nPOST: – It is used to create or update a new resource.\nPUT: – It is used to update or replace an existing resource or create a new resource.\nDELETE: – It is used to remove a resource.\n\nSteps to Test API Manually:-\n\nTo use API manually, we can use browser based REST API plugins.\n\nInstall POSTMAN(Chrome) / REST(Firefox) plugin\nEnter the API URL\nSelect the REST method\nSelect content-Header\nEnter Request JSON (POST)\nClick on send\nIt will return output response\n\nSteps to Automate REST API\n\nShare\nImprove this answer\nFollow\nedited Aug 1 '16 at 12:18\nKrrishnaaaa\n70010\n10 silver badges\n21\n21 bronze badges\nanswered Aug 1 '16 at 6:42\nkkashyap1707\n4591\n1 gold badge\n7\n7 silver badges\n15\n15 bronze badges","comments":["this is not even a proper answer"]}]},{"id":"105372","href":"https://stackoverflow.com/questions/105372/how-to-enumerate-an-enum","title":"How to enumerate an enum","description":"\n                \nHow can you enumerate an enum in C#?\n\nE.g. the following code does not compile:\n\npublic enum Suit\n{\n    Spades,\n    Hearts,\n    Clubs,\n    Diamonds\n}\n\npublic void EnumerateAllSuitsDemoMethod()\n{\n    foreach (Suit suit in Suit)\n    {\n        DoSomething(suit);\n    }\n}\n\n\nAnd it gives the following compile-time error:\n\n\n  'Suit' is a 'type' but is used like a 'variable'\n\n\nIt fails on the Suit keyword, the second one.\n    ","questionComments":["See also ... stackoverflow.com/questions/972307/…","You may want to check out the ins and outs of C# enums, which discusses this as well as other useful enum tidbits"],"answers":[{"answer":"foreach (Suit suit in (Suit[]) Enum.GetValues(typeof(Suit)))\n{\n}\n\n\nNote: The cast to (Suit[]) is not strictly necessary, but it does make the code 0.5 ns faster.\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 22:29\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 19 '08 at 20:37\njop\n78.2k10\n10 gold badges\n52\n52 silver badges\n52\n52 bronze badges","comments":["This doesn't work if you have duplicate values in the enumerator list.","I just want to point out that this, unfortunately won't work in silverlight, since the silverlight library don't comprise enum.GetValues. You have to use reflection in this case.","@Jessy this does work in case of duplicate situations like enum E {A = 0, B = 0}. Enum.GetValues results in two values being returned, though they are the same. E.A == E.B is true, so there is not distinction. If you want individual names, then you should look for Enum.GetNames.","Then if you have duplicates/synonyms in your enum, and you want the other behavior, you can use Linq's Distinct extension (since .NET 3.5), so foreach (var suit in ((Suit[])Enum.GetValues(typeof(Suit))).Distinct()) { }.","I made the mistake of trying to use var for the type. The compiler will make the variable an Object instead of the enum. List the enum type explicitly."]},{"answer":"It looks to me like you really want to print out the names of each enum, rather than the values. In which case Enum.GetNames() seems to be the right approach.\n\npublic enum Suits\n{\n    Spades,\n    Hearts,\n    Clubs,\n    Diamonds,\n    NumSuits\n}\n\npublic void PrintAllSuits()\n{\n    foreach (string name in Enum.GetNames(typeof(Suits)))\n    {\n        System.Console.WriteLine(name);\n    }\n}\n\n\nBy the way, incrementing the value is not a good way to enumerate the values of an enum. You should do this instead.\n\nI would use Enum.GetValues(typeof(Suit)) instead.\n\npublic enum Suits\n{\n    Spades,\n    Hearts,\n    Clubs,\n    Diamonds,\n    NumSuits\n}\n\npublic void PrintAllSuits()\n{\n    foreach (var suit in Enum.GetValues(typeof(Suits)))\n    {\n        System.Console.WriteLine(suit.ToString());\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Feb 10 '14 at 18:04\nmetalmad\n491\n1 silver badge\n8\n8 bronze badges\nanswered Sep 19 '08 at 20:39\nHaacked\n55k14\n14 gold badges\n87\n87 silver badges\n110\n110 bronze badges","comments":["VB Syntax here: link","I took your version with a small following changes from my side: Enum.GetValues(typeof(Suits)).OfType<Suits>().ToArray(). In that case I can iterate array of Suits enum items, not strings.","@Barabas why not just do Suits suit in Enum.GetValues(typeof(Suits)) ?","@themadking oh, man! of course, using exact type looks better than this monstrous piece of sh... code!"]},{"answer":"I made some extensions for easy enum usage. Maybe someone can use it...\n\npublic static class EnumExtensions\n{\n    /// <summary>\n    /// Gets all items for an enum value.\n    /// </summary>\n    /// <typeparam name=\"T\"></typeparam>\n    /// <param name=\"value\">The value.</param>\n    /// <returns></returns>\n    public static IEnumerable<T> GetAllItems<T>(this Enum value)\n    {\n        foreach (object item in Enum.GetValues(typeof(T)))\n        {\n            yield return (T)item;\n        }\n    }\n\n    /// <summary>\n    /// Gets all items for an enum type.\n    /// </summary>\n    /// <typeparam name=\"T\"></typeparam>\n    /// <param name=\"value\">The value.</param>\n    /// <returns></returns>\n    public static IEnumerable<T> GetAllItems<T>() where T : struct\n    {\n        foreach (object item in Enum.GetValues(typeof(T)))\n        {\n            yield return (T)item;\n        }\n    }\n\n    /// <summary>\n    /// Gets all combined items from an enum value.\n    /// </summary>\n    /// <typeparam name=\"T\"></typeparam>\n    /// <param name=\"value\">The value.</param>\n    /// <returns></returns>\n    /// <example>\n    /// Displays ValueA and ValueB.\n    /// <code>\n    /// EnumExample dummy = EnumExample.Combi;\n    /// foreach (var item in dummy.GetAllSelectedItems<EnumExample>())\n    /// {\n    ///    Console.WriteLine(item);\n    /// }\n    /// </code>\n    /// </example>\n    public static IEnumerable<T> GetAllSelectedItems<T>(this Enum value)\n    {\n        int valueAsInt = Convert.ToInt32(value, CultureInfo.InvariantCulture);\n\n        foreach (object item in Enum.GetValues(typeof(T)))\n        {\n            int itemAsInt = Convert.ToInt32(item, CultureInfo.InvariantCulture);\n\n            if (itemAsInt == (valueAsInt & itemAsInt))\n            {\n                yield return (T)item;\n            }\n        }\n    }\n\n    /// <summary>\n    /// Determines whether the enum value contains a specific value.\n    /// </summary>\n    /// <param name=\"value\">The value.</param>\n    /// <param name=\"request\">The request.</param>\n    /// <returns>\n    ///     <c>true</c> if value contains the specified value; otherwise, <c>false</c>.\n    /// </returns>\n    /// <example>\n    /// <code>\n    /// EnumExample dummy = EnumExample.Combi;\n    /// if (dummy.Contains<EnumExample>(EnumExample.ValueA))\n    /// {\n    ///     Console.WriteLine(\"dummy contains EnumExample.ValueA\");\n    /// }\n    /// </code>\n    /// </example>\n    public static bool Contains<T>(this Enum value, T request)\n    {\n        int valueAsInt = Convert.ToInt32(value, CultureInfo.InvariantCulture);\n        int requestAsInt = Convert.ToInt32(request, CultureInfo.InvariantCulture);\n\n        if (requestAsInt == (valueAsInt & requestAsInt))\n        {\n            return true;\n        }\n\n        return false;\n    }\n}\n\n\nThe enum itself must be decorated with the FlagsAttribute:\n\n[Flags]\npublic enum EnumExample\n{\n    ValueA = 1,\n    ValueB = 2,\n    ValueC = 4,\n    ValueD = 8,\n    Combi = ValueA | ValueB\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 22:33\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 3 '09 at 12:03\nbob\n6,2371\n1 gold badge\n28\n28 silver badges\n26\n26 bronze badges","comments":["A one liner for the first extension method; it's no more lazy. return Enum.GetValues(typeof(T)).Cast<T>();","Alternatively you could use OfType too: Enum.GetValues(typeof(T)).OfType<T>(). It's too bad there is not a generic version of GetValues<T>() then it would be even more slick.","Maybe someone could show how to use these extensions? The compiler do not show extension methods on enum EnumExample.","+1 for reusable code: examples - save these extension methods in a library and reference it [Flags]public enum mytypes{name1, name2 }; List<string> myTypeNames = mytypes.GetAllItems();","Starting with C# 7.3 (Visual Studio 2017 ≥ v15.7), one can use where T: Enum"]},{"answer":"Some versions of the .NET framework do not support Enum.GetValues. Here's a good workaround from Ideas 2.0: Enum.GetValues in Compact Framework:\n\npublic Enum[] GetValues(Enum enumeration)\n{\n    FieldInfo[] fields = enumeration.GetType().GetFields(BindingFlags.Static | BindingFlags.Public);\n    Enum[] enumerations = new Enum[fields.Length];\n\n    for (var i = 0; i < fields.Length; i++)\n        enumerations[i] = (Enum) fields[i].GetValue(enumeration);\n\n    return enumerations;\n}\n\n\nAs with any code that involves reflection, you should take steps to ensure it runs only once and results are cached.\n\nShare\nImprove this answer\nFollow\nedited Mar 8 '19 at 4:39\nMikael Dúi Bolinder\n2,0031\n1 gold badge\n14\n14 silver badges\n35\n35 bronze badges\nanswered Sep 3 '09 at 18:48\nEkevoo\n2,5141\n1 gold badge\n21\n21 silver badges\n32\n32 bronze badges","comments":["Why not use the yield keyword here instead instantiating a list?","or shorter: return type.GetFields().Where(x => x.IsLiteral).Select(x => x.GetValue(null)).Cast<Enum>();","@nawfal: Linq isn't available .Net CF 2.0."]},{"answer":"Use Cast<T>:\n\nvar suits = Enum.GetValues(typeof(Suit)).Cast<Suit>();\n\n\nThere you go, IEnumerable<Suit>.\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 22:53\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 17 '13 at 4:15\nsircodesalot\n10.6k5\n5 gold badges\n44\n44 silver badges\n79\n79 bronze badges","comments":["This also works in the from clause and the foreach header declarator.","This seems to be the cleanest approach.","The 'cast' api requires System.Linq. I was just short of cast."]},{"answer":"I think this is more efficient than other suggestions because GetValues() is not called each time you have a loop. It is also more concise. And you get a compile-time error, not a runtime exception if Suit is not an enum.\n\nEnumLoop<Suit>.ForEach((suit) => {\n    DoSomethingWith(suit);\n});\n\n\nEnumLoop has this completely generic definition:\n\nclass EnumLoop<Key> where Key : struct, IConvertible {\n    static readonly Key[] arr = (Key[])Enum.GetValues(typeof(Key));\n    static internal void ForEach(Action<Key> act) {\n        for (int i = 0; i < arr.Length; i++) {\n            act(arr[i]);\n        }\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 22:47\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 2 '12 at 13:36\nJames\n4,6971\n1 gold badge\n30\n30 silver badges\n39\n39 bronze badges","comments":["Careful with using generics like this. If you try to use EnumLoop with some type that is not an enum, it will compile fine, but throw an exception at runtime.","Thank you svick. Runtime exceptions will actually occur with the other answers on this page... except this one because I have added \"where Key : struct, IConvertible\" so that you get a compile time error in most cases.","No, GetValues() is called only once in the foreach.","James, I would discourage your class because clever is nice to write but in production code that many people will maintain and update, clever is extra work. If it makes a major saving or will be used a lot - so the savings is big and people will become familiar with it - it is worth it, but in most cases it slows down people trying to read and update the code and introduces a possible source bugs in the future. Less code is better :) less complexity is even better.","@GrantM Why? This code is neither complex, and it's incredibly short. On top of that, writing the class once will allow even shorter iterations of code with using is as per his example. This is extremely clean, if you can't update that code, you probably can't update any of the companies code."]},{"answer":"You won't get Enum.GetValues() in Silverlight.\n\nOriginal Blog Post by Einar Ingebrigtsen:\n\npublic class EnumHelper\n{\n    public static T[] GetValues<T>()\n    {\n        Type enumType = typeof(T);\n\n        if (!enumType.IsEnum)\n        {\n            throw new ArgumentException(\"Type '\" + enumType.Name + \"' is not an enum\");\n        }\n\n        List<T> values = new List<T>();\n\n        var fields = from field in enumType.GetFields()\n                     where field.IsLiteral\n                     select field;\n\n        foreach (FieldInfo field in fields)\n        {\n            object value = field.GetValue(enumType);\n            values.Add((T)value);\n        }\n\n        return values.ToArray();\n    }\n\n    public static object[] GetValues(Type enumType)\n    {\n        if (!enumType.IsEnum)\n        {\n            throw new ArgumentException(\"Type '\" + enumType.Name + \"' is not an enum\");\n        }\n\n        List<object> values = new List<object>();\n\n        var fields = from field in enumType.GetFields()\n                     where field.IsLiteral\n                     select field;\n\n        foreach (FieldInfo field in fields)\n        {\n            object value = field.GetValue(enumType);\n            values.Add(value);\n        }\n\n        return values.ToArray();\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 22:45\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 17 '10 at 1:29\nAubrey Taylor\n8516\n6 silver badges\n2\n2 bronze badges","comments":["Nice solution, but some refactoring will be better! :)","I am using .NET framework 4.0 & silverlight enum.getvalues work, the code I used is ---> enum.GetValues(typeof(enum))","Starting with C# 7.3 (Visual Studio 2017 ≥ v15.7), one can use where T: Enum"]},{"answer":"My solution works in .NET Compact Framework (3.5) and supports type checking at compile time:\n\npublic static List<T> GetEnumValues<T>() where T : new() {\n    T valueType = new T();\n    return typeof(T).GetFields()\n        .Select(fieldInfo => (T)fieldInfo.GetValue(valueType))\n        .Distinct()\n        .ToList();\n}\n\npublic static List<String> GetEnumNames<T>() {\n    return typeof (T).GetFields()\n        .Select(info => info.Name)\n        .Distinct()\n        .ToList();\n}\n\nIf anyone knows how to get rid of the T valueType = new T(), I'd be happy to see a solution.\n\nA call would look like this:\n\nList<MyEnum> result = Utils.GetEnumValues<MyEnum>();\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 22:35\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 7 '10 at 13:37\nMallox\n1,38411\n11 silver badges\n12\n12 bronze badges","comments":["what about using T valueType = default(T)?","Great, I didn't even know that keyword. Always nice to learn something new. Thank you! Does it always return a reference to the same object, or does it create a new instance each time the default statement is called? I haven't found anything on the net about this so far, but if it creates a new instance every time, it kind of defeats the purpose I was looking for (having a one-liner ^^).","Wouldn't this create a new instance for every iteration over the enumeration?","-1 for \"supports type checking at compile time:\". What type checking? This would work for any new() T. Also, you dont need new T() at all, you can select just the static fields alone and do .GetValue(null). See Aubrey's answer.","Starting with C# 7.3 (Visual Studio 2017 ≥ v15.7), one can use where T: Enum"]},{"answer":"I think you can use\n\nEnum.GetNames(Suit)\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '11 at 7:46\nbluish\n23.6k24\n24 gold badges\n110\n110 silver badges\n171\n171 bronze badges\nanswered Sep 19 '08 at 20:37\nTom Carr\n1,2697\n7 silver badges\n11\n11 bronze badges","comments":[]},{"answer":"public void PrintAllSuits()\n{\n    foreach(string suit in Enum.GetNames(typeof(Suits)))\n    {\n        Console.WriteLine(suit);\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 9 '17 at 20:45\nTermininja\n5,85912\n12 gold badges\n42\n42 silver badges\n46\n46 bronze badges\nanswered Sep 19 '08 at 21:05\nJoshua Drake\n2,5812\n2 gold badges\n34\n34 silver badges\n53\n53 bronze badges","comments":["That enumerates a string, don't forget to convert those things back to an enumeration value so the enumeration can be enumerated.","I see from your edit that you want to actually operate on the enums themselves, the above code addressed your original post."]},{"answer":"foreach (Suit suit in Enum.GetValues(typeof(Suit))) { }\n\n\nI've heard vague rumours that this is terifically slow. Anyone know? – Orion Edwards Oct 15 '08 at 1:31 7\n\nI think caching the array would speed it up considerably. It looks like you're getting a new array (through reflection) every time. Rather:\n\nArray enums = Enum.GetValues(typeof(Suit));\nforeach (Suit suitEnum in enums) \n{\n    DoSomething(suitEnum);\n}\n\n\nThat's at least a little faster, ja?\n\nShare\nImprove this answer\nFollow\nedited Oct 6 '17 at 7:20\nAlexander Schmidt\n5,0024\n4 gold badges\n33\n33 silver badges\n71\n71 bronze badges\nanswered Nov 16 '09 at 17:19\nlmat - Reinstate Monica\n6,2174\n4 gold badges\n44\n44 silver badges\n55\n55 bronze badges","comments":["The compiler should take care of this, though.","@StephanBijzitter Wow, you're reading pretty far down on this one :-) I agree, the compiler should make my solution unnecessary.","This is not necessary. Looking at the compiled code in ILSpy, the compiler definitely already does this. Why is this answer upvoted at all, much less 35 times?","It was upvoted a long time ago. A very long time ago. I would wager that the compiler would have solved this back then, too, though. But it sure looks more performant, doesn't it? ;-)"]},{"answer":"Just by combining the top answers, I threw together a very simple extension:\n\npublic static class EnumExtensions\n{\n    /// <summary>\n    /// Gets all items for an enum value.\n    /// </summary>\n    /// <typeparam name=\"T\"></typeparam>\n    /// <param name=\"value\">The value.</param>\n    /// <returns></returns>\n    public static IEnumerable<T> GetAllItems<T>(this T value) where T : Enum\n    {\n        return (T[])Enum.GetValues(typeof (T));\n    }\n}\n\n\nIt is clean, simple, and, by @Jeppe-Stig-Nielsen's comment, fast.\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 22:54\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 15 '13 at 8:22\nDarkside\n1,65514\n14 silver badges\n18\n18 bronze badges","comments":["Starting with C# 7.3 (Visual Studio 2017 ≥ v15.7), one can use where T: Enum"]},{"answer":"Three ways:\n\nEnum.GetValues(type) // Since .NET 1.1, not in Silverlight or .NET Compact Framework\ntype.GetEnumValues() // Only on .NET 4 and above\ntype.GetFields().Where(x => x.IsLiteral).Select(x => x.GetValue(null)) // Works everywhere\n\nI am not sure why GetEnumValues was introduced on type instances. It isn't very readable at all for me.\n\nHaving a helper class like Enum<T> is what is most readable and memorable for me:\n\npublic static class Enum<T> where T : struct, IComparable, IFormattable, IConvertible\n{\n    public static IEnumerable<T> GetValues()\n    {\n        return (T[])Enum.GetValues(typeof(T));\n    }\n\n    public static IEnumerable<string> GetNames()\n    {\n        return Enum.GetNames(typeof(T));\n    }\n}\n\n\nNow you call:\n\nEnum<Suit>.GetValues();\n\n// Or\nEnum.GetValues(typeof(Suit)); // Pretty consistent style\n\n\nOne can also use some sort of caching if performance matters, but I don't expect this to be an issue at all.\n\npublic static class Enum<T> where T : struct, IComparable, IFormattable, IConvertible\n{\n    // Lazily loaded\n    static T[] values;\n    static string[] names;\n\n    public static IEnumerable<T> GetValues()\n    {\n        return values ?? (values = (T[])Enum.GetValues(typeof(T)));\n    }\n\n    public static IEnumerable<string> GetNames()\n    {\n        return names ?? (names = Enum.GetNames(typeof(T)));\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 22:58\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 12 '13 at 15:36\nnawfal\n63k48\n48 gold badges\n304\n304 silver badges\n344\n344 bronze badges","comments":["This is a nice summary of methods. I think you should merge your other answer into this though. The truth is that enum are special and looping through them is often (usually) just as valid as enumeration because you know that the values will never change. IOW, If you have an enum that is changing all the time then you've chosen the wrong data construct to begin with."]},{"answer":"There are two ways to iterate an Enum:\n\n1. var values =  Enum.GetValues(typeof(myenum))\n2. var values =  Enum.GetNames(typeof(myenum))\n\n\nThe first will give you values in form on an array of **object**s, and the second will give you values in form of an array of **String**s.\n\nUse it in a foreach loop as below:\n\nforeach(var value in values)\n{\n    // Do operations here\n}\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 23:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 22 '16 at 18:50\nKylo Ren\n7,7385\n5 gold badges\n36\n36 silver badges\n57\n57 bronze badges","comments":["Maybe 'cos this is already covered in many answers? Let's not make answers redundant.","@nawfal yes may be covered in other answers, though not concluded well in most of them."]},{"answer":"I use ToString() then split and parse the spit array in flags.\n\n[Flags]\npublic enum ABC {\n   a = 1,\n   b = 2,\n   c = 4\n};\n\npublic IEnumerable<ABC> Getselected (ABC flags)\n{\n   var values = flags.ToString().Split(',');\n   var enums = values.Select(x => (ABC)Enum.Parse(typeof(ABC), x.Trim()));\n   return enums;\n}\n\nABC temp= ABC.a | ABC.b;\nvar list = getSelected (temp);\nforeach (var item in list)\n{\n   Console.WriteLine(item.ToString() + \" ID=\" + (int)item);\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 18 '15 at 15:51\nanswered Jul 26 '12 at 9:22\nMickey Perlstein\n1,9742\n2 gold badges\n24\n24 silver badges\n32\n32 bronze badges","comments":[]},{"answer":"New .NET 5 solution:\n\n.NET 5 has introduced a a generic version for the GetValues method:\n\nSuit[] suitValues = Enum.GetValues<Suit>();\n\n\nUsage in a foreach loop:\n\nforeach (Suit suit in Enum.GetValues<Suit>())\n{\n\n}\n\n\nwhich is now by far the most convenient solution.\n\nAnd for getting enum names:\n\nstring[] suitNames = Enum.GetNames<Suit>();\n\nShare\nImprove this answer\nFollow\nedited Jun 13 at 4:28\nMeer\n1651\n1 silver badge\n8\n8 bronze badges\nanswered Dec 2 '20 at 6:28\nArad\n2,2032\n2 gold badges\n19\n19 silver badges\n43\n43 bronze badges","comments":[]},{"answer":"I do not hold the opinion this is better, or even good. I am just stating yet another solution.\n\nIf enum values range strictly from 0 to n - 1, a generic alternative is:\n\npublic void EnumerateEnum<T>()\n{\n    int length = Enum.GetValues(typeof(T)).Length;\n    for (var i = 0; i < length; i++)\n    {\n        var @enum = (T)(object)i;\n    }\n}\n\n\nIf enum values are contiguous and you can provide the first and last element of the enum, then:\n\npublic void EnumerateEnum()\n{\n    for (var i = Suit.Spade; i <= Suit.Diamond; i++)\n    {\n        var @enum = i;\n    }\n}\n\n\nBut that's not strictly enumerating, just looping. The second method is much faster than any other approach though...\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jan 25 '13 at 0:05\nnawfal\n63k48\n48 gold badges\n304\n304 silver badges\n344\n344 bronze badges","comments":[]},{"answer":"If you need speed and type checking at build and run time, this helper method is better than using LINQ to cast each element:\n\npublic static T[] GetEnumValues<T>() where T : struct, IComparable, IFormattable, IConvertible\n{\n    if (typeof(T).BaseType != typeof(Enum))\n    {\n        throw new ArgumentException(string.Format(\"{0} is not of type System.Enum\", typeof(T)));\n    }\n    return Enum.GetValues(typeof(T)) as T[];\n}\n\n\nAnd you can use it like below:\n\nstatic readonly YourEnum[] _values = GetEnumValues<YourEnum>();\n\n\nOf course you can return IEnumerable<T>, but that buys you nothing here.\n\nShare\nImprove this answer\nFollow\nedited Jan 17 '16 at 12:11\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 15 '13 at 20:13\ndmihailescu\n1,49516\n16 silver badges\n14\n14 bronze badges","comments":["Starting with C# 7.3 (Visual Studio 2017 ≥ v15.7), one can use where T: Enum"]},{"answer":"Here is a working example of creating select options for a DDL:\n\nvar resman = ViewModelResources.TimeFrame.ResourceManager;\n\nViewBag.TimeFrames = from MapOverlayTimeFrames timeFrame\n      in Enum.GetValues(typeof(MapOverlayTimeFrames))\n      select new SelectListItem\n      {\n         Value = timeFrame.ToString(),\n         Text = resman.GetString(timeFrame.ToString()) ?? timeFrame.ToString()\n      };\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 22:48\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 25 '12 at 21:20\njhilden\n11.2k5\n5 gold badges\n44\n44 silver badges\n70\n70 bronze badges","comments":[]},{"answer":"foreach (Suit suit in Enum.GetValues(typeof(Suit)))\n{\n}\n\n\n(The current accepted answer has a cast that I don't think is needed (although I may be wrong).)\n\nShare\nImprove this answer\nFollow\nedited Jan 17 '16 at 12:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 20 '14 at 10:37\nmatt burns\n22.7k10\n10 gold badges\n93\n93 silver badges\n102\n102 bronze badges","comments":[]},{"answer":"Add method public static IEnumerable<T> GetValues<T>() to your class, like:\n\npublic static IEnumerable<T> GetValues<T>()\n{\n    return Enum.GetValues(typeof(T)).Cast<T>();\n}\n\n\nCall and pass your enum. Now you can iterate through it using foreach:\n\n public static void EnumerateAllSuitsDemoMethod()\n {\n     // Custom method\n     var foos = GetValues<Suit>();\n     foreach (var foo in foos)\n     {\n         // Do something\n     }\n }\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 23:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 31 '17 at 7:08\nMUT\n5063\n3 silver badges\n17\n17 bronze badges","comments":["I would add \"where T : struct, Enum\" to restrict the method to enums. Like this public static IEnumerable<T> ObtenerValores<T>() where T : struct, Enum => Enum.GetValues(typeof(T)).Cast<T>();"]},{"answer":"This question appears in Chapter 10 of \"C# Step by Step 2013\"\n\nThe author uses a double for-loop to iterate through a pair of Enumerators (to create a full deck of cards):\n\nclass Pack\n{\n    public const int NumSuits = 4;\n    public const int CardsPerSuit = 13;\n    private PlayingCard[,] cardPack;\n\n    public Pack()\n    {\n        this.cardPack = new PlayingCard[NumSuits, CardsPerSuit];\n        for (Suit suit = Suit.Clubs; suit <= Suit.Spades; suit++)\n        {\n            for (Value value = Value.Two; value <= Value.Ace; value++)\n            {\n                cardPack[(int)suit, (int)value] = new PlayingCard(suit, value);\n            }\n        }\n    }\n}\n\n\nIn this case, Suit and Value are both enumerations:\n\nenum Suit { Clubs, Diamonds, Hearts, Spades }\nenum Value { Two, Three, Four, Five, Six, Seven, Eight, Nine, Ten, Jack, Queen, King, Ace}\n\n\nand PlayingCard is a card object with a defined Suit and Value:\n\nclass PlayingCard\n{\n    private readonly Suit suit;\n    private readonly Value value;\n\n    public PlayingCard(Suit s, Value v)\n    {\n        this.suit = s;\n        this.value = v;\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 13 '17 at 7:22\nTermininja\n5,85912\n12 gold badges\n42\n42 silver badges\n46\n46 bronze badges\nanswered Jun 28 '15 at 6:12\nRoss Gatih\n3862\n2 silver badges\n6\n6 bronze badges","comments":["will this work if the values in enum are not sequential?"]},{"answer":"I know it is a bit messy, but if you are fan of one-liners, here is one:\n\n((Suit[])Enum.GetValues(typeof(Suit))).ToList().ForEach(i => DoSomething(i));\n\nShare\nImprove this answer\nFollow\nedited Dec 9 '19 at 23:01\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 8 '14 at 15:44\nanar khalilov\n15.4k9\n9 gold badges\n43\n43 silver badges\n58\n58 bronze badges","comments":["Is that lisp?"]},{"answer":"A simple and generic way to convert an enum to something you can interact:\n\npublic static Dictionary<int, string> ToList<T>() where T : struct\n{\n   return ((IEnumerable<T>)Enum\n       .GetValues(typeof(T)))\n       .ToDictionary(\n           item => Convert.ToInt32(item),\n           item => item.ToString());\n}\n\n\nAnd then:\n\nvar enums = EnumHelper.ToList<MyEnum>();\n\nShare\nImprove this answer\nFollow\nedited Oct 25 '16 at 14:12\nMassimiliano Kraus\n3,2755\n5 gold badges\n21\n21 silver badges\n43\n43 bronze badges\nanswered Sep 12 '14 at 18:06\nGabriel\n86710\n10 silver badges\n22\n22 bronze badges","comments":["A Dictionary is not a good idea: if you have an Enum like enum E { A = 0, B = 0 }, the 0 value is added 2 times generating an ArgumentException (you cannot add the same Key on a Dictionary 2 or more times!).","Why return a Dictionary<,> from a method named ToList? Also why not return Dictionary<T, string>?"]},{"answer":"What if you know the type will be an enum, but you don't know what the exact type is at compile time?\n\npublic class EnumHelper\n{\n    public static IEnumerable<T> GetValues<T>()\n    {\n        return Enum.GetValues(typeof(T)).Cast<T>();\n    }\n\n    public static IEnumerable getListOfEnum(Type type)\n    {\n        MethodInfo getValuesMethod = typeof(EnumHelper).GetMethod(\"GetValues\").MakeGenericMethod(type);\n        return (IEnumerable)getValuesMethod.Invoke(null, null);\n    }\n}\n\n\nThe method getListOfEnum uses reflection to take any enum type and returns an IEnumerable of all enum values.\n\nUsage:\n\nType myType = someEnumValue.GetType();\n\nIEnumerable resultEnumerable = getListOfEnum(myType);\n\nforeach (var item in resultEnumerable)\n{\n    Console.WriteLine(String.Format(\"Item: {0} Value: {1}\",item.ToString(),(int)item));\n}\n\nShare\nImprove this answer\nFollow\nedited Oct 1 '15 at 10:21\nanswered Oct 1 '15 at 10:14\nSlappywag\n1,0931\n1 gold badge\n14\n14 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"enum types are called \"enumeration types\" not because they are containers that \"enumerate\" values (which they aren't), but because they are defined by enumerating the possible values for a variable of that type.\n\n(Actually, that's a bit more complicated than that - enum types are considered to have an \"underlying\" integer type, which means each enum value corresponds to an integer value (this is typically implicit, but can be manually specified). C# was designed in a way so that you could stuff any integer of that type into the enum variable, even if it isn't a \"named\" value.)\n\nThe System.Enum.GetNames method can be used to retrieve an array of strings which are the names of the enum values, as the name suggests.\n\nEDIT: Should have suggested the System.Enum.GetValues method instead. Oops.\n\nShare\nImprove this answer\nFollow\nedited Jan 16 '18 at 20:14\nanswered Oct 11 '17 at 4:50\nEmily Chen\n1508\n8 bronze badges","comments":["Although your answer is correct in itself, it doesn't really address the OP's original question. The GetNames method returns, indeed, a string array, but the OP requires an enumerator through the values.","@SilviuPreda: Edited. It should have been GetValues instead of GetNames."]},{"answer":"For getting a list of int from an enum, use the following. It works!\n\nList<int> listEnumValues = new List<int>();\nYourEnumType[] myEnumMembers = (YourEnumType[])Enum.GetValues(typeof(YourEnumType));\nforeach ( YourEnumType enumMember in myEnumMembers)\n{\n    listEnumValues.Add(enumMember.GetHashCode());\n}\n\nShare\nImprove this answer\nFollow\nedited Jan 26 at 13:14\nanswered Oct 5 '19 at 14:53\nreza akhlaghi\n6751\n1 gold badge\n12\n12 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"When you have a bit enum like this\n\nenum DemoFlags\n{\n    DemoFlag = 1,\n    OtherFlag = 2,\n    TestFlag = 4,\n    LastFlag = 8,\n}\n\n\nWith this assignement\n\nDemoFlags demoFlags = DemoFlags.DemoFlag | DemoFlags.TestFlag;\n\n\nand need a result like this\n\n\"DemoFlag | TestFlag\"\n\n\nthis method helps:\n\npublic static string ConvertToEnumString<T>(T enumToConvert, string separator = \" | \") where T : Enum\n{\n    StringBuilder convertedEnums = new StringBuilder();\n\n    foreach (T enumValue in Enum.GetValues(typeof(T)))\n    {\n        if (enumToConvert.HasFlag(enumValue)) convertedEnums.Append($\"{ enumValue }{separator}\");\n    }\n\n    if (convertedEnums.Length > 0) convertedEnums.Length -= separator.Length;\n\n    return convertedEnums.ToString();\n}\n\nShare\nImprove this answer\nFollow\nanswered Feb 8 at 22:04\nmarsh-wiggle\n1,7933\n3 gold badges\n24\n24 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"Also you can bind to the public static members of the enum directly by using reflection:\n\ntypeof(Suit).GetMembers(BindingFlags.Public | BindingFlags.Static)\n    .ToList().ForEach(x => DoSomething(x.Name));\n\nShare\nImprove this answer\nFollow\nanswered Jan 9 '17 at 23:39\nTermininja\n5,85912\n12 gold badges\n42\n42 silver badges\n46\n46 bronze badges","comments":[]},{"answer":"If you have:\n\nenum Suit\n{\n   Spades,\n   Hearts,\n   Clubs,\n   Diamonds\n}\n\n\nThis:\n\nforeach (var e in Enum.GetValues(typeof(Suit)))\n{\n    Console.WriteLine(e.ToString() + \" = \" + (int)e);\n}\n\n\nWill output:\n\nSpades = 0\nHearts = 1\nClubs = 2\nDiamonds = 3\n\nShare\nImprove this answer\nFollow\nanswered Nov 21 '19 at 11:45\nrlv-dan\n81610\n10 silver badges\n17\n17 bronze badges","comments":[]}]},{"id":"22343224","href":"https://stackoverflow.com/questions/22343224/whats-the-difference-between-tilde-and-caret-in-package-json","title":"What's the difference between tilde(~) and caret(^) in package.json?","description":"\n                \nAfter I upgraded to the latest stable node and npm, I tried npm install moment --save. It saves the entry in the package.json with the caret ^ prefix. Previously, it was a tilde ~ prefix.\n\nWhy are these changes made in npm?\nWhat is the difference between tilde ~ and caret ^?\nWhat are the advantages over others?\n\n    ","questionComments":["FYI you can prevent prefixes or use a custom one by doing: npm config set save-prefix=''. (Stick ~ in the quotes if that's what you prefer.) I personally do this and shrinkwrap for things in production.","All the nitty gritty details of how tilde and caret work and differences: github.com/npm/node-semver#tilde-ranges-123-12-1","This tool is a great helper to test semver.npmjs.com","Semantic versioning in npm and node","Docs for npm shrinkwrap and package-lock.json vs npm-shrinkwrap.json #toSaveYouAGoogle (or two) -- fncomp mentions above and tehfoo below. Also, mneumonic: ~ stays about even, ^ goes up a little higher."],"answers":[{"answer":"See the NPM docs and semver docs:\n\n~version “Approximately equivalent to version”, will update you to all future patch versions, without incrementing the minor version. ~1.2.3 will use releases from 1.2.3 to <1.3.0.\n\n^version “Compatible with version”, will update you to all future minor/patch versions, without incrementing the major version. ^2.3.4 will use releases from 2.3.4 to <3.0.0.\n\nSee Comments below for exceptions, in particular for pre-one versions, such as ^0.2.3\n\nShare\nImprove this answer\nFollow\nedited Jul 23 '20 at 20:29\nBuZZ-dEE\n4,0748\n8 gold badges\n51\n51 silver badges\n76\n76 bronze badges\nanswered Mar 12 '14 at 8:28\njgillich\n57.7k5\n5 gold badges\n49\n49 silver badges\n80\n80 bronze badges","comments":["Posting here to hopefully catch people that don't quite think this through, but both ^ and ~ assumes you can trust minor and point releases from your dependencies. If you are publishing a library and want other people to trust you, DO NOT BLINDLY ACCEPT DOWNSTREAM DEPENDENCIES. A bad dot release from your dependency can cause a chain reaction upstream, and will have people knocking at YOUR door when things go pear shaped. This is another huge reason to use npm shrinkwrap on your production code.","You can also just do away with all the nonsense of npm prepending your versions with a ^ or a ~. Set this if you want to have tight control over your versions: npm config set save-prefix=''","@prasanthv is right: from docs.npmjs.com/misc/semver#caret-ranges-1-2-3-0-2-5-0-0-4: Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4. Allows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X.","@jgillich in semver when you use 0.2.x, 2 isn't a major version. That's why docs.npmjs.com used the specific words: the left-most non-zero digit. Also what about this case: ^0.0.4 means 0.0.4","@FagnerBrack: The specific example you provided is correct, but generally your way of thinking is wrong. An example: let's say you have package A in 3 versions: 0.0.1, 0.0.2 and 0.0.3. There is a bug in 0.0.1 so you want to have at least 0.0.2 in your package B. If you write 0.0.x you'll get 0.0.3, which is OK. But if some other package C requires both B and A and additionally has constrain \"A\": \"<0.0.2\" you'll get 0.0.1 without showing any conflict issue, which is not what you want. Using tilde ~0.0.2 should help you avoid this issue."]},{"answer":"I would like to add the official npmjs documentation as well which describes all methods for version specificity including the ones referred to in the question\n\nvalue\tdesc\n~version\t\"Approximately equivalent to version\"\nSee npm semver - Tilde Ranges\n^version\t\"Compatible with version\"\nSee npm semver - Caret Ranges\nversion\tMust match version exactly\n>version\tMust be greater than version\n>=version\tetc\n<version\t\n<=version\t\n1.2.x\t1.2.0, 1.2.1, etc., but not 1.3.0\n*\tMatches any version\nlatest\tObtains latest release\n\nThe above list is not exhaustive. Other version specifiers include GitHub urls and GitHub user repo's, local paths and packages with specific npm tags\n\nOfficial Docs\nnpm docs > package.json > dependencies\nnpm docs > semver > versions\nsemver (7)\nShare\nImprove this answer\nFollow\nedited Apr 4 at 14:30\nKyleMit\n41.1k55\n55 gold badges\n379\n379 silver badges\n553\n553 bronze badges\nanswered Sep 16 '14 at 6:25\nAhmad\n17k8\n8 gold badges\n46\n46 silver badges\n79\n79 bronze badges","comments":["It is also possible to specify an exact range of versions, like 1.2.0 || >=1.2.2 <1.3.0: Exactly 1.2.0, or everything from 1.2.2 to 1.3.0 (inclusive), but not 1.2.1, or 1.3.1 and above, and also not 1.1.x and below.","A more specific link form the above -> docs.npmjs.com/files/package.json#dependencies","\"Approximately equivalent to version\" and \"Compatible with version\" are such frustratingly non-specific ways to describe ~ and ^ behavior. Thank you @jgillich for providing an actual answer!","Another resource : nodejs.dev/learn/semantic-versioning-using-npm","Is latest recommend for debs that never depend on versions? Does the question makes sense at all.."]},{"answer":"npm allows installing newer version of a package than the one specified. Using tilde (~) gives you bug fix releases and caret (^) gives you backwards-compatible new functionality as well.\n\nThe problem is old versions usually don't receive bug fixes that much, so npm uses caret (^) as the default for --save.\n\nAccording to: \"Semver explained - why there's a caret (^) in my package.json?\".\n\nNote that the rules apply to versions above 1.0.0 and not every project follows semantic versioning. For versions 0.x.x the caret allows only patch updates, i.e., it behaves the same as the tilde. See \"Caret Ranges\"\n\nHere's a visual explanation of the concepts:\n\nSource: \"Semantic Versioning Cheatsheet\".\n\nShare\nImprove this answer\nFollow\nedited Apr 16 '20 at 10:30\nRonan Boiteau\n8,2336\n6 gold badges\n32\n32 silver badges\n48\n48 bronze badges\nanswered Jul 30 '15 at 20:40\npspi\n9,3811\n1 gold badge\n13\n13 silver badges\n13\n13 bronze badges","comments":["What about ^0.2.5? from docs.npmjs.com/misc/semver#caret-ranges-1-2-3-0-2-5-0-0-4: Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4. Allows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X.","@rofrol any version before 1.0.0 is considered unstable and these rules don't apply","So your explanation isn't complete","@rofrol yeah, omitting for readability is good sometimes, chances of having anything below 1.0.0 for a dependency in package json are pretty low. see also 20/80 principle, is a great rule for focusing on what matters","@pspi Having versions below 1.0.0 is \"unlikely\"? Out of 60 we've got ~15, and most of them aren't obscure."]},{"answer":"Semver\n<major>.<minor>.<patch>-beta.<beta> == 1.2.3-beta.2\n\nUse npm semver calculator for testing. Although the explanations for ^ (include everything greater than a particular version in the same major range) and ~ (include everything greater than a particular version in the same minor range) aren't a 100% correct, the calculator seems to work fine.\nAlternatively, use SemVer Check instead, which doesn't require you to pick a package and also offers explanations.\nAllow or disallow changes\nPin version: 1.2.3.\nUse ^ (like head). Allows updates at the second non-zero level from the left: ^0.2.3 means 0.2.3 <= v < 0.3.\nUse ~ (like tail). Generally freeze right-most level or set zero if omitted:\n~1 means 1.0.0 <= v < 2.0.0\n~1.2 means 1.2.0 <= v < 1.3.0.\n~1.2.4 means 1.2.4 <= v < 1.3.0.\nOmmit right-most level: 0.2 means 0.2 <= v < 1. Differs from ~ because:\nStarting omitted level version is always 0\nYou can set starting major version without specifying sublevels.\nAll (hopefully) possibilities\n\nSet starting major-level and allow updates upward\n\n*  or \"(empty string)   any version\n1                         v >= 1\n\n\nFreeze major-level\n\n~0 (0)            0.0 <= v < 1\n0.2               0.2 <= v < 1          // Can't do that with ^ or ~ \n~1 (1, ^1)        1 <= v < 2\n^1.2              1.2 <= v < 2\n^1.2.3            1.2.3 <= v < 2\n^1.2.3-beta.4     1.2.3-beta.4 <= v < 2\n\n\nFreeze minor-level\n\n^0.0 (0.0)        0 <= v < 0.1\n~0.2              0.2 <= v < 0.3\n~1.2              1.2 <= v < 1.3\n~0.2.3 (^0.2.3)   0.2.3 <= v < 0.3\n~1.2.3            1.2.3 <= v < 1.3\n\n\nFreeze patch-level\n\n~1.2.3-beta.4     1.2.3-beta.4 <= v < 1.2.4 (only beta or pr allowed)\n^0.0.3-beta       0.0.3-beta.0 <= v < 0.0.4 or 0.0.3-pr.0 <= v < 0.0.4 (only beta or pr allowed)\n^0.0.3-beta.4     0.0.3-beta.4 <= v < 0.0.4 or 0.0.3-pr.4 <= v < 0.0.4 (only beta or pr allowed)\n\n\nDisallow updates\n\n1.2.3             1.2.3\n^0.0.3 (0.0.3)    0.0.3\n\n\nNotice: Missing major, minor, patch or specifying beta without number, is the same as any for the missing level.\n\nNotice: When you install a package which has 0 as major level, the update will only install new beta/pr level version! That's because npm sets ^ as default in package.json and when installed version is like 0.1.3, it freezes all major/minor/patch levels.\n\nhttps://docs.npmjs.com/misc/semver\nhttps://docs.npmjs.com/files/package.json#dependencies\nShare\nImprove this answer\nFollow\nedited Jul 16 '20 at 9:27\nanswered Oct 11 '15 at 16:52\nrofrol\n12.2k7\n7 gold badges\n66\n66 silver badges\n65\n65 bronze badges","comments":["Telling people to avoid starting projects from 0 because library and consuming developers don't understand the system is a terrible solution. I think @asdfasdfads has much better information.","@ProLoser I just think that the system should be simplified, and we shouldn't use 0.x versions.","The use case around early lifecycle development and v0 makes a LOT of sense. Learning how v0 behaves properly has actually made me look forward to other early-lifecycle projects. It means you can have a rapidly changing API with lots of backwards incompatibility without being forced to declare your project as 1.x (aka: stable) when it really isn't.","I understand it, but I just don't like how it works with semver and qualifiers","It feels more like an opinion and shouldn't be framed as a generally accepted approach. And ^0.1.x gets patches perfectly fine."]},{"answer":"~ fixes major and minor numbers. It is used when you're ready to accept bug-fixes in your dependency, but don't want any potentially incompatible changes.\n\n^ fixes the major number only. It is used when you're closely watching your dependencies and are ready to quickly change your code if minor release will be incompatible.\n\nIn addition to that, ^ is not supported by old npm versions, and should be used with caution.\n\nSo, ^ is a good default, but it's not perfect. I suggest to carefully pick and configure the semver operator that is most useful to you.\n\nShare\nImprove this answer\nFollow\nedited Sep 20 '14 at 13:45\nCam Jackson\n10k6\n6 gold badges\n41\n41 silver badges\n72\n72 bronze badges\nanswered Mar 12 '14 at 23:05\nalex\n10.9k2\n2 gold badges\n27\n27 silver badges\n41\n41 bronze badges","comments":["not true: Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4. Allows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X. docs.npmjs.com/misc/semver#caret-ranges-1-2-3-0-2-5-0-0-4","This answer is completely wrong (as are many other here). None of these ever fix a major number! As @rofrol said, ^ simply keeps the left most non-zero digit unchanged. ~ on the other hand allows only patch updates if the minor version is specified (e.g. ~1.2.3 or ~1.2) and allows minor updates if the minor version is not specified (e.g. ~1).","@TheBaj They mean \"fix\" as \"define\" (\"fixate\") rather than \"adjust\", so you all agree on how the major number gets handled.","Yes, this answer seemed totally backwards until I realized the answerer meant \"fix\" as in \"to make fixed, stationary, or unchanging.\""]},{"answer":"~ : Reasonably close to\n\n   ~1.1.5: 1.1.0 <= accepted < 1.2.0\n\n\n^: Compatible with\n\n   ^1.1.5: 1.1.5 <= accepted < 2.0.0\n\n   ^0.1.3: 0.1.3 <= accepted < 0.2.0\n\n   ^0.0.4: 0.0.4 <= accepted < 0.1.0\n\nShare\nImprove this answer\nFollow\nedited Feb 25 '15 at 22:54\nchharvey\n6,4815\n5 gold badges\n48\n48 silver badges\n75\n75 bronze badges\nanswered Jun 27 '14 at 16:12\nhaotang\n5,13231\n31 silver badges\n43\n43 bronze badges","comments":["@kytwb - no. In the special case of zeroth-release version numbers, the carat is equivalent to the tilde. Thus ^0.1.3 only accepts versions 0.1.x and will not accept 0.2.0, even though that's a minor increment. This behavior is equivalent to ~0.1.3. The reasoning behind this behavior is due to the fact that zeroth-release packages are still considered unstable; in the words of semver.org, #4, \"anything may change at any time\" (including backwards-incompatible changes)."]},{"answer":"^ is 1.[any].[any] (latest minor version)\n~ is 1.2.[any] (latest patch)\n\nA great read is this blog post on how semver applies to npm\nand what they're doing to make it match the semver standard\nhttp://blog.npmjs.org/post/98131109725/npm-2-0-0\n\nShare\nImprove this answer\nFollow\nanswered Dec 15 '14 at 18:07\nWill Stern\n15.7k5\n5 gold badges\n32\n32 silver badges\n21\n21 bronze badges","comments":["not true: Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4. Allows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X. docs.npmjs.com/misc/semver#caret-ranges-1-2-3-0-2-5-0-0-4"]},{"answer":"~ Tilde:\n\n~ freezes major and minor numbers.\nIt is used when you're ready to accept bug-fixes in your dependency, but don't want any potentially incompatible changes.\nThe tilde matches the most recent minor version (the middle number).\n~1.2.3 will match all 1.2.x versions, but it will miss 1.3.0.\nTilde (~) gives you bug fix releases\n\n^ Caret:\n\n^ freezes the major number only.\nIt is used when you're closely watching your dependencies and are ready to quickly change your code if minor release will be incompatible.\nIt will update you to the most recent major version (the first number).\n^1.2.3 will match any 1.x.x release including 1.3.0, but it will hold off on 2.0.0.\nCaret (^) gives you backwards-compatible new functionality as well.\nShare\nImprove this answer\nFollow\nedited Jul 1 '19 at 17:08\ncoding_idiot\n13k9\n9 gold badges\n59\n59 silver badges\n112\n112 bronze badges\nanswered Sep 30 '16 at 10:56\nLaxmi\n3,59921\n21 silver badges\n30\n30 bronze badges","comments":["The tilde matches the most recent patch version (the last number). The caret matches the most most recent minor version (the middle number).","\"freezes\" is the best explanation.","Caret both freezes the major number and will update you to the most recent major version (the first number)? The major number is the first number, so this doesn't make sense."]},{"answer":"Hat matching may be considered \"broken\" because it wont update ^0.1.2 to 0.2.0. When the software is emerging use 0.x.y versions and hat matching will only match the last varying digit (y). This is done on purpose. The reason is that while the software is evolving the API changes rapidly: one day you have these methods and the other day you have those methods and the old ones are gone. If you don't want to break the code for people who already are using your library you go and increment the major version: e.g. 1.0.0 -> 2.0.0 -> 3.0.0. So, by the time your software is finally 100% done and full-featured it will be like version 11.0.0 and that doesn't look very meaningful, and actually looks confusing. If you were, on the other hand, using 0.1.x -> 0.2.x -> 0.3.x versions then by the time the software is finally 100% done and full-featured it is released as version 1.0.0 and it means \"This release is a long-term service one, you can proceed and use this version of the library in your production code, and the author won't change everything tomorrow, or next month, and he won't abandon the package\".\n\nThe rule is: use 0.x.y versioning when your software hasn't yet matured and release it with incrementing the middle digit when your public API changes (therefore people having ^0.1.0 won't get 0.2.0 update and it won't break their code). Then, when the software matures, release it under 1.0.0 and increment the leftmost digit each time your public API changes (therefore people having ^1.0.0 won't get 2.0.0 update and it won't break their code).\n\nGiven a version number MAJOR.MINOR.PATCH, increment the:\n\nMAJOR version when you make incompatible API changes,\nMINOR version when you add functionality in a backwards-compatible manner, and\nPATCH version when you make backwards-compatible bug fixes.\n\nShare\nImprove this answer\nFollow\nedited Sep 23 '16 at 11:56\nanswered Oct 19 '15 at 11:24\ncatamphetamine\n3,45126\n26 silver badges\n25\n25 bronze badges","comments":["This comment was ridiculously helpful and doesn't seem to be documented very well. Do you have a link to the documentation around this behavior? This answer about v0 projects has helped me a lot.","I don't have a link: I found this information too by googling and playing with npm semantic version calculator semver.npmjs.com","Needs to be added to their documentation in a more formal way. I gave a talk at Sony to my engineering team because it seems to so easily get overlooked. slides.com/proloser/semver-v0"]},{"answer":"One liner explanation\n\nThe standard versioning system is major.minor.build (e.g. 2.4.1)\n\nnpm checks and fixes the version of a particular package based on these characters\n\n~ : major version is fixed, minor version is fixed, matches any build number\n\ne.g. : ~2.4.1 means it will check for 2.4.x where x is anything\n\n^ : major version is fixed, matches any minor version, matches any build number\n\ne.g. : ^2.4.1 means it will check for 2.x.x where x is anything\n\nShare\nImprove this answer\nFollow\nanswered Jan 21 '17 at 8:00\nAvinash\n3,4212\n2 gold badges\n18\n18 silver badges\n38\n38 bronze badges","comments":["I see 7 lines in this answer"]},{"answer":"Tilde ~ matches minor version, if you have installed a package that has 1.4.2 and after your installation, versions 1.4.3 and 1.4.4 are also available if in your package.json it is used as ~1.4.2 then npm install in your project after upgrade will install 1.4.4 in your project. But there is 1.5.0 available for that package then it will not be installed by ~. It is called minor version.\n\nCaret ^ matches major version, if 1.4.2 package is installed in your project and after your installation 1.5.0 is released then ^ will install major version. It will not allow to install 2.1.0 if you have ^1.4.2.\n\nFixed version if you don't want to change version of package on each installation then used fixed version with out any special character e.g \"1.4.2\"\n\nLatest Version * If you want to install latest version then only use * in front of package name.\n\nShare\nImprove this answer\nFollow\nedited Nov 22 '19 at 9:24\nremix23\n2,3241\n1 gold badge\n8\n8 silver badges\n18\n18 bronze badges\nanswered Jan 17 '19 at 10:32\nMudassir\n5584\n4 silver badges\n6\n6 bronze badges","comments":["This answer is misleading. SemVer clearly states, A normal version number MUST take the form X.Y.Z [where] X is the major version, Y is the minor version, and Z is the patch version."]},{"answer":"You probably have seen the tilde (~) and caret (^) in the package.json. What is the difference between them?\n\nWhen you do npm install moment --save, It saves the entry in the package.json with the caret (^) prefix.\n\nThe tilde (~)\n\nIn the simplest terms, the tilde (~) matches the most recent minor version (the middle number). ~1.2.3 will match all 1.2.x versions but will miss 1.3.0.\n\nThe caret (^)\n\nThe caret (^), on the other hand, is more relaxed. It will update you to the most recent major version (the first number). ^1.2.3 will match any 1.x.x release including 1.3.0, but will hold off on 2.0.0.\n\nReference: https://medium.com/@Hardy2151/caret-and-tilde-in-package-json-57f1cbbe347b\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Nov 26 '17 at 19:12\nAbdou Sameh\n1593\n3 silver badges\n7\n7 bronze badges","comments":["Again, this answer is misleading. SemVer clearly states, A normal version number MUST take the form X.Y.Z [where] X is the major version, Y is the minor version, and Z is the patch version."]},{"answer":"semver is separate in to 3 major sections which is broken by dots.\n\nmajor.minor.patch\n1.0.0\n\n\nThese different major, minor and patch are using to identify different releases. tide (~) and caret (^) are using to identify which minor and patch version to be used in package versioning.\n\n~1.0.1\n Install 1.0.1 or **latest patch versions** such as 1.0.2 ,1.0.5\n^1.0.1\n Install 1.0.1 or **latest patch and minor versions** such as 1.0.2 ,1.1.0 ,1.1.1\n\nShare\nImprove this answer\nFollow\nanswered Nov 27 '19 at 8:52\nireshika piyumalie\n1,63618\n18 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"Tilde (~)\n\nmajor version is fixed, minor version is fixed, matches any build number\n\n\"express\": \"~4.13.3\" \n\n\n~4.13.3 means it will check for 4.13.x where x is anything and 4.14.0\n\nCaret (^)\n\nmajor version is fixed, matches any minor version, matches any build number\n\n\"supertest\": \"^3.0.0\"\n\n\n^3.0.0 means it will check for 3.x.x where x is anything\n\nShare\nImprove this answer\nFollow\nanswered Mar 9 '18 at 12:21\nFarhan Yaseen\n2,0012\n2 gold badges\n17\n17 silver badges\n32\n32 bronze badges","comments":["Can you elaborate on how this answer is different from the same answer posted 4 years ago?"]},{"answer":"The version number is in syntax which designates each section with different meaning. syntax is broken into three sections separated by a dot.\n\nmajor.minor.patch 1.0.2\n\nMajor, minor and patch represent the different releases of a package.\n\nnpm uses the tilde (~) and caret (^) to designate which patch and minor versions to use respectively.\n\nSo if you see ~1.0.2 it means to install version 1.0.2 or the latest patch version such as 1.0.4. If you see ^1.0.2 it means to install version 1.0.2 or the latest minor or patch version such as 1.1.0.\n\nShare\nImprove this answer\nFollow\nanswered Sep 28 '18 at 6:58\nRajashekhar Reddy\n874\n4 bronze badges","comments":["Can you elaborate on how this answer is different from the same answer posted 4 years ago?"]},{"answer":"carat ^ include everything greater than a particular version in the same major range.\n\ntilde ~ include everything greater than a particular version in the same minor range.\n\nFor example, to specify acceptable version ranges up to 1.0.4, use the following syntax:\n\nPatch releases: 1.0 or 1.0.x or ~1.0.4\nMinor releases: 1 or 1.x or ^1.0.4\nMajor releases: * or x\n\nFor more information on semantic versioning syntax, see the npm semver calculator.\n\nMore from npm documentation About semantic versioning\n\nShare\nImprove this answer\nFollow\nanswered Jul 1 '19 at 11:43\nElasticCode\n5,6102\n2 gold badges\n23\n23 silver badges\n36\n36 bronze badges","comments":[]},{"answer":"Not an answer, per se, but an observation that seems to have been overlooked.\n\nThe description for carat ranges:\n\nsee: https://github.com/npm/node-semver#caret-ranges-123-025-004\n\nAllows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple.\n\nMeans that ^10.2.3 matches 10.2.3 <= v < 20.0.0\n\nI don't think that's what they meant. Pulling in versions 11.x.x through 19.x.x will break your code.\n\nI think they meant left most non-zero number field. There is nothing in SemVer that requires number-fields to be single-digit.\n\nShare\nImprove this answer\nFollow\nedited Dec 20 '19 at 8:24\nLiam\n23.3k25\n25 gold badges\n97\n97 silver badges\n161\n161 bronze badges\nanswered Mar 20 '19 at 22:13\nJesse Chisholm\n3,4141\n1 gold badge\n29\n29 silver badges\n25\n25 bronze badges","comments":[]},{"answer":"Related to this question you can review Composer documentation on versions, but here in short:\n\nTilde Version Range (~) - ~1.2.3 is equivalent to >=1.2.3 <1.3.0\nCaret Version Range (^) - ~1.2.3 is equivalent to >=1.2.3 <2.0.0\n\nSo, with Tilde you will get automatic updates of patches but minor and major versions will not be updated. However, if you use Caret you will get patches and minor versions, but you will not get major (breaking changes) versions.\n\nTilde Version is considered \"safer\" approach, but if you are using reliable dependencies (well-maintained libraries) you should not have any problems with Caret Version (because minor changes should not be breaking changes.\n\nYou should probably review this stackoverflow post about differences between composer install and composer update.\n\nShare\nImprove this answer\nFollow\nanswered Feb 18 '20 at 14:36\nmilan.latinovic\n1,5711\n1 gold badge\n14\n14 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"~ specfices to minor version releases ^ specifies to major version releases\n\nFor example if package version is 4.5.2 ,on Update ~4.5.2 will install latest 4.5.x version (MINOR VERSION) ^4.5.2 will install latest 4.x.x version (MAJOR VERSION)\n\nShare\nImprove this answer\nFollow\nanswered May 4 '18 at 11:02\nneeraj-dixit27\n2,0981\n1 gold badge\n12\n12 silver badges\n6\n6 bronze badges","comments":["Can you elaborate on how this answer is different from the same answer posted 4 years ago?"]}]},{"id":"136097","href":"https://stackoverflow.com/questions/136097/difference-between-staticmethod-and-classmethod","title":"Difference between staticmethod and classmethod","description":"\n                \nWhat is the difference between a function decorated with @staticmethod and one decorated with @classmethod?\n    ","questionComments":["static methods are sometimes better off as module level functions in python for the sake of cleanliness. With a module function it is easier to import just the function you need and prevent unnecessary \".\" syntax (I'm looking at you Objective-C). class methods have more use since they can be used in combination with polymorphism to create \"factory pattern\" functions. this is because class methods receive the class as an implicit parameter.","tl;dr >> when compared to normal methods, the static methods and class methods can also be accessed using the class but unlike class methods, static methods are immutable via inheritance.","Related talk by Raymond Hettinger on the topic: youtube.com/watch?v=HTLu2DFOdTg","more precise youtube.com/watch?v=HTLu2DFOdTg&feature=youtu.be&t=2689 you only need classmethod for alternative constructors. Otherwise you can use staticmethod and access any class attribute (via . / dot) by the somehow more informative actual \"CLASSNAME\" instead of cls like in classmethod"],"answers":[{"answer":"Maybe a bit of example code will help: Notice the difference in the call signatures of foo, class_foo and static_foo:\n\nclass A(object):\n    def foo(self, x):\n        print(f\"executing foo({self}, {x})\")\n\n    @classmethod\n    def class_foo(cls, x):\n        print(f\"executing class_foo({cls}, {x})\")\n\n    @staticmethod\n    def static_foo(x):\n        print(f\"executing static_foo({x})\")\n\na = A()\n\n\nBelow is the usual way an object instance calls a method. The object instance, a, is implicitly passed as the first argument.\n\na.foo(1)\n# executing foo(<__main__.A object at 0xb7dbef0c>, 1)\n\n\nWith classmethods, the class of the object instance is implicitly passed as the first argument instead of self.\n\na.class_foo(1)\n# executing class_foo(<class '__main__.A'>, 1)\n\n\nYou can also call class_foo using the class. In fact, if you define something to be a classmethod, it is probably because you intend to call it from the class rather than from a class instance. A.foo(1) would have raised a TypeError, but A.class_foo(1) works just fine:\n\nA.class_foo(1)\n# executing class_foo(<class '__main__.A'>, 1)\n\n\nOne use people have found for class methods is to create inheritable alternative constructors.\n\nWith staticmethods, neither self (the object instance) nor cls (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:\n\na.static_foo(1)\n# executing static_foo(1)\n\nA.static_foo('hi')\n# executing static_foo(hi)\n\n\nStaticmethods are used to group functions which have some logical connection with a class to the class.\n\nfoo is just a function, but when you call a.foo you don't just get the function, you get a \"partially applied\" version of the function with the object instance a bound as the first argument to the function. foo expects 2 arguments, while a.foo only expects 1 argument.\n\na is bound to foo. That is what is meant by the term \"bound\" below:\n\nprint(a.foo)\n# <bound method A.foo of <__main__.A object at 0xb7d52f0c>>\n\n\nWith a.class_foo, a is not bound to class_foo, rather the class A is bound to class_foo.\n\nprint(a.class_foo)\n# <bound method type.class_foo of <class '__main__.A'>>\n\n\nHere, with a staticmethod, even though it is a method, a.static_foo just returns a good 'ole function with no arguments bound. static_foo expects 1 argument, and a.static_foo expects 1 argument too.\n\nprint(a.static_foo)\n# <function static_foo at 0xb7d479cc>\n\n\nAnd of course the same thing happens when you call static_foo with the class A instead.\n\nprint(A.static_foo)\n# <function static_foo at 0xb7d479cc>\n\nShare\nImprove this answer\nFollow\nedited Apr 12 at 8:43\nMike T\n35.4k16\n16 gold badges\n131\n131 silver badges\n172\n172 bronze badges\nanswered Nov 3 '09 at 19:13\nunutbu\n727k150\n150 gold badges\n1612\n1612 silver badges\n1557\n1557 bronze badges","comments":["I don't understand what's the catch for using staticmethod. we can just use a simple outside-of-class function.","@Alcott: You might want to move a function into a class because it logically belongs with the class. In the Python source code (e.g. multiprocessing,turtle,dist-packages), it is used to \"hide\" single-underscore \"private\" functions from the module namespace. Its use, though, is highly concentrated in just a few modules -- perhaps an indication that it is mainly a stylistic thing. Though I could not find any example of this, @staticmethod might help organize your code by being overridable by subclasses. Without it you'd have variants of the function floating around in the module namespace.","... along with some explanation on where and why to use either instance, class or static methods. You didn't give a single word about it, but neither did the OP asked about it.","@Alcott: as unutbu said, static methods are an organization/stylistic feature. Sometimes a module have many classes, and some helper functions are logically tied to a a given class and not to the others, so it makes sense not to \"pollute\" the module with many \"free functions\", and it is better to use a static method than relying on the poor style of mixing classes and function defs together in code just to show they are \"related\""]},{"answer":"A staticmethod is a method that knows nothing about the class or instance it was called on. It just gets the arguments that were passed, no implicit first argument. It is basically useless in Python -- you can just use a module function instead of a staticmethod.\n\nA classmethod, on the other hand, is a method that gets passed the class it was called on, or the class of the instance it was called on, as first argument. This is useful when you want the method to be a factory for the class: since it gets the actual class it was called on as first argument, you can always instantiate the right class, even when subclasses are involved. Observe for instance how dict.fromkeys(), a classmethod, returns an instance of the subclass when called on a subclass:\n\n>>> class DictSubclass(dict):\n...     def __repr__(self):\n...         return \"DictSubclass\"\n... \n>>> dict.fromkeys(\"abc\")\n{'a': None, 'c': None, 'b': None}\n>>> DictSubclass.fromkeys(\"abc\")\nDictSubclass\n>>> \n\nShare\nImprove this answer\nFollow\nedited May 27 '18 at 13:00\nBrian Burns\n15.5k5\n5 gold badges\n70\n70 silver badges\n63\n63 bronze badges\nanswered Sep 25 '08 at 21:05\nThomas Wouters\n120k21\n21 gold badges\n139\n139 silver badges\n118\n118 bronze badges","comments":["A staticmethod isn't useless - it's a way of putting a function into a class (because it logically belongs there), while indicating that it does not require access to the class.","Hence only 'basically' useless. Such organization, as well as dependency injection, are valid uses of staticmethods, but since modules, not classes like in Java, are the basic elements of code organization in Python, their use and usefulness is rare.","What's logical about defining a method inside a class, when it has nothing to do with either the class or its instances?","Perhaps for the inheritance sake? Static methods can be inherited and overridden just like instance methods and class methods and the lookup works as expected (unlike in Java). Static methods are not really resolved statically whether called on the class or instance, so the only difference between class and static methods is the implicit first argument.","They also create a cleaner namespace, and makes it easier to understand the function have something to do with the class."]},{"answer":"Basically @classmethod makes a method whose first argument is the class it's called from (rather than the class instance), @staticmethod does not have any implicit arguments.\n\nShare\nImprove this answer\nFollow\nedited Oct 8 '12 at 2:07\nTadeck\n119k25\n25 gold badges\n140\n140 silver badges\n190\n190 bronze badges\nanswered Sep 25 '08 at 21:07\nTerence Simpson\n3,9122\n2 gold badges\n18\n18 silver badges\n18\n18 bronze badges","comments":[]},{"answer":"Official python docs:\n\n@classmethod\n\nA class method receives the class as implicit first argument, just like an instance method receives the instance. To declare a class method, use this idiom:\n\nclass C:\n    @classmethod\n    def f(cls, arg1, arg2, ...): ... \n\n\nThe @classmethod form is a function decorator – see the description of function definitions in Function definitions for details.\n\nIt can be called either on the class (such as C.f()) or on an instance (such as C().f()). The instance is ignored except for its class. If a class method is called for a derived class, the derived class object is passed as the implied first argument.\n\nClass methods are different than C++ or Java static methods. If you want those, see staticmethod() in this section.\n\n@staticmethod\n\nA static method does not receive an implicit first argument. To declare a static method, use this idiom:\n\nclass C:\n    @staticmethod\n    def f(arg1, arg2, ...): ... \n\n\nThe @staticmethod form is a function decorator – see the description of function definitions in Function definitions for details.\n\nIt can be called either on the class (such as C.f()) or on an instance (such as C().f()). The instance is ignored except for its class.\n\nStatic methods in Python are similar to those found in Java or C++. For a more advanced concept, see classmethod() in this section.\n\nShare\nImprove this answer\nFollow\nedited Dec 11 '12 at 9:56\nme_and\n14.1k6\n6 gold badges\n59\n59 silver badges\n93\n93 bronze badges\nanswered Nov 3 '09 at 19:23\nChris B.\n2,3841\n1 gold badge\n14\n14 silver badges\n9\n9 bronze badges","comments":["Isn't there an error in docs? Shouldn't be at staticmethod: \"The instance and its class are both ignored.\" instead of \"The instance is ignored except for its class.\"?","It may be a cut-and-paste error, but strictly speaking you can't call a method on a class if you ignore the class."]},{"answer":"Here is a short article on this question\n\n@staticmethod function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It’s definition is immutable via inheritance.\n\n@classmethod function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance. That’s because the first argument for @classmethod function must always be cls (class).\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Nov 3 '09 at 19:02\nTom Neyland\n6,6212\n2 gold badges\n34\n34 silver badges\n52\n52 bronze badges","comments":["So does that mean that by using a staticmethod I am always bound to the Parent class and with the classmethod I am bound the class that I declare the classmethod in (in this case the sub class)?","No. By using a staticmethod you aren't bound at all; there is no implicit first parameter. By using classmethod, you get as implicit first parameter the class you called the method on (if you called it directly on a class), or the class of the instance you called the method on (if you called it on an instance).","Could be expanded a bit to show that, by having a class as a first argument, class methods have direct access to other class attributes and methods, while static methods do not (they would need to hardcode MyClass.attr for that)","\"It’s definition is immutable via inheritance.\" doesn't make any sense in Python, you can override a static method just fine."]},{"answer":"To decide whether to use @staticmethod or @classmethod you have to look inside your method. If your method accesses other variables/methods in your class then use @classmethod. On the other hand, if your method does not touches any other parts of the class then use @staticmethod.\n\nclass Apple:\n\n    _counter = 0\n\n    @staticmethod\n    def about_apple():\n        print('Apple is good for you.')\n\n        # note you can still access other member of the class\n        # but you have to use the class instance \n        # which is not very nice, because you have repeat yourself\n        # \n        # For example:\n        # @staticmethod\n        #    print('Number of apples have been juiced: %s' % Apple._counter)\n        #\n        # @classmethod\n        #    print('Number of apples have been juiced: %s' % cls._counter)\n        #\n        #    @classmethod is especially useful when you move your function to other class,\n        #       you don't have to rename the class reference \n\n    @classmethod\n    def make_apple_juice(cls, number_of_apples):\n        print('Make juice:')\n        for i in range(number_of_apples):\n            cls._juice_this(i)\n\n    @classmethod\n    def _juice_this(cls, apple):\n        print('Juicing %d...' % apple)\n        cls._counter += 1\n\nShare\nImprove this answer\nFollow\nedited Feb 5 '18 at 14:45\nanswered Apr 22 '16 at 15:40\nDu D.\n3,9191\n1 gold badge\n26\n26 silver badges\n33\n33 bronze badges","comments":["what would be the advantage of classmethod and cls._counter vs. staticmethod and Apple._counter","cls._counter would still be cls._counter even if the code is put in a different class, or the class name is changed. Apple._counter is specific for the Apple class; for a different class, or when the class name is changed, you would need to change the referenced class."]},{"answer":"What is the difference between @staticmethod and @classmethod in Python?\n\nYou may have seen Python code like this pseudocode, which demonstrates the signatures of the various method types and provides a docstring to explain each:\n\nclass Foo(object):\n\n    def a_normal_instance_method(self, arg_1, kwarg_2=None):\n        '''\n        Return a value that is a function of the instance with its\n        attributes, and other arguments such as arg_1 and kwarg2\n        '''\n\n    @staticmethod\n    def a_static_method(arg_0):\n        '''\n        Return a value that is a function of arg_0. It does not know the \n        instance or class it is called from.\n        '''\n\n    @classmethod\n    def a_class_method(cls, arg1):\n        '''\n        Return a value that is a function of the class and other arguments.\n        respects subclassing, it is called with the class it is called from.\n        '''\n\nThe Normal Instance Method\n\nFirst I'll explain a_normal_instance_method. This is precisely called an \"instance method\". When an instance method is used, it is used as a partial function (as opposed to a total function, defined for all values when viewed in source code) that is, when used, the first of the arguments is predefined as the instance of the object, with all of its given attributes. It has the instance of the object bound to it, and it must be called from an instance of the object. Typically, it will access various attributes of the instance.\n\nFor example, this is an instance of a string:\n\n', '\n\n\nif we use the instance method, join on this string, to join another iterable, it quite obviously is a function of the instance, in addition to being a function of the iterable list, ['a', 'b', 'c']:\n\n>>> ', '.join(['a', 'b', 'c'])\n'a, b, c'\n\nBound methods\n\nInstance methods can be bound via a dotted lookup for use later.\n\nFor example, this binds the str.join method to the ':' instance:\n\n>>> join_with_colons = ':'.join \n\n\nAnd later we can use this as a function that already has the first argument bound to it. In this way, it works like a partial function on the instance:\n\n>>> join_with_colons('abcde')\n'a:b:c:d:e'\n>>> join_with_colons(['FF', 'FF', 'FF', 'FF', 'FF', 'FF'])\n'FF:FF:FF:FF:FF:FF'\n\nStatic Method\n\nThe static method does not take the instance as an argument.\n\nIt is very similar to a module level function.\n\nHowever, a module level function must live in the module and be specially imported to other places where it is used.\n\nIf it is attached to the object, however, it will follow the object conveniently through importing and inheritance as well.\n\nAn example of a static method is str.maketrans, moved from the string module in Python 3. It makes a translation table suitable for consumption by str.translate. It does seem rather silly when used from an instance of a string, as demonstrated below, but importing the function from the string module is rather clumsy, and it's nice to be able to call it from the class, as in str.maketrans\n\n# demonstrate same function whether called from instance or not:\n>>> ', '.maketrans('ABC', 'abc')\n{65: 97, 66: 98, 67: 99}\n>>> str.maketrans('ABC', 'abc')\n{65: 97, 66: 98, 67: 99}\n\n\nIn python 2, you have to import this function from the increasingly less useful string module:\n\n>>> import string\n>>> 'ABCDEFG'.translate(string.maketrans('ABC', 'abc'))\n'abcDEFG'\n\nClass Method\n\nA class method is a similar to an instance method in that it takes an implicit first argument, but instead of taking the instance, it takes the class. Frequently these are used as alternative constructors for better semantic usage and it will support inheritance.\n\nThe most canonical example of a builtin classmethod is dict.fromkeys. It is used as an alternative constructor of dict, (well suited for when you know what your keys are and want a default value for them.)\n\n>>> dict.fromkeys(['a', 'b', 'c'])\n{'c': None, 'b': None, 'a': None}\n\n\nWhen we subclass dict, we can use the same constructor, which creates an instance of the subclass.\n\n>>> class MyDict(dict): 'A dict subclass, use to demo classmethods'\n>>> md = MyDict.fromkeys(['a', 'b', 'c'])\n>>> md\n{'a': None, 'c': None, 'b': None}\n>>> type(md)\n<class '__main__.MyDict'>\n\n\nSee the pandas source code for other similar examples of alternative constructors, and see also the official Python documentation on classmethod and staticmethod.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jan 23 '15 at 20:01\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":[]},{"answer":"I started learning programming language with C++ and then Java and then Python and so this question bothered me a lot as well, until I understood the simple usage of each.\n\nClass Method: Python unlike Java and C++ doesn't have constructor overloading. And so to achieve this you could use classmethod. Following example will explain this\n\nLet's consider we have a Person class which takes two arguments first_name and last_name and creates the instance of Person.\n\nclass Person(object):\n\n    def __init__(self, first_name, last_name):\n        self.first_name = first_name\n        self.last_name = last_name\n\n\nNow, if the requirement comes where you need to create a class using a single name only, just a first_name, you can't do something like this in Python.\n\nThis will give you an error when you will try to create an object (instance).\n\nclass Person(object):\n\n    def __init__(self, first_name, last_name):\n        self.first_name = first_name\n        self.last_name = last_name\n\n    def __init__(self, first_name):\n        self.first_name = first_name\n\n\nHowever, you could achieve the same thing using @classmethod as mentioned below\n\nclass Person(object):\n\n    def __init__(self, first_name, last_name):\n        self.first_name = first_name\n        self.last_name = last_name\n\n    @classmethod\n    def get_person(cls, first_name):\n        return cls(first_name, \"\")\n\n\nStatic Method: This is rather simple, it's not bound to instance or class and you can simply call that using class name.\n\nSo let's say in above example you need a validation that first_name should not exceed 20 characters, you can simply do this.\n\n@staticmethod  \ndef validate_name(name):\n    return len(name) <= 20\n\n\nand you could simply call using class name\n\nPerson.validate_name(\"Gaurang Shah\")\n\nShare\nImprove this answer\nFollow\nedited Apr 16 '19 at 14:21\nMui Vsky\n31\n1 silver badge\n6\n6 bronze badges\nanswered Oct 10 '17 at 10:10\nGaurang Shah\n9,0553\n3 gold badges\n49\n49 silver badges\n97\n97 bronze badges","comments":["It's an old post, but more pythonic way to achieve constructor accepting either one or two arguments would be using def __init__(self, first_name, last_name=\"\") instead of classmethod get_person. Also result will be exactly the same in this case."]},{"answer":"I think a better question is \"When would you use @classmethod vs @staticmethod?\"\n\n@classmethod allows you easy access to private members that are associated to the class definition. this is a great way to do singletons, or factory classes that control the number of instances of the created objects exist.\n\n@staticmethod provides marginal performance gains, but I have yet to see a productive use of a static method within a class that couldn't be achieved as a standalone function outside the class.\n\nShare\nImprove this answer\nFollow\nedited Aug 13 '20 at 21:32\njoel\n3,5871\n1 gold badge\n21\n21 silver badges\n40\n40 bronze badges\nanswered May 19 '15 at 15:27\nNathan Tregillus\n5,4082\n2 gold badges\n44\n44 silver badges\n73\n73 bronze badges","comments":["This question mentions access of private class members. I want to highlight that (depending on your definition of private), @staticmethods have a different access level to @classmethods. The former shouldn't access class private class members"]},{"answer":"Static Methods:\n\nSimple functions with no self argument.\nWork on class attributes; not on instance attributes.\nCan be called through both class and instance.\nThe built-in function staticmethod()is used to create them.\n\nBenefits of Static Methods:\n\nIt localizes the function name in the classscope\nIt moves the function code closer to where it is used\n\nMore convenient to import versus module-level functions since each method does not have to be specially imported\n\n@staticmethod\ndef some_static_method(*args, **kwds):\n    pass\n\n\nClass Methods:\n\nFunctions that have first argument as classname.\nCan be called through both class and instance.\n\nThese are created with classmethod in-built function.\n\n @classmethod\n def some_class_method(cls, *args, **kwds):\n     pass\n\nShare\nImprove this answer\nFollow\nedited Jul 14 '17 at 3:10\nJonathan B.\n1,98415\n15 silver badges\n17\n17 bronze badges\nanswered Oct 3 '16 at 10:41\nLaxmi\n3,59921\n21 silver badges\n30\n30 bronze badges","comments":[]},{"answer":"Only the first argument differs:\n\nnormal method: the current object is automatically passed as an (additional) first argument\nclassmethod: the class of the current object is automatically passed as an (additional) fist argument\nstaticmethod: no extra arguments are automatically passed. What you passed to the function is what you get.\n\nIn more detail...\n\nnormal method\n\nThe \"standard\" method, as in every object oriented language. When an object's method is called, it is automatically given an extra argument self as its first argument. That is, method\n\ndef f(self, x, y)\n\n\nmust be called with 2 arguments. self is automatically passed, and it is the object itself. Similar to the this that magically appears in eg. java/c++, only in python it is shown explicitly.\n\nactually, the first argument does not have to be called self, but it's the standard convention, so keep it\n\nclass method\n\nWhen the method is decorated\n\n@classmethod\ndef f(cls, x, y)\n\n\nthe automatically provided argument is not self, but the class of self.\n\nstatic method\n\nWhen the method is decorated\n\n@staticmethod\ndef f(x, y)\n\n\nthe method is not given any automatic argument at all. It is only given the parameters that it is called with.\n\nusages\nclassmethod is mostly used for alternative constructors.\nstaticmethod does not use the state of the object, or even the structure of the class itself. It could be a function external to a class. It only put inside the class for grouping functions with similar functionality (for example, like Java's Math class static methods)\nclass Point\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    @classmethod\n    def frompolar(cls, radius, angle):\n        \"\"\"The `cls` argument is the `Point` class itself\"\"\"\n        return cls(radius * cos(angle), radius * sin(angle))\n\n    @staticmethod\n    def angle(x, y):\n        \"\"\"this could be outside the class, but we put it here \njust because we think it is logically related to the class.\"\"\"\n        return atan(y, x)\n\n\np1 = Point(3, 2)\np2 = Point.frompolar(3, pi/4)\n\nangle = Point.angle(3, 2)\n\n\nShare\nImprove this answer\nFollow\nedited Aug 17 at 7:47\nanswered May 21 '19 at 10:47\nblue_note\n23.3k6\n6 gold badges\n50\n50 silver badges\n71\n71 bronze badges","comments":[]},{"answer":"@decorators were added in python 2.4 If you're using python < 2.4 you can use the classmethod() and staticmethod() function.\n\nFor example, if you want to create a factory method (A function returning an instance of a different implementation of a class depending on what argument it gets) you can do something like:\n\nclass Cluster(object):\n\n    def _is_cluster_for(cls, name):\n        \"\"\"\n        see if this class is the cluster with this name\n        this is a classmethod\n        \"\"\" \n        return cls.__name__ == name\n    _is_cluster_for = classmethod(_is_cluster_for)\n\n    #static method\n    def getCluster(name):\n        \"\"\"\n        static factory method, should be in Cluster class\n        returns a cluster object for the given name\n        \"\"\"\n        for cls in Cluster.__subclasses__():\n            if cls._is_cluster_for(name):\n                return cls()\n    getCluster = staticmethod(getCluster)\n\n\nAlso observe that this is a good example for using a classmethod and a static method, The static method clearly belongs to the class, since it uses the class Cluster internally. The classmethod only needs information about the class, and no instance of the object.\n\nAnother benefit of making the _is_cluster_for method a classmethod is so a subclass can decide to change it's implementation, maybe because it is pretty generic and can handle more than one type of cluster, so just checking the name of the class would not be enough.\n\nShare\nImprove this answer\nFollow\nedited Feb 20 '17 at 15:34\nanswered Feb 24 '12 at 9:32\nJens Timmerman\n7,6581\n1 gold badge\n35\n35 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"Let me tell the similarity between a method decorated with @classmethod vs @staticmethod first.\n\nSimilarity: Both of them can be called on the Class itself, rather than just the instance of the class. So, both of them in a sense are Class's methods.\n\nDifference: A classmethod will receive the class itself as the first argument, while a staticmethod does not.\n\nSo a static method is, in a sense, not bound to the Class itself and is just hanging in there just because it may have a related functionality.\n\n>>> class Klaus:\n        @classmethod\n        def classmthd(*args):\n            return args\n\n        @staticmethod\n        def staticmthd(*args):\n            return args\n\n# 1. Call classmethod without any arg\n>>> Klaus.classmthd()  \n(__main__.Klaus,)  # the class gets passed as the first argument\n\n# 2. Call classmethod with 1 arg\n>>> Klaus.classmthd('chumma')\n(__main__.Klaus, 'chumma')\n\n# 3. Call staticmethod without any arg\n>>> Klaus.staticmthd()  \n()\n\n# 4. Call staticmethod with 1 arg\n>>> Klaus.staticmthd('chumma')\n('chumma',)\n\nShare\nImprove this answer\nFollow\nedited Nov 8 '18 at 3:36\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered Jan 14 '18 at 14:07\nSelva\n1,83719\n19 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"@staticmethod just disables the default function as method descriptor. classmethod wraps your function in a container callable that passes a reference to the owning class as first argument:\n\n>>> class C(object):\n...  pass\n... \n>>> def f():\n...  pass\n... \n>>> staticmethod(f).__get__(None, C)\n<function f at 0x5c1cf0>\n>>> classmethod(f).__get__(None, C)\n<bound method type.f of <class '__main__.C'>>\n\n\nAs a matter of fact, classmethod has a runtime overhead but makes it possible to access the owning class. Alternatively I recommend using a metaclass and putting the class methods on that metaclass:\n\n>>> class CMeta(type):\n...  def foo(cls):\n...   print cls\n... \n>>> class C(object):\n...  __metaclass__ = CMeta\n... \n>>> C.foo()\n<class '__main__.C'>\n\nShare\nImprove this answer\nFollow\nanswered Sep 25 '08 at 21:24\nArmin Ronacher\n30.5k12\n12 gold badges\n63\n63 silver badges\n69\n69 bronze badges","comments":["One possible downside of a metaclass for this that immediately occurs to me is that you can't call the classmethod directly on an instance. c = C(); c.foo() raises AttributeError, you'd have to do type(c).foo(). This might also be considered a feature - I can't think of why you'd want to though."]},{"answer":"The definitive guide on how to use static, class or abstract methods in Python is one good link for this topic, and summary it as following.\n\n@staticmethod function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It’s definition is immutable via inheritance.\n\nPython does not have to instantiate a bound-method for object.\nIt eases the readability of the code, and it does not depend on the state of object itself;\n\n@classmethod function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance, can be overridden by subclass. That’s because the first argument for @classmethod function must always be cls (class).\n\nFactory methods, that are used to create an instance for a class using for example some sort of pre-processing.\nStatic methods calling static methods: if you split a static methods in several static methods, you shouldn't hard-code the class name but use class methods\nShare\nImprove this answer\nFollow\nedited Jul 12 '17 at 15:21\nMarianD\n9,9609\n9 gold badges\n27\n27 silver badges\n44\n44 bronze badges\nanswered Nov 16 '15 at 2:00\nzangw\n34.7k17\n17 gold badges\n132\n132 silver badges\n157\n157 bronze badges","comments":["Thanks @zangw - the inherited immutability of static function is the key difference it seems"]},{"answer":"Another consideration with respect to staticmethod vs classmethod comes up with inheritance. Say you have the following class:\n\nclass Foo(object):\n    @staticmethod\n    def bar():\n        return \"In Foo\"\n\n\nAnd you then want to override bar() in a child class:\n\nclass Foo2(Foo):\n    @staticmethod\n    def bar():\n        return \"In Foo2\"\n\n\nThis works, but note that now the bar() implementation in the child class (Foo2) can no longer take advantage of anything specific to that class. For example, say Foo2 had a method called magic() that you want to use in the Foo2 implementation of bar():\n\nclass Foo2(Foo):\n    @staticmethod\n    def bar():\n        return \"In Foo2\"\n    @staticmethod\n    def magic():\n        return \"Something useful you'd like to use in bar, but now can't\" \n\n\nThe workaround here would be to call Foo2.magic() in bar(), but then you're repeating yourself (if the name of Foo2 changes, you'll have to remember to update that bar() method).\n\nTo me, this is a slight violation of the open/closed principle, since a decision made in Foo is impacting your ability to refactor common code in a derived class (ie it's less open to extension). If bar() were a classmethod we'd be fine:\n\nclass Foo(object):\n    @classmethod\n    def bar(cls):\n        return \"In Foo\"\n\nclass Foo2(Foo):\n    @classmethod\n    def bar(cls):\n        return \"In Foo2 \" + cls.magic()\n    @classmethod\n    def magic(cls):\n        return \"MAGIC\"\n\nprint Foo2().bar()\n\n\nGives: In Foo2 MAGIC\n\nAlso: historical note: Guido Van Rossum (Python's creator) once referred to staticmethod's as \"an accident\": https://mail.python.org/pipermail/python-ideas/2012-May/014969.html\n\nwe all know how limited static methods are. (They're basically an accident -- back in the Python 2.2 days when I was inventing new-style classes and descriptors, I meant to implement class methods but at first I didn't understand them and accidentally implemented static methods first. Then it was too late to remove them and only provide class methods.\n\nAlso: https://mail.python.org/pipermail/python-ideas/2016-July/041189.html\n\nHonestly, staticmethod was something of a mistake -- I was trying to do something like Java class methods but once it was released I found what was really needed was classmethod. But it was too late to get rid of staticmethod.\n\nShare\nImprove this answer\nFollow\nedited Feb 10 at 21:13\nanswered Sep 29 '16 at 17:02\nAdam Parkin\n15.2k14\n14 gold badges\n58\n58 silver badges\n84\n84 bronze badges","comments":[]},{"answer":"I will try to explain the basic difference using an example.\n\nclass A(object):\n    x = 0\n\n    def say_hi(self):\n        pass\n\n    @staticmethod\n    def say_hi_static():\n        pass\n\n    @classmethod\n    def say_hi_class(cls):\n        pass\n\n    def run_self(self):\n        self.x += 1\n        print self.x # outputs 1\n        self.say_hi()\n        self.say_hi_static()\n        self.say_hi_class()\n\n    @staticmethod\n    def run_static():\n        print A.x  # outputs 0\n        # A.say_hi() #  wrong\n        A.say_hi_static()\n        A.say_hi_class()\n\n    @classmethod\n    def run_class(cls):\n        print cls.x # outputs 0\n        # cls.say_hi() #  wrong\n        cls.say_hi_static()\n        cls.say_hi_class()\n\n\n1 - we can directly call static and classmethods without initializing\n\n# A.run_self() #  wrong\nA.run_static()\nA.run_class()\n\n\n2- Static method cannot call self method but can call other static and classmethod\n\n3- Static method belong to class and will not use object at all.\n\n4- Class method are not bound to an object but to a class.\n\nShare\nImprove this answer\nFollow\nanswered Sep 20 '16 at 9:03\nRizwan Mumtaz\n3,4352\n2 gold badges\n24\n24 silver badges\n28\n28 bronze badges","comments":["ad 2: Are you sure? How could the staticmethod call the classmethod? It has no reference to it (to its class)."]},{"answer":"@classmethod : can be used to create a shared global access to all the instances created of that class..... like updating a record by multiple users.... I particulary found it use ful when creating singletons as well..:)\n\n@static method: has nothing to do with the class or instance being associated with ...but for readability can use static method\n\nShare\nImprove this answer\nFollow\nedited Sep 20 '17 at 17:07\nanswered Sep 20 '17 at 16:57\nvijay\n991\n1 silver badge\n7\n7 bronze badges","comments":[]},{"answer":"A class method receives the class as implicit first argument, just like an instance method receives the instance. It is a method which is bound to the class and not the object of the class.It has access to the state of the class as it takes a class parameter that points to the class and not the object instance. It can modify a class state that would apply across all the instances of the class. For example it can modify a class variable that will be applicable to all the instances.\n\nOn the other hand, a static method does not receive an implicit first argument, compared to class methods or instance methods. And can’t access or modify class state. It only belongs to the class because from design point of view that is the correct way. But in terms of functionality is not bound, at runtime, to the class.\n\nas a guideline, use static methods as utilities, use class methods for example as factory . Or maybe to define a singleton. And use instance methods to model the state and behavior of instances.\n\nHope I was clear !\n\nShare\nImprove this answer\nFollow\nanswered Nov 20 '19 at 11:48\nNicolae Petridean\n5465\n5 silver badges\n10\n10 bronze badges","comments":[]},{"answer":"You might want to consider the difference between:\n\nclass A:\n    def foo():  # no self parameter, no decorator\n        pass\n\n\nand\n\nclass B:\n    @staticmethod\n    def foo():  # no self parameter\n        pass\n\n\nThis has changed between python2 and python3:\n\npython2:\n\n>>> A.foo()\nTypeError\n>>> A().foo()\nTypeError\n>>> B.foo()\n>>> B().foo()\n\n\npython3:\n\n>>> A.foo()\n>>> A().foo()\nTypeError\n>>> B.foo()\n>>> B().foo()\n\n\nSo using @staticmethod for methods only called directly from the class has become optional in python3. If you want to call them from both class and instance, you still need to use the @staticmethod decorator.\n\nThe other cases have been well covered by unutbus answer.\n\nShare\nImprove this answer\nFollow\nedited Sep 14 '20 at 12:00\nanswered Jan 24 '19 at 12:56\nDavid Schumann\n9,7146\n6 gold badges\n59\n59 silver badges\n80\n80 bronze badges","comments":[]},{"answer":"My contribution demonstrates the difference amongst @classmethod, @staticmethod, and instance methods, including how an instance can indirectly call a @staticmethod. But instead of indirectly calling a @staticmethod from an instance, making it private may be more \"pythonic.\" Getting something from a private method isn't demonstrated here but it's basically the same concept.\n\n#!python3\n\nfrom os import system\nsystem('cls')\n# %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %\n\nclass DemoClass(object):\n    # instance methods need a class instance and\n    # can access the instance through 'self'\n    def instance_method_1(self):\n        return 'called from inside the instance_method_1()'\n\n    def instance_method_2(self):\n        # an instance outside the class indirectly calls the static_method\n        return self.static_method() + ' via instance_method_2()'\n\n    # class methods don't need a class instance, they can't access the\n    # instance (self) but they have access to the class itself via 'cls'\n    @classmethod\n    def class_method(cls):\n        return 'called from inside the class_method()'\n\n    # static methods don't have access to 'cls' or 'self', they work like\n    # regular functions but belong to the class' namespace\n    @staticmethod\n    def static_method():\n        return 'called from inside the static_method()'\n# %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %\n\n# works even if the class hasn't been instantiated\nprint(DemoClass.class_method() + '\\n')\n''' called from inside the class_method() '''\n\n# works even if the class hasn't been instantiated\nprint(DemoClass.static_method() + '\\n')\n''' called from inside the static_method() '''\n# %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %\n\n# >>>>> all methods types can be called on a class instance <<<<<\n# instantiate the class\ndemoclassObj = DemoClass()\n\n# call instance_method_1()\nprint(democlassObj.instance_method_1() + '\\n')\n''' called from inside the instance_method_1() '''\n\n# # indirectly call static_method through instance_method_2(), there's really no use\n# for this since a @staticmethod can be called whether the class has been\n# instantiated or not\nprint(democlassObj.instance_method_2() + '\\n')\n''' called from inside the static_method() via instance_method_2() '''\n\n# call class_method()\nprint(democlassObj.class_method() + '\\n')\n'''  called from inside the class_method() '''\n\n# call static_method()\nprint(democlassObj.static_method())\n''' called from inside the static_method() '''\n\n\"\"\"\n# whether the class is instantiated or not, this doesn't work\nprint(DemoClass.instance_method_1() + '\\n')\n'''\nTypeError: TypeError: unbound method instancemethod() must be called with\nDemoClass instance as first argument (got nothing instead)\n'''\n\"\"\"\n\nShare\nImprove this answer\nFollow\nanswered Jun 25 '18 at 2:38\nMichael Swartz\n7831\n1 gold badge\n12\n12 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"Instance Method:\n\n+ Can modify object instance state\n\n+ Can modify class state\n\nClass Method:\n\n- Can't modify object instance state\n\n+ Can modify class state\n\nStatic Method:\n\n- Can't modify object instance state\n\n- Can't modify class state\n\nclass MyClass:\n    ''' \n    Instance method has a mandatory first attribute self which represent the instance itself. \n    Instance method must be called by a instantiated instance.\n    '''\n    def method(self):\n        return 'instance method called', self\n    \n    '''\n    Class method has a mandatory first attribute cls which represent the class itself. \n    Class method can be called by an instance or by the class directly. \n    Its most common using scenario is to define a factory method.\n    '''\n    @classmethod\n    def class_method(cls):\n        return 'class method called', cls\n    \n    '''\n    Static method doesn’t have any attributes of instances or the class. \n    It also can be called by an instance or by the class directly. \n    Its most common using scenario is to define some helper or utility functions which are closely relative to the class.\n    '''\n    @staticmethod\n    def static_method():\n        return 'static method called'\n\n\nobj = MyClass()\nprint(obj.method())\nprint(obj.class_method()) # MyClass.class_method()\nprint(obj.static_method()) # MyClass.static_method()\n\n\noutput:\n\n('instance method called', <__main__.MyClass object at 0x100fb3940>)\n('class method called', <class '__main__.MyClass'>)\nstatic method called\n\n\nThe instance method we actually had access to the object instance , right so this was an instance off a my class object whereas with the class method we have access to the class itself. But not to any of the objects, because the class method doesn't really care about an object existing. However you can both call a class method and static method on an object instance. This is going to work it doesn't really make a difference, so again when you call static method here it's going to work and it's going to know which method you want to call.\n\nThe Static methods are used to do some utility tasks, and class methods are used for factory methods. The factory methods can return class objects for different use cases.\n\nAnd finally, a short example for better understanding:\n\nclass Student:\n    def __init__(self, first_name, last_name):\n        self.first_name = first_name\n        self.last_name = last_name\n\n    @classmethod\n    def get_from_string(cls, name_string: str):\n        first_name, last_name = name_string.split()\n        if Student.validate_name(first_name) and Student.validate_name(last_name):\n            return cls(first_name, last_name)\n        else:\n            print('Invalid Names')\n\n    @staticmethod\n    def validate_name(name):\n        return len(name) <= 10\n\n\nstackoverflow_student = Student.get_from_string('Name Surname')\nprint(stackoverflow_student.first_name) # Name\nprint(stackoverflow_student.last_name) # Surname\n\nShare\nImprove this answer\nFollow\nedited Nov 7 '20 at 20:33\nanswered Nov 7 '20 at 20:16\nMilovan Tomašević\n1,7561\n1 gold badge\n15\n15 silver badges\n16\n16 bronze badges","comments":[]},{"answer":"The difference occurs when there is inheritance.\n\nSuppose that there are two classes-- Parent and Child. If one wants to use @staticmethod, print_name method should be written twice because the name of the class should be written in the print line.\n\nclass Parent:\n   _class_name = \"Parent\"\n\n   @staticmethod\n   def print_name():\n       print(Parent._class_name)\n\n\nclass Child(Parent):\n   _class_name = \"Child\"\n\n   @staticmethod\n   def print_name():\n       print(Child._class_name)\n\n\nParent.print_name()\nChild.print_name()\n\n\nHowever, for @classmethod, it is not required to write print_name method twice.\n\nclass Parent:\n    _class_name = \"Parent\"\n\n    @classmethod\n    def print_name(cls):\n        print(cls._class_name)\n\n\nclass Child(Parent):\n    _class_name = \"Child\"\n\n\nParent.print_name()\nChild.print_name()\n\nShare\nImprove this answer\nFollow\nanswered Mar 17 at 11:25\nH.H\n1761\n1 silver badge\n8\n8 bronze badges","comments":["Liked very much the simplicity of this answer. Wish could have given 100 votes for it."]},{"answer":"Analyze @staticmethod literally providing different insights.\n\nA normal method of a class is an implicit dynamic method which takes the instance as first argument.\nIn contrast, a staticmethod does not take the instance as first argument, so is called 'static'.\n\nA staticmethod is indeed such a normal function the same as those outside a class definition.\nIt is luckily grouped into the class just in order to stand closer where it is applied, or you might scroll around to find it.\n\nShare\nImprove this answer\nFollow\nedited Dec 12 '17 at 11:18\nanswered Dec 12 '17 at 9:40\nAbstProcDo\n15k14\n14 gold badges\n54\n54 silver badges\n99\n99 bronze badges","comments":[]},{"answer":"I think giving a purely Python version of staticmethod and classmethod would help to understand the difference between them at language level.\n\nBoth of them are non-data descriptors (It would be easier to understand them if you are familiar with descriptors first).\n\nclass StaticMethod(object):\n    \"Emulate PyStaticMethod_Type() in Objects/funcobject.c\"\n\n    def __init__(self, f):\n        self.f = f\n\n    def __get__(self, obj, objtype=None):\n        return self.f\n\n\nclass ClassMethod(object):\n    \"Emulate PyClassMethod_Type() in Objects/funcobject.c\"\n    def __init__(self, f):\n        self.f = f\n\n    def __get__(self, obj, cls=None):\n        def inner(*args, **kwargs):\n            if cls is None:\n                cls = type(obj)\n            return self.f(cls, *args, **kwargs)\n        return inner\n\nShare\nImprove this answer\nFollow\nanswered Nov 20 '19 at 9:50\nJacky1205\n2,7871\n1 gold badge\n14\n14 silver badges\n34\n34 bronze badges","comments":[]},{"answer":"Class methods, as the name suggests, are used to make changes to classes and not the objects. To make changes to classes, they will modify the class attributes(not object attributes), since that is how you update classes. This is the reason that class methods take the class(conventionally denoted by 'cls') as the first argument.\n\nclass A(object):\n    m=54\n\n    @classmethod\n    def class_method(cls):\n        print \"m is %d\" % cls.m\n\n\nStatic methods on the other hand, are used to perform functionalities that are not bound to the class i.e. they will not read or write class variables. Hence, static methods do not take classes as arguments. They are used so that classes can perform functionalities that are not directly related to the purpose of the class.\n\nclass X(object):\n    m=54 #will not be referenced\n\n    @staticmethod\n    def static_method():\n        print \"Referencing/calling a variable or function outside this class. E.g. Some global variable/function.\"\n\nShare\nImprove this answer\nFollow\nanswered Dec 1 '17 at 10:38\nTushar Vazirani\n8069\n9 silver badges\n13\n13 bronze badges","comments":["methods don't always make changes"]},{"answer":"One pretty important practical difference occurs when subclassing. If you don't mind, I'll hijack @unutbu's example:\n\nclass A: \n    def foo(self, x): \n        print(\"executing foo(%s, %s)\" % (self, x)) \n \n    @classmethod\n    def class_foo(cls, x): \n        print(\"executing class_foo(%s, %s)\" % (cls, x))\n \n    @staticmethod \n    def static_foo(x): \n        print(\"executing static_foo(%s)\" % x)\n\nclass B(A):\n    pass\n\n\nIn class_foo, the method knows which class it is called on:\n\nA.class_foo(1)\n# => executing class_foo(<class '__main__.A'>, 1)\nB.class_foo(1)\n# => executing class_foo(<class '__main__.B'>, 1)\n\n\nIn static_foo, there is no way to determine whether it is called on A or B:\n\nA.static_foo(1)\n# => executing static_foo(1)\nB.static_foo(1)\n# => executing static_foo(1)\n\n\nNote that this doesn't mean you can't use other methods in a staticmethod, you just have to reference the class directly, which means subclasses' staticmethods will still reference the parent class:\n\nclass A:\n    @classmethod\n    def class_qux(cls, x):\n        print(f\"executing class_qux({cls}, {x})\")\n    \n    @classmethod\n    def class_bar(cls, x):\n        cls.class_qux(x)\n\n    @staticmethod\n    def static_bar(x):\n        A.class_qux(x)\n\nclass B(A):\n    pass\n\nA.class_bar(1)\n# => executing class_qux(<class '__main__.A'>, 1)\nB.class_bar(1)\n# => executing class_qux(<class '__main__.B'>, 1)\nA.static_bar(1)\n# => executing class_qux(<class '__main__.A'>, 1)\nB.static_bar(1)\n# => executing class_qux(<class '__main__.A'>, 1)\n\nShare\nImprove this answer\nFollow\nanswered Jul 31 '20 at 18:12\nAle\n1,92018\n18 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"First let's start with an example code that we'll use to understand both concepts:\n\nclass Employee:\n\n    NO_OF_EMPLOYEES = 0\n  \n    def __init__(self, first_name, last_name, salary):\n        self.first_name = first_name\n        self.last_name = last_name\n        self.salary = salary\n        self.increment_employees()\n\n    def give_raise(self, amount):\n        self.salary += amount\n\n    @classmethod\n    def employee_from_full_name(cls, full_name, salary):\n        split_name = full_name.split(' ')\n        first_name = split_name[0]\n        last_name = split_name[1]\n        return cls(first_name, last_name, salary)\n\n    @classmethod\n    def increment_employees(cls):\n        cls.NO_OF_EMPLOYEES += 1\n\n    @staticmethod\n    def get_employee_legal_obligations_txt():\n        legal_obligations = \"\"\"\n        1. An employee must complete 8 hours per working day\n        2. ...\n        \"\"\"\n        return legal_obligations\n\n\nClass method\n\nA class method accepts the class itself as an implicit argument and -optionally- any other arguments specified in the definition. It’s important to understand that a class method, does not have access to object instances (like instance methods do). Therefore, class methods cannot be used to alter the state of an instantiated object but instead, they are capable of changing the class state which is shared amongst all the instances of that class. Class methods are typically useful when we need to access the class itself — for example, when we want to create a factory method, that is a method that creates instances of the class. In other words, class methods can serve as alternative constructors.\n\nIn our example code, an instance of Employee can be constructed by providing three arguments; first_name , last_name and salary.\n\nemployee_1 = Employee('Andrew', 'Brown', 85000)\nprint(employee_1.first_name)\nprint(employee_1.salary)\n\n'Andrew'\n85000\n\n\nNow let’s assume that there’s a chance that the name of an Employee can be provided in a single field in which the first and last names are separated by a whitespace. In this case, we could possibly use our class method called employee_from_full_name that accepts three arguments in total. The first one, is the class itself, which is an implicit argument which means that it won’t be provided when calling the method — Python will automatically do this for us:\n\nemployee_2 = Employee.employee_from_full_name('John Black', 95000)\nprint(employee_2.first_name)\nprint(employee_2.salary)\n\n'John'\n95000\n\n\nNote that it is also possible to call employee_from_full_name from object instances although in this context it doesn’t make a lot of sense:\n\nemployee_1 = Employee('Andrew', 'Brown', 85000)\nemployee_2 = employee_1.employee_from_full_name('John Black', 95000)\n\n\nAnother reason why we might want to create a class method, is when we need to change the state of the class. In our example, the class variable NO_OF_EMPLOYEES keeps track of the number of employees currently working for the company. This method is called every time a new instance of Employee is created and it updates the count accordingly:\n\nemployee_1 = Employee('Andrew', 'Brown', 85000)\nprint(f'Number of employees: {Employee.NO_OF_EMPLOYEES}')\nemployee_2 = Employee.employee_from_full_name('John Black', 95000)\nprint(f'Number of employees: {Employee.NO_OF_EMPLOYEES}')\n\nNumber of employees: 1\nNumber of employees: 2\n\n\nStatic methods\n\nOn the other hand, in static methods neither the instance (i.e. self) nor the class itself (i.e. cls) is passed as an implicit argument. This means that such methods, are not capable of accessing the class itself or its instances. Now one could argue that static methods are not useful in the context of classes as they can also be placed in helper modules instead of adding them as members of the class. In object oriented programming, it is important to structure your classes into logical chunks and thus, static methods are quite useful when we need to add a method under a class simply because it logically belongs to the class. In our example, the static method named get_employee_legal_obligations_txt simply returns a string that contains the legal obligations of every single employee of a company. This function, does not interact with the class itself nor with any instance. It could have been placed into a different helper module however, it is only relevant to this class and therefore we have to place it under the Employee class.\n\nA static method can be access directly from the class itself\n\nprint(Employee.get_employee_legal_obligations_txt())\n\n\n    1. An employee must complete 8 hours per working day\n    2. ...\n\n\nor from an instance of the class:\n\nemployee_1 = Employee('Andrew', 'Brown', 85000)\nprint(employee_1.get_employee_legal_obligations_txt())\n\n\n    1. An employee must complete 8 hours per working day\n    2. ...\n\n\nReferences\n\nWhat's the difference between static and class methods in Python?\nShare\nImprove this answer\nFollow\nedited Feb 4 at 16:10\nanswered Feb 4 at 16:00\nGiorgos Myrianthous\n25.4k10\n10 gold badges\n86\n86 silver badges\n118\n118 bronze badges","comments":[]},{"answer":"staticmethod has no access to attibutes of the object, of the class, or of parent classes in the inheritance hierarchy. It can be called at the class directly (without creating an object).\n\nclassmethod has no access to attributes of the object. It however can access attributes of the class and of parent classes in the inheritance hierarchy. It can be called at the class directly (without creating an object). If called at the object then it is the same as normal method which doesn't access self.<attribute(s)> and accesses self.__class__.<attribute(s)> only.\n\nThink we have a class with b=2, we will create an object and re-set this to b=4 in it. Staticmethod cannot access nothing from previous. Classmethod can access .b==2 only, via cls.b. Normal method can access both: .b==4 via self.b and .b==2 via self.__class__.b.\n\nWe could follow the KISS style (keep it simple, stupid): Don't use staticmethods and classmethods, don't use classes without instantiating them, access only the object's attributes self.attribute(s). There are languages where the OOP is implemented that way and I think it is not bad idea. :)\n\nShare\nImprove this answer\nFollow\nanswered Mar 2 '20 at 16:01\nmirek\n6636\n6 silver badges\n8\n8 bronze badges","comments":["One important thing more to classmethods: If you modify an attribute in the class method, all existing objects of this class which do not explicitly set this attribute will have the modified value.","the first sentence isn't quite true. a staticmethod can access public class members by specifying the class name, just as any caller could"]},{"answer":"Python comes with several built-in decorators. The big three are:\n\n@classmethod\n@staticmethod\n@property\n\n\n@classmethod decorator can be called with with an instance of a class or directly by the class itself as its first argument.\n\n@staticmethod is a way of putting a function into a class (because it logically belongs there), while indicating that it does not require access to the class.\n\nLet's consider the following class:\n\nclass DecoratorTest(object):\n\n    def __init__(self):\n        pass\n\n    def doubler(self, x):\n        print(\"running doubler\")\n        return x*2\n\n    @classmethod\n    def class_doubler(klass, x):\n        print(\"running doubler: %s\" % klass)\n        return x*2\n\n    @staticmethod\n    def static_doubler(x):\n        print(\"running quad\")\n        return x*2\n\ndecor = DecoratorTest()\n\n\nLet's see how it works:\n\nprint(decor.doubler(5))\n# running doubler\n# 10\n\nprint(decor.class_doubler(5))\n# running doubler: <class '__main__.DecoratorTest'> \n# 10\nprint(DecoratorTest.class_doubler(5))\n# running doubler: <class '__main__.DecoratorTest'> \n# 10\n\nprint(DecoratorTest.static_doubler(5))\n# running doubler \n# 10\nprint(decor.static_doubler(5))\n# running doubler \n# 10\n\nprint(decor.doubler)\n# <bound method DecoratorTest.doubler of <__main__.DecoratorTest object at 0x7f90e74fd150>> \nprint(decor.class_doubler)\n# <bound method DecoratorTest.class_doubler of <class '__main__.DecoratorTest'>> \nprint(decor.static_doubler)\n# <function DecoratorTest.static_doubler at 0x7f90e7447440> \n\nShare\nImprove this answer\nFollow\nedited Jan 16 at 20:03\nanswered Jan 16 at 19:58\nilluminato\n3823\n3 silver badges\n15\n15 bronze badges","comments":[]}]},{"id":"14415881","href":"https://stackoverflow.com/questions/14415881/how-can-i-pair-socks-from-a-pile-efficiently","title":"How can I pair socks from a pile efficiently?","description":"\n                \nYesterday I was pairing the socks from the clean laundry and figured out the way I was doing it is not very efficient. I was doing a naive search — picking one sock and \"iterating\" the pile in order to find its pair. This requires iterating over n/2 * n/4 = n2/8 socks on average.\n\nAs a computer scientist I was thinking what I could do? Sorting (according to size/color/...) of course came to mind to achieve an O(NlogN) solution.\n\nHashing or other not-in-place solutions are not an option, because I am not able to duplicate my socks (though it could be nice if I could).\n\nSo, the question is basically:\n\nGiven a pile of n pairs of socks, containing 2n elements (assume each sock has exactly one matching pair), what is the best way to pair them up efficiently with up to logarithmic extra space? (I believe I can remember that amount of info if needed.)\n\nI will appreciate an answer that addresses the following aspects:\n\n\nA general theoretical solution for a huge number of socks.\nThe actual number of socks is not that large, I don't believe my spouse and I have more than 30 pairs. (And it is fairly easy to distinguish between my socks and hers; can this be used as well?)\nIs it equivalent to the element distinctness problem?\n\n    ","questionComments":["I use pigeon hole principle to pair exactly one from the laundry pile. I have 3 different colors of socks (Red,Blue and Green) and 2 pairs of each color. I pick up 4 number of socks each time and I always make up a pair and get to work.","Yet another pigeon hole principle: if you take a subset of n/2 +1 socks, there must be at least one pair in this subset.","Great question! You might be interested in my article on a related problem, which is a discussion of the probability of pulling two matched socks out of the pile: blogs.msdn.com/b/ericlippert/archive/2010/03/22/…","Why not spawn a child and waitpid so that, as the parent, you're not even sorting any socks yourself?","I solved this problem by only owning white knee-high socks. They all match. I could simply grab any two socks at random from the pile and they would match. I further simplify the problem by NOT pairing the socks. I have a sock drawer that I simply throw all my socks into, unpaired. I grab two at random from the drawer every morning. I've simplified it down to O(0). Can't get any simpler than that. :)"],"answers":[{"answer":"Sorting solutions have been proposed, but sorting is a little too much: We don't need order; we just need equality groups.\n\nSo hashing would be enough (and faster).\n\nFor each color of socks, form a pile. Iterate over all socks in your input basket and distribute them onto the color piles.\nIterate over each pile and distribute it by some other metric (e.g. pattern) into the second set of piles\nRecursively apply this scheme until you have distributed all socks onto very small piles that you can visually process immediately\n\nThis kind of recursive hash partitioning is actually being done by SQL Server when it needs to hash join or hash aggregate over huge data sets. It distributes its build input stream into many partitions which are independent. This scheme scales to arbitrary amounts of data and multiple CPUs linearly.\n\nYou don't need recursive partitioning if you can find a distribution key (hash key) that provides enough buckets that each bucket is small enough to be processed very quickly. Unfortunately, I don't think socks have such a property.\n\nIf each sock had an integer called \"PairID\" one could easily distribute them into 10 buckets according to PairID % 10 (the last digit).\n\nThe best real-world partitioning I can think of is creating a rectangle of piles: one dimension is color, the other is the pattern. Why a rectangle? Because we need O(1) random-access to piles. (A 3D cuboid would also work, but that is not very practical.)\n\nUpdate:\n\nWhat about parallelism? Can multiple humans match the socks faster?\n\nThe simplest parallelization strategy is to have multiple workers take from the input basket and put the socks onto the piles. This only scales up so much - imagine 100 people fighting over 10 piles. The synchronization costs (manifesting themselves as hand-collisions and human communication) destroy efficiency and speed-up (see the Universal Scalability Law!). Is this prone to deadlocks? No, because each worker only needs to access one pile at a time. With just one \"lock\" there cannot be a deadlock. Livelocks might be possible depending on how the humans coordinate access to piles. They might just use random backoff like network cards do that on a physical level to determine what card can exclusively access the network wire. If it works for NICs, it should work for humans as well.\nIt scales nearly indefinitely if each worker has its own set of piles. Workers can then take big chunks of socks from the input basket (very little contention as they are doing it rarely) and they do not need to synchronise when distributing the socks at all (because they have thread-local piles). At the end, all workers need to union their pile-sets. I believe that can be done in O(log (worker count * piles per worker)) if the workers form an aggregation tree.\n\nWhat about the element distinctness problem? As the article states, the element distinctness problem can be solved in O(N). This is the same for the socks problem (also O(N), if you need only one distribution step (I proposed multiple steps only because humans are bad at calculations - one step is enough if you distribute on md5(color, length, pattern, ...), i.e. a perfect hash of all attributes)).\n\nClearly, one cannot go faster than O(N), so we have reached the optimal lower bound.\n\nAlthough the outputs are not exactly the same (in one case, just a boolean. In the other case, the pairs of socks), the asymptotic complexities are the same.\n\nShare\nImprove this answer\nFollow\nedited Dec 24 '17 at 17:50\ncommunity wiki\n\n\n10 revs, 3 users 75%\nusr","comments":["This is exactly what I do! I make piles dependent on the style of the opening of the sock (I only have white), that gives me enough \"buckets\" to quickly match each of those up.","I've tried this with my socks (I've got easily 30+ pairs) and man it is FAST. One problem I've found is when I can't have a good enough hash algorithm (I've got lots of white socks without any pattern) so it becomes hard. In that case, what would be the optimal way to do it?","@NothingsImpossible that's how hash collision attacks feel like for a poor web-server! Are the white socks distinguishable by some attribute? There must be something you can distribute them on. Otherwise, you could just form pairs arbitrarily.","This is a Radix Sort, which I agree is the right answer. @MarkPeters I don't think you need a lookup table. A single linear pass over the socks can convert the socks to number vectors, making the mapping of \"sock segment\" to bucket trivial. The socks can be tied to the vectors with string so that you don't need another linear pass at the end.","A guy I went to college with actually had PairIDs. It was sewn on each pair of socks with thread: 1, 2, 3, 4..."]},{"answer":"As the architecture of the human brain is completely different than a modern CPU, this question makes no practical sense.\n\nHumans can win over CPU algorithms using the fact that \"finding a matching pair\" can be one operation for a set that isn't too big.\n\nMy algorithm:\n\nspread_all_socks_on_flat_surface();\nwhile (socks_left_on_a_surface()) {\n     // Thanks to human visual SIMD, this is one, quick operation.\n     pair = notice_any_matching_pair();\n     remove_socks_pair_from_surface(pair);\n}\n\n\nAt least this is what I am using in real life, and I find it very efficient. The downside is it requires a flat surface, but it's usually abundant.\n\nShare\nImprove this answer\nFollow\nedited May 14 '15 at 15:29\ncommunity wiki\n\n\n5 revs, 5 users 76%\ndpc.ucore.info","comments":["as the number of socks increases, human's SIMD become no better than a CPU.","The best answer, IMO. While it's fun and clever (and appropriate for SO) to reduce a day-to-day problem to a computer algorithm, it makes much more sense to use the resolution power of man's eye/brain for a set as small as ~60 socks.","@LieRyan If the socks are uniformily distributed, you will end up noticing a pair in any sufficiently small set of socks due to the birthday paradox (unless you can distinguish colors to arbitrary precision, which I doubt) so the bottleneck here wouldn't be the human color matching algorithm but the spreading step.","@dpc.ucore.info No, because they have different woven cuff patterns, cuff lengths, overall lengths and shades of black (my wife would probably physically hurt me for that last one).","You had better hope you have an even number of socks, otherwise you are going to be folding socks for a long time..."]},{"answer":"Case 1: All socks are identical (this is what I do in real life by the way).\n\nPick any two of them to make a pair. Constant time.\n\nCase 2: There are a constant number of combinations (ownership, color, size, texture, etc.).\n\nUse radix sort. This is only linear time since comparison is not required.\n\nCase 3: The number of combinations is not known in advance (general case).\n\nWe have to do comparison to check whether two socks come in pair. Pick one of the O(n log n) comparison-based sorting algorithms.\n\nHowever in real life when the number of socks is relatively small (constant), these theoretically optimal algorithms wouldn't work well. It might take even more time than sequential search, which theoretically requires quadratic time.\n\nShare\nImprove this answer\nFollow\nedited Jan 31 '13 at 21:55\ncommunity wiki\n\n\nTerry Li","comments":["> It might take even more time than sequential search, which requires quadratic time in theory. Yeah that is why I hate doing this, maybe I should throw away all my socks and start with case 1.","the down side of having all identical socks is that they tend to age at different rates. So you still end up trying to match them based on how worn they are. (which is harder than simply matching by pattern)","The problem with having 60 pairs of identical socks \"because it makes pairing easier\" is that it gives people the impression you work with computers.","Case 1 is not constant time when there's an operation involved, such as folding pairs together. In this case, it's linear time with the smallest constant factor (the proof of which is left as an exercise for the reader). One can't possibly take the same time folding one pair and a bucket full of socks. However, it scales linearly. By Amdahl's law, it has unlimited speedup, ignoring overhead. By Gustafson's law, you can fold as many pairs as it takes to fold one pair given enough workers (the amount of which is left as an exercise for the reader), ignoring overhead.","@PauloMadeira The sorting is constant time - you just take the pile and put it in your drawer. The only operation in this case is actually putting the socks on your feet which is also constant. Performance is gained by deferred execution of the sock wearing, possibly with some sacrifice in space (consumed space of non-folded socks is larger than folded). I argue that this is worth it; I usually lose this argument with my wife."]},{"answer":"Non-algorithmic answer, yet \"efficient\" when I do it:\n\nstep 1) discard all your existing socks\n\nstep 2) go to Walmart and buy them by packets of 10 - n packet of white and m packets of black. No need for other colors in everyday's life.\n\nYet times to times, I have to do this again (lost socks, damaged socks, etc.), and I hate to discard perfectly good socks too often (and I wished they kept selling the same socks reference!), so I recently took a different approach.\n\nAlgorithmic answer:\n\nConsider than if you draw only one sock for the second stack of socks, as you are doing, your odds of finding the matching sock in a naive search is quite low.\n\nSo pick up five of them at random, and memorize their shape or their length.\n\nWhy five? Usually humans are good are remembering between five and seven different elements in the working memory - a bit like the human equivalent of a RPN stack - five is a safe default.\n\nPick up one from the stack of 2n-5.\n\nNow look for a match (visual pattern matching - humans are good at that with a small stack) inside the five you drew, if you don't find one, then add that to your five.\n\nKeep randomly picking socks from the stack and compare to your 5+1 socks for a match. As your stack grows, it will reduce your performance but raise your odds. Much faster.\n\nFeel free to write down the formula to calculate how many samples you have to draw for a 50% odds of a match. IIRC it's an hypergeometric law.\n\nI do that every morning and rarely need more than three draws - but I have n similar pairs (around 10, give or take the lost ones) of m shaped white socks. Now you can estimate the size of my stack of stocks :-)\n\nBTW, I found that the sum of the transaction costs of sorting all the socks every time I needed a pair were far less than doing it once and binding the socks. A just-in-time works better because then you don't have to bind the socks, and there's also a diminishing marginal return (that is, you keep looking for that two or three socks that when somewhere in the laundry and that you need to finish matching your socks and you lose time on that).\n\nShare\nImprove this answer\nFollow\nedited Jul 29 '13 at 20:21\ncommunity wiki\n\n\nguylhem","comments":["Upvote for 'non-algorithmic' answer. This is exactly what I do and it works wonderfully. The replacement issue is not a problem if you 'rotate' your sock stock by placing washed socks in back and pulling from the front of the drawer in the morning. All socks wear evenly. When I start noticing some wear on one, I put on the shopping list to completely replace that entire class of socks. For the old socks, I give the best 20% to Goodwill (tied in a grocery sac so they don't get mixed back in) and pitch the rest. You're not wasting socks, at this point, the 80% only have 6 months left anyway.","BTW (1) Binding your socks results in the elastic one one being stored stretched and the will fail much more quickly. Limiting the kinds of unique socks you have makes binding unneded. (2) A disadvantage of limiting unique socks is that for people with certain fashion concerns, the method may be unsuitable.","I came here specifically to post your \"non-algorithmic\" answer. As in true computer science, most people never pay enough attention to the data and its structure.","I use this algorithmic approach every morning and it works like a charm! Additionally, I put worn out socks to a different pile to throw away later (unfortunately they manage to get to the original pile again before I find the time to trash it).","«n packet of white and m packets of black. No need for other colors in everyday's life» A good standard rule for easy sock selection is actually that they should match either the color of your trousers or the color of your belt. For this reason, the most commonly used colors will likely be black, blue, gray and some brown. It's hard to believe one needs many white socks."]},{"answer":"What I do is that I pick up the first sock and put it down (say, on the edge of the laundry bowl). Then I pick up another sock and check to see if it's the same as the first sock. If it is, I remove them both. If it's not, I put it down next to the first sock. Then I pick up the third sock and compare that to the first two (if they're still there). Etc.\n\nThis approach can be fairly easily be implemented in an array, assuming that \"removing\" socks is an option. Actually, you don't even need to \"remove\" socks. If you don't need sorting of the socks (see below), then you can just move them around and end up with an array that has all the socks arranged in pairs in the array.\n\nAssuming that the only operation for socks is to compare for equality, this algorithm is basically still an n2 algorithm, though I don't know about the average case (never learned to calculate that).\n\nSorting, of course improves efficiency, especially in real life where you can easily \"insert\" a sock between two other socks. In computing the same could be achieved by a tree, but that's extra space. And, of course, we're back at NlogN (or a bit more, if there are several socks that are the same by sorting criteria, but not from the same pair).\n\nOther than that, I cannot think of anything, but this method does seem to be pretty efficient in real life. :)\n\nShare\nImprove this answer\nFollow\nanswered Jan 19 '13 at 15:49\ncommunity wiki\n\n\nVilx-","comments":["This is also what I do, (note that if you simply leave spaces then inserts are also O(1) ), but it scales poorly with theoretically large numbers of socks.","scales poorly with theoretically large numbers of types of socks","@StevenLu - as I said - it's n*n or nLogn, depending on whether you sort it or not. So it scales about as poorly as any sorting algorithm. If you want faster, number them and use radix sort.","This is essentially storing found-but-not-matched socks in a hash-based lookup. With an ideal hash it is O(n), but if you've enough socks stored that the hash begins to degenerate, it becomes more complex accordingly.","what value does inserting a sock between 2 other socks provide to the goal of pairing socks? there is no cardinality of socks. :-x"]},{"answer":"This is asking the wrong question. The right question to ask is, why am I spending time sorting socks? How much does it cost on yearly basis, when you value your free time for X monetary units of your choice?\n\nAnd more often than not, this is not just any free time, it's morning free time, which you could be spending in bed, or sipping your coffee, or leaving a bit early and not being caught in the traffic.\n\nIt's often good to take a step back, and think a way around the problem.\n\nAnd there is a way!\n\nFind a sock you like. Take all relevant features into account: colour in different lighting conditions, overall quality and durability, comfort in different climatic conditions, and odour absorption. Also important is, they should not lose elasticity in storage, so natural fabrics are good, and they should be available in a plastic wrapping.\n\nIt's better if there's no difference between left and right foot socks, but it's not critical. If socks are left-right symmetrical, finding a pair is O(1) operation, and sorting the socks is approximate O(M) operation, where M is the number of places in your house, which you have littered with socks, ideally some small constant number.\n\nIf you chose a fancy pair with different left and right sock, doing a full bucket sort to left and right foot buckets take O(N+M), where N is the number of socks and M is same as above. Somebody else can give the formula for average iterations of finding the first pair, but worst case for finding a pair with blind search is N/2+1, which becomes astronomically unlikely case for reasonable N. This can be sped up by using advanced image recognition algorithms and heuristics, when scanning the pile of unsorted socks with Mk1 Eyeball.\n\nSo, an algorithm for achieving O(1) sock pairing efficiency (assuming symmetrical sock) is:\n\nYou need to estimate how many pairs of socks you will need for the rest of your life, or perhaps until you retire and move to warmer climates with no need to wear socks ever again. If you are young, you could also estimate how long it takes before we'll all have sock-sorting robots in our homes, and the whole problem becomes irrelevant.\n\nYou need to find out how you can order your selected sock in bulk, and how much it costs, and do they deliver.\n\nOrder the socks!\n\nGet rid of your old socks.\n\nAn alternative step 3 would involve comparing costs of buying the same amount of perhaps cheaper socks a few pairs at a time over the years and adding the cost of sorting socks, but take my word for it: buying in bulk is cheaper! Also, socks in storage increase in value at the rate of stock price inflation, which is more than you would get on many investments. Then again there is also storage cost, but socks really do not take much space on the top shelf of a closet.\n\nProblem solved. So, just get new socks, throw/donate your old ones away, and live happily ever after knowing you are saving money and time every day for the rest of your life.\n\nShare\nImprove this answer\nFollow\nedited Dec 24 '17 at 10:32\ncommunity wiki\n\n\n4 revs, 3 users 81%\nhyde","comments":["A lifetime (assuming 75 years) supply of socks (assuming you exhaust 4 pairs/month, that makes 3600 pairs) would take up (assuming a new pair of socks takes up 20 cubic inches) a total of 1 1/2 cubic yards. That is an enormous amount of space. Assuming they deliver it to you in a box that is roughly a cube, that crate will be about 3 feet 4 inches on a side.","@AJMansfield valid concern. However, I disagree with a few of your numbers. I'd take a timespan of just 40 years (25...65) (time between not living at parents/dorm/etc and retiring, see above). Also, I think one pair takes more like 0,5x4x6 inches in original packaging. These numbers bring your space estime down quite a bit!","Step 4 is unnecessarily wasteful, -1.","Guide for others who might be confused by AJMansfield's measurements, a translation into metric: »would take up (assuming a new pair of socks takes up 327 cm³) a total of 1.14 m³. That is an enormous amount of space. Assuming they deliver it to you in a box that is roughly a cube, that crate will be about 1.04 m on a side.«","How can a curiosity-based question be \"the wrong question\"? Classic StackOverflow..."]},{"answer":"The theoretical limit is O(n) because you need to touch each sock (unless some are already paired somehow).\n\nYou can achieve O(n) with radix sort. You just need to pick some attributes for the buckets.\n\nFirst you can choose (hers, mine) - split them into 2 piles,\nthen use colors (can have any order for the colors, e.g. alphabetically by color name) - split them into piles by color (remember to keep the initial order from step 1 for all socks in the same pile),\nthen length of the sock,\nthen texture, ....\n\nIf you can pick a limited number of attributes, but enough attributes that can uniquely identify each pair, you should be done in O(k * n), which is O(n) if we can consider k is limited.\n\nShare\nImprove this answer\nFollow\nanswered Jan 19 '13 at 20:40\ncommunity wiki\n\n\nandredor","comments":["Socks often come in 4-packs and larger, since that is cheaper, but that also makes them indistinguishable. To counter this, my wife sews a tiny mark onto each new pair of socks I buy. The mark is of a different color for each pair, or of a different shape, if she runs out of colors. With this approach you don't even need a limited set of attributes. Just sew a unique number on each pair. :) For extra points, use binary.","@Vilx- WHY?!? Isn't the whole point that they be indistinguishable?","@flup - I think the whole point is to sell in larger bundles. :) As for me, this helps to wear them down in pairs. Otherwise I can end up with three very worn socks and one brand new one. Kinda silly.","I disagree with the calculation of O(n). What is $k$? $k$ is the number of attributes. I would argue $k$ is $O(log n)$ because it has to be enough to uniquely identify each pair. If you have 2 pairs (black and white), then color ($k=1, n=2$) is enough. If you have one pair of black, short; one pair of black, long; one pair of white, short; and one pair of white, long - then $k=2, n=4$. Then if we limit $k$, we at the same time limit $n$. If we are going to limit $n$ then order calculation does not make sense anymore.","@emory, I think that you're looking for the backtick, not the $ character, to make your stuff look code-y."]},{"answer":"As a practical solution:\n\nQuickly make piles of easily distinguishable socks. (Say by color)\nQuicksort every pile and use the length of the sock for comparison. As a human you can make a fairly quick decision which sock to use to partition that avoids worst case. (You can see multiple socks in parallel, use that to your advantage!)\nStop sorting piles when they reached a threshold at which you are comfortable to find spot pairs and unpairable socks instantly\n\nIf you have 1000 socks, with 8 colors and an average distribution, you can make 4 piles of each 125 socks in c*n time. With a threshold of 5 socks you can sort every pile in 6 runs. (Counting 2 seconds to throw a sock on the right pile it will take you little under 4 hours.)\n\nIf you have just 60 socks, 3 colors and 2 sort of socks (yours / your wife's) you can sort every pile of 10 socks in 1 runs (Again threshold = 5). (Counting 2 seconds it will take you 2 min).\n\nThe initial bucket sorting will speed up your process, because it divides your n socks into k buckets in c*n time so than you will only have to do c*n*log(k) work. (Not taking into account the threshold). So all in all you do about n*c*(1 + log(k)) work, where c is the time to throw a sock on a pile.\n\nThis approach will be favourable compared to any c*x*n + O(1) method roughly as long as log(k) < x - 1.\n\nIn computer science this can be helpful: We have a collection of n things, an order on them (length) and also an equivalence relation (extra information, for example the color of socks). The equivalence relation allows us to make a partition of the original collection, and in every equivalence class our order is still maintained. The mapping of a thing to it's equivalence class can be done in O(1), so only O(n) is needed to assign each item to a class. Now we have used our extra information and can proceed in any manner to sort every class. The advantage is that the data sets are already significantly smaller.\n\nThe method can also be nested, if we have multiple equivalence relations -> make colour piles, than within every pile partition on texture, than sort on length. Any equivalence relation that creates a partition with more than 2 elements that have about even size will bring a speed improvement over sorting (provided we can directly assign a sock to its pile), and the sorting can happen very quickly on smaller data sets.\n\nShare\nImprove this answer\nFollow\nedited Jan 20 '13 at 19:56\ncommunity wiki\n\n\nSamuel","comments":["Human optimisation: I'd argue that as a human, for step 2, you should plonk the socks down in roughly ascending order, then repeat with finer and finer granularity until sorted, a bit like shell sort. This would be much faster for a human (visual estimation) than a comparison-swap based approach."]},{"answer":"You are trying to solve the wrong problem.\n\nSolution 1: Each time you put dirty socks in your laundry basket, tie them in a little knot. That way you will not have to do any sorting after the washing. Think of it like registering an index in a Mongo database. A little work ahead for some CPU savings in the future.\n\nSolution 2: If it's winter, you don't have to wear matching socks. We are programmers. Nobody needs to know, as long as it works.\n\nSolution 3: Spread the work. You want to perform such a complex CPU process asynchronously, without blocking the UI. Take that pile of socks and stuff them in a bag. Only look for a pair when you need it. That way the amount of work it takes is much less noticeable.\n\nHope this helps!\n\nShare\nImprove this answer\nFollow\nanswered Oct 19 '15 at 20:47\nNikolay Dyankov\n5,15810\n10 gold badges\n45\n45 silver badges\n65\n65 bronze badges","comments":["Tying socks (or any clothes) in a knot reduces the capability of the washer to wash the clothes, and makes untying them to wear much more difficult. Solution 2 makes maintenance more difficult the longer the state of affairs progresses; after 6 months, when you need two black ankle socks to wear with a pair of shorts and sneakers, 6 months of doing whatever works is going to make finding that pair in the same condition (dirty/clean, similar wear) much less likely. Solution 3 is less \"asynchronous\" and more straight-up \"lazy\"; do the minimum work you need exactly when you need to.","Re: solution 2: People will know I'm not wearing matching socks because they will see them in my Birks :)","@BobProbst Yes but your fellow programmers will also be wearing unmatched socks with Birks and therefore will just be happy noticing they are not the only ones."]},{"answer":"This question is actually deeply philosophical. At heart it's about whether the power of people to solve problems (the \"wetware\" of our brains) is equivalent to what can be accomplished by algorithms.\n\nAn obvious algorithm for sock sorting is:\n\nLet N be the set of socks that are still unpaired, initially empty\nfor each sock s taken from the dryer\n  if s matches a sock t in N\n    remove t from N, bundle s and t together, and throw them in the basket\n  else\n    add s to N\n\n\nNow the computer science in this problem is all about the steps\n\n\"if s pairs with a sock t in N\". How quickly can we \"remember\" what we've seen so far?\n\"remove t from N\" and \"add s to N\". How expensive is keeping track of what we've seen so far?\n\nHuman beings will use various strategies to effect these. Human memory is associative, something like a hash table where feature sets of stored values are paired with the corresponding values themselves. For example, the concept of \"red car\" maps to all the red cars a person is capable of remembering. Someone with a perfect memory has a perfect mapping. Most people are imperfect in this regard (and most others). The associative map has a limited capacity. Mappings may bleep out of existence under various circumstances (one beer too many), be recorded in error (\"I though her name was Betty, not Nettie\"), or never be overwritten even though we observe that the truth has changed (\"dad's car\" evokes \"orange Firebird\" when we actually knew he'd traded that in for the red Camaro).\n\nIn the case of socks, perfect recall means looking at a sock s always produces the memory of its sibling t, including enough information (where it is on the ironing board) to locate t in constant time. A person with photographic memory accomplishes both 1 and 2 in constant time without fail.\n\nSomeone with less than perfect memory might use a few commonsense equivalence classes based on features within his capability to track: size (papa, mama, baby), color (greenish, redish, etc.), pattern (argyle, plain, etc.), style (footie, knee-high, etc.). So the ironing board would be divided into sections for the categories. This usually allows the category to be located in constant time by memory, but then a linear search through the category \"bucket\" is needed.\n\nSomeone with no memory or imagination at all (sorry) will just keep the socks in one pile and do a linear search of the whole pile.\n\nA neat freak might use numeric labels for pairs as someone suggested. This opens the door to a total ordering, which allows the human to use exactly the same algorithms we might with a CPU: binary search, trees, hashes, etc.\n\nSo the \"best\" algorithm depends on the qualities of the wetware/hardware/software that is running it and our willingness to \"cheat\" by imposing a total order on pairs. Certainly a \"best\" meta-algorithm is to hire the worlds best sock-sorter: a person or machine that can aquire and quickly store a huge set N of sock attribute sets in a 1-1 associative memory with constant time lookup, insert, and delete. Both people and machines like this can be procured. If you have one, you can pair all the socks in O(N) time for N pairs, which is optimal. The total order tags allow you to use standard hashing to get the same result with either a human or hardware computer.\n\nShare\nImprove this answer\nFollow\nedited Apr 1 '13 at 22:16\ncommunity wiki\n\n\nGene","comments":["Ok, that's better, although it's still quite wrong ... this question is not about that. Whether or not the Church-Turing thesis is correct, both humans and our computers can sort socks. (The reality is that, humans, being highly finite entities, have far less computational power than Turing Machines ... and the same is true of our computers, but the limitations are different.)","I disagree. Of course any of our current computers is essentially and enormous DFA (modulo i/o differences) rather than a TM. Any analog device, however, such as our bodies, is capable of emulating an infinite tape. We don't yet have a useful characterization of the way our minds compute.","No infinite tape for humans or other physical devices because nothing in the human brain has infinite resolution, nor could it. It would also help to learn some neuroscience. In any case, there was no deep philosophical question here, regardless of your desire to inject one. But believe what you will ... this isn't the place for this sort of debate and I've had it too many times before. But I'm always amused by people who can barely solve the simplest problems (that's all of us) imagining that they are TM-equivalent."]},{"answer":"Cost: Moving socks -> high, finding/search socks in line -> small\n\nWhat we want to do is reduce the number of moves, and compensate with the number of searches. Also, we can utilize the multithreded environment of the Homo Sapiens to hold more things in the descision cache.\n\nX = Yours, Y = Your spouses\n\nFrom pile A of all socks:\n\nPick two socks, place corresponding X sock in X line, and Y sock in Y line at next available position.\n\nDo until A is empty.\n\nFor each line X and Y\n\nPick the first sock in line, search along the line until it finds the corresponding sock.\n\nPut into the corresponding finished line of socks.\n\nOptional While you are searching the line and and the current sock you are looking at is identical to the previous, do step 2 for these socks.\n\nOptionally to step one, you pick up two sock from that line instead of two, as the caching memory is large enough we can quickly identify if either sock matches the current one on the line you are observing. If you are fortunate enough to have three arms, you could possibly parse three socks at the same time given that the memory of the subject is large enough.\n\nDo until both X and Y is empty.\n\nDone\n\nHowever, as this have simillar complexity as selection sort, the time taken is far less due to the speeds of I/O(moving socks) and search(searching the line for a sock).\n\nShare\nImprove this answer\nFollow\nanswered Jan 19 '13 at 22:19\ncommunity wiki\n\n\n1-----1","comments":[]},{"answer":"Here's an Omega(n log n) lower bound in comparison based model. (The only valid operation is comparing two socks.)\n\nSuppose that you know that your 2n socks are arranged this way:\n\np1 p2 p3 ... pn pf(1) pf(2) ... pf(n)\n\nwhere f is an unknown permutation of the set {1,2,...,n}. Knowing this cannot make the problem harder. There are n! possible outputs (matchings between first and second half), which means you need log(n!) = Omega(n log n) comparisons. This is obtainable by sorting.\n\nSince you are interested in connections to element distinctness problem: proving the Omega(n log n) bound for element distinctness is harder, because the output is binary yes/no. Here, the output has to be a matching and the number of possible outputs suffices to get a decent bound. However, there's a variant connected to element distinctness. Suppose you are given 2n socks and wonder if they can be uniquely paired. You can get a reduction from ED by sending (a1, a2, ..., an) to (a1, a1, a2, a2, ..., an, an). (Parenthetically, the proof of hardness of ED is very interesting, via topology.)\n\nI think that there should be an Omega(n2) bound for the original problem if you allow equality tests only. My intuition is: Consider a graph where you add an edge after a test, and argue that if the graph is not dense the output is not uniquely determined.\n\nShare\nImprove this answer\nFollow\nedited Jan 20 '13 at 21:17\ncommunity wiki\n\n\nsdcvvc","comments":[]},{"answer":"This is how I actually do it, for p pairs of socks (n = 2p individual socks):\n\nGrab a sock at random from the pile.\nFor the first sock, or if all previously-chosen socks have been paired, simply place the sock into the first \"slot\" of an \"array\" of unpaired socks in front of you.\nIf you have one or more selected unpaired socks, check your current sock against all the unpaired socks in the array.\nIt is possible to separate socks into general classes or types (white/black, ankle/crew, athletic/dress) when building your array, and \"drill-down\" to only compare like-for-like.\nIf you find an acceptable match, put both socks together and remove them from the array.\nIf you do not, put the current sock into the first open slot in the array.\nRepeat with every sock.\n\nThe worst-case scenario of this scheme is that every pair of socks is different enough that it must be matched exactly, and that the first n/2 socks you pick are all different. This is your O(n2) scenario, and it's extremely unlikely. If the number of unique types of sock t is less than the number of pairs p = n/2, and the socks in each type are alike enough (usually in wear-related terms) that any sock of that type can be paired with any other, then as I inferred above, the maximum number of socks you will ever have to compare to is t, after which the next one you pull will match one of the unpaired socks. This scenario is much more likely in the average sock drawer than the worst-case, and reduces the worst-case complexity to O(n*t) where usually t << n.\n\nShare\nImprove this answer\nFollow\nedited Jan 22 '13 at 2:35\ncommunity wiki\n\n\nKeithS","comments":["This is probably pretty close to my mental process. I have an added layer of pre-sort optimization. My athletic socks get washed with the whites and my dress socks get washed with colors. This means that as long as I don't dump two loads of laundry together, my socks are already grouped by type. The white load goes really fast (many identical socks) but the dress socks take longer. Other key tip--make more available memory for the sort (fold and remove all non-socks first and THEN run the pairing algorithm)"]},{"answer":"Real-world approach:\n\nAs rapidly as possible, remove socks from the unsorted pile one at a time and place in piles in front of you. The piles should be arranged somewhat space-efficiently, with all socks pointing the same direction; the number of piles is limited by the distance you can easily reach. The selection of a pile on which to put a sock should be -- as rapidly as possible -- by putting a sock on a pile of apparently like socks; the occasional type I (putting a sock on a pile it doesn't belong to) or type II (putting a sock in its own pile when there's an existing pile of like socks) error can be tolerated -- the most important consideration is speed.\n\nOnce all the socks are in piles, rapidly go through the multi-sock piles creating pairs and removing them (these are heading for the drawer). If there are non-matching socks in the pile, re-pile them to their best (within the as-fast-as-possible constraint) pile. When all the multi-sock piles have been processed, match up remaining pairable socks that weren't paired due to type II errors. Whoosh, you're done -- and I have a lot of socks and don't wash them until a large fraction are dirty. Another practical note: I flip the top of one of a pair of socks down over the other, taking advantage of their elastic properties, so they stay together while being transported to the drawer and while in the drawer.\n\nShare\nImprove this answer\nFollow\nedited Apr 23 '20 at 19:22\ncommunity wiki\n\n\n4 revs, 2 users 54%\nPeter Mortensen","comments":[]},{"answer":"From your question it is clear you don't have much actual experience with laundry :). You need an algorithm that works well with a small number of non-pairable socks.\n\nThe answers till now don't make good use of our human pattern recognition capabilities. The game of Set provides a clue of how to do this well: put all socks in a two-dimensional space so you can both recognize them well and easily reach them with your hands. This limits you to an area of about 120 * 80 cm or so. From there select the pairs you recognize and remove them. Put extra socks in the free space and repeat. If you wash for people with easily recognizable socks (small kids come to mind), you can do a radix sort by selecting those socks first. This algorithm works well only when the number of single socks is low\n\nShare\nImprove this answer\nFollow\nanswered Jan 22 '13 at 22:05\ncommunity wiki\n\n\nStephan Eggermont","comments":["That is usually how I do it. Works much better than iterating through all the remaining socks each time.","Nice approach and I think it can be applied to some real CS problems as well. Can you please add an example of such (a CS problem where we could use a similar approach to solve problems)? Also, how does this solution scales for millions of socks?","I think this is basically th same as the other answer here, stackoverflow.com/a/14423956, from Jan 20. Both +1. Human vision system is massively parallel."]},{"answer":"Pick up a first sock and place it on a table. Now pick another sock; if it matches the first picked, place it on top of the first. If not, place it on the table a small distance from the first. Pick a third sock; if it matches either of the previous two, place it on top of them or else place it a small distance from the third. Repeat until you have picked up all the socks.\n\nShare\nImprove this answer\nFollow\nedited Feb 2 '15 at 18:40\ncommunity wiki\n\n\n2 revs, 2 users 50%\njustinfay","comments":["This is the only valid answer. All the others disregard the fact that the most time is spent distinguishing between similar socks (so lumping them all together by physical appearance makes it even worse).","For fun I wrote this method of piling socks up into a little python program gist.github.com/justinfay/53b574cf0a492f6795ef"]},{"answer":"In order to say how efficient it is to pair socks from a pile, we have to define the machine first, because the pairing isn't done whether by a turing nor by a random access machine, which are normally used as the basis for an algorithmic analysis.\n\nThe machine\n\nThe machine is an abstraction of a the real world element called human being. It is able to read from the environment via a pair of eyes. And our machine model is able to manipulate the environment by using 2 arms. Logical and arithmetic operations are calculated using our brain (hopefully ;-)).\n\nWe also have to consider the intrinsic runtime of the atomic operations that can be carried out with these instruments. Due to physical constraints, operations which are carried out by an arm or eye have non constant time complexity. This is because we can't move an endlessly large pile of socks with an arm nor can an eye see the top sock on an endlessly large pile of socks.\n\nHowever mechanical physics give us some goodies as well. We are not limited to move at most one sock with an arm. We can move a whole couple of them at once.\n\nSo depending on the previous analysis following operations should be used in descending order:\n\nlogical and arithmetic operations\nenvironmental reads\nenvironmental modifications\n\nWe can also make use of the fact that people only have a very limited amount of socks. So an environmental modification can involve all socks in the pile.\n\nThe algorithm\n\nSo here is my suggestion:\n\nSpread all socks in the pile over the floor.\nFind a pair by looking at the socks on the floor.\nRepeat from 2 until no pair can be made.\nRepeat from 1 until there are no socks on the floor.\n\nOperation 4 is necessary, because when spreading socks over the floor some socks may hide others. Here is the analysis of the algorithm:\n\nThe analysis\n\nThe algorithm terminates with high probability. This is due to the fact that one is unable to find pairs of socks in step number 2.\n\nFor the following runtime analysis of pairing n pairs of socks, we suppose that at least half of the 2n socks aren't hidden after step 1. So in the average case we can find n/2 pairs. This means that the loop is step 4 is executed O(log n) times. Step 2 is executed O(n^2) times. So we can conclude:\n\nThe algorithm involves O(ln n + n) environmental modifications (step 1 O(ln n) plus picking every pair of sock from the floor)\nThe algorithm involves O(n^2) environmental reads from step 2\nThe algorithm involves O(n^2) logical and arithmetic operations for comparing a sock with another in step 2\n\nSo we have a total runtime complexity of O(r*n^2 + w*(ln n + n)) where r and w are the factors for environmental read and environmental write operations respectively for a reasonable amount of socks. The cost of the logical and arithmetical operations are omitted, because we suppose that it takes a constant amount of logical and arithmetical operations to decide whether 2 socks belong to the same pair. This may not be feasible in every scenario.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\ncommunity wiki\n\n\nSpaceTrucker","comments":["this is the same as stackoverflow.com/a/14423956 and stackoverflow.com/a/14468913 I think.","@WillNess Yep, with a bit more of explanation"]},{"answer":"List<Sock> UnSearchedSocks = getAllSocks();\nList<Sock> UnMatchedSocks = new list<Sock>();\nList<PairOfSocks> PairedSocks = new list<PairOfSocks>();\n\nforeach (Sock newSock in UnsearchedSocks)\n{\n  Sock MatchedSock = null;\n  foreach(Sock UnmatchedSock in UnmatchedSocks)\n  {\n    if (UnmatchedSock.isPairOf(newSock))\n    {\n      MatchedSock = UnmatchedSock;\n      break;\n    }\n  }\n  if (MatchedSock != null)\n  {\n    UnmatchedSocks.remove(MatchedSock);\n    PairedSocks.Add(new PairOfSocks(MatchedSock, NewSock));\n  }\n  else\n  {\n    UnmatchedSocks.Add(NewSock);\n  }\n}\n\nShare\nImprove this answer\nFollow\nedited Mar 18 '13 at 13:29\ncommunity wiki\n\n\nChad","comments":[]},{"answer":"I came out with another solution which would not promise fewer operations, neither less time consumption, but it should be tried to see if it can be a good-enough heuristic to provide less time consumption in huge series of sock pairing.\n\nPreconditions: There is no guarantee that there are the same socks. If they are of the same color it doesn't mean they have the same size or pattern. Socks are randomly shuffled. There can be odd number of socks (some are missing, we don't know how many). Prepare to remember a variable \"index\" and set it to 0.\n\nThe result will have one or two piles: 1. \"matched\" and 2. \"missing\"\n\nHeuristic:\n\nFind most distinctive sock.\nFind its match.\nIf there is no match, put it on the \"missing\" pile.\nRepeat from 1. until there are no more most distinctive socks.\nIf there are less then 6 socks, go to 11.\nPair blindly all socks to its neighbor (do not pack it)\nFind all matched pairs, pack it and move packed pairs to \"matched\" pile; If there were no new matches - increment \"index\" by 1\nIf \"index\" is greater then 2 (this could be value dependent on sock number because with greater number of socks there are less chance to pair them blindly) go to 11\nShuffle the rest\nGo to 1\nForget \"index\"\nPick a sock\nFind its pair\nIf there is no pair for the sock, move it to the \"missing\" pile\nIf match found pair it, pack pair and move it to the \"matched\" pile\nIf there are still more then one socks go to 12\nIf there is just one left go to 14\nSmile satisfied :)\n\nAlso, there could be added check for damaged socks also, as if the removal of those. It could be inserted between 2 and 3, and between 13 and 14.\n\nI'm looking forward to hear about any experiences or corrections.\n\nShare\nImprove this answer\nFollow\nedited Feb 12 '15 at 9:50\ncommunity wiki\n\n\n6 revs, 3 users 62%\nSasa","comments":["After I wrote this, I use it every time. It helped me to became a bit more efficient and the job is less boring now."]},{"answer":"When I sort socks, I do an approximate radix sort, dropping socks near other socks of the same colour/pattern type. Except in the case when I can see an exact match at/near the location I'm about to drop the sock I extract the pair at that point.\n\nAlmost all the other algorithms (including the top scoring answer by usr) sort, then remove pairs. I find that, as a human, it is better to minimize the number of socks being considered at one time.\n\nI do this by:\n\nPicking a distinctive sock (whatever catches my eye first in the pile).\nStarting a radix sort from that conceptual location by pulling socks from the pile based on similarity to that one.\nPlace the new sock near into the current pile, with a distance based on how different it is. If you find yourself putting the sock on top of another because it is identical, form the pair there, and remove them. This means that future comparisons take less effort to find the correct place.\n\nThis takes advantage of the human ability to fuzzy-match in O(1) time, which is somewhat equivalent to the establishment of a hash-map on a computing device.\n\nBy pulling the distinctive socks first, you leave space to \"zoom\" in on the features which are less distinctive, to begin with.\n\nAfter eliminating the fluro coloured, the socks with stripes, and the three pairs of long socks, you might end up with mostly white socks roughly sorted by how worn they are.\n\nAt some point, the differences between socks are small enough that other people won't notice the difference, and any further matching effort is not needed.\n\nShare\nImprove this answer\nFollow\nedited Dec 24 '17 at 10:30\ncommunity wiki\n\n\n6 revs, 4 users 64%\nAndrew Hill","comments":[]},{"answer":"Whenever you pick up a sock, put it in one place. Then the next sock you pick up, if it doesn't match the first sock, set it beside the first one. If it does, there's a pair. This way it doesn't really matter how many combinations there are, and there are only two possibilities for each sock you pick up -- either it has a match that's already in your array of socks, or it doesn't, which means you add it to a place in the array.\n\nThis also means that you will almost certainly never have all your socks in the array, because socks will get removed as they're matched.\n\nShare\nImprove this answer\nFollow\nanswered Jan 19 '13 at 22:25\ncommunity wiki\n\n\ntrpt4him","comments":["This is what I do ... O(n)","@Pykler - It's O(n) in the best case and O(n*n) in the worst case.","Thats assuming that you cannot create a fully unique hash in your mind of all the socks you already seen, which for me is a O(1) to match a sock that I have seen and previously and placed in the waiting for matching hash","Actually that's the algorithm I had in mind: Assuming you have a limited space for n socks, proceed as described. If the new sock taken out does not match any of those already taken out and there are n socks out already, put it back and take another (randomly), or search in the rest until you find one matching, allowing to \"free a slot\"."]},{"answer":"Consider a hash-table of size 'N'.\n\nIf we assume normal distribution, then the estimated number of 'insertions' to have atleast one sock mapped to one bucket is NlogN (ie, all buckets are full)\n\nI had derived this as a part of another puzzle,but I would be happy to be proven wrong. Here's my blog article on the same\n\nLet 'N' correspond to an approximate upper-bound on the number of number of unique colors/pattern of socks that you have.\n\nOnce you have a collision(a.k.a : a match) simply remove that pair of socks. Repeat the same experiment with the next batch of NlogN socks. The beauty of it is that you could be making NlogN parallel comparisons(collision-resolution) because of the way the human mind works. :-)\n\nShare\nImprove this answer\nFollow\nanswered Jan 22 '13 at 13:33\ncommunity wiki\n\n\nArvind","comments":[]},{"answer":"Socks, whether real ones or some analogous data structure, would be supplied in pairs.\n\nThe simplest answer is prior to allowing the pair to be separated, a single data structure for the pair should have been initialized that contained a pointer to the left and right sock, thus enabling socks to be referred to directly or via their pair. A sock may also be extended to contain a pointer to its partner.\n\nThis solves any computational pairing problem by removing it with a layer of abstraction.\n\nApplying the same idea to the practical problem of pairing socks, the apparent answer is: don't allow your socks to ever be unpaired. Socks are provided as a pair, put in the drawer as a pair (perhaps by balling them together), worn as a pair. But the point where unpairing is possible is in the washer, so all that's required is a physical mechanism that allows the socks to stay together and be washed efficiently.\n\nThere are two physical possibilities:\n\nFor a 'pair' object that keeps a pointer to each sock we could have a cloth bag that we use to keep the socks together. This seems like massive overhead.\n\nBut for each sock to keep a reference to the other, there is a neat solution: a popper (or a 'snap button' if you're American), such as these:\n\nhttp://www.aliexpress.com/compare/compare-invisible-snap-buttons.html\n\nThen all you do is snap your socks together right after you take them off and put them in your washing basket, and again you've removed the problem of needing to pair your socks with a physical abstraction of the 'pair' concept.\n\nShare\nImprove this answer\nFollow\nanswered Jan 23 '13 at 1:25\ncommunity wiki\n\n\nmozboz","comments":["It does not answer the question, because handling with already paired data is easy, the question is what to do when the data is UNPAIRED and you want to pair it."]},{"answer":"I hope I can contribute something new to this problem. I noticed that all of the answers neglect the fact that there are two points where you can perform preprocessing, without slowing down your overall laundry performance.\n\nAlso, we don't need to assume a large number of socks, even for large families. Socks are taken out of the drawer and are worn, and then they are tossed in a place (maybe a bin) where they stay before being laundered. While I wouldn't call said bin a LIFO-Stack, I'd say it is safe to assume that\n\npeople toss both of their socks roughly in the same area of the bin,\nthe bin is not randomized at any point, and therefore\nany subset taken from the top of this bin generally contains both socks of a pair.\n\nSince all washing machines I know about are limited in size (regardless of how many socks you have to wash), and the actual randomizing occurs in the washing machine, no matter how many socks we have, we always have small subsets which contain almost no singletons.\n\nOur two preprocessing stages are \"putting the socks on the clothesline\" and \"Taking the socks from the clothesline\", which we have to do, in order to get socks which are not only clean but also dry. As with washing machines, clotheslines are finite, and I assume that we have the whole part of the line where we put our socks in sight.\n\nHere's the algorithm for put_socks_on_line():\n\nwhile (socks left in basket) {\n take_sock();\n if (cluster of similar socks is present) { \n   Add sock to cluster (if possible, next to the matching pair)\n } else {\n  Hang it somewhere on the line, this is now a new cluster of similar-looking socks.      \n  Leave enough space around this sock to add other socks later on \n }\n}\n\n\nDon't waste your time moving socks around or looking for the best match, this all should be done in O(n), which we would also need for just putting them on the line unsorted. The socks aren't paired yet, we only have several similarity clusters on the line. It's helpful that we have a limited set of socks here, as this helps us to create \"good\" clusters (for example, if there are only black socks in the set of socks, clustering by colours would not be the way to go)\n\nHere's the algorithm for take_socks_from_line():\n\nwhile(socks left on line) {\n take_next_sock();\n if (matching pair visible on line or in basket) {\n   Take it as well, pair 'em and put 'em away\n } else {\n   put the sock in the basket\n }\n\n\nI should point out that in order to improve the speed of the remaining steps, it is wise not to randomly pick the next sock, but to sequentially take sock after sock from each cluster. Both preprocessing steps don't take more time than just putting the socks on the line or in the basket, which we have to do no matter what, so this should greatly enhance the laundry performance.\n\nAfter this, it's easy to do the hash partitioning algorithm. Usually, about 75% of the socks are already paired, leaving me with a very small subset of socks, and this subset is already (somewhat) clustered (I don't introduce much entropy into my basket after the preprocessing steps). Another thing is that the remaining clusters tend to be small enough to be handled at once, so it is possible to take a whole cluster out of the basket.\n\nHere's the algorithm for sort_remaining_clusters():\n\nwhile(clusters present in basket) {\n  Take out the cluster and spread it\n  Process it immediately\n  Leave remaining socks where they are\n}\n\n\nAfter that, there are only a few socks left. This is where I introduce previously unpaired socks into the system and process the remaining socks without any special algorithm - the remaining socks are very few and can be processed visually very fast.\n\nFor all remaining socks, I assume that their counterparts are still unwashed and put them away for the next iteration. If you register a growth of unpaired socks over time (a \"sock leak\"), you should check your bin - it might get randomized (do you have cats which sleep in there?)\n\nI know that these algorithms take a lot of assumptions: a bin which acts as some sort of LIFO stack, a limited, normal washing machine, and a limited, normal clothesline - but this still works with very large numbers of socks.\n\nAbout parallelism: As long as you toss both socks into the same bin, you can easily parallelize all of those steps.\n\nShare\nImprove this answer\nFollow\nedited Jul 29 '19 at 11:51\ncommunity wiki\n\n\n3 revs, 2 users 93%\nPhilipp Flenker","comments":["Socks are only metaphor for pairing arbitrary objects in some database.","Got it, didn't see that you are the author. If you wanted a generic solution, you should really have said so. Anyway, there is nothing wrong with taking any information you have into account, unless you have to come up with a general solution - giving up the reusability of the solution could result in considerably better performance. In this case, considering the use case and the available data base as a whole is be beneficial. However, this special answer to your special question has issues with similar-looking socks, e.g. black socks in different sizes, so it's not applicable in some cases.","Also, you did not get >2k upvotes because you asked a question about pairing arbitrary objects in the database. You specifically constrained the question due to the very nature of socks (which you cannot duplicate, as opposed to data), you even encouraged to use the fact that you can easily distinguish your socks from the socks of your spouse. If you ask a question about socks, don't expect the answers to be about databases ;-)","There are a few assumptions: a normal washing mashine, a, normal clothesline, and the fact that you toss both socks in the bin at the same time, which means that in most cases both socks are in the same machine, and the number of leftover socks to be sorted is therefore small. But since you really wanted an answer about storing arbitrary objects in the database, is it really useful discussing my solution any futher?","As I said, I think that I addressed everything you asked for, except for the element distinctness problem, which has been answered by other people. I'm not trying to be a douche here, but I have put a lot of effort in this answer a while back, and am mildly disappointed that you now go through some of the answers and claim that they didn't answer the original question. Why don't you just leave the whole thread alone - it's still an interesting read, over 2 years after you asked it?"]},{"answer":"I have taken simple steps to reduce my effort into a process taking O(1) time.\n\nBy reducing my inputs to one of two types of socks (white socks for recreation, black socks for work), I only need to determine which of two socks I have in hand. (Technically, since they are never washed together, I have reduced the process to O(0) time.)\n\nSome upfront effort is required to find desirable socks, and to purchase in sufficient quantity as to eliminate need for your existing socks. As I'd done this before my need for black socks, my effort was minimal, but mileage may vary.\n\nSuch an upfront effort has been seen many times in very popular and effective code. Examples include #DEFINE'ing pi to several decimals (other examples exist, but that's the one that comes to mind right now).\n\nShare\nImprove this answer\nFollow\nedited Apr 23 '20 at 19:20\ncommunity wiki\n\n\n2 revs, 2 users 92%\nScott Brickey","comments":[]},{"answer":"The problem of sorting your n pairs of socks is O(n). Before you throw them in the laundry basket, you thread the left one to the right one. On taking them out, you cut the thread and put each pair into your drawer - 2 operations on n pairs, so O(n).\n\nNow the next question is simply whether you do your own laundry and your wife does hers. That is a problem likely in an entirely different domain of problems. :)\n\nShare\nImprove this answer\nFollow\nanswered Oct 8 '13 at 22:47\ncommunity wiki\n\n\nFred Mitchell","comments":["This does not answer the question, where the socks are only a metaphor.","The question was how to pair the socks from an unpaired pile, not how to avoid needing to pair."]},{"answer":"If the \"move\" operation is fairly expensive, and the \"compare\" operation is cheap, and you need to move the whole set anyway, into a buffer where search is much faster than in original storage... just integrate sorting into the obligatory move.\n\nI found integrating the process of sorting into hanging to dry makes it a breeze. I need to pick up each sock anyway, and hang it (move) and it costs me about nothing to hang it in a specific place on the strings. Now just not to force search of the whole buffer (the strings) I choose to place socks by color/shade. Darker left, brighter right, more colorful front etc. Now before I hang each sock, I look in its \"right vicinity\" if a matching one is there already - this limits \"scan\" to 2-3 other socks - and if it is, I hang the other one right next to it. Then I roll them into pairs while removing from the strings, when dry.\n\nNow this may not seem all that different from \"forming piles by color\" suggested by top answers but first, by not picking discrete piles but ranges, I have no problem classifying whether \"purple\" goes to \"red\" or \"blue\" pile; it just goes between. And then by integrating two operations (hang to dry and sort) the overhead of sorting while hanging is like 10% of what separate sorting would be.\n\nShare\nImprove this answer\nFollow\nanswered Sep 21 '14 at 8:49\ncommunity wiki\n\n\nSF.","comments":["This approach has two other advantages: line-drying loses many fewer socks IME than the tumble dryer does, and the sort process can be extended to the rest of the laundry, so (e.g.) all towels are near each other to be folded off the line and binned and taken straight to their storage. It also works in two low-effort passes, putting the clothes up and taking them down again."]},{"answer":"I've finished pairing my socks just right now, and I found that the best way to do it is the following:\n\nChoose one of the socks and put it away (create a 'bucket' for that pair)\nIf the next one is the pair of the previous one, then put it to the existing bucket, otherwise create a new one.\n\nIn the worst case it means that you will have n/2 different buckets, and you will have n-2 determinations about that which bucket contains the pair of the current sock. Obviously, this algorithm works well if you have just a few pairs; I did it with 12 pairs.\n\nIt is not so scientific, but it works well:)\n\nShare\nImprove this answer\nFollow\nedited Feb 2 '15 at 18:39\ncommunity wiki\n\n\n2 revs, 2 users 63%\nmaestro","comments":["This is still an O(n^2) algorithm since you have to iterate over each bucket whenever you pull out a new sock. But, considering the fact that even the socks bought within the same batch have minor differences which render them effectively pair-unique (or even single-unique), there's no better way anyway","Agree, but my algorithm is assuming that human is doing the pairing. Therefore, there will be a kind-of cache in your mind when you are searching for the matching bucket, so you don't really need to iterate over the buckets anyway. Not sure what kind of data structure is built for this caching mechanism in my head during the pairing."]},{"answer":"My solution does not exactly correspond to your requirements, as it formally requires O(n) \"extra\" space. However, considering my conditions it is very efficient in my practical application. Thus I think it should be interesting.\n\nCombine with Other Task\n\nThe special condition in my case is that I don't use drying machine, just hang my cloths on an ordinary cloth dryer. Hanging cloths requires O(n) operations (by the way, I always consider bin packing problem here) and the problem by its nature requires the linear \"extra\" space. When I take a new sock from the bucket I to try hang it next to its pair if the pair is already hung. If its a sock from a new pair I leave some space next to it.\n\nOracle Machine is Better ;-)\n\nIt obviously requires some extra work to check if there is the matching sock already hanging somewhere and it would render solution O(n^2) with coefficient about 1/2 for a computer. But in this case the \"human factor\" is actually an advantage -- I usually can very quickly (almost O(1)) identify the matching sock if it was already hung (probably some imperceptible in-brain caching is involved) -- consider it a kind of limited \"oracle\" as in Oracle Machine ;-) We, the humans have these advantages over digital machines in some cases ;-)\n\nHave it Almost O(n)!\n\nThus connecting the problem of pairing socks with the problem of hanging cloths I get O(n) \"extra space\" for free, and have a solution that is about O(n) in time, requires just a little more work than simple hanging cloths and allows to immediately access complete pair of socks even in a very bad Monday morning... ;-)\n\nShare\nImprove this answer\nFollow\nedited May 28 '15 at 8:26\nanswered May 27 '15 at 19:13\nwrzasa\n1,0539\n9 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"Create a hash table which will be used for unmatched socks, using the pattern as the hash. Iterate over the socks one by one. If the sock has a pattern match in the hash table, take the sock out of the table and make a pair. If the sock does not have a match, put it into the table.\n\nShare\nImprove this answer\nFollow\nanswered Sep 8 '13 at 20:07\ncommunity wiki\n\n\nviper110110","comments":["How to do it not in-place, as specifically mentioned in the question?"]}]},{"id":"16047306","href":"https://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-virtual-machine","title":"How is Docker different from a virtual machine?","description":"\n                \nI keep rereading the Docker documentation to try to understand the difference between Docker and a full VM. How does it manage to provide a full filesystem, isolated networking environment, etc. without being as heavy?\n\nWhy is deploying software to a Docker image (if that's the right term) easier than simply deploying to a consistent production environment?\n    ","questionComments":["Docker vs KVM performance analysis: bodenr.blogspot.com/2014/05/…","Docker isn't a virtual machine - it is a configuration management tool.","In simple words: VM -> three virtual layer must run for allow to your app run, if you want a server virtualization OK but if you want only run a web application is not the best solution. DOCKER -> Only one layer between your real cpu and you web application. More powerful and better cloning/mirroring if you must only run your web application for virtualize those i reccomend it","let's not forget that Docker for Mac and Docker for Windows do use the virtualization layer.","This article compares Docker-on-Windows with Docker-on-Linux, giving some helpful insights: collabnix.com/…"],"answers":[{"answer":"Docker originally used LinuX Containers (LXC), but later switched to runC (formerly known as libcontainer), which runs in the same operating system as its host. This allows it to share a lot of the host operating system resources. Also, it uses a layered filesystem (AuFS) and manages networking.\n\nAuFS is a layered file system, so you can have a read only part and a write part which are merged together. One could have the common parts of the operating system as read only (and shared amongst all of your containers) and then give each container its own mount for writing.\n\nSo, let's say you have a 1 GB container image; if you wanted to use a full VM, you would need to have 1 GB x number of VMs you want. With Docker and AuFS you can share the bulk of the 1 GB between all the containers and if you have 1000 containers you still might only have a little over 1 GB of space for the containers OS (assuming they are all running the same OS image).\n\nA full virtualized system gets its own set of resources allocated to it, and does minimal sharing. You get more isolation, but it is much heavier (requires more resources). With Docker you get less isolation, but the containers are lightweight (require fewer resources). So you could easily run thousands of containers on a host, and it won't even blink. Try doing that with Xen, and unless you have a really big host, I don't think it is possible.\n\nA full virtualized system usually takes minutes to start, whereas Docker/LXC/runC containers take seconds, and often even less than a second.\n\nThere are pros and cons for each type of virtualized system. If you want full isolation with guaranteed resources, a full VM is the way to go. If you just want to isolate processes from each other and want to run a ton of them on a reasonably sized host, then Docker/LXC/runC seems to be the way to go.\n\nFor more information, check out this set of blog posts which do a good job of explaining how LXC works.\n\nWhy is deploying software to a docker image (if that's the right term) easier than simply deploying to a consistent production environment?\n\nDeploying a consistent production environment is easier said than done. Even if you use tools like Chef and Puppet, there are always OS updates and other things that change between hosts and environments.\n\nDocker gives you the ability to snapshot the OS into a shared image, and makes it easy to deploy on other Docker hosts. Locally, dev, qa, prod, etc.: all the same image. Sure you can do this with other tools, but not nearly as easily or fast.\n\nThis is great for testing; let's say you have thousands of tests that need to connect to a database, and each test needs a pristine copy of the database and will make changes to the data. The classic approach to this is to reset the database after every test either with custom code or with tools like Flyway - this can be very time-consuming and means that tests must be run serially. However, with Docker you could create an image of your database and run up one instance per test, and then run all the tests in parallel since you know they will all be running against the same snapshot of the database. Since the tests are running in parallel and in Docker containers they could run all on the same box at the same time and should finish much faster. Try doing that with a full VM.\n\nFrom comments...\n\nInteresting! I suppose I'm still confused by the notion of \"snapshot[ting] the OS\". How does one do that without, well, making an image of the OS?\n\nWell, let's see if I can explain. You start with a base image, and then make your changes, and commit those changes using docker, and it creates an image. This image contains only the differences from the base. When you want to run your image, you also need the base, and it layers your image on top of the base using a layered file system: as mentioned above, Docker uses AuFS. AuFS merges the different layers together and you get what you want; you just need to run it. You can keep adding more and more images (layers) and it will continue to only save the diffs. Since Docker typically builds on top of ready-made images from a registry, you rarely have to \"snapshot\" the whole OS yourself.\n\nShare\nImprove this answer\nFollow\nedited Nov 19 '19 at 19:29\nHassan Ahmed\n4053\n3 silver badges\n9\n9 bronze badges\nanswered Apr 16 '13 at 22:35\nKen Cochrane\n69.8k9\n9 gold badges\n46\n46 silver badges\n58\n58 bronze badges","comments":[]},{"answer":"Good answers. Just to get an image representation of container vs VM, have a look at the one below.\n\nSource\n\nShare\nImprove this answer\nFollow\nedited Nov 7 '18 at 12:12\nUwe Keim\n37.1k53\n53 gold badges\n163\n163 silver badges\n270\n270 bronze badges\nanswered Oct 14 '15 at 18:02\nmanu97\n6,6612\n2 gold badges\n15\n15 silver badges\n20\n20 bronze badges","comments":["<strike>As far as I understand, above the \"docker engine\" there should be a shared linux kernel. Then there are commonly even shared bins/libs. First after that comes the bins/libs and apps that are specific to each container. Please correct me if I am wrong.</strike> I was wrong. Docker images shares the kernel with the host, see superuser.com/questions/889472/…. However, to illustrate the union filesystem of the containers, there could be a shared layer of libs/bins directly above the docker engine.","I have a problem with the picture above, because Hypervisor can be installed on bare metal/infrastructure but Docket cannot (yet)","@reza, I agree Hypervisor can be installed on Bare metal, but the point is Docker is recommended for containerization of apps and how to limit or avoid the virtualization which is not needed/applicable for some scenarios. Ken Cochrane explains this more in detail stackoverflow.com/a/16048358/2478933","This does not clarify what is Docker Engine. Very abstract pictures.","There is no \"Docker Engine\" layer between container and kernel, container is just a process with special settings in the kernel (namespaces, cgroups, etc.)"]},{"answer":"It might be helpful to understand how virtualization and containers work at a low level. That will clear up lot of things.\n\nNote: I'm simplifying a bit in the description below. See references for more information.\n\nHow does virtualization work at a low level?\n\nIn this case the VM manager takes over the CPU ring 0 (or the \"root mode\" in newer CPUs) and intercepts all privileged calls made by the guest OS to create the illusion that the guest OS has its own hardware. Fun fact: Before 1998 it was thought to be impossible to achieve this on the x86 architecture because there was no way to do this kind of interception. The folks at VMware were the first who had an idea to rewrite the executable bytes in memory for privileged calls of the guest OS to achieve this.\n\nThe net effect is that virtualization allows you to run two completely different OSes on the same hardware. Each guest OS goes through all the processes of bootstrapping, loading kernel, etc. You can have very tight security. For example, a guest OS can't get full access to the host OS or other guests and mess things up.\n\nHow do containers work at a low level?\n\nAround 2006, people including some of the employees at Google implemented a new kernel level feature called namespaces (however the idea long before existed in FreeBSD). One function of the OS is to allow sharing of global resources like network and disks among processes. What if these global resources were wrapped in namespaces so that they are visible only to those processes that run in the same namespace? Say, you can get a chunk of disk and put that in namespace X and then processes running in namespace Y can't see or access it. Similarly, processes in namespace X can't access anything in memory that is allocated to namespace Y. Of course, processes in X can't see or talk to processes in namespace Y. This provides a kind of virtualization and isolation for global resources. This is how Docker works: Each container runs in its own namespace but uses exactly the same kernel as all other containers. The isolation happens because the kernel knows the namespace that was assigned to the process and during API calls it makes sure that the process can only access resources in its own namespace.\n\nThe limitations of containers vs VMs should be obvious now: You can't run completely different OSes in containers like in VMs. However you can run different distros of Linux because they do share the same kernel. The isolation level is not as strong as in a VM. In fact, there was a way for a \"guest\" container to take over the host in early implementations. Also you can see that when you load a new container, an entire new copy of the OS doesn't start like it does in a VM. All containers share the same kernel. This is why containers are light weight. Also unlike a VM, you don't have to pre-allocate a significant chunk of memory to containers because we are not running a new copy of the OS. This enables running thousands of containers on one OS while sandboxing them, which might not be possible if we were running separate copies of the OS in their own VMs.\n\nShare\nImprove this answer\nFollow\nedited Aug 11 '20 at 14:08\nBoann\n45.4k13\n13 gold badges\n107\n107 silver badges\n138\n138 bronze badges\nanswered Jan 13 '16 at 1:49\nShital Shah\n49.5k10\n10 gold badges\n196\n196 silver badges\n162\n162 bronze badges","comments":["Wow, thanks for the great low-level explanation (and historical facts). I was looking for that and is not found above. What do you mean by \"you can run different distros of Linux because they do share the same kernel.\"? Are you saying that a guest container must have the exact same Linux kernel version or that it doesn't matter? If it doesn't matter what if I invoke an OS command on the guest but is only supported in the guest kernel. Or for example a bug fixed in the guest kernel but not in the host kernel. All guests would manifest the bug, correct? Even though the guests were patched.","@Jeach: the containers don't have their own kernel, they're sharing/using the one of the host. So you can't run containers that need different kernels on the same machine/VM.","+1 This should be the marked answer, whilst the other answers offer some clarification, only a bottom up low level explanation can clear up how this tech works, 'processes grouped in their own namespace = container'. Thank you so much, I get it now.","Yes. But note that a container is more than an application of namespaces. It also uses facilities like control groups for resource limiting and accounting, and a union-capable file system for efficient file system allocation. But yes, ultimately a container is a use-case for a bunch of pre-existing OS facilities."]},{"answer":"I like Ken Cochrane's answer.\n\nBut I want to add additional point of view, not covered in detail here. In my opinion Docker differs also in whole process. In contrast to VMs, Docker is not (only) about optimal resource sharing of hardware, moreover it provides a \"system\" for packaging application (preferable, but not a must, as a set of microservices).\n\nTo me it fits in the gap between developer-oriented tools like rpm, Debian packages, Maven, npm + Git on one side and ops tools like Puppet, VMware, Xen, you name it...\n\nWhy is deploying software to a docker image (if that's the right term) easier than simply deploying to a consistent production environment?\n\nYour question assumes some consistent production environment. But how to keep it consistent? Consider some amount (>10) of servers and applications, stages in the pipeline.\n\nTo keep this in sync you'll start to use something like Puppet, Chef or your own provisioning scripts, unpublished rules and/or lot of documentation... In theory servers can run indefinitely, and be kept completely consistent and up to date. Practice fails to manage a server's configuration completely, so there is considerable scope for configuration drift, and unexpected changes to running servers.\n\nSo there is a known pattern to avoid this, the so called immutable server. But the immutable server pattern was not loved. Mostly because of the limitations of VMs that were used before Docker. Dealing with several gigabytes big images, moving those big images around, just to change some fields in the application, was very very laborious. Understandable...\n\nWith a Docker ecosystem, you will never need to move around gigabytes on \"small changes\" (thanks aufs and Registry) and you don't need to worry about losing performance by packaging applications into a Docker container at runtime. You don't need to worry about versions of that image.\n\nAnd finally you will even often be able to reproduce complex production environments even on your Linux laptop (don't call me if doesn't work in your case ;))\n\nAnd of course you can start Docker containers in VMs (it's a good idea). Reduce your server provisioning on the VM level. All the above could be managed by Docker.\n\nP.S. Meanwhile Docker uses its own implementation \"libcontainer\" instead of LXC. But LXC is still usable.\n\nShare\nImprove this answer\nFollow\nedited Aug 28 '18 at 20:13\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 19 '14 at 16:21\naholbreich\n4,5231\n1 gold badge\n20\n20 silver badges\n34\n34 bronze badges","comments":["Seems odd to include git in a group of tools like rpm and dpkg. I mention this because I see the attempts to use versions control systems like git as a distribution/packaging tool to be a source of much confusion.","he's not wrong though, git can be used for package management, bower for example is internally basically a fancy cli for downloading git tags.","packaging applications in containers is an interesting and valid approach. However if you packaged it in docker this would be overkill, as there would not be straightforward support for dependencies or any shared libraries. This is exactly what new packaging tech like Ubuntu Snap and Flatpak for Redhat are trying to achieve. In my opinion, one of these packaging tech will win and become the future of packaging in linux.","@blitzen9872 agree on this. But was mentioned exactly because it used so often in for distributuon in praxis, again i don't like it either."]},{"answer":"Docker isn't a virtualization methodology. It relies on other tools that actually implement container-based virtualization or operating system level virtualization. For that, Docker was initially using LXC driver, then moved to libcontainer which is now renamed as runc. Docker primarily focuses on automating the deployment of applications inside application containers. Application containers are designed to package and run a single service, whereas system containers are designed to run multiple processes, like virtual machines. So, Docker is considered as a container management or application deployment tool on containerized systems.\n\nIn order to know how it is different from other virtualizations, let's go through virtualization and its types. Then, it would be easier to understand what's the difference there.\n\nVirtualization\n\nIn its conceived form, it was considered a method of logically dividing mainframes to allow multiple applications to run simultaneously. However, the scenario drastically changed when companies and open source communities were able to provide a method of handling the privileged instructions in one way or another and allow for multiple operating systems to be run simultaneously on a single x86 based system.\n\nHypervisor\n\nThe hypervisor handles creating the virtual environment on which the guest virtual machines operate. It supervises the guest systems and makes sure that resources are allocated to the guests as necessary. The hypervisor sits in between the physical machine and virtual machines and provides virtualization services to the virtual machines. To realize it, it intercepts the guest operating system operations on the virtual machines and emulates the operation on the host machine's operating system.\n\nThe rapid development of virtualization technologies, primarily in cloud, has driven the use of virtualization further by allowing multiple virtual servers to be created on a single physical server with the help of hypervisors, such as Xen, VMware Player, KVM, etc., and incorporation of hardware support in commodity processors, such as Intel VT and AMD-V.\n\nTypes of Virtualization\n\nThe virtualization method can be categorized based on how it mimics hardware to a guest operating system and emulates a guest operating environment. Primarily, there are three types of virtualization:\n\nEmulation\nParavirtualization\nContainer-based virtualization\n\nEmulation\n\nEmulation, also known as full virtualization runs the virtual machine OS kernel entirely in software. The hypervisor used in this type is known as Type 2 hypervisor. It is installed on the top of the host operating system which is responsible for translating guest OS kernel code to software instructions. The translation is done entirely in software and requires no hardware involvement. Emulation makes it possible to run any non-modified operating system that supports the environment being emulated. The downside of this type of virtualization is an additional system resource overhead that leads to a decrease in performance compared to other types of virtualizations.\n\nExamples in this category include VMware Player, VirtualBox, QEMU, Bochs, Parallels, etc.\n\nParavirtualization\n\nParavirtualization, also known as Type 1 hypervisor, runs directly on the hardware, or “bare-metal”, and provides virtualization services directly to the virtual machines running on it. It helps the operating system, the virtualized hardware, and the real hardware to collaborate to achieve optimal performance. These hypervisors typically have a rather small footprint and do not, themselves, require extensive resources.\n\nExamples in this category include Xen, KVM, etc.\n\nContainer-based Virtualization\n\nContainer-based virtualization, also known as operating system-level virtualization, enables multiple isolated executions within a single operating system kernel. It has the best possible performance and density and features dynamic resource management. The isolated virtual execution environment provided by this type of virtualization is called a container and can be viewed as a traced group of processes.\n\nThe concept of a container is made possible by the namespaces feature added to Linux kernel version 2.6.24. The container adds its ID to every process and adding new access control checks to every system call. It is accessed by the clone() system call that allows creating separate instances of previously-global namespaces.\n\nNamespaces can be used in many different ways, but the most common approach is to create an isolated container that has no visibility or access to objects outside the container. Processes running inside the container appear to be running on a normal Linux system although they are sharing the underlying kernel with processes located in other namespaces, same for other kinds of objects. For instance, when using namespaces, the root user inside the container is not treated as root outside the container, adding additional security.\n\nThe Linux Control Groups (cgroups) subsystem, the next major component to enable container-based virtualization, is used to group processes and manage their aggregate resource consumption. It is commonly used to limit the memory and CPU consumption of containers. Since a containerized Linux system has only one kernel and the kernel has full visibility into the containers, there is only one level of resource allocation and scheduling.\n\nSeveral management tools are available for Linux containers, including LXC, LXD, systemd-nspawn, lmctfy, Warden, Linux-VServer, OpenVZ, Docker, etc.\n\nContainers vs Virtual Machines\n\nUnlike a virtual machine, a container does not need to boot the operating system kernel, so containers can be created in less than a second. This feature makes container-based virtualization unique and desirable than other virtualization approaches.\n\nSince container-based virtualization adds little or no overhead to the host machine, container-based virtualization has near-native performance\n\nFor container-based virtualization, no additional software is required, unlike other virtualizations.\n\nAll containers on a host machine share the scheduler of the host machine saving need of extra resources.\n\nContainer states (Docker or LXC images) are small in size compared to virtual machine images, so container images are easy to distribute.\n\nResource management in containers is achieved through cgroups. Cgroups does not allow containers to consume more resources than allocated to them. However, as of now, all resources of host machine are visible in virtual machines, but can't be used. This can be realized by running top or htop on containers and host machine at the same time. The output across all environments will look similar.\n\nUpdate:\n\nHow does Docker run containers in non-Linux systems?\n\nIf containers are possible because of the features available in the Linux kernel, then the obvious question is how do non-Linux systems run containers. Both Docker for Mac and Windows use Linux VMs to run the containers. Docker Toolbox used to run containers in Virtual Box VMs. But, the latest Docker uses Hyper-V in Windows and Hypervisor.framework in Mac.\n\nNow, let me describe how Docker for Mac runs containers in detail.\n\nDocker for Mac uses https://github.com/moby/hyperkit to emulate the hypervisor capabilities and Hyperkit uses hypervisor.framework in its core. Hypervisor.framework is Mac's native hypervisor solution. Hyperkit also uses VPNKit and DataKit to namespace network and filesystem respectively.\n\nThe Linux VM that Docker runs in Mac is read-only. However, you can bash into it by running:\n\nscreen ~/Library/Containers/com.docker.docker/Data/vms/0/tty.\n\nNow, we can even check the Kernel version of this VM:\n\n# uname -a\nLinux linuxkit-025000000001 4.9.93-linuxkit-aufs #1 SMP Wed Jun 6 16:86_64 Linux.\n\nAll containers run inside this VM.\n\nThere are some limitations to hypervisor.framework. Because of that Docker doesn't expose docker0 network interface in Mac. So, you can't access containers from the host. As of now, docker0 is only available inside the VM.\n\nHyper-v is the native hypervisor in Windows. They are also trying to leverage Windows 10's capabilities to run Linux systems natively.\n\nShare\nImprove this answer\nFollow\nedited Nov 20 '19 at 22:22\nHassan Ahmed\n4053\n3 silver badges\n9\n9 bronze badges\nanswered Apr 2 '16 at 0:55\nAshish Bista\n3,9651\n1 gold badge\n16\n16 silver badges\n22\n22 bronze badges","comments":[]},{"answer":"Most of the answers here talk about virtual machines. I'm going to give you a one-liner response to this question that has helped me the most over the last couple years of using Docker. It's this:\n\nDocker is just a fancy way to run a process, not a virtual machine.\n\nNow, let me explain a bit more about what that means. Virtual machines are their own beast. I feel like explaining what Docker is will help you understand this more than explaining what a virtual machine is. Especially because there are many fine answers here telling you exactly what someone means when they say \"virtual machine\". So...\n\nA Docker container is just a process (and its children) that is compartmentalized using cgroups inside the host system's kernel from the rest of the processes. You can actually see your Docker container processes by running ps aux on the host. For example, starting apache2 \"in a container\" is just starting apache2 as a special process on the host. It's just been compartmentalized from other processes on the machine. It is important to note that your containers do not exist outside of your containerized process' lifetime. When your process dies, your container dies. That's because Docker replaces pid 1 inside your container with your application (pid 1 is normally the init system). This last point about pid 1 is very important.\n\nAs far as the filesystem used by each of those container processes, Docker uses UnionFS-backed images, which is what you're downloading when you do a docker pull ubuntu. Each \"image\" is just a series of layers and related metadata. The concept of layering is very important here. Each layer is just a change from the layer underneath it. For example, when you delete a file in your Dockerfile while building a Docker container, you're actually just creating a layer on top of the last layer which says \"this file has been deleted\". Incidentally, this is why you can delete a big file from your filesystem, but the image still takes up the same amount of disk space. The file is still there, in the layers underneath the current one. Layers themselves are just tarballs of files. You can test this out with docker save --output /tmp/ubuntu.tar ubuntu and then cd /tmp && tar xvf ubuntu.tar. Then you can take a look around. All those directories that look like long hashes are actually the individual layers. Each one contains files (layer.tar) and metadata (json) with information about that particular layer. Those layers just describe changes to the filesystem which are saved as a layer \"on top of\" its original state. When reading the \"current\" data, the filesystem reads data as though it were looking only at the top-most layers of changes. That's why the file appears to be deleted, even though it still exists in \"previous\" layers, because the filesystem is only looking at the top-most layers. This allows completely different containers to share their filesystem layers, even though some significant changes may have happened to the filesystem on the top-most layers in each container. This can save you a ton of disk space, when your containers share their base image layers. However, when you mount directories and files from the host system into your container by way of volumes, those volumes \"bypass\" the UnionFS, so changes are not stored in layers.\n\nNetworking in Docker is achieved by using an ethernet bridge (called docker0 on the host), and virtual interfaces for every container on the host. It creates a virtual subnet in docker0 for your containers to communicate \"between\" one another. There are many options for networking here, including creating custom subnets for your containers, and the ability to \"share\" your host's networking stack for your container to access directly.\n\nDocker is moving very fast. Its documentation is some of the best documentation I've ever seen. It is generally well-written, concise, and accurate. I recommend you check the documentation available for more information, and trust the documentation over anything else you read online, including Stack Overflow. If you have specific questions, I highly recommend joining #docker on Freenode IRC and asking there (you can even use Freenode's webchat for that!).\n\nShare\nImprove this answer\nFollow\nedited Jun 15 '16 at 19:09\nanswered Apr 4 '16 at 2:35\nL0j1k\n11.1k7\n7 gold badges\n49\n49 silver badges\n64\n64 bronze badges","comments":["\"Docker is just a fancy way to run a process, not a virtual machine.\" this is a great summary, thanks!","Thanks! The credit for that goes out to programmerq from the #docker channel on Freenode IRC."]},{"answer":"Through this post we are going to draw some lines of differences between VMs and LXCs. Let's first define them.\n\nVM:\n\nA virtual machine emulates a physical computing environment, but requests for CPU, memory, hard disk, network and other hardware resources are managed by a virtualization layer which translates these requests to the underlying physical hardware.\n\nIn this context the VM is called as the Guest while the environment it runs on is called the host.\n\nLXCs:\n\nLinux Containers (LXC) are operating system-level capabilities that make it possible to run multiple isolated Linux containers, on one control host (the LXC host). Linux Containers serve as a lightweight alternative to VMs as they don’t require the hypervisors viz. Virtualbox, KVM, Xen, etc.\n\nNow unless you were drugged by Alan (Zach Galifianakis- from the Hangover series) and have been in Vegas for the last year, you will be pretty aware about the tremendous spurt of interest for Linux containers technology, and if I will be specific one container project which has created a buzz around the world in last few months is – Docker leading to some echoing opinions that cloud computing environments should abandon virtual machines (VMs) and replace them with containers due to their lower overhead and potentially better performance.\n\nBut the big question is, is it feasible?, will it be sensible?\n\na. LXCs are scoped to an instance of Linux. It might be different flavors of Linux (e.g. a Ubuntu container on a CentOS host but it’s still Linux.) Similarly, Windows-based containers are scoped to an instance of Windows now if we look at VMs they have a pretty broader scope and using the hypervisors you are not limited to operating systems Linux or Windows.\n\nb. LXCs have low overheads and have better performance as compared to VMs. Tools viz. Docker which are built on the shoulders of LXC technology have provided developers with a platform to run their applications and at the same time have empowered operations people with a tool that will allow them to deploy the same container on production servers or data centers. It tries to make the experience between a developer running an application, booting and testing an application and an operations person deploying that application seamless, because this is where all the friction lies in and purpose of DevOps is to break down those silos.\n\nSo the best approach is the cloud infrastructure providers should advocate an appropriate use of the VMs and LXC, as they are each suited to handle specific workloads and scenarios.\n\nAbandoning VMs is not practical as of now. So both VMs and LXCs have their own individual existence and importance.\n\nShare\nImprove this answer\nFollow\nedited Mar 11 '17 at 17:19\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 26 '14 at 7:46\nPankaj Arora\n1,6411\n1 gold badge\n8\n8 silver badges\n4\n4 bronze badges","comments":["Your part \"b\" above is exactly what the Docker folks have been saying about the technology. It's meant to make the development and deployment tasks easier. And based on my experience as a dev and as a sysop, I have to agree.","It's pretty abstract answer. We need use-cases when to use/not use Docker. That's the question. Everyone can find what the Docker is like but only a few can explain on real scenarios.","docker is being brought into the windows world now, since it's no longer dependent on LXC: blogs.msdn.com/b/nzdev/archive/2015/06/02/… please correct me if I misunderstood the answers here","I have a hard time understanding the \"(e.g. a Ubuntu container on a Centos host but it’s still Linux)\" part of the containers. The way I understand it, is that containers share the host kernel. If I have a host VM running Linux kernel 4.6 for example, having several guest VM's running Linux kernels 2.4, 2.6, 3.2, 4.1 and 4.4. If I execute commands specific to that kernel, I will get the guest kernel's behavior (and not the host). But if my guest VM's are containers now, would the executed command be determined by the host kernel?","Upvote for Alan reference!"]},{"answer":"Docker encapsulates an application with all its dependencies.\n\nA virtualizer encapsulates an OS that can run any applications it can normally run on a bare metal machine.\n\nShare\nImprove this answer\nFollow\nedited Aug 28 '18 at 20:07\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 27 '14 at 18:25\nGiovanni De Gasperis\n1,1851\n1 gold badge\n7\n7 silver badges\n3\n3 bronze badges","comments":["I'm learning about LXC, correct me if I'm wrong, but it could be some sort of virtualenv? but obviously broader, not just circunscripted to python for saying","I like this answer the best. It simple and goes straight to point. Now that one has a basic understand of WHAT LXC and Virtualizers can do, the details from other reading will make sense.","@Phil It did after I read the detailed answers above it first.","I assume they want to know how to encapsulate. That's the big part which would show the difference between them but you did not answer."]},{"answer":"They both are very different. Docker is lightweight and uses LXC/libcontainer (which relies on kernel namespacing and cgroups) and does not have machine/hardware emulation such as hypervisor, KVM. Xen which are heavy.\n\nDocker and LXC is meant more for sandboxing, containerization, and resource isolation. It uses the host OS's (currently only Linux kernel) clone API which provides namespacing for IPC, NS (mount), network, PID, UTS, etc.\n\nWhat about memory, I/O, CPU, etc.? That is controlled using cgroups where you can create groups with certain resource (CPU, memory, etc.) specification/restriction and put your processes in there. On top of LXC, Docker provides a storage backend (http://www.projectatomic.io/docs/filesystems/) e.g., union mount filesystem where you can add layers and share layers between different mount namespaces.\n\nThis is a powerful feature where the base images are typically readonly and only when the container modifies something in the layer will it write something to read-write partition (a.k.a. copy on write). It also provides many other wrappers such as registry and versioning of images.\n\nWith normal LXC you need to come with some rootfs or share the rootfs and when shared, and the changes are reflected on other containers. Due to lot of these added features, Docker is more popular than LXC. LXC is popular in embedded environments for implementing security around processes exposed to external entities such as network and UI. Docker is popular in cloud multi-tenancy environment where consistent production environment is expected.\n\nA normal VM (for example, VirtualBox and VMware) uses a hypervisor, and related technologies either have dedicated firmware that becomes the first layer for the first OS (host OS, or guest OS 0) or a software that runs on the host OS to provide hardware emulation such as CPU, USB/accessories, memory, network, etc., to the guest OSes. VMs are still (as of 2015) popular in high security multi-tenant environment.\n\nDocker/LXC can almost be run on any cheap hardware (less than 1 GB of memory is also OK as long as you have newer kernel) vs. normal VMs need at least 2 GB of memory, etc., to do anything meaningful with it. But Docker support on the host OS is not available in OS such as Windows (as of Nov 2014) where as may types of VMs can be run on windows, Linux, and Macs.\n\nHere is a pic from docker/rightscale : \n\nShare\nImprove this answer\nFollow\nedited Apr 3 '17 at 5:15\nanswered Nov 3 '14 at 17:44\nresultsway\n9,2835\n5 gold badges\n30\n30 silver badges\n38\n38 bronze badges","comments":[]},{"answer":"1. Lightweight\n\nThis is probably the first impression for many docker learners.\n\nFirst, docker images are usually smaller than VM images, makes it easy to build, copy, share.\n\nSecond, Docker containers can start in several milliseconds, while VM starts in seconds.\n\n2. Layered File System\n\nThis is another key feature of Docker. Images have layers, and different images can share layers, make it even more space-saving and faster to build.\n\nIf all containers use Ubuntu as their base images, not every image has its own file system, but share the same underline ubuntu files, and only differs in their own application data.\n\n3. Shared OS Kernel\n\nThink of containers as processes!\n\nAll containers running on a host is indeed a bunch of processes with different file systems. They share the same OS kernel, only encapsulates system library and dependencies.\n\nThis is good for most cases(no extra OS kernel maintains) but can be a problem if strict isolations are necessary between containers.\n\nWhy it matters?\n\nAll these seem like improvements, not revolution. Well, quantitative accumulation leads to qualitative transformation.\n\nThink about application deployment. If we want to deploy a new software(service) or upgrade one, it is better to change the config files and processes instead of creating a new VM. Because Creating a VM with updated service, testing it(share between Dev & QA), deploying to production takes hours, even days. If anything goes wrong, you got to start again, wasting even more time. So, use configuration management tool(puppet, saltstack, chef etc.) to install new software, download new files is preferred.\n\nWhen it comes to docker, it's impossible to use a newly created docker container to replace the old one. Maintainance is much easier!Building a new image, share it with QA, testing it, deploying it only takes minutes(if everything is automated), hours in the worst case. This is called immutable infrastructure: do not maintain(upgrade) software, create a new one instead.\n\nIt transforms how services are delivered. We want applications, but have to maintain VMs(which is a pain and has little to do with our applications). Docker makes you focus on applications and smooths everything.\n\nShare\nImprove this answer\nFollow\nanswered Aug 10 '17 at 4:25\ncizixs\n10.2k6\n6 gold badges\n43\n43 silver badges\n58\n58 bronze badges","comments":[]},{"answer":"Docker, basically containers, supports OS virtualization i.e. your application feels that it has a complete instance of an OS whereas VM supports hardware virtualization. You feel like it is a physical machine in which you can boot any OS.\n\nIn Docker, the containers running share the host OS kernel, whereas in VMs they have their own OS files. The environment (the OS) in which you develop an application would be same when you deploy it to various serving environments, such as \"testing\" or \"production\".\n\nFor example, if you develop a web server that runs on port 4000, when you deploy it to your \"testing\" environment, that port is already used by some other program, so it stops working. In containers there are layers; all the changes you have made to the OS would be saved in one or more layers and those layers would be part of image, so wherever the image goes the dependencies would be present as well.\n\nIn the example shown below, the host machine has three VMs. In order to provide the applications in the VMs complete isolation, they each have their own copies of OS files, libraries and application code, along with a full in-memory instance of an OS.  Whereas the figure below shows the same scenario with containers. Here, containers simply share the host operating system, including the kernel and libraries, so they don’t need to boot an OS, load libraries or pay a private memory cost for those files. The only incremental space they take is any memory and disk space necessary for the application to run in the container. While the application’s environment feels like a dedicated OS, the application deploys just like it would onto a dedicated host. The containerized application starts in seconds and many more instances of the application can fit onto the machine than in the VM case. \n\nSource: https://azure.microsoft.com/en-us/blog/containers-docker-windows-and-trends/\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jan 9 '17 at 13:22\nAli Kahoot\n2,2711\n1 gold badge\n18\n18 silver badges\n22\n22 bronze badges","comments":[]},{"answer":"There are three different setups that providing a stack to run an application on (This will help us to recognize what a container is and what makes it so much powerful than other solutions):\n\n1) Traditional Servers(bare metal)\n2) Virtual machines (VMs)\n3) Containers\n\n\n1) Traditional server stack consist of a physical server that runs an operating system and your application.\n\nAdvantages:\n\nUtilization of raw resources\n\nIsolation\n\nDisadvantages:\n\nVery slow deployment time\nExpensive\nWasted resources\nDifficult to scale\nDifficult to migrate\nComplex configuration\n\n2) The VM stack consist of a physical server which runs an operating system and a hypervisor that manages your virtual machine, shared resources, and networking interface. Each Vm runs a Guest Operating System, an application or set of applications.\n\nAdvantages:\n\nGood use of resources\nEasy to scale\nEasy to backup and migrate\nCost efficiency\nFlexibility\n\nDisadvantages:\n\nResource allocation is problematic\nVendor lockin\nComplex configuration\n\n3) The Container Setup, the key difference with other stack is container-based virtualization uses the kernel of the host OS to rum multiple isolated guest instances. These guest instances are called as containers. The host can be either a physical server or VM.\n\nAdvantages:\n\nIsolation\nLightweight\nResource effective\nEasy to migrate\nSecurity\nLow overhead\nMirror production and development environment\n\nDisadvantages:\n\nSame Architecture\nResource heavy apps\nNetworking and security issues.\n\nBy comparing the container setup with its predecessors, we can conclude that containerization is the fastest, most resource effective, and most secure setup we know to date. Containers are isolated instances that run your application. Docker spin up the container in a way, layers get run time memory with default storage drivers(Overlay drivers) those run within seconds and copy-on-write layer created on top of it once we commit into the container, that powers the execution of containers. In case of VM's that will take around a minute to load everything into the virtualize environment. These lightweight instances can be replaced, rebuild, and moved around easily. This allows us to mirror the production and development environment and is tremendous help in CI/CD processes. The advantages containers can provide are so compelling that they're definitely here to stay.\n\nShare\nImprove this answer\nFollow\nedited Feb 12 '17 at 17:43\nanswered Feb 12 '17 at 16:47\nmohan08p\n3,8931\n1 gold badge\n22\n22 silver badges\n35\n35 bronze badges","comments":["Please tell why this should be the \"most secure setup\" in comparison to VMs.","@MKesper: When you migrate from legacy environment to container environment, you have various ways to build security paradigm, one that is based on proactive rather than reactive approach to preventing intrusions. It allows you to secure your application and runtime at more granular and nuanced level. They also empower to identify and resolve potential security threats before they disrupt your workflows. And, it's possible to to combine static analysis with ML in order to automate runtime defense and enforce policies across your environment. Hence, the line \"most secure setup\"."]},{"answer":"In relation to:-\n\n\"Why is deploying software to a docker image easier than simply deploying to a consistent production environment ?\"\n\nMost software is deployed to many environments, typically a minimum of three of the following:\n\nIndividual developer PC(s)\nShared developer environment\nIndividual tester PC(s)\nShared test environment\nQA environment\nUAT environment\nLoad / performance testing\nLive staging\nProduction\nArchive\n\nThere are also the following factors to consider:\n\nDevelopers, and indeed testers, will all have either subtlely or vastly different PC configurations, by the very nature of the job\nDevelopers can often develop on PCs beyond the control of corporate or business standardisation rules (e.g. freelancers who develop on their own machines (often remotely) or contributors to open source projects who are not 'employed' or 'contracted' to configure their PCs a certain way)\nSome environments will consist of a fixed number of multiple machines in a load balanced configuration\nMany production environments will have cloud-based servers dynamically (or 'elastically') created and destroyed depending on traffic levels\n\nAs you can see the extrapolated total number of servers for an organisation is rarely in single figures, is very often in triple figures and can easily be significantly higher still.\n\nThis all means that creating consistent environments in the first place is hard enough just because of sheer volume (even in a green field scenario), but keeping them consistent is all but impossible given the high number of servers, addition of new servers (dynamically or manually), automatic updates from o/s vendors, anti-virus vendors, browser vendors and the like, manual software installs or configuration changes performed by developers or server technicians, etc. Let me repeat that - it's virtually (no pun intended) impossible to keep environments consistent (okay, for the purist, it can be done, but it involves a huge amount of time, effort and discipline, which is precisely why VMs and containers (e.g. Docker) were devised in the first place).\n\nSo think of your question more like this \"Given the extreme difficulty of keeping all environments consistent, is it easier to deploying software to a docker image, even when taking the learning curve into account ?\". I think you'll find the answer will invariably be \"yes\" - but there's only one way to find out, post this new question on Stack Overflow.\n\nShare\nImprove this answer\nFollow\nanswered Oct 15 '16 at 11:25\nGreg Trevellick\n1,14716\n16 silver badges\n24\n24 bronze badges","comments":["So, if I deploy my docker image with 15 different boxes which have all different OS/version combinations, all my docker images will run same?","@Teomanshipahi If all these containers could use the same kernel provided by host, yes, they will all run successfully.","If I use docker for windows on my local, can I deploy and run same way in linux/mac?","The things that always seem to get glossed over is that there are still version dependencies: 1) The developer must develop on the same environment that the image contains; 2) The dev environment and the test environment need to be running the same (or compatible) versions of both the linux kernel and docker itself...yes?"]},{"answer":"There are many answers which explain more detailed on the differences, but here is my very brief explanation.\n\nOne important difference is that VMs use a separate kernel to run the OS. That's the reason it is heavy and takes time to boot, consuming more system resources.\n\nIn Docker, the containers share the kernel with the host; hence it is lightweight and can start and stop quickly.\n\nIn Virtualization, the resources are allocated in the beginning of set up and hence the resources are not fully utilized when the virtual machine is idle during many of the times. In Docker, the containers are not allocated with fixed amount of hardware resources and is free to use the resources depending on the requirements and hence it is highly scalable.\n\nDocker uses UNION File system .. Docker uses a copy-on-write technology to reduce the memory space consumed by containers. Read more here\n\nShare\nImprove this answer\nFollow\nedited Oct 9 '17 at 19:38\nanswered Apr 11 '17 at 3:20\nJayabalan Bala\n6766\n6 silver badges\n15\n15 bronze badges","comments":["\"In Virtualization, the resources are allocated in the beginning of set up and hence the resources are not fully utilized when the virtual machine is idle during many of the times\" Hyper-V has a notion of Dynamic Memory where you can specify Minimum, Maximum and Startup RAM."]},{"answer":"With a virtual machine, we have a server, we have a host operating system on that server, and then we have a hypervisor. And then running on top of that hypervisor, we have any number of guest operating systems with an application and its dependent binaries, and libraries on that server. It brings a whole guest operating system with it. It's quite heavyweight. Also there's a limit to how much you can actually put on each physical machine.\n\nDocker containers on the other hand, are slightly different. We have the server. We have the host operating system. But instead a hypervisor, we have the Docker engine, in this case. In this case, we're not bringing a whole guest operating system with us. We're bringing a very thin layer of the operating system, and the container can talk down into the host OS in order to get to the kernel functionality there. And that allows us to have a very lightweight container.\n\nAll it has in there is the application code and any binaries and libraries that it requires. And those binaries and libraries can actually be shared across different containers if you want them to be as well. And what this enables us to do, is a number of things. They have much faster startup time. You can't stand up a single VM in a few seconds like that. And equally, taking them down as quickly.. so we can scale up and down very quickly and we'll look at that later on.\n\nEvery container thinks that it’s running on its own copy of the operating system. It’s got its own file system, own registry, etc. which is a kind of a lie. It’s actually being virtualized.\n\nShare\nImprove this answer\nFollow\nedited Jun 21 '18 at 19:49\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 21 '18 at 8:22\nNedzad G\n8871\n1 gold badge\n7\n7 silver badges\n21\n21 bronze badges","comments":[]},{"answer":"Source: Kubernetes in Action.\n\nShare\nImprove this answer\nFollow\nanswered Jul 16 '18 at 2:56\nTastyCode\n5,3694\n4 gold badges\n32\n32 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"I have used Docker in production environments and staging very much. When you get used to it you will find it very powerful for building a multi container and isolated environments.\n\nDocker has been developed based on LXC (Linux Container) and works perfectly in many Linux distributions, especially Ubuntu.\n\nDocker containers are isolated environments. You can see it when you issue the top command in a Docker container that has been created from a Docker image.\n\nBesides that, they are very light-weight and flexible thanks to the dockerFile configuration.\n\nFor example, you can create a Docker image and configure a DockerFile and tell that for example when it is running then wget 'this', apt-get 'that', run 'some shell script', setting environment variables and so on.\n\nIn micro-services projects and architecture Docker is a very viable asset. You can achieve scalability, resiliency and elasticity with Docker, Docker swarm, Kubernetes and Docker Compose.\n\nAnother important issue regarding Docker is Docker Hub and its community. For example, I implemented an ecosystem for monitoring kafka using Prometheus, Grafana, Prometheus-JMX-Exporter, and Docker.\n\nFor doing that, I downloaded configured Docker containers for zookeeper, kafka, Prometheus, Grafana and jmx-collector then mounted my own configuration for some of them using YAML files, or for others, I changed some files and configuration in the Docker container and I build a whole system for monitoring kafka using multi-container Dockers on a single machine with isolation and scalability and resiliency that this architecture can be easily moved into multiple servers.\n\nBesides the Docker Hub site there is another site called quay.io that you can use to have your own Docker images dashboard there and pull/push to/from it. You can even import Docker images from Docker Hub to quay then running them from quay on your own machine.\n\nNote: Learning Docker in the first place seems complex and hard, but when you get used to it then you can not work without it.\n\nI remember the first days of working with Docker when I issued the wrong commands or removing my containers and all of data and configurations mistakenly.\n\nShare\nImprove this answer\nFollow\nedited Nov 20 '19 at 7:30\nHassan Ahmed\n4053\n3 silver badges\n9\n9 bronze badges\nanswered May 22 '17 at 15:45\nTouraj Ebrahimi\n4663\n3 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"This is how Docker introduces itself:\n\nDocker is the company driving the container movement and the only container platform provider to address every application across the hybrid cloud. Today’s businesses are under pressure to digitally transform but are constrained by existing applications and infrastructure while rationalizing an increasingly diverse portfolio of clouds, datacenters and application architectures. Docker enables true independence between applications and infrastructure and developers and IT ops to unlock their potential and creates a model for better collaboration and innovation.\n\nSo Docker is container based, meaning you have images and containers which can be run on your current machine. It's not including the operating system like VMs, but like a pack of different working packs like Java, Tomcat, etc.\n\nIf you understand containers, you get what Docker is and how it's different from VMs...\n\nSo, what's a container?\n\nA container image is a lightweight, stand-alone, executable package of a piece of software that includes everything needed to run it: code, runtime, system tools, system libraries, settings. Available for both Linux and Windows based apps, containerized software will always run the same, regardless of the environment. Containers isolate software from its surroundings, for example differences between development and staging environments and help reduce conflicts between teams running different software on the same infrastructure.\n\nSo as you see in the image below, each container has a separate pack and running on a single machine share that machine's operating system... They are secure and easy to ship...\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered May 23 '18 at 13:32\nAlireza\n86.1k21\n21 gold badges\n246\n246 silver badges\n154\n154 bronze badges","comments":[]},{"answer":"There are a lot of nice technical answers here that clearly discuss the differences between VMs and containers as well as the origins of Docker.\n\nFor me the fundamental difference between VMs and Docker is how you manage the promotion of your application.\n\nWith VMs you promote your application and its dependencies from one VM to the next DEV to UAT to PRD.\n\nOften these VM's will have different patches and libraries.\nIt is not uncommon for multiple applications to share a VM. This requires managing configuration and dependencies for all the applications.\nBackout requires undoing changes in the VM. Or restoring it if possible.\n\nWith Docker the idea is that you bundle up your application inside its own container along with the libraries it needs and then promote the whole container as a single unit.\n\nExcept for the kernel the patches and libraries are identical.\nAs a general rule there is only one application per container which simplifies configuration.\nBackout consists of stopping and deleting the container.\n\nSo at the most fundamental level with VMs you promote the application and its dependencies as discrete components whereas with Docker you promote everything in one hit.\n\nAnd yes there are issues with containers including managing them although tools like Kubernetes or Docker Swarm greatly simplify the task.\n\nShare\nImprove this answer\nFollow\nedited Jun 21 '18 at 19:57\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 25 '18 at 11:58\nTJA\n2,4312\n2 gold badges\n21\n21 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"In my opinion it depends, it can be seen from the needs of your application, why decide to deploy to Docker because Docker breaks the application into small parts according to its function, this becomes effective because when one application / function is an error it has no effect on other applications , in contrast to using full vm, it will be slower and more complex in configuration, but in some ways safer than docker\n\nShare\nImprove this answer\nFollow\nanswered Nov 16 '20 at 0:50\nSulaiman Al-farisi\n171\n1 bronze badge","comments":[]},{"answer":"The docker documentation (and self-explanation) makes a distinction between \"virtual machines\" vs. \"containers\". They have the tendency to interpret and use things in a little bit uncommon ways. They can do that because it is up to them, what do they write in their documentation, and because the terminology for virtualization is not yet really exact.\n\nFact is what the Docker documentation understands on \"containers\", is paravirtualization (sometimes \"OS-Level virtualization\") in the reality, contrarily the hardware virtualization, which is docker not.\n\nDocker is a low quality paravirtualisation solution. The container vs. VM distinction is invented by the docker development, to explain the serious disadvantages of their product.\n\nThe reason, why it became so popular, is that they \"gave the fire to the ordinary people\", i.e. it made possible the simple usage of typically server ( = Linux) environments / software products on Win10 workstations. This is also a reason for us to tolerate their little \"nuance\". But it does not mean that we should also believe it.\n\nThe situation is made yet more cloudy by the fact that docker on Windows hosts used an embedded Linux in HyperV, and its containers have run in that. Thus, docker on Windows uses a combined hardware and paravirtualization solution.\n\nIn short, Docker containers are low-quality (para)virtual machines with a huge advantage and a lot of disadvantages.\n\nShare\nImprove this answer\nFollow\nanswered Nov 26 '20 at 15:53\npeterh\n10.1k15\n15 gold badges\n70\n70 silver badges\n89\n89 bronze badges","comments":["long on personal opinion, short on facts, supporting evidence and explanation. Does not add to or improve on older answers.","@Spike0xff Exactly which statements require evidence? I can insert them into the post, but I am not sure. For example, anybody knowing how docker works, and what is paravirtualization, had imho difficulty to deny that docker is a paravirtualization engine. Today I would add to, that docker is good in configurability and devops things (for example, you can have a Dockerfile or compose.yml in your git tree).","@Spike0xff Btw, sometimes also I go trough an answer list and vote down nearly everything. I do this if I feel a bad-answer bongo. And now you did the same! I think I am right, so I can live with your down, but I am open for communication/edit suggestions."]}]},{"id":"40471","href":"https://stackoverflow.com/questions/40471/what-are-the-differences-between-a-hashmap-and-a-hashtable-in-java","title":"What are the differences between a HashMap and a Hashtable in Java?","description":"\n                \nWhat are the differences between a HashMap and a Hashtable in Java?\n\nWhich is more efficient for non-threaded applications?\n    ","questionComments":["HashTable is obsolete in Java 1.7 and it is recommended to use ConcurrentMap implementation","@MissFiona No, ConcurrentMap is not necessary here, as the Question says “non-threaded applications” meaning threading/concurrency is not an issue."],"answers":[{"answer":"There are several differences between HashMap and Hashtable in Java:\n\nHashtable is synchronized, whereas HashMap is not. This makes HashMap better for non-threaded applications, as unsynchronized Objects typically perform better than synchronized ones.\n\nHashtable does not allow null keys or values. HashMap allows one null key and any number of null values.\n\nOne of HashMap's subclasses is LinkedHashMap, so in the event that you'd want predictable iteration order (which is insertion order by default), you could easily swap out the HashMap for a LinkedHashMap. This wouldn't be as easy if you were using Hashtable.\n\nSince synchronization is not an issue for you, I'd recommend HashMap. If synchronization becomes an issue, you may also look at ConcurrentHashMap.\n\nShare\nImprove this answer\nFollow\nedited Sep 13 '18 at 19:38\nanswered Sep 2 '08 at 23:02\nJosh Brown\n49.8k9\n9 gold badges\n50\n50 silver badges\n78\n78 bronze badges","comments":["If you want to make a HashMap thread-safe, use Collections.synchronizedMap().","I would also comment that the naive approach to thread-safety in Hashtable (\"synchronizing every method should take care of any concurrency problems!\") makes it very much worse for threaded applications. You're better off externally synchronizing a HashMap (and thinking about the consequences), or using a ConcurrentMap implementation (and exploiting its extended API for concurrency). Bottom line: the only reason to use Hashtable is when a legacy API (from ca. 1996) requires it.","HashMap gives flexibility to programmer to write threadSafe code when they actually use it. It happened rarely that I needed a thread safe collection like ConcurrentHashMap or HashTable. What I needed is certain set of functions or certain statements in a synchronized block to be threadsafe.","Hashtable is obsolete and we are using HashMap for non thread safe environment. If you need thread safety then you can use Collections.synchronizedMap() or use ConcurrentHashMap which is more efficient that hashtable.","It's obsolete but not deprecated and I'm wondering why this is. I'm guessing removing this class (and Vector for the same reasons) would break too much existing code and annotating with @Deprecated would imply an intention to remove the code, which apparently is not there."]},{"answer":"Note, that a lot of the answers state that Hashtable is synchronized. In practice this buys you very little. The synchronization is on the accessor/mutator methods will stop two threads adding or removing from the map concurrently, but in the real world, you will often need additional synchronization.\n\nA very common idiom is to \"check then put\" — i.e. look for an entry in the Map, and add it if it does not already exist. This is not in any way an atomic operation whether you use Hashtable or HashMap.\n\nAn equivalently synchronised HashMap can be obtained by:\n\nCollections.synchronizedMap(myMap);\n\n\nBut to correctly implement this logic you need additional synchronisation of the form:\n\nsynchronized(myMap) {\n    if (!myMap.containsKey(\"tomato\"))\n        myMap.put(\"tomato\", \"red\");\n}\n\n\nEven iterating over a Hashtable's entries (or a HashMap obtained by Collections.synchronizedMap) is not thread-safe unless you also guard the Map against being modified through additional synchronization.\n\nImplementations of the ConcurrentMap interface (for example ConcurrentHashMap) solve some of this by including thread safe check-then-act semantics such as:\n\nConcurrentMap.putIfAbsent(key, value);\n\nShare\nImprove this answer\nFollow\nedited May 15 at 11:22\nGodfather\n251\n1 silver badge\n6\n6 bronze badges\nanswered Sep 3 '08 at 11:00\nserg10\n29.3k16\n16 gold badges\n66\n66 silver badges\n92\n92 bronze badges","comments":["Also note that if a HashMap is modified, iterators pointing to it are rendered invalid.","So is there any difference between synchronized(myMap) {...} and ConcurrentHashMap in terms of thread safe?","Very true, I tried to explain same here..lovehasija.com/2012/08/16/…","@Bhushan: It will throw on a best-effort basis, this is not guaranteed behavior: docs.oracle.com/javase/7/docs/api/java/util/HashMap.html","Having been in the middle of a JVM development crew for a number of years I can state that Hashtable's internal synchronization is at least useful for properly pointing the finger at the customer's code when he writes dodgy concurrent code. We received several complaints of failures inside HashMap (and hence \"obviously\" a JDK/JVM bug), when the cause was concurrent modification."]},{"answer":"Hashtable is considered legacy code. There's nothing about Hashtable that can't be done using HashMap or derivations of HashMap, so for new code, I don't see any justification for going back to Hashtable.\n\nShare\nImprove this answer\nFollow\nedited Aug 7 '18 at 12:18\nkryger\n11.9k8\n8 gold badges\n42\n42 silver badges\n62\n62 bronze badges\nanswered Jun 25 '09 at 1:46\naberrant80\n11.9k8\n8 gold badges\n43\n43 silver badges\n63\n63 bronze badges","comments":["From Hashtable javadoc (emphasis added): \"As of the Java 2 platform v1.2, this class was retrofitted to implement the Map interface, making it a member of the Java Collections Framework.\" However, you are right that it is legacy code. All the benefits of synchronization can be obtained more efficiently with Collections.synchronizedMap(HashMap). (Similar to Vector being a legacy version of Collections.synchronizedList(ArrayList).)","@aberrant80: unfortunately you have no choice between the two and have to use Hashtable when programming for J2ME...","this answer should be deleted. it contains incorrect information and has a lot of upvotes.","@anon58192932 Is it possible to edit the question to fix it?","We have to get the attention of the poster @aberrant80 or an admin by flagging. Flagging could help - will try that now."]},{"answer":"This question is often asked in interviews to check whether the candidate understands the correct usage of collection classes and is aware of alternative solutions available.\n\nThe HashMap class is roughly equivalent to Hashtable, except that it is non synchronized and permits nulls. (HashMap allows null values as key and value whereas Hashtable doesn't allow nulls).\nHashMap does not guarantee that the order of the map will remain constant over time.\nHashMap is non synchronized whereas Hashtable is synchronized.\nIterator in the HashMap is fail-safe while the enumerator for the Hashtable is not and throw ConcurrentModificationException if any other Thread modifies the map structurally by adding or removing any element except Iterator's own remove() method. But this is not a guaranteed behavior and will be done by JVM on best effort.\n\nNote on Some Important Terms:\n\nSynchronized means only one thread can modify a hash table at one point in time. Basically, it means that any thread before performing an update on a Hashtable will have to acquire a lock on the object while others will wait for the lock to be released.\nFail-safe is relevant within the context of iterators. If an iterator has been created on a collection object and some other thread tries to modify the collection object \"structurally\", a concurrent modification exception will be thrown. It is possible for other threads though to invoke the set method since it doesn't modify the collection \"structurally\". However, if prior to calling set, the collection has been modified structurally, IllegalArgumentException will be thrown.\nStructurally modification means deleting or inserting element which could effectively change the structure of the map.\n\nHashMap can be synchronized by\n\nMap m = Collections.synchronizeMap(hashMap);\n\nMap provides Collection views instead of direct support for iteration via Enumeration objects. Collection views greatly enhance the expressiveness of the interface, as discussed later in this section. Map allows you to iterate over keys, values, or key-value pairs; Hashtable does not provide the third option. Map provides a safe way to remove entries in the midst of iteration; Hashtable did not. Finally, Map fixes a minor deficiency in the Hashtable interface. Hashtable has a method called contains, which returns true if the Hashtable contains a given value. Given its name, you'd expect this method to return true if the Hashtable contained a given key because the key is the primary access mechanism for a Hashtable. The Map interface eliminates this source of confusion by renaming the method containsValue. Also, this improves the interface's consistency — containsValue parallels containsKey.\n\nThe Map Interface\n\nShare\nImprove this answer\nFollow\nedited May 14 at 17:16\nGodfather\n251\n1 silver badge\n6\n6 bronze badges\nanswered Oct 4 '11 at 6:39\nsravan\n4,9991\n1 gold badge\n28\n28 silver badges\n33\n33 bronze badges","comments":["This answer contains at least 2 significant factual inaccuracies. It certainly DOES NOT deserve this many upvotes.","1) HashMap's iterators are NOT fail-safe. They are fail-fast. There is a huge difference in meaning between those two terms. 2) There is no set operation on a HashMap. 3) The put(...) operation won't throw IllegalArgumentException if there was a previous change. 4) The fail-fast behaviour of HashMap also occurs if you change a mapping. 5) The fail-fast behaviour is guaranteed. (What is not guaranteed is the behaviour of a HashTable if you make a concurrent modification. The actual behaviour is ... unpredictable.)","6) Hashtable does not guarantee that the order of map elements will be stable over time either. (You are perhaps confusing Hashtable with LinkedHashMap.)","Anyone else really worried that students these days are getting the errant idea that getting \"synchronized versions\" of the collections somehow means that you don't have to externally synchronize compound operations? My favorite example of this being thing.set(thing.get() + 1); which more often than not catches newbies by surprise as completely unprotected, especially if the get() and set() are synchronized methods. Many of them are expecting magic.","Iterators on HashMap is not fail-safe"]},{"answer":"HashMap: An implementation of the Map interface that uses hash codes to index an array. Hashtable: Hi, 1998 called. They want their collections API back.\n\nSeriously though, you're better off staying away from Hashtable altogether. For single-threaded apps, you don't need the extra overhead of synchronisation. For highly concurrent apps, the paranoid synchronisation might lead to starvation, deadlocks, or unnecessary garbage collection pauses. Like Tim Howland pointed out, you might use ConcurrentHashMap instead.\n\nShare\nImprove this answer\nFollow\nedited Dec 4 '17 at 21:31\nanswered Sep 2 '08 at 23:14\nApocalisp\n33.7k8\n8 gold badges\n100\n100 silver badges\n150\n150 bronze badges","comments":["This actually makes sense. ConcurrentHashMaps gives you freedom of synchronization and debugging is lot more easier.","Is this specific to Java or all the hash map implementation."]},{"answer":"Keep in mind that HashTable was legacy class before Java Collections Framework (JCF) was introduced and was later retrofitted to implement the Map interface. So was Vector and Stack.\n\nTherefore, always stay away from them in new code since there always better alternative in the JCF as others had pointed out.\n\nHere is the Java collection cheat sheet that you will find useful. Notice the gray block contains the legacy class HashTable,Vector and Stack.\n\nShare\nImprove this answer\nFollow\nedited Jun 3 '15 at 5:43\nPratik Khadloya\n11.5k10\n10 gold badges\n72\n72 silver badges\n95\n95 bronze badges\nanswered Mar 25 '14 at 8:58\npierrotlefou\n36.8k33\n33 gold badges\n132\n132 silver badges\n169\n169 bronze badges","comments":[]},{"answer":"There are many good answers already posted. I'm adding few new points and summarizing it.\n\nHashMap and Hashtable both are used to store data in key and value form. Both are using hashing technique to store unique keys. But there are many differences between HashMap and Hashtable classes that are given below.\n\nHashMap\n\nHashMap is non synchronized. It is not-thread safe and can't be shared between many threads without proper synchronization code.\nHashMap allows one null key and multiple null values.\nHashMap is a new class introduced in JDK 1.2.\nHashMap is fast.\nWe can make the HashMap as synchronized by calling this code\nMap m = Collections.synchronizedMap(HashMap);  \nHashMap is traversed by Iterator.\nIterator in HashMap is fail-fast.\nHashMap inherits AbstractMap class.\n\nHashtable\n\nHashtable is synchronized. It is thread-safe and can be shared with many threads.\nHashtable doesn't allow null key or value.\nHashtable is a legacy class.\nHashtable is slow.\nHashtable is internally synchronized and can't be unsynchronized.\nHashtable is traversed by Enumerator and Iterator.\nEnumerator in Hashtable is not fail-fast.\nHashtable inherits Dictionary class.\n\nFurther reading What is difference between HashMap and Hashtable in Java?\n\nShare\nImprove this answer\nFollow\nedited May 29 at 11:53\nsanjeevRm\n1,3122\n2 gold badges\n10\n10 silver badges\n19\n19 bronze badges\nanswered Mar 6 '17 at 10:09\nroottraveller\n6,5564\n4 gold badges\n51\n51 silver badges\n61\n61 bronze badges","comments":["Pretty much covered in this answer (dupicate of )- stackoverflow.com/a/39785829/432903.","Why do you say ~\"Hashtable is a legacy class\"? Where is the supporting documentation for that.","@IgorGanapolsky you may read this - stackoverflow.com/questions/21086307/…","Maintaining HashMap is costly than TreeMap. Because HashMap creates unnecessary extra buckets.","A LinkedHashMap has a doubly-linked list of entries, not of buckets. Buckets are accessible via array indices and need not be linked."]},{"answer":"In addition to what izb said, HashMap allows null values, whereas the Hashtable does not.\n\nAlso note that Hashtable extends the Dictionary class, which as the Javadocs state, is obsolete and has been replaced by the Map interface.\n\nShare\nImprove this answer\nFollow\nanswered Sep 2 '08 at 20:30\nmatt b\n133k64\n64 gold badges\n269\n269 silver badges\n335\n335 bronze badges","comments":["but that does not make the HashTable obsolete does it?","@Pacerier HashTable is obsolete since Java 1.7."]},{"answer":"Take a look at this chart. It provides comparisons between different data structures along with HashMap and Hashtable. The comparison is precise, clear and easy to understand.\n\nJava Collection Matrix\n\nShare\nImprove this answer\nFollow\nedited Nov 22 '19 at 17:34\nYousha Aleayoub\n3,4003\n3 gold badges\n44\n44 silver badges\n59\n59 bronze badges\nanswered Nov 20 '12 at 5:35\nSujan\n1,4122\n2 gold badges\n22\n22 silver badges\n42\n42 bronze badges","comments":[]},{"answer":"Hashtable is similar to the HashMap and has a similar interface. It is recommended that you use HashMap, unless you require support for legacy applications or you need synchronisation, as the Hashtables methods are synchronised. So in your case as you are not multi-threading, HashMaps are your best bet.\n\nShare\nImprove this answer\nFollow\nedited Mar 2 '15 at 8:55\nnbro\n12.6k21\n21 gold badges\n89\n89 silver badges\n164\n164 bronze badges\nanswered Sep 2 '08 at 20:25\nMiles D\n7,5825\n5 gold badges\n31\n31 silver badges\n35\n35 bronze badges","comments":[]},{"answer":"Another key difference between hashtable and hashmap is that Iterator in the HashMap is fail-fast while the enumerator for the Hashtable is not and throw ConcurrentModificationException if any other Thread modifies the map structurally by adding or removing any element except Iterator's own remove() method. But this is not a guaranteed behavior and will be done by JVM on best effort.\"\n\nMy source: http://javarevisited.blogspot.com/2010/10/difference-between-hashmap-and.html\n\nShare\nImprove this answer\nFollow\nanswered Sep 8 '11 at 6:40\nNeerja\n3613\n3 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"Beside all the other important aspects already mentioned here, Collections API (e.g. Map interface) is being modified all the time to conform to the \"latest and greatest\" additions to Java spec.\n\nFor example, compare Java 5 Map iterating:\n\nfor (Elem elem : map.keys()) {\n  elem.doSth();\n}\n\n\nversus the old Hashtable approach:\n\nfor (Enumeration en = htable.keys(); en.hasMoreElements(); ) {\n  Elem elem = (Elem) en.nextElement();\n  elem.doSth();\n}\n\n\nIn Java 1.8 we are also promised to be able to construct and access HashMaps like in good old scripting languages:\n\nMap<String,Integer> map = { \"orange\" : 12, \"apples\" : 15 };\nmap[\"apples\"];\n\n\nUpdate: No, they won't land in 1.8... :(\n\nAre Project Coin's collection enhancements going to be in JDK8?\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Jan 12 '12 at 9:17\npwes\n1,93020\n20 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"Hashtable is synchronized, whereas HashMap isn't. That makes Hashtable slower than Hashmap.\n\nFor single thread applications, use HashMap since they are otherwise the same in terms of functionality.\n\nShare\nImprove this answer\nFollow\nedited Sep 15 '20 at 20:28\nKoray Tugay\n20.8k37\n37 gold badges\n159\n159 silver badges\n282\n282 bronze badges\nanswered Sep 2 '08 at 20:22\nizb\n46.1k39\n39 gold badges\n112\n112 silver badges\n166\n166 bronze badges","comments":[]},{"answer":"HashTable is synchronized, if you are using it in a single thread you can use HashMap, which is an unsynchronized version. Unsynchronized objects are often a little more performant. By the way if multiple threads access a HashMap concurrently, and at least one of the threads modifies the map structurally, it must be synchronized externally. Youn can wrap a unsynchronized map in a synchronized one using :\n\nMap m = Collections.synchronizedMap(new HashMap(...));\n\n\nHashTable can only contain non-null object as a key or as a value. HashMap can contain one null key and null values.\n\nThe iterators returned by Map are fail-fast, if the map is structurally modified at any time after the iterator is created, in any way except through the iterator's own remove method, the iterator will throw a ConcurrentModificationException. Thus, in the face of concurrent modification, the iterator fails quickly and cleanly, rather than risking arbitrary, non-deterministic behavior at an undetermined time in the future. Whereas the Enumerations returned by Hashtable's keys and elements methods are not fail-fast.\n\nHashTable and HashMap are member of the Java Collections Framework (since Java 2 platform v1.2, HashTable was retrofitted to implement the Map interface).\n\nHashTable is considered legacy code, the documentation advise to use ConcurrentHashMap in place of Hashtable if a thread-safe highly-concurrent implementation is desired.\n\nHashMap doesn't guarantee the order in which elements are returned. For HashTable I guess it's the same but I'm not entirely sure, I don't find ressource that clearly state that.\n\nShare\nImprove this answer\nFollow\nanswered Apr 29 '12 at 13:57\nalain.janinm\n19.1k10\n10 gold badges\n57\n57 silver badges\n104\n104 bronze badges","comments":[]},{"answer":"HashMap and Hashtable have significant algorithmic differences as well. No one has mentioned this before so that's why I am bringing it up. HashMap will construct a hash table with power of two size, increase it dynamically such that you have at most about eight elements (collisions) in any bucket and will stir the elements very well for general element types. However, the Hashtable implementation provides better and finer control over the hashing if you know what you are doing, namely you can fix the table size using e.g. the closest prime number to your values domain size and this will result in better performance than HashMap i.e. less collisions for some cases.\n\nSeparate from the obvious differences discussed extensively in this question, I see the Hashtable as a \"manual drive\" car where you have better control over the hashing and the HashMap as the \"automatic drive\" counterpart that will generally perform well.\n\nShare\nImprove this answer\nFollow\nedited Jan 24 '14 at 8:35\nanswered Dec 10 '12 at 8:57\nSkyWalker\n12k15\n15 gold badges\n69\n69 silver badges\n148\n148 bronze badges","comments":[]},{"answer":"Based on the info here, I'd recommend going with HashMap. I think the biggest advantage is that Java will prevent you from modifying it while you are iterating over it, unless you do it through the iterator.\n\nShare\nImprove this answer\nFollow\nanswered Sep 2 '08 at 20:14\npkaeding\n33.4k29\n29 gold badges\n96\n96 silver badges\n136\n136 bronze badges","comments":["It doesn't actually prevent it, it just detects it and throws an error.","I'm pretty sure it will throw a ConncurrentModificationException before the underlying collection is modified, though I could be wrong.","It will attempt to detect concurrent modification and throw an exception. But if you're doing anything with threads, it can't make any promises. Absolutely anything can happen, including breakage."]},{"answer":"A Collection — sometimes called a container — is simply an object that groups multiple elements into a single unit. Collections are used to store, retrieve, manipulate, and communicate aggregate data. A collections framework W is a unified architecture for representing and manipulating collections.\n\nThe HashMap JDK1.2 and Hashtable JDK1.0, both are used to represent a group of objects that are represented in <Key, Value> pair. Each <Key, Value> pair is called Entry object. The collection of Entries is referred by the object of HashMap and Hashtable. Keys in a collection must be unique or distinctive. [as they are used to retrieve a mapped value a particular key. values in a collection can be duplicated.]\n\n« Superclass, Legacy and Collection Framework member\n\nHashtable is a legacy class introduced in JDK1.0, which is a subclass of Dictionary class. From JDK1.2 Hashtable is re-engineered to implement the Map interface to make a member of collection framework. HashMap is a member of Java Collection Framework right from the beginning of its introduction in JDK1.2. HashMap is the subclass of the AbstractMap class.\n\npublic class Hashtable<K,V> extends Dictionary<K,V> implements Map<K,V>, Cloneable, Serializable { ... }\n\npublic class HashMap<K,V> extends AbstractMap<K,V> implements Map<K,V>, Cloneable, Serializable { ... }\n\n\n« Initial capacity and Load factor\n\nThe capacity is the number of buckets in the hash table, and the initial capacity is simply the capacity at the time the hash table is created. Note that the hash table is open: in the case of a \"hash collision\", a single bucket stores multiple entries, which must be searched sequentially. The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased.\n\nHashMap constructs an empty hash table with the default initial capacity (16) and the default load factor (0.75). Where as Hashtable constructs empty hashtable with a default initial capacity (11) and load factor/fill ratio (0.75).\n\n« Structural modification in case of hash collision\n\nHashMap, Hashtable in case of hash collisions they store the map entries in linked lists. From Java8 for HashMap if hash bucket grows beyond a certain threshold, that bucket will switch from linked list of entries to a balanced tree. which improve worst-case performance from O(n) to O(log n). While converting the list to binary tree, hashcode is used as a branching variable. If there are two different hashcodes in the same bucket, one is considered bigger and goes to the right of the tree and other one to the left. But when both the hashcodes are equal, HashMap assumes that the keys are comparable, and compares the key to determine the direction so that some order can be maintained. It is a good practice to make the keys of HashMap comparable. On adding entries if bucket size reaches TREEIFY_THRESHOLD = 8 convert linked list of entries to a balanced tree, on removing entries less than TREEIFY_THRESHOLD and at most UNTREEIFY_THRESHOLD = 6 will reconvert balanced tree to linked list of entries. Java 8 SRC, stackpost\n\n« Collection-view iteration, Fail-Fast and Fail-Safe\n\n    +--------------------+-----------+-------------+\n    |                    | Iterator  | Enumeration |\n    +--------------------+-----------+-------------+\n    | Hashtable          | fail-fast |    safe     |\n    +--------------------+-----------+-------------+\n    | HashMap            | fail-fast | fail-fast   |\n    +--------------------+-----------+-------------+\n    | ConcurrentHashMap  |   safe    |   safe      |\n    +--------------------+-----------+-------------+\n\n\nIterator is a fail-fast in nature. i.e it throws ConcurrentModificationException if a collection is modified while iterating other than it’s own remove() method. Where as Enumeration is fail-safe in nature. It doesn’t throw any exceptions if a collection is modified while iterating.\n\nAccording to Java API Docs, Iterator is always preferred over the Enumeration.\n\nNOTE: The functionality of Enumeration interface is duplicated by the Iterator interface. In addition, Iterator adds an optional remove operation, and has shorter method names. New implementations should consider using Iterator in preference to Enumeration.\n\nIn Java 5 introduced ConcurrentMap Interface: ConcurrentHashMap - a highly concurrent, high-performance ConcurrentMap implementation backed by a hash table. This implementation never blocks when performing retrievals and allows the client to select the concurrency level for updates. It is intended as a drop-in replacement for Hashtable: in addition to implementing ConcurrentMap, it supports all of the \"legacy\" methods peculiar to Hashtable.\n\nEach HashMapEntrys value is volatile thereby ensuring fine grain consistency for contended modifications and subsequent reads; each read reflects the most recently completed update\n\nIterators and Enumerations are Fail Safe - reflecting the state at some point since the creation of iterator/enumeration; this allows for simultaneous reads and modifications at the cost of reduced consistency. They do not throw ConcurrentModificationException. However, iterators are designed to be used by only one thread at a time.\n\nLike Hashtable but unlike HashMap, this class does not allow null to be used as a key or value.\n\npublic static void main(String[] args) {\n\n    //HashMap<String, Integer> hash = new HashMap<String, Integer>();\n    Hashtable<String, Integer> hash = new Hashtable<String, Integer>();\n    //ConcurrentHashMap<String, Integer> hash = new ConcurrentHashMap<>();\n    \n    new Thread() {\n        @Override public void run() {\n            try {\n                for (int i = 10; i < 20; i++) {\n                    sleepThread(1);\n                    System.out.println(\"T1 :- Key\"+i);\n                    hash.put(\"Key\"+i, i);\n                }\n                System.out.println( System.identityHashCode( hash ) );\n            } catch ( Exception e ) {\n                e.printStackTrace();\n            }\n        }\n    }.start();\n    new Thread() {\n        @Override public void run() {\n            try {\n                sleepThread(5);\n                // ConcurrentHashMap  traverse using Iterator, Enumeration is Fail-Safe.\n                \n                // Hashtable traverse using Enumeration is Fail-Safe, Iterator is Fail-Fast.\n                for (Enumeration<String> e = hash.keys(); e.hasMoreElements(); ) {\n                    sleepThread(1);\n                    System.out.println(\"T2 : \"+ e.nextElement());\n                }\n                \n                // HashMap traverse using Iterator, Enumeration is Fail-Fast.\n                /*\n                for (Iterator< Entry<String, Integer> > it = hash.entrySet().iterator(); it.hasNext(); ) {\n                    sleepThread(1);\n                    System.out.println(\"T2 : \"+ it.next());\n                    // ConcurrentModificationException at java.util.Hashtable$Enumerator.next\n                }\n                */\n                \n                /*\n                Set< Entry<String, Integer> > entrySet = hash.entrySet();\n                Iterator< Entry<String, Integer> > it = entrySet.iterator();\n                Enumeration<Entry<String, Integer>> entryEnumeration = Collections.enumeration( entrySet );\n                while( entryEnumeration.hasMoreElements() ) {\n                    sleepThread(1);\n                    Entry<String, Integer> nextElement = entryEnumeration.nextElement();\n                    System.out.println(\"T2 : \"+ nextElement.getKey() +\" : \"+ nextElement.getValue() );\n                    //java.util.ConcurrentModificationException at java.util.HashMap$HashIterator.nextNode\n                    //                                          at java.util.HashMap$EntryIterator.next\n                    //                                          at java.util.Collections$3.nextElement\n                }\n                */\n            } catch ( Exception e ) {\n                e.printStackTrace();\n            }\n        }\n    }.start();\n    \n    Map<String, String> unmodifiableMap = Collections.unmodifiableMap( map );\n    try {\n        unmodifiableMap.put(\"key4\", \"unmodifiableMap\");\n    } catch (java.lang.UnsupportedOperationException e) {\n        System.err.println(\"UnsupportedOperationException : \"+ e.getMessage() );\n    }\n}\nstatic void sleepThread( int sec ) {\n    try {\n        Thread.sleep( 1000 * sec );\n    } catch (InterruptedException e) {\n        e.printStackTrace();\n    }\n}\n\n\n« Null Keys And Null Values\n\nHashMap allows maximum one null key and any number of null values. Where as Hashtable doesn’t allow even a single null key and null value, if the key or value null is then it throws NullPointerException. Example\n\n« Synchronized, Thread Safe\n\nHashtable is internally synchronized. Therefore, it is very much safe to use Hashtable in multi threaded applications. Where as HashMap is not internally synchronized. Therefore, it is not safe to use HashMap in multi threaded applications without external synchronization. You can externally synchronize HashMap using Collections.synchronizedMap() method.\n\n« Performance\n\nAs Hashtable is internally synchronized, this makes Hashtable slightly slower than the HashMap.\n\n@See\n\nA red–black tree is a kind of self-balancing binary search tree\nPerformance Improvement for HashMap in Java 8\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jan 4 '18 at 11:58\nYash\n7,6202\n2 gold badges\n57\n57 silver badges\n64\n64 bronze badges","comments":[]},{"answer":"For threaded apps, you can often get away with ConcurrentHashMap- depends on your performance requirements.\n\nShare\nImprove this answer\nFollow\nanswered Sep 2 '08 at 22:38\nTim Howland\n7,6963\n3 gold badges\n25\n25 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"1.Hashmap and HashTable both store key and value.\n\n2.Hashmap can store one key as null. Hashtable can't store null.\n\n3.HashMap is not synchronized but Hashtable is synchronized.\n\n4.HashMap can be synchronized with Collection.SyncronizedMap(map)\n\nMap hashmap = new HashMap();\n\nMap map = Collections.SyncronizedMap(hashmap);\n\nShare\nImprove this answer\nFollow\nedited Mar 22 '15 at 15:43\nJared Burrows\n51.3k22\n22 gold badges\n144\n144 silver badges\n180\n180 bronze badges\nanswered Aug 27 '14 at 11:29\nRahul Tripathi\n5152\n2 gold badges\n7\n7 silver badges\n15\n15 bronze badges","comments":[]},{"answer":"Apart from the differences already mentioned, it should be noted that since Java 8, HashMap dynamically replaces the Nodes (linked list) used in each bucket with TreeNodes (red-black tree), so that even if high hash collisions exist, the worst case when searching is\n\nO(log(n)) for HashMap Vs O(n) in Hashtable.\n\n*The aforementioned improvement has not been applied to Hashtable yet, but only to HashMap, LinkedHashMap, and ConcurrentHashMap.\n\nFYI, currently,\n\nTREEIFY_THRESHOLD = 8 : if a bucket contains more than 8 nodes, the linked list is transformed into a balanced tree.\nUNTREEIFY_THRESHOLD = 6 : when a bucket becomes too small (due to removal or resizing) the tree is converted back to linked list.\nShare\nImprove this answer\nFollow\nanswered May 4 '16 at 15:04\nKostas Chalkias\n3,8612\n2 gold badges\n21\n21 silver badges\n23\n23 bronze badges","comments":[]},{"answer":"There are 5 basic differentiations with HashTable and HashMaps.\n\nMaps allows you to iterate and retrieve keys, values, and both key-value pairs as well, Where HashTable don't have all this capability.\nIn Hashtable there is a function contains(), which is very confusing to use. Because the meaning of contains is slightly deviating. Whether it means contains key or contains value? tough to understand. Same thing in Maps we have ContainsKey() and ContainsValue() functions, which are very easy to understand.\nIn hashmap you can remove element while iterating, safely. where as it is not possible in hashtables.\nHashTables are by default synchronized, so it can be used with multiple threads easily. Where as HashMaps are not synchronized by default, so can be used with only single thread. But you can still convert HashMap to synchronized by using Collections util class's synchronizedMap(Map m) function.\nHashTable won't allow null keys or null values. Where as HashMap allows one null key, and multiple null values.\nShare\nImprove this answer\nFollow\nedited Apr 10 '14 at 15:44\nBrad Larson♦\n169k45\n45 gold badges\n388\n388 silver badges\n563\n563 bronze badges\nanswered Dec 11 '13 at 12:45\nuser1923551\n4,41632\n32 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"My small contribution :\n\nFirst and most significant different between Hashtable and HashMap is that, HashMap is not thread-safe while Hashtable is a thread-safe collection.\n\nSecond important difference between Hashtable and HashMap is performance, since HashMap is not synchronized it perform better than Hashtable.\n\nThird difference on Hashtable vs HashMap is that Hashtable is obsolete class and you should be using ConcurrentHashMap in place of Hashtable in Java.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Mar 18 '14 at 21:46\nShreyos Adikari\n11.5k19\n19 gold badges\n69\n69 silver badges\n76\n76 bronze badges","comments":[]},{"answer":"HashMap: It is a class available inside java.util package and it is used to store the element in key and value format.\n\nHashtable: It is a legacy class which is being recognized inside collection framework.\n\nShare\nImprove this answer\nFollow\nedited Dec 28 '18 at 2:05\nPang\n8,698144\n144 gold badges\n79\n79 silver badges\n113\n113 bronze badges\nanswered Jan 31 '13 at 13:41\nAnkit\n2352\n2 silver badges\n7\n7 bronze badges","comments":["If it is does so , it should be in comments not as answer."]},{"answer":"Hashtable is synchronized whereas HashMap is not.\nAnother difference is that iterator in the HashMap is fail-safe while the enumerator for the Hashtable isn't. If you change the map while iterating, you'll know.\nHashMap permits null values in it, while Hashtable doesn't.\nShare\nImprove this answer\nFollow\nedited Aug 16 '19 at 19:08\nIhor Patsian\n1,2602\n2 gold badges\n15\n15 silver badges\n24\n24 bronze badges\nanswered Jan 22 '13 at 5:31\nraja\n2,2932\n2 gold badges\n20\n20 silver badges\n25\n25 bronze badges","comments":["HashMap iterator is fail-fast not fail-safe. Thats why we have ConcurrentHashMap that allows modification while iteration. Check this post journaldev.com/122/…","@Pankaj Exactly."]},{"answer":"HashTable is a legacy class in the jdk that shouldn't be used anymore. Replace usages of it with ConcurrentHashMap. If you don't require thread safety, use HashMap which isn't threadsafe but faster and uses less memory.\n\nShare\nImprove this answer\nFollow\nedited Apr 21 '13 at 17:27\nanswered Apr 15 '13 at 14:49\njontejj\n2,6001\n1 gold badge\n21\n21 silver badges\n27\n27 bronze badges","comments":["Because I thought the other answers, at the time, didn't dismiss HashTable but explained that it was threadsafe. The truth is that as soon as you see HashTable in code, you should replace it with ConcurrentHashMap without skipping a beat. And if thread safety is not a concern then HashMap can be used to improve performance a bit."]},{"answer":"HashMap and HashTable\n\nSome important points about HashMap and HashTable. please read below details.\n\n1) Hashtable and Hashmap implement the java.util.Map interface 2) Both Hashmap and Hashtable is the hash based collection. and working on hashing. so these are similarity of HashMap and HashTable.\n\nWhat is the difference between HashMap and HashTable?\n\n1) First difference is HashMap is not thread safe While HashTable is ThreadSafe\n2) HashMap is performance wise better because it is not thread safe. while Hashtable performance wise is not better because it is thread safe. so multiple thread can not access Hashtable at the same time.\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '17 at 14:59\nPawan Patil\n8743\n3 gold badges\n15\n15 silver badges\n37\n37 bronze badges\nanswered Jul 5 '14 at 6:27\nJegsVala\n1,62117\n17 silver badges\n25\n25 bronze badges","comments":["Down-voted because this answer is not correct in some aspects. Hashtable does not implement the Map interface, but only extends the Dictionary class, which is obsolete."]},{"answer":"Hashtable:\n\nHashtable is a data structure that retains values of key-value pair. It doesn’t allow null for both the keys and the values. You will get a NullPointerException if you add null value. It is synchronized. So it comes with its cost. Only one thread can access HashTable at a particular time.\n\nExample :\n\nimport java.util.Map;\nimport java.util.Hashtable;\n\npublic class TestClass {\n\n    public static void main(String args[ ]) {\n    Map<Integer,String> states= new Hashtable<Integer,String>();\n    states.put(1, \"INDIA\");\n    states.put(2, \"USA\");\n\n    states.put(3, null);    //will throw NullPointerEcxeption at runtime\n\n    System.out.println(states.get(1));\n    System.out.println(states.get(2));\n//  System.out.println(states.get(3));\n\n    }\n}\n\n\nHashMap:\n\nHashMap is like Hashtable but it also accepts key value pair. It allows null for both the keys and the values. Its performance better is better than HashTable, because it is unsynchronized.\n\nExample:\n\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class TestClass {\n\n    public static void main(String args[ ]) {\n    Map<Integer,String> states = new HashMap<Integer,String>();\n    states.put(1, \"INDIA\");\n    states.put(2, \"USA\");\n\n    states.put(3, null);    // Okay\n    states.put(null,\"UK\");\n\n    System.out.println(states.get(1));\n    System.out.println(states.get(2));\n    System.out.println(states.get(3));\n\n    }\n}\n\nShare\nImprove this answer\nFollow\nedited Apr 26 '16 at 9:46\nmanojgolty\n921\n1 silver badge\n7\n7 bronze badges\nanswered Feb 10 '15 at 7:44\nIntelliJ Amiya\n71.1k14\n14 gold badges\n155\n155 silver badges\n187\n187 bronze badges","comments":[]},{"answer":"HashMap and Hashtable both are used to store data in key and value form. Both are using hashing technique to store unique keys. ut there are many differences between HashMap and Hashtable classes that are given below.\n\nShare\nImprove this answer\nFollow\nanswered Oct 30 '19 at 11:32\nDeC\n1,75018\n18 silver badges\n33\n33 bronze badges","comments":["I think it is copied from javaconceptoftheday.com/…"]},{"answer":"Old and classic topic, just want to add this helpful blog that explains this:\n\nhttp://blog.manishchhabra.com/2012/08/the-5-main-differences-betwen-hashmap-and-hashtable/\n\nBlog by Manish Chhabra\n\nThe 5 main differences betwen HashMap and Hashtable\n\nHashMap and Hashtable both implement java.util.Map interface but there are some differences that Java developers must understand to write more efficient code. As of the Java 2 platform v1.2, Hashtable class was retrofitted to implement the Map interface, making it a member of the Java Collections Framework.\n\nOne of the major differences between HashMap and Hashtable is that HashMap is non-synchronized whereas Hashtable is synchronized, which means Hashtable is thread-safe and can be shared between multiple threads but HashMap cannot be shared between multiple threads without proper synchronization. Java 5 introduced ConcurrentHashMap which is an alternative of Hashtable and provides better scalability than Hashtable in Java.Synchronized means only one thread can modify a hash table at one point of time. Basically, it means that any thread before performing an update on a hashtable will have to acquire a lock on the object while others will wait for lock to be released.\n\nThe HashMap class is roughly equivalent to Hashtable, except that it permits nulls. (HashMap allows null values as key and value whereas Hashtable doesn’t allow nulls).\n\nThe third significant difference between HashMap vs Hashtable is that Iterator in the HashMap is a fail-fast iterator while the enumerator for the Hashtable is not and throw ConcurrentModificationException if any other Thread modifies the map structurally by adding or removing any element except Iterator’s own remove() method. But this is not a guaranteed behavior and will be done by JVM on best effort. This is also an important difference between Enumeration and Iterator in Java.\n\nOne more notable difference between Hashtable and HashMap is that because of thread-safety and synchronization Hashtable is much slower than HashMap if used in Single threaded environment. So if you don’t need synchronization and HashMap is only used by one thread, it out perform Hashtable in Java.\n\nHashMap does not guarantee that the order of the map will remain constant over time.\n\nNote that HashMap can be synchronized by\n\nMap m = Collections.synchronizedMap(hashMap);\n\n\nIn Summary there are significant differences between Hashtable and HashMap in Java e.g. thread-safety and speed and based upon that only use Hashtable if you absolutely need thread-safety, if you are running Java 5 consider using ConcurrentHashMap in Java.\n\nShare\nImprove this answer\nFollow\nedited Aug 6 '15 at 8:04\nBalusC\n1.0m355\n355 gold badges\n3498\n3498 silver badges\n3470\n3470 bronze badges\nanswered Aug 17 '14 at 9:58\nNight0\n3155\n5 silver badges\n11\n11 bronze badges","comments":["ConcurrentHashMap is not read-synchronized, whereas Hashtable is. So if you have a high amount of read operations happening simultaneously with writes, a Hashtable would serve you better if you care about data integrity."]},{"answer":"HashMap is emulated and therefore usable in GWT client code whereas Hashtable is not.\n\nShare\nImprove this answer\nFollow\nanswered Jul 15 '13 at 9:54\npong\n5044\n4 silver badges\n12\n12 bronze badges","comments":["Is that a comprehensive description of differences between the two apis?","Yes (sic!). That's all GWT developers need to know about it."]}]},{"id":"59838","href":"https://stackoverflow.com/questions/59838/how-can-i-check-if-a-directory-exists-in-a-bash-shell-script","title":"How can I check if a directory exists in a Bash shell script?","description":"\n                \nWhat command can be used to check if a directory exists or not, within a Bash shell script?\n    ","questionComments":[],"answers":[{"answer":"To check if a directory exists in a shell script, you can use the following:\n\nif [ -d \"$DIRECTORY\" ]; then\n  # Control will enter here if $DIRECTORY exists.\nfi\n\n\nOr to check if a directory doesn't exist:\n\nif [ ! -d \"$DIRECTORY\" ]; then\n  # Control will enter here if $DIRECTORY doesn't exist.\nfi\n\n\nHowever, as Jon Ericson points out, subsequent commands may not work as intended if you do not take into account that a symbolic link to a directory will also pass this check. E.g. running this:\n\nln -s \"$ACTUAL_DIR\" \"$SYMLINK\"\nif [ -d \"$SYMLINK\" ]; then \n  rmdir \"$SYMLINK\" \nfi\n\n\nWill produce the error message:\n\nrmdir: failed to remove `symlink': Not a directory\n\n\nSo symbolic links may have to be treated differently, if subsequent commands expect directories:\n\nif [ -d \"$LINK_OR_DIR\" ]; then \n  if [ -L \"$LINK_OR_DIR\" ]; then\n    # It is a symlink!\n    # Symbolic link specific commands go here.\n    rm \"$LINK_OR_DIR\"\n  else\n    # It's a directory!\n    # Directory command goes here.\n    rmdir \"$LINK_OR_DIR\"\n  fi\nfi\n\n\nTake particular note of the double-quotes used to wrap the variables. The reason for this is explained by 8jean in another answer.\n\nIf the variables contain spaces or other unusual characters it will probably cause the script to fail.\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 11:54\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 12 '08 at 20:07\nGrundlefleck\n116k22\n22 gold badges\n89\n89 silver badges\n110\n110 bronze badges","comments":["If you want to play it safe with the GNU tools, use of -- is highly recommended (end-of-options marker). Otherwise, if your variable contains something that looks like an option, the script'll fail just as with spaces.","For modern versions of bash, ksh, etc. [...] is a builtin","One thing to keep in mind: [ ! -d \"$DIRECTORY\" ] will be true either if $DIRECTORY doesn't exist, or if does exist but isn't a directory. Consider something like if [ ! -d \"$DIRECTORY\" ] ; then mkdir \"$DIRECTORY\" ; fi; this will fail if \"$DIRECTORY\" is a file. (Of course you should check whether mkdir succeeded anyway; there are a number of reasons it can fail.)","It might be worth mentioning that as soon as the check has been performed the situation can have changed already due to other processes. In many cases it is better to just create or use the directory and react on a failure.","Instead of testing for both the directory (-d) and the symlink (-L), it's easier just to append a slash to the variable, like if [ -d \"${THING:+$THING/}\" ]. A directory won't mind the extra slash. A file will evaluate to false. Empty will remain empty, so false. And a symlink will be resolved to its destination. Of course, it depends on your goal. If you want to go there, this is fine. If you want to delete it, then the code in this answer is better."]},{"answer":"Remember to always wrap variables in double quotes when referencing them in a Bash script. Kids these days grow up with the idea that they can have spaces and lots of other funny characters in their directory names. (Spaces! Back in my days, we didn't have no fancy spaces! ;))\n\nOne day, one of those kids will run your script with $DIRECTORY set to \"My M0viez\" and your script will blow up. You don't want that. So use this.\n\nif [ -d \"$DIRECTORY\" ]; then\n    # Will enter here if $DIRECTORY exists, even if it contains spaces\nfi\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 11:56\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 15 '08 at 22:00\n8jean\n8,2321\n1 gold badge\n20\n20 silver badges\n13\n13 bronze badges","comments":["Another reason to use double quotes is in case $DIRECTORY is not set for some reason.","\"always wrap variables in double quotes...in a bash script.\" For bash, not technically necessary when using [[...]]; see tldp.org/LDP/abs/html/testconstructs.html#DBLBRACKETS (note: no word splitting): \"No filename expansion or word splitting takes place between [[ and ]], but there is parameter expansion and command substitution.\"","Directories on Unix/Linux should not have any whitespaces, and subsequently scripts should not be adapted to it. It's bad enough Windows supports it, with all consequences to Windows scripting, but please, for the love of whatever, no need to introduce unnecessary requirements.","@tvCa I find that users generally prefer to be allowed more flexibility in their directory names rather than being forced to make things easier for developers. (In fact, when dealing with long file names, I find ones without spaces to be a pain as that kills word wrapping even though I myself have suffered in the past from not accounting for paths with spaces in scripts and programs.)","Ha. Spaces are just characters that have no glyphs usually. Anyway, you can escape them with a backslash."]},{"answer":"Note the -d test can produce some surprising results:\n\n$ ln -s tmp/ t\n$ if [ -d t ]; then rmdir t; fi\nrmdir: directory \"t\": Path component not a directory\n\n\nFile under: \"When is a directory not a directory?\" The answer: \"When it's a symlink to a directory.\" A slightly more thorough test:\n\nif [ -d t ]; then \n   if [ -L t ]; then \n      rm t\n   else \n      rmdir t\n   fi\nfi\n\n\nYou can find more information in the Bash manual on Bash conditional expressions and the [ builtin command and the [[ compound commmand.\n\nShare\nImprove this answer\nFollow\nedited Sep 11 '17 at 14:10\nJonathan Leffler\n674k127\n127 gold badges\n821\n821 silver badges\n1193\n1193 bronze badges\nanswered Sep 12 '08 at 20:26\nJon Ericson\n19.7k11\n11 gold badges\n94\n94 silver badges\n140\n140 bronze badges","comments":["or, assuming it is only necessary to work on directories (and links can be ignored) => if [ -d tmpdir -a ! -L tmpdir ]; then echo \"is directory\"; rmdir tmpdir; fi ... or, for one command that works on both links & dirs: rm -r tmpdir"]},{"answer":"I find the double-bracket version of test makes writing logic tests more natural:\n\nif [[ -d \"${DIRECTORY}\" && ! -L \"${DIRECTORY}\" ]] ; then\n    echo \"It's a bona-fide directory\"\nfi\n\nShare\nImprove this answer\nFollow\nedited Jul 1 '13 at 1:56\nJay\n18.1k33\n33 gold badges\n110\n110 silver badges\n169\n169 bronze badges\nanswered Sep 12 '08 at 21:33\nyukondude\n22.6k13\n13 gold badges\n46\n46 silver badges\n56\n56 bronze badges","comments":["for if [[ -d \"$TARFILE\" ]] I'm getting [[: not found","@TheVillageIdiot and @Hedgehog, are you using bash shell? The double bracket isn't universally supported. Here's a SO answer on that point: stackoverflow.com/questions/669452/…","And in Busybox ash with default compilation options [[ ]] is supported, but doesn't in fact provide any different functionality to [ ]. If portability is a concern, stick with [ ] and use the necessary workarounds.","...if using bash constructs in a shell script, the first line of the script should be: #!/bin/bash (and not #!/bin/sh, ksh, etc)","When using double square brackets in bash, you do not need to quote the variables."]},{"answer":"Shorter form:\n\n# if $DIR is a directory, then print yes\n[ -d \"$DIR\" ] && echo \"Yes\"\n\nShare\nImprove this answer\nFollow\nedited Feb 2 at 10:21\nLucas\n4282\n2 gold badges\n9\n9 silver badges\n13\n13 bronze badges\nanswered Sep 12 '08 at 21:08\nelmarco\n28.3k21\n21 gold badges\n58\n58 silver badges\n68\n68 bronze badges","comments":["Does this work like this: if $dir is a dir, then echo \"yes\"? A bit of explanation would help :)","cmd && other is a common shorthand for if cmd; then other; fi -- this works with most programming languages which support Boolean logic, and is known as short-circuit evaluation.","The behavior is not the same under set -e (which is a shell programming best practice).","@dolmen the [ -d \"$DIR\" ] is checked (followed by && echo Yes), so I believe set -e makes no difference to the script behaviour (i.e if the test fails, the script continues normally)."]},{"answer":"To check if a directory exists you can use a simple if structure like this:\n\nif [ -d directory/path to a directory ] ; then\n# Things to do\n\nelse #if needed #also: elif [new condition]\n# Things to do\nfi\n\n\nYou can also do it in the negative:\n\nif [ ! -d directory/path to a directory ] ; then\n# Things to do when not an existing directory\n\n\nNote: Be careful. Leave empty spaces on either side of both opening and closing braces.\n\nWith the same syntax you can use:\n\n-e: any kind of archive\n\n-f: file\n\n-h: symbolic link\n\n-r: readable file\n\n-w: writable file\n\n-x: executable file\n\n-s: file size greater than zero\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:12\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 8 '15 at 2:50\nJorge Barroso\n1,7181\n1 gold badge\n9\n9 silver badges\n13\n13 bronze badges","comments":["How is this any better than the accepted answer from 2008, aside from going off-topic with the file switches?","better, because of [ ! -d directory/path to a directory ]"]},{"answer":"A simple script to test if a directory or file is present or not:\n\n if [ -d /home/ram/dir ]   # For file \"if [ -f /home/rama/file ]\"\n then\n     echo \"dir present\"\n else\n     echo \"dir not present\"\n fi\n\n\nA simple script to check whether the directory is present or not:\n\n mkdir tempdir   # If you want to check file use touch instead of mkdir\n ret=$?\n if [ \"$ret\" == \"0\" ]\n then\n     echo \"dir present\"\n else\n     echo \"dir not present\"\n fi\n\n\nThe above scripts will check if the directory is present or not\n\n$? if the last command is a success it returns \"0\", else a non-zero value. Suppose tempdir is already present. Then mkdir tempdir will give an error like below:\n\nmkdir: cannot create directory ‘tempdir’: File exists\n\nShare\nImprove this answer\nFollow\nedited Sep 9 '20 at 10:30\nJames Brown\n32.7k6\n6 gold badges\n31\n31 silver badges\n54\n54 bronze badges\nanswered May 15 '18 at 5:36\nyoctotutor.com\n4,6614\n4 gold badges\n19\n19 silver badges\n32\n32 bronze badges","comments":["The second one would create the directory, if it didn't exist at first. Then it's not idempotent.","👆👆👆. The 2nd one seems dangerous. Since it creates the directory, it's not even true anymore that the dir is not present.","mkdir will also not create the full path (without a param), but the opposite would be even more dangerous, as you are not even able to revert (rm -f) the changes as you don't know which directories it created"]},{"answer":"You can use test -d (see man test).\n\n-d file True if file exists and is a directory.\n\nFor example:\n\ntest -d \"/etc\" && echo Exists || echo Does not exist\n\n\nNote: The test command is same as conditional expression [ (see: man [), so it's portable across shell scripts.\n\n[ - This is a synonym for the test builtin, but the last argument must, be a literal ], to match the opening [.\n\nFor possible options or further help, check:\n\nhelp [\nhelp test\nman test or man [\nShare\nImprove this answer\nFollow\nedited Mar 16 '16 at 17:01\nanswered Sep 12 '15 at 21:25\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges","comments":[]},{"answer":"Or for something completely useless:\n\n[ -d . ] || echo \"No\"\n\nShare\nImprove this answer\nFollow\nedited Aug 17 '09 at 15:47\nsth\n203k49\n49 gold badges\n265\n265 silver badges\n357\n357 bronze badges\nanswered Aug 17 '09 at 14:02\nSilly","comments":["It will never print \"No\". Current directory always exists, unless deleted by another thread or other ways.","Perfect sample :) given that how \"unique\" are some answers compared to the accepted answer","Why has this been upvoted so many times? It doesn't answer the question."]},{"answer":"Here's a very pragmatic idiom:\n\n(cd $dir) || return # Is this a directory,\n                    # and do we have access?\n\n\nI typically wrap it in a function:\n\ncan_use_as_dir() {\n    (cd ${1:?pathname expected}) || return\n}\n\n\nOr:\n\nassert_dir_access() {\n    (cd ${1:?pathname expected}) || exit\n}\n\n\nThe nice thing about this approach is that I do not have to think of a good error message.\n\ncd will give me a standard one line message to standard error already. It will also give more information than I will be able to provide. By performing the cd inside a subshell ( ... ), the command does not affect the current directory of the caller. If the directory exists, this subshell and the function are just a no-op.\n\nNext is the argument that we pass to cd: ${1:?pathname expected}. This is a more elaborate form of parameter substitution which is explained in more detail below.\n\nTl;dr: If the string passed into this function is empty, we again exit from the subshell ( ... ) and return from the function with the given error message.\n\nQuoting from the ksh93 man page:\n\n${parameter:?word}\n\n\nIf parameter is set and is non-null then substitute its value; otherwise, print word and exit from the shell (if not interactive). If word is omitted then a standard message is printed.\n\nand\n\nIf the colon : is omitted from the above expressions, then the shell only checks whether parameter is set or not.\n\nThe phrasing here is peculiar to the shell documentation, as word may refer to any reasonable string, including whitespace.\n\nIn this particular case, I know that the standard error message 1: parameter not set is not sufficient, so I zoom in on the type of value that we expect here - the pathname of a directory.\n\nA philosophical note:\n\nThe shell is not an object oriented language, so the message says pathname, not directory. At this level, I'd rather keep it simple - the arguments to a function are just strings.\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:07\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 9 '12 at 21:43\nHenk Langeveld\n7,19238\n38 silver badges\n53\n53 bronze badges","comments":["This do more than only check for existance: This check for accessibility at your user level. SO question stand for existance only. So right answer is test -d as @Grundlefleck explained.","@F.Hauri - He didn't ask for anything more, that's true. However, I've found that I typically need to know more than that.","And it never occurred to me that no test can be conclusive, unless it runs as root. test -d /unreadable/exists will fail, even if the argument exists."]},{"answer":"if [ -d \"$Directory\" -a -w \"$Directory\" ]\nthen\n    #Statements\nfi\n\n\nThe above code checks if the directory exists and if it is writable.\n\nShare\nImprove this answer\nFollow\nedited May 25 '11 at 8:51\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 21 '10 at 6:06\nmuralikrishna\n4094\n4 silver badges\n2\n2 bronze badges","comments":["-a is identical in effect to -e. It has been \"deprecated,\" and its use is discouraged."]},{"answer":"DIRECTORY=/tmp\n\nif [ -d \"$DIRECTORY\" ]; then\n    echo \"Exists\"\nfi\n\n\nTry online\n\nShare\nImprove this answer\nFollow\nanswered Oct 9 '19 at 6:08\nVishal\n18k17\n17 gold badges\n73\n73 silver badges\n91\n91 bronze badges","comments":["remeber space after [ -> [` `-d. i got error because of missing space","AGAIN, this answer was already given in 2008, with more useful explanations. The only new thing here is the online playground."]},{"answer":"More features using find\n\nCheck existence of the folder within sub-directories:\n\n  found=`find -type d -name \"myDirectory\"`\n  if [ -n \"$found\" ]\n  then\n      # The variable 'found' contains the full path where \"myDirectory\" is.\n      # It may contain several lines if there are several folders named \"myDirectory\".\n  fi\n\n\nCheck existence of one or several folders based on a pattern within the current directory:\n\n  found=`find -maxdepth 1 -type d -name \"my*\"`\n  if [ -n \"$found\" ]\n  then\n      # The variable 'found' contains the full path where folders \"my*\" have been found.\n  fi\n\n\nBoth combinations. In the following example, it checks the existence of the folder in the current directory:\n\n  found=`find -maxdepth 1 -type d -name \"myDirectory\"`\n  if [ -n \"$found\" ]\n  then\n      # The variable 'found' is not empty => \"myDirectory\"` exists.\n  fi\n\nShare\nImprove this answer\nFollow\nedited Dec 17 '20 at 13:12\nfaho\n10.5k28\n28 silver badges\n35\n35 bronze badges\nanswered Sep 12 '08 at 20:17\nNeil Neyman\n2,05116\n16 silver badges\n21\n21 bronze badges","comments":["Hi Niel. Your idea may be useful to check the existence of directories depending on a pattern like: find -maxdepth 1 -type d -name 'pattern'. Do you mind if I append in your answer this trick? Cheers ;)"]},{"answer":"Type this code on the Bash prompt:\n\nif [ -d \"$DIRECTORY\" ]; then\n    # If true this block of code will execute\nfi\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 5 '14 at 3:39\nsantosh\n3437\n7 silver badges\n18\n18 bronze badges","comments":["AGAIN, this answer was already given in 2008. What's the point in repeating it?!"]},{"answer":"Actually, you should use several tools to get a bulletproof approach:\n\nDIR_PATH=`readlink -f \"${the_stuff_you_test}\"` # Get rid of symlinks and get abs path\nif [[ -d \"${DIR_PATH}\" ]] ; Then # Now you're testing\n    echo \"It's a dir\";\nfi\n\n\nThere isn't any need to worry about spaces and special characters as long as you use \"${}\".\n\nNote that [[]] is not as portable as [], but since most people work with modern versions of Bash (since after all, most people don't even work with command line :-p), the benefit is greater than the trouble.\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 11:58\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 17 '10 at 17:46\ne-satis\n525k103\n103 gold badges\n284\n284 silver badges\n322\n322 bronze badges","comments":[]},{"answer":"Have you considered just doing whatever you want to do in the if rather than looking before you leap?\n\nI.e., if you want to check for the existence of a directory before you enter it, try just doing this:\n\nif pushd /path/you/want/to/enter; then\n    # Commands you want to run in this directory\n    popd\nfi\n\n\nIf the path you give to pushd exists, you'll enter it and it'll exit with 0, which means the then portion of the statement will execute. If it doesn't exist, nothing will happen (other than some output saying the directory doesn't exist, which is probably a helpful side-effect anyways for debugging).\n\nIt seems better than this, which requires repeating yourself:\n\nif [ -d /path/you/want/to/enter ]; then\n    pushd /path/you/want/to/enter\n    # Commands you want to run in this directory\n    popd\nfi\n\n\nThe same thing works with cd, mv, rm, etc... if you try them on files that don't exist, they'll exit with an error and print a message saying it doesn't exist, and your then block will be skipped. If you try them on files that do exist, the command will execute and exit with a status of 0, allowing your then block to execute.\n\nShare\nImprove this answer\nFollow\nedited May 12 '20 at 6:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 7 '17 at 16:24\nArtOfWarfare\n18.1k15\n15 gold badges\n124\n124 silver badges\n180\n180 bronze badges","comments":["pushd is to me the most elegant way of doing this. I was about to post it as an answer :)"]},{"answer":"[[ -d \"$DIR\" && ! -L \"$DIR\" ]] && echo \"It's a directory and not a symbolic link\"\n\n\nN.B: Quoting variables is a good practice.\n\nExplanation:\n\n-d: check if it's a directory\n-L: check if it's a symbolic link\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 13:29\nanswered Apr 19 '15 at 0:54\nJahid\n18.7k8\n8 gold badges\n81\n81 silver badges\n97\n97 bronze badges","comments":["An explanation would be in order (by editing your answer, not here in comments)."]},{"answer":"To check more than one directory use this code:\n\nif [ -d \"$DIRECTORY1\" ] && [ -d \"$DIRECTORY2\" ] then\n    # Things to do\nfi\n\nShare\nImprove this answer\nFollow\nedited Jan 27 '16 at 13:02\nrbs\n9572\n2 gold badges\n15\n15 silver badges\n23\n23 bronze badges\nanswered Dec 29 '15 at 9:45\nRaamesh Keerthi\n5811\n1 gold badge\n5\n5 silver badges\n12\n12 bronze badges","comments":["how can you check that it doesn't exists?"]},{"answer":"Check if the directory exists, else make one:\n\n[ -d \"$DIRECTORY\" ] || mkdir $DIRECTORY\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:20\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 23 '16 at 7:25\nDavid Okwii\n6,4052\n2 gold badges\n29\n29 silver badges\n27\n27 bronze badges","comments":["You could use mkdir -p \"$DIRECTORY\" for the same effect.","Need double quotes around $DIRECTORY in the mkdir part as well. Otherwise, word splitting may result in undesirable results. For example: dir=\"a b\"; mkdir $dir will result in two directories a and b being created, rather than a single a b directory."]},{"answer":"[ -d ~/Desktop/TEMPORAL/ ] && echo \"DIRECTORY EXISTS\" || echo \"DIRECTORY DOES NOT EXIST\"\n\nShare\nImprove this answer\nFollow\nedited Jul 28 '13 at 8:36\ndoubleDown\n7,1761\n1 gold badge\n28\n28 silver badges\n45\n45 bronze badges\nanswered Apr 18 '13 at 22:12\nJuan Carlos Kuri Pinto\n1,11212\n12 silver badges\n12\n12 bronze badges","comments":["An explanation would be in order (by editing your answer, not here in comments)."]},{"answer":"This answer wrapped up as a shell script\n\nExamples\n$ is_dir ~                           \nYES\n\n$ is_dir /tmp                        \nYES\n\n$ is_dir ~/bin                       \nYES\n\n$ mkdir '/tmp/test me'\n\n$ is_dir '/tmp/test me'\nYES\n\n$ is_dir /asdf/asdf                  \nNO\n\n# Example of calling it in another script\nDIR=~/mydata\nif [ $(is_dir $DIR) == \"NO\" ]\nthen\n  echo \"Folder doesnt exist: $DIR\";\n  exit;\nfi\n\nis_dir\nfunction show_help()\n{\n  IT=$(CAT <<EOF\n\n  usage: DIR\n  output: YES or NO, depending on whether or not the directory exists.\n\n  )\n  echo \"$IT\"\n  exit\n}\n\nif [ \"$1\" == \"help\" ]\nthen\n  show_help\nfi\nif [ -z \"$1\" ]\nthen\n  show_help\nfi\n\nDIR=$1\nif [ -d $DIR ]; then \n   echo \"YES\";\n   exit;\nfi\necho \"NO\";\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:26\nCommunity♦\n11\n1 silver badge\nanswered Apr 15 '16 at 18:13\nBrad Parks\n55.7k55\n55 gold badges\n224\n224 silver badges\n293\n293 bronze badges","comments":[]},{"answer":"Using the -e check will check for files and this includes directories.\n\nif [ -e ${FILE_PATH_AND_NAME} ]\nthen\n    echo \"The file or directory exists.\"\nfi\n\nShare\nImprove this answer\nFollow\nedited Jul 28 '13 at 8:34\ndoubleDown\n7,1761\n1 gold badge\n28\n28 silver badges\n45\n45 bronze badges\nanswered Jul 25 '13 at 13:12\nbailey86\n2413\n3 silver badges\n5\n5 bronze badges","comments":["And does not correctly answer the OP's question - is it a directory?"]},{"answer":"if [ -d \"$DIRECTORY\" ]; then\n    # Will enter here if $DIRECTORY exists\nfi\n\n\nThis is not completely true...\n\nIf you want to go to that directory, you also need to have the execute rights on the directory. Maybe you need to have write rights as well.\n\nTherefore:\n\nif [ -d \"$DIRECTORY\" ] && [ -x \"$DIRECTORY\" ] ; then\n    # ... to go to that directory (even if DIRECTORY is a link)\n    cd $DIRECTORY\n    pwd\nfi\n\nif [ -d \"$DIRECTORY\" ] && [ -w \"$DIRECTORY\" ] ; then\n    # ... to go to that directory and write something there (even if DIRECTORY is a link)\n    cd $DIRECTORY\n    touch foobar\nfi\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:00\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 18 '10 at 10:52\nuser296421","comments":[]},{"answer":"As per Jonathan's comment:\n\nIf you want to create the directory and it does not exist yet, then the simplest technique is to use mkdir -p which creates the directory — and any missing directories up the path — and does not fail if the directory already exists, so you can do it all at once with:\n\nmkdir -p /some/directory/you/want/to/exist || exit 1\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:19\ncommunity wiki\n\n\n3 revs, 3 users 70%\nkenorb","comments":[]},{"answer":"In kind of a ternary form,\n\n[ -d \"$directory\" ] && echo \"exist\" || echo \"not exist\"\n\n\nAnd with test:\n\ntest -d \"$directory\" && echo \"exist\" || echo \"not exist\"\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 15 '17 at 13:36\nAbhishek Gurjar\n7,2409\n9 gold badges\n35\n35 silver badges\n41\n41 bronze badges","comments":[]},{"answer":"The ls command in conjunction with -l (long listing) option returns attributes information about files and directories.\nIn particular the first character of ls -l output it is usually a d or a - (dash). In case of a d the one listed is a directory for sure.\n\nThe following command in just one line will tell you if the given ISDIR variable contains a path to a directory or not:\n\n[[ $(ls -ld \"$ISDIR\" | cut -c1) == 'd' ]] &&\n    echo \"YES, $ISDIR is a directory.\" || \n    echo \"Sorry, $ISDIR is not a directory\"\n\n\nPractical usage:\n\n    [claudio@nowhere ~]$ ISDIR=\"$HOME/Music\" \n    [claudio@nowhere ~]$ ls -ld \"$ISDIR\"\n    drwxr-xr-x. 2 claudio claudio 4096 Aug 23 00:02 /home/claudio/Music\n    [claudio@nowhere ~]$ [[ $(ls -ld \"$ISDIR\" | cut -c1) == 'd' ]] && \n        echo \"YES, $ISDIR is a directory.\" ||\n        echo \"Sorry, $ISDIR is not a directory\"\n    YES, /home/claudio/Music is a directory.\n\n    [claudio@nowhere ~]$ touch \"empty file.txt\"\n    [claudio@nowhere ~]$ ISDIR=\"$HOME/empty file.txt\" \n    [claudio@nowhere ~]$ [[ $(ls -ld \"$ISDIR\" | cut -c1) == 'd' ]] && \n        echo \"YES, $ISDIR is a directory.\" || \n        echo \"Sorry, $ISDIR is not a directoy\"\n    Sorry, /home/claudio/empty file.txt is not a directory\n\nShare\nImprove this answer\nFollow\nedited Feb 26 '14 at 11:21\nHenk Langeveld\n7,19238\n38 silver badges\n53\n53 bronze badges\nanswered Sep 15 '11 at 19:47\nztank1013\n6,1712\n2 gold badges\n18\n18 silver badges\n20\n20 bronze badges","comments":["+1, but it when ISDIR does not exist at all you get an error message as well as your diagnostics message."]},{"answer":"file=\"foo\" \nif [[ -e \"$file\" ]]; then echo \"File Exists\"; fi;\n\nShare\nImprove this answer\nFollow\nanswered Feb 22 '13 at 2:39\najmartin\n2,2231\n1 gold badge\n24\n24 silver badges\n41\n41 bronze badges","comments":["An explanation would be in order (by editing your answer, not here in comments)."]},{"answer":"There are great solutions out there, but ultimately every script will fail if you're not in the right directory. So code like this:\n\nif [ -d \"$LINK_OR_DIR\" ]; then\nif [ -L \"$LINK_OR_DIR\" ]; then\n    # It is a symlink!\n    # Symbolic link specific commands go here\n    rm \"$LINK_OR_DIR\"\nelse\n    # It's a directory!\n    # Directory command goes here\n    rmdir \"$LINK_OR_DIR\"\nfi\nfi\n\n\nwill execute successfully only if at the moment of execution you're in a directory that has a subdirectory that you happen to check for.\n\nI understand the initial question like this: to verify if a directory exists irrespective of the user's position in the file system. So using the command 'find' might do the trick:\n\ndir=\" \"\necho \"Input directory name to search for:\"\nread dir\nfind $HOME -name $dir -type d\n\n\nThis solution is good because it allows the use of wildcards, a useful feature when searching for files/directories. The only problem is that, if the searched directory doesn't exist, the 'find' command will print nothing to standard output (not an elegant solution for my taste) and will have nonetheless a zero exit. Maybe someone could improve on this.\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:03\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 12 '11 at 20:40\ndromichaetes\n931\n1 silver badge\n3\n3 bronze badges","comments":["I'd be offended if a program went looking through my entire hard drive to find a directory rather than just politely looking in my current working directory or using the absolute path I give it. What you've suggested might be nice for a tool named locate but not nice for anything else..."]},{"answer":"The below find can be used,\n\nfind . -type d -name dirname -prune -print\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:09\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Aug 13 '14 at 13:41\nSadhun\n2444\n4 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"(1)\n\n[ -d Piyush_Drv1 ] && echo \"\"Exists\"\" || echo \"Not Exists\"\n\n\n(2)\n\n[ `find . -type d -name Piyush_Drv1 -print | wc -l` -eq 1 ] && echo Exists || echo \"Not Exists\"\n\n\n(3)\n\n[[ -d run_dir  && ! -L run_dir ]] && echo Exists || echo \"Not Exists\"\n\n\nIf an issue is found with one of the approaches provided above:\n\nWith the ls command; the cases when a directory does not exists - an error message is shown\n\n[[ `ls -ld SAMPLE_DIR| grep ^d | wc -l` -eq 1 ]] && echo exists || not exists\n\n\n-ksh: not: not found [No such file or directory]\n\nShare\nImprove this answer\nFollow\nedited May 7 '20 at 12:17\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 13 '15 at 7:21\nPiyush Baijal\n2614\n4 silver badges\n12\n12 bronze badges","comments":["What does \"above\" refer to? The three command lines in this answer or previous answers? (Please respond by editing your answer, not here in comments. Thanks in advance.)."]}]},{"id":"5480258","href":"https://stackoverflow.com/questions/5480258/how-to-delete-a-remote-tag","title":"How to delete a remote tag?","description":"\n                \nHow do you delete a Git tag that has already been pushed?\n    ","questionComments":[],"answers":[{"answer":"You can push an 'empty' reference to the remote tag name:\n\ngit push origin :tagname\n\n\nOr, more expressively, use the --delete option (or -d if your git version is older than 1.8.0):\n\ngit push --delete origin tagname\n\n\nNote that git has tag namespace and branch namespace so you may use the same name for a branch and for a tag. If you want to make sure that you cannot accidentally remove the branch instead of the tag, you can specify full ref which will never delete a branch:\n\ngit push origin :refs/tags/tagname\n\n\nIf you also need to delete the local tag, use:\n\ngit tag --delete tagname\n\nBackground\n\nPushing a branch, tag, or other ref to a remote repository involves specifying \"which repo, what source, what destination?\"\n\ngit push remote-repo source-ref:destination-ref\n\n\nA real world example where you push your master branch to the origin's master branch is:\n\ngit push origin refs/heads/master:refs/heads/master\n\n\nWhich because of default paths, can be shortened to:\n\ngit push origin master:master\n\n\nTags work the same way:\n\ngit push origin refs/tags/release-1.0:refs/tags/release-1.0\n\n\nWhich can also be shortened to:\n\ngit push origin release-1.0:release-1.0\n\n\nBy omitting the source ref (the part before the colon), you push 'nothing' to the destination, deleting the ref on the remote end.\n\nShare\nImprove this answer\nFollow\nedited Oct 21 '20 at 14:19\nHarry B\n2,5501\n1 gold badge\n18\n18 silver badges\n40\n40 bronze badges\nanswered Mar 29 '11 at 23:45\nAdam Franco\n71.2k4\n4 gold badges\n33\n33 silver badges\n39\n39 bronze badges","comments":["+1 for both answering the question and explaining the general case, and detailing the unabridged syntax's meaning","And just in case someone wonders how to delete multiple tags at a time you simple list them using white space, e.g. git push --delete origin tag1 tag2. Same is valid for local tags deletion git tag -d tag1 tag2","If tag name collides with a branch name you may end up with deleting your branch. Ha-ha. See the second answer - it's more ecological","The background helped me a lot to understand when i got an error: error: dst refspec \"my-tag\" matches more than one. error: failed to push some refs that I could execute git push origin :refs/tags/my-tag to specifically delete only the tag, and not the branch.","It is also interesting to know that git tag -d `git tag` will delete all local tags. Same applies for git push --delete origin `git tag` assuming you pulled the remote tags locally. That was handy in a test environment."]},{"answer":"A more straightforward way is\n\ngit push --delete origin YOUR_TAG_NAME\n\n\nIMO prefixing colon syntax is a little bit odd in this situation\n\nShare\nImprove this answer\nFollow\nedited May 5 '15 at 10:30\nd4nyll\n9,4875\n5 gold badges\n44\n44 silver badges\n60\n60 bronze badges\nanswered Oct 9 '12 at 0:47\nquexer\n4,6381\n1 gold badge\n10\n10 silver badges\n9\n9 bronze badges","comments":["I think this is the proper way... other syntax look more like hacks to me.","Yep, this is simple and works. Though I'd clarify the answer by specifying what's the variable part: git push --delete origin \"TAGNAME\", where TAGNAME is the name of the original tag.","This works. One addition: If you have a branch and a tag with the same name, you can put the word tag before your tag name to make sure you get the tag, not the branch.","@andypaxo What the command takes is refspecs, the correct way would be prefixing the tags with refs/tags/, like this: refs/tags/v2.3.1.","I had 'bad' tag name created on remote server somehow, which had special characters, so I can't sync with that, so simply removed that with your suggestion: git push --delete origin \"service--<default>--151\" , can't remove it not with intellij, not with stash, not with sourceTree. Thanks !"]},{"answer":"If you have a remote tag v0.1.0 to delete, and your remote is origin, then simply:\n\ngit push origin :refs/tags/v0.1.0\n\n\nIf you also need to delete the tag locally:\n\ngit tag -d v0.1.0\n\n\nSee Adam Franco's answer for an explanation of Git's unusual : syntax for deletion.\n\nShare\nImprove this answer\nFollow\nedited May 3 '18 at 19:03\nTed Hopp\n224k48\n48 gold badges\n373\n373 silver badges\n491\n491 bronze badges\nanswered Jul 21 '12 at 16:14\nAlex Dean\n14.5k11\n11 gold badges\n59\n59 silver badges\n72\n72 bronze badges","comments":["this also works with jgit. the :tag shorthand does not work with jgit","I got fatal: remote part of refspec is not a valid name in :/refs/tags/0.0.1 ...?","@ChaimEliyah you have a leading slash, maybe that's your problem","Better answer, as this also works if you have a branch and a tag that's called the same.","Just :tagname should work for the remote deletion."]},{"answer":"Delete all local tags and get the list of remote tags:\n\ngit tag -l | xargs git tag -d\ngit fetch\n\n\nRemove all remote tags\n\ngit tag -l | xargs -n 1 git push --delete origin\n\n\nClean up local tags\n\ngit tag -l | xargs git tag -d\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '16 at 18:29\nErikE\n44.2k21\n21 gold badges\n140\n140 silver badges\n182\n182 bronze badges\nanswered Apr 2 '13 at 2:26\nSiddhartha Mukherjee\n5,9423\n3 gold badges\n21\n21 silver badges\n10\n10 bronze badges","comments":["How to remove all tags from the local and remote repos. This is what I was looking for, thanks!","git fetch, delete remote and then clean up locals, worked beautifully!","slow, but the most straightforward"]},{"answer":"To remove the tag from the remote repository:\n\ngit push --delete origin TAGNAME\n\n\nYou may also want to delete the tag locally:\n\ngit tag -d TAGNAME\n\nShare\nImprove this answer\nFollow\nanswered Sep 4 '14 at 10:30\nAndrea\n10.9k4\n4 gold badges\n29\n29 silver badges\n38\n38 bronze badges","comments":["so one line to do both: git push --delete origin TAGNAME && git tag -d TAGNAME"]},{"answer":"git tag -d your_tag_name\ngit push origin :refs/tags/your_tag_name\n\n\nThe first line deletes your_tag_name from local repo and second line deletes your_tag_name from remote repo.\n\nFor those who use GitHub, one more step is needed: discarding draft. \n\nShare\nImprove this answer\nFollow\nedited Dec 17 '20 at 16:45\nanswered May 13 '19 at 17:56\nAyub\n1,73222\n22 silver badges\n27\n27 bronze badges","comments":["While this command may answer the question, providing additional context regarding why and/or how this code answers the question improves its long-term value. How to Answer","Please note that the OP did not explicitly include the github tag in their question, so the last step might not be applicable to the OP.","Good point @Edric. I've updated the answer."]},{"answer":"From your terminal, do this:\n\ngit fetch\ngit tags\ngit tag -d {tag-name}\ngit push origin :refs/tags/{tag-name}\n\n\nNow go to Github.com and refresh, they disappear.\n\nShare\nImprove this answer\nFollow\nedited Jan 4 '17 at 17:00\nanswered Jun 27 '16 at 13:23\nMahmoud Zalt\n25k7\n7 gold badges\n75\n75 silver badges\n78\n78 bronze badges","comments":["git tag not tags"]},{"answer":"Delete local tag '12345'\ngit tag -d 12345\n\nDelete remote tag '12345' (eg; GitHub version too)\ngit push origin :refs/tags/12345\n\nalternative approach\ngit push --delete origin tagName\ngit tag -d tagName\n\n\nShare\nImprove this answer\nFollow\nedited May 2 '18 at 13:12\nanswered Mar 23 '18 at 9:50\nL Y E S - C H I O U K H\n3,9777\n7 gold badges\n33\n33 silver badges\n52\n52 bronze badges","comments":[]},{"answer":"Just notice that, if you have a remote branch named as a remote tag, these commands are ambiguous:\n\ngit push origin :tagname\ngit push --delete origin tagname\n\n\nSo you must use this command to delete the tag:\n\ngit push origin :refs/tags/<tag>\n\n\nand this one to delete the branch:\n\ngit push origin :refs/heads/<branch>\n\n\nIf not, you would get an error like this:\n\nerror: dst refspec <tagname> matches more than one.\nerror: failed to push some refs to '<repo>'\n\nShare\nImprove this answer\nFollow\nedited May 27 '16 at 10:37\ntshepang\n11k21\n21 gold badges\n85\n85 silver badges\n128\n128 bronze badges\nanswered May 5 '16 at 17:28\nAlex Vazquez Fente\n4484\n4 silver badges\n9\n9 bronze badges","comments":["Short and concise. This post along with MeganZhou's popped out as being the answer to why we were having issues, the branchname and tagname were identical. I deleted the local tag and pushed to :refs/tags and all was good."]},{"answer":"Up to 100x faster method for thousands of remote tags\n\nAfter reading through these answers while needing to delete over 11,000 tags, I learned these methods relying or xargs take far too long, unless you have hours to burn.\n\nStruggling, I found two much faster ways. For both, start with git tag or git ls-remote --tags to make a list of tags you want to delete on the remote. In the examples below you can omit or replace sorting_proccessing_etc with any greping, sorting, tailing or heading you want (e.g. grep -P \"my_regex\" | sort | head -n -200 etc) :\n\nThis first method is by far the fastest, maybe 20 to 100 times faster than using xargs, and works with a least several thousand tags at a time.\ngit push origin $(< git tag | sorting_processing_etc \\\n| sed -e 's/^/:/' | paste -sd \" \") #note exclude \"<\" for zsh\n\n\nHow does this work? The normal, line-separated list of tags is converted to a single line of space-separated tags, each prepended with : so . . .\n\ntag1   becomes\ntag2   ======>  :tag1 :tag2 :tag3\ntag3\n\n\nUsing git push with this format tag pushes nothing into each remote ref, erasing it (the normal format for pushing this way is local_ref_path:remote_ref_path).\n\nMethod two is broken out as a separate answer elsewhere on this same page\n\nAfter both of these methods, you'll probably want to delete your local tags too. This is much faster so we can go back to using xargs and git tag -d, which is sufficient.\n\ngit tag | sorting_processing_etc | xargs -L 1 git tag -d\n\n\nOR similar to the remote delete:\n\ngit tag -d $(< git tag | sorting_processing_etc | paste -sd \" \")\n\nShare\nImprove this answer\nFollow\nedited Sep 7 '17 at 21:18\nanswered Apr 15 '17 at 2:30\nTonyH\n1,0577\n7 silver badges\n14\n14 bronze badges","comments":["You should split this into a few different answers. The answer with multiple tags on one line is, without a doubt, the right answer for bulk tag deletion. It's actually a little difficult to find this info nearly anywhere else. Even knowing what I'm looking for I have a hard time finding it in the git help page :) So kudos to you and highlight that as the right answer, and move the GitHub API one to a different place. And finally, the deleting tags locally, in bulk, works with space delimited tags (get rid of the colons)","Thanks for the praise and suggestions. I will split this up. I don't understand your comment about local tag deletion. I don't think my final command snippet uses any colons, but I'm on mobile so maybe missing something.","Sorry, I just meant that what you're doing to delete remote tags, works with deleting local tags, providing the entire list at once. :) Just instead of git push origin :tag1 :tag2 etc. you'd do git tag --delete tag1 tag2 tag3 that way you can have a total cleanup. Again, thanks a ton!"]},{"answer":"If you use SourceTree - a great Git GUI - then you can easily do this without the command line by doing the following:\n\nOpen your repository in SourceTree\nSelect and expand the \"Tags\" tab on the left\nRight-Click on the tag you want deleted\nSelect \"Delete YOUR_TAG_NAME\"\nIn the verification window, select \"Remove Tag From Remotes\"\n\nYOUR_TAG_NAME will now be removed from your local repository and all remotes - be it GitHub, BitBucket, or wherever else you listed as a remote for that repository.\n\nAlso, if you deleted a tag locally but not on the remote origins, and you want to delete it everywhere, then just create a new tag that has the same name and is attached at the same commit as the origins. Then, repeat the steps above to delete everywhere.\n\nShare\nImprove this answer\nFollow\nanswered Oct 27 '18 at 13:23\nChris Sprague\n2,03423\n23 silver badges\n19\n19 bronze badges","comments":["Works like a charm. Thanks!","Note that this is safe and will not delete any commit - only the tag itself"]},{"answer":"If you have created a tag called release01 in a Git repository you would remove it from your repository by doing the following:\n\ngit tag -d release01 \ngit push origin :refs/tags/release01 \n\n\nTo remove one from a Mercurial repository:\n\nhg tag --remove featurefoo\n\n\nPlease reference https://confluence.atlassian.com/pages/viewpage.action?pageId=282175551\n\nShare\nImprove this answer\nFollow\nedited May 27 '16 at 10:38\ntshepang\n11k21\n21 gold badges\n85\n85 silver badges\n128\n128 bronze badges\nanswered Nov 11 '14 at 5:54\nMeganZhou\n3163\n3 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"I wanted to remove all tags except for those that match a pattern so that I could delete all but the last couple of months of production tags, here's what I used to great success:\n\nDelete All Remote Tags & Exclude Expression From Delete\n\ngit tag -l | grep -P '^(?!Production-2017-0[89])' | xargs -n 1 git push --delete origin\n\n\nDelete All Local Tags & Exclude Expression From Delete\n\ngit tag -l | grep -P '^(?!Production-2017-0[89])' | xargs git tag -d\n\nShare\nImprove this answer\nFollow\nanswered Sep 25 '17 at 23:11\nLucent Fox\n1,5671\n1 gold badge\n14\n14 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"If you're using PowerShell, and you want to delete a bunch of them:\n\n# Local tags:\ngit tag -l | foreach { git tag -d $_ }\n\n# Remote tags:\ngit tag -l | foreach { git push --delete origin $_ }\n\n\nOf course, you can also filter them before deleting:\n\ngit tag -l | Where-Object { $_ -like \"build-*\" } | foreach { git tag -d $_ }\n\nShare\nImprove this answer\nFollow\nanswered Aug 23 '17 at 11:44\nrsenna\n11k1\n1 gold badge\n51\n51 silver badges\n60\n60 bronze badges","comments":[]},{"answer":"As @CubanX suggested, I've split this answer from my original:\n\nHere is a method which is several times faster than xargs and may scale much more with tweaking. It uses the Github API, a personal access token, and leverages the utility parallel.\ngit tag | sorting_processing_etc | parallel --jobs 2 curl -i -X DELETE \\ \nhttps://api.github.com/repos/My_Account/my_repo/git/refs/tags/{} -H \n\\\"authorization: token GIT_OAUTH_OR_PERSONAL_KEY_HERE\\\"  \\\n-H \\\"cache-control: no-cache\\\"`\n\n\nparallel has many operating modes, but generally parallelizes any command you give it while allowing you to set limits on the number of processes. You can alter the --jobs 2 parameter to allow faster operation, but I had problems with Github's rate limits, which are currently 5000/hr, but also seems to have an undocumented short-term limit as well.\n\nAfter this, you'll probably want to delete your local tags too. This is much faster so we can go back to using xargs and git tag -d, which is sufficient.\n\ngit tag | sorting_processing_etc | xargs -L 1 git tag -d\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Sep 7 '17 at 21:00\nTonyH\n1,0577\n7 silver badges\n14\n14 bronze badges","comments":["This seems much more complicated than the accepted answe. What is the benefit?","If you need to delete several thousand tags, then the speed is 10-100 times faster","Thank you for clarifying. The OP asked about deleting a single tag. I couldnt imagine why someone would use this approach for a single tag. Perhaps this answer is better for another question involving deleting many tags","I don't think it exists. I could create it to answer myself. Do you want to think that's appropriate?","I do! I think it's a fairly common practice here, actually."]},{"answer":"The other answers point out how to accomplish this, but you should keep in mind the consequences since this is a remote repository.\n\nThe git tag man page, in the On Retagging section, has a good explanation of how to courteously inform the remote repo's other users of the change. They even give a handy announcement template for communicating how others should get your changes.\n\nShare\nImprove this answer\nFollow\nanswered Mar 4 '13 at 17:04\nRichard Venable\n7,4522\n2 gold badges\n39\n39 silver badges\n46\n46 bronze badges","comments":[]},{"answer":"Simple script to remove given tag from both local and origin locations. With a check if tag really exists.\n\nif [ $(git tag -l \"$1\") ]; then\n    git tag --delete  $1\n    git push --delete origin $1\n\n    echo done.\nelse\n    echo tag named \"$1\" was not found\nfi\n\n\nHow to use:\n\nCreate shell script file (e.g. git-tag-purge.sh) and paste content.\nchmod your script file to make it executable.\nMake the script globally available\ncd to your git project\nCall script (e.g.\n$>git-tag-purge.sh tag_name\n)\nShare\nImprove this answer\nFollow\nanswered Apr 25 '17 at 12:07\nDimitar Vlasev\n611\n1 silver badge\n3\n3 bronze badges","comments":[]},{"answer":"Seems like a lot of work for something xargs already does. Looking back through this thread, I'm guessing the slowness with xargs that you experienced is because the original answer used xargs -n 1 when it didn't really need to.\n\nThis is equivalent to your method one except that xargs automatically deals with the maximum command line length:\n\ngit tag | sorting_processing_etc | xargs git push --delete origin\n\n\nxargs can run processes in parallel too. Method 2 with xargs:\n\ngit tag | sorting_processing_etc | xargs -P 5 -n 100 git push --delete origin\n\n\nThe above uses a maximum of 5 processes to handle a maximum of 100 arguments in each process. You can experiment with the arguments to find what works best for your needs.\n\nShare\nImprove this answer\nFollow\nanswered Jun 5 '17 at 15:21\nHomerM\n411\n1 bronze badge","comments":["Interesting. You learn something new about a Unix command everyday. I'll need to test my use case with this alternative."]},{"answer":"If you have a tag created starting with the # character, e.g. #ST002, you might find that u are unable to delete using normal patterns. i.e.\n\ngit tag -d #STOO2\n\n\nWill not delete the tag, but wrapping it in a String Literal like so\n\ngit tag -d \"#ST002\" or git tag -d '#ST002'\n\n\nThat will get it deleted. Hoping it will help someone who made the mistake of using # to write tag names.\n\nShare\nImprove this answer\nFollow\nanswered Apr 12 '18 at 16:23\nMernXL\n1666\n6 bronze badges","comments":[]},{"answer":"For tortoise git users, at a scale of hundreds tags, you can delete multiple tags at once using UI, but the UI is well hidden under context menu.\n\nFrom explorer windows right click -> Browse references -> Right click on ref/refmotes/name -> choose 'Delete remote tags'\n\nSee https://tortoisegit.org/docs/tortoisegit/tgit-dug-browse-ref.html\n\nShare\nImprove this answer\nFollow\nanswered Feb 6 at 17:55\nWappenull\n6295\n5 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"git push --delete origin $TAGNAME is the correct approach (in addition of a local delete).\n\nBut: make sure to use Git 2.31.\n\n\"git push $there --delete\"(man) should have been diagnosed as an error, but instead turned into a matching push, which has been corrected with Git 2.31 (Q1 2021).\n\nSee commit 20e4164 (23 Feb 2021) by Junio C Hamano (gitster).\n(Merged by Junio C Hamano -- gitster -- in commit 1400458, 25 Feb 2021)\n\npush: do not turn --delete '' into a matching push\n\nNoticed-by: Tilman Vogel\n\nWhen we added a syntax sugar \"git push remote --delete\"(man) <ref> to \"git push\"(man) as a synonym to the canonical git push remote(man) : syntax at f517f1f (\"builtin-push: add(man) --delete as syntactic sugar for :foo\", 2009-12-30, Git v1.7.0-rc0 -- merge), we weren't careful enough to make sure that <ref> is not empty.\n\nBlindly rewriting \"--delete \" to \":\" means that an empty string <ref> results in refspec \":\", which is the syntax to ask for \"matching\" push that does not delete anything.\n\nWorse yet, if there were matching refs that can be fast-forwarded, they would have been published prematurely, even if the user feels that they are not ready yet to be pushed out, which would be a real disaster.\n\nShare\nImprove this answer\nFollow\nanswered Feb 28 at 1:58\nVonC\n1.1m448\n448 gold badges\n3731\n3731 silver badges\n4386\n4386 bronze badges","comments":[]},{"answer":"Here is a local testcase to test it locally without messing with a remote:\n\n~/p $ mkdir gittest    \n~/p/git $ cd gittest/\n~/p/gittest $ git init\nInitialized empty Git repository in /Users/local_user/p/gittest/.git/\n ~/p/gittest $ touch testfile.txt\n ~/p/gittest $ git add testfile.txt\n ~/p/gittest $ git commit -m \"initial commit\"\n[master (root-commit) 912ce0e] initial commit\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 testfile.txt\n ~/p/gittest $ git tag\n ~/p/gittest $ git tag -a testtag\n ~/p/gittest $ git tag\ntesttag\n ~/p/gittest $ git show-ref\n912ce0e40635c90241fdab756dce7ea34938de57 refs/heads/master\nb0a6c15cabb990e6d6c46f762891b63608d962f3 refs/tags/testtag\n ~/p/gittest $ cd ..\n ~/p $ mkdir gitbare\n ~/p $ cd gitbare\n ~/p/gitbare $ git init --bare\nInitialized empty Git repository in /Users/local_user/p/gitbare/\n ~/p/gitbare $ cd ..\n ~/p $ cd gittest/\n ~/p/gittest $ git remote add origin /Users/local_user/p/gitbare\n ~/p/gittest $ git push -u origin master\nCounting objects: 3, done.\nWriting objects: 100% (3/3), 215 bytes | 215.00 KiB/s, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nTo /Users/local_user/p/gitbare\n * [new branch]      master -> master\nBranch 'master' set up to track remote branch 'master' from 'origin'.\n ~/p/gittest $ git push origin testtag\nCounting objects: 1, done.\nWriting objects: 100% (1/1), 163 bytes | 163.00 KiB/s, done.\nTotal 1 (delta 0), reused 0 (delta 0)\nTo /Users/local_user/p/gitbare\n * [new tag]         testtag -> testtag\n ~/p/gittest $ git show-ref\n912ce0e40635c90241fdab756dce7ea34938de57 refs/heads/master\n912ce0e40635c90241fdab756dce7ea34938de57 refs/remotes/origin/master\nb0a6c15cabb990e6d6c46f762891b63608d962f3 refs/tags/testtag\n ~/p/gittest $ git push -d origin testtag\nTo /Users/local_user/p/gitbare\n - [deleted]         testtag\n ~/p/gittest    git tag -d testtag\nDeleted tag 'testtag' (was b0a6c15)\n ~/p/gittest $ git show-ref\n912ce0e40635c90241fdab756dce7ea34938de57 refs/heads/master\n912ce0e40635c90241fdab756dce7ea34938de57 refs/remotes/origin/master\n ~/p/gittest\n\nShare\nImprove this answer\nFollow\nanswered May 3 '18 at 18:36\nAdnan Y\n2,2841\n1 gold badge\n20\n20 silver badges\n26\n26 bronze badges","comments":[]},{"answer":"Just wanted to share an alias I created which does the same thing:\n\nAdd the following to your ~/.gitconfig\n\n[alias]\n    delete-tag = \"!f() { \\\n            echo 'deleting tag' $1 'from remote/origin ausing command: git push --delete origin tagName;'; \\\n            git push --delete origin $1; \\\n            echo 'deleting tag' $1 'from local using command: git tag -d tagName;'; \\\n            git tag -d $1; \\\n        }; f\"\n\n\nThe usage looks like:\n\n-->git delete-tag v1.0-DeleteMe\ndeleting tag v1.0-DeleteMe from remote/origin ausing command: git push --delete origin tagName;\nTo https://github.com/jsticha/pafs\n - [deleted]             v1.0-DeleteMe\ndeleting tag v1.0-DeleteMe from local using command: git tag -d tagName;\nDeleted tag 'v1.0-DeleteMe' (was 300d3ef22)\n\nShare\nImprove this answer\nFollow\nedited Jul 22 '20 at 11:29\nAhmed Ashour\n4,24310\n10 gold badges\n30\n30 silver badges\n46\n46 bronze badges\nanswered Apr 10 '19 at 18:34\nranma2913\n9748\n8 silver badges\n7\n7 bronze badges","comments":[]},{"answer":"To delete a tag on your remote repository, you can use\n\ngit push <remote> :refs/tags/<tagname>\n\n\nThe way to interpret the above is to read it as the null value, the value before the colon is being pushed to remote tag name.\n\nShare\nImprove this answer\nFollow\nanswered Dec 6 '20 at 9:11\nasafeca\n111\n1 bronze badge","comments":[]},{"answer":"This worked for me\n\ngit push --force origin refs/tags/<tag_name>:refs/tags/<tag_name>\n\nShare\nImprove this answer\nFollow\nanswered Aug 10 at 10:13\nkarthi190\n514\n4 bronze badges","comments":[]}]},{"id":"2334712","href":"https://stackoverflow.com/questions/2334712/how-do-i-update-from-a-select-in-sql-server","title":"How do I UPDATE from a SELECT in SQL Server?","description":"\n                \nIn SQL Server, it is possible to insert rows into a table with an INSERT.. SELECT statement:\nINSERT INTO Table (col1, col2, col3)\nSELECT col1, col2, col3 \nFROM other_table \nWHERE sql = 'cool'\n\nIs it also possible to update a table with SELECT? I have a temporary table containing the values and would like to update another table using those values. Perhaps something like this:\nUPDATE Table SET col1, col2\nSELECT col1, col2 \nFROM other_table \nWHERE sql = 'cool'\nWHERE Table.id = other_table.id\n\n    ","questionComments":["UPDATE Table_A SET Table_A.col1 = Table_B.col1, Table_A.col2 = Table_B.col2 FROM Some_Table AS Table_A INNER JOIN Other_Table AS Table_B ON Table_A.id = Table_B.id WHERE Table_A.col3 = 'cool'","UPDATE YourTable SET Col1 = OtherTable.Col1, Col2 = OtherTable.Col2 FROM ( SELECT ID, Col1, Col2 FROM other_table) AS OtherTable WHERE OtherTable.ID = YourTable.ID"],"answers":[{"answer":"UPDATE\n    Table_A\nSET\n    Table_A.col1 = Table_B.col1,\n    Table_A.col2 = Table_B.col2\nFROM\n    Some_Table AS Table_A\n    INNER JOIN Other_Table AS Table_B\n        ON Table_A.id = Table_B.id\nWHERE\n    Table_A.col3 = 'cool'\n\nShare\nImprove this answer\nFollow\nedited Apr 30 '16 at 1:26\nDai\n114k21\n21 gold badges\n190\n190 silver badges\n287\n287 bronze badges\nanswered Feb 25 '10 at 14:39\nRobin Day\n96.1k23\n23 gold badges\n113\n113 silver badges\n162\n162 bronze badges","comments":["If you are editing the the link between tables (SET Table.other_table_id = @NewValue) then change the ON statement to something like ON Table.id = @IdToEdit AND other_table.id = @NewValue","@CharlesWood yeah. I have the same question in MySQL. It would be great if someone knows how to implement it to MySQL and share with everyone. I'm sure lots of people are looking for a MySQL version solution","How do I use an alias in set? update table set a.col1 = b.col2 from table a inner join table2 b on a.id = b.id; Instead I have to use update table set table.col1 = b.col2 from table a inner join table2 b on a.id = b.id;","Somewhat related, I often like to write my UPDATE queries as SELECT statements first so that I can see the data that will be updated before I execute. Sebastian covers a technique for this in a recent blog post: sqlity.net/en/2867/update-from-select","You can't do SET Table_A.col1 = SUM(Table_B.col1) or any other aggregate. Jamal's answer allows you to put the aggregate in the SELECT stackoverflow.com/a/8963158/695671"]},{"answer":"In SQL Server 2008 (or newer), use MERGE\n\nMERGE INTO YourTable T\n   USING other_table S \n      ON T.id = S.id\n         AND S.tsql = 'cool'\nWHEN MATCHED THEN\n   UPDATE \n      SET col1 = S.col1, \n          col2 = S.col2;\n\n\nAlternatively:\n\nMERGE INTO YourTable T\n   USING (\n          SELECT id, col1, col2 \n            FROM other_table \n           WHERE tsql = 'cool'\n         ) S\n      ON T.id = S.id\nWHEN MATCHED THEN\n   UPDATE \n      SET col1 = S.col1, \n          col2 = S.col2;\n\nShare\nImprove this answer\nFollow\nedited May 12 at 17:57\nspeyck\n4002\n2 silver badges\n13\n13 bronze badges\nanswered Sep 9 '11 at 9:40\nonedaywhen\n51.3k12\n12 gold badges\n91\n91 silver badges\n132\n132 bronze badges","comments":["MERGE can also be used for \"Upserting\" records; that is, UPDATE if matching record exists, INSERT new record if no match found","This was around 10x quicker than the equivalent update...join statement for me.","MERGE can also be used to DELETE. But be careful with MERGE as the TARGET table cannot be a remote table.","Merge bugs: mssqltips.com/sqlservertip/3074/…","@SimonD: pick any SQL Server keyword and you will find bugs. Your point? I wager there are more bugs (and more fundamental ones too) associated with UPDATE than MERGE, folks have just learned to live with them and they become part of the landscape ('features'). Consider that blogs didn't exist when UPDATE was the new kid on the block."]},{"answer":"UPDATE YourTable \nSET Col1 = OtherTable.Col1, \n    Col2 = OtherTable.Col2 \nFROM (\n    SELECT ID, Col1, Col2 \n    FROM other_table) AS OtherTable\nWHERE \n    OtherTable.ID = YourTable.ID\n\nShare\nImprove this answer\nFollow\nedited Jan 1 '20 at 20:30\nDDiamond\n1,6262\n2 gold badges\n4\n4 silver badges\n16\n16 bronze badges\nanswered Jan 22 '12 at 17:47\nJamal\n7,5371\n1 gold badge\n11\n11 silver badges\n2\n2 bronze badges","comments":["By far the simplest! However your missing the ID field from the inner SELECT. You'll need this for the WHERE clause to work","This will tend to work across almost all DBMS which means learn once, execute everywhere. If that is more important to you than performance you might prefer this answer, especially if your update is a one off to correct some data.","If you need to set the first table with aggregates from the second, you can put the aggregates in the select subquery, as you cannot do SET Table_A.col1 = SUM(Table_B.col1) (or any other aggregate function). So better than Robin Day's answer for this purpose.","I really like this solution as it feels like a natural compliment to the way INSERT ... SELECT works. Thanks for sharing!"]},{"answer":"I'd modify Robin's excellent answer to the following:\n\nUPDATE Table\nSET Table.col1 = other_table.col1,\n Table.col2 = other_table.col2\nFROM\n    Table\nINNER JOIN other_table ON Table.id = other_table.id\nWHERE\n    Table.col1 != other_table.col1\nOR Table.col2 != other_table.col2\nOR (\n    other_table.col1 IS NOT NULL\n    AND Table.col1 IS NULL\n)\nOR (\n    other_table.col2 IS NOT NULL\n    AND Table.col2 IS NULL\n)\n\n\nWithout a WHERE clause, you'll affect even rows that don't need to be affected, which could (possibly) cause index recalculation or fire triggers that really shouldn't have been fired.\n\nShare\nImprove this answer\nFollow\nedited May 19 '18 at 17:18\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 8 '11 at 21:20\nquillbreaker\n5,9213\n3 gold badges\n26\n26 silver badges\n46\n46 bronze badges","comments":["This assumes none of the columns are nullable though.","You're right, I was typing the example by hand. I've added a third and fourth clause to the where statement to deal with that.","WHERE EXISTS(SELECT T1.Col1, T1.Col2 EXCEPT SELECT T2.Col1, T2.Col2)) is more concise.","shouldn't the statement also contain these two in the where clause? (other_table.col1 is null and table.col1 is not null) or (other_table.col2 is null and table.col2 is not null)","Depends on if you want to replace nulls in the destination with nulls from the source. Frequently, I don't. But if you do, Martin's construction of the where clause is the best thing to use."]},{"answer":"One way\n\nUPDATE t \nSET t.col1 = o.col1, \n    t.col2 = o.col2\nFROM \n    other_table o \n  JOIN \n    t ON t.id = o.id\nWHERE \n    o.sql = 'cool'\n\nShare\nImprove this answer\nFollow\nedited May 20 '15 at 10:12\nshA.t\n15.4k5\n5 gold badges\n47\n47 silver badges\n96\n96 bronze badges\nanswered Feb 25 '10 at 14:41\nSQLMenace\n126k23\n23 gold badges\n198\n198 silver badges\n221\n221 bronze badges","comments":[]},{"answer":"Another possibility not mentioned yet is to just chuck the SELECT statement itself into a CTE and then update the CTE.\n\n;WITH CTE\n     AS (SELECT T1.Col1,\n                T2.Col1 AS _Col1,\n                T1.Col2,\n                T2.Col2 AS _Col2\n         FROM   T1\n                JOIN T2\n                  ON T1.id = T2.id\n         /*Where clause added to exclude rows that are the same in both tables\n           Handles NULL values correctly*/\n         WHERE EXISTS(SELECT T1.Col1,\n                             T1.Col2\n                       EXCEPT\n                       SELECT T2.Col1,\n                              T2.Col2))\nUPDATE CTE\nSET    Col1 = _Col1,\n       Col2 = _Col2\n\n\nThis has the benefit that it is easy to run the SELECT statement on its own first to sanity check the results, but it does requires you to alias the columns as above if they are named the same in source and target tables.\n\nThis also has the same limitation as the proprietary UPDATE ... FROM syntax shown in four of the other answers. If the source table is on the many side of a one-to-many join then it is undeterministic which of the possible matching joined records will be used in the Update (an issue that MERGE avoids by raising an error if there is an attempt to update the same row more than once).\n\nShare\nImprove this answer\nFollow\nedited May 19 '18 at 17:21\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Nov 6 '11 at 0:18\nMartin Smith\n406k80\n80 gold badges\n688\n688 silver badges\n780\n780 bronze badges","comments":["is there any meaning of the name CTE ?","@ShivanRaptor - It is the acronym for Common Table Expression. Just an arbitrary alias in this case.","This also works well with multiple CTEs: ;WITH SomeCompexCTE AS (...), CTEAsAbove AS (SELECT T1.Col1,... FROM T1 JOIN SomeComplexCTE...) UPDATE CTEAsAbove SET Col1=_Col1, ..."]},{"answer":"For the record (and others searching like I was), you can do it in MySQL like this:\n\nUPDATE first_table, second_table\nSET first_table.color = second_table.color\nWHERE first_table.id = second_table.foreign_id\n\nShare\nImprove this answer\nFollow\nanswered Oct 5 '12 at 14:20\nAdrian Macneil\n12.3k4\n4 gold badges\n49\n49 silver badges\n68\n68 bronze badges","comments":[]},{"answer":"Using alias:\n\nUPDATE t\n   SET t.col1 = o.col1\n  FROM table1 AS t\n         INNER JOIN \n       table2 AS o \n         ON t.id = o.id\n\nShare\nImprove this answer\nFollow\nedited Mar 12 '18 at 16:10\nanswered May 23 '12 at 13:06\nrageit\n3,3501\n1 gold badge\n24\n24 silver badges\n37\n37 bronze badges","comments":[]},{"answer":"The simple way to do it is:\n\nUPDATE\n    table_to_update,\n    table_info\nSET\n    table_to_update.col1 = table_info.col1,\n    table_to_update.col2 = table_info.col2\n\nWHERE\n    table_to_update.ID = table_info.ID\n\nShare\nImprove this answer\nFollow\nedited Jul 25 '16 at 19:39\nShiva\n18.7k13\n13 gold badges\n76\n76 silver badges\n104\n104 bronze badges\nanswered Nov 14 '12 at 13:17\nPatrick Frenette\n8596\n6 silver badges\n2\n2 bronze badges","comments":["This is not SQl Server syntax and it will not work in SQL server"]},{"answer":"This may be a niche reason to perform an update (for example, mainly used in a procedure), or may be obvious to others, but it should also be stated that you can perform an update-select statement without using join (in case the tables you're updating between have no common field).\n\nupdate\n    Table\nset\n    Table.example = a.value\nfrom\n    TableExample a\nwhere\n    Table.field = *key value* -- finds the row in Table \n    AND a.field = *key value* -- finds the row in TableExample a\n\nShare\nImprove this answer\nFollow\nanswered Jun 11 '12 at 16:58\nRyan\n2,8576\n6 gold badges\n33\n33 silver badges\n45\n45 bronze badges","comments":[]},{"answer":"Here is another useful syntax:\n\nUPDATE suppliers\nSET supplier_name = (SELECT customers.name\n                     FROM customers\n                     WHERE customers.customer_id = suppliers.supplier_id)\nWHERE EXISTS (SELECT customers.name\n              FROM customers\n              WHERE customers.customer_id = suppliers.supplier_id);\n\n\nIt checks if it is null or not by using \"WHERE EXIST\".\n\nShare\nImprove this answer\nFollow\nedited Apr 14 '14 at 19:44\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered May 2 '13 at 9:48\nefirat\n3,1232\n2 gold badges\n35\n35 silver badges\n38\n38 bronze badges","comments":[]},{"answer":"I add this only so you can see a quick way to write it so that you can check what will be updated before doing the update.\n\nUPDATE Table \nSET  Table.col1 = other_table.col1,\n     Table.col2 = other_table.col2 \n--select Table.col1, other_table.col,Table.col2,other_table.col2, *   \nFROM     Table \nINNER JOIN     other_table \n    ON     Table.id = other_table.id \n\nShare\nImprove this answer\nFollow\nanswered Sep 8 '11 at 21:35\nHLGEM\n89.7k11\n11 gold badges\n107\n107 silver badges\n173\n173 bronze badges","comments":[]},{"answer":"If you use MySQL instead of SQL Server, the syntax is:\n\nUPDATE Table1\nINNER JOIN Table2\nON Table1.id = Table2.id\nSET Table1.col1 = Table2.col1,\n    Table1.col2 = Table2.col2\n\nShare\nImprove this answer\nFollow\nedited Aug 11 '16 at 8:16\nSimon Hughes\n3,4353\n3 gold badges\n22\n22 silver badges\n44\n44 bronze badges\nanswered Oct 3 '13 at 13:16\nHentold\n8377\n7 silver badges\n11\n11 bronze badges","comments":["What if we want to update Table2.col1? how will we do that. table two is extracted on the base of the query condition."]},{"answer":"UPDATE from SELECT with INNER JOIN in SQL Database\n\nSince there are too many replies of this post, which are most heavily up-voted, I thought I would provide my suggestion here too. Although the question is very interesting, I have seen in many forum sites and made a solution using INNER JOIN with screenshots.\n\nAt first, I have created a table named with schoolold and inserted few records with respect to their column names and execute it.\n\nThen I executed SELECT command to view inserted records.\n\nThen I created a new table named with schoolnew and similarly executed above actions on it.\n\nThen, to view inserted records in it, I execute SELECT command.\n\nNow, Here I want to make some changes in third and fourth row, to complete this action, I execute UPDATE command with INNER JOIN.\n\nTo view the changes I execute the SELECT command.\n\nYou can see how Third and Fourth records of table schoolold easily replaced with table schoolnew by using INNER JOIN with UPDATE statement.\n\nShare\nImprove this answer\nFollow\nedited Nov 24 '18 at 7:56\nBSMP\n3,9848\n8 gold badges\n31\n31 silver badges\n41\n41 bronze badges\nanswered Nov 30 '15 at 5:48\nJason Clark\n9096\n6 gold badges\n17\n17 silver badges\n44\n44 bronze badges","comments":[]},{"answer":"And if you wanted to join the table with itself (which won't happen too often):\n\nupdate t1                    -- just reference table alias here\nset t1.somevalue = t2.somevalue\nfrom table1 t1               -- these rows will be the targets\ninner join table1 t2         -- these rows will be used as source\non ..................        -- the join clause is whatever suits you\n\nShare\nImprove this answer\nFollow\nedited May 19 '18 at 19:28\nanswered Jun 27 '14 at 21:14\njakubiszon\n2,1261\n1 gold badge\n21\n21 silver badges\n35\n35 bronze badges","comments":["+1 but you should have used relevant alias names like targett1 and sourcet1 rather than (or as well as) comments."]},{"answer":"Updating through CTE is more readable than the other answers here:\n\n;WITH cte\n     AS (SELECT col1,col2,id\n         FROM   other_table\n         WHERE  sql = 'cool')\nUPDATE A\nSET    A.col1 = B.col1,\n       A.col2 = B.col2\nFROM   table A\n       INNER JOIN cte B\n               ON A.id = B.id\n\nShare\nImprove this answer\nFollow\nedited May 19 '18 at 17:31\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 12 '15 at 16:32\nPரதீப்\n86.4k16\n16 gold badges\n112\n112 silver badges\n149\n149 bronze badges","comments":[]},{"answer":"The following example uses a derived table, a SELECT statement after the FROM clause, to return the old and new values for further updates:\n\nUPDATE x\nSET    x.col1 = x.newCol1,\n       x.col2 = x.newCol2\nFROM   (SELECT t.col1,\n               t2.col1 AS newCol1,\n               t.col2,\n               t2.col2 AS newCol2\n        FROM   [table] t\n               JOIN other_table t2\n                 ON t.ID = t2.ID) x\n\nShare\nImprove this answer\nFollow\nedited Jun 25 '16 at 21:28\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 25 '13 at 6:18\nAleksandr Fedorenko\n15.4k6\n6 gold badges\n35\n35 silver badges\n42\n42 bronze badges","comments":[]},{"answer":"If you are using SQL Server you can update one table from another without specifying a join and simply link the two from the where clause. This makes a much simpler SQL query:\n\nUPDATE Table1\nSET Table1.col1 = Table2.col1,\n    Table1.col2 = Table2.col2\nFROM\n    Table2\nWHERE\n    Table1.id = Table2.id\n\nShare\nImprove this answer\nFollow\nedited May 19 '18 at 17:37\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 20 '17 at 16:34\nRichard\n1,10410\n10 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"Consolidating all the different approaches here.\n\nSelect update\nUpdate with a common table expression\nMerge\n\nSample table structure is below and will update from Product_BAK to Product table.\n\nProduct\nCREATE TABLE [dbo].[Product](\n    [Id] [int] IDENTITY(1, 1) NOT NULL,\n    [Name] [nvarchar](100) NOT NULL,\n    [Description] [nvarchar](100) NULL\n) ON [PRIMARY]\n\nProduct_BAK\n    CREATE TABLE [dbo].[Product_BAK](\n        [Id] [int] IDENTITY(1, 1) NOT NULL,\n        [Name] [nvarchar](100) NOT NULL,\n        [Description] [nvarchar](100) NULL\n    ) ON [PRIMARY]\n\n1. Select update\n    update P1\n    set Name = P2.Name\n    from Product P1\n    inner join Product_Bak P2 on p1.id = P2.id\n    where p1.id = 2\n\n2. Update with a common table expression\n    ; With CTE as\n    (\n        select id, name from Product_Bak where id = 2\n    )\n    update P\n    set Name = P2.name\n    from  product P  inner join CTE P2 on P.id = P2.id\n    where P2.id = 2\n\n3. Merge\n    Merge into product P1\n    using Product_Bak P2 on P1.id = P2.id\n\n    when matched then\n    update set p1.[description] = p2.[description], p1.name = P2.Name;\n\n\nIn this Merge statement, we can do inset if not finding a matching record in the target, but exist in the source and please find syntax:\n\n    Merge into product P1\n    using Product_Bak P2 on P1.id = P2.id;\n\n    when matched then\n    update set p1.[description] = p2.[description], p1.name = P2.Name;\n\n    WHEN NOT MATCHED THEN\n    insert (name, description)\n    values(p2.name, P2.description);\n\nShare\nImprove this answer\nFollow\nedited Mar 29 '19 at 14:07\nanswered Jan 31 '18 at 15:42\nAbdul Azeez\n6298\n8 silver badges\n17\n17 bronze badges","comments":[]},{"answer":"The other way is to use a derived table:\n\nUPDATE t\nSET t.col1 = a.col1\n    ,t.col2 = a.col2\nFROM (\nSELECT id, col1, col2 FROM @tbl2) a\nINNER JOIN @tbl1 t ON t.id = a.id\n\n\nSample data\n\nDECLARE @tbl1 TABLE (id INT, col1 VARCHAR(10), col2 VARCHAR(10))\nDECLARE @tbl2 TABLE (id INT, col1 VARCHAR(10), col2 VARCHAR(10))\n\nINSERT @tbl1 SELECT 1, 'a', 'b' UNION SELECT 2, 'b', 'c'\n\nINSERT @tbl2 SELECT 1, '1', '2' UNION SELECT 2, '3', '4'\n\nUPDATE t\nSET t.col1 = a.col1\n    ,t.col2 = a.col2\nFROM (\nSELECT id, col1, col2 FROM @tbl2) a\nINNER JOIN @tbl1 t ON t.id = a.id\n\nSELECT * FROM @tbl1\nSELECT * FROM @tbl2\n\nShare\nImprove this answer\nFollow\nedited Jun 25 '16 at 20:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 24 '16 at 23:35\nsqluser\n5,1887\n7 gold badges\n32\n32 silver badges\n49\n49 bronze badges","comments":[]},{"answer":"UPDATE TQ\nSET TQ.IsProcessed = 1, TQ.TextName = 'bla bla bla'\nFROM TableQueue TQ\nINNER JOIN TableComment TC ON TC.ID = TQ.TCID\nWHERE TQ.IsProcessed = 0\n\n\nTo make sure you are updating what you want, select first\n\nSELECT TQ.IsProcessed, 1 AS NewValue1, TQ.TextName, 'bla bla bla' AS NewValue2\nFROM TableQueue TQ\nINNER JOIN TableComment TC ON TC.ID = TQ.TCID\nWHERE TQ.IsProcessed = 0\n\nShare\nImprove this answer\nFollow\nanswered Nov 30 '16 at 21:06\nYaman\n97316\n16 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"There is even a shorter method and it might be surprising for you:\n\nSample data set:\n\nCREATE TABLE #SOURCE ([ID] INT, [Desc] VARCHAR(10));\nCREATE TABLE #DEST   ([ID] INT, [Desc] VARCHAR(10));\n\nINSERT INTO #SOURCE VALUES(1,'Desc_1'), (2, 'Desc_2'), (3, 'Desc_3');\nINSERT INTO #DEST   VALUES(1,'Desc_4'), (2, 'Desc_5'), (3, 'Desc_6');\n\n\nCode:\n\nUPDATE #DEST\nSET #DEST.[Desc] = #SOURCE.[Desc]\nFROM #SOURCE\nWHERE #DEST.[ID] = #SOURCE.[ID];\n\nShare\nImprove this answer\nFollow\nedited Oct 18 '18 at 14:24\nanswered Jan 26 '17 at 13:28\nBartosz X\n2,18223\n23 silver badges\n30\n30 bronze badges","comments":["YES - there is no JOIN on purpose and NO - this can't be applied on table variables.","I think if you use [_id] on your #SOURCE not [ID] the same as #DESTINATION's, they might let you do JOIN. \"on #DESTINATION.ID=#SOURCE._id. Or even use table variable like @tbl, \"on PermTable.ID=@memorytbl._id\". Have you tried? I am using a phone to reply this, no computer to try.","What does this have to do with updating from a SELECT?","This is the same idea but another method - you don't have to put \"select\" at all to achieve JOIN and WHERE in update statement - which is SELECT type of query without even writing SELECT"]},{"answer":"Use:\n\ndrop table uno\ndrop table dos\n\ncreate table uno\n(\n    uid int,\n    col1 char(1),\n    col2 char(2)\n)\ncreate table dos\n(\n    did int,\n    col1 char(1),\n    col2 char(2),\n    [sql] char(4)\n)\ninsert into uno(uid) values (1)\ninsert into uno(uid) values (2)\ninsert into dos values (1,'a','b',null)\ninsert into dos values (2,'c','d','cool')\n\nselect * from uno \nselect * from dos\n\n\nEITHER:\n\nupdate uno set col1 = (select col1 from dos where uid = did and [sql]='cool'), \ncol2 = (select col2 from dos where uid = did and [sql]='cool')\n\n\nOR:\n\nupdate uno set col1=d.col1,col2=d.col2 from uno \ninner join dos d on uid=did where [sql]='cool'\n\nselect * from uno \nselect * from dos\n\n\nIf the ID column name is the same in both tables then just put the table name before the table to be updated and use an alias for the selected table, i.e.:\n\nupdate uno set col1 = (select col1 from dos d where uno.[id] = d.[id] and [sql]='cool'),\ncol2  = (select col2 from dos d where uno.[id] = d.[id] and [sql]='cool')\n\nShare\nImprove this answer\nFollow\nedited May 19 '18 at 17:24\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jun 18 '14 at 11:40\nruss\n5513\n3 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"In the accepted answer, after the:\n\nSET\nTable_A.col1 = Table_B.col1,\nTable_A.col2 = Table_B.col2\n\n\nI would add:\n\nOUTPUT deleted.*, inserted.*\n\n\nWhat I usually do is putting everything in a roll backed transaction and using the \"OUTPUT\": in this way I see everything that is about to happen. When I am happy with what I see, I change the ROLLBACK into COMMIT.\n\nI usually need to document what I did, so I use the \"results to Text\" option when I run the roll-backed query and I save both the script and the result of the OUTPUT. (Of course this is not practical if I changed too many rows)\n\nShare\nImprove this answer\nFollow\nedited Apr 28 '18 at 12:33\nuser9713753\nanswered Apr 27 '17 at 7:54\nJohannes Wentu\n8211\n1 gold badge\n12\n12 silver badges\n27\n27 bronze badges","comments":[]},{"answer":"UPDATE table AS a\nINNER JOIN table2 AS b\nON a.col1 = b.col1\nINNER JOIN ... AS ...\nON ... = ...\nSET ...\nWHERE ...\n\nShare\nImprove this answer\nFollow\nanswered Jul 31 '15 at 8:04\nCornezuelo del Centeno\n4947\n7 silver badges\n19\n19 bronze badges","comments":[]},{"answer":"The below solution works for a MySQL database:\n\nUPDATE table1 a , table2 b \nSET a.columname = 'some value' \nWHERE b.columnname IS NULL ;\n\nShare\nImprove this answer\nFollow\nedited May 19 '18 at 17:26\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 1 '14 at 6:24\nMateen\n1,3841\n1 gold badge\n16\n16 silver badges\n24\n24 bronze badges","comments":[]},{"answer":"The other way to update from a select statement:\n\nUPDATE A\nSET A.col = A.col,B.col1 = B.col1\nFROM  first_Table AS A\nINNER JOIN second_Table AS B  ON A.id = B.id WHERE A.col2 = 'cool'\n\nShare\nImprove this answer\nFollow\nedited May 19 '18 at 17:32\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 8 '16 at 12:02\nGovind Tupkar\n2662\n2 silver badges\n5\n5 bronze badges","comments":["This answer turned up in the low quality review queue, presumably because you don't provide any explanation of the code. If this code answers the question, consider adding adding some text explaining the code in your answer. This way, you are far more likely to get more upvotes — and help the questioner learn something new."]},{"answer":"Option 1: Using Inner Join:\n\nUPDATE\n    A\nSET\n    A.col1 = B.col1,\n    A.col2 = B.col2\nFROM\n    Some_Table AS A\n    INNER JOIN Other_Table AS B\n        ON A.id = B.id\nWHERE\n    A.col3 = 'cool'\n\n\nOption 2: Co related Sub query\n\nUPDATE table \nSET Col1 = B.Col1, \n    Col2 = B.Col2 \nFROM (\n    SELECT ID, Col1, Col2 \n    FROM other_table) B\nWHERE \n    B.ID = table.ID\n\nShare\nImprove this answer\nFollow\nedited Dec 7 '18 at 9:17\nJesse\n3,1836\n6 gold badges\n24\n24 silver badges\n36\n36 bronze badges\nanswered Nov 7 '18 at 7:34\nSanthana\n4114\n4 silver badges\n15\n15 bronze badges","comments":["Did it work for you? I used exact same query but had errors when used inner join, alias coun't be resolved. However the co-related sub query worked perfectly.","I don't have the exact error logs but the alias A was being referenced before the assignment, which caused the error.","I used the correlated sub query"]},{"answer":"UPDATE table1\nSET column1 = (SELECT expression1\n               FROM table2\n               WHERE conditions)\n[WHERE conditions];\n\n\nThe syntax for the UPDATE statement when updating one table with data from another table in SQL Server\n\nShare\nImprove this answer\nFollow\nanswered Mar 14 '19 at 7:00\nRokonz Zaz\n1191\n1 silver badge\n5\n5 bronze badges","comments":[]},{"answer":"Important to point out, as others have, MySQL or MariaDB use a different syntax. Also it supports a very convenient USING syntax (in contrast to T/SQL). Also INNER JOIN is synonymous with JOIN. Therefor the query in the original question would be best implemented in MySQL thusly:\n\nUPDATE\n    Some_Table AS Table_A\n\nJOIN\n    Other_Table AS Table_B USING(id)\n\nSET\n    Table_A.col1 = Table_B.col1,\n    Table_A.col2 = Table_B.col2\n\nWHERE\n    Table_A.col3 = 'cool'\n\n\nI've not seen the a solution to the asked question in the other answers, hence my two cents. (tested on PHP 7.4.0 MariaDB 10.4.10)\n\nShare\nImprove this answer\nFollow\nedited Feb 6 at 15:25\nanswered Jun 10 '20 at 11:43\ntheking2\n1,1231\n1 gold badge\n14\n14 silver badges\n24\n24 bronze badges","comments":[]}]},{"id":"509211","href":"https://stackoverflow.com/questions/509211/understanding-slice-notation","title":"Understanding slice notation","description":"\n                \nI need a good explanation (references are a plus) on Python's slice notation. \n\nTo me, this notation needs a bit of picking up. \n\nIt looks extremely powerful, but I haven't quite got my head around it.\n    ","questionComments":[],"answers":[{"answer":"It's pretty simple really:\n\na[start:stop]  # items start through stop-1\na[start:]      # items start through the rest of the array\na[:stop]       # items from the beginning through stop-1\na[:]           # a copy of the whole array\n\n\nThere is also the step value, which can be used with any of the above:\n\na[start:stop:step] # start through not past stop, by step\n\n\nThe key point to remember is that the :stop value represents the first value that is not in the selected slice. So, the difference between stop and start is the number of elements selected (if step is 1, the default).\n\nThe other feature is that start or stop may be a negative number, which means it counts from the end of the array instead of the beginning. So:\n\na[-1]    # last item in the array\na[-2:]   # last two items in the array\na[:-2]   # everything except the last two items\n\n\nSimilarly, step may be a negative number:\n\na[::-1]    # all items in the array, reversed\na[1::-1]   # the first two items, reversed\na[:-3:-1]  # the last two items, reversed\na[-3::-1]  # everything except the last two items, reversed\n\n\nPython is kind to the programmer if there are fewer items than you ask for. For example, if you ask for a[:-2] and a only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.\n\nRelation to slice() object\n\nThe slicing operator [] is actually being used in the above code with a slice() object using the : notation (which is only valid within []), i.e.:\n\na[start:stop:step]\n\n\nis equivalent to:\n\na[slice(start, stop, step)]\n\n\nSlice objects also behave slightly differently depending on the number of arguments, similarly to range(), i.e. both slice(stop) and slice(start, stop[, step]) are supported. To skip specifying a given argument, one might use None, so that e.g. a[start:] is equivalent to a[slice(start, None)] or a[::-1] is equivalent to a[slice(None, None, -1)].\n\nWhile the :-based notation is very helpful for simple slicing, the explicit use of slice() objects simplifies the programmatic generation of slicing.\n\nShare\nImprove this answer\nFollow\nedited Feb 24 '20 at 19:27\nanswered Feb 3 '09 at 22:48\nGreg Hewgill\n843k170\n170 gold badges\n1107\n1107 silver badges\n1243\n1243 bronze badges","comments":["Slicing builtin types returns a copy but that's not universal. Notably, slicing NumPy arrays returns a view that shares memory with the original.","This is a beautiful answer with the votes to prove it, but it misses one thing: you can substitute None for any of the empty spaces. For example [None:None] makes a whole copy. This is useful when you need to specify the end of the range using a variable and need to include the last item.","Note that contrary to usual Python slices (see above), in Pandas Dataframes both the start and the stop are included when present in the index. For further info see the Pandas indexing documentation.","What really annoys me is that python says that when you don't set the start and the end, they default to 0 and the length of sequence. So, in theory, when you use \"abcdef\"[::-1] it should be transformed to \"abcdef\"[0:6:-1], but these two expressions does not get the same output. I feel that something is missing in python documentation since the creation of the language.","And I know that \"abcdef\"[::-1] is transformed to \"abcdef\"[6:-7:-1], so, the best way to explain would be: let len be the length of the sequence. If step is positive, the defaults for start and end are 0 and len. Else if step is negative, the defaults for start and end are len and -len - 1."]},{"answer":"The Python tutorial talks about it (scroll down a bit until you get to the part about slicing).\n\nThe ASCII art diagram is helpful too for remembering how slices work:\n\n +---+---+---+---+---+---+\n | P | y | t | h | o | n |\n +---+---+---+---+---+---+\n 0   1   2   3   4   5   6\n-6  -5  -4  -3  -2  -1\n\n\nOne way to remember how slices work is to think of the indices as pointing between characters, with the left edge of the first character numbered 0. Then the right edge of the last character of a string of n characters has index n.\n\nShare\nImprove this answer\nFollow\nedited Sep 18 '17 at 11:02\nkenorb\n122k66\n66 gold badges\n599\n599 silver badges\n634\n634 bronze badges\nanswered Feb 3 '09 at 22:49\nHans Nowak\n6,6731\n1 gold badge\n17\n17 silver badges\n16\n16 bronze badges","comments":["This suggestion works for positive stride, but does not for a negative stride. From the diagram, I expect a[-4,-6,-1] to be yP but it is ty. What always work is to think in characters or slots and use indexing as a half-open interval -- right-open if positive stride, left-open if negative stride.","But there's no way to collapse to an empty set starting from the end (like x[:0] does when starting from the beginning), so you have to special-case small arrays. :/","@aguadopd You are absolutely right. The solution is to have the indices shifted to the right, centered just below the characters, and notice that the stop is always excluded. See another response just below.","Addendum to my comment: see my answer with diagrams below: stackoverflow.com/a/56332104/2343869"]},{"answer":"Enumerating the possibilities allowed by the grammar:\n\n>>> seq[:]                # [seq[0],   seq[1],          ..., seq[-1]    ]\n>>> seq[low:]             # [seq[low], seq[low+1],      ..., seq[-1]    ]\n>>> seq[:high]            # [seq[0],   seq[1],          ..., seq[high-1]]\n>>> seq[low:high]         # [seq[low], seq[low+1],      ..., seq[high-1]]\n>>> seq[::stride]         # [seq[0],   seq[stride],     ..., seq[-1]    ]\n>>> seq[low::stride]      # [seq[low], seq[low+stride], ..., seq[-1]    ]\n>>> seq[:high:stride]     # [seq[0],   seq[stride],     ..., seq[high-1]]\n>>> seq[low:high:stride]  # [seq[low], seq[low+stride], ..., seq[high-1]]\n\n\nOf course, if (high-low)%stride != 0, then the end point will be a little lower than high-1.\n\nIf stride is negative, the ordering is changed a bit since we're counting down:\n\n>>> seq[::-stride]        # [seq[-1],   seq[-1-stride],   ..., seq[0]    ]\n>>> seq[high::-stride]    # [seq[high], seq[high-stride], ..., seq[0]    ]\n>>> seq[:low:-stride]     # [seq[-1],   seq[-1-stride],   ..., seq[low+1]]\n>>> seq[high:low:-stride] # [seq[high], seq[high-stride], ..., seq[low+1]]\n\n\nExtended slicing (with commas and ellipses) are mostly used only by special data structures (like NumPy); the basic sequences don't support them.\n\n>>> class slicee:\n...     def __getitem__(self, item):\n...         return repr(item)\n...\n>>> slicee()[0, 1:2, ::5, ...]\n'(0, slice(1, 2, None), slice(None, None, 5), Ellipsis)'\n\nShare\nImprove this answer\nFollow\nedited May 7 '19 at 12:16\nGeorgy\n6,8417\n7 gold badges\n49\n49 silver badges\n59\n59 bronze badges\nanswered Feb 3 '09 at 23:08\nephemient\n183k34\n34 gold badges\n260\n260 silver badges\n381\n381 bronze badges","comments":["Actually there is still something left out e.g. if I type 'apple'[4:-4:-1] I get 'elp', python is translating the -4 to a 1 maybe?","note that backticks are deprecated in favour of repr","@liyuan The type implementing __getitem__ is; your example is equivalent to apple[slice(4, -4, -1)]."]},{"answer":"The answers above don't discuss slice assignment. To understand slice assignment, it's helpful to add another concept to the ASCII art:\n\n                +---+---+---+---+---+---+\n                | P | y | t | h | o | n |\n                +---+---+---+---+---+---+\nSlice position: 0   1   2   3   4   5   6\nIndex position:   0   1   2   3   4   5\n\n>>> p = ['P','y','t','h','o','n']\n# Why the two sets of numbers:\n# indexing gives items, not lists\n>>> p[0]\n 'P'\n>>> p[5]\n 'n'\n\n# Slicing gives lists\n>>> p[0:1]\n ['P']\n>>> p[0:2]\n ['P','y']\n\n\nOne heuristic is, for a slice from zero to n, think: \"zero is the beginning, start at the beginning and take n items in a list\".\n\n>>> p[5] # the last of six items, indexed from zero\n 'n'\n>>> p[0:5] # does NOT include the last item!\n ['P','y','t','h','o']\n>>> p[0:6] # not p[0:5]!!!\n ['P','y','t','h','o','n']\n\n\nAnother heuristic is, \"for any slice, replace the start by zero, apply the previous heuristic to get the end of the list, then count the first number back up to chop items off the beginning\"\n\n>>> p[0:4] # Start at the beginning and count out 4 items\n ['P','y','t','h']\n>>> p[1:4] # Take one item off the front\n ['y','t','h']\n>>> p[2:4] # Take two items off the front\n ['t','h']\n# etc.\n\n\nThe first rule of slice assignment is that since slicing returns a list, slice assignment requires a list (or other iterable):\n\n>>> p[2:3]\n ['t']\n>>> p[2:3] = ['T']\n>>> p\n ['P','y','T','h','o','n']\n>>> p[2:3] = 't'\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: can only assign an iterable\n\n\nThe second rule of slice assignment, which you can also see above, is that whatever portion of the list is returned by slice indexing, that's the same portion that is changed by slice assignment:\n\n>>> p[2:4]\n ['T','h']\n>>> p[2:4] = ['t','r']\n>>> p\n ['P','y','t','r','o','n']\n\n\nThe third rule of slice assignment is, the assigned list (iterable) doesn't have to have the same length; the indexed slice is simply sliced out and replaced en masse by whatever is being assigned:\n\n>>> p = ['P','y','t','h','o','n'] # Start over\n>>> p[2:4] = ['s','p','a','m']\n>>> p\n ['P','y','s','p','a','m','o','n']\n\n\nThe trickiest part to get used to is assignment to empty slices. Using heuristic 1 and 2 it's easy to get your head around indexing an empty slice:\n\n>>> p = ['P','y','t','h','o','n']\n>>> p[0:4]\n ['P','y','t','h']\n>>> p[1:4]\n ['y','t','h']\n>>> p[2:4]\n ['t','h']\n>>> p[3:4]\n ['h']\n>>> p[4:4]\n []\n\n\nAnd then once you've seen that, slice assignment to the empty slice makes sense too:\n\n>>> p = ['P','y','t','h','o','n']\n>>> p[2:4] = ['x','y'] # Assigned list is same length as slice\n>>> p\n ['P','y','x','y','o','n'] # Result is same length\n>>> p = ['P','y','t','h','o','n']\n>>> p[3:4] = ['x','y'] # Assigned list is longer than slice\n>>> p\n ['P','y','t','x','y','o','n'] # The result is longer\n>>> p = ['P','y','t','h','o','n']\n>>> p[4:4] = ['x','y']\n>>> p\n ['P','y','t','h','x','y','o','n'] # The result is longer still\n\n\nNote that, since we are not changing the second number of the slice (4), the inserted items always stack right up against the 'o', even when we're assigning to the empty slice. So the position for the empty slice assignment is the logical extension of the positions for the non-empty slice assignments.\n\nBacking up a little bit, what happens when you keep going with our procession of counting up the slice beginning?\n\n>>> p = ['P','y','t','h','o','n']\n>>> p[0:4]\n ['P','y','t','h']\n>>> p[1:4]\n ['y','t','h']\n>>> p[2:4]\n ['t','h']\n>>> p[3:4]\n ['h']\n>>> p[4:4]\n []\n>>> p[5:4]\n []\n>>> p[6:4]\n []\n\n\nWith slicing, once you're done, you're done; it doesn't start slicing backwards. In Python you don't get negative strides unless you explicitly ask for them by using a negative number.\n\n>>> p[5:3:-1]\n ['n','o']\n\n\nThere are some weird consequences to the \"once you're done, you're done\" rule:\n\n>>> p[4:4]\n []\n>>> p[5:4]\n []\n>>> p[6:4]\n []\n>>> p[6]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nIndexError: list index out of range\n\n\nIn fact, compared to indexing, Python slicing is bizarrely error-proof:\n\n>>> p[100:200]\n []\n>>> p[int(2e99):int(1e99)]\n []\n\n\nThis can come in handy sometimes, but it can also lead to somewhat strange behavior:\n\n>>> p\n ['P', 'y', 't', 'h', 'o', 'n']\n>>> p[int(2e99):int(1e99)] = ['p','o','w','e','r']\n>>> p\n ['P', 'y', 't', 'h', 'o', 'n', 'p', 'o', 'w', 'e', 'r']\n\n\nDepending on your application, that might... or might not... be what you were hoping for there!\n\nBelow is the text of my original answer. It has been useful to many people, so I didn't want to delete it.\n\n>>> r=[1,2,3,4]\n>>> r[1:1]\n[]\n>>> r[1:1]=[9,8]\n>>> r\n[1, 9, 8, 2, 3, 4]\n>>> r[1:1]=['blah']\n>>> r\n[1, 'blah', 9, 8, 2, 3, 4]\n\n\nThis may also clarify the difference between slicing and indexing.\n\nShare\nImprove this answer\nFollow\nedited Jan 2 '19 at 16:44\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 18 '11 at 21:37\nDavid M. Perlman\n4,1711\n1 gold badge\n14\n14 silver badges\n11\n11 bronze badges","comments":["Excellent explanation. But the logic behind slicing is very non-intuitive."]},{"answer":"Explain Python's slice notation\n\nIn short, the colons (:) in subscript notation (subscriptable[subscriptarg]) make slice notation - which has the optional arguments, start, stop, step:\n\nsliceable[start:stop:step]\n\n\nPython slicing is a computationally fast way to methodically access parts of your data. In my opinion, to be even an intermediate Python programmer, it's one aspect of the language that it is necessary to be familiar with.\n\nImportant Definitions\n\nTo begin with, let's define a few terms:\n\nstart: the beginning index of the slice, it will include the element at this index unless it is the same as stop, defaults to 0, i.e. the first index. If it's negative, it means to start n items from the end.\n\nstop: the ending index of the slice, it does not include the element at this index, defaults to length of the sequence being sliced, that is, up to and including the end.\n\nstep: the amount by which the index increases, defaults to 1. If it's negative, you're slicing over the iterable in reverse.\n\nHow Indexing Works\n\nYou can make any of these positive or negative numbers. The meaning of the positive numbers is straightforward, but for negative numbers, just like indexes in Python, you count backwards from the end for the start and stop, and for the step, you simply decrement your index. This example is from the documentation's tutorial, but I've modified it slightly to indicate which item in a sequence each index references:\n\n +---+---+---+---+---+---+\n | P | y | t | h | o | n |\n +---+---+---+---+---+---+\n   0   1   2   3   4   5 \n  -6  -5  -4  -3  -2  -1\n\nHow Slicing Works\n\nTo use slice notation with a sequence that supports it, you must include at least one colon in the square brackets that follow the sequence (which actually implement the __getitem__ method of the sequence, according to the Python data model.)\n\nSlice notation works like this:\n\nsequence[start:stop:step]\n\n\nAnd recall that there are defaults for start, stop, and step, so to access the defaults, simply leave out the argument.\n\nSlice notation to get the last nine elements from a list (or any other sequence that supports it, like a string) would look like this:\n\nmy_list[-9:]\n\n\nWhen I see this, I read the part in the brackets as \"9th from the end, to the end.\" (Actually, I abbreviate it mentally as \"-9, on\")\n\nExplanation:\n\nThe full notation is\n\nmy_list[-9:None:None]\n\n\nand to substitute the defaults (actually when step is negative, stop's default is -len(my_list) - 1, so None for stop really just means it goes to whichever end step takes it to):\n\nmy_list[-9:len(my_list):1]\n\n\nThe colon, :, is what tells Python you're giving it a slice and not a regular index. That's why the idiomatic way of making a shallow copy of lists in Python 2 is\n\nlist_copy = sequence[:]\n\n\nAnd clearing them is with:\n\ndel my_list[:]\n\n\n(Python 3 gets a list.copy and list.clear method.)\n\nWhen step is negative, the defaults for start and stop change\n\nBy default, when the step argument is empty (or None), it is assigned to +1.\n\nBut you can pass in a negative integer, and the list (or most other standard slicables) will be sliced from the end to the beginning.\n\nThus a negative slice will change the defaults for start and stop!\n\nConfirming this in the source\n\nI like to encourage users to read the source as well as the documentation. The source code for slice objects and this logic is found here. First we determine if step is negative:\n\n step_is_negative = step_sign < 0;\n\n\nIf so, the lower bound is -1 meaning we slice all the way up to and including the beginning, and the upper bound is the length minus 1, meaning we start at the end. (Note that the semantics of this -1 is different from a -1 that users may pass indexes in Python indicating the last item.)\n\nif (step_is_negative) {\n    lower = PyLong_FromLong(-1L);\n    if (lower == NULL)\n        goto error;\n\n    upper = PyNumber_Add(length, lower);\n    if (upper == NULL)\n        goto error;\n}\n\n\nOtherwise step is positive, and the lower bound will be zero and the upper bound (which we go up to but not including) the length of the sliced list.\n\nelse {\n    lower = _PyLong_Zero;\n    Py_INCREF(lower);\n    upper = length;\n    Py_INCREF(upper);\n}\n\n\nThen, we may need to apply the defaults for start and stop - the default then for start is calculated as the upper bound when step is negative:\n\nif (self->start == Py_None) {\n    start = step_is_negative ? upper : lower;\n    Py_INCREF(start);\n}\n\n\nand stop, the lower bound:\n\nif (self->stop == Py_None) {\n    stop = step_is_negative ? lower : upper;\n    Py_INCREF(stop);\n}\n\nGive your slices a descriptive name!\n\nYou may find it useful to separate forming the slice from passing it to the list.__getitem__ method (that's what the square brackets do). Even if you're not new to it, it keeps your code more readable so that others that may have to read your code can more readily understand what you're doing.\n\nHowever, you can't just assign some integers separated by colons to a variable. You need to use the slice object:\n\nlast_nine_slice = slice(-9, None)\n\n\nThe second argument, None, is required, so that the first argument is interpreted as the start argument otherwise it would be the stop argument.\n\nYou can then pass the slice object to your sequence:\n\n>>> list(range(100))[last_nine_slice]\n[91, 92, 93, 94, 95, 96, 97, 98, 99]\n\n\nIt's interesting that ranges also take slices:\n\n>>> range(100)[last_nine_slice]\nrange(91, 100)\n\nMemory Considerations:\n\nSince slices of Python lists create new objects in memory, another important function to be aware of is itertools.islice. Typically you'll want to iterate over a slice, not just have it created statically in memory. islice is perfect for this. A caveat, it doesn't support negative arguments to start, stop, or step, so if that's an issue you may need to calculate indices or reverse the iterable in advance.\n\nlength = 100\nlast_nine_iter = itertools.islice(list(range(length)), length-9, None, 1)\nlist_last_nine = list(last_nine_iter)\n\n\nand now:\n\n>>> list_last_nine\n[91, 92, 93, 94, 95, 96, 97, 98, 99]\n\n\nThe fact that list slices make a copy is a feature of lists themselves. If you're slicing advanced objects like a Pandas DataFrame, it may return a view on the original, and not a copy.\n\nShare\nImprove this answer\nFollow\nedited Jun 20 '20 at 9:12\nCommunity♦\n11\n1 silver badge\nanswered Jul 12 '14 at 13:19\nAaron Hall♦\n302k75\n75 gold badges\n374\n374 silver badges\n314\n314 bronze badges","comments":["I like the idea of naming slices. I would suggest (start:stop) notation is misleading and (start_at:stop_before) notation may have preventing me searching out this Q&A in the first place.","@WinEunuuchs2Unix that's great feedback - this is a standard Python behavior, but it could be made clearer in that sort of way, so I'll consider updating my material to include this semantic."]},{"answer":"And a couple of things that weren't immediately obvious to me when I first saw the slicing syntax:\n\n>>> x = [1,2,3,4,5,6]\n>>> x[::-1]\n[6,5,4,3,2,1]\n\n\nEasy way to reverse sequences!\n\nAnd if you wanted, for some reason, every second item in the reversed sequence:\n\n>>> x = [1,2,3,4,5,6]\n>>> x[::-2]\n[6,4,2]\n\nShare\nImprove this answer\nFollow\nanswered Feb 3 '09 at 23:15\nDana\n28.8k17\n17 gold badges\n59\n59 silver badges\n72\n72 bronze badges","comments":[]},{"answer":"In Python 2.7\n\nSlicing in Python\n\n[a:b:c]\n\nlen = length of string, tuple or list\n\nc -- default is +1. The sign of c indicates forward or backward, absolute value of c indicates steps. Default is forward with step size 1. Positive means forward, negative means backward.\n\na --  When c is positive or blank, default is 0. When c is negative, default is -1.\n\nb --  When c is positive or blank, default is len. When c is negative, default is -(len+1).\n\n\nUnderstanding index assignment is very important.\n\nIn forward direction, starts at 0 and ends at len-1\n\nIn backward direction, starts at -1 and ends at -len\n\n\nWhen you say [a:b:c], you are saying depending on the sign of c (forward or backward), start at a and end at b (excluding element at bth index). Use the indexing rule above and remember you will only find elements in this range:\n\n-len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1\n\n\nBut this range continues in both directions infinitely:\n\n...,-len -2 ,-len-1,-len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1, len, len +1, len+2 , ....\n\n\nFor example:\n\n             0    1    2   3    4   5   6   7   8   9   10   11\n             a    s    t   r    i   n   g\n    -9  -8  -7   -6   -5  -4   -3  -2  -1\n\n\nIf your choice of a, b, and c allows overlap with the range above as you traverse using rules for a,b,c above you will either get a list with elements (touched during traversal) or you will get an empty list.\n\nOne last thing: if a and b are equal, then also you get an empty list:\n\n>>> l1\n[2, 3, 4]\n\n>>> l1[:]\n[2, 3, 4]\n\n>>> l1[::-1] # a default is -1 , b default is -(len+1)\n[4, 3, 2]\n\n>>> l1[:-4:-1] # a default is -1\n[4, 3, 2]\n\n>>> l1[:-3:-1] # a default is -1\n[4, 3]\n\n>>> l1[::] # c default is +1, so a default is 0, b default is len\n[2, 3, 4]\n\n>>> l1[::-1] # c is -1 , so a default is -1 and b default is -(len+1)\n[4, 3, 2]\n\n\n>>> l1[-100:-200:-1] # Interesting\n[]\n\n>>> l1[-1:-200:-1] # Interesting\n[4, 3, 2]\n\n\n>>> l1[-1:-1:1]\n[]\n\n\n>>> l1[-1:5:1] # Interesting\n[4]\n\n\n>>> l1[1:-7:1]\n[]\n\n>>> l1[1:-7:-1] # Interesting\n[3, 2]\n\n>>> l1[:-2:-2] # a default is -1, stop(b) at -2 , step(c) by 2 in reverse direction\n[4]\n\nShare\nImprove this answer\nFollow\nedited Jul 10 '17 at 16:59\nanswered Oct 22 '12 at 5:33\nAnkur Agarwal\n20.4k33\n33 gold badges\n121\n121 silver badges\n184\n184 bronze badges","comments":["another one interesting example: a = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ]; a[:-2:-2] which results to [9]"]},{"answer":"Found this great table at http://wiki.python.org/moin/MovingToPythonFromOtherLanguages\n\nPython indexes and slices for a six-element list.\nIndexes enumerate the elements, slices enumerate the spaces between the elements.\n\nIndex from rear:    -6  -5  -4  -3  -2  -1      a=[0,1,2,3,4,5]    a[1:]==[1,2,3,4,5]\nIndex from front:    0   1   2   3   4   5      len(a)==6          a[:5]==[0,1,2,3,4]\n                   +---+---+---+---+---+---+    a[0]==0            a[:-2]==[0,1,2,3]\n                   | a | b | c | d | e | f |    a[5]==5            a[1:2]==[1]\n                   +---+---+---+---+---+---+    a[-1]==5           a[1:-1]==[1,2,3,4]\nSlice from front:  :   1   2   3   4   5   :    a[-2]==4\nSlice from rear:   :  -5  -4  -3  -2  -1   :\n                                                b=a[:]\n                                                b==[0,1,2,3,4,5] (shallow copy of a)\nShare\nImprove this answer\nFollow\nanswered Sep 6 '11 at 6:50\nAdrianoFerrari\n2,06018\n18 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"After using it a bit I realise that the simplest description is that it is exactly the same as the arguments in a for loop...\n\n(from:to:step)\n\n\nAny of them are optional:\n\n(:to:step)\n(from::step)\n(from:to)\n\n\nThen the negative indexing just needs you to add the length of the string to the negative indices to understand it.\n\nThis works for me anyway...\n\nShare\nImprove this answer\nFollow\nedited Jan 2 '19 at 16:40\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 19 '09 at 20:52\nSimon\n71.7k25\n25 gold badges\n83\n83 silver badges\n117\n117 bronze badges","comments":[]},{"answer":"I find it easier to remember how it works, and then I can figure out any specific start/stop/step combination.\n\nIt's instructive to understand range() first:\n\ndef range(start=0, stop, step=1):  # Illegal syntax, but that's the effect\n    i = start\n    while (i < stop if step > 0 else i > stop):\n        yield i\n        i += step\n\n\nBegin from start, increment by step, do not reach stop. Very simple.\n\nThe thing to remember about negative step is that stop is always the excluded end, whether it's higher or lower. If you want same slice in opposite order, it's much cleaner to do the reversal separately: e.g. 'abcde'[1:-2][::-1] slices off one char from left, two from right, then reverses. (See also reversed().)\n\nSequence slicing is same, except it first normalizes negative indexes, and it can never go outside the sequence:\n\nTODO: The code below had a bug with \"never go outside the sequence\" when abs(step)>1; I think I patched it to be correct, but it's hard to understand.\n\ndef this_is_how_slicing_works(seq, start=None, stop=None, step=1):\n    if start is None:\n        start = (0 if step > 0 else len(seq)-1)\n    elif start < 0:\n        start += len(seq)\n    if not 0 <= start < len(seq):  # clip if still outside bounds\n        start = (0 if step > 0 else len(seq)-1)\n    if stop is None:\n        stop = (len(seq) if step > 0 else -1)  # really -1, not last element\n    elif stop < 0:\n        stop += len(seq)\n    for i in range(start, stop, step):\n        if 0 <= i < len(seq):\n            yield seq[i]\n\n\nDon't worry about the is None details - just remember that omitting start and/or stop always does the right thing to give you the whole sequence.\n\nNormalizing negative indexes first allows start and/or stop to be counted from the end independently: 'abcde'[1:-2] == 'abcde'[1:3] == 'bc' despite range(1,-2) == []. The normalization is sometimes thought of as \"modulo the length\", but note it adds the length just once: e.g. 'abcde'[-53:42] is just the whole string.\n\nShare\nImprove this answer\nFollow\nedited Jan 2 '19 at 16:46\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 29 '12 at 10:15\nBeni Cherniavsky-Paskin\n8,4182\n2 gold badges\n44\n44 silver badges\n56\n56 bronze badges","comments":["The this_is_how_slicing_works is not the same as python slice. E.G. [0, 1, 2][-5:3:3] will get [0] in python, but list(this_is_how_slicing_works([0, 1, 2], -5, 3, 3)) get [1].","@Eastsun Oops, you're right! A clearer case: range(4)[-200:200:3] == [0, 3] but list(this_is_how_slicing_works([0, 1, 2, 3], -200, 200, 3)) == [2]. My if 0 <= i < len(seq): was an attempt to implement \"never go outside the sequence\" simply but is wrong for step>1. I'll rewrite it later today (with tests)."]},{"answer":"I use the \"an index points between elements\" method of thinking about it myself, but one way of describing it which sometimes helps others get it is this:\n\nmylist[X:Y]\n\n\nX is the index of the first element you want.\nY is the index of the first element you don't want.\n\nShare\nImprove this answer\nFollow\nanswered Feb 6 '09 at 21:16\nSteve Losh\n19.1k2\n2 gold badges\n48\n48 silver badges\n44\n44 bronze badges","comments":[]},{"answer":"Index:\n      ------------>\n  0   1   2   3   4\n+---+---+---+---+---+\n| a | b | c | d | e |\n+---+---+---+---+---+\n  0  -4  -3  -2  -1\n      <------------\n\nSlice:\n    <---------------|\n|--------------->\n:   1   2   3   4   :\n+---+---+---+---+---+\n| a | b | c | d | e |\n+---+---+---+---+---+\n:  -4  -3  -2  -1   :\n|--------------->\n    <---------------|\n\n\nI hope this will help you to model the list in Python.\n\nReference: http://wiki.python.org/moin/MovingToPythonFromOtherLanguages\n\nShare\nImprove this answer\nFollow\nedited Feb 11 '17 at 19:56\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Feb 4 '13 at 7:20\nxiaoyu\n7,0031\n1 gold badge\n14\n14 silver badges\n13\n13 bronze badges","comments":[]},{"answer":"Python slicing notation:\n\na[start:end:step]\n\nFor start and end, negative values are interpreted as being relative to the end of the sequence.\nPositive indices for end indicate the position after the last element to be included.\nBlank values are defaulted as follows: [+0:-0:1].\nUsing a negative step reverses the interpretation of start and end\n\nThe notation extends to (numpy) matrices and multidimensional arrays. For example, to slice entire columns you can use:\n\nm[::,0:2:] ## slice the first two columns\n\n\nSlices hold references, not copies, of the array elements. If you want to make a separate copy an array, you can use deepcopy().\n\nShare\nImprove this answer\nFollow\nedited May 23 '17 at 12:34\nCommunity♦\n11\n1 silver badge\nanswered Apr 28 '13 at 19:49\nBrent Bradburn\n42.1k13\n13 gold badges\n130\n130 silver badges\n140\n140 bronze badges","comments":[]},{"answer":"This is how I teach slices to newbies:\n\nUnderstanding the difference between indexing and slicing:\n\nWiki Python has this amazing picture which clearly distinguishes indexing and slicing.\n\nIt is a list with six elements in it. To understand slicing better, consider that list as a set of six boxes placed together. Each box has an alphabet in it.\n\nIndexing is like dealing with the contents of box. You can check contents of any box. But you can't check the contents of multiple boxes at once. You can even replace the contents of the box. But you can't place two balls in one box or replace two balls at a time.\n\nIn [122]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [123]: alpha\nOut[123]: ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [124]: alpha[0]\nOut[124]: 'a'\n\nIn [127]: alpha[0] = 'A'\n\nIn [128]: alpha\nOut[128]: ['A', 'b', 'c', 'd', 'e', 'f']\n\nIn [129]: alpha[0,1]\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-129-c7eb16585371> in <module>()\n----> 1 alpha[0,1]\n\nTypeError: list indices must be integers, not tuple\n\n\nSlicing is like dealing with boxes themselves. You can pick up the first box and place it on another table. To pick up the box, all you need to know is the position of beginning and ending of the box.\n\nYou can even pick up the first three boxes or the last two boxes or all boxes between 1 and 4. So, you can pick any set of boxes if you know the beginning and ending. These positions are called start and stop positions.\n\nThe interesting thing is that you can replace multiple boxes at once. Also you can place multiple boxes wherever you like.\n\nIn [130]: alpha[0:1]\nOut[130]: ['A']\n\nIn [131]: alpha[0:1] = 'a'\n\nIn [132]: alpha\nOut[132]: ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [133]: alpha[0:2] = ['A', 'B']\n\nIn [134]: alpha\nOut[134]: ['A', 'B', 'c', 'd', 'e', 'f']\n\nIn [135]: alpha[2:2] = ['x', 'xx']\n\nIn [136]: alpha\nOut[136]: ['A', 'B', 'x', 'xx', 'c', 'd', 'e', 'f']\n\n\nSlicing With Step:\n\nTill now you have picked boxes continuously. But sometimes you need to pick up discretely. For example, you can pick up every second box. You can even pick up every third box from the end. This value is called step size. This represents the gap between your successive pickups. The step size should be positive if You are picking boxes from the beginning to end and vice versa.\n\nIn [137]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [142]: alpha[1:5:2]\nOut[142]: ['b', 'd']\n\nIn [143]: alpha[-1:-5:-2]\nOut[143]: ['f', 'd']\n\nIn [144]: alpha[1:5:-2]\nOut[144]: []\n\nIn [145]: alpha[-1:-5:2]\nOut[145]: []\n\n\nHow Python Figures Out Missing Parameters:\n\nWhen slicing, if you leave out any parameter, Python tries to figure it out automatically.\n\nIf you check the source code of CPython, you will find a function called PySlice_GetIndicesEx() which figures out indices to a slice for any given parameters. Here is the logical equivalent code in Python.\n\nThis function takes a Python object and optional parameters for slicing and returns the start, stop, step, and slice length for the requested slice.\n\ndef py_slice_get_indices_ex(obj, start=None, stop=None, step=None):\n\n    length = len(obj)\n\n    if step is None:\n        step = 1\n    if step == 0:\n        raise Exception(\"Step cannot be zero.\")\n\n    if start is None:\n        start = 0 if step > 0 else length - 1\n    else:\n        if start < 0:\n            start += length\n        if start < 0:\n            start = 0 if step > 0 else -1\n        if start >= length:\n            start = length if step > 0 else length - 1\n\n    if stop is None:\n        stop = length if step > 0 else -1\n    else:\n        if stop < 0:\n            stop += length\n        if stop < 0:\n            stop = 0 if step > 0 else -1\n        if stop >= length:\n            stop = length if step > 0 else length - 1\n\n    if (step < 0 and stop >= start) or (step > 0 and start >= stop):\n        slice_length = 0\n    elif step < 0:\n        slice_length = (stop - start + 1)/(step) + 1\n    else:\n        slice_length = (stop - start - 1)/(step) + 1\n\n    return (start, stop, step, slice_length)\n\n\nThis is the intelligence that is present behind slices. Since Python has an built-in function called slice, you can pass some parameters and check how smartly it calculates missing parameters.\n\nIn [21]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [22]: s = slice(None, None, None)\n\nIn [23]: s\nOut[23]: slice(None, None, None)\n\nIn [24]: s.indices(len(alpha))\nOut[24]: (0, 6, 1)\n\nIn [25]: range(*s.indices(len(alpha)))\nOut[25]: [0, 1, 2, 3, 4, 5]\n\nIn [26]: s = slice(None, None, -1)\n\nIn [27]: range(*s.indices(len(alpha)))\nOut[27]: [5, 4, 3, 2, 1, 0]\n\nIn [28]: s = slice(None, 3, -1)\n\nIn [29]: range(*s.indices(len(alpha)))\nOut[29]: [5, 4]\n\n\nNote: This post was originally written in my blog, The Intelligence Behind Python Slices.\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '19 at 7:58\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 24 '15 at 16:08\nChillarAnand\n23.5k8\n8 gold badges\n101\n101 silver badges\n117\n117 bronze badges","comments":[]},{"answer":"You can also use slice assignment to remove one or more elements from a list:\n\nr = [1, 'blah', 9, 8, 2, 3, 4]\n>>> r[1:4] = []\n>>> r\n[1, 2, 3, 4]\n\nShare\nImprove this answer\nFollow\nedited Apr 19 '13 at 16:28\nanswered Apr 5 '13 at 1:59\ndansalmo\n10.5k5\n5 gold badges\n53\n53 silver badges\n49\n49 bronze badges","comments":[]},{"answer":"This is just for some extra info... Consider the list below\n\n>>> l=[12,23,345,456,67,7,945,467]\n\n\nFew other tricks for reversing the list:\n\n>>> l[len(l):-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[:-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[len(l)::-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[::-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[-1:-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\nShare\nImprove this answer\nFollow\nedited May 8 '19 at 8:35\nGeorgy\n6,8417\n7 gold badges\n49\n49 silver badges\n59\n59 bronze badges\nanswered Mar 22 '12 at 17:20\nArindam Roychowdhury\n4,1155\n5 gold badges\n45\n45 silver badges\n52\n52 bronze badges","comments":[]},{"answer":"As a general rule, writing code with a lot of hardcoded index values leads to a readability and maintenance mess. For example, if you come back to the code a year later, you’ll look at it and wonder what you were thinking when you wrote it. The solution shown is simply a way of more clearly stating what your code is actually doing. In general, the built-in slice() creates a slice object that can be used anywhere a slice is allowed. For example:\n\n>>> items = [0, 1, 2, 3, 4, 5, 6]\n>>> a = slice(2, 4)\n>>> items[2:4]\n[2, 3]\n>>> items[a]\n[2, 3]\n>>> items[a] = [10,11]\n>>> items\n[0, 1, 10, 11, 4, 5, 6]\n>>> del items[a]\n>>> items\n[0, 1, 4, 5, 6]\n\n\nIf you have a slice instance s, you can get more information about it by looking at its s.start, s.stop, and s.step attributes, respectively. For example:\n\n>>> a = slice(10, 50, 2)\n>>> a.start\n10\n>>> a.stop\n50\n>>> a.step\n2\n>>>\n\nShare\nImprove this answer\nFollow\nanswered Dec 7 '13 at 16:52\nPython_Dude\n4976\n6 silver badges\n12\n12 bronze badges","comments":[]},{"answer":"1. Slice Notation\n\nTo make it simple, remember slice has only one form：\n\ns[start:end:step]\n\n\nand here is how it works:\n\ns: an object that can be sliced\nstart: first index to start iteration\nend: last index, NOTE that end index will not be included in the resulted slice\nstep: pick element every step index\n\nAnother import thing: all start,end, step can be omitted! And if they are omitted, their default value will be used: 0,len(s),1 accordingly.\n\nSo possible variations are:\n\n# Mostly used variations\ns[start:end]\ns[start:]\ns[:end]\n\n# Step-related variations\ns[:end:step]\ns[start::step]\ns[::step]\n\n# Make a copy\ns[:]\n\n\nNOTE: If start >= end (considering only when step>0), Python will return a empty slice [].\n\n2. Pitfalls\n\nThe above part explains the core features on how slice works, and it will work on most occasions. However, there can be pitfalls you should watch out, and this part explains them.\n\nNegative indexes\n\nThe very first thing that confuses Python learners is that an index can be negative! Don't panic: a negative index means count backwards.\n\nFor example:\n\ns[-5:]    # Start at the 5th index from the end of array,\n          # thus returning the last 5 elements.\ns[:-5]    # Start at index 0, and end until the 5th index from end of array,\n          # thus returning s[0:len(s)-5].\n\nNegative step\n\nMaking things more confusing is that step can be negative too!\n\nA negative step means iterate the array backwards: from the end to start, with the end index included, and the start index excluded from the result.\n\nNOTE: when step is negative, the default value for start is len(s) (while end does not equal to 0, because s[::-1] contains s[0]). For example:\n\ns[::-1]            # Reversed slice\ns[len(s)::-1]      # The same as above, reversed slice\ns[0:len(s):-1]     # Empty list\n\nOut of range error?\n\nBe surprised: slice does not raise an IndexError when the index is out of range!\n\nIf the index is out of range, Python will try its best to set the index to 0 or len(s) according to the situation. For example:\n\ns[:len(s)+5]      # The same as s[:len(s)]\ns[-len(s)-5::]    # The same as s[0:]\ns[len(s)+5::-1]   # The same as s[len(s)::-1], and the same as s[::-1]\n\n3. Examples\n\nLet's finish this answer with examples, explaining everything we have discussed:\n\n# Create our array for demonstration\nIn [1]: s = [i for i in range(10)]\n\nIn [2]: s\nOut[2]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [3]: s[2:]   # From index 2 to last index\nOut[3]: [2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [4]: s[:8]   # From index 0 up to index 8\nOut[4]: [0, 1, 2, 3, 4, 5, 6, 7]\n\nIn [5]: s[4:7]  # From index 4 (included) up to index 7(excluded)\nOut[5]: [4, 5, 6]\n\nIn [6]: s[:-2]  # Up to second last index (negative index)\nOut[6]: [0, 1, 2, 3, 4, 5, 6, 7]\n\nIn [7]: s[-2:]  # From second last index (negative index)\nOut[7]: [8, 9]\n\nIn [8]: s[::-1] # From last to first in reverse order (negative step)\nOut[8]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n\nIn [9]: s[::-2] # All odd numbers in reversed order\nOut[9]: [9, 7, 5, 3, 1]\n\nIn [11]: s[-2::-2] # All even numbers in reversed order\nOut[11]: [8, 6, 4, 2, 0]\n\nIn [12]: s[3:15]   # End is out of range, and Python will set it to len(s).\nOut[12]: [3, 4, 5, 6, 7, 8, 9]\n\nIn [14]: s[5:1]    # Start > end; return empty list\nOut[14]: []\n\nIn [15]: s[11]     # Access index 11 (greater than len(s)) will raise an IndexError\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n<ipython-input-15-79ffc22473a3> in <module>()\n----> 1 s[11]\n\nIndexError: list index out of range\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '19 at 8:04\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jan 9 '17 at 12:52\ncizixs\n10.2k6\n6 gold badges\n43\n43 silver badges\n58\n58 bronze badges","comments":[]},{"answer":"The previous answers don't discuss multi-dimensional array slicing which is possible using the famous NumPy package:\n\nSlicing can also be applied to multi-dimensional arrays.\n\n# Here, a is a NumPy array\n\n>>> a\narray([[ 1,  2,  3,  4],\n       [ 5,  6,  7,  8],\n       [ 9, 10, 11, 12]])\n>>> a[:2, 0:3:2]\narray([[1, 3],\n       [5, 7]])\n\n\nThe \":2\" before the comma operates on the first dimension and the \"0:3:2\" after the comma operates on the second dimension.\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '19 at 8:08\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Mar 1 '17 at 2:31\nStatham\n3,4442\n2 gold badges\n28\n28 silver badges\n44\n44 bronze badges","comments":["Just a friendly reminder that you cannot do this on Python list but only on array in Numpy"]},{"answer":"I personally think about it like a for loop:\n\na[start:end:step]\n# for(i = start; i < end; i += step)\n\n\nAlso, note that negative values for start and end are relative to the end of the list and computed in the example above by given_index + a.shape[0].\n\nShare\nImprove this answer\nFollow\nedited Jan 15 '20 at 12:29\nArsen Khachaturyan\n6,6304\n4 gold badges\n34\n34 silver badges\n37\n37 bronze badges\nanswered Aug 23 '19 at 14:10\nRaman\n2,4851\n1 gold badge\n20\n20 silver badges\n43\n43 bronze badges","comments":[]},{"answer":"In my opinion, you will understand and memorize better the Python string slicing notation if you look at it the following way (read on).\n\nLet's work with the following string ...\n\nazString = \"abcdefghijklmnopqrstuvwxyz\"\n\n\nFor those who don't know, you can create any substring from azString using the notation azString[x:y]\n\nComing from other programming languages, that's when the common sense gets compromised. What are x and y?\n\nI had to sit down and run several scenarios in my quest for a memorization technique that will help me remember what x and y are and help me slice strings properly at the first attempt.\n\nMy conclusion is that x and y should be seen as the boundary indexes that are surrounding the strings that we want to extra. So we should see the expression as azString[index1, index2] or even more clearer as azString[index_of_first_character, index_after_the_last_character].\n\nHere is an example visualization of that ...\n\nLetters   a b c d e f g h i j ...\n         ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑\n             ┊           ┊\nIndexes  0 1 2 3 4 5 6 7 8 9 ...\n             ┊           ┊\ncdefgh    index1       index2\n\n\nSo all you have to do is setting index1 and index2 to the values that will surround the desired substring. For instance, to get the substring \"cdefgh\", you can use azString[2:8], because the index on the left side of \"c\" is 2 and the one on the right size of \"h\" is 8.\n\nRemember that we are setting the boundaries. And those boundaries are the positions where you could place some brackets that will be wrapped around the substring like this ...\n\na b [ c d e f g h ] i j\n\nThat trick works all the time and is easy to memorize.\n\nShare\nImprove this answer\nFollow\nedited Jan 8 '20 at 16:12\nanswered Dec 12 '17 at 4:13\nasiby\n2,61923\n23 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"#!/usr/bin/env python\n\ndef slicegraphical(s, lista):\n\n    if len(s) > 9:\n        print \"\"\"Enter a string of maximum 9 characters,\n    so the printig would looki nice\"\"\"\n        return 0;\n    # print \" \",\n    print '  '+'+---' * len(s) +'+'\n    print ' ',\n    for letter in s:\n        print '| {}'.format(letter),\n    print '|'\n    print \" \",; print '+---' * len(s) +'+'\n\n    print \" \",\n    for letter in range(len(s) +1):\n        print '{}  '.format(letter),\n    print \"\"\n    for letter in range(-1*(len(s)), 0):\n        print ' {}'.format(letter),\n    print ''\n    print ''\n\n\n    for triada in lista:\n        if len(triada) == 3:\n            if triada[0]==None and triada[1] == None and triada[2] == None:\n                # 000\n                print s+'[   :   :   ]' +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] == None and triada[2] != None:\n                # 001\n                print s+'[   :   :{0:2d} ]'.format(triada[2], '','') +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] != None and triada[2] == None:\n                # 010\n                print s+'[   :{0:2d} :   ]'.format(triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] != None and triada[2] != None:\n                # 011\n                print s+'[   :{0:2d} :{1:2d} ]'.format(triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] == None and triada[2] == None:\n                # 100\n                print s+'[{0:2d} :   :   ]'.format(triada[0]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] == None and triada[2] != None:\n                # 101\n                print s+'[{0:2d} :   :{1:2d} ]'.format(triada[0], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] != None and triada[2] == None:\n                # 110\n                print s+'[{0:2d} :{1:2d} :   ]'.format(triada[0], triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] != None and triada[2] != None:\n                # 111\n                print s+'[{0:2d} :{1:2d} :{2:2d} ]'.format(triada[0], triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n\n        elif len(triada) == 2:\n            if triada[0] == None and triada[1] == None:\n                # 00\n                print s+'[   :   ]    ' + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] == None and triada[1] != None:\n                # 01\n                print s+'[   :{0:2d} ]    '.format(triada[1]) + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] != None and triada[1] == None:\n                # 10\n                print s+'[{0:2d} :   ]    '.format(triada[0]) + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] != None and triada[1] != None:\n                # 11\n                print s+'[{0:2d} :{1:2d} ]    '.format(triada[0],triada[1]) + ' = ', s[triada[0]:triada[1]]\n\n        elif len(triada) == 1:\n            print s+'[{0:2d} ]        '.format(triada[0]) + ' = ', s[triada[0]]\n\n\nif __name__ == '__main__':\n    # Change \"s\" to what ever string you like, make it 9 characters for\n    # better representation.\n    s = 'COMPUTERS'\n\n    # add to this list different lists to experement with indexes\n    # to represent ex. s[::], use s[None, None,None], otherwise you get an error\n    # for s[2:] use s[2:None]\n\n    lista = [[4,7],[2,5,2],[-5,1,-1],[4],[-4,-6,-1], [2,-3,1],[2,-3,-1], [None,None,-1],[-5,None],[-5,0,-1],[-5,None,-1],[-1,1,-2]]\n\n    slicegraphical(s, lista)\n\n\nYou can run this script and experiment with it, below is some samples that I got from the script.\n\n  +---+---+---+---+---+---+---+---+---+\n  | C | O | M | P | U | T | E | R | S |\n  +---+---+---+---+---+---+---+---+---+\n  0   1   2   3   4   5   6   7   8   9   \n -9  -8  -7  -6  -5  -4  -3  -2  -1 \n\nCOMPUTERS[ 4 : 7 ]     =  UTE\nCOMPUTERS[ 2 : 5 : 2 ] =  MU\nCOMPUTERS[-5 : 1 :-1 ] =  UPM\nCOMPUTERS[ 4 ]         =  U\nCOMPUTERS[-4 :-6 :-1 ] =  TU\nCOMPUTERS[ 2 :-3 : 1 ] =  MPUT\nCOMPUTERS[ 2 :-3 :-1 ] =  \nCOMPUTERS[   :   :-1 ] =  SRETUPMOC\nCOMPUTERS[-5 :   ]     =  UTERS\nCOMPUTERS[-5 : 0 :-1 ] =  UPMO\nCOMPUTERS[-5 :   :-1 ] =  UPMOC\nCOMPUTERS[-1 : 1 :-2 ] =  SEUM\n[Finished in 0.9s]\n\n\nWhen using a negative step, notice that the answer is shifted to the right by 1.\n\nShare\nImprove this answer\nFollow\nanswered Oct 18 '14 at 17:40\nmahmoh\n7627\n7 silver badges\n14\n14 bronze badges","comments":[]},{"answer":"My brain seems happy to accept that lst[start:end] contains the start-th item. I might even say that it is a 'natural assumption'.\n\nBut occasionally a doubt creeps in and my brain asks for reassurance that it does not contain the end-th element.\n\nIn these moments I rely on this simple theorem:\n\nfor any n,    lst = lst[:n] + lst[n:]\n\n\nThis pretty property tells me that lst[start:end] does not contain the end-th item because it is in lst[end:].\n\nNote that this theorem is true for any n at all. For example, you can check that\n\nlst = range(10)\nlst[:-42] + lst[-42:] == lst\n\n\nreturns True.\n\nShare\nImprove this answer\nFollow\nanswered May 26 '16 at 8:16\nRobert\n1,28413\n13 silver badges\n20\n20 bronze badges","comments":[]},{"answer":"I want to add one Hello, World! example that explains the basics of slices for the very beginners. It helped me a lot.\n\nLet's have a list with six values ['P', 'Y', 'T', 'H', 'O', 'N']:\n\n+---+---+---+---+---+---+\n| P | Y | T | H | O | N |\n+---+---+---+---+---+---+\n  0   1   2   3   4   5\n\n\nNow the simplest slices of that list are its sublists. The notation is [<index>:<index>] and the key is to read it like this:\n\n[ start cutting before this index : end cutting before this index ]\n\n\nNow if you make a slice [2:5] of the list above, this will happen:\n\n        |           |\n+---+---|---+---+---|---+\n| P | Y | T | H | O | N |\n+---+---|---+---+---|---+\n  0   1 | 2   3   4 | 5\n\n\nYou made a cut before the element with index 2 and another cut before the element with index 5. So the result will be a slice between those two cuts, a list ['T', 'H', 'O'].\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '19 at 8:23\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Apr 4 '18 at 9:52\nJeyekomon\n1,8321\n1 gold badge\n21\n21 silver badges\n28\n28 bronze badges","comments":[]},{"answer":"In Python, the most basic form for slicing is the following:\n\nl[start:end]\n\n\nwhere l is some collection, start is an inclusive index, and end is an exclusive index.\n\nIn [1]: l = list(range(10))\n\nIn [2]: l[:5] # First five elements\nOut[2]: [0, 1, 2, 3, 4]\n\nIn [3]: l[-5:] # Last five elements\nOut[3]: [5, 6, 7, 8, 9]\n\n\nWhen slicing from the start, you can omit the zero index, and when slicing to the end, you can omit the final index since it is redundant, so do not be verbose:\n\nIn [5]: l[:3] == l[0:3]\nOut[5]: True\n\nIn [6]: l[7:] == l[7:len(l)]\nOut[6]: True\n\n\nNegative integers are useful when doing offsets relative to the end of a collection:\n\nIn [7]: l[:-1] # Include all elements but the last one\nOut[7]: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n\nIn [8]: l[-3:] # Take the last three elements\nOut[8]: [7, 8, 9]\n\n\nIt is possible to provide indices that are out of bounds when slicing such as:\n\nIn [9]: l[:20] # 20 is out of index bounds, and l[20] will raise an IndexError exception\nOut[9]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [11]: l[-20:] # -20 is out of index bounds, and l[-20] will raise an IndexError exception\nOut[11]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nKeep in mind that the result of slicing a collection is a whole new collection. In addition, when using slice notation in assignments, the length of the slice assignments do not need to be the same. The values before and after the assigned slice will be kept, and the collection will shrink or grow to contain the new values:\n\nIn [16]: l[2:6] = list('abc') # Assigning fewer elements than the ones contained in the sliced collection l[2:6]\n\nIn [17]: l\nOut[17]: [0, 1, 'a', 'b', 'c', 6, 7, 8, 9]\n\nIn [18]: l[2:5] = list('hello') # Assigning more elements than the ones contained in the sliced collection l [2:5]\n\nIn [19]: l\nOut[19]: [0, 1, 'h', 'e', 'l', 'l', 'o', 6, 7, 8, 9]\n\n\nIf you omit the start and end index, you will make a copy of the collection:\n\nIn [14]: l_copy = l[:]\n\nIn [15]: l == l_copy and l is not l_copy\nOut[15]: True\n\n\nIf the start and end indexes are omitted when performing an assignment operation, the entire content of the collection will be replaced with a copy of what is referenced:\n\nIn [20]: l[:] = list('hello...')\n\nIn [21]: l\nOut[21]: ['h', 'e', 'l', 'l', 'o', '.', '.', '.']\n\n\nBesides basic slicing, it is also possible to apply the following notation:\n\nl[start:end:step]\n\n\nwhere l is a collection, start is an inclusive index, end is an exclusive index, and step is a stride that can be used to take every nth item in l.\n\nIn [22]: l = list(range(10))\n\nIn [23]: l[::2] # Take the elements which indexes are even\nOut[23]: [0, 2, 4, 6, 8]\n\nIn [24]: l[1::2] # Take the elements which indexes are odd\nOut[24]: [1, 3, 5, 7, 9]\n\n\nUsing step provides a useful trick to reverse a collection in Python:\n\nIn [25]: l[::-1]\nOut[25]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n\n\nIt is also possible to use negative integers for step as the following example:\n\nIn[28]:  l[::-2]\nOut[28]: [9, 7, 5, 3, 1]\n\n\nHowever, using a negative value for step could become very confusing. Moreover, in order to be Pythonic, you should avoid using start, end, and step in a single slice. In case this is required, consider doing this in two assignments (one to slice, and the other to stride).\n\nIn [29]: l = l[::2] # This step is for striding\n\nIn [30]: l\nOut[30]: [0, 2, 4, 6, 8]\n\nIn [31]: l = l[1:-1] # This step is for slicing\n\nIn [32]: l\nOut[32]: [2, 4, 6]\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '19 at 8:16\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Sep 4 '17 at 16:00\nlmiguelvargasf\n43.5k36\n36 gold badges\n176\n176 silver badges\n177\n177 bronze badges","comments":[]},{"answer":"Most of the previous answers clears up questions about slice notation.\n\nThe extended indexing syntax used for slicing is aList[start:stop:step], and basic examples are:\n\n:\n\nMore slicing examples: 15 Extended Slices\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '19 at 8:19\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Oct 6 '17 at 22:30\nRoshan Bagdiya\n1,62516\n16 silver badges\n39\n39 bronze badges","comments":[]},{"answer":"The below is the example of an index of a string:\n\n +---+---+---+---+---+\n | H | e | l | p | A |\n +---+---+---+---+---+\n 0   1   2   3   4   5\n-5  -4  -3  -2  -1\n\nstr=\"Name string\"\n\n\nSlicing example: [start:end:step]\n\nstr[start:end] # Items start through end-1\nstr[start:]    # Items start through the rest of the array\nstr[:end]      # Items from the beginning through end-1\nstr[:]         # A copy of the whole array\n\n\nBelow is the example usage:\n\nprint str[0] = N\nprint str[0:2] = Na\nprint str[0:7] = Name st\nprint str[0:7:2] = Nm t\nprint str[0:-1:2] = Nm ti\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '19 at 8:10\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 28 '17 at 10:12\nPrince Dhadwal\n2353\n3 silver badges\n6\n6 bronze badges","comments":[]},{"answer":"If you feel negative indices in slicing is confusing, here's a very easy way to think about it: just replace the negative index with len - index. So for example, replace -3 with len(list) - 3.\n\nThe best way to illustrate what slicing does internally is just show it in code that implements this operation:\n\ndef slice(list, start = None, end = None, step = 1):\n  # Take care of missing start/end parameters\n  start = 0 if start is None else start\n  end = len(list) if end is None else end\n\n  # Take care of negative start/end parameters\n  start = len(list) + start if start < 0 else start\n  end = len(list) + end if end < 0 else end\n\n  # Now just execute a for-loop with start, end and step\n  return [list[i] for i in range(start, end, step)]\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '19 at 8:22\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Dec 19 '17 at 6:12\nShital Shah\n49.5k10\n10 gold badges\n196\n196 silver badges\n162\n162 bronze badges","comments":[]},{"answer":"The basic slicing technique is to define the starting point, the stopping point, and the step size - also known as stride.\n\nFirst, we will create a list of values to use in our slicing.\n\nCreate two lists to slice. The first is a numeric list from 1 to 9 (List A). The second is also a numeric list, from 0 to 9 (List B):\n\nA = list(range(1, 10, 1)) # Start, stop, and step\nB = list(range(9))\n\nprint(\"This is List A:\", A)\nprint(\"This is List B:\", B)\n\n\nIndex the number 3 from A and the number 6 from B.\n\nprint(A[2])\nprint(B[6])\n\n\nBasic Slicing\n\nExtended indexing syntax used for slicing is aList[start:stop:step]. The start argument and the step argument both default to none - the only required argument is stop. Did you notice this is similar to how range was used to define lists A and B? This is because the slice object represents the set of indices specified by range(start, stop, step). Python 3.4 documentation.\n\nAs you can see, defining only stop returns one element. Since the start defaults to none, this translates into retrieving only one element.\n\nIt is important to note, the first element is index 0, not index 1. This is why we are using 2 lists for this exercise. List A's elements are numbered according to the ordinal position (the first element is 1, the second element is 2, etc.) while List B's elements are the numbers that would be used to index them ([0] for the first element 0, etc.).\n\nWith extended indexing syntax, we retrieve a range of values. For example, all values are retrieved with a colon.\n\nA[:]\n\n\nTo retrieve a subset of elements, the start and stop positions need to be defined.\n\nGiven the pattern aList[start:stop], retrieve the first two elements from List A.\n\nShare\nImprove this answer\nFollow\nedited Sep 26 '19 at 8:25\nPeter Mortensen\n28.7k21\n21 gold badges\n95\n95 silver badges\n123\n123 bronze badges\nanswered Jul 23 '18 at 13:06\nBabu Chandermani\n911\n1 silver badge\n5\n5 bronze badges","comments":[]},{"answer":"The rules of slicing are as follows:\n[lower bound : upper bound : step size]\n\n\nI- Convert upper bound and lower bound into common signs.\n\nII- Then check if the step size is a positive or a negative value.\n\n(i) If the step size is a positive value, upper bound should be greater than lower bound, otherwise empty string is printed. For example:\n\ns=\"Welcome\"\ns1=s[0:3:1]\nprint(s1)\n\n\nThe output:\n\nWel\n\n\nHowever if we run the following code:\n\ns=\"Welcome\"\ns1=s[3:0:1]\nprint(s1)\n\n\nIt will return an empty string.\n\n(ii) If the step size if a negative value, upper bound should be lesser than lower bound, otherwise empty string will be printed. For example:\n\ns=\"Welcome\"\ns1=s[3:0:-1]\nprint(s1)\n\n\nThe output:\n\ncle\n\n\nBut if we run the following code:\n\ns=\"Welcome\"\ns1=s[0:5:-1]\nprint(s1)\n\n\nThe output will be an empty string.\n\nThus in the code:\n\nstr = 'abcd'\nl = len(str)\nstr2 = str[l-1:0:-1]    #str[3:0:-1] \nprint(str2)\nstr2 = str[l-1:-1:-1]    #str[3:-1:-1]\nprint(str2)\n\n\nIn the first str2=str[l-1:0:-1], the upper bound is lesser than the lower bound, thus dcb is printed.\n\nHowever in str2=str[l-1:-1:-1], the upper bound is not less than the lower bound (upon converting lower bound into negative value which is -1: since index of last element is -1 as well as 3).\n\nShare\nImprove this answer\nFollow\nanswered Jul 23 '20 at 5:22\nAnshika Singh\n5927\n7 silver badges\n15\n15 bronze badges","comments":[]}]},{"id":"679915","href":"https://stackoverflow.com/questions/679915/how-do-i-test-for-an-empty-javascript-object","title":"How do I test for an empty JavaScript object?","description":"\n                \nAfter an AJAX request, sometimes my application may return an empty object, like:\n\nvar a = {};\n\n\nHow can I check whether that's the case?\n    ","questionComments":["Do you use JSON.js script? Or any other JSON library. Then you can use JSON.encode() function to convert var to string and then test it.","Just check for if (Object.keys(obj).length === 0) { // handle empty obj }","@GabrielPetersson Please never provide solutions as comments. Your comment is a violation of this Q&A's very clear/simple page design. Resolving advice is to be posted as an answer. Comments under the question should ask the OP for clarification or offer non-resolving insights. meta.stackexchange.com/a/296481/352329"],"answers":[{"answer":"ECMA 5+:\n\n// because Object.keys(new Date()).length === 0;\n// we have to do some additional check\nobj // 👈 null and undefined check\n&& Object.keys(obj).length === 0 && obj.constructor === Object\n\n\nNote, though, that this creates an unnecessary array (the return value of keys).\n\nPre-ECMA 5:\n\nfunction isEmpty(obj) {\n  for(var prop in obj) {\n    if(obj.hasOwnProperty(prop)) {\n      return false;\n    }\n  }\n\n  return JSON.stringify(obj) === JSON.stringify({});\n}\n\n\njQuery:\n\njQuery.isEmptyObject({}); // true\n\n\nlodash:\n\n_.isEmpty({}); // true\n\n\nUnderscore:\n\n_.isEmpty({}); // true\n\n\nHoek\n\nHoek.deepEqual({}, {}); // true\n\n\nExtJS\n\nExt.Object.isEmpty({}); // true\n\n\nAngularJS (version 1)\n\nangular.equals({}, {}); // true\n\n\nRamda\n\nR.isEmpty({}); // true\n\nShare\nImprove this answer\nFollow\nedited Feb 6 at 17:48\ncommunity wiki\n\n\n15 revs, 15 users 53%\nAdam Zerner","comments":["Here is performance test between jQuery and underscore jsperf.com/isempty-vs-isemptyobject/6","Object.keys(new Date()).length === 0; so this answer can be misleading.","Why do we need to check obj.contructor===Object in ECMA5+ code ? We can only use this code obj // 👈 null and undefined check && Object.keys(obj).length === 0","The comment right above yours literally explains why =) There are a million different objects, so you want to make sure to only test for \"actual object primitives\", i.e. objects whose constructor is not some extension of Object."]},{"answer":"If ECMAScript 5 support is available, you can use Object.keys():\n\nfunction isEmpty(obj) {\n    return Object.keys(obj).length === 0;\n}\n\n\nFor ES3 and older, there's no easy way to do this. You'll have to loop over the properties explicitly:\n\nfunction isEmpty(obj) {\n    for(var prop in obj) {\n        if(obj.hasOwnProperty(prop))\n            return false;\n    }\n\n    return true;\n}\n\nShare\nImprove this answer\nFollow\nedited Feb 10 at 13:25\nmikemaccana\n84.5k77\n77 gold badges\n327\n327 silver badges\n402\n402 bronze badges\nanswered Mar 25 '09 at 1:49\nChristoph\n152k36\n36 gold badges\n172\n172 silver badges\n230\n230 bronze badges","comments":["This works fine, or more simply: function isEmpty(object) { for(var i in object) { return true; } return false; }","Shouldnt true and false be reversed in this function?","@namtax: no - the function is named isEmpty(), so it should return false if it has a property","@NicholasKreidberg That code function isEmpty(object) { for(var i in object) { return true; } return false; } got to be corrected after 11 years. Here's the correction: function isEmpty(obj) {     return !(() => {         for (const i in obj) {             return true;         }         return false;     })(); }","Alernatively: function isObjectEmpty(obj) {     for (const i in obj) return false;      return true; }"]},{"answer":"For those of you who have the same problem but use jQuery, you can use jQuery.isEmptyObject.\n\nShare\nImprove this answer\nFollow\nedited May 18 '20 at 22:46\nUnmitigated\n40k7\n7 gold badges\n33\n33 silver badges\n54\n54 bronze badges\nanswered May 19 '10 at 14:07\nErik Töyrä Silfverswärd\n9,2582\n2 gold badges\n22\n22 silver badges\n21\n21 bronze badges","comments":["HEY! I just spent a few hours debugging IE 8 issues only to find that it was jQuery.isEmptyObject that was causing the problem. It returns true if the object is empty.","Why do you post answer including jQuery if the question is not about jQuery at all?","I know its an old comment, but I wonder your question @MFD3000, because the docu says: returns true, if object is empty (as the name indicates it)","including jQuery for such a basic task is not what I would call the right answer. It's true that nowadays jQuery is almost ubiquous, but still we shouldn't forget it is built around a very capable language itself.","Typical JS snobbery in these comments. Everyone knows a huge proportion of JavaScript on the web is written on jQuery, so it is perfectly acceptable to provide a solution here for jQuery if it already has a built-in method for testing objects. It's likely that thousands of developers looking for help will find this answer helpful. Nobody said it's the only way to do it. I notice how nobody acts all elitist about the guy who posted a solution to use underscore.js..."]},{"answer":"This is my preferred solution:\n\nvar obj = {};\nreturn Object.keys(obj).length; //returns 0 if empty or an integer > 0 if non-empty\n\nShare\nImprove this answer\nFollow\nanswered Jul 12 '14 at 7:46\ndhruvio\n3,5471\n1 gold badge\n9\n9 silver badges\n2\n2 bronze badges","comments":[]},{"answer":"You can use Underscore.js.\n\n_.isEmpty({}); // true\n\nShare\nImprove this answer\nFollow\nedited Jan 21 '16 at 15:54\nGabriel GM\n5,9112\n2 gold badges\n29\n29 silver badges\n32\n32 bronze badges\nanswered Mar 22 '11 at 20:35\nBaggz\n16.4k4\n4 gold badges\n35\n35 silver badges\n25\n25 bronze badges","comments":["Or you could use lodash is empty (lodash.com/docs#isEmpty), but how is that any different from using a jQuery solution - you still need to install an additional library. I think a vanilla javascript solution is the intent.","If adding the entire dependency is mortifying to your super-performance dependent application, you can install just _.isEmpty: npm i lodash.isempty"]},{"answer":"Performance\n\nToday 2020.01.17 I perform tests on macOS HighSierra 10.13.6 on Chrome v79.0, Safari v13.0.4 and Firefox v72.0, for chosen solutions.\n\nConclusions\n\nsolutions based on for-in (A,J,L,M) are fastest\nsolutions based on JSON.stringify (B,K) are slow\nsurprisingly also solution based on Object (N) is slow\n\nDetails\n\nThere are 15 solutions presented in the snippet below. If you want to run a performance test on your machine click HERE. This link was updated 2021.07.08 but tests oryginaly was performed here - and results in table above came from there (but now it looks like that service not longer works).\n\nShow code snippet\n\nIf my answer helped you can buy me a coffee\n\nShare\nImprove this answer\nFollow\nedited Jul 8 at 17:25\nanswered Jan 17 '20 at 12:53\nKamil Kiełczewski\n57.6k22\n22 gold badges\n275\n275 silver badges\n253\n253 bronze badges","comments":["a lot of this doesn't make sense because you're basing everything on a return of false and or true. Sometimes programming needs an if statement or a ternary operator. just fyi","For completeness, I edited your jsperf to test obj = {a:1,b:2,c:3} and for(var i in obj) is still the fastest jsperf.com/object-empty-ch/2","Your example site returns a 500 Internal Server Error","@marsnebulasoup answer updated - thanks"]},{"answer":"if(Object.getOwnPropertyNames(obj).length === 0){\n  //is empty\n}\n\n\nsee http://bencollier.net/2011/04/javascript-is-an-object-empty/\n\nShare\nImprove this answer\nFollow\nanswered Nov 6 '13 at 13:48\nes cologne\n2,3381\n1 gold badge\n15\n15 silver badges\n11\n11 bronze badges","comments":["This includes non-enumerable properties, in case you care.","The Object.getOwnPropertyNames({}).length is 10 times slower than the (for...in...) option - I suggest to avoid it as a way to test if an objetc is empty.","Object.getOwnPropertyNames(new Date()).length === 0; so this answer can be misleading."]},{"answer":"How about using JSON.stringify? It is almost available in all modern browsers.\n\nfunction isEmptyObject(obj){\n    return JSON.stringify(obj) === '{}';\n}\n\nShare\nImprove this answer\nFollow\nedited Mar 18 '15 at 9:31\nsktguha\n3842\n2 silver badges\n18\n18 bronze badges\nanswered Jan 23 '13 at 20:07\nAteszki\n2,02914\n14 silver badges\n11\n11 bronze badges","comments":["return (JSON.stringify(obj) == '{}')","This is slow and speed matters for this kind of utility. Quick perf test here: jsperf.com/empty-object-test","This is a very slow option - I suggest to use the (for...in) option instead","And it doesn't work for objects that contain functions.","It will also throw an error if there's a circular reference in the object. So it's slow, unreliable and can throw errors and break everything else. No reason to use it ever."]},{"answer":"Old question, but just had the issue. Including JQuery is not really a good idea if your only purpose is to check if the object is not empty. Instead, just deep into JQuery's code, and you will get the answer:\n\nfunction isEmptyObject(obj) {\n    var name;\n    for (name in obj) {\n        if (obj.hasOwnProperty(name)) {\n            return false;\n        }\n    }\n    return true;\n}\n\nShare\nImprove this answer\nFollow\nedited May 22 '17 at 17:32\npeterh\n10.1k15\n15 gold badges\n70\n70 silver badges\n89\n89 bronze badges\nanswered Jan 31 '13 at 10:55\nJonathan Petitcolas\n3,7153\n3 gold badges\n26\n26 silver badges\n41\n41 bronze badges","comments":["This is only useful if some other process hasn't added a prototype to your base object. To make this truly workable, you need to test for obj.hasOwnProperty(name)"]},{"answer":"I just ran into a similar situation. I didn't want to use JQuery, and wanted to do this using pure Javascript.\n\nAnd what I did was, used the following condition, and it worked for me.\n\nvar obj = {};\nif(JSON.stringify(obj) === '{}') { //This will check if the object is empty\n   //Code here..\n}\n\n\nFor not equal to, use this : JSON.stringify(obj) !== '{}'\n\nCheck out this JSFiddle\n\nShare\nImprove this answer\nFollow\nedited Apr 14 '15 at 4:45\nanswered Sep 22 '14 at 5:38\nAnish Nair\n3,03826\n26 silver badges\n41\n41 bronze badges","comments":["Will fail for objects with circular references as JSON.stringify specifically throws an exception for them.","@PedroMontotoGarcía Ok and how will an empty object have a circular reference?","If the object is not empty (and it should work for them too).","This seems to have been already mentioned by @Ateszki and is one of the slowest ways to check whether an object is not empty.","Oh yes.. I missed it. I ran into a situation where I wanted to achieve this javascript, and after a bit of thinking I figured out this way. @Ateszki, Even I though the way you did. :-) Btw, there were a lot of answers on this, and so I missed your answer."]},{"answer":"There is a simple way if you are on a newer browser. Object.keys(obj).length == 0\n\nShare\nImprove this answer\nFollow\nanswered Apr 29 '12 at 19:25\ndownload\n1,35811\n11 silver badges\n25\n25 bronze badges","comments":["Where does the keys property come from?","It's a standard method in ECMAScript 5.1","How can the above comment have 4 upvotes? Yes, Object.keys is a standard method but objects do not have a keys property. So this code will report any object as empty except it accidentally happens to have a property named key with a value which again as a property named length which is not zero. Horrible!","Object.keys(new Date()).length === 0; so this answer can be misleading.","@scravy Object is the class Object. Object has a static method named 'keys' which accepts an object as an argument. This method returns an array of strings where the strings are property names. developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/…"]},{"answer":"Using Object.keys(obj).length (as suggested above for ECMA 5+) is 10 times slower for empty objects! keep with the old school (for...in) option.\n\nTested under Node, Chrome, Firefox and IE 9, it becomes evident that for most use cases:\n\n(for...in...) is the fastest option to use!\nObject.keys(obj).length is 10 times slower for empty objects\nJSON.stringify(obj).length is always the slowest (not suprising)\nObject.getOwnPropertyNames(obj).length takes longer than Object.keys(obj).length can be much longer on some systems.\n\nBottom line performance wise, use:\n\nfunction isEmpty(obj) { \n   for (var x in obj) { return false; }\n   return true;\n}\n\n\nor\n\nfunction isEmpty(obj) {\n   for (var x in obj) { if (obj.hasOwnProperty(x))  return false; }\n   return true;\n}\n\n\nSee detailed testing results and test code at Is object empty?\n\nShare\nImprove this answer\nFollow\nedited Oct 30 '19 at 7:13\ntim-montague\n12.3k2\n2 gold badges\n51\n51 silver badges\n41\n41 bronze badges\nanswered Dec 28 '15 at 10:40\ndavidhadas\n2,16318\n18 silver badges\n16\n16 bronze badges","comments":["Object.keys is slow, but less code. On a small page, where this is called... maybe 10 times... Will this still be slower considering the additional parsing time of the additional code?"]},{"answer":"You could check for the count of the Object keys:\n\nif (Object.keys(a).length > 0) {\n    // not empty\n}\n\nShare\nImprove this answer\nFollow\nedited Jun 30 '17 at 12:22\ndanopz\n3,0595\n5 gold badges\n27\n27 silver badges\n36\n36 bronze badges\nanswered Jun 30 '17 at 10:11\nAshutosh Ranjan\n6245\n5 silver badges\n10\n10 bronze badges","comments":["Why would you add a comment for an answer that was already given and give a worse answer? stackoverflow.com/a/32108184/4229159 and it's the 1st answer from April","How if I have a very big object and do that on each loop just to see if the object was empty?","This answer doesn't appear to add anything that the accepted answer doesn't already say."]},{"answer":"Just a workaround. Can your server generate some special property in case of no data?\n\nFor example:\n\nvar a = {empty:true};\n\n\nThen you can easily check it in your AJAX callback code.\n\nAnother way to check it:\n\nif (a.toSource() === \"({})\")  // then 'a' is empty\n\n\nEDIT: If you use any JSON library (f.e. JSON.js) then you may try JSON.encode() function and test the result against empty value string.\n\nShare\nImprove this answer\nFollow\nedited Mar 4 '13 at 12:40\nfranzlorenzon\n5,3736\n6 gold badges\n32\n32 silver badges\n55\n55 bronze badges\nanswered Mar 25 '09 at 11:48\nThevs\n3,1032\n2 gold badges\n19\n19 silver badges\n31\n31 bronze badges","comments":["toSource() is non-standard and doesn't work in IE or Opera (and potentially other browsers I didn't check)","@Thevs: perhaps you have a different copy of the current version of ECMA-262, but mine does not list a toSource property in section 15.2.4; according to MDC, it was introduced in JS1.3 (i.e. Netscape Navigator 4.06), but it's NOT in ECMA-262, 3rd edition!","@Thevs: well, at least 2 important browser vendors didn't implement it, so it's hardly a de-facto-standard, and as it's not in ECMA-262, it's not a real one either...","Even when it does work, toSource() is a horrible way to do this (as is JSON.encode()). It needs to build a string representing your entire object to just check if it's empty. There's the overhead of converting things to strings, but moreover it will need to convert a million things if your object has a million properties, while actually just looking at one will let you know that it is not empty.","@Thevs the overhead is bigger, even if it might be (I'm not sure it is under every circumstance) in the same order of magnitude. However, that answer involves returning false as soon as a different property is found which makes the story is different all together..."]},{"answer":"As per the ES2017 specification on Object.entries(), the check is simple using any modern browser--\n\nObject.entries({}).length === 0\n\nShare\nImprove this answer\nFollow\nedited Feb 2 at 7:53\nanswered Dec 29 '18 at 9:11\nVikrant\n4884\n4 silver badges\n9\n9 bronze badges","comments":["Is there any benefit to using this over Object.keys or Object.values?","@faintsignal using those are perfectly fine. I just added entries as did not find it in the comments.","Still need to use obj.constructor === Object, as: Object.entries(new Date()).length returns 0."]},{"answer":"I've created a complete function to determine if object is empty.\n\nIt uses Object.keys from ECMAScript 5 (ES5) functionality if possible to achieve the best performance (see compatibility table) and fallbacks to the most compatible approach for older engines (browsers).\n\nSolution\n/**\n * Returns true if specified object has no properties,\n * false otherwise.\n *\n * @param {object} object\n * @returns {boolean}\n */\nfunction isObjectEmpty(object)\n{\n    if ('object' !== typeof object) {\n        throw new Error('Object must be specified.');\n    }\n\n    if (null === object) {\n        return true;\n    }\n\n    if ('undefined' !== Object.keys) {\n        // Using ECMAScript 5 feature.\n        return (0 === Object.keys(object).length);\n    } else {\n        // Using legacy compatibility mode.\n        for (var key in object) {\n            if (object.hasOwnProperty(key)) {\n                return false;\n            }\n        }\n        return true;\n    }\n}\n\n\nHere's the Gist for this code.\n\nAnd here's the JSFiddle with demonstration and a simple test.\n\nI hope it will help someone. Cheers!\n\nShare\nImprove this answer\nFollow\nedited Apr 25 '17 at 23:42\nanswered May 21 '14 at 13:55\nSlava Fomin II\n21.8k22\n22 gold badges\n100\n100 silver badges\n178\n178 bronze badges","comments":["This fails for a null object.","Hi @torazaburo! Thanks for taking a notice! I've updated all sources with correct implementation.","The Object.keys({}).length is 10 times slower than the (for...in...) option - I suggest to avoid it as a way to test if an objetc is empty.","Object.keys(new Date()).length === 0; so this answer can be misleading."]},{"answer":"My take:\n\nfunction isEmpty(obj) {\n  return Object.keys(obj).length === 0;\n}\n\nvar a = {\n  a: 1,\n  b: 2\n}\nvar b = {}\n\nconsole.log(isEmpty(a)); // false\nconsole.log(isEmpty(b)); // true\n Run code snippetExpand snippet\n\nJust, I don't think all browsers implement Object.keys() currently.\n\nShare\nImprove this answer\nFollow\nedited Jan 31 at 18:46\nCertainPerformance\n274k33\n33 gold badges\n192\n192 silver badges\n217\n217 bronze badges\nanswered Oct 31 '11 at 13:39\nNiKo\n10.7k5\n5 gold badges\n42\n42 silver badges\n56\n56 bronze badges","comments":["Object.keys(new Date()).length === 0; so this answer can be misleading.","Depends if you consider a date being always \"full\" despite never exposing keys. But I agree that if that's your plan, adding some supplementary instanceof check for Date constructor is a good option."]},{"answer":"I am using this.\n\nfunction isObjectEmpty(object) {\n  var isEmpty = true;\n  for (keys in object) {\n     isEmpty = false;\n     break; // exiting since we found that the object is not empty\n  }\n  return isEmpty;\n}\n\n\nEg:\n\nvar myObject = {}; // Object is empty\nvar isEmpty  = isObjectEmpty(myObject); // will return true;\n\n// populating the object\nmyObject = {\"name\":\"John Smith\",\"Address\":\"Kochi, Kerala\"}; \n\n// check if the object is empty\nisEmpty  = isObjectEmpty(myObject); // will return false;\n\n\nfrom here\n\nUpdate\n\nOR\n\nyou can use the jQuery implementation of isEmptyObject\n\nfunction isEmptyObject(obj) {\n  var name;\n  for (name in obj) {\n    return false;\n  }\n  return true;\n}\n\nShare\nImprove this answer\nFollow\nedited Feb 5 '20 at 8:58\nns16\n1,1062\n2 gold badges\n10\n10 silver badges\n21\n21 bronze badges\nanswered Jun 8 '12 at 8:04\nkiranvj\n23.7k5\n5 gold badges\n52\n52 silver badges\n69\n69 bronze badges","comments":["hi. when you test this function with number or boolean true or false return true and this is not correct result. isObjectEmpty(true). isObjectEmpty(false). isObjectEmpty(1)","We are checking whether the object is empty, not if the data type is an object. In your case to check if its an object we need to something like if(typeof a === \"object\") {...}"]},{"answer":"function isEmpty(obj) {\n  for(var i in obj) { return false; }\n  return true;\n}\n\nShare\nImprove this answer\nFollow\nedited Nov 1 '11 at 8:26\nLightness Races in Orbit\n362k69\n69 gold badges\n599\n599 silver badges\n994\n994 bronze badges\nanswered Apr 24 '09 at 13:09\nikettu","comments":["That'll report also true, when, for instance, a JavaScript library extends Object with a method through the prototype chain, because that's enumerable and the for in statement loops through enumerable properties."]},{"answer":"The following example show how to test if a JavaScript object is empty, if by empty we means has no own properties to it.\n\nThe script works on ES6.\n\nconst isEmpty = (obj) => {\n    if (obj === null ||\n        obj === undefined ||\n        Array.isArray(obj) ||\n        typeof obj !== 'object'\n    ) {\n        return true;\n    }\n    return Object.getOwnPropertyNames(obj).length === 0;\n};\nconsole.clear();\nconsole.log('-----');\nconsole.log(isEmpty(''));           // true\nconsole.log(isEmpty(33));           // true\nconsole.log(isEmpty([]));           // true\nconsole.log(isEmpty({}));           // true\nconsole.log(isEmpty({ length: 0, custom_property: [] })); // false\nconsole.log('-----');\nconsole.log(isEmpty('Hello'));      // true\nconsole.log(isEmpty([1, 2, 3]));    // true\nconsole.log(isEmpty({ test: 1 }));  // false\nconsole.log(isEmpty({ length: 3, custom_property: [1, 2, 3] })); // false\nconsole.log('-----');\nconsole.log(isEmpty(new Date()));   // true\nconsole.log(isEmpty(Infinity));     // true\nconsole.log(isEmpty(null));         // true\nconsole.log(isEmpty(undefined));    // true\n Run code snippetExpand snippet\n\nShare\nImprove this answer\nFollow\nedited Jul 20 '18 at 12:38\nLostMyGlasses\n2,67416\n16 silver badges\n26\n26 bronze badges\nanswered Mar 29 '17 at 10:42\nGibboK\n65.1k129\n129 gold badges\n389\n389 silver badges\n626\n626 bronze badges","comments":[]},{"answer":"jQuery have special function isEmptyObject() for this case:\n\njQuery.isEmptyObject({}) // true\njQuery.isEmptyObject({ foo: \"bar\" }) // false\n\n\nRead more on http://api.jquery.com/jQuery.isEmptyObject/\n\nShare\nImprove this answer\nFollow\nanswered Jan 25 '11 at 14:25\nAnton Danilchenko","comments":[]},{"answer":"I would go for checking if it has at least one key. That would suffice to tell me that it's not empty.\n\nBoolean(Object.keys(obj || {})[0]) // obj || {} checks for undefined\n\nShare\nImprove this answer\nFollow\nedited Feb 19 at 15:27\nanswered Sep 11 '18 at 10:35\nTudor Morar\n2,89821\n21 silver badges\n23\n23 bronze badges","comments":["what if the first key returns false value ? the result will be false which is incorrect .","I have tested for that. Can you give a working example?","this is short and concise, but will result in runtime error if the Object is undefined","@ Jimmy Obonyo Abor How can a key be false?","@Ajay even if the key is 0, the solution works"]},{"answer":"Under the hood all empty check methods in all libraries use object keys checking logic. Its an odd way to make it understandable, which you can put in a method, Described here.\n\nfor(key in obj){\n   //your work here.\n break;\n}\n\n\nWhich has evolved in ES5, now put simply you can check the object's keys length, using Object.Keys method which takes your object as it's parameter:\n\nif(Object.keys(obj).length > 0){\n //do your work here\n}\n\n\nOr if you are using Lodash (you must be) then.\n\n _.isEmpty(obj) //==true or false\n\nShare\nImprove this answer\nFollow\nedited Jan 28 '19 at 11:42\nuser5283119\nanswered May 15 '14 at 12:51\nahmadalibaloch\n5,3841\n1 gold badge\n41\n41 silver badges\n55\n55 bronze badges","comments":["While is is correct as an odd way of making an if-statement -- it will probably confuse somebody who will maintain the code after you."]},{"answer":"\nyou can use this simple code that did not use jQuery or other libraries\n\nvar a=({});\n\n//check is an empty object\nif(JSON.stringify(a)=='{}') {\n    alert('it is empty');\n} else {\n    alert('it is not empty');\n}\n\n\nJSON class and it's functions (parse and stringify) are very usefull but has some problems with IE7 that you can fix it with this simple code http://www.json.org/js.html.\n\nOther Simple Way (simplest Way) :\nyou can use this way without using jQuery or JSON object.\n\n\nvar a=({});\n\nfunction isEmptyObject(obj) {\n    if(typeof obj!='object') {\n        //it is not object, so is not empty\n        return false;\n    } else {\n        var x,i=0;\n        for(x in obj) {\n            i++;\n        }\n        if(i>0) {\n            //this object has some properties or methods\n            return false;\n        } else {\n            //this object has not any property or method\n            return true;\n        }\n    }\n}\n\nalert(isEmptyObject(a));    //true is alerted\n\nShare\nImprove this answer\nFollow\nedited Sep 3 '13 at 4:34\nanswered Aug 28 '13 at 6:33\niman\n5,4091\n1 gold badge\n17\n17 silver badges\n23\n23 bronze badges","comments":["JSON.stringify solution fails if object contains non-stringifiable properties such as functions or \"undefined\", although granted that's an edge case."]},{"answer":"Best way that I found:\n\nfunction isEmpty(obj)\n{\n    if (!obj)\n    {\n        return true;\n    }\n\n    if (!(typeof(obj) === 'number') && !Object.keys(obj).length)\n    {\n        return true;\n    }\n\n    return false;\n}\n\n\nWorks for:\n\n    t1: {} -> true\n    t2: {0:1} -: false\n    t3: [] -> true\n    t4: [2] -> false\n    t5: null -> true\n    t6: undefined -> true\n    t7: \"\" -> true\n    t8: \"a\" -> false\n    t9: 0 -> true\n    t10: 1 -> false\n\nShare\nImprove this answer\nFollow\nanswered Mar 15 '17 at 13:32\nDiegoAraujo\n1351\n1 silver badge\n6\n6 bronze badges","comments":["I would say that 0 is not empty since it is actually a number. everything else looks good but the fix is easy. in the first if statement add this. if (!obj && obj !== 0)."]},{"answer":"If jQuery and the web browser is not available, there is also an isEmpty function in underscore.js.\n\n_.isEmpty({}) // returns true\n\n\nAdditionally, it does not assume the input parameter to be an object. For a list or string or undefined, it will also turn the correct answer.\n\nShare\nImprove this answer\nFollow\nanswered Jan 14 '14 at 3:02\njichi\n5,0901\n1 gold badge\n28\n28 silver badges\n25\n25 bronze badges","comments":["Underscore was already mentioned in an answer a few years earlier."]},{"answer":"The correct answer is:\n\nconst isEmptyObject = obj =>\n  Object.getOwnPropertyNames(obj).length === 0 &&\n  Object.getOwnPropertySymbols(obj).length === 0 &&\n  Object.getPrototypeOf(obj) === Object.prototype;\n\n\nThis checks that:\n\nThe object has no own properties (regardless of enumerability).\nThe object has no own property symbols.\nThe object's prototype is exactly Object.prototype.\n\nIn other words, the object is indistinguishable from one created with {}.\n\nShare\nImprove this answer\nFollow\nedited Jun 5 '18 at 1:27\nanswered Apr 9 '18 at 9:37\nJesse\n5,5763\n3 gold badges\n34\n34 silver badges\n39\n39 bronze badges","comments":[]},{"answer":"A simpler solution: var a = {};\nCase a is empty: !Object.keys(a).length returns true.\n\nShare\nImprove this answer\nFollow\nanswered Aug 21 '20 at 17:43\nDohd\n1832\n2 silver badges\n4\n4 bronze badges","comments":[]},{"answer":"In addition to Thevs answer:\n\nvar o = {};\nalert($.toJSON(o)=='{}'); // true\n\nvar o = {a:1};\nalert($.toJSON(o)=='{}'); // false\n\n\nit's jquery + jquery.json\n\nShare\nImprove this answer\nFollow\nanswered Feb 26 '10 at 12:33\nstarikovs\n2,7641\n1 gold badge\n25\n25 silver badges\n30\n30 bronze badges","comments":["I don't like using JSON because it can't work with circular object structures.","If your page loads jQuery then use $.isEmptyObject(), don't waste cycles with non-obvious conversions."]},{"answer":"Caveat! Beware of JSON's limitiations.\n\njavascript:\n  obj={  f:function(){}  };\n  alert( \"Beware!! obj is NOT empty!\\n\\nobj = {  f:function(){}  }\" + \n               \"\\n\\nJSON.stringify( obj )\\n\\nreturns\\n\\n\" +\n                        JSON.stringify( obj ) );\n\n\ndisplays\n\n    Beware!! obj is NOT empty!\n\n    obj = {  f:function(){}  }\n\n    JSON.stringify( obj )\n\n    returns\n\n    {}\n\nShare\nImprove this answer\nFollow\nanswered May 24 '11 at 1:52\nEkim\n9331\n1 gold badge\n8\n8 silver badges\n7\n7 bronze badges","comments":[]}]}]